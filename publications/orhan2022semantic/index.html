<!DOCTYPE html>
<html lang="en-us">

  <!-- _includes/head.html -->
<head>
  <!-- begin code v 7.0 -->
  <span id="wts2185304"></span>
  <script>
  var wts7 = {};
  wts7.invisible='';
  wts7.page_name='';
  wts7.group_name='';
  wts7.conversion_number='';
  wts7.user_id='';
  var wts=document.createElement('script');wts.async=true;
  wts.src='https://app.ardalio.com/wts7.js';document.head.appendChild(wts);
  wts.onload = function(){ wtsl7(2185304,4); };
  </script><noscript><img src="https://app.ardalio.com/7/4/2185304.png"></noscript>
  <!-- end code v 7.0 -->
  <!-- MathJax -->
  <script>
    window.MathJax = {
      tex: { inlineMath: [["\\(","\\)"]], displayMath: [["\\[","\\]"]] },
      options: { processHtmlClass: "mathjax-content", processEscapes: true }
    };
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <link href="https://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta charset="utf-8">

  <!-- Viewport -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- ✅ Manual SEO keywords (specific to Learning to Hash) -->
  <meta name="keywords" content="learning to hash, machine learning, hashing, approximate nearest neighbour search, ANN, LSH, locality sensitive hashing, vector quantization, deep hashing, binary embeddings, information retrieval, similarity search">

  <!-- ✅ Jekyll SEO plugin (title, description, canonical, OG/Twitter, JSON-LD) -->
  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Semantic Pose Verification For Outdoor Visual Localization With Self-supervised Contrastive Learning | Awesome Learning to Hash</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="Semantic Pose Verification For Outdoor Visual Localization With Self-supervised Contrastive Learning" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Any city-scale visual localization system has to overcome long-term appearance changes, such as varying illumination conditions or seasonal changes between query and database images. Since semantic content is more robust to such changes, we exploit semantic information to improve visual localization. In our scenario, the database consists of gnomonic views generated from panoramic images (e.g. Google Street View) and query images are collected with a standard field-of-view camera at a different time. To improve localization, we check the semantic similarity between query and database images, which is not trivial since the position and viewpoint of the cameras do not exactly match. To learn similarity, we propose training a CNN in a self-supervised fashion with contrastive learning on a dataset of semantically segmented images. With experiments we showed that this semantic similarity estimation approach works better than measuring the similarity at pixel-level. Finally, we used the semantic similarity scores to verify the retrievals obtained by a state-of-the-art visual localization method and observed that contrastive learning-based pose verification increases top-1 recall value to 0.90 which corresponds to a 2% improvement." />
<meta property="og:description" content="Any city-scale visual localization system has to overcome long-term appearance changes, such as varying illumination conditions or seasonal changes between query and database images. Since semantic content is more robust to such changes, we exploit semantic information to improve visual localization. In our scenario, the database consists of gnomonic views generated from panoramic images (e.g. Google Street View) and query images are collected with a standard field-of-view camera at a different time. To improve localization, we check the semantic similarity between query and database images, which is not trivial since the position and viewpoint of the cameras do not exactly match. To learn similarity, we propose training a CNN in a self-supervised fashion with contrastive learning on a dataset of semantically segmented images. With experiments we showed that this semantic similarity estimation approach works better than measuring the similarity at pixel-level. Finally, we used the semantic similarity scores to verify the retrievals obtained by a state-of-the-art visual localization method and observed that contrastive learning-based pose verification increases top-1 recall value to 0.90 which corresponds to a 2% improvement." />
<link rel="canonical" href="https://learning2hash.github.io/publications/orhan2022semantic/" />
<meta property="og:url" content="https://learning2hash.github.io/publications/orhan2022semantic/" />
<meta property="og:site_name" content="Awesome Learning to Hash" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-08-20T13:32:23-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Semantic Pose Verification For Outdoor Visual Localization With Self-supervised Contrastive Learning" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-08-20T13:32:23-05:00","datePublished":"2025-08-20T13:32:23-05:00","description":"Any city-scale visual localization system has to overcome long-term appearance changes, such as varying illumination conditions or seasonal changes between query and database images. Since semantic content is more robust to such changes, we exploit semantic information to improve visual localization. In our scenario, the database consists of gnomonic views generated from panoramic images (e.g. Google Street View) and query images are collected with a standard field-of-view camera at a different time. To improve localization, we check the semantic similarity between query and database images, which is not trivial since the position and viewpoint of the cameras do not exactly match. To learn similarity, we propose training a CNN in a self-supervised fashion with contrastive learning on a dataset of semantically segmented images. With experiments we showed that this semantic similarity estimation approach works better than measuring the similarity at pixel-level. Finally, we used the semantic similarity scores to verify the retrievals obtained by a state-of-the-art visual localization method and observed that contrastive learning-based pose verification increases top-1 recall value to 0.90 which corresponds to a 2% improvement.","headline":"Semantic Pose Verification For Outdoor Visual Localization With Self-supervised Contrastive Learning","mainEntityOfPage":{"@type":"WebPage","@id":"https://learning2hash.github.io/publications/orhan2022semantic/"},"url":"https://learning2hash.github.io/publications/orhan2022semantic/"}</script>
<!-- End Jekyll SEO tag -->


  <!-- Site CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="shortcut icon" href="/public/favicon.svg">
  <link rel="search" href="/public/opensearchdescription.xml" type="application/opensearchdescription+xml" title="learning2hash" />

  <!-- ✅ Single, modern jQuery + DataTables -->
  <link rel="stylesheet" href="https://cdn.datatables.net/1.13.6/css/jquery.dataTables.min.css">
  <script src="https://code.jquery.com/jquery-3.7.0.min.js" defer></script>
  <script src="https://cdn.datatables.net/1.13.6/js/jquery.dataTables.min.js" defer></script>

  <!-- Optional sanity log -->
  <script defer>
    window.addEventListener('DOMContentLoaded', () => {
      console.log('jQuery:', jQuery?.fn?.jquery);
      console.log('DataTables loaded:', !!jQuery?.fn?.dataTable);
    });
  </script>
</head>


  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

  <body class="theme-base-0c layout-reverse">

    <a href='/contributing.html' class='ribbon'>Add your paper to Learning2Hash</a>
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Awesome Learning to Hash
        </a>
      </h1>
      <p class="lead">A Webpage dedicated to the latest research on Hash Function Learning. Maintained by <a href="http://sjmoran.github.io/">Sean Moran</a>.</p>
    </div>

    <nav class="sidebar-nav">
      <div class="sidebar-item">
        <p style="font-size: 12px">
          Search related work 
          <input type='text' id='searchTarget' size="16"/> 
          <button onClick="search();">Go</button>
        </p>
      </div>
      <a class="sidebar-nav-item" href="/papers.html">All Papers</a>
      <a class="sidebar-nav-item" href="/tags.html">Papers by Tag</a>
      <a class="sidebar-nav-item" href="/tsne-viz.html">2D Map of Papers</a>
      <a class="sidebar-nav-item" href="/topic-viz.html">Topic Explorer</a>
      <a class="sidebar-nav-item" href="/author-viz.html">Author Explorer </a>
      <a class="sidebar-nav-item" href="/opensource.html">Tools Explorer </a>
      <a class="sidebar-nav-item" href="/tutorial.html">Tutorial</a>
      <a class="sidebar-nav-item" href="/resources.html">Resources, Courses &#38; Events</a>
      <a class="sidebar-nav-item" href="/contributing.html">Contributing</a>
    </nav>

    <div class="sidebar-item">
      <p style="font-size: 12px">
        Contact <a href="http://www.seanjmoran.com">Sean Moran</a> about this survey or website.
        <span style="font-size: 9px">
          Made with <a href="https://jekyllrb.com">Jekyll</a> and <a href="https://github.com/poole/hyde">Hyde</a>.
        </span>
      </p>
    </div>
  </div>
</div>

<script defer>
document.addEventListener('DOMContentLoaded', function () {
  function doSearch() {
    const el = document.getElementById('searchTarget');
    if (!el) return;
    const q = el.value.trim();
    try { if (typeof ga === 'function') ga('send', 'event', 'search', 'search', q); } catch(e) {}
    window.location = "/papers.html#" + encodeURIComponent(q);
  }

  // jQuery path if loaded
  if (window.jQuery) {
    $('#searchTarget').on('keydown', function (e) {
      if (e.key === 'Enter') doSearch();
    });
    document.querySelector('.sidebar-item button')?.addEventListener('click', doSearch);
  } else {
    // vanilla fallback
    const input = document.getElementById('searchTarget');
    const btn = document.querySelector('.sidebar-item button');
    if (input) {
      input.addEventListener('keydown', function (e) {
        if (e.key === 'Enter') doSearch();
      });
    }
    if (btn) btn.addEventListener('click', doSearch);
  }

  // keep global for inline onClick="search()"
  window.search = doSearch;
});
</script>


    <div class="content container">
      <div class="page">
  <h1 class="page-title">Semantic Pose Verification For Outdoor Visual Localization With Self-supervised Contrastive Learning</h1>
  <h5>
  
    
      Semih Orhan, Jose J. Guerrero, Yalin Bastanlar
    
  
  . 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)
   2022
  
    – <span>5 citations</span>
  
  </h5>
  <p>
    
      [<a href="https://arxiv.org/abs/2203.16945" target="_blank">Paper</a>]
    
    &nbsp;<a href='http://scholar.google.com/scholar?q=Semantic Pose Verification For Outdoor Visual Localization With Self-supervised Contrastive Learning' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
    &nbsp;<a href='https://www.semanticscholar.org/search?q=Semantic Pose Verification For Outdoor Visual Localization With Self-supervised Contrastive Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
    <br/>
    
      <tag><a href="/tags.html#Datasets">Datasets</a></tag>
    
      <tag><a href="/tags.html#Supervised">Supervised</a></tag>
    
      <tag><a href="/tags.html#Self-Supervised">Self-Supervised</a></tag>
    
      <tag><a href="/tags.html#Evaluation">Evaluation</a></tag>
    
      <tag><a href="/tags.html#CVPR">CVPR</a></tag>
    
  </p>
  <p><p>Any city-scale visual localization system has to overcome long-term
appearance changes, such as varying illumination conditions or seasonal changes
between query and database images. Since semantic content is more robust to
such changes, we exploit semantic information to improve visual localization.
In our scenario, the database consists of gnomonic views generated from
panoramic images (e.g. Google Street View) and query images are collected with
a standard field-of-view camera at a different time. To improve localization,
we check the semantic similarity between query and database images, which is
not trivial since the position and viewpoint of the cameras do not exactly
match. To learn similarity, we propose training a CNN in a self-supervised
fashion with contrastive learning on a dataset of semantically segmented
images. With experiments we showed that this semantic similarity estimation
approach works better than measuring the similarity at pixel-level. Finally, we
used the semantic similarity scores to verify the retrievals obtained by a
state-of-the-art visual localization method and observed that contrastive
learning-based pose verification increases top-1 recall value to 0.90 which
corresponds to a 2% improvement.</p>
</p>

  <h6>Similar Work</h6>
  <p>
    <ul id="relwork">

    </ul>
  </p>

 <script>  
    $(document).ready(
      function() {
        $.getJSON("/publications-metadata/orhan2022semantic.json", function(data) {
          num_papers = data.length;
          html = "";
          for (let i=0; i < num_papers; i++) {
              html += '<li><a href="/publications/' + data[i][0] + '">'+ data[i][1] +'</a></li>'
          }
          $("#relwork").append(html);
        });
      });
  </script>


</div>

    </div>

  </body>
</html>
