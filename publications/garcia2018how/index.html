<!DOCTYPE html>
<html lang="en-us">

  <!-- _includes/head.html -->
<head>
  <!-- begin code v 7.0 -->
  <span id="wts2185304"></span>
  <script>
  var wts7 = {};
  wts7.invisible='';
  wts7.page_name='';
  wts7.group_name='';
  wts7.conversion_number='';
  wts7.user_id='';
  var wts=document.createElement('script');wts.async=true;
  wts.src='https://app.ardalio.com/wts7.js';document.head.appendChild(wts);
  wts.onload = function(){ wtsl7(2185304,4); };
  </script><noscript><img src="https://app.ardalio.com/7/4/2185304.png"></noscript>
  <!-- end code v 7.0 -->
  <!-- MathJax -->
  <script>
    window.MathJax = {
      tex: { inlineMath: [["\\(","\\)"]], displayMath: [["\\[","\\]"]] },
      options: { processHtmlClass: "mathjax-content", processEscapes: true }
    };
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <link href="https://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta charset="utf-8">

  <!-- Viewport -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- ✅ Manual SEO keywords (specific to Learning to Hash) -->
  <meta name="keywords" content="learning to hash, machine learning, hashing, approximate nearest neighbour search, ANN, LSH, locality sensitive hashing, vector quantization, deep hashing, binary embeddings, information retrieval, similarity search">

  <!-- ✅ Jekyll SEO plugin (title, description, canonical, OG/Twitter, JSON-LD) -->
  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>How To Read Paintings: Semantic Art Understanding With Multi-modal Retrieval | Awesome Learning to Hash</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="How To Read Paintings: Semantic Art Understanding With Multi-modal Retrieval" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Automatic art analysis has been mostly focused on classifying artworks into different artistic styles. However, understanding an artistic representation involves more complex processes, such as identifying the elements in the scene or recognizing author influences. We present SemArt, a multi-modal dataset for semantic art understanding. SemArt is a collection of fine-art painting images in which each image is associated to a number of attributes and a textual artistic comment, such as those that appear in art catalogues or museum collections. To evaluate semantic art understanding, we envisage the Text2Art challenge, a multi-modal retrieval task where relevant paintings are retrieved according to an artistic text, and vice versa. We also propose several models for encoding visual and textual artistic representations into a common semantic space. Our best approach is able to find the correct image within the top 10 ranked images in the 45.5% of the test samples. Moreover, our models show remarkable levels of art understanding when compared against human evaluation." />
<meta property="og:description" content="Automatic art analysis has been mostly focused on classifying artworks into different artistic styles. However, understanding an artistic representation involves more complex processes, such as identifying the elements in the scene or recognizing author influences. We present SemArt, a multi-modal dataset for semantic art understanding. SemArt is a collection of fine-art painting images in which each image is associated to a number of attributes and a textual artistic comment, such as those that appear in art catalogues or museum collections. To evaluate semantic art understanding, we envisage the Text2Art challenge, a multi-modal retrieval task where relevant paintings are retrieved according to an artistic text, and vice versa. We also propose several models for encoding visual and textual artistic representations into a common semantic space. Our best approach is able to find the correct image within the top 10 ranked images in the 45.5% of the test samples. Moreover, our models show remarkable levels of art understanding when compared against human evaluation." />
<link rel="canonical" href="https://learning2hash.github.io/publications/garcia2018how/" />
<meta property="og:url" content="https://learning2hash.github.io/publications/garcia2018how/" />
<meta property="og:site_name" content="Awesome Learning to Hash" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-10-11T02:23:52-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="How To Read Paintings: Semantic Art Understanding With Multi-modal Retrieval" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-10-11T02:23:52-05:00","datePublished":"2025-10-11T02:23:52-05:00","description":"Automatic art analysis has been mostly focused on classifying artworks into different artistic styles. However, understanding an artistic representation involves more complex processes, such as identifying the elements in the scene or recognizing author influences. We present SemArt, a multi-modal dataset for semantic art understanding. SemArt is a collection of fine-art painting images in which each image is associated to a number of attributes and a textual artistic comment, such as those that appear in art catalogues or museum collections. To evaluate semantic art understanding, we envisage the Text2Art challenge, a multi-modal retrieval task where relevant paintings are retrieved according to an artistic text, and vice versa. We also propose several models for encoding visual and textual artistic representations into a common semantic space. Our best approach is able to find the correct image within the top 10 ranked images in the 45.5% of the test samples. Moreover, our models show remarkable levels of art understanding when compared against human evaluation.","headline":"How To Read Paintings: Semantic Art Understanding With Multi-modal Retrieval","mainEntityOfPage":{"@type":"WebPage","@id":"https://learning2hash.github.io/publications/garcia2018how/"},"url":"https://learning2hash.github.io/publications/garcia2018how/"}</script>
<!-- End Jekyll SEO tag -->


  <!-- Site CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="shortcut icon" href="/public/favicon.ico">
  <link rel="search" href="/public/opensearchdescription.xml" type="application/opensearchdescription+xml" title="learning2hash" />

  <!-- ✅ Single, modern jQuery + DataTables -->
  <link rel="stylesheet" href="https://cdn.datatables.net/1.13.6/css/jquery.dataTables.min.css">
  <script src="https://code.jquery.com/jquery-3.7.0.min.js" defer></script>
  <script src="https://cdn.datatables.net/1.13.6/js/jquery.dataTables.min.js" defer></script>

  <!-- Optional sanity log -->
  <script defer>
    window.addEventListener('DOMContentLoaded', () => {
      console.log('jQuery:', jQuery?.fn?.jquery);
      console.log('DataTables loaded:', !!jQuery?.fn?.dataTable);
    });
  </script>
</head>


  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

  <body class="theme-base-0c layout-reverse">

    <a href='/contributing.html' class='ribbon'>Add your paper to Learning2Hash</a>
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Awesome Learning to Hash
        </a>
      </h1>
      <p class="lead">A Webpage dedicated to the latest research on Hash Function Learning. Maintained by <a href="http://sjmoran.github.io/">Sean Moran</a>.</p>
    </div>

    <nav class="sidebar-nav">
      <div class="sidebar-item">
        <p style="font-size: 12px">
          Search related work 
          <input type='text' id='searchTarget' size="16"/> 
          <button onClick="search();">Go</button>
        </p>
      </div>
      <a class="sidebar-nav-item" href="/papers.html">All Papers</a>
      <a class="sidebar-nav-item" href="/tags.html">Papers by Tag</a>
      <a class="sidebar-nav-item" href="/tsne-viz.html">2D Map of Papers</a>
      <a class="sidebar-nav-item" href="/topic-viz.html">Topic Explorer</a>
      <a class="sidebar-nav-item" href="/author-viz.html">Author Explorer </a>
      <a class="sidebar-nav-item" href="/opensource.html">Tools Explorer </a>
      <a class="sidebar-nav-item" href="/tutorial.html">Tutorial</a>
      <a class="sidebar-nav-item" href="/resources.html">Resources, Courses &#38; Events</a>
      <a class="sidebar-nav-item" href="/contributing.html">Contributing</a>
    </nav>

    <div class="sidebar-item">
      <p style="font-size: 12px">
        Contact <a href="http://www.seanjmoran.com">Sean Moran</a> about this survey or website.
        <span style="font-size: 9px">
          Made with <a href="https://jekyllrb.com">Jekyll</a> and <a href="https://github.com/poole/hyde">Hyde</a>.
        </span>
      </p>
    </div>
  </div>
</div>

<script defer>
document.addEventListener('DOMContentLoaded', function () {
  function doSearch() {
    const el = document.getElementById('searchTarget');
    if (!el) return;
    const q = el.value.trim();
    try { if (typeof ga === 'function') ga('send', 'event', 'search', 'search', q); } catch(e) {}
    window.location = "/papers.html#" + encodeURIComponent(q);
  }

  // jQuery path if loaded
  if (window.jQuery) {
    $('#searchTarget').on('keydown', function (e) {
      if (e.key === 'Enter') doSearch();
    });
    document.querySelector('.sidebar-item button')?.addEventListener('click', doSearch);
  } else {
    // vanilla fallback
    const input = document.getElementById('searchTarget');
    const btn = document.querySelector('.sidebar-item button');
    if (input) {
      input.addEventListener('keydown', function (e) {
        if (e.key === 'Enter') doSearch();
      });
    }
    if (btn) btn.addEventListener('click', doSearch);
  }

  // keep global for inline onClick="search()"
  window.search = doSearch;
});
</script>


    <div class="content container">
      <div class="page">
  <h1 class="page-title">How To Read Paintings: Semantic Art Understanding With Multi-modal Retrieval</h1>

  <h5>
    
    
    <a href="https://scholar.google.com/scholar?q=Noa%20Garcia,%20George%20Vogiatzis" 
       target="_blank" rel="noopener noreferrer">
      Noa Garcia, George Vogiatzis
    </a>
    
    
    . Lecture Notes in Computer Science
     2019
    
      – <span>97 citations</span>
    
  </h5>

  <!-- Inline Share Buttons -->
  <div class="share-buttons">
    <button id="share-twitter" class="icon-btn" title="Share on X (Twitter)" aria-label="Share on X (Twitter)">
      <img src="/public/media/x.svg" alt="X (Twitter) icon">
    </button>
    <button id="share-linkedin" class="icon-btn" title="Share on LinkedIn" aria-label="Share on LinkedIn">
      <img src="/public/media/linkedin.svg" alt="LinkedIn icon">
    </button>
    <button id="share-copy" class="icon-btn copy-btn" title="Copy Link" aria-label="Copy link to clipboard">
      <svg viewBox="0 0 24 24" width="18" height="18" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
      </svg>
      <span class="copy-label">Copy</span>
    </button>
  </div>

  <p>
    
      [<a href="https://arxiv.org/abs/1810.09617" target="_blank" rel="noopener noreferrer">Paper</a>]
    
    &nbsp;<a href="https://scholar.google.com/scholar?q=How%20To%20Read%20Paintings:%20Semantic%20Art%20Understanding%20With%20Multi-modal%20Retrieval" target="_blank" rel="noopener noreferrer">
      <img style="display:inline; margin:0;" src="/public/media/google-scholar.png" alt="Search on Google Scholar"/>
    </a>
    &nbsp;<a href="https://www.semanticscholar.org/search?q=How%20To%20Read%20Paintings:%20Semantic%20Art%20Understanding%20With%20Multi-modal%20Retrieval" target="_blank" rel="noopener noreferrer">
      <img style="display:inline; margin:0;" src="/public/media/semscholar.png" alt="Search on Semantic Scholar"/>
    </a>
    <br/>
    
      <tag><a href="/tags.html#Datasets">Datasets</a></tag>
    
      <tag><a href="/tags.html#Evaluation">Evaluation</a></tag>
    
  </p>

  <p><p>Automatic art analysis has been mostly focused on classifying artworks into
different artistic styles. However, understanding an artistic representation
involves more complex processes, such as identifying the elements in the scene
or recognizing author influences. We present SemArt, a multi-modal dataset for
semantic art understanding. SemArt is a collection of fine-art painting images
in which each image is associated to a number of attributes and a textual
artistic comment, such as those that appear in art catalogues or museum
collections. To evaluate semantic art understanding, we envisage the Text2Art
challenge, a multi-modal retrieval task where relevant paintings are retrieved
according to an artistic text, and vice versa. We also propose several models
for encoding visual and textual artistic representations into a common semantic
space. Our best approach is able to find the correct image within the top 10
ranked images in the 45.5% of the test samples. Moreover, our models show
remarkable levels of art understanding when compared against human evaluation.</p>
</p>

  <h6>Similar Work</h6>
  <ul id="relwork"></ul>

  <script>
    document.addEventListener('DOMContentLoaded', function () {
      const relwork = document.getElementById('relwork');
      if (relwork) {
        const metaPath = "/publications-metadata/garcia2018how.json";
        fetch(metaPath, { credentials: 'same-origin' })
          .then(res => {
            if (!res.ok) throw new Error(res.status + " " + res.statusText);
            return res.json();
          })
          .then(data => {
            if (!Array.isArray(data)) return;
            relwork.innerHTML = data
              .map(d => `<li><a href="/publications/${d[0]}">${d[1]}</a></li>`)
              .join('');
          })
          .catch(err => console.warn("Failed to load similar work JSON:", err));
      }

      const meta = {
        title: "How To Read Paintings: Semantic Art Understanding With Multi-modal Retrieval",
        conference: "Lecture Notes in Computer Science",
        year: 2019,
        tags: ["Datasets","Evaluation"]
      };

      const pageUrl = encodeURIComponent(window.location.href);
      let tweetText = `New paper: ${meta.title}`;
      if (meta.conference) tweetText += ` — ${meta.conference}`;
      if (meta.year) tweetText += ` (${meta.year})`;
      tweetText += ` 🔍`;

      const hashtags = (Array.isArray(meta.tags) ? meta.tags : [])
        .slice(0, 3)
        .map(t => String(t).replace(/[^A-Za-z0-9]/g, ''))
        .filter(Boolean)
        .join(',');

      const twitterBtn  = document.getElementById('share-twitter');
      const linkedinBtn = document.getElementById('share-linkedin');
      const copyBtn     = document.getElementById('share-copy');

      if (twitterBtn) {
        twitterBtn.addEventListener('click', () => {
          const customText = encodeURIComponent(tweetText);
          const hashParam  = hashtags ? `&hashtags=${encodeURIComponent(hashtags)}` : '';
          window.open(
            `https://twitter.com/intent/tweet?text=${customText}&url=${pageUrl}${hashParam}`,
            '_blank', 'noopener,noreferrer'
          );
        });
      }

      if (linkedinBtn) {
        linkedinBtn.addEventListener('click', () => {
          window.open(
            `https://www.linkedin.com/sharing/share-offsite/?url=${pageUrl}`,
            '_blank', 'noopener,noreferrer'
          );
        });
      }

      if (copyBtn) {
        copyBtn.addEventListener('click', () => {
          navigator.clipboard.writeText(window.location.href).then(() => {
            copyBtn.classList.add('copied');
            setTimeout(() => copyBtn.classList.remove('copied'), 900);
          });
        });
      }
    });
  </script>

  <style>
    .share-buttons {
      display: flex;
      gap: 8px;
      align-items: center;
      margin: 0.4em 0 1em 0;
      opacity: 0.9;
      flex-wrap: wrap;
    }

    .icon-btn {
      appearance: none;
      background: #f8f8f8;
      border: none;
      border-radius: 8px;
      width: 38px;
      height: 38px;
      display: inline-flex;
      flex-direction: column;
      align-items: center;
      justify-content: flex-start; /* start high, then push down */
      padding-top: 8px; /* lower the icons visually */
      cursor: pointer;
      transition: background 0.15s ease, transform 0.15s ease;
      position: relative;
    }

    .icon-btn img,
    .icon-btn svg {
      display: block;
      margin-top: 4px; /* fine-tune visual center */
      width: 18px;
      height: 18px;
      opacity: 0.8;
      object-fit: contain;
      object-position: center;
    }

    /* Copy button label */
    .copy-btn {
      width: auto;
      padding: 0 12px;
      flex-direction: row;
      align-items: center;
      justify-content: center;
      gap: 6px;
    }

    .copy-btn .copy-label {
      font-size: 0.85em;
      font-weight: 500;
      color: #333;
      user-select: none;
      margin-top: 2px;
    }

    .icon-btn:hover {
      background: #e9e9e9;
      transform: translateY(-1px);
    }

    .icon-btn:hover img,
    .icon-btn:hover svg {
      opacity: 1;
    }

    .icon-btn.copied {
      background: #d9f7e6;
    }
  </style>
</div>

    </div>

  </body>
</html>
