<hr />
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>layout: publication
title: "Learning Deep Structure-Preserving Image-Text Embeddings"
authors: Wang Liwei, Li Yin, Lazebnik Svetlana
conference: Arxiv
year: 2015
bibkey: wang2015learning
additional_links:
   - {name: "License", url: "http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}    - {name: "Paper", url: "https://arxiv.org/abs/1511.06078"}
tags: ['Arxiv', 'TIP', 'Image Retrieval']
---

This paper proposes a method for learning joint embeddings of images and text using a two-branch neural network with multiple layers of linear projections followed by nonlinearities. The network is trained using a large margin objective that combines cross-view ranking constraints with within-view neighborhood structure preservation constraints inspired by metric learning literature. Extensive experiments show that our approach gains significant improvements in accuracy for image-to-text and text-to-image retrieval. Our method achieves new state-of-the-art results on the Flickr30K and MSCOCO image-sentence datasets and shows promise on the new task of phrase localization on the Flickr30K Entities dataset.
</code></pre></div></div>

