<!DOCTYPE html>
<html lang="en-us">

  <!-- _includes/head.html -->
<head>
  <!-- begin code v 7.0 -->
  <span id="wts2185304"></span>
  <script>
  var wts7 = {};
  wts7.invisible='';
  wts7.page_name='';
  wts7.group_name='';
  wts7.conversion_number='';
  wts7.user_id='';
  var wts=document.createElement('script');wts.async=true;
  wts.src='https://app.ardalio.com/wts7.js';document.head.appendChild(wts);
  wts.onload = function(){ wtsl7(2185304,4); };
  </script><noscript><img src="https://app.ardalio.com/7/4/2185304.png"></noscript>
  <!-- end code v 7.0 -->
  <!-- MathJax -->
  <script>
    window.MathJax = {
      tex: { inlineMath: [["\\(","\\)"]], displayMath: [["\\[","\\]"]] },
      options: { processHtmlClass: "mathjax-content", processEscapes: true }
    };
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <link href="https://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta charset="utf-8">

  <!-- Viewport -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- ✅ Manual SEO keywords (specific to Learning to Hash) -->
  <meta name="keywords" content="learning to hash, machine learning, hashing, approximate nearest neighbour search, ANN, LSH, locality sensitive hashing, vector quantization, deep hashing, binary embeddings, information retrieval, similarity search">

  <!-- ✅ Jekyll SEO plugin (title, description, canonical, OG/Twitter, JSON-LD) -->
  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Hypercube LSH For Approximate Near Neighbors | Awesome Learning to Hash</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="Hypercube LSH For Approximate Near Neighbors" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A celebrated technique for finding near neighbors for the angular distance involves using a set of \textit{random} hyperplanes to partition the space into hash regions [Charikar, STOC 2002]. Experiments later showed that using a set of \textit{orthogonal} hyperplanes, thereby partitioning the space into the Voronoi regions induced by a hypercube, leads to even better results [Terasawa and Tanaka, WADS 2007]. However, no theoretical explanation for this improvement was ever given, and it remained unclear how the resulting hypercube hash method scales in high dimensions. In this work, we provide explicit asymptotics for the collision probabilities when using hypercubes to partition the space. For instance, two near-orthogonal vectors are expected to collide with probability ((\frac{1}{\pi})^{d + o(d)}) in dimension (d), compared to ((\frac{1}{2})^d) when using random hyperplanes. Vectors at angle (\frac{\pi}{3}) collide with probability ((\frac{\sqrt{3}}{\pi})^{d + o(d)}), compared to ((\frac{2}{3})^d) for random hyperplanes, and near-parallel vectors collide with similar asymptotic probabilities in both cases. For (c)-approximate nearest neighbor searching, this translates to a decrease in the exponent (\rho) of locality-sensitive hashing (LSH) methods of a factor up to (log_2(\pi) \approx 1.652) compared to hyperplane LSH. For (c = 2), we obtain (\rho \approx 0.302 + o(1)) for hypercube LSH, improving upon the (\rho \approx 0.377) for hyperplane LSH. We further describe how to use hypercube LSH in practice, and we consider an example application in the area of lattice algorithms." />
<meta property="og:description" content="A celebrated technique for finding near neighbors for the angular distance involves using a set of \textit{random} hyperplanes to partition the space into hash regions [Charikar, STOC 2002]. Experiments later showed that using a set of \textit{orthogonal} hyperplanes, thereby partitioning the space into the Voronoi regions induced by a hypercube, leads to even better results [Terasawa and Tanaka, WADS 2007]. However, no theoretical explanation for this improvement was ever given, and it remained unclear how the resulting hypercube hash method scales in high dimensions. In this work, we provide explicit asymptotics for the collision probabilities when using hypercubes to partition the space. For instance, two near-orthogonal vectors are expected to collide with probability ((\frac{1}{\pi})^{d + o(d)}) in dimension (d), compared to ((\frac{1}{2})^d) when using random hyperplanes. Vectors at angle (\frac{\pi}{3}) collide with probability ((\frac{\sqrt{3}}{\pi})^{d + o(d)}), compared to ((\frac{2}{3})^d) for random hyperplanes, and near-parallel vectors collide with similar asymptotic probabilities in both cases. For (c)-approximate nearest neighbor searching, this translates to a decrease in the exponent (\rho) of locality-sensitive hashing (LSH) methods of a factor up to (log_2(\pi) \approx 1.652) compared to hyperplane LSH. For (c = 2), we obtain (\rho \approx 0.302 + o(1)) for hypercube LSH, improving upon the (\rho \approx 0.377) for hyperplane LSH. We further describe how to use hypercube LSH in practice, and we consider an example application in the area of lattice algorithms." />
<link rel="canonical" href="https://learning2hash.github.io/publications/laarhoven2017hypercube/" />
<meta property="og:url" content="https://learning2hash.github.io/publications/laarhoven2017hypercube/" />
<meta property="og:site_name" content="Awesome Learning to Hash" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-08-20T04:39:38-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Hypercube LSH For Approximate Near Neighbors" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-08-20T04:39:38-05:00","datePublished":"2025-08-20T04:39:38-05:00","description":"A celebrated technique for finding near neighbors for the angular distance involves using a set of \\textit{random} hyperplanes to partition the space into hash regions [Charikar, STOC 2002]. Experiments later showed that using a set of \\textit{orthogonal} hyperplanes, thereby partitioning the space into the Voronoi regions induced by a hypercube, leads to even better results [Terasawa and Tanaka, WADS 2007]. However, no theoretical explanation for this improvement was ever given, and it remained unclear how the resulting hypercube hash method scales in high dimensions. In this work, we provide explicit asymptotics for the collision probabilities when using hypercubes to partition the space. For instance, two near-orthogonal vectors are expected to collide with probability ((\\frac{1}{\\pi})^{d + o(d)}) in dimension (d), compared to ((\\frac{1}{2})^d) when using random hyperplanes. Vectors at angle (\\frac{\\pi}{3}) collide with probability ((\\frac{\\sqrt{3}}{\\pi})^{d + o(d)}), compared to ((\\frac{2}{3})^d) for random hyperplanes, and near-parallel vectors collide with similar asymptotic probabilities in both cases. For (c)-approximate nearest neighbor searching, this translates to a decrease in the exponent (\\rho) of locality-sensitive hashing (LSH) methods of a factor up to (log_2(\\pi) \\approx 1.652) compared to hyperplane LSH. For (c = 2), we obtain (\\rho \\approx 0.302 + o(1)) for hypercube LSH, improving upon the (\\rho \\approx 0.377) for hyperplane LSH. We further describe how to use hypercube LSH in practice, and we consider an example application in the area of lattice algorithms.","headline":"Hypercube LSH For Approximate Near Neighbors","mainEntityOfPage":{"@type":"WebPage","@id":"https://learning2hash.github.io/publications/laarhoven2017hypercube/"},"url":"https://learning2hash.github.io/publications/laarhoven2017hypercube/"}</script>
<!-- End Jekyll SEO tag -->


  <!-- Site CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="shortcut icon" href="/public/favicon.svg">
  <link rel="search" href="/public/opensearchdescription.xml" type="application/opensearchdescription+xml" title="learning2hash" />

  <!-- ✅ Single, modern jQuery + DataTables -->
  <link rel="stylesheet" href="https://cdn.datatables.net/1.13.6/css/jquery.dataTables.min.css">
  <script src="https://code.jquery.com/jquery-3.7.0.min.js" defer></script>
  <script src="https://cdn.datatables.net/1.13.6/js/jquery.dataTables.min.js" defer></script>

  <!-- Optional sanity log -->
  <script defer>
    window.addEventListener('DOMContentLoaded', () => {
      console.log('jQuery:', jQuery?.fn?.jquery);
      console.log('DataTables loaded:', !!jQuery?.fn?.dataTable);
    });
  </script>
</head>


  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

  <body class="theme-base-0c layout-reverse">

    <a href='/contributing.html' class='ribbon'>Add your paper to Learning2Hash</a>
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Awesome Learning to Hash
        </a>
      </h1>
      <p class="lead">A Webpage dedicated to the latest research on Hash Function Learning. Maintained by <a href="http://sjmoran.github.io/">Sean Moran</a>.</p>
    </div>

    <nav class="sidebar-nav">
      <div class="sidebar-item">
        <p style="font-size: 12px">
          Search related work 
          <input type='text' id='searchTarget' size="16"/> 
          <button onClick="search();">Go</button>
        </p>
      </div>
      <a class="sidebar-nav-item" href="/papers.html">All Papers</a>
      <a class="sidebar-nav-item" href="/tags.html">Papers by Tag</a>
      <a class="sidebar-nav-item" href="/tsne-viz.html">2D Map of Papers</a>
      <a class="sidebar-nav-item" href="/topic-viz.html">Topic Explorer</a>
      <a class="sidebar-nav-item" href="/author-viz.html">Author Explorer </a>
      <a class="sidebar-nav-item" href="/opensource.html">Tools Explorer </a>
      <a class="sidebar-nav-item" href="/tutorial.html">Tutorial</a>
      <a class="sidebar-nav-item" href="/resources.html">Resources, Courses &#38; Events</a>
      <a class="sidebar-nav-item" href="/contributing.html">Contributing</a>
    </nav>

    <div class="sidebar-item">
      <p style="font-size: 12px">
        Contact <a href="http://www.seanjmoran.com">Sean Moran</a> about this survey or website.
        <span style="font-size: 9px">
          Made with <a href="https://jekyllrb.com">Jekyll</a> and <a href="https://github.com/poole/hyde">Hyde</a>.
        </span>
      </p>
    </div>
  </div>
</div>

<script defer>
document.addEventListener('DOMContentLoaded', function () {
  function doSearch() {
    const el = document.getElementById('searchTarget');
    if (!el) return;
    const q = el.value.trim();
    try { if (typeof ga === 'function') ga('send', 'event', 'search', 'search', q); } catch(e) {}
    window.location = "/papers.html#" + encodeURIComponent(q);
  }

  // jQuery path if loaded
  if (window.jQuery) {
    $('#searchTarget').on('keydown', function (e) {
      if (e.key === 'Enter') doSearch();
    });
    document.querySelector('.sidebar-item button')?.addEventListener('click', doSearch);
  } else {
    // vanilla fallback
    const input = document.getElementById('searchTarget');
    const btn = document.querySelector('.sidebar-item button');
    if (input) {
      input.addEventListener('keydown', function (e) {
        if (e.key === 'Enter') doSearch();
      });
    }
    if (btn) btn.addEventListener('click', doSearch);
  }

  // keep global for inline onClick="search()"
  window.search = doSearch;
});
</script>


    <div class="content container">
      <div class="page">
  <h1 class="page-title">Hypercube LSH For Approximate Near Neighbors</h1>
  <h5>
  
    
      Thijs Laarhoven
    
  
  . 42nd International Symposium on Mathematical Foundations of Computer Science (MFCS 2017) pp. 71-720 2017
   2017
  
    – <span>2 citations</span>
  
  </h5>
  <p>
    
      [<a href="https://arxiv.org/abs/1702.05760" target="_blank">Paper</a>]
    
    &nbsp;<a href='http://scholar.google.com/scholar?q=Hypercube LSH For Approximate Near Neighbors' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
    &nbsp;<a href='https://www.semanticscholar.org/search?q=Hypercube LSH For Approximate Near Neighbors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
    <br/>
    
      <tag><a href="/tags.html#Hashing Methods">Hashing Methods</a></tag>
    
      <tag><a href="/tags.html#Locality Sensitive Hashing">Locality Sensitive Hashing</a></tag>
    
  </p>
  <p><p>A celebrated technique for finding near neighbors for the angular distance
involves using a set of \textit{random} hyperplanes to partition the space into
hash regions [Charikar, STOC 2002]. Experiments later showed that using a set
of \textit{orthogonal} hyperplanes, thereby partitioning the space into the
Voronoi regions induced by a hypercube, leads to even better results [Terasawa
and Tanaka, WADS 2007]. However, no theoretical explanation for this
improvement was ever given, and it remained unclear how the resulting hypercube
hash method scales in high dimensions.
  In this work, we provide explicit asymptotics for the collision probabilities
when using hypercubes to partition the space. For instance, two near-orthogonal
vectors are expected to collide with probability ((\frac{1}{\pi})^{d + o(d)})
in dimension (d), compared to ((\frac{1}{2})^d) when using random hyperplanes.
Vectors at angle (\frac{\pi}{3}) collide with probability
((\frac{\sqrt{3}}{\pi})^{d + o(d)}), compared to ((\frac{2}{3})^d) for random
hyperplanes, and near-parallel vectors collide with similar asymptotic
probabilities in both cases.
  For (c)-approximate nearest neighbor searching, this translates to a decrease
in the exponent (\rho) of locality-sensitive hashing (LSH) methods of a factor
up to (log_2(\pi) \approx 1.652) compared to hyperplane LSH. For (c = 2), we
obtain (\rho \approx 0.302 + o(1)) for hypercube LSH, improving upon the (\rho
\approx 0.377) for hyperplane LSH. We further describe how to use hypercube LSH
in practice, and we consider an example application in the area of lattice
algorithms.</p>
</p>

  <h6>Similar Work</h6>
  <p>
    <ul id="relwork">

    </ul>
  </p>

 <script>  
    $(document).ready(
      function() {
        $.getJSON("/publications-metadata/laarhoven2017hypercube.json", function(data) {
          num_papers = data.length;
          html = "";
          for (let i=0; i < num_papers; i++) {
              html += '<li><a href="/publications/' + data[i][0] + '">'+ data[i][1] +'</a></li>'
          }
          $("#relwork").append(html);
        });
      });
  </script>


</div>

    </div>

  </body>
</html>
