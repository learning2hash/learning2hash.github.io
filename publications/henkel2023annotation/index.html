<!DOCTYPE html>
<html lang="en-us">

  <!-- _includes/head.html -->
<head>
  <!-- begin code v 7.0 -->
  <span id="wts2185304"></span>
  <script>
  var wts7 = {};
  wts7.invisible='';
  wts7.page_name='';
  wts7.group_name='';
  wts7.conversion_number='';
  wts7.user_id='';
  var wts=document.createElement('script');wts.async=true;
  wts.src='https://app.ardalio.com/wts7.js';document.head.appendChild(wts);
  wts.onload = function(){ wtsl7(2185304,4); };
  </script><noscript><img src="https://app.ardalio.com/7/4/2185304.png"></noscript>
  <!-- end code v 7.0 -->
  <!-- MathJax -->
  <script>
    window.MathJax = {
      tex: { inlineMath: [["\\(","\\)"]], displayMath: [["\\[","\\]"]] },
      options: { processHtmlClass: "mathjax-content", processEscapes: true }
    };
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <link href="https://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta charset="utf-8">

  <!-- Viewport -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- ✅ Manual SEO keywords (specific to Learning to Hash) -->
  <meta name="keywords" content="learning to hash, machine learning, hashing, approximate nearest neighbour search, ANN, LSH, locality sensitive hashing, vector quantization, deep hashing, binary embeddings, information retrieval, similarity search">

  <!-- ✅ Jekyll SEO plugin (title, description, canonical, OG/Twitter, JSON-LD) -->
  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Annotation Cost Efficient Active Learning For Content Based Image Retrieval | Awesome Learning to Hash</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="Annotation Cost Efficient Active Learning For Content Based Image Retrieval" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Deep metric learning (DML) based methods have been found very effective for content-based image retrieval (CBIR) in remote sensing (RS). For accurately learning the model parameters of deep neural networks, most of the DML methods require a high number of annotated training images, which can be costly to gather. To address this problem, in this paper we present an annotation cost efficient active learning (AL) method (denoted as ANNEAL). The proposed method aims to iteratively enrich the training set by annotating the most informative image pairs as similar or dissimilar, while accurately modelling a deep metric space. This is achieved by two consecutive steps. In the first step the pairwise image similarity is modelled based on the available training set. Then, in the second step the most uncertain and diverse (i.e., informative) image pairs are selected to be annotated. Unlike the existing AL methods for CBIR, at each AL iteration of ANNEAL a human expert is asked to annotate the most informative image pairs as similar/dissimilar. This significantly reduces the annotation cost compared to annotating images with land-use/land cover class labels. Experimental results show the effectiveness of our method. The code of ANNEAL is publicly available at https://git.tu-berlin.de/rsim/ANNEAL." />
<meta property="og:description" content="Deep metric learning (DML) based methods have been found very effective for content-based image retrieval (CBIR) in remote sensing (RS). For accurately learning the model parameters of deep neural networks, most of the DML methods require a high number of annotated training images, which can be costly to gather. To address this problem, in this paper we present an annotation cost efficient active learning (AL) method (denoted as ANNEAL). The proposed method aims to iteratively enrich the training set by annotating the most informative image pairs as similar or dissimilar, while accurately modelling a deep metric space. This is achieved by two consecutive steps. In the first step the pairwise image similarity is modelled based on the available training set. Then, in the second step the most uncertain and diverse (i.e., informative) image pairs are selected to be annotated. Unlike the existing AL methods for CBIR, at each AL iteration of ANNEAL a human expert is asked to annotate the most informative image pairs as similar/dissimilar. This significantly reduces the annotation cost compared to annotating images with land-use/land cover class labels. Experimental results show the effectiveness of our method. The code of ANNEAL is publicly available at https://git.tu-berlin.de/rsim/ANNEAL." />
<link rel="canonical" href="https://learning2hash.github.io/publications/henkel2023annotation/" />
<meta property="og:url" content="https://learning2hash.github.io/publications/henkel2023annotation/" />
<meta property="og:site_name" content="Awesome Learning to Hash" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-10-05T05:55:01-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Annotation Cost Efficient Active Learning For Content Based Image Retrieval" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-10-05T05:55:01-05:00","datePublished":"2025-10-05T05:55:01-05:00","description":"Deep metric learning (DML) based methods have been found very effective for content-based image retrieval (CBIR) in remote sensing (RS). For accurately learning the model parameters of deep neural networks, most of the DML methods require a high number of annotated training images, which can be costly to gather. To address this problem, in this paper we present an annotation cost efficient active learning (AL) method (denoted as ANNEAL). The proposed method aims to iteratively enrich the training set by annotating the most informative image pairs as similar or dissimilar, while accurately modelling a deep metric space. This is achieved by two consecutive steps. In the first step the pairwise image similarity is modelled based on the available training set. Then, in the second step the most uncertain and diverse (i.e., informative) image pairs are selected to be annotated. Unlike the existing AL methods for CBIR, at each AL iteration of ANNEAL a human expert is asked to annotate the most informative image pairs as similar/dissimilar. This significantly reduces the annotation cost compared to annotating images with land-use/land cover class labels. Experimental results show the effectiveness of our method. The code of ANNEAL is publicly available at https://git.tu-berlin.de/rsim/ANNEAL.","headline":"Annotation Cost Efficient Active Learning For Content Based Image Retrieval","mainEntityOfPage":{"@type":"WebPage","@id":"https://learning2hash.github.io/publications/henkel2023annotation/"},"url":"https://learning2hash.github.io/publications/henkel2023annotation/"}</script>
<!-- End Jekyll SEO tag -->


  <!-- Site CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="shortcut icon" href="/public/favicon.ico">
  <link rel="search" href="/public/opensearchdescription.xml" type="application/opensearchdescription+xml" title="learning2hash" />

  <!-- ✅ Single, modern jQuery + DataTables -->
  <link rel="stylesheet" href="https://cdn.datatables.net/1.13.6/css/jquery.dataTables.min.css">
  <script src="https://code.jquery.com/jquery-3.7.0.min.js" defer></script>
  <script src="https://cdn.datatables.net/1.13.6/js/jquery.dataTables.min.js" defer></script>

  <!-- Optional sanity log -->
  <script defer>
    window.addEventListener('DOMContentLoaded', () => {
      console.log('jQuery:', jQuery?.fn?.jquery);
      console.log('DataTables loaded:', !!jQuery?.fn?.dataTable);
    });
  </script>
</head>


  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

  <body class="theme-base-0c layout-reverse">

    <a href='/contributing.html' class='ribbon'>Add your paper to Learning2Hash</a>
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Awesome Learning to Hash
        </a>
      </h1>
      <p class="lead">A Webpage dedicated to the latest research on Hash Function Learning. Maintained by <a href="http://sjmoran.github.io/">Sean Moran</a>.</p>
    </div>

    <nav class="sidebar-nav">
      <div class="sidebar-item">
        <p style="font-size: 12px">
          Search related work 
          <input type='text' id='searchTarget' size="16"/> 
          <button onClick="search();">Go</button>
        </p>
      </div>
      <a class="sidebar-nav-item" href="/papers.html">All Papers</a>
      <a class="sidebar-nav-item" href="/tags.html">Papers by Tag</a>
      <a class="sidebar-nav-item" href="/tsne-viz.html">2D Map of Papers</a>
      <a class="sidebar-nav-item" href="/topic-viz.html">Topic Explorer</a>
      <a class="sidebar-nav-item" href="/author-viz.html">Author Explorer </a>
      <a class="sidebar-nav-item" href="/opensource.html">Tools Explorer </a>
      <a class="sidebar-nav-item" href="/tutorial.html">Tutorial</a>
      <a class="sidebar-nav-item" href="/resources.html">Resources, Courses &#38; Events</a>
      <a class="sidebar-nav-item" href="/contributing.html">Contributing</a>
    </nav>

    <div class="sidebar-item">
      <p style="font-size: 12px">
        Contact <a href="http://www.seanjmoran.com">Sean Moran</a> about this survey or website.
        <span style="font-size: 9px">
          Made with <a href="https://jekyllrb.com">Jekyll</a> and <a href="https://github.com/poole/hyde">Hyde</a>.
        </span>
      </p>
    </div>
  </div>
</div>

<script defer>
document.addEventListener('DOMContentLoaded', function () {
  function doSearch() {
    const el = document.getElementById('searchTarget');
    if (!el) return;
    const q = el.value.trim();
    try { if (typeof ga === 'function') ga('send', 'event', 'search', 'search', q); } catch(e) {}
    window.location = "/papers.html#" + encodeURIComponent(q);
  }

  // jQuery path if loaded
  if (window.jQuery) {
    $('#searchTarget').on('keydown', function (e) {
      if (e.key === 'Enter') doSearch();
    });
    document.querySelector('.sidebar-item button')?.addEventListener('click', doSearch);
  } else {
    // vanilla fallback
    const input = document.getElementById('searchTarget');
    const btn = document.querySelector('.sidebar-item button');
    if (input) {
      input.addEventListener('keydown', function (e) {
        if (e.key === 'Enter') doSearch();
      });
    }
    if (btn) btn.addEventListener('click', doSearch);
  }

  // keep global for inline onClick="search()"
  window.search = doSearch;
});
</script>


    <div class="content container">
      <div class="page">
  <h1 class="page-title">Annotation Cost Efficient Active Learning For Content Based Image Retrieval</h1>

  <h5>
    
    
    <a href="https://scholar.google.com/scholar?q=Julia%20Henkel,%20Genc%20Hoxha,%20Gencer%20Sumbul,%20Lars%20M%C3%B6llenbrok,%20Beg%C3%BCm%20Demir" 
       target="_blank" rel="noopener noreferrer">
      Julia Henkel, Genc Hoxha, Gencer Sumbul, Lars Möllenbrok, Begüm Demir
    </a>
    
    
    . IGARSS 2023 - 2023 IEEE International Geoscience and Remote Sensing Symposium
     2023
    
      – <span>1 citation</span>
    
  </h5>

  <p>
    
      [<a href="https://git.tu-berlin.de/rsim/ANNEAL" target="_blank" rel="noopener noreferrer">Code</a>]
    
      [<a href="https://arxiv.org/abs/2306.11605" target="_blank" rel="noopener noreferrer">Paper</a>]
    
    &nbsp;<a href="https://scholar.google.com/scholar?q=Annotation%20Cost%20Efficient%20Active%20Learning%20For%20Content%20Based%20Image%20Retrieval" target="_blank" rel="noopener noreferrer">
      <img style="display:inline; margin:0;" src="/public/media/google-scholar.png" alt="Search on Google Scholar"/>
    </a>
    &nbsp;<a href="https://www.semanticscholar.org/search?q=Annotation%20Cost%20Efficient%20Active%20Learning%20For%20Content%20Based%20Image%20Retrieval" target="_blank" rel="noopener noreferrer">
      <img style="display:inline; margin:0;" src="/public/media/semscholar.png" alt="Search on Semantic Scholar"/>
    </a>
    <br/>
    
      <tag><a href="/tags.html#Distance%20Metric%20Learning">Distance Metric Learning</a></tag>
    
      <tag><a href="/tags.html#Image%20Retrieval">Image Retrieval</a></tag>
    
  </p>

  <p><p>Deep metric learning (DML) based methods have been found very effective for
content-based image retrieval (CBIR) in remote sensing (RS). For accurately
learning the model parameters of deep neural networks, most of the DML methods
require a high number of annotated training images, which can be costly to
gather. To address this problem, in this paper we present an annotation cost
efficient active learning (AL) method (denoted as ANNEAL). The proposed method
aims to iteratively enrich the training set by annotating the most informative
image pairs as similar or dissimilar, while accurately modelling a deep metric
space. This is achieved by two consecutive steps. In the first step the
pairwise image similarity is modelled based on the available training set.
Then, in the second step the most uncertain and diverse (i.e., informative)
image pairs are selected to be annotated. Unlike the existing AL methods for
CBIR, at each AL iteration of ANNEAL a human expert is asked to annotate the
most informative image pairs as similar/dissimilar. This significantly reduces
the annotation cost compared to annotating images with land-use/land cover
class labels. Experimental results show the effectiveness of our method. The
code of ANNEAL is publicly available at https://git.tu-berlin.de/rsim/ANNEAL.</p>
</p>

  <h6>Similar Work</h6>
  <ul id="relwork"></ul>

  <!-- Share Buttons -->
  <h6>Share this Paper</h6>
  <div class="share-buttons" style="margin-bottom: 1em;">
    <button id="share-twitter" title="Share on X (Twitter)">🐦</button>
    <button id="share-linkedin" title="Share on LinkedIn">💼</button>
    <button id="share-copy" title="Copy Link">🔗</button>
  </div>

  <!-- Vanilla JS -->
  <script>
    document.addEventListener('DOMContentLoaded', function () {
      // Similar work section
      var relwork = document.getElementById('relwork');
      if (relwork) {
        var metaPath = "/publications-metadata/henkel2023annotation.json";

        fetch(metaPath, { credentials: 'same-origin' })
          .then(function (res) {
            if (!res.ok) throw new Error(res.status + " " + res.statusText);
            return res.json();
          })
          .then(function (data) {
            if (!Array.isArray(data)) return;
            relwork.innerHTML = data
              .map(function (d) {
                var slug = d[0];
                var title = d[1];
                return '<li><a href="/publications/' + slug + '">' + title + '</a></li>';
              })
              .join('');
          })
          .catch(function (err) {
            console.warn("Failed to load similar work JSON:", err);
          });
      }

      // Share buttons
      const pageUrl = encodeURIComponent(window.location.href);
      const pageTitle = encodeURIComponent(document.title);

      const twitterBtn = document.getElementById('share-twitter');
      const linkedinBtn = document.getElementById('share-linkedin');
      const copyBtn = document.getElementById('share-copy');

      if (twitterBtn) {
        twitterBtn.addEventListener('click', () => {
          window.open(`https://twitter.com/intent/tweet?text=${pageTitle}&url=${pageUrl}`, '_blank');
        });
      }

      if (linkedinBtn) {
        linkedinBtn.addEventListener('click', () => {
          window.open(`https://www.linkedin.com/sharing/share-offsite/?url=${pageUrl}`, '_blank');
        });
      }

      if (copyBtn) {
        copyBtn.addEventListener('click', () => {
          navigator.clipboard.writeText(window.location.href).then(() => {
            alert('✅ Link copied to clipboard!');
          });
        });
      }
    });
  </script>

  <!-- Optional CSS -->
  <style>
    .share-buttons button {
      background: #f2f2f2;
      border: none;
      border-radius: 6px;
      margin-right: 6px;
      padding: 6px 10px;
      font-size: 1.2em;
      cursor: pointer;
      transition: background 0.2s;
    }
    .share-buttons button:hover {
      background: #e0e0e0;
    }
  </style>
</div>

    </div>

  </body>
</html>
