<!DOCTYPE html>
<html lang="en-us">

  <!-- _includes/head.html -->
<head>
  <!-- begin code v 7.0 -->
  <span id="wts2185304"></span>
  <script>
  var wts7 = {};
  wts7.invisible='';
  wts7.page_name='';
  wts7.group_name='';
  wts7.conversion_number='';
  wts7.user_id='';
  var wts=document.createElement('script');wts.async=true;
  wts.src='https://app.ardalio.com/wts7.js';document.head.appendChild(wts);
  wts.onload = function(){ wtsl7(2185304,4); };
  </script><noscript><img src="https://app.ardalio.com/7/4/2185304.png"></noscript>
  <!-- end code v 7.0 -->
  <!-- MathJax -->
  <script>
    window.MathJax = {
      tex: { inlineMath: [["\\(","\\)"]], displayMath: [["\\[","\\]"]] },
      options: { processHtmlClass: "mathjax-content", processEscapes: true }
    };
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <link href="https://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta charset="utf-8">

  <!-- Viewport -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- ✅ Manual SEO keywords (specific to Learning to Hash) -->
  <meta name="keywords" content="learning to hash, machine learning, hashing, approximate nearest neighbour search, ANN, LSH, locality sensitive hashing, vector quantization, deep hashing, binary embeddings, information retrieval, similarity search">

  <!-- ✅ Jekyll SEO plugin (title, description, canonical, OG/Twitter, JSON-LD) -->
  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Micronn: An On-device Disk-resident Updatable Vector Database | Awesome Learning to Hash</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="Micronn: An On-device Disk-resident Updatable Vector Database" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Nearest neighbour search over dense vector collections has important applications in information retrieval, retrieval augmented generation (RAG), and content ranking. Performing efficient search over large vector collections is a well studied problem with many existing approaches and open source implementations. However, most state-of-the-art systems are generally targeted towards scenarios using large servers with an abundance of memory, static vector collections that are not updatable, and nearest neighbour search in isolation of other search criteria. We present Micro Nearest Neighbour (MicroNN), an embedded nearest-neighbour vector search engine designed for scalable similarity search in low-resource environments. MicroNN addresses the problem of on-device vector search for real-world workloads containing updates and hybrid search queries that combine nearest neighbour search with structured attribute filters. In this scenario, memory is highly constrained and disk-efficient index structures and algorithms are required, as well as support for continuous inserts and deletes. MicroNN is an embeddable library that can scale to large vector collections with minimal resources. MicroNN is used in production and powers a wide range of vector search use-cases on-device. MicroNN takes less than 7 ms to retrieve the top-100 nearest neighbours with 90% recall on publicly available million-scale vector benchmark while using ~10 MB of memory." />
<meta property="og:description" content="Nearest neighbour search over dense vector collections has important applications in information retrieval, retrieval augmented generation (RAG), and content ranking. Performing efficient search over large vector collections is a well studied problem with many existing approaches and open source implementations. However, most state-of-the-art systems are generally targeted towards scenarios using large servers with an abundance of memory, static vector collections that are not updatable, and nearest neighbour search in isolation of other search criteria. We present Micro Nearest Neighbour (MicroNN), an embedded nearest-neighbour vector search engine designed for scalable similarity search in low-resource environments. MicroNN addresses the problem of on-device vector search for real-world workloads containing updates and hybrid search queries that combine nearest neighbour search with structured attribute filters. In this scenario, memory is highly constrained and disk-efficient index structures and algorithms are required, as well as support for continuous inserts and deletes. MicroNN is an embeddable library that can scale to large vector collections with minimal resources. MicroNN is used in production and powers a wide range of vector search use-cases on-device. MicroNN takes less than 7 ms to retrieve the top-100 nearest neighbours with 90% recall on publicly available million-scale vector benchmark while using ~10 MB of memory." />
<link rel="canonical" href="https://learning2hash.github.io/publications/pound2025micronn/" />
<meta property="og:url" content="https://learning2hash.github.io/publications/pound2025micronn/" />
<meta property="og:site_name" content="Awesome Learning to Hash" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-09-06T09:39:08-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Micronn: An On-device Disk-resident Updatable Vector Database" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-09-06T09:39:08-05:00","datePublished":"2025-09-06T09:39:08-05:00","description":"Nearest neighbour search over dense vector collections has important applications in information retrieval, retrieval augmented generation (RAG), and content ranking. Performing efficient search over large vector collections is a well studied problem with many existing approaches and open source implementations. However, most state-of-the-art systems are generally targeted towards scenarios using large servers with an abundance of memory, static vector collections that are not updatable, and nearest neighbour search in isolation of other search criteria. We present Micro Nearest Neighbour (MicroNN), an embedded nearest-neighbour vector search engine designed for scalable similarity search in low-resource environments. MicroNN addresses the problem of on-device vector search for real-world workloads containing updates and hybrid search queries that combine nearest neighbour search with structured attribute filters. In this scenario, memory is highly constrained and disk-efficient index structures and algorithms are required, as well as support for continuous inserts and deletes. MicroNN is an embeddable library that can scale to large vector collections with minimal resources. MicroNN is used in production and powers a wide range of vector search use-cases on-device. MicroNN takes less than 7 ms to retrieve the top-100 nearest neighbours with 90% recall on publicly available million-scale vector benchmark while using ~10 MB of memory.","headline":"Micronn: An On-device Disk-resident Updatable Vector Database","mainEntityOfPage":{"@type":"WebPage","@id":"https://learning2hash.github.io/publications/pound2025micronn/"},"url":"https://learning2hash.github.io/publications/pound2025micronn/"}</script>
<!-- End Jekyll SEO tag -->


  <!-- Site CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="shortcut icon" href="/public/favicon.svg">
  <link rel="search" href="/public/opensearchdescription.xml" type="application/opensearchdescription+xml" title="learning2hash" />

  <!-- ✅ Single, modern jQuery + DataTables -->
  <link rel="stylesheet" href="https://cdn.datatables.net/1.13.6/css/jquery.dataTables.min.css">
  <script src="https://code.jquery.com/jquery-3.7.0.min.js" defer></script>
  <script src="https://cdn.datatables.net/1.13.6/js/jquery.dataTables.min.js" defer></script>

  <!-- Optional sanity log -->
  <script defer>
    window.addEventListener('DOMContentLoaded', () => {
      console.log('jQuery:', jQuery?.fn?.jquery);
      console.log('DataTables loaded:', !!jQuery?.fn?.dataTable);
    });
  </script>
</head>


  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

  <body class="theme-base-0c layout-reverse">

    <a href='/contributing.html' class='ribbon'>Add your paper to Learning2Hash</a>
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Awesome Learning to Hash
        </a>
      </h1>
      <p class="lead">A Webpage dedicated to the latest research on Hash Function Learning. Maintained by <a href="http://sjmoran.github.io/">Sean Moran</a>.</p>
    </div>

    <nav class="sidebar-nav">
      <div class="sidebar-item">
        <p style="font-size: 12px">
          Search related work 
          <input type='text' id='searchTarget' size="16"/> 
          <button onClick="search();">Go</button>
        </p>
      </div>
      <a class="sidebar-nav-item" href="/papers.html">All Papers</a>
      <a class="sidebar-nav-item" href="/tags.html">Papers by Tag</a>
      <a class="sidebar-nav-item" href="/tsne-viz.html">2D Map of Papers</a>
      <a class="sidebar-nav-item" href="/topic-viz.html">Topic Explorer</a>
      <a class="sidebar-nav-item" href="/author-viz.html">Author Explorer </a>
      <a class="sidebar-nav-item" href="/opensource.html">Tools Explorer </a>
      <a class="sidebar-nav-item" href="/tutorial.html">Tutorial</a>
      <a class="sidebar-nav-item" href="/resources.html">Resources, Courses &#38; Events</a>
      <a class="sidebar-nav-item" href="/contributing.html">Contributing</a>
    </nav>

    <div class="sidebar-item">
      <p style="font-size: 12px">
        Contact <a href="http://www.seanjmoran.com">Sean Moran</a> about this survey or website.
        <span style="font-size: 9px">
          Made with <a href="https://jekyllrb.com">Jekyll</a> and <a href="https://github.com/poole/hyde">Hyde</a>.
        </span>
      </p>
    </div>
  </div>
</div>

<script defer>
document.addEventListener('DOMContentLoaded', function () {
  function doSearch() {
    const el = document.getElementById('searchTarget');
    if (!el) return;
    const q = el.value.trim();
    try { if (typeof ga === 'function') ga('send', 'event', 'search', 'search', q); } catch(e) {}
    window.location = "/papers.html#" + encodeURIComponent(q);
  }

  // jQuery path if loaded
  if (window.jQuery) {
    $('#searchTarget').on('keydown', function (e) {
      if (e.key === 'Enter') doSearch();
    });
    document.querySelector('.sidebar-item button')?.addEventListener('click', doSearch);
  } else {
    // vanilla fallback
    const input = document.getElementById('searchTarget');
    const btn = document.querySelector('.sidebar-item button');
    if (input) {
      input.addEventListener('keydown', function (e) {
        if (e.key === 'Enter') doSearch();
      });
    }
    if (btn) btn.addEventListener('click', doSearch);
  }

  // keep global for inline onClick="search()"
  window.search = doSearch;
});
</script>


    <div class="content container">
      <div class="page">
  <h1 class="page-title">Micronn: An On-device Disk-resident Updatable Vector Database</h1>

  <h5>
    
    
    <a href="https://scholar.google.com/scholar?q=Jeffrey%20Pound,%20Floris%20Chabert,%20Arjun%20Bhushan,%20Ankur%20Goswami,%20Anil%20Pacaci,%20Shihabur%20Rahman%20Chowdhury" 
       target="_blank" rel="noopener noreferrer">
      Jeffrey Pound, Floris Chabert, Arjun Bhushan, Ankur Goswami, Anil Pacaci, Shihabur Rahman Chowdhury
    </a>
    
    
    . Companion of the 2025 International Conference on Management of Data
     2025
    
      – <span>0 citations</span>
    
  </h5>

  <p>
    
      [<a href="https://arxiv.org/abs/2504.05573" target="_blank" rel="noopener noreferrer">Paper</a>]
    
    &nbsp;<a href="https://scholar.google.com/scholar?q=Micronn:%20An%20On-device%20Disk-resident%20Updatable%20Vector%20Database" target="_blank" rel="noopener noreferrer">
      <img style="display:inline; margin:0;" src="/public/media/google-scholar.png" alt="Search on Google Scholar"/>
    </a>
    &nbsp;<a href="https://www.semanticscholar.org/search?q=Micronn:%20An%20On-device%20Disk-resident%20Updatable%20Vector%20Database" target="_blank" rel="noopener noreferrer">
      <img style="display:inline; margin:0;" src="/public/media/semscholar.png" alt="Search on Semantic Scholar"/>
    </a>
    <br/>
    
      <tag><a href="/tags.html#Evaluation">Evaluation</a></tag>
    
      <tag><a href="/tags.html#Similarity%20Search">Similarity Search</a></tag>
    
      <tag><a href="/tags.html#Tools%20&%20Libraries">Tools & Libraries</a></tag>
    
      <tag><a href="/tags.html#Vector%20Indexing">Vector Indexing</a></tag>
    
  </p>

  <p><p>Nearest neighbour search over dense vector collections has important
applications in information retrieval, retrieval augmented generation (RAG),
and content ranking. Performing efficient search over large vector collections
is a well studied problem with many existing approaches and open source
implementations. However, most state-of-the-art systems are generally targeted
towards scenarios using large servers with an abundance of memory, static
vector collections that are not updatable, and nearest neighbour search in
isolation of other search criteria. We present Micro Nearest Neighbour
(MicroNN), an embedded nearest-neighbour vector search engine designed for
scalable similarity search in low-resource environments. MicroNN addresses the
problem of on-device vector search for real-world workloads containing updates
and hybrid search queries that combine nearest neighbour search with structured
attribute filters. In this scenario, memory is highly constrained and
disk-efficient index structures and algorithms are required, as well as support
for continuous inserts and deletes. MicroNN is an embeddable library that can
scale to large vector collections with minimal resources. MicroNN is used in
production and powers a wide range of vector search use-cases on-device.
MicroNN takes less than 7 ms to retrieve the top-100 nearest neighbours with
90% recall on publicly available million-scale vector benchmark while using ~10
MB of memory.</p>
</p>

  <h6>Similar Work</h6>
  <ul id="relwork"></ul>

  <!-- Vanilla JS: no jQuery needed -->
  <script>
    document.addEventListener('DOMContentLoaded', function () {
      var relwork = document.getElementById('relwork');
      if (!relwork) return;

      var metaPath = "/publications-metadata/pound2025micronn.json";

      fetch(metaPath, { credentials: 'same-origin' })
        .then(function (res) {
          if (!res.ok) throw new Error(res.status + " " + res.statusText);
          return res.json();
        })
        .then(function (data) {
          if (!Array.isArray(data)) return;
          relwork.innerHTML = data
            .map(function (d) {
              var slug = d[0];
              var title = d[1];
              return '<li><a href="/publications/' + slug + '">' + title + '</a></li>';
            })
            .join('');
        })
        .catch(function (err) {
          console.warn("Failed to load similar work JSON:", err);
        });
    });
  </script>
</div>

    </div>

  </body>
</html>
