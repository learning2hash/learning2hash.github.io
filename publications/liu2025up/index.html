<!DOCTYPE html>
<html lang="en-us">

  <!-- _includes/head.html -->
<head>
  <!-- begin code v 7.0 -->
  <span id="wts2185304"></span>
  <script>
  var wts7 = {};
  wts7.invisible='';
  wts7.page_name='';
  wts7.group_name='';
  wts7.conversion_number='';
  wts7.user_id='';
  var wts=document.createElement('script');wts.async=true;
  wts.src='https://app.ardalio.com/wts7.js';document.head.appendChild(wts);
  wts.onload = function(){ wtsl7(2185304,4); };
  </script><noscript><img src="https://app.ardalio.com/7/4/2185304.png"></noscript>
  <!-- end code v 7.0 -->

 <!-- MathJax -->
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true
      },
      options: {
        // Only process elements with this class:
        processHtmlClass: 'mathjax-content',
        // And explicitly skip anything marked as no-mathjax
        ignoreHtmlClass: 'no-mathjax'
      }
    };
  </script>
  <script id="MathJax-script" async
          src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <link href="https://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta charset="utf-8">

  <!-- Viewport -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- âœ… Manual SEO keywords (specific to Learning to Hash) -->
  <meta name="keywords" content="learning to hash, machine learning, hashing, approximate nearest neighbour search, ANN, LSH, locality sensitive hashing, vector quantization, deep hashing, binary embeddings, information retrieval, similarity search">

  <!-- âœ… Jekyll SEO plugin (title, description, canonical, OG/Twitter, JSON-LD) -->
  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Up-person: Unified Parameter-efficient Transfer Learning For Text-based Person Retrieval | Awesome Learning to Hash</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="Up-person: Unified Parameter-efficient Transfer Learning For Text-based Person Retrieval" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Text-based Person Retrieval (TPR) as a multi-modal task, which aims to retrieve the target person from a pool of candidate images given a text description, has recently garnered considerable attention due to the progress of contrastive visual-language pre-trained model. Prior works leverage pre-trained CLIP to extract person visual and textual features and fully fine-tune the entire network, which have shown notable performance improvements compared to uni-modal pre-training models. However, full-tuning a large model is prone to overfitting and hinders the generalization ability. In this paper, we propose a novel Unified Parameter-Efficient Transfer Learning (PETL) method for Text-based Person Retrieval (UP-Person) to thoroughly transfer the multi-modal knowledge from CLIP. Specifically, UP-Person simultaneously integrates three lightweight PETL components including Prefix, LoRA and Adapter, where Prefix and LoRA are devised together to mine local information with task-specific information prompts, and Adapter is designed to adjust global feature representations. Additionally, two vanilla submodules are optimized to adapt to the unified architecture of TPR. For one thing, S-Prefix is proposed to boost attention of prefix and enhance the gradient propagation of prefix tokens, which improves the flexibility and performance of the vanilla prefix. For another thing, L-Adapter is designed in parallel with layer normalization to adjust the overall distribution, which can resolve conflicts caused by overlap and interaction among multiple submodules. Extensive experimental results demonstrate that our UP-Person achieves state-of-the-art results across various person retrieval datasets, including CUHK-PEDES, ICFG-PEDES and RSTPReid while merely fine-tuning 4.7% parameters. Code is available at https://github.com/Liu-Yating/UP-Person." />
<meta property="og:description" content="Text-based Person Retrieval (TPR) as a multi-modal task, which aims to retrieve the target person from a pool of candidate images given a text description, has recently garnered considerable attention due to the progress of contrastive visual-language pre-trained model. Prior works leverage pre-trained CLIP to extract person visual and textual features and fully fine-tune the entire network, which have shown notable performance improvements compared to uni-modal pre-training models. However, full-tuning a large model is prone to overfitting and hinders the generalization ability. In this paper, we propose a novel Unified Parameter-Efficient Transfer Learning (PETL) method for Text-based Person Retrieval (UP-Person) to thoroughly transfer the multi-modal knowledge from CLIP. Specifically, UP-Person simultaneously integrates three lightweight PETL components including Prefix, LoRA and Adapter, where Prefix and LoRA are devised together to mine local information with task-specific information prompts, and Adapter is designed to adjust global feature representations. Additionally, two vanilla submodules are optimized to adapt to the unified architecture of TPR. For one thing, S-Prefix is proposed to boost attention of prefix and enhance the gradient propagation of prefix tokens, which improves the flexibility and performance of the vanilla prefix. For another thing, L-Adapter is designed in parallel with layer normalization to adjust the overall distribution, which can resolve conflicts caused by overlap and interaction among multiple submodules. Extensive experimental results demonstrate that our UP-Person achieves state-of-the-art results across various person retrieval datasets, including CUHK-PEDES, ICFG-PEDES and RSTPReid while merely fine-tuning 4.7% parameters. Code is available at https://github.com/Liu-Yating/UP-Person." />
<link rel="canonical" href="https://learning2hash.github.io/publications/liu2025up/" />
<meta property="og:url" content="https://learning2hash.github.io/publications/liu2025up/" />
<meta property="og:site_name" content="Awesome Learning to Hash" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2026-01-24T07:06:35-06:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Up-person: Unified Parameter-efficient Transfer Learning For Text-based Person Retrieval" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2026-01-24T07:06:35-06:00","datePublished":"2026-01-24T07:06:35-06:00","description":"Text-based Person Retrieval (TPR) as a multi-modal task, which aims to retrieve the target person from a pool of candidate images given a text description, has recently garnered considerable attention due to the progress of contrastive visual-language pre-trained model. Prior works leverage pre-trained CLIP to extract person visual and textual features and fully fine-tune the entire network, which have shown notable performance improvements compared to uni-modal pre-training models. However, full-tuning a large model is prone to overfitting and hinders the generalization ability. In this paper, we propose a novel Unified Parameter-Efficient Transfer Learning (PETL) method for Text-based Person Retrieval (UP-Person) to thoroughly transfer the multi-modal knowledge from CLIP. Specifically, UP-Person simultaneously integrates three lightweight PETL components including Prefix, LoRA and Adapter, where Prefix and LoRA are devised together to mine local information with task-specific information prompts, and Adapter is designed to adjust global feature representations. Additionally, two vanilla submodules are optimized to adapt to the unified architecture of TPR. For one thing, S-Prefix is proposed to boost attention of prefix and enhance the gradient propagation of prefix tokens, which improves the flexibility and performance of the vanilla prefix. For another thing, L-Adapter is designed in parallel with layer normalization to adjust the overall distribution, which can resolve conflicts caused by overlap and interaction among multiple submodules. Extensive experimental results demonstrate that our UP-Person achieves state-of-the-art results across various person retrieval datasets, including CUHK-PEDES, ICFG-PEDES and RSTPReid while merely fine-tuning 4.7% parameters. Code is available at https://github.com/Liu-Yating/UP-Person.","headline":"Up-person: Unified Parameter-efficient Transfer Learning For Text-based Person Retrieval","mainEntityOfPage":{"@type":"WebPage","@id":"https://learning2hash.github.io/publications/liu2025up/"},"url":"https://learning2hash.github.io/publications/liu2025up/"}</script>
<!-- End Jekyll SEO tag -->


  <!-- Site CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="shortcut icon" href="/public/favicon.ico">
  <link rel="search" href="/public/opensearchdescription.xml" type="application/opensearchdescription+xml" title="learning2hash" />

  <!-- âœ… Single, modern jQuery + DataTables -->
  <link rel="stylesheet" href="https://cdn.datatables.net/1.13.6/css/jquery.dataTables.min.css">
  <script src="https://code.jquery.com/jquery-3.7.0.min.js" defer></script>
  <script src="https://cdn.datatables.net/1.13.6/js/jquery.dataTables.min.js" defer></script>

  <!-- Optional sanity log -->
  <script defer>
    window.addEventListener('DOMContentLoaded', () => {
      console.log('jQuery:', jQuery?.fn?.jquery);
      console.log('DataTables loaded:', !!jQuery?.fn?.dataTable);
    });
  </script>
</head>


  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

  <body class="theme-base-0c layout-reverse">

    <!-- Ribbon -->
<a href='/contributing.html' class='ribbon'>Add your paper to Learning2Hash</a>

<!-- Sidebar -->
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">Awesome Learning to Hash</a>
      </h1>
      <p class="lead">A Webpage dedicated to the latest research on Hash Function Learning. Maintained by <a href="https://www.buymeacoffee.com/sjmoran">Sean Moran</a>.</p>
    </div>

    <nav class="sidebar-nav">
      <div class="sidebar-item">
        <p style="font-size: 12px">
          Search related work
          <input type="text" id="searchTarget" size="16" />
          <button type="button" onClick="search();">Go</button>
        </p>
      </div>

      <!-- NOTE: use quoted comparisons for page.url -->
      <a class="sidebar-nav-item"
         href="/papers.html">All Papers</a>
      <a class="sidebar-nav-item"
         href="/tags.html">Papers by Tag</a>
      <a class="sidebar-nav-item"
         href="/tsne-viz.html">2D Map of Papers</a>
      <a class="sidebar-nav-item"
         href="/topic-viz.html">Topic Explorer</a>
      <a class="sidebar-nav-item"
         href="/opensource.html">Tools Explorer</a>
      <a class="sidebar-nav-item"
         href="/author-viz.html">Author Explorer</a>
      <a class="sidebar-nav-item"
         href="/tutorial.html">Tutorial</a>
      <a class="sidebar-nav-item"
         href="/resources.html">Resources, Courses &amp; Events</a>
      <a class="sidebar-nav-item"
         href="/contributing.html">Contributing</a>
    </nav>

    <!-- ===== Stay Updated (minimal block) ===== -->
    <hr style="border:none; border-top:1px solid #d8dee9; margin:0.75rem 0;" />
    <div class="sidebar-item" aria-label="Stay updated">
      <h3 style="margin:0 0 0.25rem 0; font-size:1rem;">Stay Updated</h3>
      <ul style="list-style:none; padding-left:0; margin:0;">
        <li style="margin:0.35rem 0;">
          <a class="sidebar-nav-item" href="/feed/publications.xml"
             rel="alternate" type="application/rss+xml">ðŸ“° RSS Feed</a>
        </li>
      </ul>
    </div>
    <!-- ===== End Stay Updated ===== -->

    <div class="sidebar-item">
      <p style="font-size: 12px">
        Contact <a href="https://sjmoran.github.io">Sean Moran</a> about this survey or website.
        <span style="font-size: 9px">
          Made with <a href="https://jekyllrb.com">Jekyll</a> and
          <a href="https://github.com/poole/hyde">Hyde</a>.
        </span>
      </p>
    </div>
  </div>
</div>

<style>
/* === Scrollable Right Sidebar (wider, matches Awesome LLM Papers) === */
.sidebar {
  position: fixed;
  top: 0;
  right: 0;
  height: 100vh;
  overflow-y: auto;
  overflow-x: hidden;
  padding: 1.5rem 1.25rem;
  box-sizing: border-box;
  background-color: #7da2b3;
  scrollbar-gutter: stable;

  /* wider: 260â€“420px instead of 240â€“340px */
  width: clamp(260px, 30vw, 420px);
  max-width: clamp(260px, 30vw, 420px);
}

/* Allow normal flow inside sticky container */
.sidebar .container.sidebar-sticky {
  position: relative;
  max-height: none;
  overflow: visible;
}

/* Optional: prettier scrollbar */
.sidebar::-webkit-scrollbar { width: 8px; }
.sidebar::-webkit-scrollbar-thumb { background: rgba(0,0,0,0.25); border-radius: 4px; }
.sidebar::-webkit-scrollbar-thumb:hover { background: rgba(0,0,0,0.4); }

/* Match content offset */
.main, .content {
  margin-right: clamp(260px, 30vw, 420px);
}

/* Mobile view: sidebar collapses */
@media (max-width: 880px) {
  .sidebar {
    position: static;
    height: auto;
    width: auto;
    max-width: none;
    border-bottom: 1px solid rgba(0,0,0,0.08);
  }
  .main, .content {
    margin-right: 0 !important;
  }
}
</style>

<script defer>
document.addEventListener('DOMContentLoaded', function () {
  // ---- Search ----
  function doSearch() {
    const el = document.getElementById('searchTarget');
    if (!el) return;
    const q = el.value.trim();
    try { if (typeof ga === 'function') ga('send', 'event', 'search', 'search', q); } catch(e) {}
    window.location = "/papers.html#" + encodeURIComponent(q);
  }

  if (window.jQuery) {
    $('#searchTarget').on('keydown', function (e) {
      if (e.key === 'Enter') doSearch();
    });
    document.querySelector('.sidebar-item button')?.addEventListener('click', doSearch);
  } else {
    const input = document.getElementById('searchTarget');
    const btn = document.querySelector('.sidebar-item button');
    if (input) {
      input.addEventListener('keydown', function (e) {
        if (e.key === 'Enter') doSearch();
      });
    }
    if (btn) btn.addEventListener('click', doSearch);
  }

  window.search = doSearch;

  // ---- Match content margin to actual sidebar width ----
  const sb = document.querySelector('.sidebar');
  const mains = document.querySelectorAll('.main, .content');
  function syncSidebarWidth() {
    if (!sb) return;
    const w = sb.offsetWidth + 'px';
    mains.forEach(m => m && (m.style.marginRight = w));
  }
  syncSidebarWidth();
  window.addEventListener('resize', syncSidebarWidth);
});
</script>


    <div class="content container mathjax-content">
      <div class="page">
  <h1 class="page-title">Up-person: Unified Parameter-efficient Transfer Learning For Text-based Person Retrieval</h1>

  <h5>
    
    
    <a href="https://scholar.google.com/scholar?q=Yating%20Liu,%20Yaowei%20Li,%20Xiangyuan%20Lan,%20Wenming%20Yang,%20Zimo%20Liu,%20Qingmin%20Liao" 
       target="_blank" rel="noopener noreferrer">
      Yating Liu, Yaowei Li, Xiangyuan Lan, Wenming Yang, Zimo Liu, Qingmin Liao
    </a>
    
    
    . Arxiv
     2025
    
      â€“ <span>0 citations</span>
    
  </h5>

  <!-- Inline Share Buttons -->
  <div class="share-buttons">
    <button id="share-twitter" class="icon-btn" title="Share on X (Twitter)" aria-label="Share on X (Twitter)">
      <img src="/public/media/x.svg" alt="X (Twitter) icon">
    </button>
    <button id="share-linkedin" class="icon-btn" title="Share on LinkedIn" aria-label="Share on LinkedIn">
      <img src="/public/media/linkedin.svg" alt="LinkedIn icon">
    </button>
    <button id="share-copy" class="icon-btn copy-btn" title="Copy Link" aria-label="Copy link to clipboard">
      <svg viewBox="0 0 24 24" width="18" height="18" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
        <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
        <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
      </svg>
      <span class="copy-label">Copy</span>
    </button>
  </div>

  <p>
    
      [<a href="https://github.com/Liu-Yating/UP-Person" target="_blank" rel="noopener noreferrer">Code</a>]
    
      [<a href="https://arxiv.org/abs/2504.10084" target="_blank" rel="noopener noreferrer">Paper</a>]
    
    &nbsp;<a href="https://scholar.google.com/scholar?q=Up-person:%20Unified%20Parameter-efficient%20Transfer%20Learning%20For%20Text-based%20Person%20Retrieval" target="_blank" rel="noopener noreferrer">
      <img style="display:inline; margin:0;" src="/public/media/google-scholar.png" alt="Search on Google Scholar"/>
    </a>
    &nbsp;<a href="https://www.semanticscholar.org/search?q=Up-person:%20Unified%20Parameter-efficient%20Transfer%20Learning%20For%20Text-based%20Person%20Retrieval" target="_blank" rel="noopener noreferrer">
      <img style="display:inline; margin:0;" src="/public/media/semscholar.png" alt="Search on Semantic Scholar"/>
    </a>
    <br/>
    
      <tag><a href="/tags.html#Datasets">Datasets</a></tag>
    
      <tag><a href="/tags.html#Evaluation">Evaluation</a></tag>
    
  </p>

  <p><p>Text-based Person Retrieval (TPR) as a multi-modal task, which aims to
retrieve the target person from a pool of candidate images given a text
description, has recently garnered considerable attention due to the progress
of contrastive visual-language pre-trained model. Prior works leverage
pre-trained CLIP to extract person visual and textual features and fully
fine-tune the entire network, which have shown notable performance improvements
compared to uni-modal pre-training models. However, full-tuning a large model
is prone to overfitting and hinders the generalization ability. In this paper,
we propose a novel Unified Parameter-Efficient Transfer Learning (PETL) method
for Text-based Person Retrieval (UP-Person) to thoroughly transfer the
multi-modal knowledge from CLIP. Specifically, UP-Person simultaneously
integrates three lightweight PETL components including Prefix, LoRA and
Adapter, where Prefix and LoRA are devised together to mine local information
with task-specific information prompts, and Adapter is designed to adjust
global feature representations. Additionally, two vanilla submodules are
optimized to adapt to the unified architecture of TPR. For one thing, S-Prefix
is proposed to boost attention of prefix and enhance the gradient propagation
of prefix tokens, which improves the flexibility and performance of the vanilla
prefix. For another thing, L-Adapter is designed in parallel with layer
normalization to adjust the overall distribution, which can resolve conflicts
caused by overlap and interaction among multiple submodules. Extensive
experimental results demonstrate that our UP-Person achieves state-of-the-art
results across various person retrieval datasets, including CUHK-PEDES,
ICFG-PEDES and RSTPReid while merely fine-tuning 4.7% parameters. Code is
available at https://github.com/Liu-Yating/UP-Person.</p>
</p>

  <h6>Similar Work</h6>
  <ul id="relwork"></ul>

  <script>
    document.addEventListener('DOMContentLoaded', function () {
      const relwork = document.getElementById('relwork');
      if (relwork) {
        const metaPath = "/publications-metadata/liu2025up.json";
        fetch(metaPath, { credentials: 'same-origin' })
          .then(res => {
            if (!res.ok) throw new Error(res.status + " " + res.statusText);
            return res.json();
          })
          .then(data => {
            if (!Array.isArray(data)) return;
            relwork.innerHTML = data
              .map(d => `<li><a href="/publications/${d[0]}">${d[1]}</a></li>`)
              .join('');
          })
          .catch(err => console.warn("Failed to load similar work JSON:", err));
      }

      const meta = {
        title: "Up-person: Unified Parameter-efficient Transfer Learning For Text-based Person Retrieval",
        conference: "Arxiv",
        year: 2025,
        tags: ["Datasets","Evaluation"]
      };

      const pageUrl = encodeURIComponent(window.location.href);
      let tweetText = `New paper: ${meta.title}`;
      if (meta.conference) tweetText += ` â€” ${meta.conference}`;
      if (meta.year) tweetText += ` (${meta.year})`;
      tweetText += ` ðŸ”`;

      const hashtags = (Array.isArray(meta.tags) ? meta.tags : [])
        .slice(0, 3)
        .map(t => String(t).replace(/[^A-Za-z0-9]/g, ''))
        .filter(Boolean)
        .join(',');

      const twitterBtn  = document.getElementById('share-twitter');
      const linkedinBtn = document.getElementById('share-linkedin');
      const copyBtn     = document.getElementById('share-copy');

      if (twitterBtn) {
        twitterBtn.addEventListener('click', () => {
          const customText = encodeURIComponent(tweetText);
          const hashParam  = hashtags ? `&hashtags=${encodeURIComponent(hashtags)}` : '';
          window.open(
            `https://twitter.com/intent/tweet?text=${customText}&url=${pageUrl}${hashParam}`,
            '_blank', 'noopener,noreferrer'
          );
        });
      }

      if (linkedinBtn) {
        linkedinBtn.addEventListener('click', () => {
          window.open(
            `https://www.linkedin.com/sharing/share-offsite/?url=${pageUrl}`,
            '_blank', 'noopener,noreferrer'
          );
        });
      }

      if (copyBtn) {
        copyBtn.addEventListener('click', () => {
          navigator.clipboard.writeText(window.location.href).then(() => {
            copyBtn.classList.add('copied');
            setTimeout(() => copyBtn.classList.remove('copied'), 900);
          });
        });
      }
    });
  </script>

  <style>
    .share-buttons {
      display: flex;
      gap: 8px;
      align-items: center;
      margin: 0.4em 0 1em 0;
      opacity: 0.9;
      flex-wrap: wrap;
    }

    .icon-btn {
      appearance: none;
      background: #f8f8f8;
      border: none;
      border-radius: 8px;
      width: 38px;
      height: 38px;
      display: inline-flex;
      flex-direction: column;
      align-items: center;
      justify-content: flex-start; /* start high, then push down */
      padding-top: 8px; /* lower the icons visually */
      cursor: pointer;
      transition: background 0.15s ease, transform 0.15s ease;
      position: relative;
    }

    .icon-btn img,
    .icon-btn svg {
      display: block;
      margin-top: 4px; /* fine-tune visual center */
      width: 18px;
      height: 18px;
      opacity: 0.8;
      object-fit: contain;
      object-position: center;
    }

    /* Copy button label */
    .copy-btn {
      width: auto;
      padding: 0 12px;
      flex-direction: row;
      align-items: center;
      justify-content: center;
      gap: 6px;
    }

    .copy-btn .copy-label {
      font-size: 0.85em;
      font-weight: 500;
      color: #333;
      user-select: none;
      margin-top: 2px;
    }

    .icon-btn:hover {
      background: #e9e9e9;
      transform: translateY(-1px);
    }

    .icon-btn:hover img,
    .icon-btn:hover svg {
      opacity: 1;
    }

    .icon-btn.copied {
      background: #d9f7e6;
    }
  </style>
</div>

    </div>

  </body>
</html>
