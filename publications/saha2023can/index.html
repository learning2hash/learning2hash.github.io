<!DOCTYPE html>
<html lang="en-us">

  <head>
<!-- Begin Web-Stat code v 7.0 -->
<span id="wts2185304"></span>
<script>var wts=document.createElement('script');wts.async=true;
wts.src='https://app.ardalio.com/log7.js';document.head.appendChild(wts);
wts.onload = function(){ wtslog7(2185304,4); };
</script><noscript><a href="https://www.web-stat.com">
<img src="https://app.ardalio.com/7/4/2185304.png" 
alt="Web-Stat web statistics"></a></noscript>
<!-- End Web-Stat code v 7.0 -->
  <!-- Hotjar Tracking Code for https://learning2hash.github.io/ -->
<script>
    (function(h,o,t,j,a,r){
        h.hj=h.hj||function(){(h.hj.q=h.hj.q||[]).push(arguments)};
        h._hjSettings={hjid:1843243,hjsv:6};
        a=o.getElementsByTagName('head')[0];
        r=o.createElement('script');r.async=1;
        r.src=t+h._hjSettings.hjid+j+h._hjSettings.hjsv;
        a.appendChild(r);
    })(window,document,'https://static.hotjar.com/c/hotjar-','.js?sv=');
</script><!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-109544763-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-109544763-1');
</script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [["\\(","\\)"]],
        displayMath: [["\\[","\\]"]]
      }
    });
  </script>
  <script type="text/javascript" async
    src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="keywords" content="machine learning, hashing, approximate nearest neighbour search, lsh, learning-to-hash">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Can Language Models Teach Weaker Agents Teacher Explanations Improve Students Via Personalization | Awesome Learning to Hash</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="Can Language Models Teach Weaker Agents Teacher Explanations Improve Students Via Personalization" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A hallmark property of explainable AI models is the ability to teach other agents communicating knowledge of how to perform a task. While Large Language Models perform complex reasoning by generating explanations for their predictions it is unclear whether they also make good teachers for weaker agents. To address this we consider a student-teacher framework between two LLM agents and study if when and how the teacher should intervene with natural language explanations to improve the students performance. Since communication is expensive we define a budget such that the teacher only communicates explanations for a fraction of the data after which the student should perform well on its own. We decompose the teaching problem along four axes (1) if teachers test time intervention improve student predictions (2) when it is worth explaining a data point (3) how the teacher should personalize explanations to better teach the student and (4) if teacher explanations also improve students on future unexplained data. We first show that teacher LLMs can indeed intervene on student reasoning to improve their performance. Next inspired by the Theory of Mind abilities of effective teachers we propose building two few-shot mental models of the student. The first model defines an Intervention Function that simulates the utility of an intervention allowing the teacher to intervene when this utility is the highest and improving student performance at lower budgets. The second model enables the teacher to personalize explanations for a particular student and outperform unpersonalized teachers. We also demonstrate that in multi-turn interactions teacher explanations generalize and learning from explained data improves student performance on future unexplained data. Finally we verify that misaligned teachers can lower student performance to random chance by intentionally misleading them." />
<meta property="og:description" content="A hallmark property of explainable AI models is the ability to teach other agents communicating knowledge of how to perform a task. While Large Language Models perform complex reasoning by generating explanations for their predictions it is unclear whether they also make good teachers for weaker agents. To address this we consider a student-teacher framework between two LLM agents and study if when and how the teacher should intervene with natural language explanations to improve the students performance. Since communication is expensive we define a budget such that the teacher only communicates explanations for a fraction of the data after which the student should perform well on its own. We decompose the teaching problem along four axes (1) if teachers test time intervention improve student predictions (2) when it is worth explaining a data point (3) how the teacher should personalize explanations to better teach the student and (4) if teacher explanations also improve students on future unexplained data. We first show that teacher LLMs can indeed intervene on student reasoning to improve their performance. Next inspired by the Theory of Mind abilities of effective teachers we propose building two few-shot mental models of the student. The first model defines an Intervention Function that simulates the utility of an intervention allowing the teacher to intervene when this utility is the highest and improving student performance at lower budgets. The second model enables the teacher to personalize explanations for a particular student and outperform unpersonalized teachers. We also demonstrate that in multi-turn interactions teacher explanations generalize and learning from explained data improves student performance on future unexplained data. Finally we verify that misaligned teachers can lower student performance to random chance by intentionally misleading them." />
<link rel="canonical" href="https://learning2hash.github.io/publications/saha2023can/" />
<meta property="og:url" content="https://learning2hash.github.io/publications/saha2023can/" />
<meta property="og:site_name" content="Awesome Learning to Hash" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-10-09T06:33:00-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Can Language Models Teach Weaker Agents Teacher Explanations Improve Students Via Personalization" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2024-10-09T06:33:00-05:00","datePublished":"2024-10-09T06:33:00-05:00","description":"A hallmark property of explainable AI models is the ability to teach other agents communicating knowledge of how to perform a task. While Large Language Models perform complex reasoning by generating explanations for their predictions it is unclear whether they also make good teachers for weaker agents. To address this we consider a student-teacher framework between two LLM agents and study if when and how the teacher should intervene with natural language explanations to improve the students performance. Since communication is expensive we define a budget such that the teacher only communicates explanations for a fraction of the data after which the student should perform well on its own. We decompose the teaching problem along four axes (1) if teachers test time intervention improve student predictions (2) when it is worth explaining a data point (3) how the teacher should personalize explanations to better teach the student and (4) if teacher explanations also improve students on future unexplained data. We first show that teacher LLMs can indeed intervene on student reasoning to improve their performance. Next inspired by the Theory of Mind abilities of effective teachers we propose building two few-shot mental models of the student. The first model defines an Intervention Function that simulates the utility of an intervention allowing the teacher to intervene when this utility is the highest and improving student performance at lower budgets. The second model enables the teacher to personalize explanations for a particular student and outperform unpersonalized teachers. We also demonstrate that in multi-turn interactions teacher explanations generalize and learning from explained data improves student performance on future unexplained data. Finally we verify that misaligned teachers can lower student performance to random chance by intentionally misleading them.","headline":"Can Language Models Teach Weaker Agents Teacher Explanations Improve Students Via Personalization","mainEntityOfPage":{"@type":"WebPage","@id":"https://learning2hash.github.io/publications/saha2023can/"},"url":"https://learning2hash.github.io/publications/saha2023can/"}</script>
<!-- End Jekyll SEO tag -->


  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="shortcut icon" href="/public/favicon.svg">
  <link rel="search" href="/public/opensearchdescription.xml" 
      type="application/opensearchdescription+xml" 
      title="learning2hash" />

  <script src="https://code.jquery.com/jquery-3.2.1.min.js"
  integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
  crossorigin="anonymous"></script>
  
  <link rel="stylesheet" type="text/css" href="//cdn.datatables.net/1.10.16/css/jquery.dataTables.min.css">
  <script type="text/javascript" charset="utf8" src="//cdn.datatables.net/1.10.16/js/jquery.dataTables.min.js"></script>
</head>


  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

  <body class="theme-base-0c layout-reverse">

    <a href='/contributing.html' class='ribbon'>Add your paper to Learning2Hash</a>
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Awesome Learning to Hash
        </a>
      </h1>
      <p class="lead">A Webpage dedicated to the latest research on Hash Function Learning. Maintained by <a href="http://sjmoran.github.io/">Sean Moran</a>.</p>
    </div>

    <nav class="sidebar-nav">
      <div class="sidebar-item">
        <p style="font-size: 12px">
          Search related work 
          <input type='text' id='searchTarget' size="16"/> 
          <button onClick="search();">Go</button>
        </p>
      </div>
      <a class="sidebar-nav-item" href="/papers.html">All Papers</a>
      <a class="sidebar-nav-item" href="/tags.html">Papers by Tag</a>
      <a class="sidebar-nav-item" href="/tsne-viz.html">2D Map of Papers</a>
      <a class="sidebar-nav-item" href="/topic-viz.html">Topic-based Explorer</a>
      <a class="sidebar-nav-item" href="/base-taxonomy/">Core Taxonomy</a>
      <a class="sidebar-nav-item" href="/base-taxonomy/datasets.html">Datasets</a>
      <a class="sidebar-nav-item" href="/tutorial.html">Tutorial</a>
      <a class="sidebar-nav-item" href="/resources.html">Resources, Courses &#38; Events</a>
      <a class="sidebar-nav-item" href="/contributing.html">Contributing</a>
    </nav>

    <div class="sidebar-item">
      <p style="font-size: 12px">
        Contact <a href="http://www.seanjmoran.com">Sean Moran</a> about this survey or website.
        <span style="font-size: 9px">
          Made with <a href="https://jekyllrb.com">Jekyll</a> and <a href="https://github.com/poole/hyde">Hyde</a>.
        </span>
      </p>
    </div>
  </div>
</div>

<script>
$("#searchTarget").keydown(function (e) {	
  if (e.keyCode == 13) {
    search();
  }
});

function search() {
  try {
    ga('send', 'event', 'search', 'search', $("#searchTarget").val());
  } finally {
    window.location = "/papers.html#" + $("#searchTarget").val();
  }
}
</script>


    <div class="content container">
      <div class="page">
  <h1 class="page-title">Can Language Models Teach Weaker Agents Teacher Explanations Improve Students Via Personalization</h1>
  <h5>Swarnadeep Saha, Peter Hase, Mohit Bansal. Arxiv 2023</h5>
  <p>
    
      [<a href="https://arxiv.org/abs/http://arxiv.org/abs/2306.09299v2" target="_blank">Paper</a>]
    
    &nbsp;<a href='http://scholar.google.com/scholar?q=Can Language Models Teach Weaker Agents Teacher Explanations Improve Students Via Personalization' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
    &nbsp;<a href='https://www.semanticscholar.org/search?q=Can Language Models Teach Weaker Agents Teacher Explanations Improve Students Via Personalization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
    <br/>
    
      <tag><a href="/tags.html#ARXIV">ARXIV</a></tag>
    
      <tag><a href="/tags.html#Independent">Independent</a></tag>
    
  </p>
  <p><p>A hallmark property of explainable AI models is the ability to teach other agents communicating knowledge of how to perform a task. While Large Language Models perform complex reasoning by generating explanations for their predictions it is unclear whether they also make good teachers for weaker agents. To address this we consider a student-teacher framework between two LLM agents and study if when and how the teacher should intervene with natural language explanations to improve the students performance. Since communication is expensive we define a budget such that the teacher only communicates explanations for a fraction of the data after which the student should perform well on its own. We decompose the teaching problem along four axes (1) if teachers test time intervention improve student predictions (2) when it is worth explaining a data point (3) how the teacher should personalize explanations to better teach the student and (4) if teacher explanations also improve students on future unexplained data. We first show that teacher LLMs can indeed intervene on student reasoning to improve their performance. Next inspired by the Theory of Mind abilities of effective teachers we propose building two few-shot mental models of the student. The first model defines an Intervention Function that simulates the utility of an intervention allowing the teacher to intervene when this utility is the highest and improving student performance at lower budgets. The second model enables the teacher to personalize explanations for a particular student and outperform unpersonalized teachers. We also demonstrate that in multi-turn interactions teacher explanations generalize and learning from explained data improves student performance on future unexplained data. Finally we verify that misaligned teachers can lower student performance to random chance by intentionally misleading them.</p>
</p>

  <h6>Similar Work</h6>
  <p>
    <ul id="relwork">

    </ul>
  </p>

  <script>  
    $(document).ready(
      function() {
        $.getJSON("/publications-metadata/saha2023can.json", function(data) {
          num_papers = data.length;
          html = "";
          for (let i=0; i < num_papers; i++) {
              html += '<li><a href="/publications/' + data[i][0] + '">'+ data[i][1] +'</a></li>'
          }
          $("#relwork").append(html);
        });
      });
  </script>

</div>

    </div>

  </body>
</html>
