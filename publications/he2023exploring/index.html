<!DOCTYPE html>
<html lang="en-us">

  <head>
<!-- Begin Web-Stat code v 7.0 -->
<span id="wts2185304"></span>
<script>var wts=document.createElement('script');wts.async=true;
wts.src='https://app.ardalio.com/log7.js';document.head.appendChild(wts);
wts.onload = function(){ wtslog7(2185304,4); };
</script><noscript><a href="https://www.web-stat.com">
<img src="https://app.ardalio.com/7/4/2185304.png" 
alt="Web-Stat web statistics"></a></noscript>
<!-- End Web-Stat code v 7.0 -->
  <!-- Hotjar Tracking Code for https://learning2hash.github.io/ -->
<script>
    (function(h,o,t,j,a,r){
        h.hj=h.hj||function(){(h.hj.q=h.hj.q||[]).push(arguments)};
        h._hjSettings={hjid:1843243,hjsv:6};
        a=o.getElementsByTagName('head')[0];
        r=o.createElement('script');r.async=1;
        r.src=t+h._hjSettings.hjid+j+h._hjSettings.hjsv;
        a.appendChild(r);
    })(window,document,'https://static.hotjar.com/c/hotjar-','.js?sv=');
</script><!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-109544763-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-109544763-1');
</script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [["\\(","\\)"]],
        displayMath: [["\\[","\\]"]]
      }
    });
  </script>
  <script type="text/javascript" async
    src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="keywords" content="machine learning, hashing, approximate nearest neighbour search, lsh, learning-to-hash">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Exploring Human-like Translation Strategy With Large Language Models | Awesome Learning to Hash</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="Exploring Human-like Translation Strategy With Large Language Models" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Large language models (LLMs) have demonstrated impressive capabilities in general scenarios exhibiting a level of aptitude that approaches in some aspects even surpasses human-level intelligence. Among their numerous skills the translation abilities of LLMs have received considerable attention. Compared to typical machine translation that focuses solely on source-to-target mapping LLM-based translation can potentially mimic the human translation process which might take preparatory steps to ensure high-quality translation. This work explores this possibility by proposing the MAPS framework which stands for Multi-Aspect Prompting and Selection. Specifically we enable LLMs first to analyze the given source sentence and induce three aspects of translation-related knowledge keywords topics and relevant demonstrations to guide the final translation process. Moreover we employ a selection mechanism based on quality estimation to filter out noisy and unhelpful knowledge. Both automatic (3 LLMs x 11 directions x 2 automatic metrics) and human evaluation (preference study and MQM) demonstrate the effectiveness of MAPS. Further analysis shows that by mimicking the human translation process MAPS reduces various translation errors such as hallucination ambiguity mistranslation awkward style untranslated text and omission. Source code is available at https://github.com/zwhe99/MAPS-mt." />
<meta property="og:description" content="Large language models (LLMs) have demonstrated impressive capabilities in general scenarios exhibiting a level of aptitude that approaches in some aspects even surpasses human-level intelligence. Among their numerous skills the translation abilities of LLMs have received considerable attention. Compared to typical machine translation that focuses solely on source-to-target mapping LLM-based translation can potentially mimic the human translation process which might take preparatory steps to ensure high-quality translation. This work explores this possibility by proposing the MAPS framework which stands for Multi-Aspect Prompting and Selection. Specifically we enable LLMs first to analyze the given source sentence and induce three aspects of translation-related knowledge keywords topics and relevant demonstrations to guide the final translation process. Moreover we employ a selection mechanism based on quality estimation to filter out noisy and unhelpful knowledge. Both automatic (3 LLMs x 11 directions x 2 automatic metrics) and human evaluation (preference study and MQM) demonstrate the effectiveness of MAPS. Further analysis shows that by mimicking the human translation process MAPS reduces various translation errors such as hallucination ambiguity mistranslation awkward style untranslated text and omission. Source code is available at https://github.com/zwhe99/MAPS-mt." />
<link rel="canonical" href="https://learning2hash.github.io/publications/he2023exploring/" />
<meta property="og:url" content="https://learning2hash.github.io/publications/he2023exploring/" />
<meta property="og:site_name" content="Awesome Learning to Hash" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-10-09T06:33:00-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Exploring Human-like Translation Strategy With Large Language Models" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2024-10-09T06:33:00-05:00","datePublished":"2024-10-09T06:33:00-05:00","description":"Large language models (LLMs) have demonstrated impressive capabilities in general scenarios exhibiting a level of aptitude that approaches in some aspects even surpasses human-level intelligence. Among their numerous skills the translation abilities of LLMs have received considerable attention. Compared to typical machine translation that focuses solely on source-to-target mapping LLM-based translation can potentially mimic the human translation process which might take preparatory steps to ensure high-quality translation. This work explores this possibility by proposing the MAPS framework which stands for Multi-Aspect Prompting and Selection. Specifically we enable LLMs first to analyze the given source sentence and induce three aspects of translation-related knowledge keywords topics and relevant demonstrations to guide the final translation process. Moreover we employ a selection mechanism based on quality estimation to filter out noisy and unhelpful knowledge. Both automatic (3 LLMs x 11 directions x 2 automatic metrics) and human evaluation (preference study and MQM) demonstrate the effectiveness of MAPS. Further analysis shows that by mimicking the human translation process MAPS reduces various translation errors such as hallucination ambiguity mistranslation awkward style untranslated text and omission. Source code is available at https://github.com/zwhe99/MAPS-mt.","headline":"Exploring Human-like Translation Strategy With Large Language Models","mainEntityOfPage":{"@type":"WebPage","@id":"https://learning2hash.github.io/publications/he2023exploring/"},"url":"https://learning2hash.github.io/publications/he2023exploring/"}</script>
<!-- End Jekyll SEO tag -->


  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="shortcut icon" href="/public/favicon.svg">
  <link rel="search" href="/public/opensearchdescription.xml" 
      type="application/opensearchdescription+xml" 
      title="learning2hash" />

  <script src="https://code.jquery.com/jquery-3.2.1.min.js"
  integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
  crossorigin="anonymous"></script>
  
  <link rel="stylesheet" type="text/css" href="//cdn.datatables.net/1.10.16/css/jquery.dataTables.min.css">
  <script type="text/javascript" charset="utf8" src="//cdn.datatables.net/1.10.16/js/jquery.dataTables.min.js"></script>
</head>


  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

  <body class="theme-base-0c layout-reverse">

    <a href='/contributing.html' class='ribbon'>Add your paper to Learning2Hash</a>
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Awesome Learning to Hash
        </a>
      </h1>
      <p class="lead">A Webpage dedicated to the latest research on Hash Function Learning. Maintained by <a href="http://sjmoran.github.io/">Sean Moran</a>.</p>
    </div>

    <nav class="sidebar-nav">
      <div class="sidebar-item">
        <p style="font-size: 12px">
          Search related work 
          <input type='text' id='searchTarget' size="16"/> 
          <button onClick="search();">Go</button>
        </p>
      </div>
      <a class="sidebar-nav-item" href="/papers.html">All Papers</a>
      <a class="sidebar-nav-item" href="/tags.html">Papers by Tag</a>
      <a class="sidebar-nav-item" href="/tsne-viz.html">2D Map of Papers</a>
      <a class="sidebar-nav-item" href="/topic-viz.html">Topic-based Explorer</a>
      <a class="sidebar-nav-item" href="/base-taxonomy/">Core Taxonomy</a>
      <a class="sidebar-nav-item" href="/base-taxonomy/datasets.html">Datasets</a>
      <a class="sidebar-nav-item" href="/tutorial.html">Tutorial</a>
      <a class="sidebar-nav-item" href="/resources.html">Resources, Courses &#38; Events</a>
      <a class="sidebar-nav-item" href="/contributing.html">Contributing</a>
    </nav>

    <div class="sidebar-item">
      <p style="font-size: 12px">
        Contact <a href="http://www.seanjmoran.com">Sean Moran</a> about this survey or website.
        <span style="font-size: 9px">
          Made with <a href="https://jekyllrb.com">Jekyll</a> and <a href="https://github.com/poole/hyde">Hyde</a>.
        </span>
      </p>
    </div>
  </div>
</div>

<script>
$("#searchTarget").keydown(function (e) {	
  if (e.keyCode == 13) {
    search();
  }
});

function search() {
  try {
    ga('send', 'event', 'search', 'search', $("#searchTarget").val());
  } finally {
    window.location = "/papers.html#" + $("#searchTarget").val();
  }
}
</script>


    <div class="content container">
      <div class="page">
  <h1 class="page-title">Exploring Human-like Translation Strategy With Large Language Models</h1>
  <h5>Zhiwei He, Tian Liang, Wenxiang Jiao, Zhuosheng Zhang, Yujiu Yang, Rui Wang, Zhaopeng Tu, Shuming Shi, Xing Wang. Arxiv 2023</h5>
  <p>
    
      [<a href="https://arxiv.org/abs/http://arxiv.org/abs/2305.04118v3" target="_blank">Paper</a>]
    
      [<a href="https://github.com/zwhe99/MAPS-mt" target="_blank">Code</a>]
    
    &nbsp;<a href='http://scholar.google.com/scholar?q=Exploring Human-like Translation Strategy With Large Language Models' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
    &nbsp;<a href='https://www.semanticscholar.org/search?q=Exploring Human-like Translation Strategy With Large Language Models' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
    <br/>
    
      <tag><a href="/tags.html#ARXIV">ARXIV</a></tag>
    
      <tag><a href="/tags.html#Has Code">Has Code</a></tag>
    
  </p>
  <p><p>Large language models (LLMs) have demonstrated impressive capabilities in general scenarios exhibiting a level of aptitude that approaches in some aspects even surpasses human-level intelligence. Among their numerous skills the translation abilities of LLMs have received considerable attention. Compared to typical machine translation that focuses solely on source-to-target mapping LLM-based translation can potentially mimic the human translation process which might take preparatory steps to ensure high-quality translation. This work explores this possibility by proposing the MAPS framework which stands for Multi-Aspect Prompting and Selection. Specifically we enable LLMs first to analyze the given source sentence and induce three aspects of translation-related knowledge keywords topics and relevant demonstrations to guide the final translation process. Moreover we employ a selection mechanism based on quality estimation to filter out noisy and unhelpful knowledge. Both automatic (3 LLMs x 11 directions x 2 automatic metrics) and human evaluation (preference study and MQM) demonstrate the effectiveness of MAPS. Further analysis shows that by mimicking the human translation process MAPS reduces various translation errors such as hallucination ambiguity mistranslation awkward style untranslated text and omission. Source code is available at https://github.com/zwhe99/MAPS-mt.</p>
</p>

  <h6>Similar Work</h6>
  <p>
    <ul id="relwork">

    </ul>
  </p>

  <script>  
    $(document).ready(
      function() {
        $.getJSON("/publications-metadata/he2023exploring.json", function(data) {
          num_papers = data.length;
          html = "";
          for (let i=0; i < num_papers; i++) {
              html += '<li><a href="/publications/' + data[i][0] + '">'+ data[i][1] +'</a></li>'
          }
          $("#relwork").append(html);
        });
      });
  </script>

</div>

    </div>

  </body>
</html>
