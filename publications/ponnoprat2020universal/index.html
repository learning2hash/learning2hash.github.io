<!DOCTYPE html>
<html lang="en-us">

  <head>
<!-- Begin Web-Stat code v 7.0 -->
<span id="wts2185304"></span>
<script>var wts=document.createElement('script');wts.async=true;
wts.src='https://app.ardalio.com/log7.js';document.head.appendChild(wts);
wts.onload = function(){ wtslog7(2185304,4); };
</script><noscript><a href="https://www.web-stat.com">
<img src="https://app.ardalio.com/7/4/2185304.png" 
alt="Web-Stat web statistics"></a></noscript>
<!-- End Web-Stat code v 7.0 -->
  <!-- Hotjar Tracking Code for https://learning2hash.github.io/ -->
<script>
    (function(h,o,t,j,a,r){
        h.hj=h.hj||function(){(h.hj.q=h.hj.q||[]).push(arguments)};
        h._hjSettings={hjid:1843243,hjsv:6};
        a=o.getElementsByTagName('head')[0];
        r=o.createElement('script');r.async=1;
        r.src=t+h._hjSettings.hjid+j+h._hjSettings.hjsv;
        a.appendChild(r);
    })(window,document,'https://static.hotjar.com/c/hotjar-','.js?sv=');
</script><!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-109544763-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-109544763-1');
</script>
<script>
    window.MathJax = {
      tex: {
        inlineMath: [["\\(","\\)"]],
        displayMath: [["\\[","\\]"]],
      },
      options: {
        processHtmlClass: "mathjax-content",
        processEscapes: true,
      }
    };
  </script>
  <script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="keywords" content="machine learning, hashing, approximate nearest neighbour search, lsh, learning-to-hash">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Universal Consistency Of Wasserstein (k)-nn Classifier: Negative And Positive Results | Awesome Learning to Hash</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="Universal Consistency Of Wasserstein (k)-nn Classifier: Negative And Positive Results" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The Wasserstein distance provides a notion of dissimilarities between probability measures, which has recent applications in learning of structured data with varying size such as images and text documents. In this work, we study the (k)-nearest neighbor classifier ((k)-NN) of probability measures under the Wasserstein distance. We show that the (k)-NN classifier is not universally consistent on the space of measures supported in ((0,1)). As any Euclidean ball contains a copy of ((0,1)), one should not expect to obtain universal consistency without some restriction on the base metric space, or the Wasserstein space itself. To this end, via the notion of (\sigma)-finite metric dimension, we show that the (k)-NN classifier is universally consistent on spaces of measures supported in a (\sigma)-uniformly discrete set. In addition, by studying the geodesic structures of the Wasserstein spaces for (p=1) and (p=2), we show that the (k)-NN classifier is universally consistent on the space of measures supported on a finite set, the space of Gaussian measures, and the space of measures with densities expressed as finite wavelet series." />
<meta property="og:description" content="The Wasserstein distance provides a notion of dissimilarities between probability measures, which has recent applications in learning of structured data with varying size such as images and text documents. In this work, we study the (k)-nearest neighbor classifier ((k)-NN) of probability measures under the Wasserstein distance. We show that the (k)-NN classifier is not universally consistent on the space of measures supported in ((0,1)). As any Euclidean ball contains a copy of ((0,1)), one should not expect to obtain universal consistency without some restriction on the base metric space, or the Wasserstein space itself. To this end, via the notion of (\sigma)-finite metric dimension, we show that the (k)-NN classifier is universally consistent on spaces of measures supported in a (\sigma)-uniformly discrete set. In addition, by studying the geodesic structures of the Wasserstein spaces for (p=1) and (p=2), we show that the (k)-NN classifier is universally consistent on the space of measures supported on a finite set, the space of Gaussian measures, and the space of measures with densities expressed as finite wavelet series." />
<link rel="canonical" href="https://learning2hash.github.io/publications/ponnoprat2020universal/" />
<meta property="og:url" content="https://learning2hash.github.io/publications/ponnoprat2020universal/" />
<meta property="og:site_name" content="Awesome Learning to Hash" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-08-14T11:10:36-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Universal Consistency Of Wasserstein (k)-nn Classifier: Negative And Positive Results" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-08-14T11:10:36-05:00","datePublished":"2025-08-14T11:10:36-05:00","description":"The Wasserstein distance provides a notion of dissimilarities between probability measures, which has recent applications in learning of structured data with varying size such as images and text documents. In this work, we study the (k)-nearest neighbor classifier ((k)-NN) of probability measures under the Wasserstein distance. We show that the (k)-NN classifier is not universally consistent on the space of measures supported in ((0,1)). As any Euclidean ball contains a copy of ((0,1)), one should not expect to obtain universal consistency without some restriction on the base metric space, or the Wasserstein space itself. To this end, via the notion of (\\sigma)-finite metric dimension, we show that the (k)-NN classifier is universally consistent on spaces of measures supported in a (\\sigma)-uniformly discrete set. In addition, by studying the geodesic structures of the Wasserstein spaces for (p=1) and (p=2), we show that the (k)-NN classifier is universally consistent on the space of measures supported on a finite set, the space of Gaussian measures, and the space of measures with densities expressed as finite wavelet series.","headline":"Universal Consistency Of Wasserstein (k)-nn Classifier: Negative And Positive Results","mainEntityOfPage":{"@type":"WebPage","@id":"https://learning2hash.github.io/publications/ponnoprat2020universal/"},"url":"https://learning2hash.github.io/publications/ponnoprat2020universal/"}</script>
<!-- End Jekyll SEO tag -->


  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="shortcut icon" href="/public/favicon.svg">
  <link rel="search" href="/public/opensearchdescription.xml" 
      type="application/opensearchdescription+xml" 
      title="learning2hash" />

  <script src="https://code.jquery.com/jquery-3.2.1.min.js"
  integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
  crossorigin="anonymous"></script>
  
  <link rel="stylesheet" type="text/css" href="//cdn.datatables.net/1.10.16/css/jquery.dataTables.min.css">
  <script type="text/javascript" charset="utf8" src="//cdn.datatables.net/1.10.16/js/jquery.dataTables.min.js"></script>
</head>


  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

  <body class="theme-base-0c layout-reverse">

    <a href='/contributing.html' class='ribbon'>Add your paper to Learning2Hash</a>
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Awesome Learning to Hash
        </a>
      </h1>
      <p class="lead">A Webpage dedicated to the latest research on Hash Function Learning. Maintained by <a href="http://sjmoran.github.io/">Sean Moran</a>.</p>
    </div>

    <nav class="sidebar-nav">
      <div class="sidebar-item">
        <p style="font-size: 12px">
          Search related work 
          <input type='text' id='searchTarget' size="16"/> 
          <button onClick="search();">Go</button>
        </p>
      </div>
      <a class="sidebar-nav-item" href="/papers.html">All Papers</a>
      <a class="sidebar-nav-item" href="/tags.html">Papers by Tag</a>
      <a class="sidebar-nav-item" href="/tsne-viz.html">2D Map of Papers</a>
      <a class="sidebar-nav-item" href="/topic-viz.html">Topic Explorer</a>
      <a class="sidebar-nav-item" href="/author-viz.html">Author Explorer </a>
      <a class="sidebar-nav-item" href="/tutorial.html">Tutorial</a>
      <a class="sidebar-nav-item" href="/resources.html">Resources, Courses &#38; Events</a>
      <a class="sidebar-nav-item" href="/contributing.html">Contributing</a>
    </nav>

    <div class="sidebar-item">
      <p style="font-size: 12px">
        Contact <a href="http://www.seanjmoran.com">Sean Moran</a> about this survey or website.
        <span style="font-size: 9px">
          Made with <a href="https://jekyllrb.com">Jekyll</a> and <a href="https://github.com/poole/hyde">Hyde</a>.
        </span>
      </p>
    </div>
  </div>
</div>

<script>
$("#searchTarget").keydown(function (e) {	
  if (e.keyCode == 13) {
    search();
  }
});

function search() {
  try {
    ga('send', 'event', 'search', 'search', $("#searchTarget").val());
  } finally {
    window.location = "/papers.html#" + $("#searchTarget").val();
  }
}
</script>


    <div class="content container">
      <div class="page">
  <h1 class="page-title">Universal Consistency Of Wasserstein \(k\)-nn Classifier: Negative And Positive Results</h1>
  <h5>
  
    
      Donlapark Ponnoprat
    
  
  . Arxiv
   2020
  
    – <span>0 citations</span>
  
  </h5>
  <p>
    
      [<a href="https://arxiv.org/abs/2009.04651" target="_blank">Paper</a>]
    
    &nbsp;<a href='http://scholar.google.com/scholar?q=Universal Consistency Of Wasserstein \(k\)-nn Classifier: Negative And Positive Results' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
    &nbsp;<a href='https://www.semanticscholar.org/search?q=Universal Consistency Of Wasserstein \(k\)-nn Classifier: Negative And Positive Results' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
    <br/>
    
  </p>
  <p><p>The Wasserstein distance provides a notion of dissimilarities between
probability measures, which has recent applications in learning of structured
data with varying size such as images and text documents. In this work, we
study the (k)-nearest neighbor classifier ((k)-NN) of probability measures
under the Wasserstein distance. We show that the (k)-NN classifier is not
universally consistent on the space of measures supported in ((0,1)). As any
Euclidean ball contains a copy of ((0,1)), one should not expect to obtain
universal consistency without some restriction on the base metric space, or the
Wasserstein space itself. To this end, via the notion of (\sigma)-finite metric
dimension, we show that the (k)-NN classifier is universally consistent on
spaces of measures supported in a (\sigma)-uniformly discrete set. In addition,
by studying the geodesic structures of the Wasserstein spaces for (p=1) and
(p=2), we show that the (k)-NN classifier is universally consistent on the
space of measures supported on a finite set, the space of Gaussian measures,
and the space of measures with densities expressed as finite wavelet series.</p>
</p>

  <h6>Similar Work</h6>
  <p>
    <ul id="relwork">

    </ul>
  </p>

 <script>  
    $(document).ready(
      function() {
        $.getJSON("/publications-metadata/ponnoprat2020universal.json", function(data) {
          num_papers = data.length;
          html = "";
          for (let i=0; i < num_papers; i++) {
              html += '<li><a href="/publications/' + data[i][0] + '">'+ data[i][1] +'</a></li>'
          }
          $("#relwork").append(html);
        });
      });
  </script>


</div>

    </div>

  </body>
</html>
