<!DOCTYPE html>
<html lang="en-us">

  <head>
<!-- Begin Web-Stat code v 7.0 -->
<span id="wts2185304"></span>
<script>var wts=document.createElement('script');wts.async=true;
wts.src='https://app.ardalio.com/log7.js';document.head.appendChild(wts);
wts.onload = function(){ wtslog7(2185304,4); };
</script><noscript><a href="https://www.web-stat.com">
<img src="https://app.ardalio.com/7/4/2185304.png" 
alt="Web-Stat web statistics"></a></noscript>
<!-- End Web-Stat code v 7.0 -->
  <!-- Hotjar Tracking Code for https://learning2hash.github.io/ -->
<script>
    (function(h,o,t,j,a,r){
        h.hj=h.hj||function(){(h.hj.q=h.hj.q||[]).push(arguments)};
        h._hjSettings={hjid:1843243,hjsv:6};
        a=o.getElementsByTagName('head')[0];
        r=o.createElement('script');r.async=1;
        r.src=t+h._hjSettings.hjid+j+h._hjSettings.hjsv;
        a.appendChild(r);
    })(window,document,'https://static.hotjar.com/c/hotjar-','.js?sv=');
</script><!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-109544763-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-109544763-1');
</script>
<script>
    window.MathJax = {
      tex: {
        inlineMath: [["\\(","\\)"]],
        displayMath: [["\\[","\\]"]],
      },
      options: {
        processHtmlClass: "mathjax-content",
        processEscapes: true,
      }
    };
  </script>
  <script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="keywords" content="machine learning, hashing, approximate nearest neighbour search, lsh, learning-to-hash">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Multi-resolution Hashing For Fast Pairwise Summations | Awesome Learning to Hash</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="Multi-resolution Hashing For Fast Pairwise Summations" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A basic computational primitive in the analysis of massive datasets is summing simple functions over a large number of objects. Modern applications pose an additional challenge in that such functions often depend on a parameter vector \(y\) (query) that is unknown a priori. Given a set of points \(X\subset \mathbb{R}^{d}\) and a pairwise function \(w:\mathbb{R}^{d}\times \mathbb{R}^{d}\to [0,1]\), we study the problem of designing a data-structure that enables sublinear-time approximation of the summation \(Z_{w}(y)=\frac{1}{|X|}\sum_{x\in X}w(x,y)\) for any query \(y\in \mathbb{R}^{d}\). By combining ideas from Harmonic Analysis (partitions of unity and approximation theory) with Hashing-Based-Estimators [Charikar, Siminelakis FOCS’17], we provide a general framework for designing such data structures through hashing that reaches far beyond what previous techniques allowed. A key design principle is a collection of \(T\geq 1\) hashing schemes with collision probabilities \(p_{1},\ldots, p_{T}\) such that \(\sup_{t\in [T]}\{p_{t}(x,y)\} = \Theta(\sqrt{w(x,y)})\). This leads to a data-structure that approximates \(Z_{w}(y)\) using a sub-linear number of samples from each hash family. Using this new framework along with Distance Sensitive Hashing [Aumuller, Christiani, Pagh, Silvestri PODS’18], we show that such a collection can be constructed and evaluated efficiently for any log-convex function \(w(x,y)=e^{\phi(\langle x,y\rangle)}\) of the inner product on the unit sphere \(x,y\in \mathcal{S}^{d-1}\). Our method leads to data structures with sub-linear query time that significantly improve upon random sampling and can be used for Kernel Density or Partition Function Estimation. We provide extensions of our result from the sphere to \(\mathbb{R}^{d}\) and from scalar functions to vector functions." />
<meta property="og:description" content="A basic computational primitive in the analysis of massive datasets is summing simple functions over a large number of objects. Modern applications pose an additional challenge in that such functions often depend on a parameter vector \(y\) (query) that is unknown a priori. Given a set of points \(X\subset \mathbb{R}^{d}\) and a pairwise function \(w:\mathbb{R}^{d}\times \mathbb{R}^{d}\to [0,1]\), we study the problem of designing a data-structure that enables sublinear-time approximation of the summation \(Z_{w}(y)=\frac{1}{|X|}\sum_{x\in X}w(x,y)\) for any query \(y\in \mathbb{R}^{d}\). By combining ideas from Harmonic Analysis (partitions of unity and approximation theory) with Hashing-Based-Estimators [Charikar, Siminelakis FOCS’17], we provide a general framework for designing such data structures through hashing that reaches far beyond what previous techniques allowed. A key design principle is a collection of \(T\geq 1\) hashing schemes with collision probabilities \(p_{1},\ldots, p_{T}\) such that \(\sup_{t\in [T]}\{p_{t}(x,y)\} = \Theta(\sqrt{w(x,y)})\). This leads to a data-structure that approximates \(Z_{w}(y)\) using a sub-linear number of samples from each hash family. Using this new framework along with Distance Sensitive Hashing [Aumuller, Christiani, Pagh, Silvestri PODS’18], we show that such a collection can be constructed and evaluated efficiently for any log-convex function \(w(x,y)=e^{\phi(\langle x,y\rangle)}\) of the inner product on the unit sphere \(x,y\in \mathcal{S}^{d-1}\). Our method leads to data structures with sub-linear query time that significantly improve upon random sampling and can be used for Kernel Density or Partition Function Estimation. We provide extensions of our result from the sphere to \(\mathbb{R}^{d}\) and from scalar functions to vector functions." />
<link rel="canonical" href="https://learning2hash.github.io/publications/charikar2018multi/" />
<meta property="og:url" content="https://learning2hash.github.io/publications/charikar2018multi/" />
<meta property="og:site_name" content="Awesome Learning to Hash" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-06-18T10:32:10-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Multi-resolution Hashing For Fast Pairwise Summations" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-06-18T10:32:10-05:00","datePublished":"2025-06-18T10:32:10-05:00","description":"A basic computational primitive in the analysis of massive datasets is summing simple functions over a large number of objects. Modern applications pose an additional challenge in that such functions often depend on a parameter vector \\(y\\) (query) that is unknown a priori. Given a set of points \\(X\\subset \\mathbb{R}^{d}\\) and a pairwise function \\(w:\\mathbb{R}^{d}\\times \\mathbb{R}^{d}\\to [0,1]\\), we study the problem of designing a data-structure that enables sublinear-time approximation of the summation \\(Z_{w}(y)=\\frac{1}{|X|}\\sum_{x\\in X}w(x,y)\\) for any query \\(y\\in \\mathbb{R}^{d}\\). By combining ideas from Harmonic Analysis (partitions of unity and approximation theory) with Hashing-Based-Estimators [Charikar, Siminelakis FOCS’17], we provide a general framework for designing such data structures through hashing that reaches far beyond what previous techniques allowed. A key design principle is a collection of \\(T\\geq 1\\) hashing schemes with collision probabilities \\(p_{1},\\ldots, p_{T}\\) such that \\(\\sup_{t\\in [T]}\\{p_{t}(x,y)\\} = \\Theta(\\sqrt{w(x,y)})\\). This leads to a data-structure that approximates \\(Z_{w}(y)\\) using a sub-linear number of samples from each hash family. Using this new framework along with Distance Sensitive Hashing [Aumuller, Christiani, Pagh, Silvestri PODS’18], we show that such a collection can be constructed and evaluated efficiently for any log-convex function \\(w(x,y)=e^{\\phi(\\langle x,y\\rangle)}\\) of the inner product on the unit sphere \\(x,y\\in \\mathcal{S}^{d-1}\\). Our method leads to data structures with sub-linear query time that significantly improve upon random sampling and can be used for Kernel Density or Partition Function Estimation. We provide extensions of our result from the sphere to \\(\\mathbb{R}^{d}\\) and from scalar functions to vector functions.","headline":"Multi-resolution Hashing For Fast Pairwise Summations","mainEntityOfPage":{"@type":"WebPage","@id":"https://learning2hash.github.io/publications/charikar2018multi/"},"url":"https://learning2hash.github.io/publications/charikar2018multi/"}</script>
<!-- End Jekyll SEO tag -->


  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="shortcut icon" href="/public/favicon.svg">
  <link rel="search" href="/public/opensearchdescription.xml" 
      type="application/opensearchdescription+xml" 
      title="learning2hash" />

  <script src="https://code.jquery.com/jquery-3.2.1.min.js"
  integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
  crossorigin="anonymous"></script>
  
  <link rel="stylesheet" type="text/css" href="//cdn.datatables.net/1.10.16/css/jquery.dataTables.min.css">
  <script type="text/javascript" charset="utf8" src="//cdn.datatables.net/1.10.16/js/jquery.dataTables.min.js"></script>
</head>


  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

  <body class="theme-base-0c layout-reverse">

    <a href='/contributing.html' class='ribbon'>Add your paper to Learning2Hash</a>
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Awesome Learning to Hash
        </a>
      </h1>
      <p class="lead">A Webpage dedicated to the latest research on Hash Function Learning. Maintained by <a href="http://sjmoran.github.io/">Sean Moran</a>.</p>
    </div>

    <nav class="sidebar-nav">
      <div class="sidebar-item">
        <p style="font-size: 12px">
          Search related work 
          <input type='text' id='searchTarget' size="16"/> 
          <button onClick="search();">Go</button>
        </p>
      </div>
      <a class="sidebar-nav-item" href="/papers.html">All Papers</a>
      <a class="sidebar-nav-item" href="/tags.html">Papers by Tag</a>
      <a class="sidebar-nav-item" href="/tsne-viz.html">2D Map of Papers</a>
      <a class="sidebar-nav-item" href="/topic-viz.html">Topic-based Explorer</a>
      <a class="sidebar-nav-item" href="/tutorial.html">Tutorial</a>
      <a class="sidebar-nav-item" href="/resources.html">Resources, Courses &#38; Events</a>
      <a class="sidebar-nav-item" href="/contributing.html">Contributing</a>
    </nav>

    <div class="sidebar-item">
      <p style="font-size: 12px">
        Contact <a href="http://www.seanjmoran.com">Sean Moran</a> about this survey or website.
        <span style="font-size: 9px">
          Made with <a href="https://jekyllrb.com">Jekyll</a> and <a href="https://github.com/poole/hyde">Hyde</a>.
        </span>
      </p>
    </div>
  </div>
</div>

<script>
$("#searchTarget").keydown(function (e) {	
  if (e.keyCode == 13) {
    search();
  }
});

function search() {
  try {
    ga('send', 'event', 'search', 'search', $("#searchTarget").val());
  } finally {
    window.location = "/papers.html#" + $("#searchTarget").val();
  }
}
</script>


    <div class="content container">
      <div class="page mathjax-content">
  <h1 class="page-title">Multi-resolution Hashing For Fast Pairwise Summations</h1>
  <h5>Moses Charikar, Paris Siminelakis. Arxiv 2018</h5>
  
  <p>
    
      [<a href="https://arxiv.org/abs/1807.07635" target="_blank">Paper</a>]
    
    &nbsp;<a href='http://scholar.google.com/scholar?q=Multi-resolution%20Hashing%20For%20Fast%20Pairwise%20Summations' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
    &nbsp;<a href='https://www.semanticscholar.org/search?q=Multi-resolution%20Hashing%20For%20Fast%20Pairwise%20Summations' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
    <br/>
    
      <span class="tag"><a href="/tags.html#Hashing Methods">Hashing Methods</a></span>
    
      <span class="tag"><a href="/tags.html#Applications">Applications</a></span>
    
  </p>
  
  <p><p>A basic computational primitive in the analysis of massive datasets is
summing simple functions over a large number of objects. Modern applications
pose an additional challenge in that such functions often depend on a parameter
vector \(y\) (query) that is unknown a priori. Given a set of points \(X\subset
\mathbb{R}^{d}\) and a pairwise function \(w:\mathbb{R}^{d}\times
\mathbb{R}^{d}\to [0,1]\), we study the problem of designing a data-structure
that enables sublinear-time approximation of the summation
\(Z_{w}(y)=\frac{1}{|X|}\sum_{x\in X}w(x,y)\) for any query \(y\in
\mathbb{R}^{d}\). By combining ideas from Harmonic Analysis (partitions of unity
and approximation theory) with Hashing-Based-Estimators [Charikar, Siminelakis
FOCS’17], we provide a general framework for designing such data structures
through hashing that reaches far beyond what previous techniques allowed.
  A key design principle is a collection of \(T\geq 1\) hashing schemes with
collision probabilities \(p_{1},\ldots, p_{T}\) such that \(\sup_{t\in
[T]}\{p_{t}(x,y)\} = \Theta(\sqrt{w(x,y)})\). This leads to a data-structure
that approximates \(Z_{w}(y)\) using a sub-linear number of samples from each
hash family. Using this new framework along with Distance Sensitive Hashing
[Aumuller, Christiani, Pagh, Silvestri PODS’18], we show that such a collection
can be constructed and evaluated efficiently for any log-convex function
\(w(x,y)=e^{\phi(\langle x,y\rangle)}\) of the inner product on the unit sphere
\(x,y\in \mathcal{S}^{d-1}\).
  Our method leads to data structures with sub-linear query time that
significantly improve upon random sampling and can be used for Kernel Density
or Partition Function Estimation. We provide extensions of our result from the
sphere to \(\mathbb{R}^{d}\) and from scalar functions to vector functions.</p>
</p>

  <h6>Similar Work</h6>
  <p>
    <ul id="relwork"></ul>
  </p>

  <script defer>
    $(document).ready(function() {
      $.getJSON("/publications-metadata/charikar2018multi.json", function(data) {
        var num_papers = data.length;
        var html = "";
        for (var i = 0; i < num_papers; i++) {
          html += '<li><a href="/publications/' + data[i][0] + '">'+ data[i][1] +'</a></li>';
        }
        $("#relwork").append(html);
      }).fail(function() {
        console.error("Failed to load related work metadata.");
      });
    });
  </script>

</div>

    </div>

  </body>
</html>
