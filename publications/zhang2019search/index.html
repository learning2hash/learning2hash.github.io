<!DOCTYPE html>
<html lang="en-us">

  <!-- _includes/head.html -->
<head>
  <!-- begin code v 7.0 -->
  <span id="wts2185304"></span>
  <script>
  var wts7 = {};
  wts7.invisible='';
  wts7.page_name='';
  wts7.group_name='';
  wts7.conversion_number='';
  wts7.user_id='';
  var wts=document.createElement('script');wts.async=true;
  wts.src='https://app.ardalio.com/wts7.js';document.head.appendChild(wts);
  wts.onload = function(){ wtsl7(2185304,4); };
  </script><noscript><img src="https://app.ardalio.com/7/4/2185304.png"></noscript>
  <!-- end code v 7.0 -->
  <!-- MathJax -->
  <script>
    window.MathJax = {
      tex: { inlineMath: [["\\(","\\)"]], displayMath: [["\\[","\\]"]] },
      options: { processHtmlClass: "mathjax-content", processEscapes: true }
    };
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <link href="https://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta charset="utf-8">

  <!-- Viewport -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- ✅ Manual SEO keywords (specific to Learning to Hash) -->
  <meta name="keywords" content="learning to hash, machine learning, hashing, approximate nearest neighbour search, ANN, LSH, locality sensitive hashing, vector quantization, deep hashing, binary embeddings, information retrieval, similarity search">

  <!-- ✅ Jekyll SEO plugin (title, description, canonical, OG/Twitter, JSON-LD) -->
  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Search Efficient Binary Network Embedding | Awesome Learning to Hash</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="Search Efficient Binary Network Embedding" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Traditional network embedding primarily focuses on learning a continuous vector representation for each node, preserving network structure and/or node content information, such that off-the-shelf machine learning algorithms can be easily applied to the vector-format node representations for network analysis. However, the learned continuous vector representations are inefficient for large-scale similarity search, which often involves finding nearest neighbors measured by distance or similarity in a continuous vector space. In this paper, we propose a search efficient binary network embedding algorithm called BinaryNE to learn a binary code for each node, by simultaneously modeling node context relations and node attribute relations through a three-layer neural network. BinaryNE learns binary node representations through a stochastic gradient descent based online learning algorithm. The learned binary encoding not only reduces memory usage to represent each node, but also allows fast bit-wise comparisons to support faster node similarity search than using Euclidean distance or other distance measures. Extensive experiments and comparisons demonstrate that BinaryNE not only delivers more than 25 times faster search speed, but also provides comparable or better search quality than traditional continuous vector based network embedding methods. The binary codes learned by BinaryNE also render competitive performance on node classification and node clustering tasks. The source code of this paper is available at https://github.com/daokunzhang/BinaryNE." />
<meta property="og:description" content="Traditional network embedding primarily focuses on learning a continuous vector representation for each node, preserving network structure and/or node content information, such that off-the-shelf machine learning algorithms can be easily applied to the vector-format node representations for network analysis. However, the learned continuous vector representations are inefficient for large-scale similarity search, which often involves finding nearest neighbors measured by distance or similarity in a continuous vector space. In this paper, we propose a search efficient binary network embedding algorithm called BinaryNE to learn a binary code for each node, by simultaneously modeling node context relations and node attribute relations through a three-layer neural network. BinaryNE learns binary node representations through a stochastic gradient descent based online learning algorithm. The learned binary encoding not only reduces memory usage to represent each node, but also allows fast bit-wise comparisons to support faster node similarity search than using Euclidean distance or other distance measures. Extensive experiments and comparisons demonstrate that BinaryNE not only delivers more than 25 times faster search speed, but also provides comparable or better search quality than traditional continuous vector based network embedding methods. The binary codes learned by BinaryNE also render competitive performance on node classification and node clustering tasks. The source code of this paper is available at https://github.com/daokunzhang/BinaryNE." />
<link rel="canonical" href="https://learning2hash.github.io/publications/zhang2019search/" />
<meta property="og:url" content="https://learning2hash.github.io/publications/zhang2019search/" />
<meta property="og:site_name" content="Awesome Learning to Hash" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-08-20T08:58:27-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Search Efficient Binary Network Embedding" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-08-20T08:58:27-05:00","datePublished":"2025-08-20T08:58:27-05:00","description":"Traditional network embedding primarily focuses on learning a continuous vector representation for each node, preserving network structure and/or node content information, such that off-the-shelf machine learning algorithms can be easily applied to the vector-format node representations for network analysis. However, the learned continuous vector representations are inefficient for large-scale similarity search, which often involves finding nearest neighbors measured by distance or similarity in a continuous vector space. In this paper, we propose a search efficient binary network embedding algorithm called BinaryNE to learn a binary code for each node, by simultaneously modeling node context relations and node attribute relations through a three-layer neural network. BinaryNE learns binary node representations through a stochastic gradient descent based online learning algorithm. The learned binary encoding not only reduces memory usage to represent each node, but also allows fast bit-wise comparisons to support faster node similarity search than using Euclidean distance or other distance measures. Extensive experiments and comparisons demonstrate that BinaryNE not only delivers more than 25 times faster search speed, but also provides comparable or better search quality than traditional continuous vector based network embedding methods. The binary codes learned by BinaryNE also render competitive performance on node classification and node clustering tasks. The source code of this paper is available at https://github.com/daokunzhang/BinaryNE.","headline":"Search Efficient Binary Network Embedding","mainEntityOfPage":{"@type":"WebPage","@id":"https://learning2hash.github.io/publications/zhang2019search/"},"url":"https://learning2hash.github.io/publications/zhang2019search/"}</script>
<!-- End Jekyll SEO tag -->


  <!-- Site CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="shortcut icon" href="/public/favicon.svg">
  <link rel="search" href="/public/opensearchdescription.xml" type="application/opensearchdescription+xml" title="learning2hash" />

  <!-- ✅ Single, modern jQuery + DataTables -->
  <link rel="stylesheet" href="https://cdn.datatables.net/1.13.6/css/jquery.dataTables.min.css">
  <script src="https://code.jquery.com/jquery-3.7.0.min.js" defer></script>
  <script src="https://cdn.datatables.net/1.13.6/js/jquery.dataTables.min.js" defer></script>

  <!-- Optional sanity log -->
  <script defer>
    window.addEventListener('DOMContentLoaded', () => {
      console.log('jQuery:', jQuery?.fn?.jquery);
      console.log('DataTables loaded:', !!jQuery?.fn?.dataTable);
    });
  </script>
</head>


  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

  <body class="theme-base-0c layout-reverse">

    <a href='/contributing.html' class='ribbon'>Add your paper to Learning2Hash</a>
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Awesome Learning to Hash
        </a>
      </h1>
      <p class="lead">A Webpage dedicated to the latest research on Hash Function Learning. Maintained by <a href="http://sjmoran.github.io/">Sean Moran</a>.</p>
    </div>

    <nav class="sidebar-nav">
      <div class="sidebar-item">
        <p style="font-size: 12px">
          Search related work 
          <input type='text' id='searchTarget' size="16"/> 
          <button onClick="search();">Go</button>
        </p>
      </div>
      <a class="sidebar-nav-item" href="/papers.html">All Papers</a>
      <a class="sidebar-nav-item" href="/tags.html">Papers by Tag</a>
      <a class="sidebar-nav-item" href="/tsne-viz.html">2D Map of Papers</a>
      <a class="sidebar-nav-item" href="/topic-viz.html">Topic Explorer</a>
      <a class="sidebar-nav-item" href="/author-viz.html">Author Explorer </a>
      <a class="sidebar-nav-item" href="/opensource.html">Tools Explorer </a>
      <a class="sidebar-nav-item" href="/tutorial.html">Tutorial</a>
      <a class="sidebar-nav-item" href="/resources.html">Resources, Courses &#38; Events</a>
      <a class="sidebar-nav-item" href="/contributing.html">Contributing</a>
    </nav>

    <div class="sidebar-item">
      <p style="font-size: 12px">
        Contact <a href="http://www.seanjmoran.com">Sean Moran</a> about this survey or website.
        <span style="font-size: 9px">
          Made with <a href="https://jekyllrb.com">Jekyll</a> and <a href="https://github.com/poole/hyde">Hyde</a>.
        </span>
      </p>
    </div>
  </div>
</div>

<script defer>
document.addEventListener('DOMContentLoaded', function () {
  function doSearch() {
    const el = document.getElementById('searchTarget');
    if (!el) return;
    const q = el.value.trim();
    try { if (typeof ga === 'function') ga('send', 'event', 'search', 'search', q); } catch(e) {}
    window.location = "/papers.html#" + encodeURIComponent(q);
  }

  // jQuery path if loaded
  if (window.jQuery) {
    $('#searchTarget').on('keydown', function (e) {
      if (e.key === 'Enter') doSearch();
    });
    document.querySelector('.sidebar-item button')?.addEventListener('click', doSearch);
  } else {
    // vanilla fallback
    const input = document.getElementById('searchTarget');
    const btn = document.querySelector('.sidebar-item button');
    if (input) {
      input.addEventListener('keydown', function (e) {
        if (e.key === 'Enter') doSearch();
      });
    }
    if (btn) btn.addEventListener('click', doSearch);
  }

  // keep global for inline onClick="search()"
  window.search = doSearch;
});
</script>


    <div class="content container">
      <div class="page">
  <h1 class="page-title">Search Efficient Binary Network Embedding</h1>
  <h5>
  
    
      Daokun Zhang, Jie Yin, Xingquan Zhu, Chengqi Zhang
    
  
  . ACM Transactions on Knowledge Discovery from Data
   2021
  
    – <span>2 citations</span>
  
  </h5>
  <p>
    
      [<a href="https://arxiv.org/abs/1901.04097" target="_blank">Paper</a>]
    
    &nbsp;<a href='http://scholar.google.com/scholar?q=Search Efficient Binary Network Embedding' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
    &nbsp;<a href='https://www.semanticscholar.org/search?q=Search Efficient Binary Network Embedding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
    <br/>
    
      <tag><a href="/tags.html#Hashing Methods">Hashing Methods</a></tag>
    
      <tag><a href="/tags.html#Compact Codes">Compact Codes</a></tag>
    
      <tag><a href="/tags.html#Scalability">Scalability</a></tag>
    
      <tag><a href="/tags.html#Distance Metric Learning">Distance Metric Learning</a></tag>
    
      <tag><a href="/tags.html#Memory Efficiency">Memory Efficiency</a></tag>
    
      <tag><a href="/tags.html#Similarity Search">Similarity Search</a></tag>
    
      <tag><a href="/tags.html#Evaluation">Evaluation</a></tag>
    
  </p>
  <p><p>Traditional network embedding primarily focuses on learning a continuous
vector representation for each node, preserving network structure and/or node
content information, such that off-the-shelf machine learning algorithms can be
easily applied to the vector-format node representations for network analysis.
However, the learned continuous vector representations are inefficient for
large-scale similarity search, which often involves finding nearest neighbors
measured by distance or similarity in a continuous vector space. In this paper,
we propose a search efficient binary network embedding algorithm called
BinaryNE to learn a binary code for each node, by simultaneously modeling node
context relations and node attribute relations through a three-layer neural
network. BinaryNE learns binary node representations through a stochastic
gradient descent based online learning algorithm. The learned binary encoding
not only reduces memory usage to represent each node, but also allows fast
bit-wise comparisons to support faster node similarity search than using
Euclidean distance or other distance measures. Extensive experiments and
comparisons demonstrate that BinaryNE not only delivers more than 25 times
faster search speed, but also provides comparable or better search quality than
traditional continuous vector based network embedding methods. The binary codes
learned by BinaryNE also render competitive performance on node classification
and node clustering tasks. The source code of this paper is available at
https://github.com/daokunzhang/BinaryNE.</p>
</p>

  <h6>Similar Work</h6>
  <p>
    <ul id="relwork">

    </ul>
  </p>

 <script>  
    $(document).ready(
      function() {
        $.getJSON("/publications-metadata/zhang2019search.json", function(data) {
          num_papers = data.length;
          html = "";
          for (let i=0; i < num_papers; i++) {
              html += '<li><a href="/publications/' + data[i][0] + '">'+ data[i][1] +'</a></li>'
          }
          $("#relwork").append(html);
        });
      });
  </script>


</div>

    </div>

  </body>
</html>
