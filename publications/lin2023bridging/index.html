<!DOCTYPE html>
<html lang="en-us">

  <head>
<!-- Begin Web-Stat code v 7.0 -->
<span id="wts2185304"></span>
<script>var wts=document.createElement('script');wts.async=true;
wts.src='https://app.ardalio.com/log7.js';document.head.appendChild(wts);
wts.onload = function(){ wtslog7(2185304,4); };
</script><noscript><a href="https://www.web-stat.com">
<img src="https://app.ardalio.com/7/4/2185304.png" 
alt="Web-Stat web statistics"></a></noscript>
<!-- End Web-Stat code v 7.0 -->
  <!-- Hotjar Tracking Code for https://learning2hash.github.io/ -->
<script>
    (function(h,o,t,j,a,r){
        h.hj=h.hj||function(){(h.hj.q=h.hj.q||[]).push(arguments)};
        h._hjSettings={hjid:1843243,hjsv:6};
        a=o.getElementsByTagName('head')[0];
        r=o.createElement('script');r.async=1;
        r.src=t+h._hjSettings.hjid+j+h._hjSettings.hjsv;
        a.appendChild(r);
    })(window,document,'https://static.hotjar.com/c/hotjar-','.js?sv=');
</script><!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-109544763-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-109544763-1');
</script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [["\\(","\\)"]],
        displayMath: [["\\[","\\]"]]
      }
    });
  </script>
  <script type="text/javascript" async
    src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="keywords" content="machine learning, hashing, approximate nearest neighbour search, lsh, learning-to-hash">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Bridging Items And Language A Transition Paradigm For Large Language Model-based Recommendation | Awesome Learning to Hash</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="Bridging Items And Language A Transition Paradigm For Large Language Model-based Recommendation" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Harnessing Large Language Models (LLMs) for recommendation is rapidly emerging which relies on two fundamental steps to bridge the recommendation item space and the language space 1) item indexing utilizes identifiers to represent items in the language space and 2) generation grounding associates LLMs generated token sequences to in-corpus items. However previous methods exhibit inherent limitations in the two steps. Existing ID-based identifiers (e.g. numeric IDs) and description-based identifiers (e.g. titles) either lose semantics or lack adequate distinctiveness. Moreover prior generation grounding methods might generate invalid identifiers thus misaligning with in-corpus items. To address these issues we propose a novel Transition paradigm for LLM-based Recommender (named TransRec) to bridge items and language. Specifically TransRec presents multi-facet identifiers which simultaneously incorporate ID title and attribute for item indexing to pursue both distinctiveness and semantics. Additionally we introduce a specialized data structure for TransRec to ensure generating valid identifiers only and utilize substring indexing to encourage LLMs to generate from any position of identifiers. Lastly TransRec presents an aggregated grounding module to leverage generated multi-facet identifiers to rank in-corpus items efficiently. We instantiate TransRec on two backbone models BART-large and LLaMA-7B. Extensive results on three real-world datasets under diverse settings validate the superiority of TransRec." />
<meta property="og:description" content="Harnessing Large Language Models (LLMs) for recommendation is rapidly emerging which relies on two fundamental steps to bridge the recommendation item space and the language space 1) item indexing utilizes identifiers to represent items in the language space and 2) generation grounding associates LLMs generated token sequences to in-corpus items. However previous methods exhibit inherent limitations in the two steps. Existing ID-based identifiers (e.g. numeric IDs) and description-based identifiers (e.g. titles) either lose semantics or lack adequate distinctiveness. Moreover prior generation grounding methods might generate invalid identifiers thus misaligning with in-corpus items. To address these issues we propose a novel Transition paradigm for LLM-based Recommender (named TransRec) to bridge items and language. Specifically TransRec presents multi-facet identifiers which simultaneously incorporate ID title and attribute for item indexing to pursue both distinctiveness and semantics. Additionally we introduce a specialized data structure for TransRec to ensure generating valid identifiers only and utilize substring indexing to encourage LLMs to generate from any position of identifiers. Lastly TransRec presents an aggregated grounding module to leverage generated multi-facet identifiers to rank in-corpus items efficiently. We instantiate TransRec on two backbone models BART-large and LLaMA-7B. Extensive results on three real-world datasets under diverse settings validate the superiority of TransRec." />
<link rel="canonical" href="https://learning2hash.github.io/publications/lin2023bridging/" />
<meta property="og:url" content="https://learning2hash.github.io/publications/lin2023bridging/" />
<meta property="og:site_name" content="Awesome Learning to Hash" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-10-09T06:33:00-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Bridging Items And Language A Transition Paradigm For Large Language Model-based Recommendation" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2024-10-09T06:33:00-05:00","datePublished":"2024-10-09T06:33:00-05:00","description":"Harnessing Large Language Models (LLMs) for recommendation is rapidly emerging which relies on two fundamental steps to bridge the recommendation item space and the language space 1) item indexing utilizes identifiers to represent items in the language space and 2) generation grounding associates LLMs generated token sequences to in-corpus items. However previous methods exhibit inherent limitations in the two steps. Existing ID-based identifiers (e.g. numeric IDs) and description-based identifiers (e.g. titles) either lose semantics or lack adequate distinctiveness. Moreover prior generation grounding methods might generate invalid identifiers thus misaligning with in-corpus items. To address these issues we propose a novel Transition paradigm for LLM-based Recommender (named TransRec) to bridge items and language. Specifically TransRec presents multi-facet identifiers which simultaneously incorporate ID title and attribute for item indexing to pursue both distinctiveness and semantics. Additionally we introduce a specialized data structure for TransRec to ensure generating valid identifiers only and utilize substring indexing to encourage LLMs to generate from any position of identifiers. Lastly TransRec presents an aggregated grounding module to leverage generated multi-facet identifiers to rank in-corpus items efficiently. We instantiate TransRec on two backbone models BART-large and LLaMA-7B. Extensive results on three real-world datasets under diverse settings validate the superiority of TransRec.","headline":"Bridging Items And Language A Transition Paradigm For Large Language Model-based Recommendation","mainEntityOfPage":{"@type":"WebPage","@id":"https://learning2hash.github.io/publications/lin2023bridging/"},"url":"https://learning2hash.github.io/publications/lin2023bridging/"}</script>
<!-- End Jekyll SEO tag -->


  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="shortcut icon" href="/public/favicon.svg">
  <link rel="search" href="/public/opensearchdescription.xml" 
      type="application/opensearchdescription+xml" 
      title="learning2hash" />

  <script src="https://code.jquery.com/jquery-3.2.1.min.js"
  integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
  crossorigin="anonymous"></script>
  
  <link rel="stylesheet" type="text/css" href="//cdn.datatables.net/1.10.16/css/jquery.dataTables.min.css">
  <script type="text/javascript" charset="utf8" src="//cdn.datatables.net/1.10.16/js/jquery.dataTables.min.js"></script>
</head>


  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

  <body class="theme-base-0c layout-reverse">

    <a href='/contributing.html' class='ribbon'>Add your paper to Learning2Hash</a>
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Awesome Learning to Hash
        </a>
      </h1>
      <p class="lead">A Webpage dedicated to the latest research on Hash Function Learning. Maintained by <a href="http://sjmoran.github.io/">Sean Moran</a>.</p>
    </div>

    <nav class="sidebar-nav">
      <div class="sidebar-item">
        <p style="font-size: 12px">
          Search related work 
          <input type='text' id='searchTarget' size="16"/> 
          <button onClick="search();">Go</button>
        </p>
      </div>
      <a class="sidebar-nav-item" href="/papers.html">All Papers</a>
      <a class="sidebar-nav-item" href="/tags.html">Papers by Tag</a>
      <a class="sidebar-nav-item" href="/tsne-viz.html">2D Map of Papers</a>
      <a class="sidebar-nav-item" href="/topic-viz.html">Topic-based Explorer</a>
      <a class="sidebar-nav-item" href="/base-taxonomy/">Core Taxonomy</a>
      <a class="sidebar-nav-item" href="/base-taxonomy/datasets.html">Datasets</a>
      <a class="sidebar-nav-item" href="/tutorial.html">Tutorial</a>
      <a class="sidebar-nav-item" href="/resources.html">Resources, Courses &#38; Events</a>
      <a class="sidebar-nav-item" href="/contributing.html">Contributing</a>
    </nav>

    <div class="sidebar-item">
      <p style="font-size: 12px">
        Contact <a href="http://www.seanjmoran.com">Sean Moran</a> about this survey or website.
        <span style="font-size: 9px">
          Made with <a href="https://jekyllrb.com">Jekyll</a> and <a href="https://github.com/poole/hyde">Hyde</a>.
        </span>
      </p>
    </div>
  </div>
</div>

<script>
$("#searchTarget").keydown(function (e) {	
  if (e.keyCode == 13) {
    search();
  }
});

function search() {
  try {
    ga('send', 'event', 'search', 'search', $("#searchTarget").val());
  } finally {
    window.location = "/papers.html#" + $("#searchTarget").val();
  }
}
</script>


    <div class="content container">
      <div class="page">
  <h1 class="page-title">Bridging Items And Language A Transition Paradigm For Large Language Model-based Recommendation</h1>
  <h5>Xinyu Lin, Wenjie Wang, Yongqi Li, Fuli Feng, See-kiong Ng, Tat-seng Chua. Arxiv 2023</h5>
  <p>
    
      [<a href="https://arxiv.org/abs/http://arxiv.org/abs/2310.06491v2" target="_blank">Paper</a>]
    
    &nbsp;<a href='http://scholar.google.com/scholar?q=Bridging Items And Language A Transition Paradigm For Large Language Model-based Recommendation' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
    &nbsp;<a href='https://www.semanticscholar.org/search?q=Bridging Items And Language A Transition Paradigm For Large Language Model-based Recommendation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
    <br/>
    
      <tag><a href="/tags.html#ARXIV">ARXIV</a></tag>
    
  </p>
  <p><p>Harnessing Large Language Models (LLMs) for recommendation is rapidly emerging which relies on two fundamental steps to bridge the recommendation item space and the language space 1) item indexing utilizes identifiers to represent items in the language space and 2) generation grounding associates LLMs generated token sequences to in-corpus items. However previous methods exhibit inherent limitations in the two steps. Existing ID-based identifiers (e.g. numeric IDs) and description-based identifiers (e.g. titles) either lose semantics or lack adequate distinctiveness. Moreover prior generation grounding methods might generate invalid identifiers thus misaligning with in-corpus items. To address these issues we propose a novel Transition paradigm for LLM-based Recommender (named TransRec) to bridge items and language. Specifically TransRec presents multi-facet identifiers which simultaneously incorporate ID title and attribute for item indexing to pursue both distinctiveness and semantics. Additionally we introduce a specialized data structure for TransRec to ensure generating valid identifiers only and utilize substring indexing to encourage LLMs to generate from any position of identifiers. Lastly TransRec presents an aggregated grounding module to leverage generated multi-facet identifiers to rank in-corpus items efficiently. We instantiate TransRec on two backbone models BART-large and LLaMA-7B. Extensive results on three real-world datasets under diverse settings validate the superiority of TransRec.</p>
</p>

  <h6>Similar Work</h6>
  <p>
    <ul id="relwork">

    </ul>
  </p>

  <script>  
    $(document).ready(
      function() {
        $.getJSON("/publications-metadata/lin2023bridging.json", function(data) {
          num_papers = data.length;
          html = "";
          for (let i=0; i < num_papers; i++) {
              html += '<li><a href="/publications/' + data[i][0] + '">'+ data[i][1] +'</a></li>'
          }
          $("#relwork").append(html);
        });
      });
  </script>

</div>

    </div>

  </body>
</html>
