<!DOCTYPE html>
<html lang="en-us">

  <head>
<!-- Begin Web-Stat code v 7.0 -->
<span id="wts2185304"></span>
<script>var wts=document.createElement('script');wts.async=true;
wts.src='https://app.ardalio.com/log7.js';document.head.appendChild(wts);
wts.onload = function(){ wtslog7(2185304,4); };
</script><noscript><a href="https://www.web-stat.com">
<img src="https://app.ardalio.com/7/4/2185304.png" 
alt="Web-Stat web statistics"></a></noscript>
<!-- End Web-Stat code v 7.0 -->
  <!-- Hotjar Tracking Code for https://learning2hash.github.io/ -->
<script>
    (function(h,o,t,j,a,r){
        h.hj=h.hj||function(){(h.hj.q=h.hj.q||[]).push(arguments)};
        h._hjSettings={hjid:1843243,hjsv:6};
        a=o.getElementsByTagName('head')[0];
        r=o.createElement('script');r.async=1;
        r.src=t+h._hjSettings.hjid+j+h._hjSettings.hjsv;
        a.appendChild(r);
    })(window,document,'https://static.hotjar.com/c/hotjar-','.js?sv=');
</script><!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-109544763-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-109544763-1');
</script>
<script>
    window.MathJax = {
      tex: {
        inlineMath: [["\\(","\\)"]],
        displayMath: [["\\[","\\]"]],
      },
      options: {
        processHtmlClass: "mathjax-content",
        processEscapes: true,
      }
    };
  </script>
  <script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="keywords" content="machine learning, hashing, approximate nearest neighbour search, lsh, learning-to-hash">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Hashing Embeddings Of Optimal Dimension, With Applications To Linear Least Squares | Awesome Learning to Hash</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="Hashing Embeddings Of Optimal Dimension, With Applications To Linear Least Squares" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The aim of this paper is two-fold: firstly, to present subspace embedding properties for \(s\)-hashing sketching matrices, with \(s\geq 1\), that are optimal in the projection dimension \(m\) of the sketch, namely, \(m=\mathcal{O}(d)\), where \(d\) is the dimension of the subspace. A diverse set of results are presented that address the case when the input matrix has sufficiently low coherence (thus removing the \(log^2 d\) factor dependence in \(m\), in the low-coherence result of Bourgain et al (2015) at the expense of a smaller coherence requirement); how this coherence changes with the number \(s\) of column nonzeros (allowing a scaling of \(\sqrt{s}\) of the coherence bound), or is reduced through suitable transformations (when considering hashed – instead of subsampled – coherence reducing transformations such as randomised Hadamard). Secondly, we apply these general hashing sketching results to the special case of Linear Least Squares (LLS), and develop Ski-LLS, a generic software package for these problems, that builds upon and improves the Blendenpik solver on dense input and the (sequential) LSRN performance on sparse problems. In addition to the hashing sketching improvements, we add suitable linear algebra tools for rank-deficient and for sparse problems that lead Ski-LLS to outperform not only sketching-based routines on randomly generated input, but also state of the art direct solver SPQR and iterative code HSL on certain subsets of the sparse Florida matrix collection; namely, on least squares problems that are significantly overdetermined, or moderately sparse, or difficult." />
<meta property="og:description" content="The aim of this paper is two-fold: firstly, to present subspace embedding properties for \(s\)-hashing sketching matrices, with \(s\geq 1\), that are optimal in the projection dimension \(m\) of the sketch, namely, \(m=\mathcal{O}(d)\), where \(d\) is the dimension of the subspace. A diverse set of results are presented that address the case when the input matrix has sufficiently low coherence (thus removing the \(log^2 d\) factor dependence in \(m\), in the low-coherence result of Bourgain et al (2015) at the expense of a smaller coherence requirement); how this coherence changes with the number \(s\) of column nonzeros (allowing a scaling of \(\sqrt{s}\) of the coherence bound), or is reduced through suitable transformations (when considering hashed – instead of subsampled – coherence reducing transformations such as randomised Hadamard). Secondly, we apply these general hashing sketching results to the special case of Linear Least Squares (LLS), and develop Ski-LLS, a generic software package for these problems, that builds upon and improves the Blendenpik solver on dense input and the (sequential) LSRN performance on sparse problems. In addition to the hashing sketching improvements, we add suitable linear algebra tools for rank-deficient and for sparse problems that lead Ski-LLS to outperform not only sketching-based routines on randomly generated input, but also state of the art direct solver SPQR and iterative code HSL on certain subsets of the sparse Florida matrix collection; namely, on least squares problems that are significantly overdetermined, or moderately sparse, or difficult." />
<link rel="canonical" href="https://learning2hash.github.io/publications/cartis2021hashing/" />
<meta property="og:url" content="https://learning2hash.github.io/publications/cartis2021hashing/" />
<meta property="og:site_name" content="Awesome Learning to Hash" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-06-18T11:30:54-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Hashing Embeddings Of Optimal Dimension, With Applications To Linear Least Squares" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-06-18T11:30:54-05:00","datePublished":"2025-06-18T11:30:54-05:00","description":"The aim of this paper is two-fold: firstly, to present subspace embedding properties for \\(s\\)-hashing sketching matrices, with \\(s\\geq 1\\), that are optimal in the projection dimension \\(m\\) of the sketch, namely, \\(m=\\mathcal{O}(d)\\), where \\(d\\) is the dimension of the subspace. A diverse set of results are presented that address the case when the input matrix has sufficiently low coherence (thus removing the \\(log^2 d\\) factor dependence in \\(m\\), in the low-coherence result of Bourgain et al (2015) at the expense of a smaller coherence requirement); how this coherence changes with the number \\(s\\) of column nonzeros (allowing a scaling of \\(\\sqrt{s}\\) of the coherence bound), or is reduced through suitable transformations (when considering hashed – instead of subsampled – coherence reducing transformations such as randomised Hadamard). Secondly, we apply these general hashing sketching results to the special case of Linear Least Squares (LLS), and develop Ski-LLS, a generic software package for these problems, that builds upon and improves the Blendenpik solver on dense input and the (sequential) LSRN performance on sparse problems. In addition to the hashing sketching improvements, we add suitable linear algebra tools for rank-deficient and for sparse problems that lead Ski-LLS to outperform not only sketching-based routines on randomly generated input, but also state of the art direct solver SPQR and iterative code HSL on certain subsets of the sparse Florida matrix collection; namely, on least squares problems that are significantly overdetermined, or moderately sparse, or difficult.","headline":"Hashing Embeddings Of Optimal Dimension, With Applications To Linear Least Squares","mainEntityOfPage":{"@type":"WebPage","@id":"https://learning2hash.github.io/publications/cartis2021hashing/"},"url":"https://learning2hash.github.io/publications/cartis2021hashing/"}</script>
<!-- End Jekyll SEO tag -->


  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="shortcut icon" href="/public/favicon.svg">
  <link rel="search" href="/public/opensearchdescription.xml" 
      type="application/opensearchdescription+xml" 
      title="learning2hash" />

  <script src="https://code.jquery.com/jquery-3.2.1.min.js"
  integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
  crossorigin="anonymous"></script>
  
  <link rel="stylesheet" type="text/css" href="//cdn.datatables.net/1.10.16/css/jquery.dataTables.min.css">
  <script type="text/javascript" charset="utf8" src="//cdn.datatables.net/1.10.16/js/jquery.dataTables.min.js"></script>
</head>


  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

  <body class="theme-base-0c layout-reverse">

    <a href='/contributing.html' class='ribbon'>Add your paper to Learning2Hash</a>
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Awesome Learning to Hash
        </a>
      </h1>
      <p class="lead">A Webpage dedicated to the latest research on Hash Function Learning. Maintained by <a href="http://sjmoran.github.io/">Sean Moran</a>.</p>
    </div>

    <nav class="sidebar-nav">
      <div class="sidebar-item">
        <p style="font-size: 12px">
          Search related work 
          <input type='text' id='searchTarget' size="16"/> 
          <button onClick="search();">Go</button>
        </p>
      </div>
      <a class="sidebar-nav-item" href="/papers.html">All Papers</a>
      <a class="sidebar-nav-item" href="/tags.html">Papers by Tag</a>
      <a class="sidebar-nav-item" href="/tsne-viz.html">2D Map of Papers</a>
      <a class="sidebar-nav-item" href="/topic-viz.html">Topic-based Explorer</a>
      <a class="sidebar-nav-item" href="/tutorial.html">Tutorial</a>
      <a class="sidebar-nav-item" href="/resources.html">Resources, Courses &#38; Events</a>
      <a class="sidebar-nav-item" href="/contributing.html">Contributing</a>
    </nav>

    <div class="sidebar-item">
      <p style="font-size: 12px">
        Contact <a href="http://www.seanjmoran.com">Sean Moran</a> about this survey or website.
        <span style="font-size: 9px">
          Made with <a href="https://jekyllrb.com">Jekyll</a> and <a href="https://github.com/poole/hyde">Hyde</a>.
        </span>
      </p>
    </div>
  </div>
</div>

<script>
$("#searchTarget").keydown(function (e) {	
  if (e.keyCode == 13) {
    search();
  }
});

function search() {
  try {
    ga('send', 'event', 'search', 'search', $("#searchTarget").val());
  } finally {
    window.location = "/papers.html#" + $("#searchTarget").val();
  }
}
</script>


    <div class="content container">
      <div class="page mathjax-content">
  <h1 class="page-title">Hashing Embeddings Of Optimal Dimension, With Applications To Linear Least Squares</h1>
  <h5>Coralia Cartis, Jan Fiala, Zhen Shao. Arxiv 2021</h5>
  
  <p>
    
      [<a href="https://arxiv.org/abs/2105.11815" target="_blank">Paper</a>]
    
    &nbsp;<a href='http://scholar.google.com/scholar?q=Hashing%20Embeddings%20Of%20Optimal%20Dimension,%20With%20Applications%20To%20Linear%20Least%20Squares' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
    &nbsp;<a href='https://www.semanticscholar.org/search?q=Hashing%20Embeddings%20Of%20Optimal%20Dimension,%20With%20Applications%20To%20Linear%20Least%20Squares' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
    <br/>
    
      <span class="tag"><a href="/tags.html#Hashing Methods">Hashing Methods</a></span>
    
      <span class="tag"><a href="/tags.html#Applications">Applications</a></span>
    
  </p>
  
  <p><p>The aim of this paper is two-fold: firstly, to present subspace embedding
properties for \(s\)-hashing sketching matrices, with \(s\geq 1\), that are optimal
in the projection dimension \(m\) of the sketch, namely, \(m=\mathcal{O}(d)\),
where \(d\) is the dimension of the subspace. A diverse set of results are
presented that address the case when the input matrix has sufficiently low
coherence (thus removing the \(log^2 d\) factor dependence in \(m\), in the
low-coherence result of Bourgain et al (2015) at the expense of a smaller
coherence requirement); how this coherence changes with the number \(s\) of
column nonzeros (allowing a scaling of \(\sqrt{s}\) of the coherence bound), or
is reduced through suitable transformations (when considering hashed – instead
of subsampled – coherence reducing transformations such as randomised
Hadamard). Secondly, we apply these general hashing sketching results to the
special case of Linear Least Squares (LLS), and develop Ski-LLS, a generic
software package for these problems, that builds upon and improves the
Blendenpik solver on dense input and the (sequential) LSRN performance on
sparse problems. In addition to the hashing sketching improvements, we add
suitable linear algebra tools for rank-deficient and for sparse problems that
lead Ski-LLS to outperform not only sketching-based routines on randomly
generated input, but also state of the art direct solver SPQR and iterative
code HSL on certain subsets of the sparse Florida matrix collection; namely, on
least squares problems that are significantly overdetermined, or moderately
sparse, or difficult.</p>
</p>

  <h6>Similar Work</h6>
  <p>
    <ul id="relwork"></ul>
  </p>

  <script defer>
    $(document).ready(function() {
      $.getJSON("/publications-metadata/cartis2021hashing.json", function(data) {
        var num_papers = data.length;
        var html = "";
        for (var i = 0; i < num_papers; i++) {
          html += '<li><a href="/publications/' + data[i][0] + '">'+ data[i][1] +'</a></li>';
        }
        $("#relwork").append(html);
      }).fail(function() {
        console.error("Failed to load related work metadata.");
      });
    });
  </script>

</div>

    </div>

  </body>
</html>
