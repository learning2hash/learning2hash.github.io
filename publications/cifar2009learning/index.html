<!DOCTYPE html>
<html lang="en-us">

  <head>
  <!-- Hotjar Tracking Code for https://learning2hash.github.io/ -->
<script>
    (function(h,o,t,j,a,r){
        h.hj=h.hj||function(){(h.hj.q=h.hj.q||[]).push(arguments)};
        h._hjSettings={hjid:1843243,hjsv:6};
        a=o.getElementsByTagName('head')[0];
        r=o.createElement('script');r.async=1;
        r.src=t+h._hjSettings.hjid+j+h._hjSettings.hjsv;
        a.appendChild(r);
    })(window,document,'https://static.hotjar.com/c/hotjar-','.js?sv=');
</script><!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-109544763-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-109544763-1');
</script>

  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="keywords" content="machine learning, hashing, approximate nearest neighbour search, lsh, learning-to-hash">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Learning Multiple Layers of Features from Tiny Images | Awesome Learning to Hash</title>
<meta name="generator" content="Jekyll v4.1.0" />
<meta property="og:title" content="Learning Multiple Layers of Features from Tiny Images" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Groups at MIT and NYU have collected a dataset of millions of tiny colour images from the web. It is, in principle, an excellent dataset for unsupervised training of deep generative models, but previous researchers who have tried this have found it difficult to learn a good set of filters from the images. We show how to train a multi-layer generative model that learns to extract meaningful features which resemble those found in the human visual cortex. Using a novel parallelization algorithm to distribute the work among multiple machines connected on a network, we show how training such a model can be done in reasonable time. A second problematic aspect of the tiny images dataset is that there are no reliable class labels which makes it hard to use for object recognition experiments. We created two sets of reliable labels. The CIFAR-10 set has 6000 examples of each of 10 classes and the CIFAR-100 set has 600 examples of each of 100 non-overlapping classes. Using these labels, we show that object recognition is significantly improved by pre-training a layer of features on a large set of unlabeled tiny images." />
<meta property="og:description" content="Groups at MIT and NYU have collected a dataset of millions of tiny colour images from the web. It is, in principle, an excellent dataset for unsupervised training of deep generative models, but previous researchers who have tried this have found it difficult to learn a good set of filters from the images. We show how to train a multi-layer generative model that learns to extract meaningful features which resemble those found in the human visual cortex. Using a novel parallelization algorithm to distribute the work among multiple machines connected on a network, we show how training such a model can be done in reasonable time. A second problematic aspect of the tiny images dataset is that there are no reliable class labels which makes it hard to use for object recognition experiments. We created two sets of reliable labels. The CIFAR-10 set has 6000 examples of each of 10 classes and the CIFAR-100 set has 600 examples of each of 100 non-overlapping classes. Using these labels, we show that object recognition is significantly improved by pre-training a layer of features on a large set of unlabeled tiny images." />
<link rel="canonical" href="https://learning2hash.github.io/publications/cifar2009learning/" />
<meta property="og:url" content="https://learning2hash.github.io/publications/cifar2009learning/" />
<meta property="og:site_name" content="Awesome Learning to Hash" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-01-12T12:41:17-06:00" />
<script type="application/ld+json">
{"url":"https://learning2hash.github.io/publications/cifar2009learning/","headline":"Learning Multiple Layers of Features from Tiny Images","dateModified":"2021-01-12T12:41:17-06:00","datePublished":"2021-01-12T12:41:17-06:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://learning2hash.github.io/publications/cifar2009learning/"},"description":"Groups at MIT and NYU have collected a dataset of millions of tiny colour images from the web. It is, in principle, an excellent dataset for unsupervised training of deep generative models, but previous researchers who have tried this have found it difficult to learn a good set of filters from the images. We show how to train a multi-layer generative model that learns to extract meaningful features which resemble those found in the human visual cortex. Using a novel parallelization algorithm to distribute the work among multiple machines connected on a network, we show how training such a model can be done in reasonable time. A second problematic aspect of the tiny images dataset is that there are no reliable class labels which makes it hard to use for object recognition experiments. We created two sets of reliable labels. The CIFAR-10 set has 6000 examples of each of 10 classes and the CIFAR-100 set has 600 examples of each of 100 non-overlapping classes. Using these labels, we show that object recognition is significantly improved by pre-training a layer of features on a large set of unlabeled tiny images.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="shortcut icon" href="/public/favicon.svg">
  <link rel="search" href="/public/opensearchdescription.xml" 
      type="application/opensearchdescription+xml" 
      title="learning2hash" />

  <script src="https://code.jquery.com/jquery-3.2.1.min.js"
  integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
  crossorigin="anonymous"></script>
  
  <link rel="stylesheet" type="text/css" href="//cdn.datatables.net/1.10.16/css/jquery.dataTables.min.css">
  <script type="text/javascript" charset="utf8" src="//cdn.datatables.net/1.10.16/js/jquery.dataTables.min.js"></script>
</head>


  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

  <body class="theme-base-0c layout-reverse">

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Awesome Learning to Hash
        </a>
      </h1>
      <p class="lead">A webpage dedicated to the latest research on learning-to-hash, including state-of-the-art deep hashing models, all updated on a weekly basis. Maintained by <a href="http://sjmoran.github.io/">Sean Moran</a>.</p>
    </div>

  <nav class="sidebar-nav">
   <div class="sidebar-item"><p style="font-size: 12px">Search related work <input type='text' id='searchTarget' size="16"/> <button onClick="search();">Go</button></p></div>
    <a class="sidebar-nav-item" href="/papers.html">All Papers</a>
   <a class="sidebar-nav-item" href="/tags.html">Papers by Tag</a>
   <a class="sidebar-nav-item" href="/tsne-viz.html">2D Map of Papers</a>
   <a class="sidebar-nav-item" href="/base-taxonomy/">Core Taxonomy</a>
   <a class="sidebar-nav-item-small" href="/base-taxonomy/quantisation.html">Quantisation Models</a>
   <a class="sidebar-nav-item-small" href="/base-taxonomy/supervised.html">Supervised Projection Models</a>
   <a class="sidebar-nav-item-small" href="/base-taxonomy/unsupervised.html">Unsupervised Projection Models</a></ul>
   <a class="sidebar-nav-item-small" href="/base-taxonomy/independent.html">Data Independent Projection Models</a></ul>
  <a class="sidebar-nav-item" href="/base-taxonomy/datasets.html">Datasets</a>
  <a class="sidebar-nav-item" href="/resources.html">Resources, Courses &#38; Events</a>
  <a class="sidebar-nav-item" href="/tutorial.html">Tutorial</a>
  <a class="sidebar-nav-item" href="/contributing.html">Contributing</a>
  <a class="sidebar-nav-item" href="/contributors.html">Contributors</a>
   <a class="sidebar-nav-item" href="/cite.html">How to Cite this Site</a>

</nav>

  <div class="sidebar-item">
    <p style="font-size: 12px">Contact <a href="http://www.seanjmoran.com">Sean Moran</a> about this survey or website.
    <span style="font-size: 9px">
      Made with <a href="https://jekyllrb.com">Jekyll</a> and <a href="https://github.com/poole/hyde">Hyde</a>.
    </span></p>
  </div>
</div></div>

<script>
$("#searchTarget").keydown(function (e) {	
  if (e.keyCode == 13) {
    search();
  }
});
function search() {
  try {
    ga('send', 'event', 'search', 'search', $("#searchTarget").val());
  } finally {
    window.location = "/papers.html#" + $("#searchTarget").val();
  }
}
</script>


    <div class="content container">
      <div class="page">
  <h1 class="page-title">Learning Multiple Layers of Features from Tiny Images</h1>
  <h5>A. Krizhevsky. University of Toronto 2009</h5>
  <p>
    
      [<a href="https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf" target="_blank">PDF</a>]
    
      [<a href="https://www.cs.toronto.edu/~kriz/cifar.html" target="_blank">URL</a>]
    
      [<a href="https://www.dropbox.com/s/875u1rkva9iffpj/Gist512CIFAR10.mat?dl=0&m=" target="_blank">Features</a>]
    
    &nbsp;<a href='http://scholar.google.com/scholar?q=Learning Multiple Layers of Features from Tiny Images' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
    &nbsp;<a href='https://www.semanticscholar.org/search?q=Learning Multiple Layers of Features from Tiny Images' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
    &nbsp;<a href='http://academic.microsoft.com/#/search?iq=Learning%20Multiple%20Layers%20of%20Features%20from%20Tiny%20Images' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
  <br/>
  
      <tag><a href="/tags.html#Dataset">Dataset</a></tag>
    
      
</p>    
      
      <p><p>Groups at MIT and NYU have collected a dataset of millions of tiny colour images from the web. It
is, in principle, an excellent dataset for unsupervised training of deep generative models, but previous
researchers who have tried this have found it difficult to learn a good set of
filters from the images.
We show how to train a multi-layer generative model that learns to extract meaningful features which
resemble those found in the human visual cortex. Using a novel parallelization algorithm to distribute
the work among multiple machines connected on a network, we show how training such a model can be
done in reasonable time.
A second problematic aspect of the tiny images dataset is that there are no reliable class labels
which makes it hard to use for object recognition experiments. We created two sets of reliable labels.
The CIFAR-10 set has 6000 examples of each of 10 classes and the CIFAR-100 set has 600 examples of
each of 100 non-overlapping classes. Using these labels, we show that object recognition is significantly
improved by pre-training a layer of features on a large set of unlabeled tiny images.</p>
</p>
</div>

    </div>

  </body>
</html>
