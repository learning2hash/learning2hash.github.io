<!DOCTYPE html>
<html lang="en-us">

  <head>
<!-- Begin Web-Stat code v 7.0 -->
<span id="wts2185304"></span>
<script>var wts=document.createElement('script');wts.async=true;
wts.src='https://app.ardalio.com/log7.js';document.head.appendChild(wts);
wts.onload = function(){ wtslog7(2185304,4); };
</script><noscript><a href="https://www.web-stat.com">
<img src="https://app.ardalio.com/7/4/2185304.png" 
alt="Web-Stat web statistics"></a></noscript>
<!-- End Web-Stat code v 7.0 -->
  <!-- Hotjar Tracking Code for https://learning2hash.github.io/ -->
<script>
    (function(h,o,t,j,a,r){
        h.hj=h.hj||function(){(h.hj.q=h.hj.q||[]).push(arguments)};
        h._hjSettings={hjid:1843243,hjsv:6};
        a=o.getElementsByTagName('head')[0];
        r=o.createElement('script');r.async=1;
        r.src=t+h._hjSettings.hjid+j+h._hjSettings.hjsv;
        a.appendChild(r);
    })(window,document,'https://static.hotjar.com/c/hotjar-','.js?sv=');
</script><!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-109544763-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-109544763-1');
</script>

  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="keywords" content="machine learning, hashing, approximate nearest neighbour search, lsh, learning-to-hash">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>RREH Reconstruction Relations Embedded Hashing for Semi-Paired Cross-Modal Retrieval | Awesome Learning to Hash</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="RREH Reconstruction Relations Embedded Hashing for Semi-Paired Cross-Modal Retrieval" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Known for efficient computation and easy storage hashing has been extensively explored in cross-modal retrieval. The majority of current hashing models are predicated on the premise of a direct one-to-one mapping between data points. However in real practice data correspondence across modalities may be partially provided. In this research we introduce an innovative unsupervised hashing technique designed for semi-paired cross-modal retrieval tasks named Reconstruction Relations Embedded Hashing (RREH). RREH assumes that multi-modal data share a common subspace. For paired data RREH explores the latent consistent information of heterogeneous modalities by seeking a shared representation. For unpaired data to effectively capture the latent discriminative features the high-order relationships between unpaired data and anchors are embedded into the latent subspace which are computed by efficient linear reconstruction. The anchors are sampled from paired data which improves the efficiency of hash learning. The RREH trains the underlying features and the binary encodings in a unified framework with high-order reconstruction relations preserved. With the well devised objective function and discrete optimization algorithm RREH is designed to be scalable making it suitable for large-scale datasets and facilitating efficient cross-modal retrieval. In the evaluation process the proposed is tested with partially paired data to establish its superiority over several existing methods." />
<meta property="og:description" content="Known for efficient computation and easy storage hashing has been extensively explored in cross-modal retrieval. The majority of current hashing models are predicated on the premise of a direct one-to-one mapping between data points. However in real practice data correspondence across modalities may be partially provided. In this research we introduce an innovative unsupervised hashing technique designed for semi-paired cross-modal retrieval tasks named Reconstruction Relations Embedded Hashing (RREH). RREH assumes that multi-modal data share a common subspace. For paired data RREH explores the latent consistent information of heterogeneous modalities by seeking a shared representation. For unpaired data to effectively capture the latent discriminative features the high-order relationships between unpaired data and anchors are embedded into the latent subspace which are computed by efficient linear reconstruction. The anchors are sampled from paired data which improves the efficiency of hash learning. The RREH trains the underlying features and the binary encodings in a unified framework with high-order reconstruction relations preserved. With the well devised objective function and discrete optimization algorithm RREH is designed to be scalable making it suitable for large-scale datasets and facilitating efficient cross-modal retrieval. In the evaluation process the proposed is tested with partially paired data to establish its superiority over several existing methods." />
<link rel="canonical" href="https://learning2hash.github.io/publications/wang2024rreh/" />
<meta property="og:url" content="https://learning2hash.github.io/publications/wang2024rreh/" />
<meta property="og:site_name" content="Awesome Learning to Hash" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-09-21T13:25:49-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="RREH Reconstruction Relations Embedded Hashing for Semi-Paired Cross-Modal Retrieval" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2024-09-21T13:25:49-05:00","datePublished":"2024-09-21T13:25:49-05:00","description":"Known for efficient computation and easy storage hashing has been extensively explored in cross-modal retrieval. The majority of current hashing models are predicated on the premise of a direct one-to-one mapping between data points. However in real practice data correspondence across modalities may be partially provided. In this research we introduce an innovative unsupervised hashing technique designed for semi-paired cross-modal retrieval tasks named Reconstruction Relations Embedded Hashing (RREH). RREH assumes that multi-modal data share a common subspace. For paired data RREH explores the latent consistent information of heterogeneous modalities by seeking a shared representation. For unpaired data to effectively capture the latent discriminative features the high-order relationships between unpaired data and anchors are embedded into the latent subspace which are computed by efficient linear reconstruction. The anchors are sampled from paired data which improves the efficiency of hash learning. The RREH trains the underlying features and the binary encodings in a unified framework with high-order reconstruction relations preserved. With the well devised objective function and discrete optimization algorithm RREH is designed to be scalable making it suitable for large-scale datasets and facilitating efficient cross-modal retrieval. In the evaluation process the proposed is tested with partially paired data to establish its superiority over several existing methods.","headline":"RREH Reconstruction Relations Embedded Hashing for Semi-Paired Cross-Modal Retrieval","mainEntityOfPage":{"@type":"WebPage","@id":"https://learning2hash.github.io/publications/wang2024rreh/"},"url":"https://learning2hash.github.io/publications/wang2024rreh/"}</script>
<!-- End Jekyll SEO tag -->


  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="shortcut icon" href="/public/favicon.svg">
  <link rel="search" href="/public/opensearchdescription.xml" 
      type="application/opensearchdescription+xml" 
      title="learning2hash" />

  <script src="https://code.jquery.com/jquery-3.2.1.min.js"
  integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
  crossorigin="anonymous"></script>
  
  <link rel="stylesheet" type="text/css" href="//cdn.datatables.net/1.10.16/css/jquery.dataTables.min.css">
  <script type="text/javascript" charset="utf8" src="//cdn.datatables.net/1.10.16/js/jquery.dataTables.min.js"></script>
</head>


  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

  <body class="theme-base-0c layout-reverse">

    <a href='/contributing.html' class='ribbon'>Add your paper to Learning2Hash</a>
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Awesome Learning to Hash
        </a>
      </h1>
      <p class="lead">A Webpage dedicated to the latest research on Hash Function Learning. Maintained by <a href="http://sjmoran.github.io/">Sean Moran</a>.</p>
    </div>

    <nav class="sidebar-nav">
      <div class="sidebar-item">
        <p style="font-size: 12px">
          Search related work 
          <input type='text' id='searchTarget' size="16"/> 
          <button onClick="search();">Go</button>
        </p>
      </div>
      <a class="sidebar-nav-item" href="/papers.html">All Papers</a>
      <a class="sidebar-nav-item" href="/tags.html">Papers by Tag</a>
      <a class="sidebar-nav-item" href="/tsne-viz.html">2D Map of Papers</a>
      <a class="sidebar-nav-item" href="/topic-viz.html">Topic-based Explorer</a>
      <a class="sidebar-nav-item" href="/base-taxonomy/">Core Taxonomy</a>
      <a class="sidebar-nav-item" href="/base-taxonomy/datasets.html">Datasets</a>
      <a class="sidebar-nav-item" href="/tutorial.html">Tutorial</a>
      <a class="sidebar-nav-item" href="/resources.html">Resources, Courses &#38; Events</a>
      <a class="sidebar-nav-item" href="/contributing.html">Contributing</a>
    </nav>

    <div class="sidebar-item">
      <p style="font-size: 12px">
        Contact <a href="http://www.seanjmoran.com">Sean Moran</a> about this survey or website.
        <span style="font-size: 9px">
          Made with <a href="https://jekyllrb.com">Jekyll</a> and <a href="https://github.com/poole/hyde">Hyde</a>.
        </span>
      </p>
    </div>
  </div>
</div>

<script>
$("#searchTarget").keydown(function (e) {	
  if (e.keyCode == 13) {
    search();
  }
});

function search() {
  try {
    ga('send', 'event', 'search', 'search', $("#searchTarget").val());
  } finally {
    window.location = "/papers.html#" + $("#searchTarget").val();
  }
}
</script>


    <div class="content container">
      <div class="page">
  <h1 class="page-title">RREH Reconstruction Relations Embedded Hashing for Semi-Paired Cross-Modal Retrieval</h1>
  <h5>Wang Jianzong, Shi Haoxiang, Luo Kaiyi, Zhang Xulong, Cheng Ning, Xiao Jing. Arxiv 2024</h5>
  <p>
    
      [<a href="https://arxiv.org/abs/2405.17777" target="_blank">Paper</a>]
    
    &nbsp;<a href='http://scholar.google.com/scholar?q=RREH Reconstruction Relations Embedded Hashing for Semi-Paired Cross-Modal Retrieval' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
    &nbsp;<a href='https://www.semanticscholar.org/search?q=RREH Reconstruction Relations Embedded Hashing for Semi-Paired Cross-Modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
    <br/>
    
      <tag><a href="/tags.html#ARXIV">ARXIV</a></tag>
    
      <tag><a href="/tags.html#Cross Modal">Cross Modal</a></tag>
    
      <tag><a href="/tags.html#Supervised">Supervised</a></tag>
    
      <tag><a href="/tags.html#Unsupervised">Unsupervised</a></tag>
    
  </p>
  <p><p>Known for efficient computation and easy storage hashing has been extensively explored in cross-modal retrieval. The majority of current hashing models are predicated on the premise of a direct one-to-one mapping between data points. However in real practice data correspondence across modalities may be partially provided. In this research we introduce an innovative unsupervised hashing technique designed for semi-paired cross-modal retrieval tasks named Reconstruction Relations Embedded Hashing (RREH). RREH assumes that multi-modal data share a common subspace. For paired data RREH explores the latent consistent information of heterogeneous modalities by seeking a shared representation. For unpaired data to effectively capture the latent discriminative features the high-order relationships between unpaired data and anchors are embedded into the latent subspace which are computed by efficient linear reconstruction. The anchors are sampled from paired data which improves the efficiency of hash learning. The RREH trains the underlying features and the binary encodings in a unified framework with high-order reconstruction relations preserved. With the well devised objective function and discrete optimization algorithm RREH is designed to be scalable making it suitable for large-scale datasets and facilitating efficient cross-modal retrieval. In the evaluation process the proposed is tested with partially paired data to establish its superiority over several existing methods.</p>
</p>

  <h6>Similar Work</h6>
  <p>
    <ul id="relwork">

    </ul>
  </p>

  <script>  
    $(document).ready(
      function() {
        $.getJSON("/publications-metadata/wang2024rreh.json", function(data) {
          num_papers = data.length;
          html = "";
          for (let i=0; i < num_papers; i++) {
              html += '<li><a href="/publications/' + data[i][0] + '">'+ data[i][1] +'</a></li>'
          }
          $("#relwork").append(html);
        });
      });
  </script>

</div>

    </div>

  </body>
</html>
