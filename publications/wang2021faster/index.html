<!DOCTYPE html>
<html lang="en-us">

  <!-- _includes/head.html -->
<head>
  <!-- begin code v 7.0 -->
  <span id="wts2185304"></span>
  <script>
  var wts7 = {};
  wts7.invisible='';
  wts7.page_name='';
  wts7.group_name='';
  wts7.conversion_number='';
  wts7.user_id='';
  var wts=document.createElement('script');wts.async=true;
  wts.src='https://app.ardalio.com/wts7.js';document.head.appendChild(wts);
  wts.onload = function(){ wtsl7(2185304,4); };
  </script><noscript><img src="https://app.ardalio.com/7/4/2185304.png"></noscript>
  <!-- end code v 7.0 -->
  <!-- MathJax -->
  <script>
    window.MathJax = {
      tex: { inlineMath: [["\\(","\\)"]], displayMath: [["\\[","\\]"]] },
      options: { processHtmlClass: "mathjax-content", processEscapes: true }
    };
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <link href="https://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta charset="utf-8">

  <!-- Viewport -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- ✅ Manual SEO keywords (specific to Learning to Hash) -->
  <meta name="keywords" content="learning to hash, machine learning, hashing, approximate nearest neighbour search, ANN, LSH, locality sensitive hashing, vector quantization, deep hashing, binary embeddings, information retrieval, similarity search">

  <!-- ✅ Jekyll SEO plugin (title, description, canonical, OG/Twitter, JSON-LD) -->
  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Faster Nearest Neighbor Machine Translation | Awesome Learning to Hash</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="Faster Nearest Neighbor Machine Translation" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="\(k\)NN based neural machine translation (\(k\)NN-MT) has achieved state-of-the-art results in a variety of MT tasks. One significant shortcoming of \(k\)NN-MT lies in its inefficiency in identifying the \(k\) nearest neighbors of the query representation from the entire datastore, which is prohibitively time-intensive when the datastore size is large. In this work, we propose \textbf{Faster \(k\)NN-MT} to address this issue. The core idea of Faster \(k\)NN-MT is to use a hierarchical clustering strategy to approximate the distance between the query and a data point in the datastore, which is decomposed into two parts: the distance between the query and the center of the cluster that the data point belongs to, and the distance between the data point and the cluster center. We propose practical ways to compute these two parts in a significantly faster manner. Through extensive experiments on different MT benchmarks, we show that \textbf{Faster \(k\)NN-MT} is faster than Fast \(k\)NN-MT \citep{meng2021fast} and only slightly (1.2 times) slower than its vanilla counterpart while preserving model performance as \(k\)NN-MT. Faster \(k\)NN-MT enables the deployment of \(k\)NN-MT models on real-world MT services." />
<meta property="og:description" content="\(k\)NN based neural machine translation (\(k\)NN-MT) has achieved state-of-the-art results in a variety of MT tasks. One significant shortcoming of \(k\)NN-MT lies in its inefficiency in identifying the \(k\) nearest neighbors of the query representation from the entire datastore, which is prohibitively time-intensive when the datastore size is large. In this work, we propose \textbf{Faster \(k\)NN-MT} to address this issue. The core idea of Faster \(k\)NN-MT is to use a hierarchical clustering strategy to approximate the distance between the query and a data point in the datastore, which is decomposed into two parts: the distance between the query and the center of the cluster that the data point belongs to, and the distance between the data point and the cluster center. We propose practical ways to compute these two parts in a significantly faster manner. Through extensive experiments on different MT benchmarks, we show that \textbf{Faster \(k\)NN-MT} is faster than Fast \(k\)NN-MT \citep{meng2021fast} and only slightly (1.2 times) slower than its vanilla counterpart while preserving model performance as \(k\)NN-MT. Faster \(k\)NN-MT enables the deployment of \(k\)NN-MT models on real-world MT services." />
<link rel="canonical" href="https://learning2hash.github.io/publications/wang2021faster/" />
<meta property="og:url" content="https://learning2hash.github.io/publications/wang2021faster/" />
<meta property="og:site_name" content="Awesome Learning to Hash" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-08-31T14:32:34-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Faster Nearest Neighbor Machine Translation" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-08-31T14:32:34-05:00","datePublished":"2025-08-31T14:32:34-05:00","description":"\\(k\\)NN based neural machine translation (\\(k\\)NN-MT) has achieved state-of-the-art results in a variety of MT tasks. One significant shortcoming of \\(k\\)NN-MT lies in its inefficiency in identifying the \\(k\\) nearest neighbors of the query representation from the entire datastore, which is prohibitively time-intensive when the datastore size is large. In this work, we propose \\textbf{Faster \\(k\\)NN-MT} to address this issue. The core idea of Faster \\(k\\)NN-MT is to use a hierarchical clustering strategy to approximate the distance between the query and a data point in the datastore, which is decomposed into two parts: the distance between the query and the center of the cluster that the data point belongs to, and the distance between the data point and the cluster center. We propose practical ways to compute these two parts in a significantly faster manner. Through extensive experiments on different MT benchmarks, we show that \\textbf{Faster \\(k\\)NN-MT} is faster than Fast \\(k\\)NN-MT \\citep{meng2021fast} and only slightly (1.2 times) slower than its vanilla counterpart while preserving model performance as \\(k\\)NN-MT. Faster \\(k\\)NN-MT enables the deployment of \\(k\\)NN-MT models on real-world MT services.","headline":"Faster Nearest Neighbor Machine Translation","mainEntityOfPage":{"@type":"WebPage","@id":"https://learning2hash.github.io/publications/wang2021faster/"},"url":"https://learning2hash.github.io/publications/wang2021faster/"}</script>
<!-- End Jekyll SEO tag -->


  <!-- Site CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="shortcut icon" href="/public/favicon.svg">
  <link rel="search" href="/public/opensearchdescription.xml" type="application/opensearchdescription+xml" title="learning2hash" />

  <!-- ✅ Single, modern jQuery + DataTables -->
  <link rel="stylesheet" href="https://cdn.datatables.net/1.13.6/css/jquery.dataTables.min.css">
  <script src="https://code.jquery.com/jquery-3.7.0.min.js" defer></script>
  <script src="https://cdn.datatables.net/1.13.6/js/jquery.dataTables.min.js" defer></script>

  <!-- Optional sanity log -->
  <script defer>
    window.addEventListener('DOMContentLoaded', () => {
      console.log('jQuery:', jQuery?.fn?.jquery);
      console.log('DataTables loaded:', !!jQuery?.fn?.dataTable);
    });
  </script>
</head>


  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

  <body class="theme-base-0c layout-reverse">

    <a href='/contributing.html' class='ribbon'>Add your paper to Learning2Hash</a>
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Awesome Learning to Hash
        </a>
      </h1>
      <p class="lead">A Webpage dedicated to the latest research on Hash Function Learning. Maintained by <a href="http://sjmoran.github.io/">Sean Moran</a>.</p>
    </div>

    <nav class="sidebar-nav">
      <div class="sidebar-item">
        <p style="font-size: 12px">
          Search related work 
          <input type='text' id='searchTarget' size="16"/> 
          <button onClick="search();">Go</button>
        </p>
      </div>
      <a class="sidebar-nav-item" href="/papers.html">All Papers</a>
      <a class="sidebar-nav-item" href="/tags.html">Papers by Tag</a>
      <a class="sidebar-nav-item" href="/tsne-viz.html">2D Map of Papers</a>
      <a class="sidebar-nav-item" href="/topic-viz.html">Topic Explorer</a>
      <a class="sidebar-nav-item" href="/author-viz.html">Author Explorer </a>
      <a class="sidebar-nav-item" href="/opensource.html">Tools Explorer </a>
      <a class="sidebar-nav-item" href="/tutorial.html">Tutorial</a>
      <a class="sidebar-nav-item" href="/resources.html">Resources, Courses &#38; Events</a>
      <a class="sidebar-nav-item" href="/contributing.html">Contributing</a>
    </nav>

    <div class="sidebar-item">
      <p style="font-size: 12px">
        Contact <a href="http://www.seanjmoran.com">Sean Moran</a> about this survey or website.
        <span style="font-size: 9px">
          Made with <a href="https://jekyllrb.com">Jekyll</a> and <a href="https://github.com/poole/hyde">Hyde</a>.
        </span>
      </p>
    </div>
  </div>
</div>

<script defer>
document.addEventListener('DOMContentLoaded', function () {
  function doSearch() {
    const el = document.getElementById('searchTarget');
    if (!el) return;
    const q = el.value.trim();
    try { if (typeof ga === 'function') ga('send', 'event', 'search', 'search', q); } catch(e) {}
    window.location = "/papers.html#" + encodeURIComponent(q);
  }

  // jQuery path if loaded
  if (window.jQuery) {
    $('#searchTarget').on('keydown', function (e) {
      if (e.key === 'Enter') doSearch();
    });
    document.querySelector('.sidebar-item button')?.addEventListener('click', doSearch);
  } else {
    // vanilla fallback
    const input = document.getElementById('searchTarget');
    const btn = document.querySelector('.sidebar-item button');
    if (input) {
      input.addEventListener('keydown', function (e) {
        if (e.key === 'Enter') doSearch();
      });
    }
    if (btn) btn.addEventListener('click', doSearch);
  }

  // keep global for inline onClick="search()"
  window.search = doSearch;
});
</script>


    <div class="content container">
      <div class="page">
  <h1 class="page-title">Faster Nearest Neighbor Machine Translation</h1>

  <h5>
    
    
    <a href="https://scholar.google.com/scholar?q=Shuhe%20Wang,%20Jiwei%20Li,%20Yuxian%20Meng,%20Rongbin%20Ouyang,%20Guoyin%20Wang,%20Xiaoya%20Li,%20Tianwei%20Zhang,%20Shi%20Zong" 
       target="_blank" rel="noopener noreferrer">
      Shuhe Wang, Jiwei Li, Yuxian Meng, Rongbin Ouyang, Guoyin Wang, Xiaoya Li, Tianwei Zhang, Shi Zong
    </a>
    
    
    . Findings of the Association for Computational Linguistics: ACL 2022
     2022
    
      – <span>25 citations</span>
    
  </h5>

  <p>
    
      [<a href="https://arxiv.org/abs/2112.08152" target="_blank" rel="noopener noreferrer">Paper</a>]
    
    &nbsp;<a href="https://scholar.google.com/scholar?q=Faster%20Nearest%20Neighbor%20Machine%20Translation" target="_blank" rel="noopener noreferrer">
      <img style="display:inline; margin:0;" src="/public/media/google-scholar.png" alt="Search on Google Scholar"/>
    </a>
    &nbsp;<a href="https://www.semanticscholar.org/search?q=Faster%20Nearest%20Neighbor%20Machine%20Translation" target="_blank" rel="noopener noreferrer">
      <img style="display:inline; margin:0;" src="/public/media/semscholar.png" alt="Search on Semantic Scholar"/>
    </a>
    <br/>
    
      <tag><a href="/tags.html#Evaluation">Evaluation</a></tag>
    
  </p>

  <p><p>\(k\)NN based neural machine translation (\(k\)NN-MT) has achieved
state-of-the-art results in a variety of MT tasks. One significant shortcoming
of \(k\)NN-MT lies in its inefficiency in identifying the \(k\) nearest neighbors
of the query representation from the entire datastore, which is prohibitively
time-intensive when the datastore size is large. In this work, we propose
\textbf{Faster \(k\)NN-MT} to address this issue. The core idea of Faster
\(k\)NN-MT is to use a hierarchical clustering strategy to approximate the
distance between the query and a data point in the datastore, which is
decomposed into two parts: the distance between the query and the center of the
cluster that the data point belongs to, and the distance between the data point
and the cluster center. We propose practical ways to compute these two parts in
a significantly faster manner. Through extensive experiments on different MT
benchmarks, we show that \textbf{Faster \(k\)NN-MT} is faster than Fast \(k\)NN-MT
\citep{meng2021fast} and only slightly (1.2 times) slower than its vanilla
counterpart while preserving model performance as \(k\)NN-MT. Faster \(k\)NN-MT
enables the deployment of \(k\)NN-MT models on real-world MT services.</p>
</p>

  <h6>Similar Work</h6>
  <ul id="relwork"></ul>

  <!-- Vanilla JS: no jQuery needed -->
  <script>
    document.addEventListener('DOMContentLoaded', function () {
      var relwork = document.getElementById('relwork');
      if (!relwork) return;

      var metaPath = "/publications-metadata/wang2021faster.json";

      fetch(metaPath, { credentials: 'same-origin' })
        .then(function (res) {
          if (!res.ok) throw new Error(res.status + " " + res.statusText);
          return res.json();
        })
        .then(function (data) {
          if (!Array.isArray(data)) return;
          relwork.innerHTML = data
            .map(function (d) {
              var slug = d[0];
              var title = d[1];
              return '<li><a href="/publications/' + slug + '">' + title + '</a></li>';
            })
            .join('');
        })
        .catch(function (err) {
          console.warn("Failed to load similar work JSON:", err);
        });
    });
  </script>
</div>

    </div>

  </body>
</html>
