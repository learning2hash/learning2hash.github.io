<!DOCTYPE html>
<html lang="en-us">

  <head>
<!-- Begin Web-Stat code v 7.0 -->
<span id="wts2185304"></span>
<script>var wts=document.createElement('script');wts.async=true;
wts.src='https://app.ardalio.com/log7.js';document.head.appendChild(wts);
wts.onload = function(){ wtslog7(2185304,4); };
</script><noscript><a href="https://www.web-stat.com">
<img src="https://app.ardalio.com/7/4/2185304.png" 
alt="Web-Stat web statistics"></a></noscript>
<!-- End Web-Stat code v 7.0 -->
  <!-- Hotjar Tracking Code for https://learning2hash.github.io/ -->
<script>
    (function(h,o,t,j,a,r){
        h.hj=h.hj||function(){(h.hj.q=h.hj.q||[]).push(arguments)};
        h._hjSettings={hjid:1843243,hjsv:6};
        a=o.getElementsByTagName('head')[0];
        r=o.createElement('script');r.async=1;
        r.src=t+h._hjSettings.hjid+j+h._hjSettings.hjsv;
        a.appendChild(r);
    })(window,document,'https://static.hotjar.com/c/hotjar-','.js?sv=');
</script><!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-109544763-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-109544763-1');
</script>
<script>
    window.MathJax = {
      tex: {
        inlineMath: [["\\(","\\)"]],
        displayMath: [["\\[","\\]"]],
      },
      options: {
        processHtmlClass: "mathjax-content",
        processEscapes: true,
      }
    };
  </script>
  <script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="keywords" content="machine learning, hashing, approximate nearest neighbour search, lsh, learning-to-hash">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Distance And Similarity Measures Effect On The Performance Of K-nearest Neighbor Classifier – A Review | Awesome Learning to Hash</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="Distance And Similarity Measures Effect On The Performance Of K-nearest Neighbor Classifier – A Review" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The K-nearest neighbor (KNN) classifier is one of the simplest and most common classifiers, yet its performance competes with the most complex classifiers in the literature. The core of this classifier depends mainly on measuring the distance or similarity between the tested examples and the training examples. This raises a major question about which distance measures to be used for the KNN classifier among a large number of distance and similarity measures available? This review attempts to answer this question through evaluating the performance (measured by accuracy, precision and recall) of the KNN using a large number of distance measures, tested on a number of real-world datasets, with and without adding different levels of noise. The experimental results show that the performance of KNN classifier depends significantly on the distance used, and the results showed large gaps between the performances of different distances. We found that a recently proposed non-convex distance performed the best when applied on most datasets comparing to the other tested distances. In addition, the performance of the KNN with this top performing distance degraded only about \(20%\) while the noise level reaches \(90%\), this is true for most of the distances used as well. This means that the KNN classifier using any of the top \(10\) distances tolerate noise to a certain degree. Moreover, the results show that some distances are less affected by the added noise comparing to other distances." />
<meta property="og:description" content="The K-nearest neighbor (KNN) classifier is one of the simplest and most common classifiers, yet its performance competes with the most complex classifiers in the literature. The core of this classifier depends mainly on measuring the distance or similarity between the tested examples and the training examples. This raises a major question about which distance measures to be used for the KNN classifier among a large number of distance and similarity measures available? This review attempts to answer this question through evaluating the performance (measured by accuracy, precision and recall) of the KNN using a large number of distance measures, tested on a number of real-world datasets, with and without adding different levels of noise. The experimental results show that the performance of KNN classifier depends significantly on the distance used, and the results showed large gaps between the performances of different distances. We found that a recently proposed non-convex distance performed the best when applied on most datasets comparing to the other tested distances. In addition, the performance of the KNN with this top performing distance degraded only about \(20%\) while the noise level reaches \(90%\), this is true for most of the distances used as well. This means that the KNN classifier using any of the top \(10\) distances tolerate noise to a certain degree. Moreover, the results show that some distances are less affected by the added noise comparing to other distances." />
<link rel="canonical" href="https://learning2hash.github.io/publications/prasath2017distance/" />
<meta property="og:url" content="https://learning2hash.github.io/publications/prasath2017distance/" />
<meta property="og:site_name" content="Awesome Learning to Hash" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-07-18T05:15:23-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Distance And Similarity Measures Effect On The Performance Of K-nearest Neighbor Classifier – A Review" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-07-18T05:15:23-05:00","datePublished":"2025-07-18T05:15:23-05:00","description":"The K-nearest neighbor (KNN) classifier is one of the simplest and most common classifiers, yet its performance competes with the most complex classifiers in the literature. The core of this classifier depends mainly on measuring the distance or similarity between the tested examples and the training examples. This raises a major question about which distance measures to be used for the KNN classifier among a large number of distance and similarity measures available? This review attempts to answer this question through evaluating the performance (measured by accuracy, precision and recall) of the KNN using a large number of distance measures, tested on a number of real-world datasets, with and without adding different levels of noise. The experimental results show that the performance of KNN classifier depends significantly on the distance used, and the results showed large gaps between the performances of different distances. We found that a recently proposed non-convex distance performed the best when applied on most datasets comparing to the other tested distances. In addition, the performance of the KNN with this top performing distance degraded only about \\(20%\\) while the noise level reaches \\(90%\\), this is true for most of the distances used as well. This means that the KNN classifier using any of the top \\(10\\) distances tolerate noise to a certain degree. Moreover, the results show that some distances are less affected by the added noise comparing to other distances.","headline":"Distance And Similarity Measures Effect On The Performance Of K-nearest Neighbor Classifier – A Review","mainEntityOfPage":{"@type":"WebPage","@id":"https://learning2hash.github.io/publications/prasath2017distance/"},"url":"https://learning2hash.github.io/publications/prasath2017distance/"}</script>
<!-- End Jekyll SEO tag -->


  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="shortcut icon" href="/public/favicon.svg">
  <link rel="search" href="/public/opensearchdescription.xml" 
      type="application/opensearchdescription+xml" 
      title="learning2hash" />

  <script src="https://code.jquery.com/jquery-3.2.1.min.js"
  integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
  crossorigin="anonymous"></script>
  
  <link rel="stylesheet" type="text/css" href="//cdn.datatables.net/1.10.16/css/jquery.dataTables.min.css">
  <script type="text/javascript" charset="utf8" src="//cdn.datatables.net/1.10.16/js/jquery.dataTables.min.js"></script>
</head>


  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

  <body class="theme-base-0c layout-reverse">

    <a href='/contributing.html' class='ribbon'>Add your paper to Learning2Hash</a>
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Awesome Learning to Hash
        </a>
      </h1>
      <p class="lead">A Webpage dedicated to the latest research on Hash Function Learning. Maintained by <a href="http://sjmoran.github.io/">Sean Moran</a>.</p>
    </div>

    <nav class="sidebar-nav">
      <div class="sidebar-item">
        <p style="font-size: 12px">
          Search related work 
          <input type='text' id='searchTarget' size="16"/> 
          <button onClick="search();">Go</button>
        </p>
      </div>
      <a class="sidebar-nav-item" href="/papers.html">All Papers</a>
      <a class="sidebar-nav-item" href="/tags.html">Papers by Tag</a>
      <a class="sidebar-nav-item" href="/tsne-viz.html">2D Map of Papers</a>
      <a class="sidebar-nav-item" href="/topic-viz.html">Topic-based Explorer</a>
      <a class="sidebar-nav-item" href="/tutorial.html">Tutorial</a>
      <a class="sidebar-nav-item" href="/resources.html">Resources, Courses &#38; Events</a>
      <a class="sidebar-nav-item" href="/contributing.html">Contributing</a>
    </nav>

    <div class="sidebar-item">
      <p style="font-size: 12px">
        Contact <a href="http://www.seanjmoran.com">Sean Moran</a> about this survey or website.
        <span style="font-size: 9px">
          Made with <a href="https://jekyllrb.com">Jekyll</a> and <a href="https://github.com/poole/hyde">Hyde</a>.
        </span>
      </p>
    </div>
  </div>
</div>

<script>
$("#searchTarget").keydown(function (e) {	
  if (e.keyCode == 13) {
    search();
  }
});

function search() {
  try {
    ga('send', 'event', 'search', 'search', $("#searchTarget").val());
  } finally {
    window.location = "/papers.html#" + $("#searchTarget").val();
  }
}
</script>


    <div class="content container">
      <div class="page">
  <h1 class="page-title">Distance And Similarity Measures Effect On The Performance Of K-nearest Neighbor Classifier -- A Review</h1>
  <h5>
  Prasath et al.. Arxiv 2017
  
    – <span>92 citations</span>
  
  </h5>
  <p>
    
      [<a href="https://arxiv.org/abs/1708.04321" target="_blank">Paper</a>]
    
    &nbsp;<a href='http://scholar.google.com/scholar?q=Distance And Similarity Measures Effect On The Performance Of K-nearest Neighbor Classifier -- A Review' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
    &nbsp;<a href='https://www.semanticscholar.org/search?q=Distance And Similarity Measures Effect On The Performance Of K-nearest Neighbor Classifier -- A Review' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
    <br/>
    
      <tag><a href="/tags.html#Survey Paper">Survey Paper</a></tag>
    
      <tag><a href="/tags.html#Graph Based ANN">Graph Based ANN</a></tag>
    
      <tag><a href="/tags.html#DATASETS">DATASETS</a></tag>
    
      <tag><a href="/tags.html#Evaluation">Evaluation</a></tag>
    
  </p>
  <p><p>The K-nearest neighbor (KNN) classifier is one of the simplest and most
common classifiers, yet its performance competes with the most complex
classifiers in the literature. The core of this classifier depends mainly on
measuring the distance or similarity between the tested examples and the
training examples. This raises a major question about which distance measures
to be used for the KNN classifier among a large number of distance and
similarity measures available? This review attempts to answer this question
through evaluating the performance (measured by accuracy, precision and recall)
of the KNN using a large number of distance measures, tested on a number of
real-world datasets, with and without adding different levels of noise. The
experimental results show that the performance of KNN classifier depends
significantly on the distance used, and the results showed large gaps between
the performances of different distances. We found that a recently proposed
non-convex distance performed the best when applied on most datasets comparing
to the other tested distances. In addition, the performance of the KNN with
this top performing distance degraded only about \(20%\) while the noise level
reaches \(90%\), this is true for most of the distances used as well. This means
that the KNN classifier using any of the top \(10\) distances tolerate noise to a
certain degree. Moreover, the results show that some distances are less
affected by the added noise comparing to other distances.</p>
</p>

  <h6>Similar Work</h6>
  <p>
    <ul id="relwork">

    </ul>
  </p>

 <script>  
    $(document).ready(
      function() {
        $.getJSON("/publications-metadata/prasath2017distance.json", function(data) {
          num_papers = data.length;
          html = "";
          for (let i=0; i < num_papers; i++) {
              html += '<li><a href="/publications/' + data[i][0] + '">'+ data[i][1] +'</a></li>'
          }
          $("#relwork").append(html);
        });
      });
  </script>


</div>

    </div>

  </body>
</html>
