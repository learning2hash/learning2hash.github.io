<!DOCTYPE html>
<html lang="en-us">

  <head>
<!-- Begin Web-Stat code v 7.0 -->
<span id="wts2185304"></span>
<script>var wts=document.createElement('script');wts.async=true;
wts.src='https://app.ardalio.com/log7.js';document.head.appendChild(wts);
wts.onload = function(){ wtslog7(2185304,4); };
</script><noscript><a href="https://www.web-stat.com">
<img src="https://app.ardalio.com/7/4/2185304.png" 
alt="Web-Stat web statistics"></a></noscript>
<!-- End Web-Stat code v 7.0 -->
  <!-- Hotjar Tracking Code for https://learning2hash.github.io/ -->
<script>
    (function(h,o,t,j,a,r){
        h.hj=h.hj||function(){(h.hj.q=h.hj.q||[]).push(arguments)};
        h._hjSettings={hjid:1843243,hjsv:6};
        a=o.getElementsByTagName('head')[0];
        r=o.createElement('script');r.async=1;
        r.src=t+h._hjSettings.hjid+j+h._hjSettings.hjsv;
        a.appendChild(r);
    })(window,document,'https://static.hotjar.com/c/hotjar-','.js?sv=');
</script><!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-109544763-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-109544763-1');
</script>

  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="keywords" content="machine learning, hashing, approximate nearest neighbour search, lsh, learning-to-hash">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Unsupervised Hashing with Semantic Concept Mining | Awesome Learning to Hash</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="Unsupervised Hashing with Semantic Concept Mining" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Recently to improve the unsupervised image retrieval performance plenty of unsupervised hashing methods have been proposed by designing a semantic similarity matrix which is based on the similarities between image features extracted by a pre-trained CNN model. However most of these methods tend to ignore high-level abstract semantic concepts contained in images. Intuitively concepts play an important role in calculating the similarity among images. In real-world scenarios each image is associated with some concepts and the similarity between two images will be larger if they share more identical concepts. Inspired by the above intuition in this work we propose a novel Unsupervised Hashing with Semantic Concept Mining called UHSCM which leverages a VLP model to construct a high-quality similarity matrix. Specifically a set of randomly chosen concepts is first collected. Then by employing a vision-language pretraining (VLP) model with the prompt engineering which has shown strong power in visual representation learning the set of concepts is denoised according to the training images. Next the proposed method UHSCM applies the VLP model with prompting again to mine the concept distribution of each image and construct a high-quality semantic similarity matrix based on the mined concept distributions. Finally with the semantic similarity matrix as guiding information a novel hashing loss with a modified contrastive loss based regularization item is proposed to optimize the hashing network. Extensive experiments on three benchmark datasets show that the proposed method outperforms the state-of-the-art baselines in the image retrieval task." />
<meta property="og:description" content="Recently to improve the unsupervised image retrieval performance plenty of unsupervised hashing methods have been proposed by designing a semantic similarity matrix which is based on the similarities between image features extracted by a pre-trained CNN model. However most of these methods tend to ignore high-level abstract semantic concepts contained in images. Intuitively concepts play an important role in calculating the similarity among images. In real-world scenarios each image is associated with some concepts and the similarity between two images will be larger if they share more identical concepts. Inspired by the above intuition in this work we propose a novel Unsupervised Hashing with Semantic Concept Mining called UHSCM which leverages a VLP model to construct a high-quality similarity matrix. Specifically a set of randomly chosen concepts is first collected. Then by employing a vision-language pretraining (VLP) model with the prompt engineering which has shown strong power in visual representation learning the set of concepts is denoised according to the training images. Next the proposed method UHSCM applies the VLP model with prompting again to mine the concept distribution of each image and construct a high-quality semantic similarity matrix based on the mined concept distributions. Finally with the semantic similarity matrix as guiding information a novel hashing loss with a modified contrastive loss based regularization item is proposed to optimize the hashing network. Extensive experiments on three benchmark datasets show that the proposed method outperforms the state-of-the-art baselines in the image retrieval task." />
<link rel="canonical" href="https://learning2hash.github.io/publications/tu2022unsupervised/" />
<meta property="og:url" content="https://learning2hash.github.io/publications/tu2022unsupervised/" />
<meta property="og:site_name" content="Awesome Learning to Hash" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-09-11T09:13:05-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Unsupervised Hashing with Semantic Concept Mining" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2024-09-11T09:13:05-05:00","datePublished":"2024-09-11T09:13:05-05:00","description":"Recently to improve the unsupervised image retrieval performance plenty of unsupervised hashing methods have been proposed by designing a semantic similarity matrix which is based on the similarities between image features extracted by a pre-trained CNN model. However most of these methods tend to ignore high-level abstract semantic concepts contained in images. Intuitively concepts play an important role in calculating the similarity among images. In real-world scenarios each image is associated with some concepts and the similarity between two images will be larger if they share more identical concepts. Inspired by the above intuition in this work we propose a novel Unsupervised Hashing with Semantic Concept Mining called UHSCM which leverages a VLP model to construct a high-quality similarity matrix. Specifically a set of randomly chosen concepts is first collected. Then by employing a vision-language pretraining (VLP) model with the prompt engineering which has shown strong power in visual representation learning the set of concepts is denoised according to the training images. Next the proposed method UHSCM applies the VLP model with prompting again to mine the concept distribution of each image and construct a high-quality semantic similarity matrix based on the mined concept distributions. Finally with the semantic similarity matrix as guiding information a novel hashing loss with a modified contrastive loss based regularization item is proposed to optimize the hashing network. Extensive experiments on three benchmark datasets show that the proposed method outperforms the state-of-the-art baselines in the image retrieval task.","headline":"Unsupervised Hashing with Semantic Concept Mining","mainEntityOfPage":{"@type":"WebPage","@id":"https://learning2hash.github.io/publications/tu2022unsupervised/"},"url":"https://learning2hash.github.io/publications/tu2022unsupervised/"}</script>
<!-- End Jekyll SEO tag -->


  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="shortcut icon" href="/public/favicon.svg">
  <link rel="search" href="/public/opensearchdescription.xml" 
      type="application/opensearchdescription+xml" 
      title="learning2hash" />

  <script src="https://code.jquery.com/jquery-3.2.1.min.js"
  integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
  crossorigin="anonymous"></script>
  
  <link rel="stylesheet" type="text/css" href="//cdn.datatables.net/1.10.16/css/jquery.dataTables.min.css">
  <script type="text/javascript" charset="utf8" src="//cdn.datatables.net/1.10.16/js/jquery.dataTables.min.js"></script>
</head>


  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

  <body class="theme-base-0c layout-reverse">

    <a href='/contributing.html' class='ribbon'>Add your paper to Learning2Hash</a>
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Awesome Learning to Hash
        </a>
      </h1>
      <p class="lead">A Webpage dedicated to the latest research on Hash Function Learning. Maintained by <a href="http://sjmoran.github.io/">Sean Moran</a>.</p>
    </div>

    <nav class="sidebar-nav">
      <div class="sidebar-item">
        <p style="font-size: 12px">
          Search related work 
          <input type='text' id='searchTarget' size="16"/> 
          <button onClick="search();">Go</button>
        </p>
      </div>
      <a class="sidebar-nav-item" href="/papers.html">All Papers</a>
      <a class="sidebar-nav-item" href="/tags.html">Papers by Tag</a>
      <a class="sidebar-nav-item" href="/tsne-viz.html">2D Map of Papers</a>
      <a class="sidebar-nav-item" href="/topic-viz.html">Topic-based Explorer</a>
      <a class="sidebar-nav-item" href="/base-taxonomy/">Core Taxonomy</a>
      <a class="sidebar-nav-item" href="/base-taxonomy/datasets.html">Datasets</a>
      <a class="sidebar-nav-item" href="/tutorial.html">Tutorial</a>
      <a class="sidebar-nav-item" href="/resources.html">Resources, Courses &#38; Events</a>
      <a class="sidebar-nav-item" href="/contributing.html">Contributing</a>
    </nav>

    <div class="sidebar-item">
      <p style="font-size: 12px">
        Contact <a href="http://www.seanjmoran.com">Sean Moran</a> about this survey or website.
        <span style="font-size: 9px">
          Made with <a href="https://jekyllrb.com">Jekyll</a> and <a href="https://github.com/poole/hyde">Hyde</a>.
        </span>
      </p>
    </div>
  </div>
</div>

<script>
$("#searchTarget").keydown(function (e) {	
  if (e.keyCode == 13) {
    search();
  }
});

function search() {
  try {
    ga('send', 'event', 'search', 'search', $("#searchTarget").val());
  } finally {
    window.location = "/papers.html#" + $("#searchTarget").val();
  }
}
</script>


    <div class="content container">
      <div class="page">
  <h1 class="page-title">Unsupervised Hashing with Semantic Concept Mining</h1>
  <h5>Tu Rong-Cheng, Mao Xian-Ling, Lin Kevin Qinghong, Cai Chengfei, Qin Weize, Wang Hongfa, Wei Wei, Huang Heyan. Arxiv 2022</h5>
  <p>
    
      [<a href="https://arxiv.org/abs/2209.11475" target="_blank">Paper</a>]
    
    &nbsp;<a href='http://scholar.google.com/scholar?q=Unsupervised Hashing with Semantic Concept Mining' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
    &nbsp;<a href='https://www.semanticscholar.org/search?q=Unsupervised Hashing with Semantic Concept Mining' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
    <br/>
    
      <tag><a href="/tags.html#ARXIV">ARXIV</a></tag>
    
      <tag><a href="/tags.html#CNN">CNN</a></tag>
    
      <tag><a href="/tags.html#Image Retrieval">Image Retrieval</a></tag>
    
      <tag><a href="/tags.html#Supervised">Supervised</a></tag>
    
      <tag><a href="/tags.html#Unsupervised">Unsupervised</a></tag>
    
  </p>
  <p><p>Recently to improve the unsupervised image retrieval performance plenty of unsupervised hashing methods have been proposed by designing a semantic similarity matrix which is based on the similarities between image features extracted by a pre-trained CNN model. However most of these methods tend to ignore high-level abstract semantic concepts contained in images. Intuitively concepts play an important role in calculating the similarity among images. In real-world scenarios each image is associated with some concepts and the similarity between two images will be larger if they share more identical concepts. Inspired by the above intuition in this work we propose a novel Unsupervised Hashing with Semantic Concept Mining called UHSCM which leverages a VLP model to construct a high-quality similarity matrix. Specifically a set of randomly chosen concepts is first collected. Then by employing a vision-language pretraining (VLP) model with the prompt engineering which has shown strong power in visual representation learning the set of concepts is denoised according to the training images. Next the proposed method UHSCM applies the VLP model with prompting again to mine the concept distribution of each image and construct a high-quality semantic similarity matrix based on the mined concept distributions. Finally with the semantic similarity matrix as guiding information a novel hashing loss with a modified contrastive loss based regularization item is proposed to optimize the hashing network. Extensive experiments on three benchmark datasets show that the proposed method outperforms the state-of-the-art baselines in the image retrieval task.</p>
</p>

  <h6>Similar Work</h6>
  <p>
    <ul id="relwork">

    </ul>
  </p>

  <script>  
    $(document).ready(
      function() {
        $.getJSON("/publications-metadata/tu2022unsupervised.json", function(data) {
          num_papers = data.length;
          html = "";
          for (let i=0; i < num_papers; i++) {
              html += '<li><a href="/publications/' + data[i][0] + '">'+ data[i][1] +'</a></li>'
          }
          $("#relwork").append(html);
        });
      });
  </script>

</div>

    </div>

  </body>
</html>
