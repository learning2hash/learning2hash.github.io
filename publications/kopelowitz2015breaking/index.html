<!DOCTYPE html>
<html lang="en-us">

  <head>
<!-- Begin Web-Stat code v 7.0 -->
<span id="wts2185304"></span>
<script>var wts=document.createElement('script');wts.async=true;
wts.src='https://app.ardalio.com/log7.js';document.head.appendChild(wts);
wts.onload = function(){ wtslog7(2185304,4); };
</script><noscript><a href="https://www.web-stat.com">
<img src="https://app.ardalio.com/7/4/2185304.png" 
alt="Web-Stat web statistics"></a></noscript>
<!-- End Web-Stat code v 7.0 -->
  <!-- Hotjar Tracking Code for https://learning2hash.github.io/ -->
<script>
    (function(h,o,t,j,a,r){
        h.hj=h.hj||function(){(h.hj.q=h.hj.q||[]).push(arguments)};
        h._hjSettings={hjid:1843243,hjsv:6};
        a=o.getElementsByTagName('head')[0];
        r=o.createElement('script');r.async=1;
        r.src=t+h._hjSettings.hjid+j+h._hjSettings.hjsv;
        a.appendChild(r);
    })(window,document,'https://static.hotjar.com/c/hotjar-','.js?sv=');
</script><!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-109544763-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-109544763-1');
</script>
<script>
    window.MathJax = {
      tex: {
        inlineMath: [["\\(","\\)"]],
        displayMath: [["\\[","\\]"]],
      },
      options: {
        processHtmlClass: "mathjax-content",
        processEscapes: true,
      }
    };
  </script>
  <script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="keywords" content="machine learning, hashing, approximate nearest neighbour search, lsh, learning-to-hash">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Breaking The Variance: Approximating The Hamming Distance In $\tilde O(1/\epsilon)$ Time Per Alignment | Awesome Learning to Hash</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="Breaking The Variance: Approximating The Hamming Distance In $\tilde O(1/\epsilon)$ Time Per Alignment" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The algorithmic tasks of computing the Hamming distance between a given pattern of length (m) and each location in a text of length (n) is one of the most fundamental algorithmic tasks in string algorithms. Unfortunately, there is evidence that for a text (T) of size (n) and a pattern (P) of size (m), one cannot compute the exact Hamming distance for all locations in (T) in time which is less than (\tilde O(n\sqrt m)). However, Karloff~\cite{karloff} showed that if one is willing to suffer a (1\pm\epsilon) approximation, then it is possible to solve the problem with high probability, in (\tilde O(\frac n {\epsilon^2})) time. Due to related lower bounds for computing the Hamming distance of two strings in the one-way communication complexity model, it is strongly believed that obtaining an algorithm for solving the approximation version cannot be done much faster as a function of (\frac 1 \epsilon). We show here that this belief is false by introducing a new (\tilde O(\frac{n}{\epsilon})) time algorithm that succeeds with high probability. The main idea behind our algorithm, which is common in sparse recovery problems, is to reduce the variance of a specific randomized experiment by (approximately) separating heavy hitters from non-heavy hitters. However, while known sparse recovery techniques work very well on vectors, they do not seem to apply here, where we are dealing with mismatches between pairs of characters. We introduce two main algorithmic ingredients. The first is a new sparse recovery method that applies for pair inputs (such as in our setting). The second is a new construction of hash/projection functions, which allows to count the number of projections that induce mismatches between two characters exponentially faster than brute force. We expect that these algorithmic techniques will be of independent interest." />
<meta property="og:description" content="The algorithmic tasks of computing the Hamming distance between a given pattern of length (m) and each location in a text of length (n) is one of the most fundamental algorithmic tasks in string algorithms. Unfortunately, there is evidence that for a text (T) of size (n) and a pattern (P) of size (m), one cannot compute the exact Hamming distance for all locations in (T) in time which is less than (\tilde O(n\sqrt m)). However, Karloff~\cite{karloff} showed that if one is willing to suffer a (1\pm\epsilon) approximation, then it is possible to solve the problem with high probability, in (\tilde O(\frac n {\epsilon^2})) time. Due to related lower bounds for computing the Hamming distance of two strings in the one-way communication complexity model, it is strongly believed that obtaining an algorithm for solving the approximation version cannot be done much faster as a function of (\frac 1 \epsilon). We show here that this belief is false by introducing a new (\tilde O(\frac{n}{\epsilon})) time algorithm that succeeds with high probability. The main idea behind our algorithm, which is common in sparse recovery problems, is to reduce the variance of a specific randomized experiment by (approximately) separating heavy hitters from non-heavy hitters. However, while known sparse recovery techniques work very well on vectors, they do not seem to apply here, where we are dealing with mismatches between pairs of characters. We introduce two main algorithmic ingredients. The first is a new sparse recovery method that applies for pair inputs (such as in our setting). The second is a new construction of hash/projection functions, which allows to count the number of projections that induce mismatches between two characters exponentially faster than brute force. We expect that these algorithmic techniques will be of independent interest." />
<link rel="canonical" href="https://learning2hash.github.io/publications/kopelowitz2015breaking/" />
<meta property="og:url" content="https://learning2hash.github.io/publications/kopelowitz2015breaking/" />
<meta property="og:site_name" content="Awesome Learning to Hash" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-08-12T14:13:09-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Breaking The Variance: Approximating The Hamming Distance In $\tilde O(1/\epsilon)$ Time Per Alignment" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-08-12T14:13:09-05:00","datePublished":"2025-08-12T14:13:09-05:00","description":"The algorithmic tasks of computing the Hamming distance between a given pattern of length (m) and each location in a text of length (n) is one of the most fundamental algorithmic tasks in string algorithms. Unfortunately, there is evidence that for a text (T) of size (n) and a pattern (P) of size (m), one cannot compute the exact Hamming distance for all locations in (T) in time which is less than (\\tilde O(n\\sqrt m)). However, Karloff~\\cite{karloff} showed that if one is willing to suffer a (1\\pm\\epsilon) approximation, then it is possible to solve the problem with high probability, in (\\tilde O(\\frac n {\\epsilon^2})) time. Due to related lower bounds for computing the Hamming distance of two strings in the one-way communication complexity model, it is strongly believed that obtaining an algorithm for solving the approximation version cannot be done much faster as a function of (\\frac 1 \\epsilon). We show here that this belief is false by introducing a new (\\tilde O(\\frac{n}{\\epsilon})) time algorithm that succeeds with high probability. The main idea behind our algorithm, which is common in sparse recovery problems, is to reduce the variance of a specific randomized experiment by (approximately) separating heavy hitters from non-heavy hitters. However, while known sparse recovery techniques work very well on vectors, they do not seem to apply here, where we are dealing with mismatches between pairs of characters. We introduce two main algorithmic ingredients. The first is a new sparse recovery method that applies for pair inputs (such as in our setting). The second is a new construction of hash/projection functions, which allows to count the number of projections that induce mismatches between two characters exponentially faster than brute force. We expect that these algorithmic techniques will be of independent interest.","headline":"Breaking The Variance: Approximating The Hamming Distance In $\\tilde O(1/\\epsilon)$ Time Per Alignment","mainEntityOfPage":{"@type":"WebPage","@id":"https://learning2hash.github.io/publications/kopelowitz2015breaking/"},"url":"https://learning2hash.github.io/publications/kopelowitz2015breaking/"}</script>
<!-- End Jekyll SEO tag -->


  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="shortcut icon" href="/public/favicon.svg">
  <link rel="search" href="/public/opensearchdescription.xml" 
      type="application/opensearchdescription+xml" 
      title="learning2hash" />

  <script src="https://code.jquery.com/jquery-3.2.1.min.js"
  integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
  crossorigin="anonymous"></script>
  
  <link rel="stylesheet" type="text/css" href="//cdn.datatables.net/1.10.16/css/jquery.dataTables.min.css">
  <script type="text/javascript" charset="utf8" src="//cdn.datatables.net/1.10.16/js/jquery.dataTables.min.js"></script>
</head>


  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

  <body class="theme-base-0c layout-reverse">

    <a href='/contributing.html' class='ribbon'>Add your paper to Learning2Hash</a>
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Awesome Learning to Hash
        </a>
      </h1>
      <p class="lead">A Webpage dedicated to the latest research on Hash Function Learning. Maintained by <a href="http://sjmoran.github.io/">Sean Moran</a>.</p>
    </div>

    <nav class="sidebar-nav">
      <div class="sidebar-item">
        <p style="font-size: 12px">
          Search related work 
          <input type='text' id='searchTarget' size="16"/> 
          <button onClick="search();">Go</button>
        </p>
      </div>
      <a class="sidebar-nav-item" href="/papers.html">All Papers</a>
      <a class="sidebar-nav-item" href="/tags.html">Papers by Tag</a>
      <a class="sidebar-nav-item" href="/tsne-viz.html">2D Map of Papers</a>
      <a class="sidebar-nav-item" href="/topic-viz.html">Topic Explorer</a>
      <a class="sidebar-nav-item" href="/author-viz.html">Author Explorer </a>
      <a class="sidebar-nav-item" href="/tutorial.html">Tutorial</a>
      <a class="sidebar-nav-item" href="/resources.html">Resources, Courses &#38; Events</a>
      <a class="sidebar-nav-item" href="/contributing.html">Contributing</a>
    </nav>

    <div class="sidebar-item">
      <p style="font-size: 12px">
        Contact <a href="http://www.seanjmoran.com">Sean Moran</a> about this survey or website.
        <span style="font-size: 9px">
          Made with <a href="https://jekyllrb.com">Jekyll</a> and <a href="https://github.com/poole/hyde">Hyde</a>.
        </span>
      </p>
    </div>
  </div>
</div>

<script>
$("#searchTarget").keydown(function (e) {	
  if (e.keyCode == 13) {
    search();
  }
});

function search() {
  try {
    ga('send', 'event', 'search', 'search', $("#searchTarget").val());
  } finally {
    window.location = "/papers.html#" + $("#searchTarget").val();
  }
}
</script>


    <div class="content container">
      <div class="page">
  <h1 class="page-title">Breaking The Variance: Approximating The Hamming Distance In $\tilde O(1/\epsilon)$ Time Per Alignment</h1>
  <h5>
  
    
      Tsvi Kopelowitz, Ely Porat
    
  
  . Arxiv
   2015
  
    – <span>1 citation</span>
  
  </h5>
  <p>
    
      [<a href="https://arxiv.org/abs/1512.04515" target="_blank">Paper</a>]
    
    &nbsp;<a href='http://scholar.google.com/scholar?q=Breaking The Variance: Approximating The Hamming Distance In $\tilde O(1/\epsilon)$ Time Per Alignment' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
    &nbsp;<a href='https://www.semanticscholar.org/search?q=Breaking The Variance: Approximating The Hamming Distance In $\tilde O(1/\epsilon)$ Time Per Alignment' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
    <br/>
    
      <tag><a href="/tags.html#Distance Metric Learning">Distance Metric Learning</a></tag>
    
      <tag><a href="/tags.html#Efficiency">Efficiency</a></tag>
    
      <tag><a href="/tags.html#Hashing Methods">Hashing Methods</a></tag>
    
      <tag><a href="/tags.html#Locality Sensitive Hashing">Locality Sensitive Hashing</a></tag>
    
      <tag><a href="/tags.html#Scalability">Scalability</a></tag>
    
  </p>
  <p><p>The algorithmic tasks of computing the Hamming distance between a given
pattern of length (m) and each location in a text of length (n) is one of the
most fundamental algorithmic tasks in string algorithms. Unfortunately, there
is evidence that for a text (T) of size (n) and a pattern (P) of size (m), one
cannot compute the exact Hamming distance for all locations in (T) in time
which is less than (\tilde O(n\sqrt m)). However, Karloff~\cite{karloff} showed
that if one is willing to suffer a (1\pm\epsilon) approximation, then it is
possible to solve the problem with high probability, in (\tilde O(\frac n
{\epsilon^2})) time.
  Due to related lower bounds for computing the Hamming distance of two strings
in the one-way communication complexity model, it is strongly believed that
obtaining an algorithm for solving the approximation version cannot be done
much faster as a function of (\frac 1 \epsilon). We show here that this belief
is false by introducing a new (\tilde O(\frac{n}{\epsilon})) time algorithm
that succeeds with high probability.
  The main idea behind our algorithm, which is common in sparse recovery
problems, is to reduce the variance of a specific randomized experiment by
(approximately) separating heavy hitters from non-heavy hitters. However, while
known sparse recovery techniques work very well on vectors, they do not seem to
apply here, where we are dealing with mismatches between pairs of characters.
We introduce two main algorithmic ingredients. The first is a new sparse
recovery method that applies for pair inputs (such as in our setting). The
second is a new construction of hash/projection functions, which allows to
count the number of projections that induce mismatches between two characters
exponentially faster than brute force. We expect that these algorithmic
techniques will be of independent interest.</p>
</p>

  <h6>Similar Work</h6>
  <p>
    <ul id="relwork">

    </ul>
  </p>

 <script>  
    $(document).ready(
      function() {
        $.getJSON("/publications-metadata/kopelowitz2015breaking.json", function(data) {
          num_papers = data.length;
          html = "";
          for (let i=0; i < num_papers; i++) {
              html += '<li><a href="/publications/' + data[i][0] + '">'+ data[i][1] +'</a></li>'
          }
          $("#relwork").append(html);
        });
      });
  </script>


</div>

    </div>

  </body>
</html>
