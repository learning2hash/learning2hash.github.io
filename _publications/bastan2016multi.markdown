---
layout: publication
title: Multi-view Product Image Search Using Deep Convnets Representations
authors: Muhammet Bastan, Ozgur Yilmaz
conference: Arxiv
year: 2016
bibkey: bastan2016multi
citations: 0
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1608.03462'}]
tags: [Evaluation, Datasets, Image Retrieval]
short_authors: Muhammet Bastan, Ozgur Yilmaz
---
Multi-view product image queries can improve retrieval performance over
single view queries significantly. In this paper, we investigated the
performance of deep convolutional neural networks (ConvNets) on multi-view
product image search. First, we trained a VGG-like network to learn deep
ConvNets representations of product images. Then, we computed the deep ConvNets
representations of database and query images and performed single view queries,
and multi-view queries using several early and late fusion approaches.
  We performed extensive experiments on the publicly available Multi-View
Object Image Dataset (MVOD 5K) with both clean background queries from the
Internet and cluttered background queries from a mobile phone. We compared the
performance of ConvNets to the classical bag-of-visual-words (BoWs). We
concluded that (1) multi-view queries with deep ConvNets representations
perform significantly better than single view queries, (2) ConvNets perform
much better than BoWs and have room for further improvement, (3) pre-training
of ConvNets on a different image dataset with background clutter is needed to
obtain good performance on cluttered product image queries obtained with a
mobile phone.