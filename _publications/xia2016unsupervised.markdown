---
layout: publication
title: Unsupervised Deep Hashing for Large-scale Visual Search
authors: Xia Zhaoqiang, Feng Xiaoyi, Peng Jinye, Hadid Abdenour
conference: 
year: 2016
bibkey: xia2016unsupervised
additional_links:
   - {name: "DOI", url: "10.1109/IPTA.2016.7821007"}
   - {name: "License", url: "http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}
   - {name: "Paper", url: "https://arxiv.org/abs/1602.00206"}
tags: ['Supervised', 'Unsupervised', 'Deep Learning']
---
Learning based hashing plays a pivotal role in large-scale visual search. However, most existing hashing algorithms tend to learn shallow models that do not seek representative binary codes. In this paper, we propose a novel hashing approach based on unsupervised deep learning to hierarchically transform features into hash codes. Within the heterogeneous deep hashing framework, the autoencoder layers with specific constraints are considered to model the nonlinear mapping between features and binary codes. Then, a Restricted Boltzmann Machine (RBM) layer with constraints is utilized to reduce the dimension in the hamming space. Extensive experiments on the problem of visual search demonstrate the competitiveness of our proposed approach compared to state-of-the-art.
