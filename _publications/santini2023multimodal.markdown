---
layout: publication
title: Multimodal Search On Iconclass Using Vision-language Pre-trained Models
authors: Cristian Santini, Etienne Posthumus, Mary Ann Tan, Oleksandra Bruns, Tabea
  Tietz, Harald Sack
conference: Arxiv
year: 2023
bibkey: santini2023multimodal
citations: 0
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2306.16529'}]
tags: [Uncategorized]
short_authors: Santini et al.
---
Terminology sources, such as controlled vocabularies, thesauri and
classification systems, play a key role in digitizing cultural heritage.
However, Information Retrieval (IR) systems that allow to query and explore
these lexical resources often lack an adequate representation of the semantics
behind the user's search, which can be conveyed through multiple expression
modalities (e.g., images, keywords or textual descriptions). This paper
presents the implementation of a new search engine for one of the most widely
used iconography classification system, Iconclass. The novelty of this system
is the use of a pre-trained vision-language model, namely CLIP, to retrieve and
explore Iconclass concepts using visual or textual queries.