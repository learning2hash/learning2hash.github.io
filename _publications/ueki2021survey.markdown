---
layout: publication
title: Survey Of Visual-semantic Embedding Methods For Zero-shot Image Retrieval
authors: Kazuya Ueki
conference: 2021 20th IEEE International Conference on Machine Learning and Applications
  (ICMLA)
year: 2021
bibkey: ueki2021survey
citations: 2
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2105.07391'}]
tags: ["Evaluation", "Few Shot & Zero Shot", "Image Retrieval", "Survey Paper"]
short_authors: Kazuya Ueki
---
Visual-semantic embedding is an interesting research topic because it is
useful for various tasks, such as visual question answering (VQA), image-text
retrieval, image captioning, and scene graph generation. In this paper, we
focus on zero-shot image retrieval using sentences as queries and present a
survey of the technological trends in this area. First, we provide a
comprehensive overview of the history of the technology, starting with a
discussion of the early studies of image-to-text matching and how the
technology has evolved over time. In addition, a description of the datasets
commonly used in experiments and a comparison of the evaluation results of each
method are presented. We also introduce the implementation available on github
for use in confirming the accuracy of experiments and for further improvement.
We hope that this survey paper will encourage researchers to further develop
their research on bridging images and languages.