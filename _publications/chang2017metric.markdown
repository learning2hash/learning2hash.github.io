---
layout: publication
title: Metric Random Matchings With Applications
authors: Ching-Lueh Chang
conference: Arxiv
year: 2017
bibkey: chang2017metric
citations: 0
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1703.08433'}]
tags: ["Distance Metric Learning"]
short_authors: Ching-Lueh Chang
---
Let \((\\{1,2,\ldots,n\\},d)\) be a metric space. We analyze the expected value
and the variance of \(\sum_\{i=1\}^\{\lfloor
n/2\rfloor\}\,d(\{\boldsymbol\{\pi\}\}(2i-1),\{\boldsymbol\{\pi\}\}(2i))\) for a
uniformly random permutation \(\{\boldsymbol\{\pi\}\}\) of \(\\{1,2,\ldots,n\\}\),
leading to the following results: (I) Consider the problem of finding a point
in \(\\{1,2,\ldots,n\\}\) with the minimum sum of distances to all points. We show
that this problem has a randomized algorithm that (1) always outputs a
\((2+\epsilon)\)-approximate solution in expected \(O(n/\epsilon^2)\) time and that
(2) inherits Indyk's~\cite\{Ind99, Ind00\} algorithm to output a
\((1+\epsilon)\)-approximate solution in \(O(n/\epsilon^2)\) time with probability
\(Ω(1)\), where \(\epsilon\in(0,1)\). (II) The average distance in
\((\\{1,2,\ldots,n\\},d)\) can be approximated in \(O(n/\epsilon)\) time to within a
multiplicative factor in \([\,1/2-\epsilon,1\,]\) with probability
\(1/2+Ω(1)\), where \(\epsilon>0\). (III) Assume \(d\) to be a graph metric.
Then the average distance in \((\\{1,2,\ldots,n\\},d)\) can be approximated in
\(O(n)\) time to within a multiplicative factor in \([\,1-\epsilon,1+\epsilon\,]\)
with probability \(1/2+Ω(1)\), where \(\epsilon=\omega(1/n^\{1/4\})\).