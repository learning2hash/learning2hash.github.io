---
layout: publication
title: 'Creating Something From Nothing: Unsupervised Knowledge Distillation For Cross-modal
  Hashing'
authors: Hengtong Hu, Xie, Hong, Tian
conference: 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
year: 2020
bibkey: hu2020creating
citations: 117
additional_links: [{name: Paper, url: 'https://arxiv.org/pdf/2004.00280.pdf'}]
tags: ["CVPR", "Unsupervised"]
short_authors: Hu et al.
---
In recent years, cross-modal hashing (CMH) has attracted increasing attentions, mainly because its potential
ability of mapping contents from different modalities, especially in vision and language, into the same space, so that
it becomes efficient in cross-modal data retrieval. There are
two main frameworks for CMH, differing from each other in
whether semantic supervision is required. Compared to the
unsupervised methods, the supervised methods often enjoy
more accurate results, but require much heavier labors in
data annotation. In this paper, we propose a novel approach
that enables guiding a supervised method using outputs produced by an unsupervised method. Specifically, we make
use of teacher-student optimization for propagating knowledge. Experiments are performed on two popular CMH
benchmarks, i.e., the MIRFlickr and NUS-WIDE datasets.
Our approach outperforms all existing unsupervised methods by a large margin