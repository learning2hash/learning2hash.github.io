---
layout: publication
title: Joint Dictionaries For Zero-shot Learning
authors: Soheil Kolouri, Mohammad Rostami, Yuri Owechko, Kyungnam Kim
conference: Proceedings of the AAAI Conference on Artificial Intelligence
year: 2018
bibkey: kolouri2017joint
citations: 23
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1709.03688'}]
tags: ["AAAI", "Few Shot & Zero Shot"]
short_authors: Kolouri et al.
---
A classic approach toward zero-shot learning (ZSL) is to map the input domain
to a set of semantically meaningful attributes that could be used later on to
classify unseen classes of data (e.g. visual data). In this paper, we propose
to learn a visual feature dictionary that has semantically meaningful atoms.
Such dictionary is learned via joint dictionary learning for the visual domain
and the attribute domain, while enforcing the same sparse coding for both
dictionaries. Our novel attribute aware formulation provides an algorithmic
solution to the domain shift/hubness problem in ZSL. Upon learning the joint
dictionaries, images from unseen classes can be mapped into the attribute space
by finding the attribute aware joint sparse representation using solely the
visual data. We demonstrate that our approach provides superior or comparable
performance to that of the state of the art on benchmark datasets.