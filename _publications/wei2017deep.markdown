---
layout: publication
title: Deep Descriptor Transforming For Image Co-localization
authors: Xiu-Shen Wei, Chen-Lin Zhang, Yao Li, Chen-Wei Xie, Jianxin Wu, Chunhua Shen,
  Zhi-Hua Zhou
conference: Proceedings of the Twenty-Sixth International Joint Conference on Artificial
  Intelligence
year: 2017
bibkey: wei2017deep
citations: 29
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1705.02758'}]
tags: ["IJCAI"]
short_authors: Wei et al.
---
Reusable model design becomes desirable with the rapid expansion of machine
learning applications. In this paper, we focus on the reusability of
pre-trained deep convolutional models. Specifically, different from treating
pre-trained models as feature extractors, we reveal more treasures beneath
convolutional layers, i.e., the convolutional activations could act as a
detector for the common object in the image co-localization problem. We propose
a simple but effective method, named Deep Descriptor Transforming (DDT), for
evaluating the correlations of descriptors and then obtaining the
category-consistent regions, which can accurately locate the common object in a
set of images. Empirical studies validate the effectiveness of the proposed DDT
method. On benchmark image co-localization datasets, DDT consistently
outperforms existing state-of-the-art methods by a large margin. Moreover, DDT
also demonstrates good generalization ability for unseen categories and
robustness for dealing with noisy data.