---
layout: publication
title: 'Imagery As Inquiry: Exploring A Multimodal Dataset For Conversational Recommendation'
authors: Se-Eun Yoon, Hyunsik Jeon, Julian McAuley
conference: Arxiv
year: 2024
bibkey: yoon2024imagery
citations: 0
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2405.14142'}]
tags: ["Datasets", "Recommender Systems"]
short_authors: Se-Eun Yoon, Hyunsik Jeon, Julian McAuley
---
We introduce a multimodal dataset where users express preferences through
images. These images encompass a broad spectrum of visual expressions ranging
from landscapes to artistic depictions. Users request recommendations for books
or music that evoke similar feelings to those captured in the images, and
recommendations are endorsed by the community through upvotes. This dataset
supports two recommendation tasks: title generation and multiple-choice
selection. Our experiments with large foundation models reveal their
limitations in these tasks. Particularly, vision-language models show no
significant advantage over language-only counterparts that use descriptions,
which we hypothesize is due to underutilized visual capabilities. To better
harness these abilities, we propose the chain-of-imagery prompting, which
results in notable improvements. We release our code and datasets.