---
layout: publication
title: 'IDEAL: Independent Domain Embedding Augmentation Learning'
authors: Zhiyuan Chen, Guang Yao, Wennan Ma, Lin Xu
conference: Arxiv
year: 2021
bibkey: chen2021ideal
citations: 1
additional_links: [{name: Code, url: 'https://github.com/emdata-ailab/IDEAL*.'}, {
    name: Paper, url: 'https://arxiv.org/abs/2105.10112'}]
tags: [Evaluation, Distance Metric Learning, Image Retrieval]
short_authors: Chen et al.
---
Many efforts have been devoted to designing sampling, mining, and weighting
strategies in high-level deep metric learning (DML) loss objectives. However,
little attention has been paid to low-level but essential data transformation.
In this paper, we develop a novel mechanism, the independent domain embedding
augmentation learning (\{IDEAL\}) method. It can simultaneously learn multiple
independent embedding spaces for multiple domains generated by predefined data
transformations. Our IDEAL is orthogonal to existing DML techniques and can be
seamlessly combined with prior DML approaches for enhanced performance.
Empirical results on visual retrieval tasks demonstrate the superiority of the
proposed method. For example, the IDEAL improves the performance of MS loss by
a large margin, 84.5% \(\rightarrow\) 87.1% on Cars-196, and 65.8%
\(\rightarrow\) 69.5% on CUB-200 at Recall\(@1\). Our IDEAL with MS loss also
achieves the new state-of-the-art performance on three image retrieval
benchmarks, \ie, *Cars-196*, *CUB-200*, and *SOP*. It
outperforms the most recent DML approaches, such as Circle loss and XBM,
significantly. The source code and pre-trained models of our method will be
available at*https://github.com/emdata-ailab/IDEAL*.