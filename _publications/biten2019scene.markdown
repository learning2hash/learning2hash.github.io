---
layout: publication
title: Scene Text Visual Question Answering
authors: "Ali Furkan Biten, Ruben Tito, Andres Mafla, Lluis Gomez, Mar\xE7al Rusi\xF1\
  ol, Ernest Valveny, C. V. Jawahar, Dimosthenis Karatzas"
conference: 2019 IEEE/CVF International Conference on Computer Vision (ICCV)
year: 2019
bibkey: biten2019scene
citations: 227
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1905.13648'}]
tags: ["ICCV"]
short_authors: Biten et al.
---
Current visual question answering datasets do not consider the rich semantic
information conveyed by text within an image. In this work, we present a new
dataset, ST-VQA, that aims to highlight the importance of exploiting high-level
semantic information present in images as textual cues in the VQA process. We
use this dataset to define a series of tasks of increasing difficulty for which
reading the scene text in the context provided by the visual information is
necessary to reason and generate an appropriate answer. We propose a new
evaluation metric for these tasks to account both for reasoning errors as well
as shortcomings of the text recognition module. In addition we put forward a
series of baseline methods, which provide further insight to the newly released
dataset, and set the scene for further research.