---
layout: publication
title: Enhancing Subsequent Video Retrieval via Vision-Language Models (VLMs)
authors: Duan Yicheng, Huang Xi, Chen Duo
conference: 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
year: 2025
bibkey: duan2025enhancing
citations: 71
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2503.17415'}]
tags: [CVPR, Video Retrieval]
---
The rapid growth of video content demands efficient and precise retrieval
systems. While vision-language models (VLMs) excel in representation learning,
they often struggle with adaptive, time-sensitive video retrieval. This paper
introduces a novel framework that combines vector similarity search with
graph-based data structures. By leveraging VLM embeddings for initial retrieval
and modeling contextual relationships among video segments, our approach
enables adaptive query refinement and improves retrieval accuracy. Experiments
demonstrate its precision, scalability, and robustness, offering an effective
solution for interactive video retrieval in dynamic environments.