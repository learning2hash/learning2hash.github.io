---
layout: publication
title: 'Enhancing Subsequent Video Retrieval Via Vision-language Models (vlms)'
authors: Yicheng Duan, Xi Huang, Duo Chen
conference: "Arxiv"
year: 2025
citations: 0
bibkey: duan2025enhancing
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2503.17415'}
tags: ['Tools and Libraries', 'Evaluation Metrics', 'Applications', 'Approximate Nearest Neighbor Search']
---
The rapid growth of video content demands efficient and precise retrieval
systems. While vision-language models (VLMs) excel in representation learning,
they often struggle with adaptive, time-sensitive video retrieval. This paper
introduces a novel framework that combines vector similarity search with
graph-based data structures. By leveraging VLM embeddings for initial retrieval
and modeling contextual relationships among video segments, our approach
enables adaptive query refinement and improves retrieval accuracy. Experiments
demonstrate its precision, scalability, and robustness, offering an effective
solution for interactive video retrieval in dynamic environments.
