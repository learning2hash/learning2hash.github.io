---
layout: publication
title: Hardware-friendly Deep Learning By Network Quantization And Binarization
authors: Haotong Qin
conference: Proceedings of the Thirtieth International Joint Conference on Artificial
  Intelligence
year: 2021
bibkey: qin2021hardware
citations: 4
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2112.00737'}]
tags: ["IJCAI", "Quantization"]
short_authors: Haotong Qin
---
Quantization is emerging as an efficient approach to promote
hardware-friendly deep learning and run deep neural networks on
resource-limited hardware. However, it still causes a significant decrease to
the network in accuracy. We summarize challenges of quantization into two
categories: Quantization for Diverse Architectures and Quantization on Complex
Scenes. Our studies focus mainly on applying quantization on various
architectures and scenes and pushing the limit of quantization to extremely
compress and accelerate networks. The comprehensive research on quantization
will achieve more powerful, more efficient, and more flexible hardware-friendly
deep learning, and make it better suited to more real-world applications.