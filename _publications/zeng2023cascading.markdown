---
layout: publication
title: Cascading Hierarchical Networks With Multi45;task Balanced Loss For Fine45;grained Hashing
authors: Zeng Xianxian, Zheng Yanjun
conference: "Arxiv"
year: 2023
bibkey: zeng2023cascading
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2303.11274"}
  - {name: "Code", url: "https://github.com/kaiba007/FG&#45;CNET"}
tags: ['ARXIV', 'Has Code', 'Supervised']
---
With the explosive growth in the number of fine45;grained images in the Internet era it has become a challenging problem to perform fast and efficient retrieval from large45;scale fine45;grained images. Among the many retrieval methods hashing methods are widely used due to their high efficiency and small storage space occupation. Fine45;grained hashing is more challenging than traditional hashing problems due to the difficulties such as low inter45;class variances and high intra45;class variances caused by the characteristics of fine45;grained images. To improve the retrieval accuracy of fine45;grained hashing we propose a cascaded network to learn compact and highly semantic hash codes and introduce an attention45;guided data augmentation method. We refer to this network as a cascaded hierarchical data augmentation network. We also propose a novel approach to coordinately balance the loss of multi45;task learning. We do extensive experiments on some common fine45;grained visual classification datasets. The experimental results demonstrate that our proposed method outperforms several state45;of45;art hashing methods and can effectively improve the accuracy of fine45;grained retrieval. The source code is publicly available https://github.com/kaiba007/FG&#45;CNET.
