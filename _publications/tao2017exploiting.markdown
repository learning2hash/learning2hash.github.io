---
layout: publication
title: Exploiting Web Images For Weakly Supervised Object Detection
authors: Qingyi Tao, Hao Yang, Jianfei Cai
conference: IEEE Transactions on Multimedia
year: 2018
bibkey: tao2017exploiting
citations: 28
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1707.08721'}]
tags: []
short_authors: Qingyi Tao, Hao Yang, Jianfei Cai
---
In recent years, the performance of object detection has advanced
significantly with the evolving deep convolutional neural networks. However,
the state-of-the-art object detection methods still rely on accurate bounding
box annotations that require extensive human labelling. Object detection
without bounding box annotations, i.e, weakly supervised detection methods, are
still lagging far behind. As weakly supervised detection only uses image level
labels and does not require the ground truth of bounding box location and label
of each object in an image, it is generally very difficult to distill knowledge
of the actual appearances of objects. Inspired by curriculum learning, this
paper proposes an easy-to-hard knowledge transfer scheme that incorporates easy
web images to provide prior knowledge of object appearance as a good starting
point. While exploiting large-scale free web imagery, we introduce a
sophisticated labour free method to construct a web dataset with good diversity
in object appearance. After that, semantic relevance and distribution relevance
are introduced and utilized in the proposed curriculum training scheme. Our
end-to-end learning with the constructed web data achieves remarkable
improvement across most object classes especially for the classes that are
often considered hard in other works.