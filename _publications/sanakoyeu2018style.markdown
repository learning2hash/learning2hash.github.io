---
layout: publication
title: A Style-aware Content Loss For Real-time HD Style Transfer
authors: "Artsiom Sanakoyeu, Dmytro Kotovenko, Sabine Lang, Bj\xF6rn Ommer"
conference: Lecture Notes in Computer Science
year: 2018
bibkey: sanakoyeu2018style
citations: 221
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1807.10201'}]
tags: ["Efficiency"]
short_authors: Sanakoyeu et al.
---
Recently, style transfer has received a lot of attention. While much of this
research has aimed at speeding up processing, the approaches are still lacking
from a principled, art historical standpoint: a style is more than just a
single image or an artist, but previous work is limited to only a single
instance of a style or shows no benefit from more images. Moreover, previous
work has relied on a direct comparison of art in the domain of RGB images or on
CNNs pre-trained on ImageNet, which requires millions of labeled object
bounding boxes and can introduce an extra bias, since it has been assembled
without artistic consideration. To circumvent these issues, we propose a
style-aware content loss, which is trained jointly with a deep encoder-decoder
network for real-time, high-resolution stylization of images and videos. We
propose a quantitative measure for evaluating the quality of a stylized image
and also have art historians rank patches from our approach against those from
previous work. These and our qualitative results ranging from small image
patches to megapixel stylistic images and videos show that our approach better
captures the subtle nature in which a style affects content.