---
layout: publication
title: Does Image Anonymization Impact Computer Vision Training?
authors: "H\xE5kon Hukkel\xE5s, Frank Lindseth"
conference: 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops
  (CVPRW)
year: 2023
bibkey: "hukkel\xE5s2023does"
citations: 12
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2306.05135'}]
tags: ["CVPR"]
short_authors: "H\xE5kon Hukkel\xE5s, Frank Lindseth"
---
Image anonymization is widely adapted in practice to comply with privacy
regulations in many regions. However, anonymization often degrades the quality
of the data, reducing its utility for computer vision development. In this
paper, we investigate the impact of image anonymization for training computer
vision models on key computer vision tasks (detection, instance segmentation,
and pose estimation). Specifically, we benchmark the recognition drop on common
detection datasets, where we evaluate both traditional and realistic
anonymization for faces and full bodies. Our comprehensive experiments reflect
that traditional image anonymization substantially impacts final model
performance, particularly when anonymizing the full body. Furthermore, we find
that realistic anonymization can mitigate this decrease in performance, where
our experiments reflect a minimal performance drop for face anonymization. Our
study demonstrates that realistic anonymization can enable privacy-preserving
computer vision development with minimal performance degradation across a range
of important computer vision benchmarks.