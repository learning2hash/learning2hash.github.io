---
layout: publication
title: Learning Low Dimensional Convolutional Neural Networks For High-resolution
  Remote Sensing Image Retrieval
authors: Weixun Zhou, Shawn Newsam, Congmin Li, Zhenfeng Shao
conference: Remote Sensing
year: 2016
bibkey: zhou2016learning
citations: 176
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1610.03023'}]
tags: ["Datasets", "Evaluation", "Image Retrieval"]
short_authors: Zhou et al.
---
Learning powerful feature representations for image retrieval has always been
a challenging task in the field of remote sensing. Traditional methods focus on
extracting low-level hand-crafted features which are not only time-consuming
but also tend to achieve unsatisfactory performance due to the content
complexity of remote sensing images. In this paper, we investigate how to
extract deep feature representations based on convolutional neural networks
(CNN) for high-resolution remote sensing image retrieval (HRRSIR). To this end,
two effective schemes are proposed to generate powerful feature representations
for HRRSIR. In the first scheme, the deep features are extracted from the
fully-connected and convolutional layers of the pre-trained CNN models,
respectively; in the second scheme, we propose a novel CNN architecture based
on conventional convolution layers and a three-layer perceptron. The novel CNN
model is then trained on a large remote sensing dataset to learn low
dimensional features. The two schemes are evaluated on several public and
challenging datasets, and the results indicate that the proposed schemes and in
particular the novel CNN are able to achieve state-of-the-art performance.