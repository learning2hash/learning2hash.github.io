---
layout: publication
title: 'CPIPS: Learning To Preserve Perceptual Distances In End-to-end Image Compression'
authors: Chen-Hsiu Huang, Ja-Ling Wu
conference: 2023 Asia Pacific Signal and Information Processing Association Annual
  Summit and Conference (APSIPA ASC)
year: 2023
bibkey: huang2023cpips
citations: 1
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2310.00559'}]
tags: ["Distance Metric Learning"]
short_authors: Chen-Hsiu Huang, Ja-Ling Wu
---
Lossy image coding standards such as JPEG and MPEG have successfully achieved
high compression rates for human consumption of multimedia data. However, with
the increasing prevalence of IoT devices, drones, and self-driving cars,
machines rather than humans are processing a greater portion of captured visual
content. Consequently, it is crucial to pursue an efficient compressed
representation that caters not only to human vision but also to image
processing and machine vision tasks. Drawing inspiration from the efficient
coding hypothesis in biological systems and the modeling of the sensory cortex
in neural science, we repurpose the compressed latent representation to
prioritize semantic relevance while preserving perceptual distance. Our
proposed method, Compressed Perceptual Image Patch Similarity (CPIPS), can be
derived at a minimal cost from a learned neural codec and computed
significantly faster than DNN-based perceptual metrics such as LPIPS and DISTS.