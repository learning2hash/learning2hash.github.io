---
layout: publication
title: Cross-modal Content Inference And Feature Enrichment For Cold-start Recommendation
authors: Haokai Ma, Zhuang Qi, Xinxin Dong, Xiangxian Li, Yuze Zheng, Xiangxu Mengand
  Lei Meng
conference: 2023 International Joint Conference on Neural Networks (IJCNN)
year: 2023
bibkey: ma2023cross
citations: 9
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2307.02761'}]
tags: ["Recommender Systems"]
short_authors: Ma et al.
---
Multimedia recommendation aims to fuse the multi-modal information of items
for feature enrichment to improve the recommendation performance. However,
existing methods typically introduce multi-modal information based on
collaborative information to improve the overall recommendation precision,
while failing to explore its cold-start recommendation performance. Meanwhile,
these above methods are only applicable when such multi-modal data is
available. To address this problem, this paper proposes a recommendation
framework, named Cross-modal Content Inference and Feature Enrichment
Recommendation (CIERec), which exploits the multi-modal information to improve
its cold-start recommendation performance. Specifically, CIERec first
introduces image annotation as the privileged information to help guide the
mapping of unified features from the visual space to the semantic space in the
training phase. And then CIERec enriches the content representation with the
fusion of collaborative, visual, and cross-modal inferred representations, so
as to improve its cold-start recommendation performance. Experimental results
on two real-world datasets show that the content representations learned by
CIERec are able to achieve superior cold-start recommendation performance over
existing visually-aware recommendation algorithms. More importantly, CIERec can
consistently achieve significant improvements with different conventional
visually-aware backbones, which verifies its universality and effectiveness.