---
layout: publication
title: 'Partial Visual-semantic Embedding: Fashion Intelligence System With Sensitive
  Part-by-part Learning'
authors: Ryotaro Shimizu, Takuma Nakamura, Masayuki Goto
conference: Arxiv
year: 2022
bibkey: shimizu2022partial
citations: 0
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2211.06688'}]
tags: [Evaluation]
short_authors: Ryotaro Shimizu, Takuma Nakamura, Masayuki Goto
---
In this study, we propose a technology called the Fashion Intelligence System
based on the visual-semantic embedding (VSE) model to quantify abstract and
complex expressions unique to fashion, such as ''casual,'' ''adult-casual,''
and ''office-casual,'' and to support users' understanding of fashion. However,
the existing VSE model does not support the situations in which the image is
composed of multiple parts such as hair, tops, pants, skirts, and shoes. We
propose partial VSE, which enables sensitive learning for each part of the
fashion coordinates. The proposed model partially learns embedded
representations. This helps retain the various existing practical
functionalities and enables image-retrieval tasks in which changes are made
only to the specified parts and image reordering tasks that focus on the
specified parts. This was not possible with conventional models. Based on both
the qualitative and quantitative evaluation experiments, we show that the
proposed model is superior to conventional models without increasing the
computational complexity.