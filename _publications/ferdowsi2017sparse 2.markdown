---
layout: publication
title: Sparse Ternary Codes for similarity search have higher coding gain than dense binary codes
authors: Ferdowsi Sohrab, Voloshynovskiy Slava, Kostadinov Dimche, Holotyak Taras
conference: Arxiv
year: 2017
bibkey: ferdowsi2017sparse
additional_links:
   - {name: "License", url: "http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}
   - {name: "Paper", url: "https://arxiv.org/abs/1701.07675"}
tags: ['Arxiv']
---
This paper addresses the problem of Approximate Nearest Neighbor (ANN) search in pattern recognition where feature vectors in a database are encoded as compact codes in order to speed-up the similarity search in large-scale databases. Considering the ANN problem from an information-theoretic perspective, we interpret it as an encoding, which maps the original feature vectors to a less entropic sparse representation while requiring them to be as informative as possible. We then define the coding gain for ANN search using information-theoretic measures. We next show that the classical approach to this problem, which consists of binarization of the projected vectors is sub-optimal. Instead, a properly designed ternary encoding achieves higher coding gains and lower complexity.
