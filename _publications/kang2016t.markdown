---
layout: publication
title: 'T-CNN: Tubelets With Convolutional Neural Networks For Object Detection From
  Videos'
authors: Kai Kang, Hongsheng Li, Junjie Yan, Xingyu Zeng, Bin Yang, Tong Xiao, Cong
  Zhang, Zhe Wang, Ruohui Wang, Xiaogang Wang, Wanli Ouyang
conference: IEEE Transactions on Circuits and Systems for Video Technology
year: 2017
bibkey: kang2016t
citations: 530
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1604.02532'}]
tags: []
short_authors: Kang et al.
---
The state-of-the-art performance for object detection has been significantly
improved over the past two years. Besides the introduction of powerful deep
neural networks such as GoogleNet and VGG, novel object detection frameworks
such as R-CNN and its successors, Fast R-CNN and Faster R-CNN, play an
essential role in improving the state-of-the-art. Despite their effectiveness
on still images, those frameworks are not specifically designed for object
detection from videos. Temporal and contextual information of videos are not
fully investigated and utilized. In this work, we propose a deep learning
framework that incorporates temporal and contextual information from tubelets
obtained in videos, which dramatically improves the baseline performance of
existing still-image detection frameworks when they are applied to videos. It
is called T-CNN, i.e. tubelets with convolutional neueral networks. The
proposed framework won the recently introduced object-detection-from-video
(VID) task with provided data in the ImageNet Large-Scale Visual Recognition
Challenge 2015 (ILSVRC2015).