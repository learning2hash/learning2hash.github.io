---
layout: publication
title: Could A Large Language Model Be Conscious
authors: David J. Chalmers
conference: "Boston Review August"
year: 2023
bibkey: j2023could
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/http://arxiv.org/abs/2303.07103v3"}
tags: []
---
There has recently been widespread discussion of whether large language models might be sentient. Should we take this idea seriously I will break down the strongest reasons for and against. Given mainstream assumptions in the science of consciousness there are significant obstacles to consciousness in current models for example their lack of recurrent processing a global workspace and unified agency. At the same time it is quite possible that these obstacles will be overcome in the next decade or so. I conclude that while it is somewhat unlikely that current large language models are conscious we should take seriously the possibility that successors to large language models may be conscious in the not-too-distant future.
