---
layout: publication
title: Generalization Bound For Kernel Similarity Learning
authors: Michael Rabadi
conference: In NIPS 2016 Brains and Bits Workshop. Barcelona Spain
year: 2016
bibkey: rabadi2016generalization
citations: 0
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1610.03899'}]
tags: ["Distance Metric Learning", "NEURIPS"]
short_authors: Michael Rabadi
---
Similarity learning has received a large amount of interest and is an
important tool for many scientific and industrial applications. In this
framework, we wish to infer the distance (similarity) between points with
respect to an arbitrary distance function \(d\). Here, we formulate the problem
as a regression from a feature space \(\mathcal\{X\}\) to an arbitrary vector space
\(\mathcal\{Y\}\), where the Euclidean distance is proportional to \(d\). We then
give Rademacher complexity bounds on the generalization error. We find that
with high probability, the complexity is bounded by the maximum of the radius
of \(\mathcal\{X\}\) and the radius of \(\mathcal\{Y\}\).