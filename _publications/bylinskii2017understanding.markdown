---
layout: publication
title: Understanding Infographics Through Textual And Visual Tag Prediction
authors: Zoya Bylinskii, Sami Alsheikh, Spandan Madan, Adria Recasens, Kimberli Zhong,
  Hanspeter Pfister, Fredo Durand, Aude Oliva
conference: Arxiv
year: 2017
bibkey: bylinskii2017understanding
citations: 36
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1709.09215'}]
tags: ["Datasets"]
short_authors: Bylinskii et al.
---
We introduce the problem of visual hashtag discovery for infographics:
extracting visual elements from an infographic that are diagnostic of its
topic. Given an infographic as input, our computational approach automatically
outputs textual and visual elements predicted to be representative of the
infographic content. Concretely, from a curated dataset of 29K large
infographic images sampled across 26 categories and 391 tags, we present an
automated two step approach. First, we extract the text from an infographic and
use it to predict text tags indicative of the infographic content. And second,
we use these predicted text tags as a supervisory signal to localize the most
diagnostic visual elements from within the infographic i.e. visual hashtags. We
report performances on a categorization and multi-label tag prediction problem
and compare our proposed visual hashtags to human annotations.