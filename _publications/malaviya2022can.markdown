---
layout: publication
title: Can Humans Do Less-than-one-shot Learning?
authors: Maya Malaviya, Ilia Sucholutsky, Kerem Oktar, Thomas L. Griffiths
conference: Arxiv
year: 2022
bibkey: malaviya2022can
citations: 3
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2202.04670'}]
tags: ["Few Shot & Zero Shot"]
short_authors: Malaviya et al.
---
Being able to learn from small amounts of data is a key characteristic of
human intelligence, but exactly \{\em how\} small? In this paper, we introduce a
novel experimental paradigm that allows us to examine classification in an
extremely data-scarce setting, asking whether humans can learn more categories
than they have exemplars (i.e., can humans do "less-than-one shot" learning?).
An experiment conducted using this paradigm reveals that people are capable of
learning in such settings, and provides several insights into underlying
mechanisms. First, people can accurately infer and represent high-dimensional
feature spaces from very little data. Second, having inferred the relevant
spaces, people use a form of prototype-based categorization (as opposed to
exemplar-based) to make categorical inferences. Finally, systematic,
machine-learnable patterns in responses indicate that people may have efficient
inductive biases for dealing with this class of data-scarce problems.