---
layout: publication
title: 'Harmful Youtube Video Detection: A Taxonomy Of Online Harm And Mllms As Alternative
  Annotators'
authors: "Claire Wonjeong Jo, Miki Weso\u0142owska, Magdalena Wojcieszak"
conference: Arxiv
year: 2024
bibkey: jo2024harmful
citations: 1
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2411.05854'}]
tags: ["Evaluation", "Privacy & Security", "Survey Paper"]
short_authors: "Claire Wonjeong Jo, Miki Weso\u0142owska, Magdalena Wojcieszak"
---
Short video platforms, such as YouTube, Instagram, or TikTok, are used by
billions of users globally. These platforms expose users to harmful content,
ranging from clickbait or physical harms to misinformation or online hate. Yet,
detecting harmful videos remains challenging due to an inconsistent
understanding of what constitutes harm and limited resources and mental tolls
involved in human annotation. As such, this study advances measures and methods
to detect harm in video content. First, we develop a comprehensive taxonomy for
online harm on video platforms, categorizing it into six categories:
Information, Hate and harassment, Addictive, Clickbait, Sexual, and Physical
harms. Next, we establish multimodal large language models as reliable
annotators of harmful videos. We analyze 19,422 YouTube videos using 14 image
frames, 1 thumbnail, and text metadata, comparing the accuracy of crowdworkers
(Mturk) and GPT-4-Turbo with domain expert annotations serving as the gold
standard. Our results demonstrate that GPT-4-Turbo outperforms crowdworkers in
both binary classification (harmful vs. harmless) and multi-label harm
categorization tasks. Methodologically, this study extends the application of
LLMs to multi-label and multi-modal contexts beyond text annotation and binary
classification. Practically, our study contributes to online harm mitigation by
guiding the definitions and identification of harmful content on video
platforms.