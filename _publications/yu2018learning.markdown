---
layout: publication
title: "Learning Discriminative Hashing Codes for Cross-Modal Retrieval based on Multi-
view Features"
authors: Yu Jun, Wu Xiao-Jun, Kittler Josef
conference: "Arxiv"
year: 2018
bibkey: yu2018learning
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/1808.04152"}
tags: ['ARXIV', 'Cross Modal', 'Quantisation', 'TIP']
---
Hashing techniques have been applied broadly in retrieval tasks due to their low
storage requirements and high speed of processing. Many hashing methods based on
a single view have been extensively studied for information retrieval. However,
the representation capacity of a single view is insufficient and some
discriminative information is not captured, which results in limited
improvement. In this paper, we employ multiple views to represent images and
texts for enriching the feature information. Our framework exploits the
complementary information among multiple views to better learn the
discriminative compact hash codes. A discrete hashing learning framework that
jointly performs classifier learning and subspace learning is proposed to
complete multiple search tasks simultaneously. Our framework includes two
stages, namely a kernelization process and a quantization process. Kernelization
aims to find a common subspace where multi-view features can be fused. The
quantization stage is designed to learn discriminative unified hashing codes.
Extensive experiments are performed on single-label datasets (WiKi and MMED) and
multi-label datasets (MIRFlickr and NUS-WIDE) and the experimental results
indicate the superiority of our method compared with the state-of-the-art
methods.
