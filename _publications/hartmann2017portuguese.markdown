---
layout: publication
title: 'Portuguese Word Embeddings: Evaluating On Word Analogies And Natural Language
  Tasks'
authors: Nathan Hartmann, Erick Fonseca, Christopher Shulby, Marcos Treviso, Jessica
  Rodrigues, Sandra Aluisio
conference: Arxiv
year: 2017
bibkey: hartmann2017portuguese
citations: 150
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1708.06025'}]
tags: ["Evaluation"]
short_authors: Hartmann et al.
---
Word embeddings have been found to provide meaningful representations for
words in an efficient way; therefore, they have become common in Natural
Language Processing sys- tems. In this paper, we evaluated different word
embedding models trained on a large Portuguese corpus, including both Brazilian
and European variants. We trained 31 word embedding models using FastText,
GloVe, Wang2Vec and Word2Vec. We evaluated them intrinsically on syntactic and
semantic analogies and extrinsically on POS tagging and sentence semantic
similarity tasks. The obtained results suggest that word analogies are not
appropriate for word embedding evaluation; task-specific evaluations appear to
be a better option.