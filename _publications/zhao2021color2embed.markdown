---
layout: publication
title: 'Color2embed: Fast Exemplar-based Image Colorization Using Color Embeddings'
authors: Hengyuan Zhao, Wenhao Wu, Yihao Liu, Dongliang He
conference: Arxiv
year: 2021
bibkey: zhao2021color2embed
citations: 12
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2106.08017'}]
tags: []
short_authors: Zhao et al.
---
In this paper, we present a fast exemplar-based image colorization approach
using color embeddings named Color2Embed. Generally, due to the difficulty of
obtaining input and ground truth image pairs, it is hard to train a
exemplar-based colorization model with unsupervised and unpaired training
manner. Current algorithms usually strive to achieve two procedures: i)
retrieving a large number of reference images with high similarity for
preparing training dataset, which is inevitably time-consuming and tedious; ii)
designing complicated modules to transfer the colors of the reference image to
the target image, by calculating and leveraging the deep semantic
correspondence between them (e.g., non-local operation), which is
computationally expensive during testing. Contrary to the previous methods, we
adopt a self-augmented self-reference learning scheme, where the reference
image is generated by graphical transformations from the original colorful one
whereby the training can be formulated in a paired manner. Second, in order to
reduce the process time, our method explicitly extracts the color embeddings
and exploits a progressive style feature Transformation network, which injects
the color embeddings into the reconstruction of the final image. Such design is
much more lightweight and intelligible, achieving appealing performance with
fast processing speed.