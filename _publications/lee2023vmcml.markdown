---
layout: publication
title: 'VMCML: Video And Music Matching Via Cross-modality Lifting'
authors: Lee Yi-shan, Tseng Wei-cheng, Wang Fu-en, Sun Min
conference: 2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops
  (CVPRW)
year: 2024
bibkey: lee2023vmcml
citations: 0
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2303.12379'}]
tags: ["Audio Retrieval", "CVPR", "Datasets", "Evaluation", "Multimodal Retrieval", "Recommender Systems", "Video Retrieval"]
short_authors: Lee et al.
---
We propose a content-based system for matching video and background music.
The system aims to address the challenges in music recommendation for new users
or new music give short-form videos. To this end, we propose a cross-modal
framework VMCML that finds a shared embedding space between video and music
representations. To ensure the embedding space can be effectively shared by
both representations, we leverage CosFace loss based on margin-based cosine
similarity loss. Furthermore, we establish a large-scale dataset called MSVD,
in which we provide 390 individual music and the corresponding matched 150,000
videos. We conduct extensive experiments on Youtube-8M and our MSVD datasets.
Our quantitative and qualitative results demonstrate the effectiveness of our
proposed framework and achieve state-of-the-art video and music matching
performance.