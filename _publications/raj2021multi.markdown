---
layout: publication
title: Multi-image Visual Question Answering
authors: Harsh Raj, Janhavi Dadhania, Akhilesh Bhardwaj, Prabuchandran Kj
conference: Arxiv
year: 2021
bibkey: raj2021multi
citations: 1
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2112.13706'}]
tags: ["Datasets", "Evaluation"]
short_authors: Raj et al.
---
While a lot of work has been done on developing models to tackle the problem
of Visual Question Answering, the ability of these models to relate the
question to the image features still remain less explored. We present an
empirical study of different feature extraction methods with different loss
functions. We propose New dataset for the task of Visual Question Answering
with multiple image inputs having only one ground truth, and benchmark our
results on them. Our final model utilising Resnet + RCNN image features and
Bert embeddings, inspired from stacked attention network gives 39% word
accuracy and 99% image accuracy on CLEVER+TinyImagenet dataset.