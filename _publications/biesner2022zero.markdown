---
layout: publication
title: Zero-shot Text Matching For Automated Auditing Using Sentence Transformers
authors: "David Biesner, Maren Pielka, Rajkumar Ramamurthy, Tim Dilmaghani, Bernd\
  \ Kliem, R\xFCdiger Loitz, Rafet Sifa"
conference: 2022 21st IEEE International Conference on Machine Learning and Applications
  (ICMLA)
year: 2022
bibkey: biesner2022zero
citations: 4
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2211.07716'}]
tags: ["Efficiency", "Few Shot & Zero Shot", "Unsupervised"]
short_authors: Biesner et al.
---
Natural language processing methods have several applications in automated
auditing, including document or passage classification, information retrieval,
and question answering. However, training such models requires a large amount
of annotated data which is scarce in industrial settings. At the same time,
techniques like zero-shot and unsupervised learning allow for application of
models pre-trained using general domain data to unseen domains.
  In this work, we study the efficiency of unsupervised text matching using
Sentence-Bert, a transformer-based model, by applying it to the semantic
similarity of financial passages. Experimental results show that this model is
robust to documents from in- and out-of-domain data.