---
layout: publication
title: Context-aware Temporal Embedding Of Objects In Video Data
authors: Ahnaf Farhan, M. Shahriar Hossain
conference: Arxiv
year: 2024
bibkey: farhan2024context
citations: 0
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2408.12789'}]
tags: ["Video Retrieval"]
short_authors: Ahnaf Farhan, M. Shahriar Hossain
---
In video analysis, understanding the temporal context is crucial for
recognizing object interactions, event patterns, and contextual changes over
time. The proposed model leverages adjacency and semantic similarities between
objects from neighboring video frames to construct context-aware temporal
object embeddings. Unlike traditional methods that rely solely on visual
appearance, our temporal embedding model considers the contextual relationships
between objects, creating a meaningful embedding space where temporally
connected object's vectors are positioned in proximity. Empirical studies
demonstrate that our context-aware temporal embeddings can be used in
conjunction with conventional visual embeddings to enhance the effectiveness of
downstream applications. Moreover, the embeddings can be used to narrate a
video using a Large Language Model (LLM). This paper describes the intricate
details of the proposed objective function to generate context-aware temporal
object embeddings for video data and showcases the potential applications of
the generated embeddings in video analysis and object classification tasks.