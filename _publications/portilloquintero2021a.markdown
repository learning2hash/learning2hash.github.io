---
layout: publication
title: A Straightforward Framework For Video Retrieval Using CLIP
authors: "Jes\xFAs Andr\xE9s Portillo-Quintero, Jos\xE9 Carlos Ortiz-Bayliss, Hugo\
  \ Terashima-Mar\xEDn"
conference: Lecture Notes in Computer Science
year: 2021
bibkey: portilloquintero2021a
citations: 79
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2102.12443'}]
tags: ["Tools & Libraries", "Video Retrieval"]
short_authors: "Jes\xFAs Andr\xE9s Portillo-Quintero, Jos\xE9 Carlos Ortiz-Bayliss,\
  \ Hugo Terashima-Mar\xEDn"
---
Video Retrieval is a challenging task where a text query is matched to a
video or vice versa. Most of the existing approaches for addressing such a
problem rely on annotations made by the users. Although simple, this approach
is not always feasible in practice. In this work, we explore the application of
the language-image model, CLIP, to obtain video representations without the
need for said annotations. This model was explicitly trained to learn a common
space where images and text can be compared. Using various techniques described
in this document, we extended its application to videos, obtaining
state-of-the-art results on the MSR-VTT and MSVD benchmarks.