---
layout: publication
title: Contrastive Language-image Pre-training For The Italian Language
authors: Federico Bianchi, Giuseppe Attanasio, Raphael Pisoni, Silvia Terragni, Gabriele
  Sarti, Sri Lakshmi
conference: Arxiv
year: 2021
bibkey: bianchi2021contrastive
citations: 19
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2108.08688'}]
tags: ["Few Shot & Zero Shot"]
short_authors: Bianchi et al.
---
CLIP (Contrastive Language-Image Pre-training) is a very recent multi-modal
model that jointly learns representations of images and texts. The model is
trained on a massive amount of English data and shows impressive performance on
zero-shot classification tasks. Training the same model on a different language
is not trivial, since data in other languages might be not enough and the model
needs high-quality translations of the texts to guarantee a good performance.
In this paper, we present the first CLIP model for the Italian Language
(CLIP-Italian), trained on more than 1.4 million image-text pairs. Results show
that CLIP-Italian outperforms the multilingual CLIP model on the tasks of image
retrieval and zero-shot classification.