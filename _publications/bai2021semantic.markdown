---
layout: publication
title: Semantic-sparse Colorization Network For Deep Exemplar-based Colorization
authors: Yunpeng Bai, Chao Dong, Zenghao Chai, Andong Wang, Zhengzhuo Xu, Chun Yuan
conference: Lecture Notes in Computer Science
year: 2022
bibkey: bai2021semantic
citations: 10
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2112.01335'}]
tags: []
short_authors: Bai et al.
---
Exemplar-based colorization approaches rely on reference image to provide
plausible colors for target gray-scale image. The key and difficulty of
exemplar-based colorization is to establish an accurate correspondence between
these two images. Previous approaches have attempted to construct such a
correspondence but are faced with two obstacles. First, using luminance
channels for the calculation of correspondence is inaccurate. Second, the dense
correspondence they built introduces wrong matching results and increases the
computation burden. To address these two problems, we propose Semantic-Sparse
Colorization Network (SSCN) to transfer both the global image style and
detailed semantic-related colors to the gray-scale image in a coarse-to-fine
manner. Our network can perfectly balance the global and local colors while
alleviating the ambiguous matching problem. Experiments show that our method
outperforms existing methods in both quantitative and qualitative evaluation
and achieves state-of-the-art performance.