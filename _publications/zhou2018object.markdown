---
layout: publication
title: Object Relation Detection Based On One-shot Learning
authors: Li Zhou, Jian Zhao, Jianshu Li, Li Yuan, Jiashi Feng
conference: Arxiv
year: 2018
bibkey: zhou2018object
citations: 17
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1807.05857'}]
tags: []
short_authors: Zhou et al.
---
Detecting the relations among objects, such as "cat on sofa" and "person ride
horse", is a crucial task in image understanding, and beneficial to bridging
the semantic gap between images and natural language. Despite the remarkable
progress of deep learning in detection and recognition of individual objects,
it is still a challenging task to localize and recognize the relations between
objects due to the complex combinatorial nature of various kinds of object
relations. Inspired by the recent advances in one-shot learning, we propose a
simple yet effective Semantics Induced Learner (SIL) model for solving this
challenging task. Learning in one-shot manner can enable a detection model to
adapt to a huge number of object relations with diverse appearance effectively
and robustly. In addition, the SIL combines bottom-up and top-down attention
mech- anisms, therefore enabling attention at the level of vision and semantics
favorably. Within our proposed model, the bottom-up mechanism, which is based
on Faster R-CNN, proposes objects regions, and the top-down mechanism selects
and integrates visual features according to semantic information. Experiments
demonstrate the effectiveness of our framework over other state-of-the-art
methods on two large-scale data sets for object relation detection.