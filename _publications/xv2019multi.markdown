---
layout: publication
title: Multi-level Similarity Learning For Low-shot Recognition
authors: Hongwei Xv, Xin Sun, Junyu Dong, Shu Zhang, Qiong Li
conference: 2019 IEEE SmartWorld, Ubiquitous Intelligence &amp; Computing, Advanced
  &amp; Trusted Computing, Scalable Computing &amp; Communications, Cloud &amp; Big
  Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)
year: 2019
bibkey: xv2019multi
citations: 1
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1912.06418'}]
tags: ["Datasets", "Distance Metric Learning", "Few Shot & Zero Shot"]
short_authors: Xv et al.
---
Low-shot learning indicates the ability to recognize unseen objects based on
very limited labeled training samples, which simulates human visual
intelligence. According to this concept, we propose a multi-level similarity
model (MLSM) to capture the deep encoded distance metric between the support
and query samples. Our approach is achieved based on the fact that the image
similarity learning can be decomposed into image-level, global-level, and
object-level. Once the similarity function is established, MLSM will be able to
classify images for unseen classes by computing the similarity scores between a
limited number of labeled samples and the target images. Furthermore, we
conduct 5-way experiments with both 1-shot and 5-shot setting on Caltech-UCSD
datasets. It is demonstrated that the proposed model can achieve promising
results compared with the existing methods in practical applications.