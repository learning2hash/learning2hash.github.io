---
layout: publication
title: Predicting Visual Exemplars Of Unseen Classes For Zero-shot Learning
authors: Soravit Changpinyo, Wei-lun Chao, Fei Sha
conference: 2017 IEEE International Conference on Computer Vision (ICCV)
year: 2017
bibkey: changpinyo2016predicting
citations: 190
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1605.08151'}]
tags: ["ICCV"]
short_authors: Soravit Changpinyo, Wei-lun Chao, Fei Sha
---
Leveraging class semantic descriptions and examples of known objects,
zero-shot learning makes it possible to train a recognition model for an object
class whose examples are not available. In this paper, we propose a novel
zero-shot learning model that takes advantage of clustering structures in the
semantic embedding space. The key idea is to impose the structural constraint
that semantic representations must be predictive of the locations of their
corresponding visual exemplars. To this end, this reduces to training multiple
kernel-based regressors from semantic representation-exemplar pairs from
labeled data of the seen object categories. Despite its simplicity, our
approach significantly outperforms existing zero-shot learning methods on
standard benchmark datasets, including the ImageNet dataset with more than
20,000 unseen categories.