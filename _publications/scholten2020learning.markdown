---
layout: publication
title: Learning To Recognise Words Using Visually Grounded Speech
authors: Sebastiaan Scholten, Danny Merkx, Odette Scharenborg
conference: 2021 IEEE International Symposium on Circuits and Systems (ISCAS)
year: 2020
bibkey: scholten2020learning
citations: 2
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2006.00512'}]
tags: ["Image Retrieval", "Multimodal Retrieval"]
short_authors: Sebastiaan Scholten, Danny Merkx, Odette Scharenborg
---
We investigated word recognition in a Visually Grounded Speech model. The
model has been trained on pairs of images and spoken captions to create
visually grounded embeddings which can be used for speech to image retrieval
and vice versa. We investigate whether such a model can be used to recognise
words by embedding isolated words and using them to retrieve images of their
visual referents. We investigate the time-course of word recognition using a
gating paradigm and perform a statistical analysis to see whether well known
word competition effects in human speech processing influence word recognition.
Our experiments show that the model is able to recognise words, and the gating
paradigm reveals that words can be recognised from partial input as well and
that recognition is negatively influenced by word competition from the word
initial cohort.