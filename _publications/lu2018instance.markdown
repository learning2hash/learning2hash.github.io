---
layout: publication
title: Instance-level Sketch-based Retrieval By Deep Triplet Classification Siamese
  Network
authors: Peng Lu, Hangyu Lin, Yanwei Fu, Shaogang Gong, Yu-Gang Jiang, Xiangyang Xue
conference: Arxiv
year: 2018
bibkey: lu2018instance
citations: 2
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1811.11375'}]
tags: [Image Retrieval, Evaluation, Datasets]
short_authors: Lu et al.
---
Sketch has been employed as an effective communicative tool to express the
abstract and intuitive meanings of object. Recognizing the free-hand sketch
drawing is extremely useful in many real-world applications. While
content-based sketch recognition has been studied for several decades, the
instance-level Sketch-Based Image Retrieval (SBIR) tasks have attracted
significant research attention recently. The existing datasets such as
QMUL-Chair and QMUL-Shoe, focus on the retrieval tasks of chairs and shoes.
However, there are several key limitations in previous instance-level SBIR
works. The state-of-the-art works have to heavily rely on the pre-training
process, quality of edge maps, multi-cropping testing strategy, and augmenting
sketch images. To efficiently solve the instance-level SBIR, we propose a new
Deep Triplet Classification Siamese Network (DeepTCNet) which employs
DenseNet-169 as the basic feature extractor and is optimized by the triplet
loss and classification loss. Critically, our proposed DeepTCNet can break the
limitations existed in previous works. The extensive experiments on five
benchmark sketch datasets validate the effectiveness of the proposed model.
Additionally, to study the tasks of sketch-based hairstyle retrieval, this
paper contributes a new instance-level photo-sketch dataset - Hairstyle
Photo-Sketch dataset, which is composed of 3600 sketches and photos, and 2400
sketch-photo pairs.