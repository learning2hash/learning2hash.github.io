---
layout: publication
title: Instance-level Sketch-based Retrieval By Deep Triplet Classification Siamese Network
authors: Lu Peng, Lin Hangyu, Fu Yanwei, Gong Shaogang, Jiang Yu-gang, Xue Xiangyang
conference: "Arxiv"
year: 2018
bibkey: lu2018instance
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/1811.11375"}
tags: ['ARXIV', 'Image Retrieval', 'Supervised']
---
<p>Sketch has been employed as an effective communicative tool to
express the abstract and intuitive meanings of object. Recognizing the
free-hand sketch drawing is extremely useful in many real-world
applications. While content-based sketch recognition has been studied
for several decades, the instance-level Sketch-Based Image Retrieval
(SBIR) tasks have attracted significant research attention recently. The
existing datasets such as QMUL-Chair and QMUL-Shoe, focus on the
retrieval tasks of chairs and shoes. However, there are several key
limitations in previous instance-level SBIR works. The state-of-the-art
works have to heavily rely on the pre-training process, quality of edge
maps, multi-cropping testing strategy, and augmenting sketch images. To
efficiently solve the instance-level SBIR, we propose a new Deep Triplet
Classification Siamese Network (DeepTCNet) which employs DenseNet-169 as
the basic feature extractor and is optimized by the triplet loss and
classification loss. Critically, our proposed DeepTCNet can break the
limitations existed in previous works. The extensive experiments on five
benchmark sketch datasets validate the effectiveness of the proposed
model. Additionally, to study the tasks of sketch-based hairstyle
retrieval, this paper contributes a new instance-level photo-sketch
dataset - Hairstyle Photo-Sketch dataset, which is composed of 3600
sketches and photos, and 2400 sketch-photo pairs.</p>
