---
layout: publication
title: 'MIP-GAF: A Mllm-annotated Benchmark For Most Important Person Localization
  And Group Context Understanding'
authors: Surbhi Madan, Shreya Ghosh, Lownish Rai Sookha, M. A. Ganaie, Ramanathan
  Subramanian, Abhinav Dhall, Tom Gedeon
conference: 2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)
year: 2025
bibkey: madan2024mip
citations: 0
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2409.06224'}]
tags: ["Datasets", "Evaluation"]
short_authors: Madan et al.
---
Estimating the Most Important Person (MIP) in any social event setup is a
challenging problem mainly due to contextual complexity and scarcity of labeled
data. Moreover, the causality aspects of MIP estimation are quite subjective
and diverse. To this end, we aim to address the problem by annotating a
large-scale `in-the-wild' dataset for identifying human perceptions about the
`Most Important Person (MIP)' in an image. The paper provides a thorough
description of our proposed Multimodal Large Language Model (MLLM) based data
annotation strategy, and a thorough data quality analysis. Further, we perform
a comprehensive benchmarking of the proposed dataset utilizing state-of-the-art
MIP localization methods, indicating a significant drop in performance compared
to existing datasets. The performance drop shows that the existing MIP
localization algorithms must be more robust with respect to `in-the-wild'
situations. We believe the proposed dataset will play a vital role in building
the next-generation social situation understanding methods. The code and data
is available at https://github.com/surbhimadan92/MIP-GAF.