---
layout: publication
title: R\'enyi Divergence Guarantees For Hashing With Linear Codes
authors: Madhura Pathegama, Alexander Barg
conference: Arxiv
year: 2024
bibkey: pathegama2024r
citations: 0
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2405.04406'}]
tags: ["Hashing Methods"]
short_authors: Madhura Pathegama, Alexander Barg
---
We consider the problem of distilling uniform random bits from an unknown source with a given \(p\)-entropy using linear hashing. As our main result, we estimate the expected \(p\)-divergence from the uniform distribution over the ensemble of random linear codes for all integer \(p\ge 2\). The proof relies on analyzing how additive noise, determined by a random element of the code from the ensemble, acts on the source distribution. This action leads to the transformation of the source distribution into an approximately uniform one, a process commonly referred to as distribution smoothing. We also show that hashing with Reed-Muller matrices reaches intrinsic randomness of memoryless Bernoulli sources in the \(l_p\) sense for all integer \(p\ge 2\).