---
layout: publication
title: On The Complementarity Of Images And Text For The Expression Of Emotions In
  Social Media
authors: Anna Khlyzova, Carina Silberer, Roman Klinger
conference: Proceedings of the 12th Workshop on Computational Approaches to Subjectivity,
  Sentiment &amp; Social Media Analysis
year: 2022
bibkey: khlyzova2022complementarity
citations: 3
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2202.07427'}]
tags: ["Multimodal Retrieval"]
short_authors: Anna Khlyzova, Carina Silberer, Roman Klinger
---
Authors of posts in social media communicate their emotions and what causes
them with text and images. While there is work on emotion and stimulus
detection for each modality separately, it is yet unknown if the modalities
contain complementary emotion information in social media. We aim at filling
this research gap and contribute a novel, annotated corpus of English
multimodal Reddit posts. On this resource, we develop models to automatically
detect the relation between image and text, an emotion stimulus category and
the emotion class. We evaluate if these tasks require both modalities and find
for the image-text relations, that text alone is sufficient for most categories
(complementary, illustrative, opposing): the information in the text allows to
predict if an image is required for emotion understanding. The emotions of
anger and sadness are best predicted with a multimodal model, while text alone
is sufficient for disgust, joy, and surprise. Stimuli depicted by objects,
animals, food, or a person are best predicted by image-only models, while
multimodal models are most effective on art, events, memes, places, or
screenshots.