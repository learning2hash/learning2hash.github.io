---
layout: publication
title: Unsupervised Multi-modal Hashing For Cross-modal Retrieval
authors: Jun Yu, Xiao-jun Wu
conference: Arxiv
year: 2019
citations: 9
bibkey: yu2019unsupervised
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1904.00726'}]
tags: [Unsupervised, Tools and Libraries, Multi-Modal Hashing, Supervised, Hashing
    Methods]
---
With the advantage of low storage cost and high efficiency, hashing learning
has received much attention in the domain of Big Data. In this paper, we
propose a novel unsupervised hashing learning method to cope with this open
problem to directly preserve the manifold structure by hashing. To address this
problem, both the semantic correlation in textual space and the locally
geometric structure in the visual space are explored simultaneously in our
framework. Besides, the `2;1-norm constraint is imposed on the projection
matrices to learn the discriminative hash function for each modality. Extensive
experiments are performed to evaluate the proposed method on the three publicly
available datasets and the experimental results show that our method can
achieve superior performance over the state-of-the-art methods.