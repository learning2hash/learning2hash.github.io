---
layout: publication
title: Discriminative Supervised Hashing for Cross-Modal similarity Search
authors: Yu Jun, Wu Xiao-jun, Kittler Josef
conference: Image and Vision Computing
year: 2019
bibkey: yu2019discriminative
citations: 15
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1812.07660'}]
tags: ["Similarity-Search", "Neural-Hashing", "Hashing-Methods", "Supervised"]
---
With the advantage of low storage cost and high retrieval efficiency, hashing
techniques have recently been an emerging topic in cross-modal similarity
search. As multiple modal data reflect similar semantic content, many
researches aim at learning unified binary codes. However, discriminative
hashing features learned by these methods are not adequate. This results in
lower accuracy and robustness. We propose a novel hashing learning framework
which jointly performs classifier learning, subspace learning and matrix
factorization to preserve class-specific semantic content, termed
Discriminative Supervised Hashing (DSH), to learn the discrimative unified
binary codes for multi-modal data. Besides, reducing the loss of information
and preserving the non-linear structure of data, DSH non-linearly projects
different modalities into the common space in which the similarity among
heterogeneous data points can be measured. Extensive experiments conducted on
the three publicly available datasets demonstrate that the framework proposed
in this paper outperforms several state-of -the-art methods.