---
layout: publication
title: AMBER An Llm-free Multi-dimensional Benchmark For Mllms Hallucination Evaluation
authors: Junyang Wang, Yuhang Wang, Guohai Xu, Jing Zhang, Yukai Gu, Haitao Jia, Jiaqi Wang, Haiyang Xu, Ming Yan, Ji Zhang, Jitao Sang
conference: "Arxiv"
year: 2023
bibkey: wang2023amber
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/http://arxiv.org/abs/2311.07397v2"}
  - {name: "Code", url: "https://github.com/junyangwang0410/AMBER"}
tags: ['ARXIV', 'Has Code']
---
Despite making significant progress in multi-modal tasks current Multi-modal Large Language Models (MLLMs) encounter the significant challenge of hallucinations which may lead to harmful consequences. Therefore evaluating MLLMs hallucinations is becoming increasingly important in model improvement and practical application deployment. Previous works are limited in high evaluation costs (e.g. relying on humans or advanced LLMs) and insufficient evaluation dimensions (e.g. types of tasks and hallucinations). In this paper we propose an LLM-free multi-dimensional benchmark AMBER which can be used to evaluate both generative task and discriminative task including existence attribute and relation hallucination. Based on AMBER we design a low-cost and efficient evaluation pipeline. Additionally we conduct a comprehensive evaluation and detailed analysis of mainstream MLLMs including GPT-4V(ision) and also give guideline suggestions for mitigating hallucinations. The data and code of AMBER are available at https://github.com/junyangwang0410/AMBER.
