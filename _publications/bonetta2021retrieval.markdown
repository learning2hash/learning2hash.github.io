---
layout: publication
title: Retrieval-augmented Transformer-xl For Close-domain Dialog Generation
authors: Giovanni Bonetta, Rossella Cancelliere, Ding Liu, Paul Vozila
conference: The International FLAIRS Conference Proceedings
year: 2021
bibkey: bonetta2021retrieval
citations: 9
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2105.09235'}]
tags: ["Datasets"]
short_authors: Bonetta et al.
---
Transformer-based models have demonstrated excellent capabilities of
capturing patterns and structures in natural language generation and achieved
state-of-the-art results in many tasks. In this paper we present a
transformer-based model for multi-turn dialog response generation. Our solution
is based on a hybrid approach which augments a transformer-based generative
model with a novel retrieval mechanism, which leverages the memorized
information in the training data via k-Nearest Neighbor search. Our system is
evaluated on two datasets made by customer/assistant dialogs: the Taskmaster-1,
released by Google and holding high quality, goal-oriented conversational data
and a proprietary dataset collected from a real customer service call center.
Both achieve better BLEU scores over strong baselines.