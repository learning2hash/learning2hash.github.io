---
layout: publication
title: Contextualized End-to-end Neural Entity Linking
authors: Haotian Chen, Andrej Zukov-gregoric, Xi David Li, Sahil Wadhwa
conference: Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association
  for Computational Linguistics and the 10th International Joint Conference on Natural
  Language Processing
year: 2020
bibkey: chen2019contextualized
citations: 6
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1911.03834'}]
tags: []
short_authors: Chen et al.
---
We propose yet another entity linking model (YELM) which links words to
entities instead of spans. This overcomes any difficulties associated with the
selection of good candidate mention spans and makes the joint training of
mention detection (MD) and entity disambiguation (ED) easily possible. Our
model is based on BERT and produces contextualized word embeddings which are
trained against a joint MD and ED objective. We achieve state-of-the-art
results on several standard entity linking (EL) datasets.