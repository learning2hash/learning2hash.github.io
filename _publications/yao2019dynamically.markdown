---
layout: publication
title: Dynamically Visual Disambiguation Of Keyword-based Image Search
authors: Yazhou Yao, Zeren Sun, Fumin Shen, Li Liu, Limin Wang, Fan Zhu, Lizhong Ding,
  Gangshan Wu, Ling Shao
conference: Proceedings of the Twenty-Eighth International Joint Conference on Artificial
  Intelligence
year: 2019
bibkey: yao2019dynamically
citations: 16
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1905.10955'}]
tags: ["IJCAI", "Image Retrieval"]
short_authors: Yao et al.
---
Due to the high cost of manual annotation, learning directly from the web has
attracted broad attention. One issue that limits their performance is the
problem of visual polysemy. To address this issue, we present an adaptive
multi-model framework that resolves polysemy by visual disambiguation. Compared
to existing methods, the primary advantage of our approach lies in that our
approach can adapt to the dynamic changes in the search results. Our proposed
framework consists of two major steps: we first discover and dynamically select
the text queries according to the image search results, then we employ the
proposed saliency-guided deep multi-instance learning network to remove
outliers and learn classification models for visual disambiguation. Extensive
experiments demonstrate the superiority of our proposed approach.