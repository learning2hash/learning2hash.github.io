---
layout: publication
title: Video-based Person Re-identification With Two-stream Convolutional Network
  And Co-attentive Snippet Embedding
authors: Peixian Chen, Pingyang Dai, Qiong Wu, Yuyu Huang
conference: Arxiv
year: 2019
bibkey: chen2019video
citations: 0
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1905.11862'}]
tags: ["Datasets"]
short_authors: Chen et al.
---
Recently, the applications of person re-identification in visual surveillance
and human-computer interaction are sharply increasing, which signifies the
critical role of such a problem. In this paper, we propose a two-stream
convolutional network (ConvNet) based on the competitive similarity aggregation
scheme and co-attentive embedding strategy for video-based person
re-identification. By dividing the long video sequence into multiple short
video snippets, we manage to utilize every snippet's RGB frames, optical flow
maps and pose maps to facilitate residual networks, e.g., ResNet, for feature
extraction in the two-stream ConvNet. The extracted features are embedded by
the co-attentive embedding method, which allows for the reduction of the
effects of noisy frames. Finally, we fuse the outputs of both streams as the
embedding of a snippet, and apply competitive snippet-similarity aggregation to
measure the similarity between two sequences. Our experiments show that the
proposed method significantly outperforms current state-of-the-art approaches
on multiple datasets.