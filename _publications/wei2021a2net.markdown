---
layout: publication
title: A^2-Net Learning Attribute-Aware Hash Codes for Large-Scale Fine-Grained Image Retrieval
authors: Xiu-Shen Wei, Yang Shen, Xuhao Sun, Han-Jia Ye, Jian Yang
conference: "Neural Information Processing Systems"
year: 2021
bibkey: wei2021a2net
additional_links:
  - {name: "Paper", url: "https://papers.nips.cc/paper/2021/hash/2d3acd3e240c61820625fff66a19938f-Abstract.html"}
tags: ['Image Retrieval', 'NEURIPS', 'Supervised', 'Unsupervised']
---
Our work focuses on tackling large-scale fine-grained image retrieval as ranking the images depicting the concept of interests (i.e. the same sub-category labels) highest based on the fine-grained details in the query. It is desirable to alleviate the challenges of both fine-grained nature of small inter-class variations with large intra-class variations and explosive growth of fine-grained data for such a practical task. In this paper we propose an Attribute-Aware hashing Network (A^2-Net) for generating attribute-aware hash codes to not only make the retrieval process efficient but also establish explicit correspondences between hash codes and visual attributes. Specifically based on the captured visual representations by attention we develop an encoder-decoder structure network of a reconstruction task to unsupervisedly distill high-level attribute-specific vectors from the appearance-specific visual representations without attribute annotations. A^2-Net is also equipped with a feature decorrelation constraint upon these attribute vectors to enhance their representation abilities. Finally the required hash codes are generated by the attribute vectors driven by preserving original similarities. Qualitative experiments on five benchmark fine-grained datasets show our superiority over competing methods. More importantly quantitative results demonstrate the obtained hash codes can strongly correspond to certain kinds of crucial properties of fine-grained objects.
