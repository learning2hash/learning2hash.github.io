---
layout: publication
title: Explainable Search And Discovery Of Visual Cultural Heritage Collections With
  Multimodal Large Language Models
authors: Taylor Arnold, Lauren Tilton
conference: Arxiv
year: 2024
bibkey: arnold2024explainable
citations: 0
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2411.04663'}]
tags: ["Recommender Systems"]
short_authors: Taylor Arnold, Lauren Tilton
---
Many cultural institutions have made large digitized visual collections
available online, often under permissible re-use licences. Creating interfaces
for exploring and searching these collections is difficult, particularly in the
absence of granular metadata. In this paper, we introduce a method for using
state-of-the-art multimodal large language models (LLMs) to enable an
open-ended, explainable search and discovery interface for visual collections.
We show how our approach can create novel clustering and recommendation systems
that avoid common pitfalls of methods based directly on visual embeddings. Of
particular interest is the ability to offer concrete textual explanations of
each recommendation without the need to preselect the features of interest.
Together, these features can create a digital interface that is more open-ended
and flexible while also being better suited to addressing privacy and ethical
concerns. Through a case study using a collection of documentary photographs,
we provide several metrics showing the efficacy and possibilities of our
approach.