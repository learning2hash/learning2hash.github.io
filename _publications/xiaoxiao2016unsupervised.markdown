---
layout: publication
title: Unsupervised Place Discovery For Visual Place Classification
authors: Fei Xiaoxiao, Tanaka Kanji, Inamoto Kouya
conference: Arxiv
year: 2016
bibkey: xiaoxiao2016unsupervised
citations: 3
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1612.06933'}]
tags: ["Unsupervised"]
short_authors: Fei Xiaoxiao, Tanaka Kanji, Inamoto Kouya
---
In this study, we explore the use of deep convolutional neural networks
(DCNNs) in visual place classification for robotic mapping and localization. An
open question is how to partition the robot's workspace into places to maximize
the performance (e.g., accuracy, precision, recall) of potential DCNN
classifiers. This is a chicken and egg problem: If we had a well-trained DCNN
classifier, it is rather easy to partition the robot's workspace into places,
but the training of a DCNN classifier requires a set of pre-defined place
classes. In this study, we address this problem and present several strategies
for unsupervised discovery of place classes ("time cue," "location cue,"
"time-appearance cue," and "location-appearance cue"). We also evaluate the
efficacy of the proposed methods using the publicly available University of
Michigan North Campus Long-Term (NCLT) Dataset.