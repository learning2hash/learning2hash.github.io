---
layout: publication
title: Learning Meta-embeddings By Using Ensembles Of Embedding Sets
authors: "Wenpeng Yin, Hinrich Sch\xFCtze"
conference: Arxiv
year: 2015
bibkey: yin2015learning
citations: 8
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1508.04257'}]
tags: []
short_authors: "Wenpeng Yin, Hinrich Sch\xFCtze"
---
Word embeddings -- distributed representations of words -- in deep learning
are beneficial for many tasks in natural language processing (NLP). However,
different embedding sets vary greatly in quality and characteristics of the
captured semantics. Instead of relying on a more advanced algorithm for
embedding learning, this paper proposes an ensemble approach of combining
different public embedding sets with the aim of learning meta-embeddings.
Experiments on word similarity and analogy tasks and on part-of-speech tagging
show better performance of meta-embeddings compared to individual embedding
sets. One advantage of meta-embeddings is the increased vocabulary coverage. We
will release our meta-embeddings publicly.