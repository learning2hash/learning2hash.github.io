---
layout: publication
title: 'Item: Unsupervised Image-text Embedding Learning For Ecommerce'
authors: Baohao Liao, Michael Kozielski, Sanjika Hewavitharana, Jiangbo Yuan, Shahram
  Khadivi, Tomer Lancewicki
conference: Arxiv
year: 2023
bibkey: liao2023item
citations: 0
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2311.02084'}]
tags: [Unsupervised]
short_authors: Liao et al.
---
Product embedding serves as a cornerstone for a wide range of applications in
eCommerce. The product embedding learned from multiple modalities shows
significant improvement over that from a single modality, since different
modalities provide complementary information. However, some modalities are more
informatively dominant than others. How to teach a model to learn embedding
from different modalities without neglecting information from the less dominant
modality is challenging. We present an image-text embedding model (ITEm), an
unsupervised learning method that is designed to better attend to image and
text modalities. We extend BERT by (1) learning an embedding from text and
image without knowing the regions of interest; (2) training a global
representation to predict masked words and to construct masked image patches
without their individual representations. We evaluate the pre-trained ITEm on
two tasks: the search for extremely similar products and the prediction of
product categories, showing substantial gains compared to strong baseline
models.