---
layout: publication
title: Cross-modal Deep Variational Hashing
authors: Venice Liong, Jiwen Lu, Yap-Peng Tan, And Zhou
conference: 2017 IEEE International Conference on Computer Vision (ICCV)
year: 2017
bibkey: liong2017cross
citations: 99
additional_links: [{name: Paper, url: 'https://openaccess.thecvf.com/content_ICCV_2017/papers/Liong_Cross-Modal_Deep_Variational_ICCV_2017_paper.pdf'}]
tags: ["Compact Codes", "Datasets", "Evaluation", "Hashing Methods", "ICCV"]
short_authors: Liong et al.
---
In this paper, we propose a cross-modal deep variational hashing (CMDVH) method for cross-modality multimedia retrieval. Unlike existing cross-modal hashing methods
which learn a single pair of projections to map each example as a binary vector, we design a couple of deep neural
network to learn non-linear transformations from imagetext input pairs, so that unified binary codes can be obtained. We then design the modality-specific neural networks in a probabilistic manner where we model a latent
variable as close as possible from the inferred binary codes,
which is approximated by a posterior distribution regularized by a known prior. Experimental results on three benchmark datasets show the efficacy of the proposed approach.