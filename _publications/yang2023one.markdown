---
layout: publication
title: One-shot Action Recognition Via Multi-scale Spatial-temporal Skeleton Matching
authors: Siyuan Yang, Jun Liu, Shijian Lu, Er Meng Hwa, Alex C. Kot
conference: IEEE Transactions on Pattern Analysis and Machine Intelligence
year: 2024
bibkey: yang2023one
citations: 6
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2307.07286'}]
tags: []
short_authors: Yang et al.
---
One-shot skeleton action recognition, which aims to learn a skeleton action
recognition model with a single training sample, has attracted increasing
interest due to the challenge of collecting and annotating large-scale skeleton
action data. However, most existing studies match skeleton sequences by
comparing their feature vectors directly which neglects spatial structures and
temporal orders of skeleton data. This paper presents a novel one-shot skeleton
action recognition technique that handles skeleton action recognition via
multi-scale spatial-temporal feature matching. We represent skeleton data at
multiple spatial and temporal scales and achieve optimal feature matching from
two perspectives. The first is multi-scale matching which captures the
scale-wise semantic relevance of skeleton data at multiple spatial and temporal
scales simultaneously. The second is cross-scale matching which handles
different motion magnitudes and speeds by capturing sample-wise relevance
across multiple scales. Extensive experiments over three large-scale datasets
(NTU RGB+D, NTU RGB+D 120, and PKU-MMD) show that our method achieves superior
one-shot skeleton action recognition, and it outperforms the state-of-the-art
consistently by large margins.