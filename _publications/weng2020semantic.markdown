---
layout: publication
title: Semantic Signatures For Large-scale Visual Localization
authors: Li Weng, Valerie Gouet-Brunet, Bahman Soheilian
conference: Multimedia Tools and Applications
year: 2020
bibkey: weng2020semantic
citations: 5
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2005.03388'}]
tags: ["Evaluation", "Scalability", "Similarity Search"]
short_authors: Li Weng, Valerie Gouet-Brunet, Bahman Soheilian
---
Visual localization is a useful alternative to standard localization
techniques. It works by utilizing cameras. In a typical scenario, features are
extracted from captured images and compared with geo-referenced databases.
Location information is then inferred from the matching results. Conventional
schemes mainly use low-level visual features. These approaches offer good
accuracy but suffer from scalability issues. In order to assist localization in
large urban areas, this work explores a different path by utilizing high-level
semantic information. It is found that object information in a street view can
facilitate localization. A novel descriptor scheme called "semantic signature"
is proposed to summarize this information. A semantic signature consists of
type and angle information of visible objects at a spatial location. Several
metrics and protocols are proposed for signature comparison and retrieval. They
illustrate different trade-offs between accuracy and complexity. Extensive
simulation results confirm the potential of the proposed scheme in large-scale
applications. This paper is an extended version of a conference paper in
CBMI'18. A more efficient retrieval protocol is presented with additional
experiment results.