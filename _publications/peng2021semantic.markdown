---
layout: publication
title: Semantic Reinforced Attention Learning For Visual Place Recognition
authors: Guohao Peng, Yufeng Yue, Jun Zhang, Zhenyu Wu, Xiaoyu Tang, Danwei Wang
conference: 2021 IEEE International Conference on Robotics and Automation (ICRA)
year: 2021
bibkey: peng2021semantic
citations: 48
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2108.08443'}]
tags: ["ICRA"]
short_authors: Peng et al.
---
Large-scale visual place recognition (VPR) is inherently challenging because
not all visual cues in the image are beneficial to the task. In order to
highlight the task-relevant visual cues in the feature embedding, the existing
attention mechanisms are either based on artificial rules or trained in a
thorough data-driven manner. To fill the gap between the two types, we propose
a novel Semantic Reinforced Attention Learning Network (SRALNet), in which the
inferred attention can benefit from both semantic priors and data-driven
fine-tuning. The contribution lies in two-folds. (1) To suppress misleading
local features, an interpretable local weighting scheme is proposed based on
hierarchical feature distribution. (2) By exploiting the interpretability of
the local weighting scheme, a semantic constrained initialization is proposed
so that the local attention can be reinforced by semantic priors. Experiments
demonstrate that our method outperforms state-of-the-art techniques on
city-scale VPR benchmark datasets.