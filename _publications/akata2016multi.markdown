---
layout: publication
title: Multi-cue Zero-shot Learning With Strong Supervision
authors: Zeynep Akata, Mateusz Malinowski, Mario Fritz, Bernt Schiele
conference: 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
year: 2016
bibkey: akata2016multi
citations: 111
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1603.08754'}]
tags: ["CVPR", "Few Shot & Zero Shot"]
short_authors: Akata et al.
---
Scaling up visual category recognition to large numbers of classes remains
challenging. A promising research direction is zero-shot learning, which does
not require any training data to recognize new classes, but rather relies on
some form of auxiliary information describing the new classes. Ultimately, this
may allow to use textbook knowledge that humans employ to learn about new
classes by transferring knowledge from classes they know well. The most
successful zero-shot learning approaches currently require a particular type of
auxiliary information -- namely attribute annotations performed by humans --
that is not readily available for most classes. Our goal is to circumvent this
bottleneck by substituting such annotations by extracting multiple pieces of
information from multiple unstructured text sources readily available on the
web. To compensate for the weaker form of auxiliary information, we incorporate
stronger supervision in the form of semantic part annotations on the classes
from which we transfer knowledge. We achieve our goal by a joint embedding
framework that maps multiple text parts as well as multiple semantic parts into
a common space. Our results consistently and significantly improve on the
state-of-the-art in zero-short recognition and retrieval.