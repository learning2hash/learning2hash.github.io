---
layout: publication
title: Making Sense Of Word Embeddings
authors: Maria Pelevina, Nikolay Arefyev, Chris Biemann, Alexander Panchenko
conference: Proceedings of the 1st Workshop on Representation Learning for NLP
year: 2016
bibkey: pelevina2016making
citations: 141
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1708.03390'}]
tags: []
short_authors: Pelevina et al.
---
We present a simple yet effective approach for learning word sense
embeddings. In contrast to existing techniques, which either directly learn
sense representations from corpora or rely on sense inventories from lexical
resources, our approach can induce a sense inventory from existing word
embeddings via clustering of ego-networks of related words. An integrated WSD
mechanism enables labeling of words in context with learned sense vectors,
which gives rise to downstream applications. Experiments show that the
performance of our method is comparable to state-of-the-art unsupervised WSD
systems.