---
layout: publication
title: One-shot And Few-shot Learning Of Word Embeddings
authors: Andrew K. Lampinen, James L. McClelland
conference: Arxiv
year: 2017
bibkey: lampinen2017one
citations: 13
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1710.10280'}]
tags: ["Few Shot & Zero Shot"]
short_authors: Andrew K. Lampinen, James L. McClelland
---
Standard deep learning systems require thousands or millions of examples to
learn a concept, and cannot integrate new concepts easily. By contrast, humans
have an incredible ability to do one-shot or few-shot learning. For instance,
from just hearing a word used in a sentence, humans can infer a great deal
about it, by leveraging what the syntax and semantics of the surrounding words
tells us. Here, we draw inspiration from this to highlight a simple technique
by which deep recurrent networks can similarly exploit their prior knowledge to
learn a useful representation for a new word from little data. This could make
natural language processing systems much more flexible, by allowing them to
learn continually from the new words they encounter.