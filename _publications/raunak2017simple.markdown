---
layout: publication
title: Simple And Effective Dimensionality Reduction For Word Embeddings
authors: Vikas Raunak
conference: Arxiv
year: 2017
bibkey: raunak2017simple
citations: 20
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1708.03629'}]
tags: ["Evaluation"]
short_authors: Vikas Raunak
---
Word embeddings have become the basic building blocks for several natural
language processing and information retrieval tasks. Pre-trained word
embeddings are used in several downstream applications as well as for
constructing representations for sentences, paragraphs and documents. Recently,
there has been an emphasis on further improving the pre-trained word vectors
through post-processing algorithms. One such area of improvement is the
dimensionality reduction of the word embeddings. Reducing the size of word
embeddings through dimensionality reduction can improve their utility in memory
constrained devices, benefiting several real-world applications. In this work,
we present a novel algorithm that effectively combines PCA based dimensionality
reduction with a recently proposed post-processing algorithm, to construct word
embeddings of lower dimensions. Empirical evaluations on 12 standard word
similarity benchmarks show that our algorithm reduces the embedding
dimensionality by 50%, while achieving similar or (more often) better
performance than the higher dimension embeddings.