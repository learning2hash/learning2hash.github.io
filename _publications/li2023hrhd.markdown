---
layout: publication
title: 'HRHD-HK: A Benchmark Dataset Of High-rise And High-density Urban Scenes For
  3D Semantic Segmentation Of Photogrammetric Point Clouds'
authors: Maosu Li, Yijie Wu, Anthony G. O. Yeh, Fan Xue
conference: 2023 IEEE International Conference on Image Processing Challenges and
  Workshops (ICIPCW)
year: 2023
bibkey: li2023hrhd
citations: 5
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2307.07976'}]
tags: ["Datasets", "Evaluation"]
short_authors: Li et al.
---
Many existing 3D semantic segmentation methods, deep learning in computer
vision notably, claimed to achieve desired results on urban point clouds. Thus,
it is significant to assess these methods quantitatively in diversified
real-world urban scenes, encompassing high-rise, low-rise, high-density, and
low-density urban areas. However, existing public benchmark datasets primarily
represent low-rise scenes from European cities and cannot assess the methods
comprehensively. This paper presents a benchmark dataset of high-rise urban
point clouds, namely High-Rise, High-Density urban scenes of Hong Kong
(HRHD-HK). HRHD-HK arranged in 150 tiles contains 273 million colorful
photogrammetric 3D points from diverse urban settings. The semantic labels of
HRHD-HK include building, vegetation, road, waterbody, facility, terrain, and
vehicle. To our best knowledge, HRHD-HK is the first photogrammetric dataset
that focuses on HRHD urban areas. This paper also comprehensively evaluates
eight popular semantic segmentation methods on the HRHD-HK dataset.
Experimental results confirmed plenty of room for enhancing the current 3D
semantic segmentation of point clouds, especially for city objects with small
volumes. Our dataset is publicly available at
https://doi.org/10.25442/hku.23701866.v2.