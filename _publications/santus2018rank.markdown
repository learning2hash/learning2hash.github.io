---
layout: publication
title: A Rank-based Similarity Metric For Word Embeddings
authors: Enrico Santus, Hongmin Wang, Emmanuele Chersoni, Yue Zhang
conference: 'Proceedings of the 56th Annual Meeting of the Association for Computational
  Linguistics (Volume 2: Short Papers)'
year: 2018
bibkey: santus2018rank
citations: 14
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1805.01923'}]
tags: ["Distance Metric Learning"]
short_authors: Santus et al.
---
Word Embeddings have recently imposed themselves as a standard for
representing word meaning in NLP. Semantic similarity between word pairs has
become the most common evaluation benchmark for these representations, with
vector cosine being typically used as the only similarity metric. In this
paper, we report experiments with a rank-based metric for WE, which performs
comparably to vector cosine in similarity estimation and outperforms it in the
recently-introduced and challenging task of outlier detection, thus suggesting
that rank-based measures can improve clustering quality.