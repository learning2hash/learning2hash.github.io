---
layout: publication
title: 'Finding Beans In Burgers: Deep Semantic-visual Embedding With Localization'
authors: "Martin Engilberge, Louis Chevallier, Patrick P\xE9rez, Matthieu Cord"
conference: 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition
year: 2018
bibkey: engilberge2018finding
citations: 86
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1804.01720'}]
tags: [CVPR, Multimodal Retrieval, Evaluation]
short_authors: Engilberge et al.
---
Several works have proposed to learn a two-path neural network that maps
images and texts, respectively, to a same shared Euclidean space where geometry
captures useful semantic relationships. Such a multi-modal embedding can be
trained and used for various tasks, notably image captioning. In the present
work, we introduce a new architecture of this type, with a visual path that
leverages recent space-aware pooling mechanisms. Combined with a textual path
which is jointly trained from scratch, our semantic-visual embedding offers a
versatile model. Once trained under the supervision of captioned images, it
yields new state-of-the-art performance on cross-modal retrieval. It also
allows the localization of new concepts from the embedding space into any input
image, delivering state-of-the-art result on the visual grounding of phrases.