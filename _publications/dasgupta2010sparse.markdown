---
layout: publication
title: A Sparse Johnson--lindenstrauss Transform
authors: Dasgupta Anirban, Kumar Ravi, Sarlós Tamás
conference: "Arxiv"
year: 2010
bibkey: dasgupta2010sparse
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/1004.4240"}
tags: ['ARXIV', 'Independent']
---
Dimension reduction is a key algorithmic tool with many applications including nearest-neighbor search, compressed sensing and linear algebra in the streaming model. In this work we obtain a \{\em sparse\} version of the fundamental tool in dimension reduction --- the Johnson--Lindenstrauss transform. Using hashing and local densification, we construct a sparse projection matrix with just \{&#37; raw &#37;\}\\(\tilde\{O\}(\frac\{1\}\{\epsilon\})\\)\{&#37; endraw &#37;\} non-zero entries per column. We also show a matching lower bound on the sparsity for a large class of projection matrices. Our bounds are somewhat surprising, given the known lower bounds of \{&#37; raw &#37;\}\\(\Omega(\frac\{1\}\{\epsilon^2\})\\)\{&#37; endraw &#37;\} both on the number of rows of any projection matrix and on the sparsity of projection matrices generated by natural constructions. Using this, we achieve an \{&#37; raw &#37;\}\\(\tilde\{O\}(\frac\{1\}\{\epsilon\})\\)\{&#37; endraw &#37;\} update time per non-zero element for a \{&#37; raw &#37;\}\\((1\pm\epsilon)\\)\{&#37; endraw &#37;\}-approximate projection, thereby substantially outperforming the \{&#37; raw &#37;\}\\(\tilde\{O\}(\frac\{1\}\{\epsilon^2\})\\)\{&#37; endraw &#37;\} update time required by prior approaches. A variant of our method offers the same guarantees for sparse vectors, yet its \{&#37; raw &#37;\}\\(\tilde\{O\}(d)\\)\{&#37; endraw &#37;\} worst case running time matches the best approach of Ailon and Liberty.
