---
layout: publication
title: A Sparse Johnson--lindenstrauss Transform
authors: Dasgupta Anirban, Kumar Ravi, Sarlós Tamás
conference: "Arxiv"
year: 2010
bibkey: dasgupta2010sparse
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/1004.4240"}
tags: ['ARXIV', 'Independent']
---
<p>Dimension reduction is a key algorithmic tool with many applications
including nearest-neighbor search, compressed sensing and linear algebra
in the streaming model. In this work we obtain a {} version of the
fundamental tool in dimension reduction — the Johnson–Lindenstrauss
transform. Using hashing and local densification, we construct a sparse
projection matrix with just <span
class="math inline">\(\tilde{O}(\frac{1}{\epsilon})\)</span> non-zero
entries per column. We also show a matching lower bound on the sparsity
for a large class of projection matrices. Our bounds are somewhat
surprising, given the known lower bounds of <span
class="math inline">\(\Omega(\frac{1}{\epsilon^2})\)</span> both on the
number of rows of any projection matrix and on the sparsity of
projection matrices generated by natural constructions. Using this, we
achieve an <span
class="math inline">\(\tilde{O}(\frac{1}{\epsilon})\)</span> update time
per non-zero element for a <span
class="math inline">\((1\pm\epsilon)\)</span>-approximate projection,
thereby substantially outperforming the <span
class="math inline">\(\tilde{O}(\frac{1}{\epsilon^2})\)</span> update
time required by prior approaches. A variant of our method offers the
same guarantees for sparse vectors, yet its <span
class="math inline">\(\tilde{O}(d)\)</span> worst case running time
matches the best approach of Ailon and Liberty.</p>
