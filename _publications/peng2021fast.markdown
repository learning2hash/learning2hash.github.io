---
layout: publication
title: Fast-slow Transformer For Visually Grounding Speech
authors: Puyuan Peng, David Harwath
conference: ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech
  and Signal Processing (ICASSP)
year: 2021
bibkey: peng2021fast
citations: 16
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2109.08186'}]
tags: [Evaluation, ICASSP, Datasets, Image Retrieval]
short_authors: Puyuan Peng, David Harwath
---
We present Fast-Slow Transformer for Visually Grounding Speech, or FaST-VGS.
FaST-VGS is a Transformer-based model for learning the associations between raw
speech waveforms and visual images. The model unifies dual-encoder and
cross-attention architectures into a single model, reaping the superior
retrieval speed of the former along with the accuracy of the latter. FaST-VGS
achieves state-of-the-art speech-image retrieval accuracy on benchmark
datasets, and its learned representations exhibit strong performance on the
ZeroSpeech 2021 phonetic and semantic tasks.