---
layout: publication
title: Unsupervised Visual And Textual Information Fusion In Multimedia Retrieval
  - A Graph-based Point Of View
authors: "Gabriela Csurka, Julien Ah-Pine, St\xE9phane Clinchant"
conference: Arxiv
year: 2014
bibkey: csurka2014unsupervised
citations: 6
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1401.6891'}]
tags: ["Datasets", "Evaluation", "Graph Based ANN", "Multimodal Retrieval", "Unsupervised"]
short_authors: "Gabriela Csurka, Julien Ah-Pine, St\xE9phane Clinchant"
---
Multimedia collections are more than ever growing in size and diversity.
Effective multimedia retrieval systems are thus critical to access these
datasets from the end-user perspective and in a scalable way. We are interested
in repositories of image/text multimedia objects and we study multimodal
information fusion techniques in the context of content based multimedia
information retrieval. We focus on graph based methods which have proven to
provide state-of-the-art performances. We particularly examine two of such
methods : cross-media similarities and random walk based scores. From a
theoretical viewpoint, we propose a unifying graph based framework which
encompasses the two aforementioned approaches. Our proposal allows us to
highlight the core features one should consider when using a graph based
technique for the combination of visual and textual information. We compare
cross-media and random walk based results using three different real-world
datasets. From a practical standpoint, our extended empirical analysis allow us
to provide insights and guidelines about the use of graph based methods for
multimodal information fusion in content based multimedia information
retrieval.