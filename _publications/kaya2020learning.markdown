---
layout: publication
title: 'Learning Multi-modal Nonlinear Embeddings: Performance Bounds And An Algorithm'
authors: Semih Kaya, Elif Vural
conference: IEEE Transactions on Image Processing
year: 2020
bibkey: kaya2020learning
citations: 6
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2006.02330'}]
tags: [Text Retrieval, Evaluation, Supervised, Datasets]
short_authors: Semih Kaya, Elif Vural
---
While many approaches exist in the literature to learn low-dimensional
representations for data collections in multiple modalities, the
generalizability of multi-modal nonlinear embeddings to previously unseen data
is a rather overlooked subject. In this work, we first present a theoretical
analysis of learning multi-modal nonlinear embeddings in a supervised setting.
Our performance bounds indicate that for successful generalization in
multi-modal classification and retrieval problems, the regularity of the
interpolation functions extending the embedding to the whole data space is as
important as the between-class separation and cross-modal alignment criteria.
We then propose a multi-modal nonlinear representation learning algorithm that
is motivated by these theoretical findings, where the embeddings of the
training samples are optimized jointly with the Lipschitz regularity of the
interpolators. Experimental comparison to recent multi-modal and single-modal
learning algorithms suggests that the proposed method yields promising
performance in multi-modal image classification and cross-modal image-text
retrieval applications.