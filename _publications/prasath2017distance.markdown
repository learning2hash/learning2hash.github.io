---
layout: publication
title: Distance And Similarity Measures Effect On The Performance Of K-nearest Neighbor
  Classifier -- A Review
authors: V. B. Surya Prasath, Haneen Arafat Abu Alfeilat, Ahmad B. A. Hassanat, Omar
  Lasassmeh, Ahmad S. Tarawneh, Mahmoud Bashir Alhasanat, Hamzeh S. Eyal Salman
conference: Arxiv
year: 2017
bibkey: prasath2017distance
citations: 92
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1708.04321'}]
tags: ["Evaluation"]
short_authors: Prasath et al.
---
The K-nearest neighbor (KNN) classifier is one of the simplest and most
common classifiers, yet its performance competes with the most complex
classifiers in the literature. The core of this classifier depends mainly on
measuring the distance or similarity between the tested examples and the
training examples. This raises a major question about which distance measures
to be used for the KNN classifier among a large number of distance and
similarity measures available? This review attempts to answer this question
through evaluating the performance (measured by accuracy, precision and recall)
of the KNN using a large number of distance measures, tested on a number of
real-world datasets, with and without adding different levels of noise. The
experimental results show that the performance of KNN classifier depends
significantly on the distance used, and the results showed large gaps between
the performances of different distances. We found that a recently proposed
non-convex distance performed the best when applied on most datasets comparing
to the other tested distances. In addition, the performance of the KNN with
this top performing distance degraded only about \(20%\) while the noise level
reaches \(90%\), this is true for most of the distances used as well. This means
that the KNN classifier using any of the top \(10\) distances tolerate noise to a
certain degree. Moreover, the results show that some distances are less
affected by the added noise comparing to other distances.