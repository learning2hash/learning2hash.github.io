---
layout: publication
title: 'The Contemporary Art Of Image Search: Iterative User Intent Expansion Via
  Vision-language Model'
authors: Yilin Ye, Qian Zhu, Shishi Xiao, Kang Zhang, Wei Zeng
conference: Proceedings of the ACM on Human-Computer Interaction
year: 2024
bibkey: ye2023contemporary
citations: 2
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2312.01656'}]
tags: ["Image Retrieval"]
short_authors: Ye et al.
---
Image search is an essential and user-friendly method to explore vast
galleries of digital images. However, existing image search methods heavily
rely on proximity measurements like tag matching or image similarity, requiring
precise user inputs for satisfactory results. To meet the growing demand for a
contemporary image search engine that enables accurate comprehension of users'
search intentions, we introduce an innovative user intent expansion framework.
Our framework leverages visual-language models to parse and compose multi-modal
user inputs to provide more accurate and satisfying results. It comprises
two-stage processes: 1) a parsing stage that incorporates a language parsing
module with large language models to enhance the comprehension of textual
inputs, along with a visual parsing module that integrates an interactive
segmentation module to swiftly identify detailed visual elements within images;
and 2) a logic composition stage that combines multiple user search intents
into a unified logic expression for more sophisticated operations in complex
searching scenarios. Moreover, the intent expansion framework enables users to
perform flexible contextualized interactions with the search results to further
specify or adjust their detailed search intents iteratively. We implemented the
framework into an image search system for NFT (non-fungible token) search and
conducted a user study to evaluate its usability and novel properties. The
results indicate that the proposed framework significantly improves users'
image search experience. Particularly the parsing and contextualized
interactions prove useful in allowing users to express their search intents
more accurately and engage in a more enjoyable iterative search experience.