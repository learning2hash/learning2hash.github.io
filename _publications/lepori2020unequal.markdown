---
layout: publication
title: 'Unequal Representations: Analyzing Intersectional Biases In Word Embeddings
  Using Representational Similarity Analysis'
authors: Michael A. Lepori
conference: Proceedings of the 28th International Conference on Computational Linguistics
year: 2020
bibkey: lepori2020unequal
citations: 8
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2011.12086'}]
tags: ["COLING"]
short_authors: Michael A. Lepori
---
We present a new approach for detecting human-like social biases in word
embeddings using representational similarity analysis. Specifically, we probe
contextualized and non-contextualized embeddings for evidence of intersectional
biases against Black women. We show that these embeddings represent Black women
as simultaneously less feminine than White women, and less Black than Black
men. This finding aligns with intersectionality theory, which argues that
multiple identity categories (such as race or sex) layer on top of each other
in order to create unique modes of discrimination that are not shared by any
individual category.