---
layout: publication
title: Training Vision Transformers for Image Retrieval
authors: El-nouby et al.
conference: Arxiv
year: 2021
bibkey: elnouby2021training
citations: 120
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2102.05644'}]
tags: [Image Retrieval]
---
Transformers have shown outstanding results for natural language
understanding and, more recently, for image classification. We here extend this
work and propose a transformer-based approach for image retrieval: we adopt
vision transformers for generating image descriptors and train the resulting
model with a metric learning objective, which combines a contrastive loss with
a differential entropy regularizer. Our results show consistent and significant
improvements of transformers over convolution-based approaches. In particular,
our method outperforms the state of the art on several public benchmarks for
category-level retrieval, namely Stanford Online Product, In-Shop and CUB-200.
Furthermore, our experiments on ROxford and RParis also show that, in
comparable settings, transformers are competitive for particular object
retrieval, especially in the regime of short vector representations and
low-resolution images.