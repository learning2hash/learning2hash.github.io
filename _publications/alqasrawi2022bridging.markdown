---
layout: publication
title: 'Bridging The Gap Between Local Semantic Concepts And Bag Of Visual Words For Natural Scene Image Retrieval'
authors: Yousef Alqasrawi
conference: "Arxiv"
year: 2022
citations: 1
bibkey: alqasrawi2022bridging
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/2210.08875'}
tags: ['Tools and Libraries', 'Hashing for Real-World Applications', 'Applications']
---
This paper addresses the problem of semantic-based image retrieval of natural
scenes. A typical content-based image retrieval system deals with the query
image and images in the dataset as a collection of low-level features and
retrieves a ranked list of images based on the similarities between features of
the query image and features of images in the image dataset. However, top
ranked images in the retrieved list, which have high similarities to the query
image, may be different from the query image in terms of the semantic
interpretation of the user which is known as the semantic gap. In order to
reduce the semantic gap, this paper investigates how natural scene retrieval
can be performed using the bag of visual word model and the distribution of
local semantic concepts. The paper studies the efficiency of using different
approaches for representing the semantic information, depicted in natural scene
images, for image retrieval. An extensive experimental work has been conducted
to study the efficiency of using semantic information as well as the bag of
visual words model for natural and urban scene image retrieval.
