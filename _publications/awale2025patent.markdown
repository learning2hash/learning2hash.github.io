---
layout: publication
title: Patent Figure Classification Using Large Vision-language Models
authors: "Sushil Awale, Eric M\xFCller-Budack, Ralph Ewerth"
conference: Lecture Notes in Computer Science
year: 2025
bibkey: awale2025patent
citations: 0
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2501.12751'}]
tags: []
short_authors: "Sushil Awale, Eric M\xFCller-Budack, Ralph Ewerth"
---
Patent figure classification facilitates faceted search in patent retrieval
systems, enabling efficient prior art search. Existing approaches have explored
patent figure classification for only a single aspect and for aspects with a
limited number of concepts. In recent years, large vision-language models
(LVLMs) have shown tremendous performance across numerous computer vision
downstream tasks, however, they remain unexplored for patent figure
classification. Our work explores the efficacy of LVLMs in patent figure visual
question answering (VQA) and classification, focusing on zero-shot and few-shot
learning scenarios. For this purpose, we introduce new datasets, PatFigVQA and
PatFigCLS, for fine-tuning and evaluation regarding multiple aspects of patent
figures~(i.e., type, projection, patent class, and objects). For a
computational-effective handling of a large number of classes using LVLM, we
propose a novel tournament-style classification strategy that leverages a
series of multiple-choice questions. Experimental results and comparisons of
multiple classification approaches based on LVLMs and Convolutional Neural
Networks (CNNs) in few-shot settings show the feasibility of the proposed
approaches.