---
layout: publication
title: Multi-head Attention With Diversity For Learning Grounded Multilingual Multimodal
  Representations
authors: Po-yao Huang, Xiaojun Chang, Alexander Hauptmann
conference: Proceedings of the 2019 Conference on Empirical Methods in Natural Language
  Processing and the 9th International Joint Conference on Natural Language Processing
  (EMNLP-IJCNLP)
year: 2019
bibkey: huang2019multi
citations: 18
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1910.00058'}]
tags: ["EMNLP"]
short_authors: Po-yao Huang, Xiaojun Chang, Alexander Hauptmann
---
With the aim of promoting and understanding the multilingual version of image
search, we leverage visual object detection and propose a model with diverse
multi-head attention to learn grounded multilingual multimodal representations.
Specifically, our model attends to different types of textual semantics in two
languages and visual objects for fine-grained alignments between sentences and
images. We introduce a new objective function which explicitly encourages
attention diversity to learn an improved visual-semantic embedding space. We
evaluate our model in the German-Image and English-Image matching tasks on the
Multi30K dataset, and in the Semantic Textual Similarity task with the English
descriptions of visual content. Results show that our model yields a
significant performance gain over other methods in all of the three tasks.