---
layout: publication
title: Multi-instance Visual-semantic Embedding
authors: Zhou Ren, Hailin Jin, Zhe Lin, Chen Fang, Alan Yuille
conference: Arxiv
year: 2015
bibkey: ren2015multi
citations: 23
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1512.06963'}]
tags: []
short_authors: Ren et al.
---
Visual-semantic embedding models have been recently proposed and shown to be
effective for image classification and zero-shot learning, by mapping images
into a continuous semantic label space. Although several approaches have been
proposed for single-label embedding tasks, handling images with multiple labels
(which is a more general setting) still remains an open problem, mainly due to
the complex underlying corresponding relationship between image and its labels.
In this work, we present Multi-Instance visual-semantic Embedding model (MIE)
for embedding images associated with either single or multiple labels. Our
model discovers and maps semantically-meaningful image subregions to their
corresponding labels. And we demonstrate the superiority of our method over the
state-of-the-art on two tasks, including multi-label image annotation and
zero-shot learning.