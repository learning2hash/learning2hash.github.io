---
layout: publication
title: Triplet-based Deep Similarity Learning For Person Re-identification
authors: Wentong Liao, Michael Ying Yang, Ni Zhan, Bodo Rosenhahn
conference: 2017 IEEE International Conference on Computer Vision Workshops (ICCVW)
year: 2017
bibkey: liao2017triplet
citations: 32
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1802.03254'}]
tags: ["Datasets", "Evaluation", "ICCV", "Tools & Libraries"]
short_authors: Liao et al.
---
In recent years, person re-identification (re-id) catches great attention in
both computer vision community and industry. In this paper, we propose a new
framework for person re-identification with a triplet-based deep similarity
learning using convolutional neural networks (CNNs). The network is trained
with triplet input: two of them have the same class labels and the other one is
different. It aims to learn the deep feature representation, with which the
distance within the same class is decreased, while the distance between the
different classes is increased as much as possible. Moreover, we trained the
model jointly on six different datasets, which differs from common practice -
one model is just trained on one dataset and tested also on the same one.
However, the enormous number of possible triplet data among the large number of
training samples makes the training impossible. To address this challenge, a
double-sampling scheme is proposed to generate triplets of images as effective
as possible. The proposed framework is evaluated on several benchmark datasets.
The experimental results show that, our method is effective for the task of
person re-identification and it is comparable or even outperforms the
state-of-the-art methods.