---
layout: publication
title: Sparse Ternary Codes for similarity search have higher coding gain than dense
  binary codes
authors: Ferdowsi Sohrab, Voloshynovskiy Slava, Kostadinov Dimche, Holotyak Taras
conference: 2017 IEEE International Symposium on Information Theory (ISIT)
year: 2017
bibkey: ferdowsi2017sparse
citations: 12
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1701.07675'}]
tags: ["Hashing-Methods", "Scalability", "Compact-Codes", "Similarity-Search"]
short_authors: Ferdowsi et al.
---
This paper addresses the problem of Approximate Nearest Neighbor (ANN) search
in pattern recognition where feature vectors in a database are encoded as
compact codes in order to speed-up the similarity search in large-scale
databases. Considering the ANN problem from an information-theoretic
perspective, we interpret it as an encoding, which maps the original feature
vectors to a less entropic sparse representation while requiring them to be as
informative as possible. We then define the coding gain for ANN search using
information-theoretic measures. We next show that the classical approach to
this problem, which consists of binarization of the projected vectors is
sub-optimal. Instead, a properly designed ternary encoding achieves higher
coding gains and lower complexity.