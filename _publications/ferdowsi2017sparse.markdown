---
layout: publication
title: Sparse Ternary Codes For Similarity Search Have Higher Coding Gain Than Dense
  Binary Codes
authors: Sohrab Ferdowsi, Slava Voloshynovskiy, Dimche Kostadinov, Taras Holotyak
conference: 2017 IEEE International Symposium on Information Theory (ISIT)
year: 2017
bibkey: ferdowsi2017sparse
citations: 2
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1701.07675'}]
tags: [Compact Codes, Scalability, Similarity Search]
short_authors: Ferdowsi et al.
---
This paper addresses the problem of Approximate Nearest Neighbor (ANN) search
in pattern recognition where feature vectors in a database are encoded as
compact codes in order to speed-up the similarity search in large-scale
databases. Considering the ANN problem from an information-theoretic
perspective, we interpret it as an encoding, which maps the original feature
vectors to a less entropic sparse representation while requiring them to be as
informative as possible. We then define the coding gain for ANN search using
information-theoretic measures. We next show that the classical approach to
this problem, which consists of binarization of the projected vectors is
sub-optimal. Instead, a properly designed ternary encoding achieves higher
coding gains and lower complexity.