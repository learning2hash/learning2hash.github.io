---
layout: publication
title: 'Thousand To One: Semantic Prior Modeling For Conceptual Coding'
authors: Jianhui Chang, Zhenghui Zhao, Lingbo Yang, Chuanmin Jia, Jian Zhang, Siwei
  Ma
conference: 2021 IEEE International Conference on Multimedia and Expo (ICME)
year: 2021
bibkey: chang2021thousand
citations: 19
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2103.07131'}]
tags: []
short_authors: Chang et al.
---
Conceptual coding has been an emerging research topic recently, which encodes
natural images into disentangled conceptual representations for compression.
However, the compression performance of the existing methods is still
sub-optimal due to the lack of comprehensive consideration of rate constraint
and reconstruction quality. To this end, we propose a novel end-to-end semantic
prior modeling-based conceptual coding scheme towards extremely low bitrate
image compression, which leverages semantic-wise deep representations as a
unified prior for entropy estimation and texture synthesis. Specifically, we
employ semantic segmentation maps as structural guidance for extracting deep
semantic prior, which provides fine-grained texture distribution modeling for
better detail construction and higher flexibility in subsequent high-level
vision tasks. Moreover, a cross-channel entropy model is proposed to further
exploit the inter-channel correlation of the spatially independent semantic
prior, leading to more accurate entropy estimation for rate-constrained
training. The proposed scheme achieves an ultra-high 1000x compression ratio,
while still enjoying high visual reconstruction quality and versatility towards
visual processing and analysis tasks.