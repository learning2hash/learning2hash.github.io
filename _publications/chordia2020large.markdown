---
layout: publication
title: Large Scale Multimodal Classification Using An Ensemble Of Transformer Models
  And Co-attention
authors: Varnith Chordia, Vijay Kumar Bg
conference: Arxiv
year: 2020
bibkey: chordia2020large
citations: 8
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2011.11735'}]
tags: []
short_authors: Varnith Chordia, Vijay Kumar Bg
---
Accurate and efficient product classification is significant for E-commerce
applications, as it enables various downstream tasks such as recommendation,
retrieval, and pricing. Items often contain textual and visual information, and
utilizing both modalities usually outperforms classification utilizing either
mode alone. In this paper we describe our methodology and results for the SIGIR
eCom Rakuten Data Challenge. We employ a dual attention technique to model
image-text relationships using pretrained language and image embeddings. While
dual attention has been widely used for Visual Question Answering(VQA) tasks,
ours is the first attempt to apply the concept for multimodal classification.