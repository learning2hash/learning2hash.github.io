---
layout: publication
title: Multi-granularity Representation Learning For Sketch-based Dynamic Face Image
  Retrieval
authors: Wang Liang, Dai Dawei, Fu Shiyu, Wang Guoyin
conference: Arxiv
year: 2024
bibkey: wang2023multi
citations: 1
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2401.00371'}]
tags: ["Tools-&-Libraries", "Evaluation", "Image-Retrieval", "Datasets"]
short_authors: Wang et al.
---
In specific scenarios, face sketch can be used to identify a person. However,
drawing a face sketch often requires exceptional skill and is time-consuming,
limiting its widespread applications in actual scenarios. The new framework of
sketch less face image retrieval (SLFIR)[1] attempts to overcome the barriers
by providing a means for humans and machines to interact during the drawing
process. Considering SLFIR problem, there is a large gap between a partial
sketch with few strokes and any whole face photo, resulting in poor performance
at the early stages. In this study, we propose a multigranularity (MG)
representation learning (MGRL) method to address the SLFIR problem, in which we
learn the representation of different granularity regions for a partial sketch,
and then, by combining all MG regions of the sketches and images, the final
distance was determined. In the experiments, our method outperformed
state-of-the-art baselines in terms of early retrieval on two accessible
datasets. Codes are available at https://github.com/ddw2AIGROUP2CQUPT/MGRL.