---
layout: publication
title: Visualizing Deep Convolutional Neural Networks Using Natural Pre-images
authors: Aravindh Mahendran, Andrea Vedaldi
conference: International Journal of Computer Vision
year: 2016
bibkey: mahendran2015visualizing
citations: 524
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1512.02017'}]
tags: []
short_authors: Aravindh Mahendran, Andrea Vedaldi
---
Image representations, from SIFT and bag of visual words to Convolutional
Neural Networks (CNNs) are a crucial component of almost all computer vision
systems. However, our understanding of them remains limited. In this paper we
study several landmark representations, both shallow and deep, by a number of
complementary visualization techniques. These visualizations are based on the
concept of "natural pre-image", namely a natural-looking image whose
representation has some notable property. We study in particular three such
visualizations: inversion, in which the aim is to reconstruct an image from its
representation, activation maximization, in which we search for patterns that
maximally stimulate a representation component, and caricaturization, in which
the visual patterns that a representation detects in an image are exaggerated.
We pose these as a regularized energy-minimization framework and demonstrate
its generality and effectiveness. In particular, we show that this method can
invert representations such as HOG more accurately than recent alternatives
while being applicable to CNNs too. Among our findings, we show that several
layers in CNNs retain photographically accurate information about the image,
with different degrees of geometric and photometric invariance.