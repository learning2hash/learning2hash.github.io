---
layout: publication
title: Multi-label Sound Event Retrieval Using A Deep Learning-based Siamese Structure
  With A Pairwise Presence Matrix
authors: Jianyu Fan, Eric Nichols, Daniel Tompkins, Ana Elisa Mendez Mendez, Benjamin
  Elizalde, Philippe Pasquier
conference: ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech
  and Signal Processing (ICASSP)
year: 2020
bibkey: fan2020multi
citations: 5
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2002.09026'}]
tags: ["Datasets", "Evaluation", "ICASSP"]
short_authors: Fan et al.
---
Realistic recordings of soundscapes often have multiple sound events
co-occurring, such as car horns, engine and human voices. Sound event retrieval
is a type of content-based search aiming at finding audio samples, similar to
an audio query based on their acoustic or semantic content. State of the art
sound event retrieval models have focused on single-label audio recordings,
with only one sound event occurring, rather than on multi-label audio
recordings (i.e., multiple sound events occur in one recording). To address
this latter problem, we propose different Deep Learning architectures with a
Siamese-structure and a Pairwise Presence Matrix. The networks are trained and
evaluated using the SONYC-UST dataset containing both single- and multi-label
soundscape recordings. The performance results show the effectiveness of our
proposed model.