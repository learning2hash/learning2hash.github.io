---
layout: publication
title: Collaborative Quantization For Cross45;modal Similarity Search
authors: Zhang Ting, Wang Jingdong
conference: "Arxiv"
year: 2019
bibkey: zhang2019collaborative
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/1902.00623"}
tags: ['ARXIV', 'Quantisation']
---
Cross45;modal similarity search is a problem about designing a search system supporting querying across content modalities e.g. using an image to search for texts or using a text to search for images. This paper presents a compact coding solution for efficient search with a focus on the quantization approach which has already shown the superior performance over the hashing solutions in the single45;modal similarity search. We propose a cross45;modal quantization approach which is among the early attempts to introduce quantization into cross45;modal search. The major contribution lies in jointly learning the quantizers for both modalities through aligning the quantized representations for each pair of image and text belonging to a document. In addition our approach simultaneously learns the common space for both modalities in which quantization is conducted to enable efficient and effective search using the Euclidean distance computed in the common space with fast distance table lookup. Experimental results compared with several competitive algorithms over three benchmark datasets demonstrate that the proposed approach achieves the state45;of45;the45;art performance.
