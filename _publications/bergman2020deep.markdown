---
layout: publication
title: Deep Nearest Neighbor Anomaly Detection
authors: Liron Bergman, Niv Cohen, Yedid Hoshen
conference: Arxiv
year: 2020
bibkey: bergman2020deep
citations: 107
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2002.10445'}]
tags: ["Robustness", "Self-Supervised", "Supervised"]
short_authors: Liron Bergman, Niv Cohen, Yedid Hoshen
---
Nearest neighbors is a successful and long-standing technique for anomaly
detection. Significant progress has been recently achieved by self-supervised
deep methods (e.g. RotNet). Self-supervised features however typically
under-perform Imagenet pre-trained features. In this work, we investigate
whether the recent progress can indeed outperform nearest-neighbor methods
operating on an Imagenet pretrained feature space. The simple nearest-neighbor
based-approach is experimentally shown to outperform self-supervised methods
in: accuracy, few shot generalization, training time and noise robustness while
making fewer assumptions on image distributions.