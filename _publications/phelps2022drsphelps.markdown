---
layout: publication
title: 'Drsphelps At Semeval-2022 Task 2: Learning Idiom Representations Using BERTRAM'
authors: Dylan Phelps
conference: Proceedings of the 16th International Workshop on Semantic Evaluation
  (SemEval-2022)
year: 2022
bibkey: phelps2022drsphelps
citations: 2
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2204.02821'}]
tags: ["Evaluation"]
short_authors: Dylan Phelps
---
This paper describes our system for SemEval-2022 Task 2 Multilingual
Idiomaticity Detection and Sentence Embedding sub-task B. We modify a standard
BERT sentence transformer by adding embeddings for each idioms, which are
created using BERTRAM and a small number of contexts. We show that this
technique increases the quality of idiom representations and leads to better
performance on the task. We also perform analysis on our final results and show
that the quality of the produced idiom embeddings is highly sensitive to the
quality of the input contexts.