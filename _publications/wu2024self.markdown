---
layout: publication
title: Self-distilled Dynamic Fusion Network For Language-based Fashion Retrieval
authors: Yiming Wu, Hangfei Li, Fangfang Wang, Yilong Zhang, Ronghua Liang
conference: ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech
  and Signal Processing (ICASSP)
year: 2024
bibkey: wu2024self
citations: 5
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2405.15451'}]
tags: [ICASSP, Image Retrieval, Efficiency]
short_authors: Wu et al.
---
In the domain of language-based fashion image retrieval, pinpointing the
desired fashion item using both a reference image and its accompanying textual
description is an intriguing challenge. Existing approaches lean heavily on
static fusion techniques, intertwining image and text. Despite their
commendable advancements, these approaches are still limited by a deficiency in
flexibility. In response, we propose a Self-distilled Dynamic Fusion Network to
compose the multi-granularity features dynamically by considering the
consistency of routing path and modality-specific information simultaneously.
Two new modules are included in our proposed method: (1) Dynamic Fusion Network
with Modality Specific Routers. The dynamic network enables a flexible
determination of the routing for each reference image and modification text,
taking into account their distinct semantics and distributions. (2) Self Path
Distillation Loss. A stable path decision for queries benefits the optimization
of feature extraction as well as routing, and we approach this by progressively
refine the path decision with previous path information. Extensive experiments
demonstrate the effectiveness of our proposed model compared to existing
methods.