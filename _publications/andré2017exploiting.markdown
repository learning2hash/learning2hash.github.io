---
layout: publication
title: 'Exploiting Modern Hardware For High-dimensional Nearest Neighbor Search'
authors: Fabien André
conference: "Arxiv"
year: 2017
citations: 0
bibkey: andré2017exploiting
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/1712.02912'}
tags: ['Quantization', 'Quantization and Compression', 'Applications', 'ANN Search']
---
Many multimedia information retrieval or machine learning problems require
efficient high-dimensional nearest neighbor search techniques. For instance,
multimedia objects (images, music or videos) can be represented by
high-dimensional feature vectors. Finding two similar multimedia objects then
comes down to finding two objects that have similar feature vectors. In the
current context of mass use of social networks, large scale multimedia
databases or large scale machine learning applications are more and more
common, calling for efficient nearest neighbor search approaches.
  This thesis builds on product quantization, an efficient nearest neighbor
search technique that compresses high-dimensional vectors into short codes.
This makes it possible to store very large databases entirely in RAM, enabling
low response times. We propose several contributions that exploit the
capabilities of modern CPUs, especially SIMD and the cache hierarchy, to
further decrease response times offered by product quantization.
