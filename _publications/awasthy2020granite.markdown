---
layout: publication
title: Granite Embedding Models
authors: Awasthy et al.
conference: International Journal for Numerical and Analytical Methods in Geomechanics
year: 2020
bibkey: awasthy2020granite
citations: 14
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2502.20204'}]
tags: []
---
We introduce the Granite Embedding models, a family of encoder-based
embedding models designed for retrieval tasks, spanning dense-retrieval and
sparse retrieval architectures, with both English and Multilingual
capabilities. This report provides the technical details of training these
highly effective 12 layer embedding models, along with their efficient 6 layer
distilled counterparts. Extensive evaluations show that the models, developed
with techniques like retrieval oriented pretraining, contrastive finetuning,
knowledge distillation, and model merging significantly outperform publicly
available models of similar sizes on both internal IBM retrieval and search
tasks, and have equivalent performance on widely used information retrieval
benchmarks, while being trained on high-quality data suitable for enterprise
use. We publicly release all our Granite Embedding models under the Apache 2.0
license, allowing both research and commercial use at
https://huggingface.co/collections/ibm-granite.