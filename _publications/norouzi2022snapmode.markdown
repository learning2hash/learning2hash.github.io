---
layout: publication
title: 'Snapmode: An Intelligent And Distributed Large-scale Fashion Image Retrieval
  Platform Based On Big Data And Deep Generative Adversarial Network Technologies'
authors: Narges Norouzi, Reza Azmi, Sara Saberi Tehrani Moghadam, Maral Zarvani
conference: Arxiv
year: 2022
bibkey: norouzi2022snapmode
citations: 2
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2204.03998'}]
tags: ["Datasets", "Image Retrieval", "Large Scale Search", "Robustness", "Scalability", "Tools & Libraries"]
short_authors: Norouzi et al.
---
Fashion is now among the largest industries worldwide, for it represents
human history and helps tell the worlds story. As a result of the Fourth
Industrial Revolution, the Internet has become an increasingly important source
of fashion information. However, with a growing number of web pages and social
data, it is nearly impossible for humans to manually catch up with the ongoing
evolution and the continuously variable content in this domain. The proper
management and exploitation of big data can pave the way for the substantial
growth of the global economy as well as citizen satisfaction. Therefore,
computer scientists have found it challenging to handle e-commerce fashion
websites by using big data and machine learning technologies. This paper first
proposes a scalable focused Web Crawler engine based on the distributed
computing platforms to extract and process fashion data on e-commerce websites.
The role of the proposed platform is then described in developing a
disentangled feature extraction method by employing deep convolutional
generative adversarial networks (DCGANs) for content-based image indexing and
retrieval. Finally, the state-of-the-art solutions are compared, and the
results of the proposed approach are analyzed on a standard dataset. For the
real-life implementation of the proposed solution, a Web-based application is
developed on Apache Storm, Kafka, Solr, and Milvus platforms to create a
fashion search engine called SnapMode.