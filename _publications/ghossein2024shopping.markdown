---
layout: publication
title: 'Shopping Queries Image Dataset (SQID): An Image-enriched ESCI Dataset For
  Exploring Multimodal Learning In Product Search'
authors: Marie Al Ghossein, Ching-Wei Chen, Jason Tang
conference: Arxiv
year: 2024
bibkey: ghossein2024shopping
citations: 0
additional_links: [{name: Code, url: 'https://github.com/Crossing-Minds/shopping-queries-image-dataset'},
  {name: Paper, url: 'https://arxiv.org/abs/2405.15190'}]
tags: ["Datasets"]
short_authors: Marie Al Ghossein, Ching-Wei Chen, Jason Tang
---
Recent advances in the fields of Information Retrieval and Machine Learning
have focused on improving the performance of search engines to enhance the user
experience, especially in the world of online shopping. The focus has thus been
on leveraging cutting-edge learning techniques and relying on large enriched
datasets. This paper introduces the Shopping Queries Image Dataset (SQID), an
extension of the Amazon Shopping Queries Dataset enriched with image
information associated with 190,000 products. By integrating visual
information, SQID facilitates research around multimodal learning techniques
that can take into account both textual and visual information for improving
product search and ranking. We also provide experimental results leveraging
SQID and pretrained models, showing the value of using multimodal data for
search and ranking. SQID is available at:
https://github.com/Crossing-Minds/shopping-queries-image-dataset.