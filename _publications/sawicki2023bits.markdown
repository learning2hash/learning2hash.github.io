---
layout: publication
title: 'Bits Of Grass: Does GPT Already Know How To Write Like Whitman?'
authors: Piotr Sawicki, Marek Grzes, Fabricio Goes, Dan Brown, Max Peeperkorn, Aisha
  Khatun
conference: Arxiv
year: 2023
bibkey: sawicki2023bits
citations: 2
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2305.11064'}]
tags: ["Evaluation"]
short_authors: Sawicki et al.
---
This study examines the ability of GPT-3.5, GPT-3.5-turbo (ChatGPT) and GPT-4
models to generate poems in the style of specific authors using zero-shot and
many-shot prompts (which use the maximum context length of 8192 tokens). We
assess the performance of models that are not fine-tuned for generating poetry
in the style of specific authors, via automated evaluation. Our findings
indicate that without fine-tuning, even when provided with the maximum number
of 17 poem examples (8192 tokens) in the prompt, these models do not generate
poetry in the desired style.