---
layout: publication
title: Exploiting and Defending Against the Approximate Linearity of Apples NeuralHash
authors: Bhatia Jagdeep Singh, Meng Kevin
conference: "Arxiv"
year: 2022
bibkey: bhatia2022exploiting
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2207.14258"}
tags: ['ARXIV', 'General', 'Graph']
---
Perceptual hashes map images with identical semantic content to the same n-bit hash value while mapping semantically-different images to different hashes. These algorithms carry important applications in cybersecurity such as copyright infringement detection content fingerprinting and surveillance. Apples NeuralHash is one such system that aims to detect the presence of illegal content on users devices without compromising consumer privacy. We make the surprising discovery that NeuralHash is approximately linear which inspires the development of novel black-box attacks that can (i) evade detection of illegal images (ii) generate near-collisions and (iii) leak information about hashed images all without access to model parameters. These vulnerabilities pose serious threats to NeuralHashs security goals; to address them we propose a simple fix using classical cryptographic standards.
