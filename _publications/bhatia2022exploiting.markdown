---
layout: publication
title: Exploiting And Defending Against The Approximate Linearity Of Apple's Neuralhash
authors: Jagdeep Singh Bhatia, Kevin Meng
conference: Arxiv
year: 2022
bibkey: bhatia2022exploiting
citations: 0
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2207.14258'}]
tags: ["Evaluation"]
short_authors: Jagdeep Singh Bhatia, Kevin Meng
---
Perceptual hashes map images with identical semantic content to the same
\(n\)-bit hash value, while mapping semantically-different images to different
hashes. These algorithms carry important applications in cybersecurity such as
copyright infringement detection, content fingerprinting, and surveillance.
Apple's NeuralHash is one such system that aims to detect the presence of
illegal content on users' devices without compromising consumer privacy. We
make the surprising discovery that NeuralHash is approximately linear, which
inspires the development of novel black-box attacks that can (i) evade
detection of "illegal" images, (ii) generate near-collisions, and (iii) leak
information about hashed images, all without access to model parameters. These
vulnerabilities pose serious threats to NeuralHash's security goals; to address
them, we propose a simple fix using classical cryptographic standards.