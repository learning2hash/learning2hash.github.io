---
layout: publication
title: Mixing Context Granularities For Improved Entity Linking On Question Answering
  Data Across Entity Categories
authors: Daniil Sorokin, Iryna Gurevych
conference: Proceedings of the Seventh Joint Conference on Lexical and Computational
  Semantics
year: 2018
bibkey: sorokin2018mixing
citations: 27
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1804.08460'}]
tags: []
short_authors: Daniil Sorokin, Iryna Gurevych
---
The first stage of every knowledge base question answering approach is to
link entities in the input question. We investigate entity linking in the
context of a question answering task and present a jointly optimized neural
architecture for entity mention detection and entity disambiguation that models
the surrounding context on different levels of granularity. We use the Wikidata
knowledge base and available question answering datasets to create benchmarks
for entity linking on question answering data. Our approach outperforms the
previous state-of-the-art system on this data, resulting in an average 8%
improvement of the final score. We further demonstrate that our model delivers
a strong performance across different entity categories.