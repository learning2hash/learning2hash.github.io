---
layout: publication
title: 'Black Is To Criminal As Caucasian Is To Police: Detecting And Removing Multiclass
  Bias In Word Embeddings'
authors: Thomas Manzini, Yao Chong Lim, Yulia Tsvetkov, Alan W Black
conference: Proceedings of the 2019 Conference of the North
year: 2019
bibkey: manzini2019black
citations: 276
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1904.04047'}]
tags: ["Evaluation"]
short_authors: Manzini et al.
---
Online texts -- across genres, registers, domains, and styles -- are riddled
with human stereotypes, expressed in overt or subtle ways. Word embeddings,
trained on these texts, perpetuate and amplify these stereotypes, and propagate
biases to machine learning models that use word embeddings as features. In this
work, we propose a method to debias word embeddings in multiclass settings such
as race and religion, extending the work of (Bolukbasi et al., 2016) from the
binary setting, such as binary gender. Next, we propose a novel methodology for
the evaluation of multiclass debiasing. We demonstrate that our multiclass
debiasing is robust and maintains the efficacy in standard NLP tasks.