---
layout: publication
title: Coophash Cooperative Learning Of Multipurpose Descriptor And Contrastive Pair Generator Via Variational MCMC Teaching For Supervised Image Hashing
authors: Doan Khoa D., Xie Jianwen, Zhu Yaxuan, Zhao Yang, Li Ping
conference: "Arxiv"
year: 2022
bibkey: doan2022coophash
additional_links:
  - {name: "Paper", url: "https://arxiv.org/abs/2210.04288"}
tags: ['ARXIV', 'Supervised']
---
Leveraging supervised information can lead to superior retrieval performance in the image hashing domain but the performance degrades significantly without enough labeled data. One effective solution to boost performance is to employ generative models such as Generative Adversarial Networks (GANs) to generate synthetic data in an image hashing model. However GAN45;based methods are difficult to train which prevents the hashing approaches from jointly training the generative models and the hash functions. This limitation results in sub45;optimal retrieval performance. To overcome this limitation we propose a novel framework the generative cooperative hashing network which is based on energy45;based cooperative learning. This framework jointly learns a powerful generative representation of the data and a robust hash function via two components a top45;down contrastive pair generator that synthesizes contrastive images and a bottom45;up multipurpose descriptor that simultaneously represents the images from multiple perspectives including probability density hash code latent code and category. The two components are jointly learned via a novel likelihood45;based cooperative learning scheme. We conduct experiments on several real45;world datasets and show that the proposed method outperforms the competing hashing supervised methods achieving up to 1037; relative improvement over the current state45;of45;the45;art supervised hashing methods and exhibits a significantly better performance in out45;of45;distribution retrieval.
