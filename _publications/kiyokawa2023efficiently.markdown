---
layout: publication
title: Efficiently Collecting Training Dataset For 2D Object Detection By Online Visual
  Feedback
authors: Takuya Kiyokawa, Naoki Shirakura, Hiroki Katayama, Keita Tomochika, Jun Takamatsu
conference: Journal of Robotics and Mechatronics
year: 2025
bibkey: kiyokawa2023efficiently
citations: 0
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2304.04901'}]
tags: ["Datasets"]
short_authors: Kiyokawa et al.
---
Training deep-learning-based vision systems require the manual annotation of
a significant number of images. Such manual annotation is highly time-consuming
and labor-intensive. Although previous studies have attempted to eliminate the
effort required for annotation, the effort required for image collection was
retained. To address this, we propose a human-in-the-loop dataset collection
method that uses a web application. To counterbalance the workload and
performance by encouraging the collection of multi-view object image datasets
in an enjoyable manner, thereby amplifying motivation, we propose three types
of online visual feedback features to track the progress of the collection
status. Our experiments thoroughly investigated the impact of each feature on
collection performance and quality of operation. The results suggested the
feasibility of annotation and object detection.