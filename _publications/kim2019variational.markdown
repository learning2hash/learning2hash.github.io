---
layout: publication
title: 'Variational Prototyping-encoder: One-shot Learning With Prototypical Images'
authors: Junsik Kim, Tae-Hyun Oh, Seokju Lee, Fei Pan, In So Kweon
conference: 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
year: 2019
bibkey: kim2019variational
citations: 67
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1904.08482'}]
tags: ["CVPR"]
short_authors: Kim et al.
---
In daily life, graphic symbols, such as traffic signs and brand logos, are
ubiquitously utilized around us due to its intuitive expression beyond language
boundary. We tackle an open-set graphic symbol recognition problem by one-shot
classification with prototypical images as a single training example for each
novel class. We take an approach to learn a generalizable embedding space for
novel tasks. We propose a new approach called variational prototyping-encoder
(VPE) that learns the image translation task from real-world input images to
their corresponding prototypical images as a meta-task. As a result, VPE learns
image similarity as well as prototypical concepts which differs from widely
used metric learning based approaches. Our experiments with diverse datasets
demonstrate that the proposed VPE performs favorably against competing metric
learning based one-shot methods. Also, our qualitative analyses show that our
meta-task induces an effective embedding space suitable for unseen data
representation.