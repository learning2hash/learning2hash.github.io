---
layout: publication
title: An Empirical Study On Large Scale Text Classification With Skip-gram Embeddings
authors: Georgios Balikas, Massih-Reza Amini
conference: Arxiv
year: 2016
bibkey: balikas2016empirical
citations: 12
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1606.06623'}]
tags: ["Efficiency", "Evaluation"]
short_authors: Georgios Balikas, Massih-Reza Amini
---
We investigate the integration of word embeddings as classification features
in the setting of large scale text classification. Such representations have
been used in a plethora of tasks, however their application in classification
scenarios with thousands of classes has not been extensively researched,
partially due to hardware limitations. In this work, we examine efficient
composition functions to obtain document-level from word-level embeddings and
we subsequently investigate their combination with the traditional
one-hot-encoding representations. By presenting empirical evidence on large,
multi-class, multi-label classification problems, we demonstrate the efficiency
and the performance benefits of this combination.