---
layout: publication
title: 'N24news: A New Dataset For Multimodal News Classification'
authors: Zhen Wang, Xu Shan, Xiangxie Zhang, Jie Yang
conference: Proceedings of the 13th Conference on Language Resources and Evaluation
  (LREC 2022) pages 6768-6775
year: 2021
bibkey: wang2021n24news
citations: 6
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2108.13327'}]
tags: ["Datasets", "Evaluation", "LREC"]
short_authors: Wang et al.
---
Current news datasets merely focus on text features on the news and rarely
leverage the feature of images, excluding numerous essential features for news
classification. In this paper, we propose a new dataset, N24News, which is
generated from New York Times with 24 categories and contains both text and
image information in each news. We use a multitask multimodal method and the
experimental results show multimodal news classification performs better than
text-only news classification. Depending on the length of the text, the
classification accuracy can be increased by up to 8.11%. Our research reveals
the relationship between the performance of a multimodal classifier and its
sub-classifiers, and also the possible improvements when applying multimodal in
news classification. N24News is shown to have great potential to prompt the
multimodal news studies.