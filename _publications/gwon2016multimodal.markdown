---
layout: publication
title: Multimodal Sparse Coding For Event Detection
authors: Youngjune Gwon, William Campbell, Kevin Brady, Douglas Sturim, Miriam Cha,
  H. T. Kung
conference: Arxiv
year: 2016
bibkey: gwon2016multimodal
citations: 7
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1605.05212'}]
tags: ["Unsupervised"]
short_authors: Gwon et al.
---
Unsupervised feature learning methods have proven effective for
classification tasks based on a single modality. We present multimodal sparse
coding for learning feature representations shared across multiple modalities.
The shared representations are applied to multimedia event detection (MED) and
evaluated in comparison to unimodal counterparts, as well as other feature
learning methods such as GMM supervectors and sparse RBM. We report the
cross-validated classification accuracy and mean average precision of the MED
system trained on features learned from our unimodal and multimodal settings
for a subset of the TRECVID MED 2014 dataset.