---
layout: publication
title: Evaluating Token-level And Passage-level Dense Retrieval Models For Math Information
  Retrieval
authors: Wei Zhong, Jheng-Hong Yang, Yuqing Xie, Jimmy Lin
conference: 'Findings of the Association for Computational Linguistics: EMNLP 2022'
year: 2022
bibkey: zhong2022evaluating
citations: 12
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2203.11163'}]
tags: [Efficiency, Datasets, EMNLP, ACL]
short_authors: Zhong et al.
---
With the recent success of dense retrieval methods based on bi-encoders,
studies have applied this approach to various interesting downstream retrieval
tasks with good efficiency and in-domain effectiveness. Recently, we have also
seen the presence of dense retrieval models in Math Information Retrieval (MIR)
tasks, but the most effective systems remain classic retrieval methods that
consider hand-crafted structure features. In this work, we try to combine the
best of both worlds:\ a well-defined structure search method for effective
formula search and efficient bi-encoder dense retrieval models to capture
contextual similarities. Specifically, we have evaluated two representative
bi-encoder models for token-level and passage-level dense retrieval on recent
MIR tasks. Our results show that bi-encoder models are highly complementary to
existing structure search methods, and we are able to advance the
state-of-the-art on MIR datasets.