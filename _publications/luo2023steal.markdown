---
layout: publication
title: Steal My Artworks For Fine-tuning? A Watermarking Framework For Detecting Art
  Theft Mimicry In Text-to-image Models
authors: Ge Luo, Junqiang Huang, Manman Zhang, Zhenxing Qian, Sheng Li, Xinpeng Zhang
conference: Arxiv
year: 2023
bibkey: luo2023steal
citations: 0
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2311.13619'}]
tags: []
short_authors: Luo et al.
---
The advancement in text-to-image models has led to astonishing artistic
performances. However, several studios and websites illegally fine-tune these
models using artists' artworks to mimic their styles for profit, which violates
the copyrights of artists and diminishes their motivation to produce original
works. Currently, there is a notable lack of research focusing on this issue.
In this paper, we propose a novel watermarking framework that detects mimicry
in text-to-image models through fine-tuning. This framework embeds subtle
watermarks into digital artworks to protect their copyrights while still
preserving the artist's visual expression. If someone takes watermarked
artworks as training data to mimic an artist's style, these watermarks can
serve as detectable indicators. By analyzing the distribution of these
watermarks in a series of generated images, acts of fine-tuning mimicry using
stolen victim data will be exposed. In various fine-tune scenarios and against
watermark attack methods, our research confirms that analyzing the distribution
of watermarks in artificially generated images reliably detects unauthorized
mimicry.