---
layout: publication
title: 'A3S: Adversarial Learning Of Semantic Representations For Scene-text Spotting'
authors: Masato Fujitake
conference: ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech
  and Signal Processing (ICASSP)
year: 2023
bibkey: fujitake2023a3s
citations: 7
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2302.10641'}]
tags: ["ICASSP", "Robustness"]
short_authors: Masato Fujitake
---
Scene-text spotting is a task that predicts a text area on natural scene
images and recognizes its text characters simultaneously. It has attracted much
attention in recent years due to its wide applications. Existing research has
mainly focused on improving text region detection, not text recognition. Thus,
while detection accuracy is improved, the end-to-end accuracy is insufficient.
Texts in natural scene images tend to not be a random string of characters but
a meaningful string of characters, a word. Therefore, we propose adversarial
learning of semantic representations for scene text spotting (A3S) to improve
end-to-end accuracy, including text recognition. A3S simultaneously predicts
semantic features in the detected text area instead of only performing text
recognition based on existing visual features. Experimental results on publicly
available datasets show that the proposed method achieves better accuracy than
other methods.