---
layout: publication
title: 'VSE++: Improving Visual-semantic Embeddings With Hard Negatives'
authors: Fartash Faghri, David J. Fleet, Jamie Ryan Kiros, Sanja Fidler
conference: "Arxiv"
year: 2017
citations: 558
bibkey: faghri2017improving
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/1707.05612'}
tags: ['Loss Functions', 'Applications', 'Tools and Libraries', 'Benchmarks and Datasets', 'Learning Strategies']
---
We present a new technique for learning visual-semantic embeddings for
cross-modal retrieval. Inspired by hard negative mining, the use of hard
negatives in structured prediction, and ranking loss functions, we introduce a
simple change to common loss functions used for multi-modal embeddings. That,
combined with fine-tuning and use of augmented data, yields significant gains
in retrieval performance. We showcase our approach, VSE++, on MS-COCO and
Flickr30K datasets, using ablation studies and comparisons with existing
methods. On MS-COCO our approach outperforms state-of-the-art methods by 8.8%
in caption retrieval and 11.3% in image retrieval (at R@1).
