---
layout: publication
title: 'YAD: Leveraging T5 For Improved Automatic Diacritization Of Yor\`ub\''a Text'
authors: Akindele Michael Olawole, Jesujoba O. Alabi, Aderonke Busayo Sakpere, David
  I. Adelani
conference: Arxiv
year: 2024
bibkey: olawole2024yad
citations: 0
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2412.20218'}]
tags: ["Datasets", "Evaluation"]
short_authors: Olawole et al.
---
In this work, we present Yor\`ub\'a automatic diacritization (YAD) benchmark
dataset for evaluating Yor\`ub\'a diacritization systems. In addition, we
pre-train text-to-text transformer, T5 model for Yor\`ub\'a and showed that
this model outperform several multilingually trained T5 models. Lastly, we
showed that more data and larger models are better at diacritization for
Yor\`ub\'a