---
layout: publication
title: Near-duplicate Video Detection Featuring Coupled Temporal And Perceptual Visual
  Structures And Logical Inference Based Matching
authors: B. Tahayna, M. Belkhatir
conference: Information Processing &amp; Management
year: 2011
bibkey: tahayna2011near
citations: 8
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2005.07356'}]
tags: ["Video Retrieval"]
short_authors: B. Tahayna, M. Belkhatir
---
We propose in this paper an architecture for near-duplicate video detection
based on: (i) index and query signature based structures integrating temporal
and perceptual visual features and (ii) a matching framework computing the
logical inference between index and query documents. As far as indexing is
concerned, instead of concatenating low-level visual features in
high-dimensional spaces which results in curse of dimensionality and redundancy
issues, we adopt a perceptual symbolic representation based on color and
texture concepts. For matching, we propose to instantiate a retrieval model
based on logical inference through the coupling of an N-gram sliding window
process and theoretically-sound lattice-based structures. The techniques we
cover are robust and insensitive to general video editing and/or degradation,
making it ideal for re-broadcasted video search. Experiments are carried out on
large quantities of video data collected from the TRECVID 02, 03 and 04
collections and real-world video broadcasts recorded from two German TV
stations. An empirical comparison over two state-of-the-art dynamic programming
techniques is encouraging and demonstrates the advantage and feasibility of our
method.