---
layout: publication
title: Uncertainty-based Cross-Modal Retrieval with Probabilistic Representations
authors: Pishdad et al.
conference: 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
year: 2022
bibkey: pishdad2022uncertainty
citations: 161
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2204.09268'}]
tags: ["CVPR", "Multimodal-Retrieval"]
---
Probabilistic embeddings have proven useful for capturing polysemous word
meanings, as well as ambiguity in image matching. In this paper, we study the
advantages of probabilistic embeddings in a cross-modal setting (i.e., text and
images), and propose a simple approach that replaces the standard vector point
embeddings in extant image-text matching models with probabilistic
distributions that are parametrically learned. Our guiding hypothesis is that
the uncertainty encoded in the probabilistic embeddings captures the
cross-modal ambiguity in the input instances, and that it is through capturing
this uncertainty that the probabilistic models can perform better at downstream
tasks, such as image-to-text or text-to-image retrieval. Through extensive
experiments on standard and new benchmarks, we show a consistent advantage for
probabilistic representations in cross-modal retrieval, and validate the
ability of our embeddings to capture uncertainty.