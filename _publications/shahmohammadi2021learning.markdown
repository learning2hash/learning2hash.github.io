---
layout: publication
title: Learning Zero-shot Multifaceted Visually Grounded Word Embeddings Via Multi-task
  Training
authors: Hassan Shahmohammadi, Hendrik P. A. Lensch, R. Harald Baayen
conference: Proceedings of the 25th Conference on Computational Natural Language Learning
year: 2021
bibkey: shahmohammadi2021learning
citations: 15
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2104.07500'}]
tags: ["Few Shot & Zero Shot"]
short_authors: Hassan Shahmohammadi, Hendrik P. A. Lensch, R. Harald Baayen
---
Language grounding aims at linking the symbolic representation of language
(e.g., words) into the rich perceptual knowledge of the outside world. The
general approach is to embed both textual and visual information into a common
space -the grounded space-confined by an explicit relationship between both
modalities. We argue that this approach sacrifices the abstract knowledge
obtained from linguistic co-occurrence statistics in the process of acquiring
perceptual information. The focus of this paper is to solve this issue by
implicitly grounding the word embeddings. Rather than learning two mappings
into a joint space, our approach integrates modalities by determining a
reversible grounded mapping between the textual and the grounded space by means
of multi-task learning. Evaluations on intrinsic and extrinsic tasks show that
our embeddings are highly beneficial for both abstract and concrete words. They
are strongly correlated with human judgments and outperform previous works on a
wide range of benchmarks. Our grounded embeddings are publicly available here.