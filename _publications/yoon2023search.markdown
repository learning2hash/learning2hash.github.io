---
layout: publication
title: 'Search-adaptor: Embedding Customization For Information Retrieval'
authors: Yoon Jinsung, Arik Sercan O, Chen Yanfei, Pfister Tomas
conference: 'Proceedings of the 62nd Annual Meeting of the Association for Computational
  Linguistics (Volume 1: Long Papers)'
year: 2024
bibkey: yoon2023search
citations: 0
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2310.08750'}]
tags: ["Evaluation", "Few-shot & Zero-shot", "Information Retrieval", "Multimodal Retrieval"]
short_authors: Yoon et al.
---
Embeddings extracted by pre-trained Large Language Models (LLMs) have
significant potential to improve information retrieval and search. Beyond the
zero-shot setup in which they are being conventionally used, being able to take
advantage of the information from the relevant query-corpus paired data can
further boost the LLM capabilities. In this paper, we propose a novel method,
Search-Adaptor, for customizing LLMs for information retrieval in an efficient
and robust way. Search-Adaptor modifies the embeddings generated by pre-trained
LLMs, and can be integrated with any LLM, including those only available via
prediction APIs. On multiple English, multilingual, and multimodal retrieval
datasets, we show consistent and significant performance benefits for
Search-Adaptor -- e.g., more than 5% improvements for Google Embedding APIs in
nDCG@10 averaged over 14 BEIR datasets.