---
layout: publication
title: 'Cross-modal Retrieval In The Cooking Context: Learning Semantic Text-image
  Embeddings'
authors: "Micael Carvalho, R\xE9mi Cad\xE8ne, David Picard, Laure Soulier, Nicolas\
  \ Thome, Matthieu Cord"
conference: Arxiv
year: 2018
bibkey: carvalho2018cross
citations: 39
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1804.11146'}]
tags: ["Datasets", "Multimodal Retrieval", "Scalability"]
short_authors: Carvalho et al.
---
Designing powerful tools that support cooking activities has rapidly gained
popularity due to the massive amounts of available data, as well as recent
advances in machine learning that are capable of analyzing them. In this paper,
we propose a cross-modal retrieval model aligning visual and textual data (like
pictures of dishes and their recipes) in a shared representation space. We
describe an effective learning scheme, capable of tackling large-scale
problems, and validate it on the Recipe1M dataset containing nearly 1 million
picture-recipe pairs. We show the effectiveness of our approach regarding
previous state-of-the-art models and present qualitative results over
computational cooking use cases.