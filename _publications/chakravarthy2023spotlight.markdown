---
layout: publication
title: 'Spotlight Attention: Robust Object-centric Learning With A Spatial Locality
  Prior'
authors: Ayush Chakravarthy, Trang Nguyen, Anirudh Goyal, Yoshua Bengio, Michael C.
  Mozer
conference: Arxiv
year: 2023
bibkey: chakravarthy2023spotlight
citations: 0
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2305.19550'}]
tags: []
short_authors: Chakravarthy et al.
---
The aim of object-centric vision is to construct an explicit representation
of the objects in a scene. This representation is obtained via a set of
interchangeable modules called *slots* or *object files* that compete
for local patches of an image. The competition has a weak inductive bias to
preserve spatial continuity; consequently, one slot may claim patches scattered
diffusely throughout the image. In contrast, the inductive bias of human vision
is strong, to the degree that attention has classically been described with a
spotlight metaphor. We incorporate a spatial-locality prior into
state-of-the-art object-centric vision models and obtain significant
improvements in segmenting objects in both synthetic and real-world datasets.
Similar to human visual attention, the combination of image content and spatial
constraints yield robust unsupervised object-centric learning, including less
sensitivity to model hyperparameters.