---
layout: publication
title: Image Search With Text Feedback By Additive Attention Compositional Learning
authors: Yuxin Tian, Shawn Newsam, Kofi Boakye
conference: Arxiv
year: 2022
bibkey: tian2022image
citations: 5
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2203.03809'}]
tags: ["Datasets", "Evaluation", "Image Retrieval"]
short_authors: Yuxin Tian, Shawn Newsam, Kofi Boakye
---
Effective image retrieval with text feedback stands to impact a range of
real-world applications, such as e-commerce. Given a source image and text
feedback that describes the desired modifications to that image, the goal is to
retrieve the target images that resemble the source yet satisfy the given
modifications by composing a multi-modal (image-text) query. We propose a novel
solution to this problem, Additive Attention Compositional Learning (AACL),
that uses a multi-modal transformer-based architecture and effectively models
the image-text contexts. Specifically, we propose a novel image-text
composition module based on additive attention that can be seamlessly plugged
into deep neural networks. We also introduce a new challenging benchmark
derived from the Shopping100k dataset. AACL is evaluated on three large-scale
datasets (FashionIQ, Fashion200k, and Shopping100k), each with strong
baselines. Extensive experiments show that AACL achieves new state-of-the-art
results on all three datasets.