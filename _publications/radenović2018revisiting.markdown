---
layout: publication
title: 'Revisiting Oxford And Paris: Large-scale Image Retrieval Benchmarking'
authors: Filip Radenović, Ahmet Iscen, Giorgos Tolias, Yannis Avrithis, Ondřej Chum
conference: "Arxiv"
year: 2018
citations: 207
bibkey: radenović2018revisiting
additional_links:
  - {name: "Paper", url: 'https://arxiv.org/abs/1803.11285'}
tags: ['Cross-Modal', 'Retrieval Models', 'Shallow', 'Datasets', 'Vector Indexing', 'Supervised', 'Applications']
---
In this paper we address issues with image retrieval benchmarking on standard
and popular Oxford 5k and Paris 6k datasets. In particular, annotation errors,
the size of the dataset, and the level of challenge are addressed: new
annotation for both datasets is created with an extra attention to the
reliability of the ground truth. Three new protocols of varying difficulty are
introduced. The protocols allow fair comparison between different methods,
including those using a dataset pre-processing stage. For each dataset, 15 new
challenging queries are introduced. Finally, a new set of 1M hard,
semi-automatically cleaned distractors is selected.
  An extensive comparison of the state-of-the-art methods is performed on the
new benchmark. Different types of methods are evaluated, ranging from
local-feature-based to modern CNN based methods. The best results are achieved
by taking the best of the two worlds. Most importantly, image retrieval appears
far from being solved.
