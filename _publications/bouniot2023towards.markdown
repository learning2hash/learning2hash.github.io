---
layout: publication
title: 'Towards Few-annotation Learning For Object Detection: Are Transformer-based
  Models More Efficient ?'
authors: "Quentin Bouniot, Ang\xE9lique Loesch, Romaric Audigier, Amaury Habrard"
conference: 2023 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)
year: 2023
bibkey: bouniot2023towards
citations: 4
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2310.19936'}]
tags: ["Few Shot & Zero Shot", "Transformer Based ANN"]
short_authors: Bouniot et al.
---
For specialized and dense downstream tasks such as object detection, labeling
data requires expertise and can be very expensive, making few-shot and
semi-supervised models much more attractive alternatives. While in the few-shot
setup we observe that transformer-based object detectors perform better than
convolution-based two-stage models for a similar amount of parameters, they are
not as effective when used with recent approaches in the semi-supervised
setting. In this paper, we propose a semi-supervised method tailored for the
current state-of-the-art object detector Deformable DETR in the few-annotation
learning setup using a student-teacher architecture, which avoids relying on a
sensitive post-processing of the pseudo-labels generated by the teacher model.
We evaluate our method on the semi-supervised object detection benchmarks COCO
and Pascal VOC, and it outperforms previous methods, especially when
annotations are scarce. We believe that our contributions open new
possibilities to adapt similar object detection methods in this setup as well.