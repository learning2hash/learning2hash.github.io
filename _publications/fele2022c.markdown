---
layout: publication
title: 'C-VTON: Context-driven Image-based Virtual Try-on Network'
authors: "Benjamin Fele, Ajda Lampe, Peter Peer, Vitomir \u0160truc"
conference: 2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)
year: 2022
bibkey: fele2022c
citations: 42
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2212.04437'}]
tags: []
short_authors: Fele et al.
---
Image-based virtual try-on techniques have shown great promise for enhancing
the user-experience and improving customer satisfaction on fashion-oriented
e-commerce platforms. However, existing techniques are currently still limited
in the quality of the try-on results they are able to produce from input images
of diverse characteristics. In this work, we propose a Context-Driven Virtual
Try-On Network (C-VTON) that addresses these limitations and convincingly
transfers selected clothing items to the target subjects even under challenging
pose configurations and in the presence of self-occlusions. At the core of the
C-VTON pipeline are: (i) a geometric matching procedure that efficiently aligns
the target clothing with the pose of the person in the input images, and (ii) a
powerful image generator that utilizes various types of contextual information
when synthesizing the final try-on result. C-VTON is evaluated in rigorous
experiments on the VITON and MPV datasets and in comparison to state-of-the-art
techniques from the literature. Experimental results show that the proposed
approach is able to produce photo-realistic and visually convincing results and
significantly improves on the existing state-of-the-art.