---
layout: publication
title: Contrastive Ground-level Image And Remote Sensing Pre-training Improves Representation
  Learning For Natural World Imagery
authors: "Andy V. Huynh, Lauren E. Gillespie, Jael Lopez-Saucedo, Claire Tang, Rohan\
  \ Sikand, Mois\xE9s Exp\xF3sito-Alonso"
conference: Lecture Notes in Computer Science
year: 2024
bibkey: huynh2024contrastive
citations: 1
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2409.19439'}]
tags: ["Self-Supervised"]
short_authors: Huynh et al.
---
Multimodal image-text contrastive learning has shown that joint
representations can be learned across modalities. Here, we show how leveraging
multiple views of image data with contrastive learning can improve downstream
fine-grained classification performance for species recognition, even when one
view is absent. We propose ContRastive Image-remote Sensing Pre-training
(CRISP)\(\unicode\{x2014\}\)a new pre-training task for ground-level and aerial
image representation learning of the natural world\(\unicode\{x2014\}\)and
introduce Nature Multi-View (NMV), a dataset of natural world imagery including
\(>3\) million ground-level and aerial image pairs for over 6,000 plant taxa
across the ecologically diverse state of California. The NMV dataset and
accompanying material are available at
hf.co/datasets/andyvhuynh/NatureMultiView.