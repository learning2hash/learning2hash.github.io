---
layout: publication
title: When VLAD Met Hilbert
authors: Mehrtash Harandi, Mathieu Salzmann, Fatih Porikli
conference: Arxiv
year: 2015
bibkey: harandi2015when
citations: 0
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1507.08373'}]
tags: []
short_authors: Mehrtash Harandi, Mathieu Salzmann, Fatih Porikli
---
Vectors of Locally Aggregated Descriptors (VLAD) have emerged as powerful
image/video representations that compete with or even outperform
state-of-the-art approaches on many challenging visual recognition tasks. In
this paper, we address two fundamental limitations of VLAD: its requirement for
the local descriptors to have vector form and its restriction to linear
classifiers due to its high-dimensionality. To this end, we introduce a
kernelized version of VLAD. This not only lets us inherently exploit more
sophisticated classification schemes, but also enables us to efficiently
aggregate non-vector descriptors (e.g., tensors) in the VLAD framework.
Furthermore, we propose three approximate formulations that allow us to
accelerate the coding process while still benefiting from the properties of
kernel VLAD. Our experiments demonstrate the effectiveness of our approach at
handling manifold-valued data, such as covariance descriptors, on several
classification tasks. Our results also evidence the benefits of our nonlinear
VLAD descriptors against the linear ones in Euclidean space using several
standard benchmark datasets.