---
layout: publication
title: Content And Context Features For Scene Image Representation
authors: Chiranjibi Sitaula, Sunil Aryal, Yong Xiang, Anish Basnet, Xuequan Lu
conference: Knowledge-Based Systems
year: 2021
bibkey: sitaula2020content
citations: 26
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2006.03217'}]
tags: ["Datasets", "Evaluation"]
short_authors: Sitaula et al.
---
Existing research in scene image classification has focused on either content
features (e.g., visual information) or context features (e.g., annotations). As
they capture different information about images which can be complementary and
useful to discriminate images of different classes, we suppose the fusion of
them will improve classification results. In this paper, we propose new
techniques to compute content features and context features, and then fuse them
together. For content features, we design multi-scale deep features based on
background and foreground information in images. For context features, we use
annotations of similar images available in the web to design a filter words
(codebook). Our experiments in three widely used benchmark scene datasets using
support vector machine classifier reveal that our proposed context and content
features produce better results than existing context and content features,
respectively. The fusion of the proposed two types of features significantly
outperform numerous state-of-the-art features.