---
layout: publication
title: Learning Geometric Word Meta-embeddings
authors: Pratik Jawanpuria, N T V Satya Dev, Anoop Kunchukuttan, Bamdev Mishra
conference: Proceedings of the 5th Workshop on Representation Learning for NLP
year: 2020
bibkey: jawanpuria2020learning
citations: 12
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2004.09219'}]
tags: []
short_authors: Jawanpuria et al.
---
We propose a geometric framework for learning meta-embeddings of words from
different embedding sources. Our framework transforms the embeddings into a
common latent space, where, for example, simple averaging of different
embeddings (of a given word) is more amenable. The proposed latent space arises
from two particular geometric transformations - the orthogonal rotations and
the Mahalanobis metric scaling. Empirical results on several word similarity
and word analogy benchmarks illustrate the efficacy of the proposed framework.