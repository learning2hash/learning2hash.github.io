---
layout: publication
title: Self-augmented Multi-modal Feature Embedding
authors: Shinnosuke Matsuo, Seiichi Uchida, Brian Kenji Iwana
conference: ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech
  and Signal Processing (ICASSP)
year: 2021
bibkey: matsuo2021self
citations: 4
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2103.04731'}]
tags: ["ICASSP"]
short_authors: Shinnosuke Matsuo, Seiichi Uchida, Brian Kenji Iwana
---
Oftentimes, patterns can be represented through different modalities. For
example, leaf data can be in the form of images or contours. Handwritten
characters can also be either online or offline. To exploit this fact, we
propose the use of self-augmentation and combine it with multi-modal feature
embedding. In order to take advantage of the complementary information from the
different modalities, the self-augmented multi-modal feature embedding employs
a shared feature space. Through experimental results on classification with
online handwriting and leaf images, we demonstrate that the proposed method can
create effective embeddings.