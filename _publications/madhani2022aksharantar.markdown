---
layout: publication
title: 'Aksharantar: Open Indic-language Transliteration Datasets And Models For The
  Next Billion Users'
authors: Yash Madhani, Sushane Parthan, Priyanka Bedekar, Gokul Nc, Ruchi Khapra,
  Anoop Kunchukuttan, Pratyush Kumar, Mitesh M. Khapra
conference: 'Findings of the Association for Computational Linguistics: EMNLP 2023'
year: 2023
bibkey: madhani2022aksharantar
citations: 11
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2205.03018'}]
tags: ["Datasets", "EMNLP"]
short_authors: Madhani et al.
---
Transliteration is very important in the Indian language context due to the
usage of multiple scripts and the widespread use of romanized inputs. However,
few training and evaluation sets are publicly available. We introduce
Aksharantar, the largest publicly available transliteration dataset for Indian
languages created by mining from monolingual and parallel corpora, as well as
collecting data from human annotators. The dataset contains 26 million
transliteration pairs for 21 Indic languages from 3 language families using 12
scripts. Aksharantar is 21 times larger than existing datasets and is the first
publicly available dataset for 7 languages and 1 language family. We also
introduce the Aksharantar testset comprising 103k word pairs spanning 19
languages that enables a fine-grained analysis of transliteration models on
native origin words, foreign words, frequent words, and rare words. Using the
training set, we trained IndicXlit, a multilingual transliteration model that
improves accuracy by 15% on the Dakshina test set, and establishes strong
baselines on the Aksharantar testset introduced in this work. The models,
mining scripts, transliteration guidelines, and datasets are available at
https://github.com/AI4Bharat/IndicXlit under open-source licenses. We hope the
availability of these large-scale, open resources will spur innovation for
Indic language transliteration and downstream applications. We hope the
availability of these large-scale, open resources will spur innovation for
Indic language transliteration and downstream applications.