<!DOCTYPE html>
<html lang="en-us">

  <head>
  <!-- Hotjar Tracking Code for https://learning2hash.github.io/ -->
<script>
    (function(h,o,t,j,a,r){
        h.hj=h.hj||function(){(h.hj.q=h.hj.q||[]).push(arguments)};
        h._hjSettings={hjid:1843243,hjsv:6};
        a=o.getElementsByTagName('head')[0];
        r=o.createElement('script');r.async=1;
        r.src=t+h._hjSettings.hjid+j+h._hjSettings.hjsv;
        a.appendChild(r);
    })(window,document,'https://static.hotjar.com/c/hotjar-','.js?sv=');
</script><!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-109544763-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-109544763-1');
</script>

  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="keywords" content="machine learning, hashing, approximate nearest neighbour search, lsh, learning-to-hash">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Tutorial | Awesome Learning to Hash</title>
<meta name="generator" content="Jekyll v4.1.0" />
<meta property="og:title" content="Tutorial" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="In this tutorial we explore a learning to hash model and compare its performance to Locality Sensitive Hashing (LSH)." />
<meta property="og:description" content="In this tutorial we explore a learning to hash model and compare its performance to Locality Sensitive Hashing (LSH)." />
<link rel="canonical" href="https://learning2hash.github.io/tutorial.html" />
<meta property="og:url" content="https://learning2hash.github.io/tutorial.html" />
<meta property="og:site_name" content="Awesome Learning to Hash" />
<script type="application/ld+json">
{"url":"https://learning2hash.github.io/tutorial.html","headline":"Tutorial","@type":"WebPage","description":"In this tutorial we explore a learning to hash model and compare its performance to Locality Sensitive Hashing (LSH).","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="shortcut icon" href="/public/favicon.svg">
  <link rel="search" href="/public/opensearchdescription.xml" 
      type="application/opensearchdescription+xml" 
      title="learning2hash" />

  <script src="https://code.jquery.com/jquery-3.2.1.min.js"
  integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
  crossorigin="anonymous"></script>
  
  <link rel="stylesheet" type="text/css" href="//cdn.datatables.net/1.10.16/css/jquery.dataTables.min.css">
  <script type="text/javascript" charset="utf8" src="//cdn.datatables.net/1.10.16/js/jquery.dataTables.min.js"></script>
</head>


  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

  <body class="theme-base-0c layout-reverse">

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Awesome Learning to Hash
        </a>
      </h1>
      <p class="lead">A webpage dedicated to the latest research on learning-to-hash, including state-of-the-art deep hashing models, all updated on a weekly basis. Maintained by <a href="http://sjmoran.github.io/">Sean Moran</a>.</p>
    </div>

  <nav class="sidebar-nav">
   <div class="sidebar-item"><p style="font-size: 12px">Search related work <input type='text' id='searchTarget' size="16"/> <button onClick="search();">Go</button></p></div>
    <a class="sidebar-nav-item" href="/papers.html">All Papers</a>
   <a class="sidebar-nav-item" href="/tags.html">Papers by Tag</a>
   <a class="sidebar-nav-item" href="/tsne-viz.html">2D Map of Papers</a>
   <a class="sidebar-nav-item" href="/base-taxonomy/">Core Taxonomy</a>
   <a class="sidebar-nav-item-small" href="/base-taxonomy/quantisation.html">Quantisation Models</a>
   <a class="sidebar-nav-item-small" href="/base-taxonomy/supervised.html">Supervised Projection Models</a>
   <a class="sidebar-nav-item-small" href="/base-taxonomy/unsupervised.html">Unsupervised Projection Models</a></ul>
   <a class="sidebar-nav-item-small" href="/base-taxonomy/independent.html">Data Independent Projection Models</a></ul>
  <a class="sidebar-nav-item" href="/base-taxonomy/datasets.html">Datasets</a>
  <a class="sidebar-nav-item" href="/resources.html">Resources, Courses &#38; Events</a>
  <a class="sidebar-nav-item" href="/tutorial.html">Tutorial</a>
  <a class="sidebar-nav-item" href="/contributing.html">Contributing</a>
  <a class="sidebar-nav-item" href="/contributors.html">Contributors</a>
   <a class="sidebar-nav-item" href="/cite.html">How to Cite this Site</a>

</nav>

  <div class="sidebar-item">
    <p style="font-size: 12px">Contact <a href="http://www.seanjmoran.com">Sean Moran</a> about this survey or website.
    <span style="font-size: 9px">
      Made with <a href="https://jekyllrb.com">Jekyll</a> and <a href="https://github.com/poole/hyde">Hyde</a>.
    </span></p>
  </div>
</div></div>

<script>
$("#searchTarget").keydown(function (e) {	
  if (e.keyCode == 13) {
    search();
  }
});
function search() {
  try {
    ga('send', 'event', 'search', 'search', $("#searchTarget").val());
  } finally {
    window.location = "/papers.html#" + $("#searchTarget").val();
  }
}
</script>


    <div class="content container">
      <p>In this tutorial we explore a learning to hash model and compare its performance to Locality Sensitive Hashing (LSH).</p>

<p>Specifically we will implement rgw <a href="https://sjmoran.github.io/pdfs/grh_ecir15.pdf">Graph Regularised Hashing (GRH)</a> model of Moran and Lavrenko, a simple but empirically effective model for learning to hash. The citation bibtex can be found <a href="https://sjmoran.github.io/bib/grh.bib">here</a>.</p>

<p>The original Matlab code supplied by the authors is <a href="https://github.com/sjmoran/GRH">here</a>. We will code up a version of the model in Python 3. This tutorial will train the model on the CIFAR-10 dataset and benchmark retrieval effectiveness against LSH (random projections) using the precision at 10 metric.</p>

<p>First step is to instantiate a virtual environment for Python3:</p>

<pre>
python3 -m venv ./hashing_tutorial
source hashing_tutorial/bin/activate
</pre>

<p>We retrieve and pre-process the CIFAR-10 dataset as follows:</p>

<pre>
import scipy.io
import os
import requests

url='https://www.dropbox.com/s/875u1rkva9iffpj/Gist512CIFAR10.mat?dl=1'
response = requests.get(url)
with open(os.path.join("./", "Gist512CIFAR10.mat"), 'wb') as f:
    f.write(response.content)

mat = scipy.io.loadmat('./Gist512CIFAR10.mat')

data = mat['X']
classes = mat['X_class']
</pre>

<p>The above code should download and save the CIFAR-10 dataset pre-processed into GIST features to the current directory. We will now generate 16 random hyperplanes and project one image onto these hyperplanes, generating the hashcode:</p>

<pre>
import numpy as np

num_classes = 10
n_vectors = 32
dim = 512

np.random.seed(0)
random_vectors = np.random.randn(dim, n_vectors)
print(random_vectors)

print('dimension:', data[0,:].shape)
bin_indices_bits = data[0,:].dot(random_vectors) &gt;= 0

print(bin_indices_bits)

# [False  True False  True False  True False False False False  True  True True False False False]

</pre>

<p>The last line of code prints out the hashcode assigned to this image. Images with the exact same hashcode will collide in the same hashtable bucket. We would like these colliding images to be semantically similar i.e. have the same class label.</p>

<p>We now convert the boolean representation above into an integer representation that will denote the bin indices:</p>

<pre>
# https://wiki.python.org/moin/BitwiseOperators
# x &lt;&lt; y is the same as multiplying x by 2 ** y
powers_of_two = 1 &lt;&lt; np.arange(n_vectors - 1, -1, step=-1)
print(powers_of_two)
# [32768 16384  8192  4096  2048  1024   512   256   128    64    32    16    8     4     2     1]

bin_indices = bin_indices_bits.dot(powers_of_two)
print(bin_indices)
# 21560
</pre>

<p>The example image will hash into hashtable bucket with index 21560. Now we will hash the entire dataset using matrix operations:</p>

<pre>
bin_indices_bits = data.dot(random_vectors) &gt;= 0
print(bin_indices_bits.shape)
bin_indices = bin_indices_bits.dot(powers_of_two)
bin_indices.shape
</pre>

<p>bin_indices now contains 60,000 bin indices, one for each of the 60,000 images in the CIFAR-10 dataset. We now insert these images into a hashtable and inspect the duplicates:</p>

<pre>
from collections import defaultdict

table = defaultdict(list)
for idx, bin_index in enumerate(bin_indices):
	table[bin_index].append(idx)

for bucket,images in table.items():
	if len(images)&gt;1:
		print(images)
</pre>

<p>The code above will print out the buckets of the hashtable with at least two images and the associated IDs (i.e. row numbers in the original .mat file) of the images in each bucket. The average bin count is ~51 images, so there has been many collisions of images into buckets. Next we will inspect some of the buckets to gain an understanding of the quality of the hashing with LSH:</p>

<pre>
# We take this bucket and inspect the images:
# [46262, 46488, 47724, 59147, 59462, 59572]

print(classes.shape)
print(classes[:,46262])   # 3
print(classes[:,46488])   # 8
print(classes[:,47724])   # 7
print(classes[:,59147])   # 9
print(classes[:,59462])   # 2
print(classes[:,59572])   # 8
</pre>

<p>On this particular example we can see that LSH does fairly poorly, with only two semantically related images (class 8), colliding in the same bucket. We will inspect another bucket before moving on:</p>

<pre>
# We take this bucket and inspect the images:
# [16380, 18515, 27324, 33419, 43442, 46613, 54356]

print(classes.shape)
print(classes[:,16380])   # 0
print(classes[:,18515])   # 8
print(classes[:,27324])   # 0
print(classes[:,33419])   # 0
print(classes[:,43442])   # 0
print(classes[:,46613])   # 0
print(classes[:,54356])   # 0
</pre>

<p>In this case we see that LSH performs very well, with most of the colliding images coming from the same class label (0).</p>

<p>We now quantify the semantic retrieval effectieness of LSH more formally using the precision at search radius 10 as the number of hashcode bits are varied. Precision at 10 measures how many of the 10 retrieved nearest neighbours for a query are of the same class as the query. Firstly we create a set of queries randomly sampled from the CIFAR-10 dataset:</p>

<pre>
from sklearn.model_selection import train_test_split
np.random.seed(0)
data_train, data_test, labels_train, labels_test = train_test_split(data, classes[0,:], test_size=0.01, random_state=42)
</pre>

<p>This code will give 600 random queries that we will use alongside the LSH search index to find nearest neighbours. To search for nearest neighbours we apply a <em>Hamming radius based search</em>. In a nutshell this search methodology works by also looking in nearby bins that different from the current bin by a certain number of bits, up to a specific maximum radius. We can use the itertools combinations function to enumerate all the bins that differ from the current bin with respect to a certain number of bits, up to a maximum radius of 2 bits. As well as returning neighbours in the same bin, we also return neighbours from the nearby bins.</p>

<pre>
from itertools import combinations
from sklearn.metrics.pairwise import pairwise_distances
import pandas as pd

max_search_radius=2
topn=10
precision_history = {i: [] for i in range(max_search_radius)}

for query_image, query_label in zip(data_test,labels_test):
    bin_index_bits = np.ravel(query_image.dot(random_vectors) &gt;= 0)

    candidate_set = set()
    for search_radius in range(max_search_radius):
    	n_vectors = bin_index_bits.shape[0]
    	for different_bits in combinations(range(n_vectors), max_search_radius):
    		index = list(different_bits)
    		alternate_bits = bin_index_bits.copy()
    		alternate_bits[index] = np.logical_not(alternate_bits[index])
    		nearby_bin = alternate_bits.dot(powers_of_two)
    		if nearby_bin in table:
    			candidate_set.update(table[nearby_bin])

    	# sort candidates by their true distances from the query
    	candidate_list = list(candidate_set)
    	candidates = data[candidate_list[:]]
    	ground_truth = classes[:,candidate_list[:]][0]
    	distance = pairwise_distances(candidates, query_image.reshape(1,-1), metric='cosine').flatten()
    	distance_col = 'distance'
    	nearest_neighbors = pd.DataFrame({
        	'id': candidate_list, 'class': ground_truth, distance_col: distance
    	}).sort_values(distance_col).reset_index(drop=True)

    	candidate_set_labels = nearest_neighbors.sort_values(by=['distance'], ascending=True)['class'][:10]
    	precision = list(candidate_set_labels).count(query_label) / topn
    	precision_history[search_radius].append(precision)

mean_precision = [np.mean(precision_history[i]) for i in range(len(precision_history))]
print(mean_precision)	
</pre>

<p>The above code will produce a mean precision@10 of 0.43 across all of the 600 queries. On average, given a list of 10 returned images, 40% of those will be relevant to the query. This is not bad performance, especially since the hyperplanes were generated randomly! We now investigate how learning the hyperplanes (i.e. learning to hash) can afford a much higher level or retrieval effectiveness.</p>

<p><em>Acknowledgement:</em> Parts of this tutorial were inspired by the text-based LSH tutorial <a href="http://ethen8181.github.io/machine-learning/recsys/content_based/lsh_text.html">here</a>.</p>

    </div>

  </body>
</html>
