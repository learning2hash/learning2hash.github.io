<!DOCTYPE html>
<html lang="en-us">

  <head>
<!-- Begin Web-Stat code v 7.0 -->
<span id="wts2185304"></span>
<script>var wts=document.createElement('script');wts.async=true;
wts.src='https://app.ardalio.com/log7.js';document.head.appendChild(wts);
wts.onload = function(){ wtslog7(2185304,4); };
</script><noscript><a href="https://www.web-stat.com">
<img src="https://app.ardalio.com/7/4/2185304.png" 
alt="Web-Stat web statistics"></a></noscript>
<!-- End Web-Stat code v 7.0 -->
  <!-- Hotjar Tracking Code for https://learning2hash.github.io/ -->
<script>
    (function(h,o,t,j,a,r){
        h.hj=h.hj||function(){(h.hj.q=h.hj.q||[]).push(arguments)};
        h._hjSettings={hjid:1843243,hjsv:6};
        a=o.getElementsByTagName('head')[0];
        r=o.createElement('script');r.async=1;
        r.src=t+h._hjSettings.hjid+j+h._hjSettings.hjsv;
        a.appendChild(r);
    })(window,document,'https://static.hotjar.com/c/hotjar-','.js?sv=');
</script><!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-109544763-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-109544763-1');
</script>

  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="keywords" content="machine learning, hashing, approximate nearest neighbour search, lsh, learning-to-hash">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Tutorial | Awesome Learning to Hash</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="Tutorial" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A webpage dedicated to the latest research on learning-to-hash, including state-of-the-art deep hashing models, all updated on a weekly basis. Maintained by Sean Moran." />
<meta property="og:description" content="A webpage dedicated to the latest research on learning-to-hash, including state-of-the-art deep hashing models, all updated on a weekly basis. Maintained by Sean Moran." />
<link rel="canonical" href="https://learning2hash.github.io/tutorial.html" />
<meta property="og:url" content="https://learning2hash.github.io/tutorial.html" />
<meta property="og:site_name" content="Awesome Learning to Hash" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Tutorial" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"A webpage dedicated to the latest research on learning-to-hash, including state-of-the-art deep hashing models, all updated on a weekly basis. Maintained by Sean Moran.","headline":"Tutorial","url":"https://learning2hash.github.io/tutorial.html"}</script>
<!-- End Jekyll SEO tag -->


  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="shortcut icon" href="/public/favicon.svg">
  <link rel="search" href="/public/opensearchdescription.xml" 
      type="application/opensearchdescription+xml" 
      title="learning2hash" />

  <script src="https://code.jquery.com/jquery-3.2.1.min.js"
  integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
  crossorigin="anonymous"></script>
  
  <link rel="stylesheet" type="text/css" href="//cdn.datatables.net/1.10.16/css/jquery.dataTables.min.css">
  <script type="text/javascript" charset="utf8" src="//cdn.datatables.net/1.10.16/js/jquery.dataTables.min.js"></script>
</head>


  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

  <body class="theme-base-0c layout-reverse">

    <a href='/contributing.html' class='ribbon'>Add your paper to Learning2Hash</a>
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Awesome Learning to Hash
        </a>
      </h1>
      <p class="lead">A webpage dedicated to the latest research on learning-to-hash, including state-of-the-art deep hashing models, all updated on a weekly basis. Maintained by <a href="http://sjmoran.github.io/">Sean Moran</a>.</p>
    </div>

    <nav class="sidebar-nav">
      <div class="sidebar-item">
        <p style="font-size: 12px">
          Search related work 
          <input type='text' id='searchTarget' size="16"/> 
          <button onClick="search();">Go</button>
        </p>
      </div>
      <a class="sidebar-nav-item" href="/papers.html">All Papers</a>
      <a class="sidebar-nav-item" href="/tags.html">Papers by Tag</a>
      <a class="sidebar-nav-item" href="/tsne-viz.html">2D Map of Papers</a>
      <a class="sidebar-nav-item" href="/topic-viz.html">Topic-based Explorer</a>
      <a class="sidebar-nav-item" href="/base-taxonomy/">Core Taxonomy</a>
      <a class="sidebar-nav-item" href="/base-taxonomy/datasets.html">Datasets</a>
      <a class="sidebar-nav-item" href="/tutorial.html">Tutorial</a>
      <a class="sidebar-nav-item" href="/vector_indexing.html">LLMs, RAG & Hashin</a>
      <a class="sidebar-nav-item" href="/resources.md">Resources, Courses &#38; Events</a>
      <a class="sidebar-nav-item" href="/contributing.html">Contributing</a>
      <a class="sidebar-nav-item" href="/contributors.html">Contributors</a>
      <a class="sidebar-nav-item" href="/cite.html">How to Cite this Site</a>
    </nav>

    <div class="sidebar-item">
      <p style="font-size: 12px">
        Contact <a href="http://www.seanjmoran.com">Sean Moran</a> about this survey or website.
        <span style="font-size: 9px">
          Made with <a href="https://jekyllrb.com">Jekyll</a> and <a href="https://github.com/poole/hyde">Hyde</a>.
        </span>
      </p>
    </div>
  </div>
</div>

<script>
$("#searchTarget").keydown(function (e) {	
  if (e.keyCode == 13) {
    search();
  }
});

function search() {
  try {
    ga('send', 'event', 'search', 'search', $("#searchTarget").val());
  } finally {
    window.location = "/papers.html#" + $("#searchTarget").val();
  }
}
</script>

<style>
.sidebar {
  position: fixed; /* Keeps the sidebar in place while scrolling */
  top: 0;
  bottom: 0;
  width: 250px;
  overflow-y: auto; /* Enables vertical scrolling */
}

.container.sidebar-sticky {
  height: 100%; /* Full height for the sidebar */
  max-height: 100vh; /* Restricts the sidebar height to the viewport */
  overflow-y: auto; /* Scrolls when the content exceeds the height */
}
</style>


    <div class="content container">
      <h1 id="learning-to-hash-a-step-by-step-tutorial">Learning to Hash: A Step-by-Step Tutorial</h1>

<h3 id="overview">Overview</h3>

<p>In this tutorial, we’ll explore a powerful learning-to-hash model and its application in image retrieval. Specifically, we will compare <strong>Graph Regularized Hashing (GRH)</strong>, a supervised hashing method, to <strong>Locality Sensitive Hashing (LSH)</strong> for image retrieval tasks.</p>

<p>We’ll walk through the implementation of GRH, study its performance on the CIFAR-10 dataset, and benchmark it against LSH. GRH, initially introduced by Moran and Lavrenko, has since been extended to cross-modal hashing, which we’ll touch on later.</p>

<h3 id="what-youll-learn">What You’ll Learn</h3>

<ul>
  <li>Implementation of LSH and GRH in Python</li>
  <li>Performance comparison using the CIFAR-10 dataset</li>
  <li>Evaluation using precision at 10 and semantic nearest neighbor metrics</li>
</ul>

<h3 id="getting-started">Getting Started</h3>

<h4 id="step-1-set-up-your-environment">Step 1: Set Up Your Environment</h4>

<p>First, let’s create a Python virtual environment for this project. This will keep your dependencies organized and isolated:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python3 <span class="nt">-m</span> venv ./hashing_tutorial
<span class="nb">source </span>hashing_tutorial/bin/activate
pip3 <span class="nb">install</span> <span class="nt">-r</span> requirements.txt
</code></pre></div></div>

<h4 id="step-2-retrieve-and-pre-process-the-dataset">Step 2: Retrieve and Pre-process the Dataset</h4>

<p>We’ll use the <strong>CIFAR-10 dataset</strong> for our hashing experiments, but instead of raw images, we’ll use the GIST features to represent the images.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">scipy.io</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">requests</span>

<span class="n">url</span> <span class="o">=</span> <span class="s">'https://www.dropbox.com/s/875u1rkva9iffpj/Gist512CIFAR10.mat?dl=1'</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="s">"./"</span><span class="p">,</span> <span class="s">"Gist512CIFAR10.mat"</span><span class="p">),</span> <span class="s">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">response</span><span class="p">.</span><span class="n">content</span><span class="p">)</span>

<span class="n">mat</span> <span class="o">=</span> <span class="n">scipy</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">loadmat</span><span class="p">(</span><span class="s">'./Gist512CIFAR10.mat'</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">mat</span><span class="p">[</span><span class="s">'X'</span><span class="p">]</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">Normalizer</span><span class="p">(</span><span class="n">norm</span><span class="o">=</span><span class="s">'l2'</span><span class="p">).</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span> <span class="o">-</span> <span class="n">data</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">classes</span> <span class="o">=</span> <span class="n">mat</span><span class="p">[</span><span class="s">'X_class'</span><span class="p">]</span>
</code></pre></div></div>

<p>This code downloads the CIFAR-10 dataset and pre-processes it into GIST features. Normalization and mean centering are critical steps before indexing.</p>

<p>If you want to skip the implementation steps, you can directly run the full code <a href="./tutorial/hashing_tutorial.py">here</a>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python3 hashing_tutorial.py
</code></pre></div></div>

<h3 id="locality-sensitive-hashing-lsh-implementation">Locality Sensitive Hashing (LSH) Implementation</h3>

<h4 id="step-3-generate-hashcodes-using-lsh">Step 3: Generate Hashcodes Using LSH</h4>

<p>In LSH, we generate random hyperplanes to project images into hashcodes. Let’s start by projecting an image from the dataset:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">n_vectors</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">dim</span> <span class="o">=</span> <span class="mi">512</span>

<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">random_vectors</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">n_vectors</span><span class="p">)</span>

<span class="n">bin_indices_bits</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:].</span><span class="n">dot</span><span class="p">(</span><span class="n">random_vectors</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">0</span>
<span class="k">print</span><span class="p">(</span><span class="n">bin_indices_bits</span><span class="p">)</span>
</code></pre></div></div>

<p>This will print out the boolean hashcode for the first image. Similar hashcodes will be assigned to images that are semantically similar, i.e., from the same class.</p>

<h4 id="step-4-convert-boolean-hashcode-to-integer-representation">Step 4: Convert Boolean Hashcode to Integer Representation</h4>

<p>We now convert the boolean representation of the hashcode into an integer:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">powers_of_two</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_vectors</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">step</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">bin_indices</span> <span class="o">=</span> <span class="n">bin_indices_bits</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">powers_of_two</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">bin_indices</span><span class="p">)</span>
</code></pre></div></div>

<p>This assigns an integer bin index for the image, which will determine its bucket in the hash table.</p>

<h4 id="step-5-hash-the-entire-dataset">Step 5: Hash the Entire Dataset</h4>

<p>Now, let’s hash the entire dataset using matrix operations:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bin_indices_bits</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">random_vectors</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">0</span>
<span class="n">bin_indices</span> <span class="o">=</span> <span class="n">bin_indices_bits</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">powers_of_two</span><span class="p">)</span>
</code></pre></div></div>

<p>This generates hashcodes for all 60,000 images in the CIFAR-10 dataset.</p>

<h4 id="step-6-inspect-the-hash-buckets">Step 6: Inspect the Hash Buckets</h4>

<p>We can now create a hash table and inspect the buckets with more than one image:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>

<span class="n">table</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">bin_index</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">bin_indices</span><span class="p">):</span>
    <span class="n">table</span><span class="p">[</span><span class="n">bin_index</span><span class="p">].</span><span class="n">append</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>

<span class="k">for</span> <span class="n">bucket</span><span class="p">,</span> <span class="n">images</span> <span class="ow">in</span> <span class="n">table</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">images</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
</code></pre></div></div>

<p>This will print out the buckets that contain more than one image, allowing us to inspect collisions.</p>

<h3 id="evaluating-lsh">Evaluating LSH</h3>

<h4 id="step-7-precision-evaluation-with-hamming-radius-search">Step 7: Precision Evaluation with Hamming Radius Search</h4>

<p>To evaluate the performance, we’ll use precision at 10 as our metric. This measures how many of the 10 nearest neighbors retrieved are semantically similar to the query image:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">data_temp</span><span class="p">,</span> <span class="n">data_query</span><span class="p">,</span> <span class="n">labels_temp</span><span class="p">,</span> <span class="n">labels_query</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">data</span><span class="p">,</span> <span class="n">classes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:],</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.002</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">data_database</span><span class="p">,</span> <span class="n">data_train</span><span class="p">,</span> <span class="n">labels_database</span><span class="p">,</span> <span class="n">labels_train</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">data_temp</span><span class="p">,</span> <span class="n">labels_temp</span><span class="p">[:],</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</code></pre></div></div>

<p>Here, we split the dataset into queries, training, and database sets.</p>

<p>Using Hamming radius-based search, we vary the radius to find more candidate neighbors:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">combinations</span>

<span class="n">max_search_radius</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">precision_history</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_search_radius</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)}</span>

<span class="k">for</span> <span class="n">query_image</span><span class="p">,</span> <span class="n">query_label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">data_query</span><span class="p">,</span> <span class="n">labels_query</span><span class="p">):</span>
    <span class="n">bin_index_bits</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">query_image</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">random_vectors</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">candidate_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">search_radius</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_search_radius</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">n_vectors</span> <span class="o">=</span> <span class="n">bin_index_bits</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">different_bits</span> <span class="ow">in</span> <span class="n">combinations</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_vectors</span><span class="p">),</span> <span class="n">search_radius</span><span class="p">):</span>
            <span class="n">alternate_bits</span> <span class="o">=</span> <span class="n">bin_index_bits</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">alternate_bits</span><span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">different_bits</span><span class="p">)]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">alternate_bits</span><span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">different_bits</span><span class="p">)])</span>
            <span class="n">nearby_bin</span> <span class="o">=</span> <span class="n">alternate_bits</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">powers_of_two</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">nearby_bin</span> <span class="ow">in</span> <span class="n">table</span><span class="p">:</span>
                <span class="n">candidate_set</span><span class="p">.</span><span class="n">update</span><span class="p">(</span><span class="n">table</span><span class="p">[</span><span class="n">nearby_bin</span><span class="p">])</span>
</code></pre></div></div>

<p>This approach helps us retrieve images even from nearby hash bins, thus improving precision.</p>

<h3 id="introducing-graph-regularized-hashing-grh">Introducing Graph Regularized Hashing (GRH)</h3>

<h4 id="step-8-implement-grh">Step 8: Implement GRH</h4>

<p>While LSH relies on random projections, <strong>GRH</strong> aims to learn the projections by utilizing label information. The key is constructing an adjacency matrix to serve as the supervisory signal:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">adjacency_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">equal</span><span class="p">.</span><span class="n">outer</span><span class="p">(</span><span class="n">labels_train</span><span class="p">,</span> <span class="n">labels_train</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">row_sums</span> <span class="o">=</span> <span class="n">adjacency_matrix</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">adjacency_matrix</span> <span class="o">=</span> <span class="n">adjacency_matrix</span> <span class="o">/</span> <span class="n">row_sums</span><span class="p">[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">]</span>
</code></pre></div></div>

<p>In GRH, the hashcodes are refined iteratively through graph regularization and hyperplane updates, improving retrieval performance.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n_iter</span> <span class="o">=</span> <span class="mi">2</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_iter</span><span class="p">):</span>
    <span class="n">bin_indices_bits</span> <span class="o">=</span> <span class="p">(</span><span class="n">data_train</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">random_vectors</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">bin_indices_bits</span><span class="p">[</span><span class="n">bin_indices_bits</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
    <span class="n">bin_indices_bits_refined</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">adjacency_matrix</span><span class="p">,</span> <span class="n">bin_indices_bits</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">))</span>
    <span class="n">bin_indices_bits_refined</span> <span class="o">=</span> <span class="p">(</span><span class="n">bin_indices_bits_refined</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">bin_indices_bits_refined</span><span class="p">[</span><span class="n">bin_indices_bits_refined</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
</code></pre></div></div>

<p>This process adjusts hashcodes based on label similarity, improving semantic retrieval.</p>

<h3 id="grh-vs-lsh-performance-comparison">GRH vs LSH: Performance Comparison</h3>

<p>By learning the hash hyperplanes, GRH significantly improves retrieval performance over LSH, especially in low Hamming radius scenarios. As we increase the radius, GRH consistently outperforms LSH in terms of precision:</p>

<ul>
  <li><strong>Precision@10 with GRH:</strong> 0.25 at Hamming radius 0</li>
  <li><strong>Precision@10 with LSH:</strong> 0.1 at Hamming radius 0</li>
</ul>

<p><img src="./tutorial/lsh_precision10.png" alt="LSH vs GRH Precision" /></p>

<h3 id="conclusion">Conclusion</h3>

<p>In this tutorial, we demonstrated the differences between LSH and GRH for image retrieval. While LSH provides a fast, unsupervised hashing method, GRH offers higher retrieval accuracy by leveraging supervised learning.</p>

<p>Feel free to explore the full code <a href="./tutorial/hashing_tutorial.py">here</a> and experiment with different datasets or hashing techniques!</p>

<p><strong>Feedback:</strong> I’d love to hear your thoughts. Feel free to reach out <a href="https://sjmoran.github.io/">here</a>.</p>

    </div>

  </body>
</html>
