[{"key": "", "year": "", "title": "Aamand2018non", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Non-Empty Bins with Simple Tabulation Hashing\"\nauthors: Aamand Anders, Thorup Mikkel\nconference: Arxiv\nyear: 2018\nbibkey: aamand2018non\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1810.13187\"}\ntags: ['ARXIV']\n---\nWe consider the hashing of a set $X\\subseteq U$ with $|X|=m$ using a simple tabulation hash function $h:U\\to [n]=\\\\{0,\\dots,n-1\\\\}$ and analyse the number of non-empty bins, that is, the size of $h(X)$. We show that the expected size of $h(X)$ matches that with fully random hashing to within low-order terms. We also provide concentration bounds. The number of non-empty bins is a fundamental measure in the balls and bins paradigm, and it is critical in applications such as Bloom filters and Filter hashing. For example, normally Bloom filters are proportioned for a desired low false-positive probability assuming fully random hashing (see \\url{en.wikipedia.org/wiki/Bloom_filter}). Our results imply that if we implement the hashing with simple tabulation, we obtain the same low false-positive probability for any possible input.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-12.579365730285645, -17.983259201049805]}, {"key": "", "year": "", "title": "Aamand2019fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast hashing with Strong Concentration Bounds\"\nauthors: Aamand Anders, Knudsen Jakob B. T., Knudsen Mathias B. T., Rasmussen Peter M. R., Thorup Mikkel\nconference: Arxiv\nyear: 2019\nbibkey: aamand2019fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1905.00369\"}\ntags: ['ARXIV']\n---\nPrevious work on tabulation hashing by Patrascu and Thorup from STOC'11 on simple tabulation and from SODA'13 on twisted tabulation offered Chernoff-style concentration bounds on hash based sums, e.g., the number of balls/keys hashing to a given bin, but under some quite severe restrictions on the expected values of these sums. The basic idea in tabulation hashing is to view a key as consisting of $c=O(1)$ characters, e.g., a 64-bit key as $c=8$ characters of 8-bits. The character domain $\\Sigma$ should be small enough that character tables of size $|\\Sigma|$ fit in fast cache. The schemes then use $O(1)$ tables of this size, so the space of tabulation hashing is $O(|\\Sigma|)$. However, the concentration bounds by Patrascu and Thorup only apply if the expected sums are $\\ll |\\Sigma|$. To see the problem, consider the very simple case where we use tabulation hashing to throw $n$ balls into $m$ bins and want to analyse the number of balls in a given bin. With their concentration bounds, we are fine if $n=m$, for then the expected value is $1$. However, if $m=2$, as when tossing $n$ unbiased coins, the expected value $n/2$ is $\\gg |\\Sigma|$ for large data sets, e.g., data sets that do not fit in fast cache. To handle expectations that go beyond the limits of our small space, we need a much more advanced analysis of simple tabulation, plus a new tabulation technique that we call \\emph{tabulation-permutation} hashing which is at most twice as slow as simple tabulation. No other hashing scheme of comparable speed offers similar Chernoff-style concentration bounds.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-17.145009994506836, -20.978717803955078]}, {"key": "", "year": "", "title": "Aamand2020no", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"No Repetition: Fast Streaming with Highly Concentrated Hashing\"\nauthors: Aamand Anders, Das Debarati, Kipouridis Evangelos, Knudsen Jakob B. T., Rasmussen Peter M. R., Thorup Mikkel\nconference: Arxiv\nyear: 2020\nbibkey: aamand2020no\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2004.01156\"}\ntags: ['ARXIV']\n---\nTo get estimators that work within a certain error bound with high probability, a common strategy is to design one that works with constant probability, and then boost the probability using independent repetitions. Important examples of this approach are small space algorithms for estimating the number of distinct elements in a stream, or estimating the set similarity between large sets. Using standard strongly universal hashing to process each element, we get a sketch based estimator where the probability of a too large error is, say, 1/4. By performing $r$ independent repetitions and taking the median of the estimators, the error probability falls exponentially in $r$. However, running $r$ independent experiments increases the processing time by a factor $r$. Here we make the point that if we have a hash function with strong concentration bounds, then we get the same high probability bounds without any need for repetitions. Instead of $r$ independent sketches, we have a single sketch that is $r$ times bigger, so the total space is the same. However, we only apply a single hash function, so we save a factor $r$ in time, and the overall algorithms just get simpler. Fast practical hash functions with strong concentration bounds were recently proposed by Aamand em et al. (to appear in STOC 2020). Using their hashing schemes, the algorithms thus become very fast and practical, suitable for online processing of high volume data streams.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-18.704639434814453, -13.564935684204102]}, {"key": "", "year": "", "title": "Abdelkhalak2015content", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Content-Based Bird Retrieval using Shape context, Color moments and Bag of Features\"\nauthors: Abdelkhalak Bahri, Zouaki Hamid\nconference: Arxiv\nyear: 2015\nbibkey: abdelkhalak2015content\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1503.07816\"}\ntags: ['ARXIV']\n---\nIn this paper we propose a new descriptor for birds search. First, our work was carried on the choice of a descriptor. This choice is usually driven by the application requirements such as robustness to noise, stability with respect to bias, the invariance to geometrical transformations or tolerance to occlusions. In this context, we introduce a descriptor which combines the shape and color descriptors to have an effectiveness description of birds. The proposed descriptor is an adaptation of a descriptor based on the contours defined in article Belongie et al. [5] combined with color moments [19]. Specifically, points of interest are extracted from each image and information's in the region in the vicinity of these points are represented by descriptors of shape context concatenated with color moments. Thus, the approach bag of visual words is applied to the latter. The experimental results show the effectiveness of our descriptor for the bird search by content.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [32.5340690612793, 12.526374816894531]}, {"key": "", "year": "", "title": "Abdulkhaev2016u", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"U-CATCH: Using Color ATtribute of image patCHes in binary descriptors\"\nauthors: Abdulkhaev Alisher, Yilmaz Ozgur\nconference: Arxiv\nyear: 2016\nbibkey: abdulkhaev2016u\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1603.04408\"}\ntags: ['ARXIV']\n---\nIn this study, we propose a simple yet very effective method for extracting color information through binary feature description framework. Our method expands the dimension of binary comparisons into RGB and YCbCr spaces, showing more than 100% matching improve ment compared to non-color binary descriptors for a wide range of hard-to-match cases. The proposed method is general and can be applied to any binary descriptor to make it color sensitive. It is faster than classical binary descriptors for RGB sampling due to the abandonment of grayscale conversion and has almost identical complexity (insignificant compared to smoothing operation) for YCbCr sampling.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [16.962491989135742, -0.3958436846733093]}, {"key": "", "year": "", "title": "Ablayev2014quantum", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Quantum Hashing via Classical $\\epsilon$-universal Hashing Constructions\"\nauthors: Ablayev Farid, Ablayev Marat\nconference: Arxiv\nyear: 2014\nbibkey: ablayev2014quantum\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1404.1503\"}\ntags: ['ARXIV']\n---\nIn the paper, we define the concept of the quantum hash generator and offer design, which allows to build a large amount of different quantum hash functions. The construction is based on composition of classical $\\epsilon$-universal hash family and a given family of functions -- quantum hash generator. The proposed construction combines the properties of robust presentation of information by classical error-correcting codes together with the possibility of highly compressed presentation of information by quantum systems. In particularly, we present quantum hash function based on Reed-Solomon code, and we proved, that this construction is optimal in the sense of number of qubits needed.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-29.691299438476562, -0.8354638814926147]}, {"key": "", "year": "", "title": "Abouelnaga2021distillpose", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"DistillPose: Lightweight Camera Localization Using Auxiliary Learning\"\nauthors: Abouelnaga Yehya, Bui Mai, Ilic Slobodan\nconference: Arxiv\nyear: 2021\nbibkey: abouelnaga2021distillpose\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2108.03819\"}\ntags: ['ARXIV', 'CNN']\n---\nWe propose a lightweight retrieval-based pipeline to predict 6DOF camera poses from RGB images. Our pipeline uses a convolutional neural network (CNN) to encode a query image as a feature vector. A nearest neighbor lookup finds the pose-wise nearest database image. A siamese convolutional neural network regresses the relative pose from the nearest neighboring database image to the query image. The relative pose is then applied to the nearest neighboring absolute pose to obtain the query image's final absolute pose prediction. Our model is a distilled version of NN-Net that reduces its parameters by 98.87%, information retrieval feature vector size by 87.5%, and inference time by 89.18% without a significant decrease in localization accuracy.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [13.959905624389648, 26.913471221923828]}, {"key": "", "year": "", "title": "Afshari2021a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Similarity Measure of Histopathology Images by Deep Embeddings\"\nauthors: Afshari Mehdi, Tizhoosh H. R.\nconference: Arxiv\nyear: 2021\nbibkey: afshari2021a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2107.13703\"}\ntags: ['ARXIV']\n---\nHistopathology digital scans are large-size images that contain valuable information at the pixel level. Content-based comparison of these images is a challenging task. This study proposes a content-based similarity measure for high-resolution gigapixel histopathology images. The proposed similarity measure is an expansion of cosine vector similarity to a matrix. Each image is divided into same-size patches with a meaningful amount of information (i.e., contained enough tissue). The similarity is measured by the extraction of patch-level deep embeddings of the last pooling layer of a pre-trained deep model at four different magnification levels, namely, 1x, 2.5x, 5x, and 10x magnifications. In addition, for faster measurement, embedding reduction is investigated. Finally, to assess the proposed method, an image search method is implemented. Results show that the similarity measure represents the slide labels with a maximum accuracy of 93.18\\% for top-5 search at 5x magnification.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [17.997465133666992, 4.938373565673828]}, {"key": "", "year": "", "title": "Agarwal2014a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Novel Approach to Develop a New Hybrid Technique for Trademark Image Retrieval\"\nauthors: Agarwal Saurabh, Johari Punit Kumar\nconference: Arxiv\nyear: 2014\nbibkey: agarwal2014a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1504.03315\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nTrademark Image Retrieval is playing a vital role as a part of CBIR System. Trademark is of great significance because it carries the status value of any company. To retrieve such a fake or copied trademark we design a retrieval system which is based on hybrid techniques. It contains a mixture of two different feature vector which combined together to give a suitable retrieval system. In the proposed system we extract the corner feature which is applied on an edge pixel image. This feature is used to extract the relevant image and to more purify the result we apply other feature which is the invariant moment feature. From the experimental result we conclude that the system is 85 percent efficient.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [22.362945556640625, -4.2104268074035645]}, {"key": "", "year": "", "title": "Aghazadeh2016near", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Near-Isometric Binary Hashing for Large-scale Datasets\"\nauthors: Aghazadeh Amirali, Lan Andrew, Shrivastava Anshumali, Baraniuk Richard\nconference: Arxiv\nyear: 2016\nbibkey: aghazadeh2016near\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1603.03836\"}\ntags: ['ARXIV']\n---\nWe develop a scalable algorithm to learn binary hash codes for indexing large-scale datasets. Near-isometric binary hashing (NIBH) is a data-dependent hashing scheme that quantizes the output of a learned low-dimensional embedding to obtain a binary hash code. In contrast to conventional hashing schemes, which typically rely on an $\\ell_2$-norm (i.e., average distortion) minimization, NIBH is based on a $\\ell_\\{\\infty\\}$-norm (i.e., worst-case distortion) minimization that provides several benefits, including superior distance, ranking, and near-neighbor preservation performance. We develop a practical and efficient algorithm for NIBH based on column generation that scales well to large datasets. A range of experimental evaluations demonstrate the superiority of NIBH over ten state-of-the-art binary hashing schemes.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-25.323619842529297, -4.216777324676514]}, {"key": "", "year": "", "title": "Aguerrebere2023similarity", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Similarity search in the blink of an eye with compressed indices\"\nauthors: Aguerrebere Cecilia, Bhati Ishwar, Hildebrand Mark, Tepper Mariano, Willke Ted\nconference: Arxiv\nyear: 2023\nbibkey: aguerrebere2023similarity\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2304.04759\"}\ntags: ['ARXIV', 'Graph', 'Quantisation']\n---\nNowadays, data is represented by vectors. Retrieving those vectors, among millions and billions, that are similar to a given query is a ubiquitous problem, known as similarity search, of relevance for a wide range of applications. Graph-based indices are currently the best performing techniques for billion-scale similarity search. However, their random-access memory pattern presents challenges to realize their full potential. In this work, we present new techniques and systems for creating faster and smaller graph-based indices. To this end, we introduce a novel vector compression method, Locally-adaptive Vector Quantization (LVQ), that uses per-vector scaling and scalar quantization to improve search performance with fast similarity computations and a reduced effective bandwidth, while decreasing memory footprint and barely impacting accuracy. LVQ, when combined with a new high-performance computing system for graph-based similarity search, establishes the new state of the art in terms of performance and memory footprint. For billions of vectors, LVQ outcompetes the second-best alternatives: (1) in the low-memory regime, by up to 20.7x in throughput with up to a 3x memory footprint reduction, and (2) in the high-throughput regime by 5.8x with 1.4x less memory.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-2.7826895713806152, -18.433204650878906]}, {"key": "", "year": "", "title": "Ahle2017optimal", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Optimal Las Vegas Locality Sensitive Data Structures\"\nauthors: Ahle Thomas Dybdahl\nconference: Arxiv\nyear: 2017\nbibkey: ahle2017optimal\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1704.02054\"}\ntags: ['ARXIV', 'LSH']\n---\nWe show that approximate similarity (near neighbour) search can be solved in high dimensions with performance matching state of the art (data independent) Locality Sensitive Hashing, but with a guarantee of no false negatives. Specifically, we give two data structures for common problems. For $c$-approximate near neighbour in Hamming space we get query time $dn^\\{1/c+o(1)\\}$ and space $dn^\\{1+1/c+o(1)\\}$ matching that of \\cite{indyk1998approximate} and answering a long standing open question from~\\cite{indyk2000dimensionality} and~\\cite{pagh2016locality} in the affirmative. By means of a new deterministic reduction from $\\ell_1$ to Hamming we also solve $\\ell_1$ and $\\ell_2$ with query time $d^2n^\\{1/c+o(1)\\}$ and space $d^2 n^\\{1+1/c+o(1)\\}$. For $(s_1,s_2)$-approximate Jaccard similarity we get query time $dn^\\{\\rho+o(1)\\}$ and space $dn^\\{1+\\rho+o(1)\\}$, $\\rho=\\log\\frac\\{1+s_1\\}\\{2s_1\\}\\big/\\log\\frac\\{1+s_2\\}\\{2s_2\\}$, when sets have equal size, matching the performance of~\\cite{tobias2016}. The algorithms are based on space partitions, as with classic LSH, but we construct these using a combination of brute force, tensoring, perfect hashing and splitter functions \\`a la~\\cite{naor1995splitters}. We also show a new dimensionality reduction lemma with 1-sided error.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-11.390381813049316, -25.821125030517578]}, {"key": "", "year": "", "title": "Ahle2020the", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"The Power of Hashing with Mersenne Primes\"\nauthors: Ahle Thomas Dybdahl, Knudsen Jakob Tejs B\u00e6k, Thorup Mikkel\nconference: Arxiv\nyear: 2020\nbibkey: ahle2020the\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2008.08654\"}\ntags: ['ARXIV']\n---\nThe classic way of computing a $k$-universal hash function is to use a random degree-$(k-1)$ polynomial over a prime field $\\mathbb Z_p$. For a fast computation of the polynomial, the prime $p$ is often chosen as a Mersenne prime $p=2^b-1$. In this paper, we show that there are other nice advantages to using Mersenne primes. Our view is that the hash function's output is a $b$-bit integer that is uniformly distributed in $\\\\{0, \\dots, 2^b-1\\\\}$, except that $p$ (the all \\texttt1s value in binary) is missing. Uniform bit strings have many nice properties, such as splitting into substrings which gives us two or more hash functions for the cost of one, while preserving strong theoretical qualities. We call this trick \"Two for one\" hashing, and we demonstrate it on 4-universal hashing in the classic Count Sketch algorithm for second-moment estimation. We also provide a new fast branch-free code for division and modulus with Mersenne primes. Contrasting our analytic work, this code generalizes to any Pseudo-Mersenne primes $p=2^b-c$ for small $c$.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-14.963351249694824, -18.513227462768555]}, {"key": "", "year": "", "title": "Ahmad2015describing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Describing Colors, Textures and Shapes for Content Based Image Retrieval - A Survey\"\nauthors: Ahmad Jamil, Sajjad Muhammad, Mehmood Irfan, Rho Seungmin, Baik Sung Wook\nconference: \nyear: 2015\nbibkey: ahmad2015describing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1502.07041\"}\ntags: ['Image Retrieval']\n---\nVisual media has always been the most enjoyed way of communication. From the advent of television to the modern day hand held computers, we have witnessed the exponential growth of images around us. Undoubtedly it's a fact that they carry a lot of information in them which needs be utilized in an effective manner. Hence intense need has been felt to efficiently index and store large image collections for effective and on- demand retrieval. For this purpose low-level features extracted from the image contents like color, texture and shape has been used. Content based image retrieval systems employing these features has proven very successful. Image retrieval has promising applications in numerous fields and hence has motivated researchers all over the world. New and improved ways to represent visual content are being developed each day. Tremendous amount of research has been carried out in the last decade. In this paper we will present a detailed overview of some of the powerful color, texture and shape descriptors for content based image retrieval. A comparative analysis will also be carried out for providing an insight into outstanding challenges in this field.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [13.85934829711914, 10.918014526367188]}, {"key": "", "year": "", "title": "Aizenbud2017similarity", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Similarity Search Over Graphs Using Localized Spectral Analysis\"\nauthors: Aizenbud Yariv, Averbuch Amir, Shabat Gil, Ziv Guy\nconference: Arxiv\nyear: 2017\nbibkey: aizenbud2017similarity\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1707.03311\"}\ntags: ['ARXIV', 'Graph']\n---\nThis paper provides a new similarity detection algorithm. Given an input set of multi-dimensional data points, where each data point is assumed to be multi-dimensional, and an additional reference data point for similarity finding, the algorithm uses kernel method that embeds the data points into a low dimensional manifold. Unlike other kernel methods, which consider the entire data for the embedding, our method selects a specific set of kernel eigenvectors. The eigenvectors are chosen to separate between the data points and the reference data point so that similar data points can be easily identified as being distinct from most of the members in the dataset.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.78144645690918, -22.014801025390625]}, {"key": "", "year": "", "title": "Akinwalle2009the", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"The Usefulness of Multilevel Hash Tables with Multiple Hash Functions in Large Databases\"\nauthors: Akinwalle A. T., Ibharalu F. T.\nconference: Ann. Univ. Tibiscus Comp. Sci. Series VII\nyear: 2009\nbibkey: akinwalle2009the\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/0905.4201\"}\ntags: ['TIP']\n---\nIn this work, attempt is made to select three good hash functions which uniformly distribute hash values that permute their internal states and allow the input bits to generate different output bits. These functions are used in different levels of hash tables that are coded in Java Programming Language and a quite number of data records serve as primary data for testing the performances. The result shows that the two-level hash tables with three different hash functions give a superior performance over one-level hash table with two hash functions or zero-level hash table with one function in term of reducing the conflict keys and quick lookup for a particular element. The result assists to reduce the complexity of join operation in query language from O(n2) to O(1) by placing larger query result, if any, in multilevel hash tables with multiple hash functions and generate shorter query result.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-26.557979583740234, -4.2403717041015625]}, {"key": "", "year": "", "title": "Aksoy2022satellite", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Satellite Image Search in AgoraEO\"\nauthors: Aksoy Ahmet Kerem, Dushev Pavel, Zacharatou Eleni Tzirita, Hemsen Holmer, Charfuelan Marcela, Quian\u00e9-Ruiz Jorge-Arnulfo, Demir Beg\u00fcm, Markl Volker\nconference: Arxiv\nyear: 2022\nbibkey: aksoy2022satellite\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2208.10830\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nThe growing operational capability of global Earth Observation (EO) creates new opportunities for data-driven approaches to understand and protect our planet. However, the current use of EO archives is very restricted due to the huge archive sizes and the limited exploration capabilities provided by EO platforms. To address this limitation, we have recently proposed MiLaN, a content-based image retrieval approach for fast similarity search in satellite image archives. MiLaN is a deep hashing network based on metric learning that encodes high-dimensional image features into compact binary hash codes. We use these codes as keys in a hash table to enable real-time nearest neighbor search and highly accurate retrieval. In this demonstration, we showcase the efficiency of MiLaN by integrating it with EarthQube, a browser and search engine within AgoraEO. EarthQube supports interactive visual exploration and Query-by-Example over satellite image repositories. Demo visitors will interact with EarthQube playing the role of different users that search images in a large-scale remote sensing archive by their semantic content and apply other filters.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [19.012086868286133, -3.2746667861938477]}, {"key": "", "year": "", "title": "Alakuijala2016fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast keyed hash/pseudo-random function using SIMD multiply and permute\"\nauthors: Alakuijala Jyrki, Cox Bill, Wassenberg Jan\nconference: Arxiv\nyear: 2016\nbibkey: alakuijala2016fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1612.06257\"}\ntags: ['ARXIV', 'TIP']\n---\nHighwayHash is a new pseudo-random function based on SIMD multiply and permute instructions for thorough and fast hashing. It is 5.2 times as fast as SipHash for 1 KiB inputs. An open-source implementation is available under a permissive license. We discuss design choices and provide statistical analysis, speed measurements and preliminary cryptanalysis. Assuming it withstands further analysis, strengthened variants may also substantially accelerate file checksums and stream ciphers.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-0.9572522044181824, -14.012385368347168]}, {"key": "", "year": "", "title": "Ali2017content", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Content-Based Image Retrieval Based on Late Fusion of Binary and Local Descriptors\"\nauthors: Ali Nouman, Mazhar Danish Ali, Iqbal Zeshan, Ashraf Rehan, Ahmed Jawad, Khan Farrukh Zeeshan\nconference: International Journal of Computer Science and Information Security\nyear: 2017\nbibkey: ali2017content\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1703.08492\"}\ntags: ['Image Retrieval']\n---\nOne of the challenges in Content-Based Image Retrieval (CBIR) is to reduce the semantic gaps between low-level features and high-level semantic concepts. In CBIR, the images are represented in the feature space and the performance of CBIR depends on the type of selected feature representation. Late fusion also known as visual words integration is applied to enhance the performance of image retrieval. The recent advances in image retrieval diverted the focus of research towards the use of binary descriptors as they are reported computationally efficient. In this paper, we aim to investigate the late fusion of Fast Retina Keypoint (FREAK) and Scale Invariant Feature Transform (SIFT). The late fusion of binary and local descriptor is selected because among binary descriptors, FREAK has shown good results in classification-based problems while SIFT is robust to translation, scaling, rotation and small distortions. The late fusion of FREAK and SIFT integrates the performance of both feature descriptors for an effective image retrieval. Experimental results and comparisons show that the proposed late fusion enhances the performances of image retrieval.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [14.368337631225586, 15.92020320892334]}, {"key": "", "year": "", "title": "Ali2020practical", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Practical Hash-based Anonymity for MAC Addresses\"\nauthors: Ali Junade, Dyo Vladimir\nconference: Arxiv\nyear: 2020\nbibkey: ali2020practical\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2005.06580\"}\ntags: ['ARXIV', 'Graph']\n---\nGiven that a MAC address can uniquely identify a person or a vehicle, continuous tracking over a large geographical scale has raised serious privacy concerns amongst governments and the general public. Prior work has demonstrated that simple hash-based approaches to anonymization can be easily inverted due to the small search space of MAC addresses. In particular, it is possible to represent the entire allocated MAC address space in 39 bits and that frequency-based attacks allow for 50% of MAC addresses to be enumerated in 31 bits. We present a practical approach to MAC address anonymization using both computationally expensive hash functions and truncating the resulting hashes to allow for k-anonymity. We provide an expression for computing the percentage of expected collisions, demonstrating that for digests of 24 bits it is possible to store up to 168,617 MAC addresses with the rate of collisions less than 1%. We experimentally demonstrate that a rate of collision of 1% or less can be achieved by storing data sets of 100 MAC addresses in 13 bits, 1,000 MAC addresses in 17 bits and 10,000 MAC addresses in 20 bits.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-32.388824462890625, 4.564555644989014]}, {"key": "", "year": "", "title": "Alqasrawi2022bridging", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Bridging the Gap between Local Semantic Concepts and Bag of Visual Words for Natural Scene Image Retrieval\"\nauthors: Alqasrawi Yousef\nconference: Arxiv\nyear: 2022\nbibkey: alqasrawi2022bridging\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2210.08875\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nThis paper addresses the problem of semantic-based image retrieval of natural scenes. A typical content-based image retrieval system deals with the query image and images in the dataset as a collection of low-level features and retrieves a ranked list of images based on the similarities between features of the query image and features of images in the image dataset. However, top ranked images in the retrieved list, which have high similarities to the query image, may be different from the query image in terms of the semantic interpretation of the user which is known as the semantic gap. In order to reduce the semantic gap, this paper investigates how natural scene retrieval can be performed using the bag of visual word model and the distribution of local semantic concepts. The paper studies the efficiency of using different approaches for representing the semantic information, depicted in natural scene images, for image retrieval. An extensive experimental work has been conducted to study the efficiency of using semantic information as well as the bag of visual words model for natural and urban scene image retrieval.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [20.375280380249023, 16.464351654052734]}, {"key": "", "year": "", "title": "Alsini2023reval", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"#REVAL: a semantic evaluation framework for hashtag recommendation\"\nauthors: Alsini Areej, Huynh Du Q., Datta Amitava\nconference: Arxiv\nyear: 2023\nbibkey: alsini2023reval\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2305.18330\"}\ntags: ['ARXIV', 'TOM']\n---\nAutomatic evaluation of hashtag recommendation models is a fundamental task in many online social network systems. In the traditional evaluation method, the recommended hashtags from an algorithm are firstly compared with the ground truth hashtags for exact correspondences. The number of exact matches is then used to calculate the hit rate, hit ratio, precision, recall, or F1-score. This way of evaluating hashtag similarities is inadequate as it ignores the semantic correlation between the recommended and ground truth hashtags. To tackle this problem, we propose a novel semantic evaluation framework for hashtag recommendation, called #REval. This framework includes an internal module referred to as BERTag, which automatically learns the hashtag embeddings. We investigate on how the #REval framework performs under different word embedding methods and different numbers of synonyms and hashtags in the recommendation using our proposed #REval-hit-ratio measure. Our experiments of the proposed framework on three large datasets show that #REval gave more meaningful hashtag synonyms for hashtag recommendation evaluation. Our analysis also highlights the sensitivity of the framework to the word embedding technique, with #REval based on BERTag more superior over #REval based on FastText and Word2Vec.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-25.888408660888672, 8.001479148864746]}, {"key": "", "year": "", "title": "Alvari2017twitter", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Twitter Hashtag Recommendation using Matrix Factorization\"\nauthors: Alvari Hamidreza\nconference: Arxiv\nyear: 2017\nbibkey: alvari2017twitter\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1705.10453\"}\ntags: ['ARXIV']\n---\nTwitter, one of the biggest and most popular microblogging Websites, has evolved into a powerful communication platform which allows millions of active users to generate huge volume of microposts and queries on a daily basis. To accommodate effective categorization and easy search, users are allowed to make use of hashtags, keywords or phrases prefixed by hash character, to categorize and summarize their posts. However, valid hashtags are not restricted and thus are created in a free and heterogeneous style, increasing difficulty of the task of tweet categorization. In this paper, we propose a low-rank weighted matrix factorization based method to recommend hashtags to the users solely based on their hashtag usage history and independent from their tweets' contents. We confirm using two-sample t-test that users are more likely to adopt new hashtags similar to the ones they have previously adopted. In particular, we formulate the problem of hashtag recommendation into an optimization problem and incorporate hashtag correlation weight matrix into it to account for the similarity between different hashtags. We finally leverage widely used matrix factorization from recommender systems to solve the optimization problem by capturing the latent factors of users and hashtags. Empirical experiments demonstrate that our method is capable to properly recommend hashtags.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-26.014406204223633, 10.02712345123291]}, {"key": "", "year": "", "title": "Amara2021nearest", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Nearest neighbor search with compact codes: A decoder perspective\"\nauthors: Amara Kenza, Douze Matthijs, Sablayrolles Alexandre, J\u00e9gou Herv\u00e9\nconference: Arxiv\nyear: 2021\nbibkey: amara2021nearest\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2112.09568\"}\ntags: ['ARXIV', 'Quantisation']\n---\nModern approaches for fast retrieval of similar vectors on billion-scaled datasets rely on compressed-domain approaches such as binary sketches or product quantization. These methods minimize a certain loss, typically the mean squared error or other objective functions tailored to the retrieval problem. In this paper, we re-interpret popular methods such as binary hashing or product quantizers as auto-encoders, and point out that they implicitly make suboptimal assumptions on the form of the decoder. We design backward-compatible decoders that improve the reconstruction of the vectors from the same codes, which translates to a better performance in nearest neighbor search. Our method significantly improves over binary hashing methods or product quantization on popular benchmarks.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.49270248413086, -6.384985446929932]}, {"key": "", "year": "", "title": "Amato2016aggregating", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Aggregating Binary Local Descriptors for Image Retrieval\"\nauthors: Amato Giuseppe, Falchi Fabrizio, Vadicamo Lucia\nconference: Arxiv\nyear: 2016\nbibkey: amato2016aggregating\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1608.00813\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval']\n---\nContent-Based Image Retrieval based on local features is computationally expensive because of the complexity of both extraction and matching of local feature. On one hand, the cost for extracting, representing, and comparing local visual descriptors has been dramatically reduced by recently proposed binary local features. On the other hand, aggregation techniques provide a meaningful summarization of all the extracted feature of an image into a single descriptor, allowing us to speed up and scale up the image search. Only a few works have recently mixed together these two research directions, defining aggregation methods for binary local features, in order to leverage on the advantage of both approaches. In this paper, we report an extensive comparison among state-of-the-art aggregation methods applied to binary features. Then, we mathematically formalize the application of Fisher Kernels to Bernoulli Mixture Models. Finally, we investigate the combination of the aggregated binary features with the emerging Convolutional Neural Network (CNN) features. Our results show that aggregation methods on binary features are effective and represent a worthwhile alternative to the direct matching. Moreover, the combination of the CNN with the Fisher Vector (FV) built upon binary features allowed us to obtain a relative improvement over the CNN results that is in line with that recently obtained using the combination of the CNN with the FV built upon SIFTs. The advantage of using the FV built upon binary features is that the extraction process of binary features is about two order of magnitude faster than SIFTs.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.385040283203125, 29.833332061767578]}, {"key": "", "year": "", "title": "Amato2016on", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"On Reducing the Number of Visual Words in the Bag-of-Features Representation\"\nauthors: Amato Giuseppe, Falchi Fabrizio, Gennaro Claudio\nconference: VISAPP\nyear: 2016\nbibkey: amato2016on\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1604.04142\"}\ntags: ['Text Retrieval']\n---\nA new class of applications based on visual search engines are emerging, especially on smart-phones that have evolved into powerful tools for processing images and videos. The state-of-the-art algorithms for large visual content recognition and content based similarity search today use the \"Bag of Features\" (BoF) or \"Bag of Words\" (BoW) approach. The idea, borrowed from text retrieval, enables the use of inverted files. A very well known issue with this approach is that the query images, as well as the stored data, are described with thousands of words. This poses obvious efficiency problems when using inverted files to perform efficient image matching. In this paper, we propose and compare various techniques to reduce the number of words describing an image to improve efficiency and we study the effects of this reduction on effectiveness in landmark recognition and retrieval scenarios. We show that very relevant improvement in performance are achievable still preserving the advantages of the BoF base approach.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.808483123779297, 12.191227912902832]}, {"key": "", "year": "", "title": "Amato2016using", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Using Apache Lucene to Search Vector of Locally Aggregated Descriptors\"\nauthors: Amato Giuseppe, Bolettieri Paolo, Falchi Fabrizio, Gennaro Claudio, Vadicamo Lucia\nconference: Arxiv\nyear: 2016\nbibkey: amato2016using\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1604.05576\"}\ntags: ['ARXIV']\n---\nSurrogate Text Representation (STR) is a profitable solution to efficient similarity search on metric space using conventional text search engines, such as Apache Lucene. This technique is based on comparing the permutations of some reference objects in place of the original metric distance. However, the Achilles heel of STR approach is the need to reorder the result set of the search according to the metric distance. This forces to use a support database to store the original objects, which requires efficient random I/O on a fast secondary memory (such as flash-based storages). In this paper, we propose to extend the Surrogate Text Representation to specifically address a class of visual metric objects known as Vector of Locally Aggregated Descriptors (VLAD). This approach is based on representing the individual sub-vectors forming the VLAD vector with the STR, providing a finer representation of the vector and enabling us to get rid of the reordering phase. The experiments on a publicly available dataset show that the extended STR outperforms the baseline STR achieving satisfactory performance near to the one obtained with the original VLAD vectors.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [15.107213973999023, -20.20750617980957]}, {"key": "", "year": "", "title": "Ameur2019anetac", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"ANETAC: Arabic Named Entity Transliteration and Classification Dataset\"\nauthors: Ameur Mohamed Seghir Hadj, Meziane Farid, Guessoum Ahmed\nconference: Arxiv\nyear: 2019\nbibkey: ameur2019anetac\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1907.03110\"}\ntags: ['ARXIV', 'GAN']\n---\nIn this paper, we make freely accessible ANETAC our English-Arabic named entity transliteration and classification dataset that we built from freely available parallel translation corpora. The dataset contains 79,924 instances, each instance is a triplet (e, a, c), where e is the English named entity, a is its Arabic transliteration and c is its class that can be either a Person, a Location, or an Organization. The ANETAC dataset is mainly aimed for the researchers that are working on Arabic named entity transliteration, but it can also be used for named entity classification purposes.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [26.034440994262695, 0.3408750593662262]}, {"key": "", "year": "", "title": "Amid2016low", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Low-dimensional Data Embedding via Robust Ranking\"\nauthors: Amid Ehsan, Vlassis Nikos, Warmuth Manfred K.\nconference: Arxiv\nyear: 2016\nbibkey: amid2016low\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1611.09957\"}\ntags: ['ARXIV']\n---\nWe describe a new method called t-ETE for finding a low-dimensional embedding of a set of objects in Euclidean space. We formulate the embedding problem as a joint ranking problem over a set of triplets, where each triplet captures the relative similarities between three objects in the set. By exploiting recent advances in robust ranking, t-ETE produces high-quality embeddings even in the presence of a significant amount of noise and better preserves local scale than known methods, such as t-STE and t-SNE. In particular, our method produces significantly better results than t-SNE on signature datasets while also being faster to compute.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.396624565124512, -7.474620819091797]}, {"key": "", "year": "", "title": "Amr2010using", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Using Statistical Moment Invariants and Entropy in Image Retrieval\"\nauthors: Amr Ismail I., Amin Mohamed, Kafrawy Passent El, Sauber Amr M.\nconference: International Journal of Computer Science and Information Security, IJCSIS, Vol.\nyear: 2010\nbibkey: amr2010using\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1002.2193\"}\ntags: ['Image Retrieval', 'TOM']\n---\nAlthough content-based image retrieval (CBIR) is not a new subject, it keeps attracting more and more attention, as the amount of images grow tremendously due to internet, inexpensive hardware and automation of image acquisition. One of the applications of CBIR is fetching images from a database. This paper presents a new method for automatic image retrieval using moment invariants and image entropy, our technique could be used to find semi or perfect matches based on query by example manner, experimental results demonstrate that the purposed technique is scalable and efficient.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [16.234764099121094, 11.662631034851074]}, {"key": "", "year": "", "title": "An2023towards", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Towards Content-based Pixel Retrieval in Revisited Oxford and Paris\"\nauthors: An Guoyuan, Kim Woo Jae, Yang Saelyne, Li Rong, Huo Yuchi, Yoon Sung-Eui\nconference: Arxiv\nyear: 2023\nbibkey: an2023towards\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2309.05438\"}   - {name: \"Code\", url: \"https://github.com/anguoyuan/Pixel_retrieval-Segmented_instance_retrieval}{this\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nThis paper introduces the first two pixel retrieval benchmarks. Pixel retrieval is segmented instance retrieval. Like semantic segmentation extends classification to the pixel level, pixel retrieval is an extension of image retrieval and offers information about which pixels are related to the query object. In addition to retrieving images for the given query, it helps users quickly identify the query object in true positive images and exclude false positive images by denoting the correlated pixels. Our user study results show pixel-level annotation can significantly improve the user experience. Compared with semantic and instance segmentation, pixel retrieval requires a fine-grained recognition capability for variable-granularity targets. To this end, we propose pixel retrieval benchmarks named PROxford and PRParis, which are based on the widely used image retrieval datasets, ROxford and RParis. Three professional annotators label 5,942 images with two rounds of double-checking and refinement. Furthermore, we conduct extensive experiments and analysis on the SOTA methods in image search, image matching, detection, segmentation, and dense matching using our pixel retrieval benchmarks. Results show that the pixel retrieval task is challenging to these approaches and distinctive from existing problems, suggesting that further research can advance the content-based pixel-retrieval and thus user search experience. The datasets can be downloaded from \\href{https://github.com/anguoyuan/Pixel_retrieval-Segmented_instance_retrieval}{this link}.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.790164947509766, 13.556419372558594]}, {"key": "", "year": "", "title": "Andoni2013beyond", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Beyond Locality-Sensitive Hashing\"\nauthors: Andoni Alexandr, Indyk Piotr, Nguyen Huy L., Razenshteyn Ilya\nconference: Arxiv\nyear: 2013\nbibkey: andoni2013beyond\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1306.1547\"}\ntags: ['ARXIV', 'FOCS']\n---\nWe present a new data structure for the c-approximate near neighbor problem (ANN) in the Euclidean space. For n points in R^d, our algorithm achieves O(n^{\\rho} + d log n) query time and O(n^{1 + \\rho} + d log n) space, where \\rho &lt;= 7/(8c^2) + O(1 / c^3) + o(1). This is the first improvement over the result by Andoni and Indyk (FOCS 2006) and the first data structure that bypasses a locality-sensitive hashing lower bound proved by O'Donnell, Wu and Zhou (ICS 2011). By a standard reduction we obtain a data structure for the Hamming space and \\ell_1 norm with \\rho &lt;= 7/(8c) + O(1/c^{3/2}) + o(1), which is the first improvement over the result of Indyk and Motwani (STOC 1998).\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-6.407344341278076, -28.544559478759766]}, {"key": "", "year": "", "title": "Andoni2015optimal", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Optimal Data-Dependent Hashing for Approximate Near Neighbors\"\nauthors: Andoni Alexandr, Razenshteyn Ilya\nconference: Arxiv\nyear: 2015\nbibkey: andoni2015optimal\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1501.01062\"}\ntags: ['ARXIV', 'LSH']\n---\nWe show an optimal data-dependent hashing scheme for the approximate near neighbor problem. For an $n$-point data set in a $d$-dimensional space our data structure achieves query time $O(d n^\\{\\rho+o(1)\\})$ and space $O(n^\\{1+\\rho+o(1)\\} + dn)$, where $\\rho=\\tfrac\\{1\\}\\{2c^2-1\\}$ for the Euclidean space and approximation $c&gt;1$. For the Hamming space, we obtain an exponent of $\\rho=\\tfrac\\{1\\}\\{2c-1\\}$. Our result completes the direction set forth in [AINR14] who gave a proof-of-concept that data-dependent hashing can outperform classical Locality Sensitive Hashing (LSH). In contrast to [AINR14], the new bound is not only optimal, but in fact improves over the best (optimal) LSH data structures [IM98,AI06] for all approximation factors $c&gt;1$. From the technical perspective, we proceed by decomposing an arbitrary dataset into several subsets that are, in a certain sense, pseudo-random.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-10.349359512329102, -24.63090705871582]}, {"key": "", "year": "", "title": "Andoni2015tight", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Tight Lower Bounds for Data-Dependent Locality-Sensitive Hashing\"\nauthors: Andoni Alexandr, Razenshteyn Ilya\nconference: Arxiv\nyear: 2015\nbibkey: andoni2015tight\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1507.04299\"}\ntags: ['ARXIV']\n---\nWe prove a tight lower bound for the exponent $\\rho$ for data-dependent Locality-Sensitive Hashing schemes, recently used to design efficient solutions for the $c$-approximate nearest neighbor search. In particular, our lower bound matches the bound of $\\rho\\le \\frac\\{1\\}\\{2c-1\\}+o(1)$ for the $\\ell_1$ space, obtained via the recent algorithm from [Andoni-Razenshteyn, STOC'15]. In recent years it emerged that data-dependent hashing is strictly superior to the classical Locality-Sensitive Hashing, when the hash function is data-independent. In the latter setting, the best exponent has been already known: for the $\\ell_1$ space, the tight bound is $\\rho=1/c$, with the upper bound from [Indyk-Motwani, STOC'98] and the matching lower bound from [O'Donnell-Wu-Zhou, ITCS'11]. We prove that, even if the hashing is data-dependent, it must hold that $\\rho\\ge \\frac\\{1\\}\\{2c-1\\}-o(1)$. To prove the result, we need to formalize the exact notion of data-dependent hashing that also captures the complexity of the hash functions (in addition to their collision properties). Without restricting such complexity, we would allow for obviously infeasible solutions such as the Voronoi diagram of a dataset. To preclude such solutions, we require our hash functions to be succinct. This condition is satisfied by all the known algorithmic results.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-10.679149627685547, -24.558488845825195]}, {"key": "", "year": "", "title": "Andoni2016approximate", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Approximate Near Neighbors for General Symmetric Norms\"\nauthors: Andoni Alexandr, Nguyen Huy L., Nikolov Aleksandar, Razenshteyn Ilya, Waingarten Erik\nconference: Arxiv\nyear: 2016\nbibkey: andoni2016approximate\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1611.06222\"}\ntags: ['ARXIV']\n---\nWe show that every symmetric normed space admits an efficient nearest neighbor search data structure with doubly-logarithmic approximation. Specifically, for every $n$, $d = n^\\{o(1)\\}$, and every $d$-dimensional symmetric norm $\\|\\cdot\\|$, there exists a data structure for $\\mathrm\\{poly\\}(\\log \\log n)$-approximate nearest neighbor search over $\\|\\cdot\\|$ for $n$-point datasets achieving $n^\\{o(1)\\}$ query time and $n^\\{1+o(1)\\}$ space. The main technical ingredient of the algorithm is a low-distortion embedding of a symmetric norm into a low-dimensional iterated product of top-$k$ norms. We also show that our techniques cannot be extended to general norms.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [8.607223510742188, -17.82932472229004]}, {"key": "", "year": "", "title": "Andoni2021from", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"From Average Embeddings To Nearest Neighbor Search\"\nauthors: Andoni Alexandr, Cheikhi David\nconference: Arxiv\nyear: 2021\nbibkey: andoni2021from\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2105.05761\"}\ntags: ['ARXIV']\n---\nIn this note, we show that one can use average embeddings, introduced recently in [Naor'20, arXiv:1905.01280], to obtain efficient algorithms for approximate nearest neighbor search. In particular, a metric $X$ embeds into $\\ell_2$ on average, with distortion $D$, if, for any distribution $\\mu$ on $X$, the embedding is $D$ Lipschitz and the (square of) distance does not decrease on average (wrt $\\mu$). In particular existence of such an embedding (assuming it is efficient) implies a $O(D^3)$ approximate nearest neighbor search under $X$. This can be seen as a strengthening of the classic (bi-Lipschitz) embedding approach to nearest neighbor search, and is another application of data-dependent hashing paradigm.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [9.78995132446289, -15.390650749206543]}, {"key": "", "year": "", "title": "Andoni2021learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning to Hash Robustly, Guaranteed\"\nauthors: Andoni Alexandr, Beaglehole Daniel\nconference: Arxiv\nyear: 2021\nbibkey: andoni2021learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2108.05433\"}\ntags: ['ARXIV', 'LSH']\n---\nThe indexing algorithms for the high-dimensional nearest neighbor search (NNS) with the best worst-case guarantees are based on the randomized Locality Sensitive Hashing (LSH), and its derivatives. In practice, many heuristic approaches exist to \"learn\" the best indexing method in order to speed-up NNS, crucially adapting to the structure of the given dataset. Oftentimes, these heuristics outperform the LSH-based algorithms on real datasets, but, almost always, come at the cost of losing the guarantees of either correctness or robust performance on adversarial queries, or apply to datasets with an assumed extra structure/model. In this paper, we design an NNS algorithm for the Hamming space that has worst-case guarantees essentially matching that of theoretical algorithms, while optimizing the hashing to the structure of the dataset (think instance-optimal algorithms) for performance on the minimum-performing query. We evaluate the algorithm's ability to optimize for a given dataset both theoretically and practically. On the theoretical side, we exhibit a natural setting (dataset model) where our algorithm is much better than the standard theoretical one. On the practical side, we run experiments that show that our algorithm has a 1.8x and 2.1x better recall on the worst-performing queries to the MNIST and ImageNet datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-15.554123878479004, -10.739998817443848]}, {"key": "", "year": "", "title": "Andrecut2021additive", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Additive Feature Hashing\"\nauthors: Andrecut M.\nconference: Arxiv\nyear: 2021\nbibkey: andrecut2021additive\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2102.03943\"}\ntags: ['ARXIV']\n---\nThe hashing trick is a machine learning technique used to encode categorical features into a numerical vector representation of pre-defined fixed length. It works by using the categorical hash values as vector indices, and updating the vector values at those indices. Here we discuss a different approach based on additive-hashing and the \"almost orthogonal\" property of high-dimensional random vectors. That is, we show that additive feature hashing can be performed directly by adding the hash values and converting them into high-dimensional numerical vectors. We show that the performance of additive feature hashing is similar to the hashing trick, and we illustrate the results numerically using synthetic, language recognition, and SMS spam detection data.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [9.696452140808105, -5.307696342468262]}, {"key": "", "year": "", "title": "Andr\u00e92017exploiting", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Exploiting Modern Hardware for High-Dimensional Nearest Neighbor Search\"\nauthors: Andr\u00e9 Fabien\nconference: Arxiv\nyear: 2017\nbibkey: andr\u00e92017exploiting\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1712.02912\"}\ntags: ['ARXIV', 'Quantisation']\n---\nMany multimedia information retrieval or machine learning problems require efficient high-dimensional nearest neighbor search techniques. For instance, multimedia objects (images, music or videos) can be represented by high-dimensional feature vectors. Finding two similar multimedia objects then comes down to finding two objects that have similar feature vectors. In the current context of mass use of social networks, large scale multimedia databases or large scale machine learning applications are more and more common, calling for efficient nearest neighbor search approaches. This thesis builds on product quantization, an efficient nearest neighbor search technique that compresses high-dimensional vectors into short codes. This makes it possible to store very large databases entirely in RAM, enabling low response times. We propose several contributions that exploit the capabilities of modern CPUs, especially SIMD and the cache hierarchy, to further decrease response times offered by product quantization.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [5.355939865112305, -13.104473114013672]}, {"key": "", "year": "", "title": "Apple2021halftimehash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"HalftimeHash: Modern Hashing without 64-bit Multipliers or Finite Fields\"\nauthors: Apple Jim\nconference: Arxiv\nyear: 2021\nbibkey: apple2021halftimehash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2104.08865\"}\ntags: ['ARXIV', 'TIP']\n---\nHalftimeHash is a new algorithm for hashing long strings. The goals are few collisions (different inputs that produce identical output hash values) and high performance. Compared to the fastest universal hash functions on long strings (clhash and UMASH) HalftimeHash decreases collision probability while also increasing performance by over 50%, exceeding 16 bytes per cycle. In addition, HalftimeHash does not use any widening 64-bit multiplications or any finite field arithmetic that could limit its portability.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-27.37616729736328, -10.345784187316895]}, {"key": "", "year": "", "title": "Appleton2015multi", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Multi-probe consistent hashing\"\nauthors: Appleton Ben, O'Reilly Michael\nconference: Arxiv\nyear: 2015\nbibkey: appleton2015multi\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1505.00062\"}\ntags: ['ARXIV', 'TIP']\n---\nWe describe a consistent hashing algorithm which performs multiple lookups per key in a hash table of nodes. It requires no additional storage beyond the hash table, and achieves a peak-to-average load ratio of 1 + epsilon with just 1 + 1/epsilon lookups per key.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-28.59296989440918, -13.083230972290039]}, {"key": "", "year": "", "title": "Araujo2016large", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Large-Scale Query-by-Image Video Retrieval Using Bloom Filters\"\nauthors: Araujo Andre, Chaves Jason, Lakshman Haricharan, Angst Roland, Girod Bernd\nconference: Arxiv\nyear: 2016\nbibkey: araujo2016large\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1604.07939\"}\ntags: ['ARXIV', 'Video Retrieval']\n---\nWe consider the problem of using image queries to retrieve videos from a database. Our focus is on large-scale applications, where it is infeasible to index each database video frame independently. Our main contribution is a framework based on Bloom filters, which can be used to index long video segments, enabling efficient image-to-video comparisons. Using this framework, we investigate several retrieval architectures, by considering different types of aggregation and different functions to encode visual information -- these play a crucial role in achieving high performance. Extensive experiments show that the proposed technique improves mean average precision by 24% on a public dataset, while being 4X faster, compared to the previous state-of-the-art.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [0.06413550674915314, 29.67824363708496]}, {"key": "", "year": "", "title": "Arcos2020claraprint", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Claraprint: a chord and melody based fingerprint for western classical music cover detection\"\nauthors: Arcos Micka\u00ebl\nconference: Arxiv\nyear: 2020\nbibkey: arcos2020claraprint\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2009.10128\"}\ntags: ['ARXIV']\n---\nCover song detection has been an active field in the Music Information Retrieval (MIR) community during the past decades. Most of the research community focused in solving it for a wide range of music genres with diverse characteristics. Western classical music, a genre heavily based on the recording of \"cover songs\", or musical works, represents a large heritage, offering immediate application for an efficient fingerprint algorithm. We propose an engineering approach for retrieving a cover song from a reference database thanks to a fingerprint designed for classical musical works. We open a new data set to encourage the scientific community to use it for further researches regarding this genre.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [31.85614585876465, -5.985665321350098]}, {"key": "", "year": "", "title": "Argerich2016hash2vec", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hash2Vec, Feature Hashing for Word Embeddings\"\nauthors: Argerich Luis, Zaffaroni Joaqu\u00edn Torr\u00e9, Cano Mat\u00edas J\nconference: \nyear: 2016\nbibkey: argerich2016hash2vec\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1608.08940\"}\ntags: []\n---\nIn this paper we propose the application of feature hashing to create word embeddings for natural language processing. Feature hashing has been used successfully to create document vectors in related tasks like document classification. In this work we show that feature hashing can be applied to obtain word embeddings in linear time with the size of the data. The results show that this algorithm, that does not need training, is able to capture the semantic meaning of words. We compare the results against GloVe showing that they are similar. As far as we know this is the first application of feature hashing to the word embeddings problem and the results indicate this is a scalable technique with practical results for NLP applications.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [22.222190856933594, -1.3985553979873657]}, {"key": "", "year": "", "title": "Argerich2017generic", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Generic LSH Families for the Angular Distance Based on Johnson-Lindenstrauss Projections and Feature Hashing LSH\"\nauthors: Argerich Luis, Golmar Natalia\nconference: Arxiv\nyear: 2017\nbibkey: argerich2017generic\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1704.04684\"}\ntags: ['ARXIV', 'LSH']\n---\nIn this paper we propose the creation of generic LSH families for the angular distance based on Johnson-Lindenstrauss projections. We show that feature hashing is a valid J-L projection and propose two new LSH families based on feature hashing. These new LSH families are tested on both synthetic and real datasets with very good results and a considerable performance improvement over other LSH families. While the theoretical analysis is done for the angular distance, these families can also be used in practice for the euclidean distance with excellent results [2]. Our tests using real datasets show that the proposed LSH functions work well for the euclidean distance.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.742944717407227, -9.328096389770508]}, {"key": "", "year": "", "title": "Arponen2019shrewd", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"SHREWD: Semantic Hierarchy-based Relational Embeddings for Weakly-supervised Deep Hashing\"\nauthors: Arponen Heikki, Bishop Tom E\nconference: Arxiv\nyear: 2019\nbibkey: arponen2019shrewd\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1908.05602\"}\ntags: ['ARXIV', 'Supervised', 'Weakly Supervised']\n---\nUsing class labels to represent class similarity is a typical approach to training deep hashing systems for retrieval; samples from the same or different classes take binary 1 or 0 similarity values. This similarity does not model the full rich knowledge of semantic relations that may be present between data points. In this work we build upon the idea of using semantic hierarchies to form distance metrics between all available sample labels; for example cat to dog has a smaller distance than cat to guitar. We combine this type of semantic distance into a loss function to promote similar distances between the deep neural network embeddings. We also introduce an empirical Kullback-Leibler divergence loss term to promote binarization and uniformity of the embeddings. We test the resulting SHREWD method and demonstrate improvements in hierarchical retrieval scores using compact, binary hash codes instead of real valued ones, and show that in a weakly supervised hashing setting we are able to learn competitively without explicitly relying on class labels, but instead on similarities between labels.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-3.007913589477539, -1.2898080348968506]}, {"key": "", "year": "", "title": "Arponen2020learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning to hash with semantic similarity metrics and empirical KL divergence\"\nauthors: Arponen Heikki, Bishop Tom E.\nconference: Arxiv\nyear: 2020\nbibkey: arponen2020learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2005.04917\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval', 'Supervised']\n---\nLearning to hash is an efficient paradigm for exact and approximate nearest neighbor search from massive databases. Binary hash codes are typically extracted from an image by rounding output features from a CNN, which is trained on a supervised binary similar/ dissimilar task. Drawbacks of this approach are: (i) resulting codes do not necessarily capture semantic similarity of the input data (ii) rounding results in information loss, manifesting as decreased retrieval performance and (iii) Using only class-wise similarity as a target can lead to trivial solutions, simply encoding classifier outputs rather than learning more intricate relations, which is not detected by most performance metrics. We overcome (i) via a novel loss function encouraging the relative hash code distances of learned features to match those derived from their targets. We address (ii) via a differentiable estimate of the KL divergence between network outputs and a binary target distribution, resulting in minimal information loss when the features are rounded to binary. Finally, we resolve (iii) by focusing on a hierarchical precision metric. Efficiency of the methods is demonstrated with semantic image retrieval on the CIFAR-100, ImageNet and Conceptual Captions datasets, using similarities inferred from the WordNet label hierarchy or sentence embeddings.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [0.43616512417793274, 3.9556264877319336]}, {"key": "", "year": "", "title": "Arthur2010reverse", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Reverse Nearest Neighbors Search in High Dimensions using Locality-Sensitive Hashing\"\nauthors: Arthur David, Oudot Steve Y.\nconference: Arxiv\nyear: 2010\nbibkey: arthur2010reverse\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1011.4955\"}\ntags: ['ARXIV', 'GAN', 'LSH']\n---\nWe investigate the problem of finding reverse nearest neighbors efficiently. Although provably good solutions exist for this problem in low or fixed dimensions, to this date the methods proposed in high dimensions are mostly heuristic. We introduce a method that is both provably correct and efficient in all dimensions, based on a reduction of the problem to one instance of $\\e$-nearest neighbor search plus a controlled number of instances of {\\em exhaustive $r$-\\pleb}, a variant of {\\em Point Location among Equal Balls} where all the $r$-balls centered at the data points that contain the query point are sought for, not just one. The former problem has been extensively studied and elegantly solved in high dimensions using Locality-Sensitive Hashing (LSH) techniques. By contrast, the latter problem has a complexity that is still not fully understood. We revisit the analysis of the LSH scheme for exhaustive $r$-\\pleb using a somewhat refined notion of locality-sensitive family of hash function, which brings out a meaningful output-sensitive term in the complexity of the problem. Our analysis, combined with a non-isometric lifting of the data, enables us to answer exhaustive $r$-\\pleb queries (and down the road reverse nearest neighbors queries) efficiently. Along the way, we obtain a simple algorithm for answering exact nearest neighbor queries, whose complexity is parametrized by some {\\em condition number} measuring the inherent difficulty of a given instance of the problem.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-7.532133102416992, -21.696962356567383]}, {"key": "", "year": "", "title": "Assadi2022tight", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Tight Bounds for Monotone Minimal Perfect Hashing\"\nauthors: Assadi Sepehr, Farach-Colton Martin, Kuszmaul William\nconference: Arxiv\nyear: 2022\nbibkey: assadi2022tight\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2207.10556\"}\ntags: ['ARXIV', 'Graph']\n---\nThe monotone minimal perfect hash function (MMPHF) problem is the following indexing problem. Given a set $S= \\\\{s_1,\\ldots,s_n\\\\}$ of $n$ distinct keys from a universe $U$ of size $u$, create a data structure $DS$ that answers the following query: \\[ RankOp(q) = \\text{rank of } q \\text{ in } S \\text{ for all } q\\in S ~\\text{ and arbitrary answer otherwise.} \\] Solutions to the MMPHF problem are in widespread use in both theory and practice. The best upper bound known for the problem encodes $DS$ in $O(n\\log\\log\\log u)$ bits and performs queries in $O(\\log u)$ time. It has been an open problem to either improve the space upper bound or to show that this somewhat odd looking bound is tight. In this paper, we show the latter: specifically that any data structure (deterministic or randomized) for monotone minimal perfect hashing of any collection of $n$ elements from a universe of size $u$ requires $\\Omega(n \\cdot \\log\\log\\log\\{u\\})$ expected bits to answer every query correctly. We achieve our lower bound by defining a graph $\\mathbf\\{G\\}$ where the nodes are the possible $\\{u \\choose n\\}$ inputs and where two nodes are adjacent if they cannot share the same $DS$. The size of $DS$ is then lower bounded by the log of the chromatic number of $\\mathbf\\{G\\}$. Finally, we show that the fractional chromatic number (and hence the chromatic number) of $\\mathbf\\{G\\}$ is lower bounded by $2^\\{\\Omega(n \\log\\log\\log u)\\}$.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-9.376579284667969, -28.947452545166016]}, {"key": "", "year": "", "title": "Aum\u00fcller2012explicit", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Explicit and Efficient Hash Families Suffice for Cuckoo Hashing with a Stash\"\nauthors: Aum\u00fcller Martin, Dietzfelbinger Martin, Woelfel Philipp\nconference: Arxiv\nyear: 2012\nbibkey: aum\u00fcller2012explicit\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1204.4431\"}\ntags: ['ARXIV', 'Graph']\n---\nIt is shown that for cuckoo hashing with a stash as proposed by Kirsch, Mitzenmacher, and Wieder (2008) families of very simple hash functions can be used, maintaining the favorable performance guarantees: with stash size $s$ the probability of a rehash is $O(1/n^\\{s+1\\})$, and the evaluation time is $O(s)$. Instead of the full randomness needed for the analysis of Kirsch et al. and of Kutzelnigg (2010) (resp. $\\Theta(\\log n)$-wise independence for standard cuckoo hashing) the new approach even works with 2-wise independent hash families as building blocks. Both construction and analysis build upon the work of Dietzfelbinger and Woelfel (2003). The analysis, which can also be applied to the fully random case, utilizes a graph counting argument and is much simpler than previous proofs. As a byproduct, an algorithm for simulating uniform hashing is obtained. While it requires about twice as much space as the most space efficient solutions, it is attractive because of its simple and direct structure.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-22.09558868408203, -15.31408405303955]}, {"key": "", "year": "", "title": "Aum\u00fcller2016a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Simple Hash Class with Strong Randomness Properties in Graphs and Hypergraphs\"\nauthors: Aum\u00fcller Martin, Dietzfelbinger Martin, Woelfel Philipp\nconference: Arxiv\nyear: 2016\nbibkey: aum\u00fcller2016a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1611.00029\"}\ntags: ['ARXIV', 'Graph']\n---\nWe study randomness properties of graphs and hypergraphs generated by simple hash functions. Several hashing applications can be analyzed by studying the structure of $d$-uniform random ($d$-partite) hypergraphs obtained from a set $S$ of $n$ keys and $d$ randomly chosen hash functions $h_1,\\dots,h_d$ by associating each key $x\\in S$ with a hyperedge $\\\\{h_1(x),\\dots, h_d(x)\\\\}$. Often it is assumed that $h_1,\\dots,h_d$ exhibit a high degree of independence. We present a simple construction of a hash class whose hash functions have small constant evaluation time and can be stored in sublinear space. We devise general techniques to analyze the randomness properties of the graphs and hypergraphs generated by these hash functions, and we show that they can replace other, less efficient constructions in cuckoo hashing (with and without stash), the simulation of a uniform hash function, the construction of a perfect hash function, generalized cuckoo hashing and different load balancing scenarios.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [5.85821008682251, -32.53346633911133]}, {"key": "", "year": "", "title": "Aum\u00fcller2017distance", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Distance-Sensitive hashing\"\nauthors: Aum\u00fcller Martin, Christiani Tobias, Pagh Rasmus, Silvestri Francesco\nconference: Arxiv\nyear: 2017\nbibkey: aum\u00fcller2017distance\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1703.07867\"}\ntags: ['ARXIV', 'LSH']\n---\nLocality-sensitive hashing (LSH) is an important tool for managing high-dimensional noisy or uncertain data, for example in connection with data cleaning (similarity join) and noise-robust search (similarity search). However, for a number of problems the LSH framework is not known to yield good solutions, and instead ad hoc solutions have been designed for particular similarity and distance measures. For example, this is true for output-sensitive similarity search/join, and for indexes supporting annulus queries that aim to report a point close to a certain given distance from the query point. In this paper we initiate the study of distance-sensitive hashing (DSH), a generalization of LSH that seeks a family of hash functions such that the probability of two points having the same hash value is a given function of the distance between them. More precisely, given a distance space $(X, \\text\\{dist\\})$ and a \"collision probability function\" (CPF) $f\\colon \\mathbb\\{R\\}\\rightarrow [0,1]$ we seek a distribution over pairs of functions $(h,g)$ such that for every pair of points $x, y \\in X$ the collision probability is $\\Pr[h(x)=g(y)] = f(\\text\\{dist\\}(x,y))$. Locality-sensitive hashing is the study of how fast a CPF can decrease as the distance grows. For many spaces, $f$ can be made exponentially decreasing even if we restrict attention to the symmetric case where $g=h$. We show that the asymmetry achieved by having a pair of functions makes it possible to achieve CPFs that are, for example, increasing or unimodal, and show how this leads to principled solutions to problems not addressed by the LSH framework. This includes a novel application to privacy-preserving distance estimation. We believe that the DSH framework will find further applications in high-dimensional data management.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-8.702547073364258, -19.75843620300293]}, {"key": "", "year": "", "title": "Auvolat2015clustering", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Clustering is Efficient for Approximate Maximum Inner Product Search\"\nauthors: Auvolat Alex, Chandar Sarath, Vincent Pascal, Larochelle Hugo, Bengio Yoshua\nconference: Arxiv\nyear: 2015\nbibkey: auvolat2015clustering\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1507.05910\"}\ntags: ['ARXIV', 'LSH']\n---\nEfficient Maximum Inner Product Search (MIPS) is an important task that has a wide applicability in recommendation systems and classification with a large number of classes. Solutions based on locality-sensitive hashing (LSH) as well as tree-based solutions have been investigated in the recent literature, to perform approximate MIPS in sublinear time. In this paper, we compare these to another extremely simple approach for solving approximate MIPS, based on variants of the k-means clustering algorithm. Specifically, we propose to train a spherical k-means, after having reduced the MIPS problem to a Maximum Cosine Similarity Search (MCSS). Experiments on two standard recommendation system benchmarks as well as on large vocabulary word embeddings, show that this simple approach yields much higher speedups, for the same retrieval precision, than current state-of-the-art hashing-based and tree-based methods. This simple method also yields more robust retrievals when the query is corrupted by noise.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [6.127808570861816, -7.06684684753418]}, {"key": "", "year": "", "title": "Azarafrooz2018fuzzy", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fuzzy Hashing as Perturbation-Consistent Adversarial Kernel Embedding\"\nauthors: Azarafrooz Ari, Brock John\nconference: Arxiv\nyear: 2018\nbibkey: azarafrooz2018fuzzy\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1812.07071\"}\ntags: ['ARXIV']\n---\nMeasuring the similarity of two files is an important task in malware analysis, with fuzzy hash functions being a popular approach. Traditional fuzzy hash functions are data agnostic: they do not learn from a particular dataset how to determine similarity; their behavior is fixed across all datasets. In this paper, we demonstrate that fuzzy hash functions can be learned in a novel minimax training framework and that these learned fuzzy hash functions outperform traditional fuzzy hash functions at the file similarity task for Portable Executable files. In our approach, hash digests can be extracted from the kernel embeddings of two kernel networks, trained in a minimax framework, where the roles of players during training (i.e adversary versus generator) alternate along with the input data. We refer to this new minimax architecture as perturbation-consistent. The similarity score for a pair of files is the utility of the minimax game in equilibrium. Our experiments show that learned fuzzy hash functions generalize well, capable of determining that two files are similar even when one of those files was generated using insertion and deletion operations.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-5.860921382904053, -0.8462544679641724]}, {"key": "", "year": "", "title": "Babaie2017retrieving", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Retrieving Similar X-Ray Images from Big Image Data Using Radon Barcodes with Single Projections\"\nauthors: Babaie Morteza, Tizhoosh H. R., Zhu Shujin, Shiri M. E.\nconference: Arxiv\nyear: 2017\nbibkey: babaie2017retrieving\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1701.00449\"}\ntags: ['ARXIV', 'ICIP', 'Image Retrieval', 'TIP']\n---\nThe idea of Radon barcodes (RBC) has been introduced recently. In this paper, we propose a content-based image retrieval approach for big datasets based on Radon barcodes. Our method (Single Projection Radon Barcode, or SP-RBC) uses only a few Radon single projections for each image as global features that can serve as a basis for weak learners. This is our most important contribution in this work, which improves the results of the RBC considerably. As a matter of fact, only one projection of an image, as short as a single SURF feature vector, can already achieve acceptable results. Nevertheless, using multiple projections in a long vector will not deliver anticipated improvements. To exploit the information inherent in each projection, our method uses the outcome of each projection separately and then applies more precise local search on the small subset of retrieved images. We have tested our method using IRMA 2009 dataset a with 14,400 x-ray images as part of imageCLEF initiative. Our approach leads to a substantial decrease in the error rate in comparison with other non-learning methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [26.443777084350586, 21.8914852142334]}, {"key": "", "year": "", "title": "Babenko2014neural", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Neural Codes for Image Retrieval\"\nauthors: Babenko Artem, Slesarev Anton, Chigorin Alexandr, Lempitsky Victor\nconference: Arxiv\nyear: 2014\nbibkey: babenko2014neural\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1404.1777\"}\ntags: ['ARXIV', 'Graph', 'Image Retrieval']\n---\nIt has been shown that the activations invoked by an image within the top layers of a large convolutional neural network provide a high-level descriptor of the visual content of the image. In this paper, we investigate the use of such descriptors (neural codes) within the image retrieval application. In the experiments with several standard retrieval benchmarks, we establish that neural codes perform competitively even when the convolutional neural network has been trained for an unrelated classification task (e.g.\\ Image-Net). We also evaluate the improvement in the retrieval performance of neural codes, when the network is retrained on a dataset of images that are similar to images encountered at test time. We further evaluate the performance of the compressed neural codes and show that a simple PCA compression provides very good short codes that give state-of-the-art accuracy on a number of datasets. In general, neural codes turn out to be much more resilient to such compression in comparison other state-of-the-art descriptors. Finally, we show that discriminative dimensionality reduction trained on a dataset of pairs of matched photographs improves the performance of PCA-compressed neural codes even further. Overall, our quantitative experiments demonstrate the promise of neural codes as visual descriptors for image retrieval.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.767974853515625, 5.360313892364502]}, {"key": "", "year": "", "title": "Badamdorj2019fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast Search with Poor OCR\"\nauthors: Badamdorj Taivanbat, Ben-Shalom Adiel, Dershowitz Nachum, Wolf Lior\nconference: Arxiv\nyear: 2019\nbibkey: badamdorj2019fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1909.07899\"}\ntags: ['ARXIV']\n---\nThe indexing and searching of historical documents have garnered attention in recent years due to massive digitization efforts of important collections worldwide. Pure textual search in these corpora is a problem since optical character recognition (OCR) is infamous for performing poorly on such historical material, which often suffer from poor preservation. We propose a novel text-based method for searching through noisy text. Our system represents words as vectors, projects queries and candidates obtained from the OCR into a common space, and ranks the candidates using a metric suited to nearest-neighbor search. We demonstrate the practicality of our method on typewritten German documents from the WWII era.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [25.382999420166016, -5.950270652770996]}, {"key": "", "year": "", "title": "Bai2013learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning High-level Image Representation for Image Retrieval via Multi-Task DNN using Clickthrough Data\"\nauthors: Bai Yalong, Yang Kuiyuan, Yu Wei, Ma Wei-Ying, Zhao Tiejun\nconference: Arxiv\nyear: 2013\nbibkey: bai2013learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1312.4740\"}\ntags: ['ARXIV', 'Image Retrieval', 'TOM']\n---\nImage retrieval refers to finding relevant images from an image database for a query, which is considered difficult for the gap between low-level representation of images and high-level representation of queries. Recently further developed Deep Neural Network sheds light on automatically learning high-level image representation from raw pixels. In this paper, we proposed a multi-task DNN learned for image retrieval, which contains two parts, i.e., query-sharing layers for image representation computation and query-specific layers for relevance estimation. The weights of multi-task DNN are learned on clickthrough data by Ring Training. Experimental results on both simulated and real dataset show the effectiveness of the proposed method.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [25.094772338867188, 12.52556324005127]}, {"key": "", "year": "", "title": "Bai2020targeted", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Targeted Attack for Deep Hashing based Retrieval\"\nauthors: Bai Jiawang, Chen Bin, Li Yiming, Wu Dongxian, Guo Weiwei, Xia Shu-tao, Yang En-hui\nconference: Arxiv\nyear: 2020\nbibkey: bai2020targeted\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2004.07955\"}\ntags: ['ARXIV', 'Image Retrieval', 'Video Retrieval']\n---\nThe deep hashing based retrieval method is widely adopted in large-scale image and video retrieval. However, there is little investigation on its security. In this paper, we propose a novel method, dubbed deep hashing targeted attack (DHTA), to study the targeted attack on such retrieval. Specifically, we first formulate the targeted attack as a point-to-set optimization, which minimizes the average distance between the hash code of an adversarial example and those of a set of objects with the target label. Then we design a novel component-voting scheme to obtain an anchor code as the representative of the set of hash codes of objects with the target label, whose optimality guarantee is also theoretically derived. To balance the performance and perceptibility, we propose to minimize the Hamming distance between the hash code of the adversarial example and the anchor code under the $\\ell^\\infty$ restriction on the perturbation. Extensive experiments verify that DHTA is effective in attacking both deep hashing based image retrieval and video retrieval.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [3.491220235824585, 25.632349014282227]}, {"key": "", "year": "", "title": "Bakhtiary2015speeding", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Speeding Up Neural Networks for Large Scale Classification using WTA Hashing\"\nauthors: Bakhtiary Amir H., Lapedriza Agata, Masip David\nconference: Arxiv\nyear: 2015\nbibkey: bakhtiary2015speeding\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1504.07488\"}\ntags: ['ARXIV', 'TIP']\n---\nIn this paper we propose to use the Winner Takes All hashing technique to speed up forward propagation and backward propagation in fully connected layers in convolutional neural networks. The proposed technique reduces significantly the computational complexity, which in turn, allows us to train layers with a large number of kernels with out the associated time penalty. As a consequence we are able to train convolutional neural network on a very large number of output classes with only a small increase in the computational cost. To show the effectiveness of the technique we train a new output layer on a pretrained network using both the regular multiplicative approach and our proposed hashing methodology. Our results showed no drop in performance and demonstrate, with our implementation, a 7 fold speed up during the training.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-18.99718475341797, 12.17549991607666]}, {"key": "", "year": "", "title": "Ballard2015diamond", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Diamond Sampling for Approximate Maximum All-pairs Dot-product (MAD) Search\"\nauthors: Ballard Grey, Pinar Ali, Kolda Tamara G., Seshadhri C.\nconference: ICDM\nyear: 2015\nbibkey: ballard2015diamond\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1506.03872\"}\ntags: []\n---\nGiven two sets of vectors, $A = \\\\{\\{a_1\\}, \\dots, \\{a_m\\}\\\\}$ and $B=\\\\{\\{b_1\\},\\dots,\\{b_n\\}\\\\}$, our problem is to find the top-$t$ dot products, i.e., the largest $|\\{a_i\\}\\cdot\\{b_j\\}|$ among all possible pairs. This is a fundamental mathematical problem that appears in numerous data applications involving similarity search, link prediction, and collaborative filtering. We propose a sampling-based approach that avoids direct computation of all $mn$ dot products. We select diamonds (i.e., four-cycles) from the weighted tripartite representation of $A$ and $B$. The probability of selecting a diamond corresponding to pair $(i,j)$ is proportional to $(\\{a_i\\}\\cdot\\{b_j\\})^2$, amplifying the focus on the largest-magnitude entries. Experimental results indicate that diamond sampling is orders of magnitude faster than direct computation and requires far fewer samples than any competing approach. We also apply diamond sampling to the special case of maximum inner product search, and get significantly better results than the state-of-the-art hashing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-5.4730916023254395, -17.571514129638672]}, {"key": "", "year": "", "title": "Balntas2016pn", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"PN-Net: Conjoined Triple Deep Network for Learning Local Image Descriptors\"\nauthors: Balntas Vassileios, Johns Edward, Tang Lilian, Mikolajczyk Krystian\nconference: Arxiv\nyear: 2016\nbibkey: balntas2016pn\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1601.05030\"}\ntags: ['ARXIV', 'CNN']\n---\nIn this paper we propose a new approach for learning local descriptors for matching image patches. It has recently been demonstrated that descriptors based on convolutional neural networks (CNN) can significantly improve the matching performance. Unfortunately their computational complexity is prohibitive for any practical application. We address this problem and propose a CNN based descriptor with improved matching performance, significantly reduced training and execution time, as well as low dimensionality. We propose to train the network with triplets of patches that include a positive and negative pairs. To that end we introduce a new loss function that exploits the relations within the triplets. We compare our approach to recently introduced MatchNet and DeepCompare and demonstrate the advantages of our descriptor in terms of performance, memory footprint and speed i.e. when run in GPU, the extraction time of our 128 dimensional feature is comparable to the fastest available binary descriptors such as BRIEF and ORB.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [10.48298454284668, 30.858999252319336]}, {"key": "", "year": "", "title": "Balntas2017hpatches", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"HPatches: A benchmark and evaluation of handcrafted and learned local descriptors\"\nauthors: Balntas Vassileios, Lenc Karel, Vedaldi Andrea, Mikolajczyk Krystian\nconference: Arxiv\nyear: 2017\nbibkey: balntas2017hpatches\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1704.05939\"}\ntags: ['ARXIV', 'Deep Learning']\n---\nIn this paper, we propose a novel benchmark for evaluating local image descriptors. We demonstrate that the existing datasets and evaluation protocols do not specify unambiguously all aspects of evaluation, leading to ambiguities and inconsistencies in results reported in the literature. Furthermore, these datasets are nearly saturated due to the recent improvements in local descriptors obtained by learning them from large annotated datasets. Therefore, we introduce a new large dataset suitable for training and testing modern descriptors, together with strictly defined evaluation protocols in several tasks such as matching, retrieval and classification. This allows for more realistic, and thus more reliable comparisons in different application scenarios. We evaluate the performance of several state-of-the-art descriptors and analyse their properties. We show that a simple normalisation of traditional hand-crafted descriptors can boost their performance to the level of deep learning based descriptors within a realistic benchmarks evaluation.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [19.138473510742188, 16.665813446044922]}, {"key": "", "year": "", "title": "Banerjee2017local", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Local Neighborhood Intensity Pattern: A new texture feature descriptor for image retrieval\"\nauthors: Banerjee Prithaj, Bhunia Ayan Kumar, Bhattacharyya Avirup, Roy Partha Pratim, Murala Subrahmanyam\nconference: Arxiv\nyear: 2017\nbibkey: banerjee2017local\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1709.02463\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nIn this paper, a new texture descriptor based on the local neighborhood intensity difference is proposed for content based image retrieval (CBIR). For computation of texture features like Local Binary Pattern (LBP), the center pixel in a 3*3 window of an image is compared with all the remaining neighbors, one pixel at a time to generate a binary bit pattern. It ignores the effect of the adjacent neighbors of a particular pixel for its binary encoding and also for texture description. The proposed method is based on the concept that neighbors of a particular pixel hold a significant amount of texture information that can be considered for efficient texture representation for CBIR. Taking this into account, we develop a new texture descriptor, named as Local Neighborhood Intensity Pattern (LNIP) which considers the relative intensity difference between a particular pixel and the center pixel by considering its adjacent neighbors and generate a sign and a magnitude pattern. Since sign and magnitude patterns hold complementary information to each other, these two patterns are concatenated into a single feature descriptor to generate a more concrete and useful feature descriptor. The proposed descriptor has been tested for image retrieval on four databases, including three texture image databases - Brodatz texture image database, MIT VisTex database and Salzburg texture database and one face database AT&amp;T face database. The precision and recall values observed on these databases are compared with some state-of-art local patterns. The proposed method showed a significant improvement over many other existing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [21.99717140197754, 21.939746856689453]}, {"key": "", "year": "", "title": "Bao2015linear", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Linear Spatial Pyramid Matching Using Non-convex and non-negative Sparse Coding for Image Classification\"\nauthors: Bao Chengqiang, He Liangtian, Wang Yilun\nconference: Arxiv\nyear: 2015\nbibkey: bao2015linear\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1504.06897\"}\ntags: ['ARXIV']\n---\nRecently sparse coding have been highly successful in image classification mainly due to its capability of incorporating the sparsity of image representation. In this paper, we propose an improved sparse coding model based on linear spatial pyramid matching(SPM) and Scale Invariant Feature Transform (SIFT ) descriptors. The novelty is the simultaneous non-convex and non-negative characters added to the sparse coding model. Our numerical experiments show that the improved approach using non-convex and non-negative sparse coding is superior than the original ScSPM[1] on several typical databases.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [14.080031394958496, 2.717874526977539]}, {"key": "", "year": "", "title": "Baranchuk2018revisiting", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Revisiting the Inverted Indices for Billion-Scale Approximate Nearest Neighbors\"\nauthors: Baranchuk Dmitry, Babenko Artem, Malkov Yury\nconference: Arxiv\nyear: 2018\nbibkey: baranchuk2018revisiting\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1802.02422\"}\ntags: ['ARXIV']\n---\nThis work addresses the problem of billion-scale nearest neighbor search. The state-of-the-art retrieval systems for billion-scale databases are currently based on the inverted multi-index, the recently proposed generalization of the inverted index structure. The multi-index provides a very fine-grained partition of the feature space that allows extracting concise and accurate short-lists of candidates for the search queries. In this paper, we argue that the potential of the simple inverted index was not fully exploited in previous works and advocate its usage both for the highly-entangled deep descriptors and relatively disentangled SIFT descriptors. We introduce a new retrieval system that is based on the inverted index and outperforms the multi-index by a large margin for the same memory consumption and construction complexity. For example, our system achieves the state-of-the-art recall rates several times faster on the dataset of one billion deep descriptors compared to the efficient implementation of the inverted multi-index from the FAISS library.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [13.64310359954834, -7.7314019203186035]}, {"key": "", "year": "", "title": "Baranchuk2023dedrift", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"DeDrift: Robust Similarity Search under Content Drift\"\nauthors: Baranchuk Dmitry, Douze Matthijs, Upadhyay Yash, Yalniz I. Zeki\nconference: Arxiv\nyear: 2023\nbibkey: baranchuk2023dedrift\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2308.02752\"}\ntags: ['ARXIV']\n---\nThe statistical distribution of content uploaded and searched on media sharing sites changes over time due to seasonal, sociological and technical factors. We investigate the impact of this \"content drift\" for large-scale similarity search tools, based on nearest neighbor search in embedding space. Unless a costly index reconstruction is performed frequently, content drift degrades the search accuracy and efficiency. The degradation is especially severe since, in general, both the query and database distributions change. We introduce and analyze real-world image and video datasets for which temporal information is available over a long time period. Based on the learnings, we devise DeDrift, a method that updates embedding quantizers to continuously adapt large-scale indexing structures on-the-fly. DeDrift almost eliminates the accuracy degradation due to the query and database content drift while being up to 100x faster than a full index reconstruction.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.980697631835938, -1.2183798551559448]}, {"key": "", "year": "", "title": "Barbarani2023are", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Are Local Features All You Need for Cross-Domain Visual Place Recognition\"\nauthors: Barbarani Giovanni, Mostafa Mohamad, Bayramov Hajali, Trivigno Gabriele, Berton Gabriele, Masone Carlo, Caputo Barbara\nconference: Arxiv\nyear: 2023\nbibkey: barbarani2023are\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2304.05887\"}   - {name: \"Code\", url: \"https://github.com/gbarbarani/re-ranking-for-VPR.\"}\ntags: ['ARXIV']\n---\nVisual Place Recognition is a task that aims to predict the coordinates of an image (called query) based solely on visual clues. Most commonly, a retrieval approach is adopted, where the query is matched to the most similar images from a large database of geotagged photos, using learned global descriptors. Despite recent advances, recognizing the same place when the query comes from a significantly different distribution is still a major hurdle for state of the art retrieval methods. Examples are heavy illumination changes (e.g. night-time images) or substantial occlusions (e.g. transient objects). In this work we explore whether re-ranking methods based on spatial verification can tackle these challenges, following the intuition that local descriptors are inherently more robust than global features to domain shifts. To this end, we provide a new, comprehensive benchmark on current state of the art models. We also introduce two new demanding datasets with night and occluded queries, to be matched against a city-wide database. Code and datasets are available at https://github.com/gbarbarani/re-ranking-for-VPR.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [21.587921142578125, 17.583274841308594]}, {"key": "", "year": "", "title": "Bartal2015approximate", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Approximate nearest neighbor search for $\\ell_p$-spaces ($2 p \\infty$) via embeddings\"\nauthors: Bartal Yair, Gottlieb Lee-Ad\nconference: Arxiv\nyear: 2015\nbibkey: bartal2015approximate\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1512.01775\"}\ntags: ['ARXIV']\n---\nWhile the problem of approximate nearest neighbor search has been well-studied for Euclidean space and $\\ell_1$, few non-trivial algorithms are known for $\\ell_p$ when ($2 &lt; p &lt; \\infty$). In this paper, we revisit this fundamental problem and present approximate nearest-neighbor search algorithms which give the first non-trivial approximation factor guarantees in this setting.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [9.433279037475586, -18.3431339263916]}, {"key": "", "year": "", "title": "Barz2017automatic", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Automatic Query Image Disambiguation for Content-Based Image Retrieval\"\nauthors: Barz Bj\u00f6rn, Denzler Joachim\nconference: Arxiv\nyear: 2017\nbibkey: barz2017automatic\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1711.00953\"}\ntags: ['ARXIV', 'Image Retrieval', 'TOM']\n---\nQuery images presented to content-based image retrieval systems often have various different interpretations, making it difficult to identify the search objective pursued by the user. We propose a technique for overcoming this ambiguity, while keeping the amount of required user interaction at a minimum. To achieve this, the neighborhood of the query image is divided into coherent clusters from which the user may choose the relevant ones. A novel feedback integration technique is then employed to re-rank the entire database with regard to both the user feedback and the original query. We evaluate our approach on the publicly available MIRFLICKR-25K dataset, where it leads to a relative improvement of average precision by 23% over the baseline retrieval, which does not distinguish between different image senses.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [24.21936798095703, 12.339495658874512]}, {"key": "", "year": "", "title": "Barz2018hierarchy", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hierarchy-based Image Embeddings for Semantic Image Retrieval\"\nauthors: Barz Bj\u00f6rn, Denzler Joachim\nconference: \nyear: 2018\nbibkey: barz2018hierarchy\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1809.09924\"}\ntags: ['Image Retrieval']\n---\nDeep neural networks trained for classification have been found to learn powerful image representations, which are also often used for other tasks such as comparing images w.r.t. their visual similarity. However, visual similarity does not imply semantic similarity. In order to learn semantically discriminative features, we propose to map images onto class embeddings whose pair-wise dot products correspond to a measure of semantic similarity between classes. Such an embedding does not only improve image retrieval results, but could also facilitate integrating semantics for other tasks, e.g., novelty detection or few-shot learning. We introduce a deterministic algorithm for computing the class centroids directly based on prior world-knowledge encoded in a hierarchy of classes such as WordNet. Experiments on CIFAR-100, NABirds, and ImageNet show that our learned semantic image embeddings improve the semantic consistency of image retrieval results by a large margin.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [13.299165725708008, 6.313643932342529]}, {"key": "", "year": "", "title": "Barz2020content", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Content-based Image Retrieval and the Semantic Gap in the Deep Learning Era\"\nauthors: Barz Bj\u00f6rn, Denzler Joachim\nconference: Arxiv\nyear: 2020\nbibkey: barz2020content\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2011.06490\"}\ntags: ['ARXIV', 'Deep Learning', 'Image Retrieval', 'Survey Paper']\n---\nContent-based image retrieval has seen astonishing progress over the past decade, especially for the task of retrieving images of the same object that is depicted in the query image. This scenario is called instance or object retrieval and requires matching fine-grained visual patterns between images. Semantics, however, do not play a crucial role. This brings rise to the question: Do the recent advances in instance retrieval transfer to more generic image retrieval scenarios? To answer this question, we first provide a brief overview of the most relevant milestones of instance retrieval. We then apply them to a semantic image retrieval task and find that they perform inferior to much less sophisticated and more generic methods in a setting that requires image understanding. Following this, we review existing approaches to closing this so-called semantic gap by integrating prior world knowledge. We conclude that the key problem for the further advancement of semantic image retrieval lies in the lack of a standardized task definition and an appropriate benchmark dataset.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [15.323600769042969, 13.277031898498535]}, {"key": "", "year": "", "title": "Bastan2019large", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Large Scale Open-Set Deep Logo Detection\"\nauthors: Bastan Muhammet, Wu Hao-Yu, Cao Tian, Kota Bhargava, Tek Mehmet\nconference: Arxiv\nyear: 2019\nbibkey: bastan2019large\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1911.07440\"}\ntags: ['ARXIV']\n---\nWe present an open-set logo detection (OSLD) system, which can detect (localize and recognize) any number of unseen logo classes without re-training; it only requires a small set of canonical logo images for each logo class. We achieve this using a two-stage approach: (1) Generic logo detection to detect candidate logo regions in an image. (2) Logo matching for matching the detected logo regions to a set of canonical logo images to recognize them. We constructed an open-set logo detection dataset with 12.1k logo classes and released it for research purposes.We demonstrate the effectiveness of OSLD on our dataset and on the standard Flickr-32 logo dataset, outperforming the state-of-the-art open-set and closed-set logo detection methods by a large margin. OSLD is scalable to millions of logo classes.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [5.929266929626465, 21.266357421875]}, {"key": "", "year": "", "title": "Belazzougui2014queries", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Queries on LZ-Bounded Encodings\"\nauthors: Belazzougui Djamal, Gagie Travis, Gawrychowski Pawe\u0142, K\u00e4rkk\u00e4inen Juha, Ord\u00f3\u00f1ez Alberto, Puglisi Simon J., Tabei Yasuo\nconference: Arxiv\nyear: 2014\nbibkey: belazzougui2014queries\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1412.0967\"}\ntags: ['ARXIV', 'Graph']\n---\nWe describe a data structure that stores a string $S$ in space similar to that of its Lempel-Ziv encoding and efficiently supports access, rank and select queries. These queries are fundamental for implementing succinct and compressed data structures, such as compressed trees and graphs. We show that our data structure can be built in a scalable manner and is both small and fast in practice compared to other data structures supporting such queries.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [33.24722671508789, 3.7744407653808594]}, {"key": "", "year": "", "title": "Belazzougui2014reusing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Reusing an FM-index\"\nauthors: Belazzougui Djamal, Gagie Travis, Gog Simon, Manzini Giovanni, Sir\u00e9n Jouni\nconference: Arxiv\nyear: 2014\nbibkey: belazzougui2014reusing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1404.4814\"}\ntags: ['ARXIV']\n---\nIntuitively, if two strings $S_1$ and $S_2$ are sufficiently similar and we already have an FM-index for $S_1$ then, by storing a little extra information, we should be able to reuse parts of that index in an FM-index for $S_2$. We formalize this intuition and show that it can lead to significant space savings in practice, as well as to some interesting theoretical problems.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [32.63457489013672, 3.276834011077881]}, {"key": "", "year": "", "title": "Belazzougui2016fully", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fully Dynamic de Bruijn Graphs\"\nauthors: Belazzougui Djamal, Gagie Travis, M\u00e4kinen Veli, Previtali Marco\nconference: Arxiv\nyear: 2016\nbibkey: belazzougui2016fully\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1607.04909\"}\ntags: ['ARXIV', 'Graph']\n---\nWe present a space- and time-efficient fully dynamic implementation de Bruijn graphs, which can also support fixed-length jumbled pattern matching.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [33.819969177246094, 3.7955162525177]}, {"key": "", "year": "", "title": "Belazzougui2018fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast Prefix Search in Little Space, with Applications\"\nauthors: Belazzougui Djamal, Boldi Paolo, Pagh Rasmus, Vigna Sebastiano\nconference: Arxiv\nyear: 2018\nbibkey: belazzougui2018fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1804.04720\"}\ntags: ['ARXIV']\n---\nIt has been shown in the indexing literature that there is an essential difference between prefix/range searches on the one hand, and predecessor/rank searches on the other hand, in that the former provably allows faster query resolution. Traditionally, prefix search is solved by data structures that are also dictionaries---they actually contain the strings in $S$. For very large collections stored in slow-access memory, we propose much more compact data structures that support \\emph{weak} prefix searches---they return the ranks of matching strings provided that \\emph{some} string in $S$ starts with the given prefix. In fact, we show that our most space-efficient data structure is asymptotically space-optimal. Previously, data structures such as String B-trees (and more complicated cache-oblivious string data structures) have implicitly supported weak prefix queries, but they all have query time that grows logarithmically with the size of the string collection. In contrast, our data structures are simple, naturally cache-efficient, and have query time that depends only on the length of the prefix, all the way down to constant query time for strings that fit in one machine word. We give several applications of weak prefix searches, including exact prefix counting and approximate counting of tuples matching conjunctive prefix conditions.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-2.4525160789489746, -13.167608261108398]}, {"key": "", "year": "", "title": "Benbassat2020locality", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Locality-Sensitive Hashing for Efficient Web Application Security Testing\"\nauthors: Ben-Bassat Ilan, Rokah Erez\nconference: In Proceedings of the\nyear: 2020\nbibkey: benbassat2020locality\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2001.01128\"}\ntags: ['ACL', 'TOM']\n---\nWeb application security has become a major concern in recent years, as more and more content and services are available online. A useful method for identifying security vulnerabilities is black-box testing, which relies on an automated crawling of web applications. However, crawling Rich Internet Applications (RIAs) is a very challenging task. One of the key obstacles crawlers face is the state similarity problem: how to determine if two client-side states are equivalent. As current methods do not completely solve this problem, a successful scan of many real-world RIAs is still not possible. We present a novel approach to detect redundant content for security testing purposes. The algorithm applies locality-sensitive hashing using MinHash sketches in order to analyze the Document Object Model (DOM) structure of web pages, and to efficiently estimate similarity between them. Our experimental results show that this approach allows a successful scan of RIAs that cannot be crawled otherwise.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-31.533340454101562, 8.08326530456543]}, {"key": "", "year": "", "title": "Bencohen2021semantic", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Semantic Diversity Learning for Zero-Shot Multi-label Classification\"\nauthors: Ben-Cohen Avi, Zamir Nadav, Baruch Emanuel Ben, Friedman Itamar, Zelnik-Manor Lihi\nconference: Arxiv\nyear: 2021\nbibkey: bencohen2021semantic\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2105.05926\"}\ntags: ['ARXIV', 'Image Retrieval', 'TIP']\n---\nTraining a neural network model for recognizing multiple labels associated with an image, including identifying unseen labels, is challenging, especially for images that portray numerous semantically diverse labels. As challenging as this task is, it is an essential task to tackle since it represents many real-world cases, such as image retrieval of natural images. We argue that using a single embedding vector to represent an image, as commonly practiced, is not sufficient to rank both relevant seen and unseen labels accurately. This study introduces an end-to-end model training for multi-label zero-shot learning that supports semantic diversity of the images and labels. We propose to use an embedding matrix having principal embedding vectors trained using a tailored loss function. In addition, during training, we suggest up-weighting in the loss function image samples presenting higher semantic diversity to encourage the diversity of the embedding matrix. Extensive experiments show that our proposed method improves the zero-shot model's quality in tag-based image retrieval achieving SoTA results on several common datasets (NUS-Wide, COCO, Open Images).\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-3.8540892601013184, 15.143295288085938]}, {"key": "", "year": "", "title": "Bender2021iceberg", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Iceberg Hashing: Optimizing Many Hash-Table Criteria at Once\"\nauthors: Bender Michael A., Conway Alex, Farach-Colton Mart\u00edn, Kuszmaul William, Tagliavini Guido\nconference: Arxiv\nyear: 2021\nbibkey: bender2021iceberg\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2109.04548\"}\ntags: ['ARXIV']\n---\nDespite being one of the oldest data structures in computer science, hash tables continue to be the focus of a great deal of both theoretical and empirical research. A central reason for this is that many of the fundamental properties that one desires from a hash table are difficult to achieve simultaneously; thus many variants offering different trade-offs have been proposed. This paper introduces Iceberg hashing, a hash table that simultaneously offers the strongest known guarantees on a large number of core properties. Iceberg hashing supports constant-time operations while improving on the state of the art for space efficiency, cache efficiency, and low failure probability. Iceberg hashing is also the first hash table to support a load factor of up to $1 - o(1)$ while being stable, meaning that the position where an element is stored only ever changes when resizes occur. In fact, in the setting where keys are $\\Theta(\\log n)$ bits, the space guarantees that Iceberg hashing offers, namely that it uses at most $\\log \\binom\\{|U|\\}\\{n\\} + O(n \\log \\log n)$ bits to store $n$ items from a universe $U$, matches a lower bound by Demaine et al. that applies to any stable hash table. Iceberg hashing introduces new general-purpose techniques for some of the most basic aspects of hash-table design. Notably, our indirection-free technique for dynamic resizing, which we call waterfall addressing, and our techniques for achieving stability and very-high probability guarantees, can be applied to any hash table that makes use of the front-yard/backyard paradigm for hash table design.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-22.04730796813965, -17.64582061767578]}, {"key": "", "year": "", "title": "Bender2021on", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"On the Optimal Time/Space Tradeoff for Hash Tables\"\nauthors: Bender Michael A., Farach-Colton Mart\u00edn, Kuszmaul John, Kuszmaul William, Liu Mingmou\nconference: Arxiv\nyear: 2021\nbibkey: bender2021on\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2111.00602\"}\ntags: ['ARXIV']\n---\nFor nearly six decades, the central open question in the study of hash tables has been to determine the optimal achievable tradeoff curve between time and space. State-of-the-art hash tables offer the following guarantee: If keys/values are Theta(log n) bits each, then it is possible to achieve constant-time insertions/deletions/queries while wasting only O(loglog n) bits of space per key when compared to the information-theoretic optimum. Even prior to this bound being achieved, the target of O(loglog n) wasted bits per key was known to be a natural end goal, and was proven to be optimal for a number of closely related problems (e.g., stable hashing, dynamic retrieval, and dynamically-resized filters). This paper shows that O(loglog n) wasted bits per key is not the end of the line for hashing. In fact, for any k \\in [log* n], it is possible to achieve O(k)-time insertions/deletions, O(1)-time queries, and O(\\log^{(k)} n) wasted bits per key (all with high probability in n). This means that, each time we increase insertion/deletion time by an \\emph{additive constant}, we reduce the wasted bits per key \\emph{exponentially}. We further show that this tradeoff curve is the best achievable by any of a large class of hash tables, including any hash table designed using the current framework for making constant-time hash tables succinct.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-17.289443969726562, -15.698765754699707]}, {"key": "", "year": "", "title": "Bercea2023locally", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Locally Uniform Hashing\"\nauthors: Bercea Ioana O., Beretta Lorenzo, Klausen Jonas, Houen Jakob B\u00e6k Tejs, Thorup Mikkel\nconference: Arxiv\nyear: 2023\nbibkey: bercea2023locally\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2308.14134\"}\ntags: ['ARXIV', 'GAN']\n---\nHashing is a common technique used in data processing, with a strong impact on the time and resources spent on computation. Hashing also affects the applicability of theoretical results that often assume access to (unrealistic) uniform/fully-random hash functions. In this paper, we are concerned with designing hash functions that are practical and come with strong theoretical guarantees on their performance. To this end, we present tornado tabulation hashing, which is simple, fast, and exhibits a certain full, local randomness property that provably makes diverse algorithms perform almost as if (abstract) fully-random hashing was used. For example, this includes classic linear probing, the widely used HyperLogLog algorithm of Flajolet, Fusy, Gandouet, Meunier [AOFA 97] for counting distinct elements, and the one-permutation hashing of Li, Owen, and Zhang [NIPS 12] for large-scale machine learning. We also provide a very efficient solution for the classical problem of obtaining fully-random hashing on a fixed (but unknown to the hash function) set of $n$ keys using $O(n)$ space. As a consequence, we get more efficient implementations of the splitting trick of Dietzfelbinger and Rink [ICALP'09] and the succinct space uniform hashing of Pagh and Pagh [SICOMP'08]. Tornado tabulation hashing is based on a simple method to systematically break dependencies in tabulation-based hashing techniques.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-20.93497085571289, -16.1339111328125]}, {"key": "", "year": "", "title": "Berman2018supermodular", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Supermodular Locality Sensitive Hashes\"\nauthors: Berman Maxim, Blaschko Matthew B.\nconference: Arxiv\nyear: 2018\nbibkey: berman2018supermodular\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1807.06686\"}\ntags: ['ARXIV', 'LSH']\n---\nIn this work, we show deep connections between Locality Sensitive Hashability and submodular analysis. We show that the LSHablility of the most commonly analyzed set similarities is in one-to-one correspondance with the supermodularity of these similarities when taken with respect to the symmetric difference of their arguments. We find that the supermodularity of equivalent LSHable similarities can be dependent on the set encoding. While monotonicity and supermodularity does not imply the metric condition necessary for supermodularity, this condition is guaranteed for the more restricted class of supermodular Hamming similarities that we introduce. We show moreover that LSH preserving transformations are also supermodular-preserving, yielding a way to generate families of similarities both LSHable and supermodular. Finally, we show that even the more restricted family of cardinality-based supermodular Hamming similarities presents promising aspects for the study of the link between LSHability and supermodularity. We hope that the several bridges that we introduce between LSHability and supermodularity paves the way to a better understanding both of supermodular analysis and LSHability, notably in the context of large-scale supermodular optimization.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-2.6783385276794434, -7.2863287925720215]}, {"key": "", "year": "", "title": "Berriche2024leveraging", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Leveraging High-Resolution Features for Improved Deep Hashing-based Image Retrieval\"\nauthors: Berriche Aymene, Zakaria Mehdi Adjal, Baghdadi Riyadh\nconference: Arxiv\nyear: 2024\nbibkey: berriche2024leveraging\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2403.13747\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval']\n---\nDeep hashing techniques have emerged as the predominant approach for efficient image retrieval. Traditionally, these methods utilize pre-trained convolutional neural networks (CNNs) such as AlexNet and VGG-16 as feature extractors. However, the increasing complexity of datasets poses challenges for these backbone architectures in capturing meaningful features essential for effective image retrieval. In this study, we explore the efficacy of employing high-resolution features learned through state-of-the-art techniques for image retrieval tasks. Specifically, we propose a novel methodology that utilizes High-Resolution Networks (HRNets) as the backbone for the deep hashing task, termed High-Resolution Hashing Network (HHNet). Our approach demonstrates superior performance compared to existing methods across all tested benchmark datasets, including CIFAR-10, NUS-WIDE, MS COCO, and ImageNet. This performance improvement is more pronounced for complex datasets, which highlights the need to learn high-resolution features for intricate image retrieval tasks. Furthermore, we conduct a comprehensive analysis of different HRNet configurations and provide insights into the optimal architecture for the deep hashing task\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [7.155587673187256, 24.832876205444336]}, {"key": "", "year": "", "title": "Bessa2023weighted", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Weighted Minwise Hashing Beats Linear Sketching for Inner Product Estimation\"\nauthors: Bessa Aline, Daliri Majid, Freire Juliana, Musco Cameron, Musco Christopher, Santos A\u00e9cio, Zhang Haoxiang\nconference: In Proceedings of the ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems\nyear: 2023\nbibkey: bessa2023weighted\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2301.05811\"}\ntags: []\n---\nWe present a new approach for computing compact sketches that can be used to approximate the inner product between pairs of high-dimensional vectors. Based on the Weighted MinHash algorithm, our approach admits strong accuracy guarantees that improve on the guarantees of popular linear sketching approaches for inner product estimation, such as CountSketch and Johnson-Lindenstrauss projection. Specifically, while our method admits guarantees that exactly match linear sketching for dense vectors, it yields significantly lower error for sparse vectors with limited overlap between non-zero entries. Such vectors arise in many applications involving sparse data. They are also important in increasingly popular dataset search applications, where inner product sketches are used to estimate data covariance, conditional means, and other quantities involving columns in unjoined tables. We complement our theoretical results by showing that our approach empirically outperforms existing linear sketches and unweighted hashing-based sketches for sparse vectors.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [10.274070739746094, -10.739447593688965]}, {"key": "", "year": "", "title": "Bhatia2022exploiting", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Exploiting and Defending Against the Approximate Linearity of Apple's NeuralHash\"\nauthors: Bhatia Jagdeep Singh, Meng Kevin\nconference: Arxiv\nyear: 2022\nbibkey: bhatia2022exploiting\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2207.14258\"}\ntags: ['ARXIV', 'Graph']\n---\nPerceptual hashes map images with identical semantic content to the same $n$-bit hash value, while mapping semantically-different images to different hashes. These algorithms carry important applications in cybersecurity such as copyright infringement detection, content fingerprinting, and surveillance. Apple's NeuralHash is one such system that aims to detect the presence of illegal content on users' devices without compromising consumer privacy. We make the surprising discovery that NeuralHash is approximately linear, which inspires the development of novel black-box attacks that can (i) evade detection of \"illegal\" images, (ii) generate near-collisions, and (iii) leak information about hashed images, all without access to model parameters. These vulnerabilities pose serious threats to NeuralHash's security goals; to address them, we propose a simple fix using classical cryptographic standards.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-31.275192260742188, 4.350188255310059]}, {"key": "", "year": "", "title": "Bhattarai2020diagram", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Diagram Image Retrieval using Sketch-Based Deep Learning and Transfer Learning\"\nauthors: Bhattarai Manish, Oyen Diane, Castorena Juan, Yang Liping, Wohlberg Brendt\nconference: Arxiv\nyear: 2020\nbibkey: bhattarai2020diagram\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2004.10780\"}\ntags: ['ARXIV', 'Deep Learning', 'Image Retrieval']\n---\nResolution of the complex problem of image retrieval for diagram images has yet to be reached. Deep learning methods continue to excel in the fields of object detection and image classification applied to natural imagery. However, the application of such methodologies applied to binary imagery remains limited due to lack of crucial features such as textures,color and intensity information. This paper presents a deep learning based method for image-based search for binary patent images by taking advantage of existing large natural image repositories for image search and sketch-based methods (Sketches are not identical to diagrams, but they do share some characteristics; for example, both imagery types are gray scale (binary), composed of contours, and are lacking in texture). We begin by using deep learning to generate sketches from natural images for image retrieval and then train a second deep learning model on the sketches. We then use our small set of manually labeled patent diagram images via transfer learning to adapt the image search from sketches of natural images to diagrams. Our experiment results show the effectiveness of deep learning with transfer learning for detecting near-identical copies in patent images and querying similar images based on content.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [6.920866012573242, 19.019929885864258]}, {"key": "", "year": "", "title": "Bhunia2018a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Novel Feature Descriptor for Image Retrieval by Combining Modified Color Histogram and Diagonally Symmetric Co-occurrence Texture Pattern\"\nauthors: Bhunia Ayan Kumar, Bhattacharyya Avirup, Banerjee Prithaj, Roy Partha Pratim, Murala Subrahmanyam\nconference: Arxiv\nyear: 2018\nbibkey: bhunia2018a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1801.00879\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nIn this paper, we have proposed a novel feature descriptors combining color and texture information collectively. In our proposed color descriptor component, the inter-channel relationship between Hue (H) and Saturation (S) channels in the HSV color space has been explored which was not done earlier. We have quantized the H channel into a number of bins and performed the voting with saturation values and vice versa by following a principle similar to that of the HOG descriptor, where orientation of the gradient is quantized into a certain number of bins and voting is done with gradient magnitude. This helps us to study the nature of variation of saturation with variation in Hue and nature of variation of Hue with the variation in saturation. The texture component of our descriptor considers the co-occurrence relationship between the pixels symmetric about both the diagonals of a 3x3 window. Our work is inspired from the work done by Dubey et al.[1]. These two components, viz. color and texture information individually perform better than existing texture and color descriptors. Moreover, when concatenated the proposed descriptors provide significant improvement over existing descriptors for content base color image retrieval. The proposed descriptor has been tested for image retrieval on five databases, including texture image databases - MIT VisTex database and Salzburg texture database and natural scene databases Corel 1K, Corel 5K and Corel 10K. The precision and recall values experimented on these databases are compared with some state-of-art local patterns. The proposed method provided satisfactory results from the experiments.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [22.06403923034668, 21.996044158935547]}, {"key": "", "year": "", "title": "Bhunia2018texture", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Texture Synthesis Guided Deep Hashing for Texture Image Retrieval\"\nauthors: Bhunia Ayan Kumar, Kishore Perla Sai Raj, Mukherjee Pranay, Das Abhirup, Roy Partha Pratim\nconference: Arxiv\nyear: 2018\nbibkey: bhunia2018texture\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1811.01401\"}\ntags: ['ARXIV', 'Deep Learning', 'Image Retrieval']\n---\nWith the large-scale explosion of images and videos over the internet, efficient hashing methods have been developed to facilitate memory and time efficient retrieval of similar images. However, none of the existing works uses hashing to address texture image retrieval mostly because of the lack of sufficiently large texture image databases. Our work addresses this problem by developing a novel deep learning architecture that generates binary hash codes for input texture images. For this, we first pre-train a Texture Synthesis Network (TSN) which takes a texture patch as input and outputs an enlarged view of the texture by injecting newer texture content. Thus it signifies that the TSN encodes the learnt texture specific information in its intermediate layers. In the next stage, a second network gathers the multi-scale feature representations from the TSN's intermediate layers using channel-wise attention, combines them in a progressive manner to a dense continuous representation which is finally converted into a binary hash code with the help of individual and pairwise label information. The new enlarged texture patches also help in data augmentation to alleviate the problem of insufficient texture data and are used to train the second stage of the network. Experiments on three public texture image retrieval datasets indicate the superiority of our texture synthesis guided hashing approach over current state-of-the-art methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-7.042718410491943, 6.452234268188477]}, {"key": "", "year": "", "title": "Bhute2014content", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Content Based Image Indexing and Retrieval\"\nauthors: Bhute Avinash N, Meshram B. B.\nconference: IJGIP\nyear: 2014\nbibkey: bhute2014content\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1401.1742\"}\ntags: ['Image Retrieval', 'TIP', 'TOM']\n---\nIn this paper, we present the efficient content based image retrieval systems which employ the color, texture and shape information of images to facilitate the retrieval process. For efficient feature extraction, we extract the color, texture and shape feature of images automatically using edge detection which is widely used in signal processing and image compression. For facilitated the speedy retrieval we are implements the antipole-tree algorithm for indexing the images.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [26.110595703125, 9.437859535217285]}, {"key": "", "year": "", "title": "Bibak2020mmh", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"MMH* with arbitrary modulus is always almost-universal\"\nauthors: Bibak Khodakhast, Kapron Bruce M., Srinivasan Venkatesh\nconference: Information Processing Letters\nyear: 2020\nbibkey: bibak2020mmh\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2010.05420\"}\ntags: []\n---\nUniversal hash functions, discovered by Carter and Wegman in 1979, are of great importance in computer science with many applications. MMH$^*$ is a well-known $\\triangle$-universal hash function family, based on the evaluation of a dot product modulo a prime. In this paper, we introduce a generalization of MMH$^*$, that we call GMMH$^*$, using the same construction as MMH$^*$ but with an arbitrary integer modulus $n&gt;1$, and show that GMMH$^*$ is $\\frac\\{1\\}\\{p\\}$-almost-$\\triangle$-universal, where $p$ is the smallest prime divisor of $n$. This bound is tight.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-27.039127349853516, -16.908395767211914]}, {"key": "", "year": "", "title": "Bingmann2019cobs", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"COBS: a Compact Bit-Sliced Signature Index\"\nauthors: Bingmann Timo, Bradley Phelim, Gauger Florian, Iqbal Zamin\nconference: Arxiv\nyear: 2019\nbibkey: bingmann2019cobs\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1905.09624\"}\ntags: ['ARXIV']\n---\nWe present COBS, a COmpact Bit-sliced Signature index, which is a cross-over between an inverted index and Bloom filters. Our target application is to index $k$-mers of DNA samples or $q$-grams from text documents and process approximate pattern matching queries on the corpus with a user-chosen coverage threshold. Query results may contain a number of false positives which decreases exponentially with the query length. We compare COBS to seven other index software packages on 100000 microbial DNA samples. COBS' compact but simple data structure outperforms the other indexes in construction time and query performance with Mantis by Pandey et al. in second place. However, unlike Mantis and other previous work, COBS does not need the complete index in RAM and is thus designed to scale to larger document sets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [21.833940505981445, -17.29062843322754]}, {"key": "", "year": "", "title": "Biswas2020perceptual", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Perceptual Hashing applied to Tor domains recognition\"\nauthors: Biswas Rubel, Vasco-Carofilis Roberto A., Fernandez Eduardo Fidalgo, Martino Francisco J\u00e1\u00f1ez, Medina Pablo Blanco\nconference: Arxiv\nyear: 2020\nbibkey: biswas2020perceptual\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2005.10090\"}\ntags: ['ARXIV', 'TOM']\n---\nThe Tor darknet hosts different types of illegal content, which are monitored by cybersecurity agencies. However, manually classifying Tor content can be slow and error-prone. To support this task, we introduce Frequency-Dominant Neighborhood Structure (F-DNS), a new perceptual hashing method for automatically classifying domains by their screenshots. First, we evaluated F-DNS using images subject to various content preserving operations. We compared them with their original images, achieving better correlation coefficients than other state-of-the-art methods, especially in the case of rotation. Then, we applied F-DNS to categorize Tor domains using the Darknet Usage Service Images-2K (DUSI-2K), a dataset with screenshots of active Tor service domains. Finally, we measured the performance of F-DNS against an image classification approach and a state-of-the-art hashing method. Our proposal obtained 98.75% accuracy in Tor images, surpassing all other methods compared.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-31.540180206298828, 8.057682991027832]}, {"key": "", "year": "", "title": "Biswas2021state", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"State of the Art: Image Hashing\"\nauthors: Biswas Rubel, Blanco-Medina Pablo\nconference: Arxiv\nyear: 2021\nbibkey: biswas2021state\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2108.11794\"}\ntags: ['ARXIV', 'Deep Learning', 'Image Retrieval', 'Survey Paper']\n---\nPerceptual image hashing methods are often applied in various objectives, such as image retrieval, finding duplicate or near-duplicate images, and finding similar images from large-scale image content. The main challenge in image hashing techniques is robust feature extraction, which generates the same or similar hashes in images that are visually identical. In this article, we present a short review of the state-of-the-art traditional perceptual hashing and deep learning-based perceptual hashing methods, identifying the best approaches.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [18.7130069732666, 12.094776153564453]}, {"key": "", "year": "", "title": "Black2021compositional", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Compositional Sketch Search\"\nauthors: Black Alexander, Bui Tu, Mai Long, Jin Hailin, Collomosse John\nconference: Arxiv\nyear: 2021\nbibkey: black2021compositional\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2106.08009\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval', 'Quantisation', 'TIP']\n---\nWe present an algorithm for searching image collections using free-hand sketches that describe the appearance and relative positions of multiple objects. Sketch based image retrieval (SBIR) methods predominantly match queries containing a single, dominant object invariant to its position within an image. Our work exploits drawings as a concise and intuitive representation for specifying entire scene compositions. We train a convolutional neural network (CNN) to encode masked visual features from sketched objects, pooling these into a spatial descriptor encoding the spatial relationships and appearances of objects in the composition. Training the CNN backbone as a Siamese network under triplet loss yields a metric search embedding for measuring compositional similarity which may be efficiently leveraged for visual search by applying product quantization.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [26.215009689331055, 5.24493408203125]}, {"key": "", "year": "", "title": "Blumenstiel2024multi", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Multi-Spectral Remote Sensing Image Retrieval Using Geospatial Foundation Models\"\nauthors: Blumenstiel Benedikt, Moor Viktoria, Kienzler Romeo, Brunschwiler Thomas\nconference: Arxiv\nyear: 2024\nbibkey: blumenstiel2024multi\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2403.02059\"}   - {name: \"Code\", url: \"https://github.com/IBM/remote-sensing-image-retrieval.\"}\ntags: ['ARXIV', 'Deep Learning', 'Image Retrieval', 'TIP']\n---\nImage retrieval enables an efficient search through vast amounts of satellite imagery and returns similar images to a query. Deep learning models can identify images across various semantic concepts without the need for annotations. This work proposes to use Geospatial Foundation Models, like Prithvi, for remote sensing image retrieval with multiple benefits: i) the models encode multi-spectral satellite data and ii) generalize without further fine-tuning. We introduce two datasets to the retrieval task and observe a strong performance: Prithvi processes six bands and achieves a mean Average Precision of 97.62% on BigEarthNet-43 and 44.51% on ForestNet-12, outperforming other RGB-based models. Further, we evaluate three compression methods with binarized embeddings balancing retrieval speed and accuracy. They match the retrieval speed of much shorter hash codes while maintaining the same accuracy as floating-point embeddings but with a 32-fold compression. The code is available at https://github.com/IBM/remote-sensing-image-retrieval.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [7.391443252563477, 8.804533004760742]}, {"key": "", "year": "", "title": "Bolettieri2009cophir", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"CoPhIR: a Test Collection for Content-Based Image Retrieval\"\nauthors: Bolettieri Paolo, Esuli Andrea, Falchi Fabrizio, Lucchese Claudio, Perego Raffaele, Piccioli Tommaso, Rabitti Fausto\nconference: Arxiv\nyear: 2009\nbibkey: bolettieri2009cophir\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/0905.4627\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nThe scalability, as well as the effectiveness, of the different Content-based Image Retrieval (CBIR) approaches proposed in literature, is today an important research issue. Given the wealth of images on the Web, CBIR systems must in fact leap towards Web-scale datasets. In this paper, we report on our experience in building a test collection of 100 million images, with the corresponding descriptive features, to be used in experimenting new scalable techniques for similarity searching, and comparing their results. In the context of the SAPIR (Search on Audio-visual content using Peer-to-peer Information Retrieval) European project, we had to experiment our distributed similarity searching technology on a realistic data set. Therefore, since no large-scale collection was available for research purposes, we had to tackle the non-trivial process of image crawling and descriptive feature extraction (we used five MPEG-7 features) using the European EGEE computer GRID. The result of this effort is CoPhIR, the first CBIR test collection of such scale. CoPhIR is now open to the research community for experiments and comparisons, and access to the collection was already granted to more than 50 research groups worldwide.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [10.409064292907715, 8.31375503540039]}, {"key": "", "year": "", "title": "Bondugula2015shoe", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"SHOE: Supervised Hashing with Output Embeddings\"\nauthors: Bondugula Sravanthi, Manjunatha Varun, Davis Larry S., Doermann David\nconference: Arxiv\nyear: 2015\nbibkey: bondugula2015shoe\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1502.00030\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval', 'Supervised']\n---\nWe present a supervised binary encoding scheme for image retrieval that learns projections by taking into account similarity between classes obtained from output embeddings. Our motivation is that binary hash codes learned in this way improve both the visual quality of retrieval results and existing supervised hashing schemes. We employ a sequential greedy optimization that learns relationship aware projections by minimizing the difference between inner products of binary codes and output embedding vectors. We develop a joint optimization framework to learn projections which improve the accuracy of supervised hashing over the current state of the art with respect to standard and sibling evaluation metrics. We further boost performance by applying the supervised dimensionality reduction technique on kernelized input CNN features. Experiments are performed on three datasets: CUB-2011, SUN-Attribute and ImageNet ILSVRC 2010. As a by-product of our method, we show that using a simple k-nn pooling classifier with our discriminative codes improves over the complex classification models on fine grained datasets like CUB and offer an impressive compression ratio of 1024 on CNN features.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [6.805963039398193, 1.5902128219604492]}, {"key": "", "year": "", "title": "Bose2011improving", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Improving Anonymity in Shared Key Primitives Based on Perfect Hash Families\"\nauthors: Bose Mausumi, Mukerjee Rahul\nconference: Arxiv\nyear: 2011\nbibkey: bose2011improving\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1105.5681\"}\ntags: ['ARXIV', 'ICIP']\n---\nWe propose a new scheme for sharing symmetric key operations among a set of participants according to a (t,n) threshold access structure. We focus on anonymity properties of this scheme and show that this scheme provides improved values of anonymity measures than the existing ones. In particular, the scheme can provide optimal and equitable participant anonymity when it is based on balanced perfect hash families.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-29.875133514404297, 1.4765639305114746]}, {"key": "", "year": "", "title": "Bose2015a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Hybrid Approach for Improved Content-based Image Retrieval using Segmentation\"\nauthors: Bose Smarajit, Pal Amita, Mallick Jhimli, Kumar Sunil, Rudra Pratyaydipta\nconference: Arxiv\nyear: 2015\nbibkey: bose2015a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1502.03215\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nThe objective of Content-Based Image Retrieval (CBIR) methods is essentially to extract, from large (image) databases, a specified number of images similar in visual and semantic content to a so-called query image. To bridge the semantic gap that exists between the representation of an image by low-level features (namely, colour, shape, texture) and its high-level semantic content as perceived by humans, CBIR systems typically make use of the relevance feedback (RF) mechanism. RF iteratively incorporates user-given inputs regarding the relevance of retrieved images, to improve retrieval efficiency. One approach is to vary the weights of the features dynamically via feature reweighting. In this work, an attempt has been made to improve retrieval accuracy by enhancing a CBIR system based on color features alone, through implicit incorporation of shape information obtained through prior segmentation of the images. Novel schemes for feature reweighting as well as for initialization of the relevant set for improved relevance feedback, have also been proposed for boosting performance of RF- based CBIR. At the same time, new measures for evaluation of retrieval accuracy have been suggested, to overcome the limitations of existing measures in the RF context. Results of extensive experiments have been presented to illustrate the effectiveness of the proposed approaches.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [21.894027709960938, 11.699735641479492]}, {"key": "", "year": "", "title": "Bostanci2015is", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Is Hamming distance the only way for matching binary image feature descriptors\"\nauthors: Bostanci Erkan\nconference: Electronics Letters\nyear: 2015\nbibkey: bostanci2015is\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1512.02355\"}\ntags: ['Graph']\n---\nBrute force matching of binary image feature descriptors is conventionally performed using the Hamming distance. This paper assesses the use of alternative metrics in order to see whether they can produce feature correspondences that yield more accurate homography matrices. Two statistical tests, namely ANOVA (Analysis of Variance) and McNemar's test were employed for evaluation. Results show that Jackard-Needham and Dice metrics can display better performance for some descriptors. Yet, these performance differences were not found to be statistically significant.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [9.619141578674316, -2.919924736022949]}, {"key": "", "year": "", "title": "Botelho2007perfect", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Perfect Hashing for Data Management Applications\"\nauthors: Botelho Fabiano C., Pagh Rasmus, Ziviani Nivio\nconference: Arxiv\nyear: 2007\nbibkey: botelho2007perfect\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/cs/0702159\"}\ntags: ['ARXIV']\n---\nPerfect hash functions can potentially be used to compress data in connection with a variety of data management tasks. Though there has been considerable work on how to construct good perfect hash functions, there is a gap between theory and practice among all previous methods on minimal perfect hashing. On one side, there are good theoretical results without experimentally proven practicality for large key sets. On the other side, there are the theoretically analyzed time and space usage algorithms that assume that truly random hash functions are available for free, which is an unrealistic assumption. In this paper we attempt to bridge this gap between theory and practice, using a number of techniques from the literature to obtain a novel scheme that is theoretically well-understood and at the same time achieves an order-of-magnitude increase in performance compared to previous ``practical'' methods. This improvement comes from a combination of a novel, theoretically optimal perfect hashing scheme that greatly simplifies previous methods, and the fact that our algorithm is designed to make good use of the memory hierarchy. We demonstrate the scalability of our algorithm by considering a set of over one billion URLs from the World Wide Web of average length 64, for which we construct a minimal perfect hash function on a commodity PC in a little more than 1 hour. Our scheme produces minimal perfect hash functions using slightly more than 3 bits per key. For perfect hash functions in the range $\\\\{0,...,2n-1\\\\}$ the space usage drops to just over 2 bits per key (i.e., one bit more than optimal for representing the key). This is significantly below of what has been achieved previously for very large values of $n$.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-20.05433464050293, -14.792914390563965]}, {"key": "", "year": "", "title": "Boucher2015relative", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Relative Select\"\nauthors: Boucher Christina, Bowe Alexander, Gagie Travis, Manzini Giovanni, Sir\u00e9n Jouni\nconference: Arxiv\nyear: 2015\nbibkey: boucher2015relative\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1506.03262\"}\ntags: ['ARXIV', 'Graph']\n---\nMotivated by the problem of storing coloured de Bruijn graphs, we show how, if we can already support fast select queries on one string, then we can store a little extra information and support fairly fast select queries on a similar string.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [33.789451599121094, 3.6960668563842773]}, {"key": "", "year": "", "title": "Boytsov2019accurate", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Accurate and Fast Retrieval for Complex Non-metric Data via Neighborhood Graphs\"\nauthors: Boytsov Leonid, Nyberg Eric\nconference: Arxiv\nyear: 2019\nbibkey: boytsov2019accurate\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1910.03534\"}\ntags: ['ARXIV', 'Graph']\n---\nWe demonstrate that a graph-based search algorithm-relying on the construction of an approximate neighborhood graph-can directly work with challenging non-metric and/or non-symmetric distances without resorting to metric-space mapping and/or distance symmetrization, which, in turn, lead to substantial performance degradation. Although the straightforward metrization and symmetrization is usually ineffective, we find that constructing an index using a modified, e.g., symmetrized, distance can improve performance. This observation paves a way to a new line of research of designing index-specific graph-construction distance functions.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [8.833106994628906, -27.404325485229492]}, {"key": "", "year": "", "title": "Breznik2022cross", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Cross-Modality Sub-Image Retrieval using Contrastive Multimodal Image Representations\"\nauthors: Breznik Eva, Wetzer Elisabeth, Lindblad Joakim, Sladoje Nata\u0161a\nconference: Arxiv\nyear: 2022\nbibkey: breznik2022cross\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2201.03597\"}   - {name: \"Code\", url: \"https://github.com/MIDA-group/CrossModal_ImgRetrieval}.\"}\ntags: ['ARXIV', 'Cross Modal', 'Deep Learning', 'Image Retrieval']\n---\nIn tissue characterization and cancer diagnostics, multimodal imaging has emerged as a powerful technique. Thanks to computational advances, large datasets can be exploited to discover patterns in pathologies and improve diagnosis. However, this requires efficient and scalable image retrieval methods. Cross-modality image retrieval is particularly challenging, since images of similar (or even the same) content captured by different modalities might share few common structures. We propose a new application-independent content-based image retrieval (CBIR) system for reverse (sub-)image search across modalities, which combines deep learning to generate representations (embedding the different modalities in a common space) with classical feature extraction and bag-of-words models for efficient and reliable retrieval. We illustrate its advantages through a replacement study, exploring a number of feature extractors and learned representations, as well as through comparison to recent (cross-modality) CBIR methods. For the task of (sub-)image retrieval on a (publicly available) dataset of brightfield and second harmonic generation microscopy images, the results show that our approach is superior to all tested alternatives. We discuss the shortcomings of the compared methods and observe the importance of equivariance and invariance properties of the learned representations and feature extractors in the CBIR pipeline. Code is available at: \\url{https://github.com/MIDA-group/CrossModal_ImgRetrieval}.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.979957580566406, 10.50667667388916]}, {"key": "", "year": "", "title": "Brisaboa2011compressed", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Compressed String Dictionaries\"\nauthors: Brisaboa Nieves R., C\u00e1novas Rodrigo, Mart\u00ednez-Prieto Miguel A., Navarro Gonzalo\nconference: Arxiv\nyear: 2011\nbibkey: brisaboa2011compressed\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1101.5506\"}\ntags: ['ARXIV', 'Graph']\n---\nThe problem of storing a set of strings --- a string dictionary --- in compact form appears naturally in many cases. While classically it has represented a small part of the whole data to be processed (e.g., for Natural Language processing or for indexing text collections), more recent applications in Web engines, Web mining, RDF graphs, Internet routing, Bioinformatics, and many others, make use of very large string dictionaries, whose size is a significant fraction of the whole data. Thus novel approaches to compress them efficiently are necessary. In this paper we experimentally compare time and space performance of some existing alternatives, as well as new ones we propose. We show that space reductions of up to 20% of the original size of the strings is possible while supporting fast dictionary searches.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-1.678162932395935, -12.651300430297852]}, {"key": "", "year": "", "title": "Brisaboa2020revisiting", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Revisiting compact RDF stores based on k2-trees\"\nauthors: Brisaboa Nieves R., Cerdeira-Pena Ana, de Bernardo Guillermo, Fari\u00f1a Antonio\nconference: Arxiv\nyear: 2020\nbibkey: brisaboa2020revisiting\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2002.11622\"}\ntags: ['ARXIV']\n---\nWe present a new compact representation to efficiently store and query large RDF datasets in main memory. Our proposal, called BMatrix, is based on the k2-tree, a data structure devised to represent binary matrices in a compressed way, and aims at improving the results of previous state-of-the-art alternatives, especially in datasets with a relatively large number of predicates. We introduce our technique, together with some improvements on the basic k2-tree that can be applied to our solution in order to boost compression. Experimental results in the flagship RDF dataset DBPedia show that our proposal achieves better compression than existing alternatives, while yielding competitive query times, particularly in the most frequent triple patterns and in queries with unbound predicate, in which we outperform existing solutions.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.613807678222656, -5.6056108474731445]}, {"key": "", "year": "", "title": "Brogan2017spotting", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Spotting the Difference: Context Retrieval and Analysis for Improved Forgery Detection and Localization\"\nauthors: Brogan Joel, Bestagini Paolo, Bharati Aparna, Pinto Allan, Moreira Daniel, Bowyer Kevin, Flynn Patrick, Rocha Anderson, Scheirer Walter\nconference: Arxiv\nyear: 2017\nbibkey: brogan2017spotting\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1705.00604\"}   - {name: \"Paper\", url: \"https://www.nist.gov/itl/iad/mig/nimble-challenge],\"}\ntags: ['ARXIV', 'Text Retrieval']\n---\nAs image tampering becomes ever more sophisticated and commonplace, the need for image forensics algorithms that can accurately and quickly detect forgeries grows. In this paper, we revisit the ideas of image querying and retrieval to provide clues to better localize forgeries. We propose a method to perform large-scale image forensics on the order of one million images using the help of an image search algorithm and database to gather contextual clues as to where tampering may have taken place. In this vein, we introduce five new strongly invariant image comparison methods and test their effectiveness under heavy noise, rotation, and color space changes. Lastly, we show the effectiveness of these methods compared to passive image forensics using Nimble [https://www.nist.gov/itl/iad/mig/nimble-challenge], a new, state-of-the-art dataset from the National Institute of Standards and Technology (NIST).\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [23.169208526611328, 3.284336566925049]}, {"key": "", "year": "", "title": "Bronstein2011kernel", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Kernel diff-hash\"\nauthors: Bronstein Michael M\nconference: Arxiv\nyear: 2011\nbibkey: bronstein2011kernel\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1111.0466\"}\ntags: ['ARXIV']\n---\nThis paper presents a kernel formulation of the recently introduced diff-hash algorithm for the construction of similarity-sensitive hash functions. Our kernel diff-hash algorithm that shows superior performance on the problem of image feature descriptor matching.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [3.9163453578948975, -1.1183229684829712]}, {"key": "", "year": "", "title": "Bronstein2011multimodal", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Multimodal diff-hash\"\nauthors: Bronstein Michael M.\nconference: Arxiv\nyear: 2011\nbibkey: bronstein2011multimodal\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1111.1461\"}\ntags: ['ARXIV']\n---\nMany applications require comparing multimodal data with different structure and dimensionality that cannot be compared directly. Recently, there has been increasing interest in methods for learning and efficiently representing such multimodal similarity. In this paper, we present a simple algorithm for multimodal similarity-preserving hashing, trying to map multimodal data into the Hamming space while preserving the intra- and inter-modal similarities. We show that our method significantly outperforms the state-of-the-art method in the field.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [1.9146450757980347, -10.607149124145508]}, {"key": "", "year": "", "title": "Brooks2017multi", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Multi-Level Spherical Locality Sensitive Hashing For Approximate Near Neighbors\"\nauthors: Brooks Teresa Nicole, Almajalid Rania\nconference: Arxiv\nyear: 2017\nbibkey: brooks2017multi\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1709.03517\"}\ntags: ['ARXIV', 'LSH']\n---\nThis paper introduces \"Multi-Level Spherical LSH\": parameter-free, a multi-level, data-dependant Locality Sensitive Hashing data structure for solving the Approximate Near Neighbors Problem (ANN). This data structure uses a modified version of a multi-probe adaptive querying algorithm, with the potential of achieving a $O(n^p + t)$ query run time, for all inputs n where $t &lt;= n$.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [10.733562469482422, -16.35667610168457]}, {"key": "", "year": "", "title": "Bu2014image", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Image retrieval with hierarchical matching pursuit\"\nauthors: Bu Shasha, Zhang Yu-Jin\nconference: Arxiv\nyear: 2014\nbibkey: bu2014image\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1406.0588\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nA novel representation of images for image retrieval is introduced in this paper, by using a new type of feature with remarkable discriminative power. Despite the multi-scale nature of objects, most existing models perform feature extraction on a fixed scale, which will inevitably degrade the performance of the whole system. Motivated by this, we introduce a hierarchical sparse coding architecture for image retrieval to explore multi-scale cues. Sparse codes extracted on lower layers are transmitted to higher layers recursively. With this mechanism, cues from different scales are fused. Experiments on the Holidays dataset show that the proposed method achieves an excellent retrieval performance with a small code length.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [17.283735275268555, 20.319103240966797]}, {"key": "", "year": "", "title": "Budikova2012query", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Query Language for Complex Similarity Queries\"\nauthors: Budikova Petra, Batko Michal, Zezula Pavel\nconference: Arxiv\nyear: 2012\nbibkey: budikova2012query\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1204.1185\"}\ntags: ['ARXIV']\n---\nFor complex data types such as multimedia, traditional data management methods are not suitable. Instead of attribute matching approaches, access methods based on object similarity are becoming popular. Recently, this resulted in an intensive research of indexing and searching methods for the similarity-based retrieval. Nowadays, many efficient methods are already available, but using them to build an actual search system still requires specialists that tune the methods and build the system manually. Several attempts have already been made to provide a more convenient high-level interface in a form of query languages for such systems, but these are limited to support only basic similarity queries. In this paper, we propose a new language that allows to formulate content-based queries in a flexible way, taking into account the functionality offered by a particular search engine in use. To ensure this, the language is based on a general data model with an abstract set of operations. Consequently, the language supports various advanced query operations such as similarity joins, reverse nearest neighbor queries, or distinct kNN queries, as well as multi-object and multi-modal queries. The language is primarily designed to be used with the MESSIF framework for content-based searching but can be employed by other retrieval systems as well.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [0.8197497129440308, -18.67474937438965]}, {"key": "", "year": "", "title": "Budikova2014disa", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"DISA at ImageCLEF 2014 Revised: Search-based Image Annotation with DeCAF Features\"\nauthors: Budikova Petra, Botorek Jan, Batko Michal, Zezula Pavel\nconference: Arxiv\nyear: 2014\nbibkey: budikova2014disa\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1409.4627\"}\ntags: ['ARXIV', 'ICIP']\n---\nThis paper constitutes an extension to the report on DISA-MU team participation in the ImageCLEF 2014 Scalable Concept Image Annotation Task as published in [3]. Specifically, we introduce a new similarity search component that was implemented into the system, report on the results achieved by utilizing this component, and analyze the influence of different similarity search parameters on the annotation quality.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [32.17695617675781, 4.714867115020752]}, {"key": "", "year": "", "title": "Bui2016generalisation", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Generalisation and Sharing in Triplet Convnets for Sketch based Visual Search\"\nauthors: Bui Tu, Ribeiro Leonardo, Ponti Moacir, Collomosse John\nconference: Computers &amp; Graphics, vol\nyear: 2016\nbibkey: bui2016generalisation\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1611.05301\"}\ntags: ['CNN', 'Graph', 'Image Retrieval']\n---\nWe propose and evaluate several triplet CNN architectures for measuring the similarity between sketches and photographs, within the context of the sketch based image retrieval (SBIR) task. In contrast to recent fine-grained SBIR work, we study the ability of our networks to generalise across diverse object categories from limited training data, and explore in detail strategies for weight sharing, pre-processing, data augmentation and dimensionality reduction. We exceed the performance of pre-existing techniques on both the Flickr15k category level SBIR benchmark by $18\\%$, and the TU-Berlin SBIR benchmark by $\\sim10 \\mathcal\\{T\\}_b$, when trained on the 250 category TU-Berlin classification dataset augmented with 25k corresponding photographs harvested from the Internet.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [16.75359535217285, 29.637971878051758]}, {"key": "", "year": "", "title": "Burlacu2021hash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hash-Based Tree Similarity and Simplification in Genetic Programming for Symbolic Regression\"\nauthors: Burlacu Bogdan, Kammerer Lukas, Affenzeller Michael, Kronberger Gabriel\nconference: In: Moreno-D\\'iaz R. et al. Computer Aided Systems Theory. Lecture Notes in Computer Science, Vol.\nyear: 2021\nbibkey: burlacu2021hash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2107.10640\"}\ntags: []\n---\nWe introduce in this paper a runtime-efficient tree hashing algorithm for the identification of isomorphic subtrees, with two important applications in genetic programming for symbolic regression: fast, online calculation of population diversity and algebraic simplification of symbolic expression trees. Based on this hashing approach, we propose a simple diversity-preservation mechanism with promising results on a collection of symbolic regression benchmark problems.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-23.933502197265625, 0.8842957019805908]}, {"key": "", "year": "", "title": "B\u00f6hm2020massively", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Massively Parallel Graph Drawing and Representation Learning\"\nauthors: B\u00f6hm Christian, Plant Claudia\nconference: IEEE BigData\nyear: 2020\nbibkey: b\u00f6hm2020massively\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2011.03479\"}\ntags: ['Graph', 'TIP']\n---\nTo fully exploit the performance potential of modern multi-core processors, machine learning and data mining algorithms for big data must be parallelized in multiple ways. Today's CPUs consist of multiple cores, each following an independent thread of control, and each equipped with multiple arithmetic units which can perform the same operation on a vector of multiple data objects. Graph embedding, i.e. converting the vertices of a graph into numerical vectors is a data mining task of high importance and is useful for graph drawing (low-dimensional vectors) and graph representation learning (high-dimensional vectors). In this paper, we propose MulticoreGEMPE (Graph Embedding by Minimizing the Predictive Entropy), an information-theoretic method which can generate low and high-dimensional vectors. MulticoreGEMPE applies MIMD (Multiple Instructions Multiple Data, using OpenMP) and SIMD (Single Instructions Multiple Data, using AVX-512) parallelism. We propose general ideas applicable in other graph-based algorithms like \\emph{vectorized hashing} and \\emph{vectorized reduction}. Our experimental evaluation demonstrates the superiority of our approach.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [5.036475658416748, -30.003189086914062]}, {"key": "", "year": "", "title": "B\u00f6hm2022unsupervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Unsupervised visualization of image datasets using contrastive learning\"\nauthors: B\u00f6hm Jan Niklas, Berens Philipp, Kobak Dmitry\nconference: ICLR\nyear: 2022\nbibkey: b\u00f6hm2022unsupervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2210.09879\"}\ntags: ['Graph', 'Self Supervised', 'Supervised', 'Unsupervised']\n---\nVisualization methods based on the nearest neighbor graph, such as t-SNE or UMAP, are widely used for visualizing high-dimensional data. Yet, these approaches only produce meaningful results if the nearest neighbors themselves are meaningful. For images represented in pixel space this is not the case, as distances in pixel space are often not capturing our sense of similarity and therefore neighbors are not semantically close. This problem can be circumvented by self-supervised approaches based on contrastive learning, such as SimCLR, relying on data augmentation to generate implicit neighbors, but these methods do not produce two-dimensional embeddings suitable for visualization. Here, we present a new method, called t-SimCNE, for unsupervised visualization of image data. T-SimCNE combines ideas from contrastive learning and neighbor embeddings, and trains a parametric mapping from the high-dimensional pixel space into two dimensions. We show that the resulting 2D embeddings achieve classification accuracy comparable to the state-of-the-art high-dimensional SimCLR representations, thus faithfully capturing semantic relationships. Using t-SimCNE, we obtain informative visualizations of the CIFAR-10 and CIFAR-100 datasets, showing rich cluster structure and highlighting artifacts and outliers.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [10.765629768371582, -29.220500946044922]}, {"key": "", "year": "", "title": "Cai2016a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Revisit of Hashing Algorithms for Approximate Nearest Neighbor Search\"\nauthors: Cai Deng\nconference: Arxiv\nyear: 2016\nbibkey: cai2016a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1612.07545\"}\ntags: ['ARXIV', 'LSH']\n---\nApproximate Nearest Neighbor Search (ANNS) is a fundamental problem in many areas of machine learning and data mining. During the past decade, numerous hashing algorithms are proposed to solve this problem. Every proposed algorithm claims outperform other state-of-the-art hashing methods. However, the evaluation of these hashing papers was not thorough enough, and those claims should be re-examined. The ultimate goal of an ANNS method is returning the most accurate answers (nearest neighbors) in the shortest time. If implemented correctly, almost all the hashing methods will have their performance improved as the code length increases. However, many existing hashing papers only report the performance with the code length shorter than 128. In this paper, we carefully revisit the problem of search with a hash index, and analyze the pros and cons of two popular hash index search procedures. Then we proposed a very simple but effective two level index structures and make a thorough comparison of eleven popular hashing algorithms. Surprisingly, the random-projection-based Locality Sensitive Hashing (LSH) is the best performed algorithm, which is in contradiction to the claims in all the other ten hashing papers. Despite the extreme simplicity of random-projection-based LSH, our results show that the capability of this algorithm has been far underestimated. For the sake of reproducibility, all the codes used in the paper are released on GitHub, which can be used as a testing platform for a fair comparison between various hashing algorithms.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-14.135918617248535, -11.267624855041504]}, {"key": "", "year": "", "title": "Cai2017a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Revisit on Deep Hashings for Large-scale Content Based Image Retrieval\"\nauthors: Cai Deng, Gu Xiuye, Wang Chaoqi\nconference: Arxiv\nyear: 2017\nbibkey: cai2017a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1711.06016\"}\ntags: ['ARXIV', 'Image Retrieval', 'LSH', 'Supervised', 'TIP', 'Unsupervised']\n---\nThere is a growing trend in studying deep hashing methods for content-based image retrieval (CBIR), where hash functions and binary codes are learnt using deep convolutional neural networks and then the binary codes can be used to do approximate nearest neighbor (ANN) search. All the existing deep hashing papers report their methods' superior performance over the traditional hashing methods according to their experimental results. However, there are serious flaws in the evaluations of existing deep hashing papers: (1) The datasets they used are too small and simple to simulate the real CBIR situation. (2) They did not correctly include the search time in their evaluation criteria, while the search time is crucial in real CBIR systems. (3) The performance of some unsupervised hashing algorithms (e.g., LSH) can easily be boosted if one uses multiple hash tables, which is an important factor should be considered in the evaluation while most of the deep hashing papers failed to do so. We re-evaluate several state-of-the-art deep hashing methods with a carefully designed experimental setting. Empirical results reveal that the performance of these deep hashing methods are inferior to multi-table IsoH, a very simple unsupervised hashing method. Thus, the conclusions in all the deep hashing papers should be carefully re-examined.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-9.227537155151367, 3.946329355239868]}, {"key": "", "year": "", "title": "Cakir2015online", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Online Supervised Hashing for Ever-Growing Datasets\"\nauthors: Cakir Fatih, Bargal Sarah Adel, Sclaroff Stan\nconference: Arxiv\nyear: 2015\nbibkey: cakir2015online\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1511.03257\"}\ntags: ['ARXIV', 'Supervised', 'Unsupervised']\n---\nSupervised hashing methods are widely-used for nearest neighbor search in computer vision applications. Most state-of-the-art supervised hashing approaches employ batch-learners. Unfortunately, batch-learning strategies can be inefficient when confronted with large training datasets. Moreover, with batch-learners, it is unclear how to adapt the hash functions as a dataset continues to grow and diversify over time. Yet, in many practical scenarios the dataset grows and diversifies; thus, both the hash functions and the indexing must swiftly accommodate these changes. To address these issues, we propose an online hashing method that is amenable to changes and expansions of the datasets. Since it is an online algorithm, our approach offers linear complexity with the dataset size. Our solution is supervised, in that we incorporate available label information to preserve the semantic neighborhood. Such an adaptive hashing method is attractive; but it requires recomputing the hash table as the hash functions are updated. If the frequency of update is high, then recomputing the hash table entries may cause inefficiencies in the system, especially for large indexes. Thus, we also propose a framework to reduce hash table updates. We compare our method to state-of-the-art solutions on two benchmarks and demonstrate significant improvements over previous work.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-15.64411449432373, -6.874025821685791]}, {"key": "", "year": "", "title": "Cakir2017mihash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"MIHash: Online Hashing with Mutual Information\"\nauthors: Cakir Fatih, He Kun, Bargal Sarah Adel, Sclaroff Stan\nconference: Arxiv\nyear: 2017\nbibkey: cakir2017mihash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1703.08919\"}\ntags: ['ARXIV', 'Image Retrieval', 'Streaming Data']\n---\nLearning-based hashing methods are widely used for nearest neighbor retrieval, and recently, online hashing methods have demonstrated good performance-complexity trade-offs by learning hash functions from streaming data. In this paper, we first address a key challenge for online hashing: the binary codes for indexed data must be recomputed to keep pace with updates to the hash functions. We propose an efficient quality measure for hash functions, based on an information-theoretic quantity, mutual information, and use it successfully as a criterion to eliminate unnecessary hash table updates. Next, we also show how to optimize the mutual information objective using stochastic gradient descent. We thus develop a novel hashing method, MIHash, that can be used in both online and batch settings. Experiments on image retrieval benchmarks (including a 2.5M image dataset) confirm the effectiveness of our formulation, both in reducing hash table recomputations and in learning high-quality hash functions.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-6.247551441192627, 19.204010009765625]}, {"key": "", "year": "", "title": "Cakir2018hashing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hashing with Binary Matrix Pursuit\"\nauthors: Cakir Fatih, He Kun, Sclaroff Stan\nconference: Arxiv\nyear: 2018\nbibkey: cakir2018hashing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1808.01990\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval']\n---\nWe propose theoretical and empirical improvements for two-stage hashing methods. We first provide a theoretical analysis on the quality of the binary codes and show that, under mild assumptions, a residual learning scheme can construct binary codes that fit any neighborhood structure with arbitrary accuracy. Secondly, we show that with high-capacity hash functions such as CNNs, binary code inference can be greatly simplified for many standard neighborhood definitions, yielding smaller optimization problems and more robust codes. Incorporating our findings, we propose a novel two-stage hashing method that significantly outperforms previous hashing studies on widely used image retrieval benchmarks.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [4.456857681274414, 2.228801727294922]}, {"key": "", "year": "", "title": "Cao2014a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Fast String Matching Algorithm Based on Lowlight Characters in the Pattern\"\nauthors: Cao Zhengjun, Liu Lihua\nconference: Arxiv\nyear: 2014\nbibkey: cao2014a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1401.7110\"}\ntags: ['ARXIV']\n---\nWe put forth a new string matching algorithm which matches the pattern from neither the left nor the right end, instead a special position. Comparing with the Knuth-Morris-Pratt algorithm and the Boyer-Moore algorithm, the new algorithm is more flexible to pick the position for starting comparisons. The option really brings it a saving in cost.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [1.0784934759140015, -11.971253395080566]}, {"key": "", "year": "", "title": "Cao2016correlation", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Correlation Hashing Network for Efficient Cross-Modal Retrieval\"\nauthors: Cao Yue, Long Mingsheng, Wang Jianmin, Yu Philip S.\nconference: Arxiv\nyear: 2016\nbibkey: cao2016correlation\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1602.06697\"}\ntags: ['ARXIV', 'Cross Modal', 'Quantisation']\n---\nHashing is widely applied to approximate nearest neighbor search for large-scale multimodal retrieval with storage and computation efficiency. Cross-modal hashing improves the quality of hash coding by exploiting semantic correlations across different modalities. Existing cross-modal hashing methods first transform data into low-dimensional feature vectors, and then generate binary codes by another separate quantization step. However, suboptimal hash codes may be generated since the quantization error is not explicitly minimized and the feature representation is not jointly optimized with the binary codes. This paper presents a Correlation Hashing Network (CHN) approach to cross-modal hashing, which jointly learns good data representation tailored to hash coding and formally controls the quantization error. The proposed CHN is a hybrid deep architecture that constitutes a convolutional neural network for learning good image representations, a multilayer perception for learning good text representations, two hashing layers for generating compact binary codes, and a structured max-margin loss that integrates all things together to enable learning similarity-preserving and high-quality hash codes. Extensive empirical study shows that CHN yields state of the art cross-modal retrieval performance on standard benchmarks.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-4.587935447692871, -3.208416223526001]}, {"key": "", "year": "", "title": "Cao2016transitive", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Transitive Hashing Network for Heterogeneous Multimedia Retrieval\"\nauthors: Cao Zhangjie, Long Mingsheng, Yang Qiang\nconference: Arxiv\nyear: 2016\nbibkey: cao2016transitive\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1608.04307\"}\ntags: ['ARXIV', 'Cross Modal']\n---\nHashing has been widely applied to large-scale multimedia retrieval due to the storage and retrieval efficiency. Cross-modal hashing enables efficient retrieval from database of one modality in response to a query of another modality. Existing work on cross-modal hashing assumes heterogeneous relationship across modalities for hash function learning. In this paper, we relax the strong assumption by only requiring such heterogeneous relationship in an auxiliary dataset different from the query/database domain. We craft a hybrid deep architecture to simultaneously learn the cross-modal correlation from the auxiliary dataset, and align the dataset distributions between the auxiliary dataset and the query/database domain, which generates transitive hash codes for heterogeneous multimedia retrieval. Extensive experiments exhibit that the proposed approach yields state of the art multimedia retrieval performance on public datasets, i.e. NUS-WIDE, ImageNet-YahooQA.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-15.446966171264648, 3.7717859745025635]}, {"key": "", "year": "", "title": "Cao2017hashnet", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"HashNet: Deep Learning to Hash by Continuation\"\nauthors: Cao Zhangjie, Long Mingsheng, Wang Jianmin, Yu Philip S.\nconference: Arxiv\nyear: 2017\nbibkey: cao2017hashnet\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1702.00758\"}\ntags: ['ARXIV', 'Deep Learning']\n---\nLearning to hash has been widely applied to approximate nearest neighbor search for large-scale multimedia retrieval, due to its computation efficiency and retrieval quality. Deep learning to hash, which improves retrieval quality by end-to-end representation learning and hash encoding, has received increasing attention recently. Subject to the ill-posed gradient difficulty in the optimization with sign activations, existing deep learning to hash methods need to first learn continuous representations and then generate binary hash codes in a separated binarization step, which suffer from substantial loss of retrieval quality. This work presents HashNet, a novel deep architecture for deep learning to hash by continuation method with convergence guarantees, which learns exactly binary hash codes from imbalanced similarity data. The key idea is to attack the ill-posed gradient problem in optimizing deep networks with non-smooth binary activations by continuation method, in which we begin from learning an easier network with smoothed activation function and let it evolve during the training, until it eventually goes back to being the original, difficult to optimize, deep network with the sign activation function. Comprehensive empirical evidence shows that HashNet can generate exactly binary hash codes and yield state-of-the-art multimedia retrieval performance on standard benchmarks.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-15.23027515411377, 5.28325080871582]}, {"key": "", "year": "", "title": "Cao2017transfer", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Transfer Adversarial Hashing for Hamming Space Retrieval\"\nauthors: Cao Zhangjie, Long Mingsheng, Huang Chao, Wang Jianmin\nconference: Arxiv\nyear: 2017\nbibkey: cao2017transfer\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1712.04616\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nHashing is widely applied to large-scale image retrieval due to the storage and retrieval efficiency. Existing work on deep hashing assumes that the database in the target domain is identically distributed with the training set in the source domain. This paper relaxes this assumption to a transfer retrieval setting, which allows the database and the training set to come from different but relevant domains. However, the transfer retrieval setting will introduce two technical difficulties: first, the hash model trained on the source domain cannot work well on the target domain due to the large distribution gap; second, the domain gap makes it difficult to concentrate the database points to be within a small Hamming ball. As a consequence, transfer retrieval performance within Hamming Radius 2 degrades significantly in existing hashing methods. This paper presents Transfer Adversarial Hashing (TAH), a new hybrid deep architecture that incorporates a pairwise $t$-distribution cross-entropy loss to learn concentrated hash codes and an adversarial network to align the data distributions between the source and target domains. TAH can generate compact transfer hash codes for efficient image retrieval on both source and target domains. Comprehensive experiments validate that TAH yields state of the art Hamming space retrieval performance on standard datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-0.47846734523773193, 9.425027847290039]}, {"key": "", "year": "", "title": "Cao2018deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Priority Hashing\"\nauthors: Cao Zhangjie, Sun Ziping, Long Mingsheng, Wang Jianmin, Yu Philip S.\nconference: Arxiv\nyear: 2018\nbibkey: cao2018deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1809.01238\"}\ntags: ['ARXIV', 'Image Retrieval', 'Quantisation']\n---\nDeep hashing enables image retrieval by end-to-end learning of deep representations and hash codes from training data with pairwise similarity information. Subject to the distribution skewness underlying the similarity information, most existing deep hashing methods may underperform for imbalanced data due to misspecified loss functions. This paper presents Deep Priority Hashing (DPH), an end-to-end architecture that generates compact and balanced hash codes in a Bayesian learning framework. The main idea is to reshape the standard cross-entropy loss for similarity-preserving learning such that it down-weighs the loss associated to highly-confident pairs. This idea leads to a novel priority cross-entropy loss, which prioritizes the training on uncertain pairs over confident pairs. Also, we propose another priority quantization loss, which prioritizes hard-to-quantize examples for generation of nearly lossless hash codes. Extensive experiments demonstrate that DPH can generate high-quality hash codes and yield state-of-the-art image retrieval results on three datasets, ImageNet, NUS-WIDE, and MS-COCO.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-3.9368650913238525, 13.374464988708496]}, {"key": "", "year": "", "title": "Cao2019enhancing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Enhancing Remote Sensing Image Retrieval with Triplet Deep Metric Learning Network\"\nauthors: Cao Rui, Zhang Qian, Zhu Jiasong, Li Qing, Li Qingquan, Liu Bozhi, Qiu Guoping\nconference: International Journal of Remote Sensing,\nyear: 2019\nbibkey: cao2019enhancing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1902.05818\"}\ntags: ['CNN', 'Image Retrieval', 'Supervised', 'Unsupervised']\n---\nWith the rapid growing of remotely sensed imagery data, there is a high demand for effective and efficient image retrieval tools to manage and exploit such data. In this letter, we present a novel content-based remote sensing image retrieval method based on Triplet deep metric learning convolutional neural network (CNN). By constructing a Triplet network with metric learning objective function, we extract the representative features of the images in a semantic space in which images from the same class are close to each other while those from different classes are far apart. In such a semantic space, simple metric measures such as Euclidean distance can be used directly to compare the similarity of images and effectively retrieve images of the same class. We also investigate a supervised and an unsupervised learning methods for reducing the dimensionality of the learned semantic features. We present comprehensive experimental results on two publicly available remote sensing image retrieval datasets and show that our method significantly outperforms state-of-the-art.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [9.270155906677246, 24.749330520629883]}, {"key": "", "year": "", "title": "Cao2023efficient", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Efficient Image-Text Retrieval via Keyword-Guided Pre-Screening\"\nauthors: Cao Min, Bai Yang, Wang Jingyao, Cao Ziqiang, Nie Liqiang, Zhang Min\nconference: Arxiv\nyear: 2023\nbibkey: cao2023efficient\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2303.07740\"}\ntags: ['ARXIV', 'Cross Modal', 'Text Retrieval']\n---\nUnder the flourishing development in performance, current image-text retrieval methods suffer from $N$-related time complexity, which hinders their application in practice. Targeting at efficiency improvement, this paper presents a simple and effective keyword-guided pre-screening framework for the image-text retrieval. Specifically, we convert the image and text data into the keywords and perform the keyword matching across modalities to exclude a large number of irrelevant gallery samples prior to the retrieval network. For the keyword prediction, we transfer it into a multi-label classification problem and propose a multi-task learning scheme by appending the multi-label classifiers to the image-text retrieval network to achieve a lightweight and high-performance keyword prediction. For the keyword matching, we introduce the inverted index in the search engine and create a win-win situation on both time and space complexities for the pre-screening. Extensive experiments on two widely-used datasets, i.e., Flickr30K and MS-COCO, verify the effectiveness of the proposed framework. The proposed framework equipped with only two embedding layers achieves $O(1)$ querying time complexity, while improving the retrieval efficiency and keeping its performance, when applied prior to the common image-text retrieval methods. Our code will be released.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.598078727722168, 14.803812980651855]}, {"key": "", "year": "", "title": "Capelis2005data", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Data Tastes Better Seasoned: Introducing the ASH Family of Hashing Algorithms\"\nauthors: Capelis D. J.\nconference: Arxiv\nyear: 2005\nbibkey: capelis2005data\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/cs/0501038\"}\ntags: ['ARXIV', 'Graph']\n---\nOver the recent months it has become clear that the current generation of cryptographic hashing algorithms are insufficient to meet future needs. The ASH family of algorithms provides modifications to the existing SHA-2 family. These modifications are designed with two main goals: 1) Providing increased collision resistance. 2) Increasing mitigation of security risks post-collision. The unique public/private sections and salt/pepper design elements provide increased flexibility for a broad range of applications. The ASH family is a new generation of cryptographic hashing algorithms.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-25.94015121459961, 3.473095417022705]}, {"key": "", "year": "", "title": "Carreiraperpi\u00f1\u00e1n2015hashing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hashing with binary autoencoders\"\nauthors: Carreira-Perpi\u00f1\u00e1n Miguel \u00c1., Raziperchikolaei Ramin\nconference: Arxiv\nyear: 2015\nbibkey: carreiraperpi\u00f1\u00e1n2015hashing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1501.00756\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nAn attractive approach for fast search in image databases is binary hashing, where each high-dimensional, real-valued image is mapped onto a low-dimensional, binary vector and the search is done in this binary space. Finding the optimal hash function is difficult because it involves binary constraints, and most approaches approximate the optimization by relaxing the constraints and then binarizing the result. Here, we focus on the binary autoencoder model, which seeks to reconstruct an image from the binary code produced by the hash function. We show that the optimization can be simplified with the method of auxiliary coordinates. This reformulates the optimization as alternating two easier steps: one that learns the encoder and decoder separately, and one that optimizes the code for each image. Image retrieval experiments, using precision/recall and a measure of code utilization, show the resulting hash function outperforms or is competitive with state-of-the-art methods for binary hashing.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [5.229055881500244, 0.822712779045105]}, {"key": "", "year": "", "title": "Carreiraperpi\u00f1\u00e1n2016an", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"An ensemble diversity approach to supervised binary hashing\"\nauthors: Carreira-Perpi\u00f1\u00e1n Miguel \u00c1., Raziperchikolaei Ramin\nconference: Arxiv\nyear: 2016\nbibkey: carreiraperpi\u00f1\u00e1n2016an\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1602.01557\"}\ntags: ['ARXIV', 'Image Retrieval', 'Supervised']\n---\nBinary hashing is a well-known approach for fast approximate nearest-neighbor search in information retrieval. Much work has focused on affinity-based objective functions involving the hash functions or binary codes. These objective functions encode neighborhood information between data points and are often inspired by manifold learning algorithms. They ensure that the hash functions differ from each other through constraints or penalty terms that encourage codes to be orthogonal or dissimilar across bits, but this couples the binary variables and complicates the already difficult optimization. We propose a much simpler approach: we train each hash function (or bit) independently from each other, but introduce diversity among them using techniques from classifier ensembles. Surprisingly, we find that not only is this faster and trivially parallelizable, but it also improves over the more complex, coupled objective function, and achieves state-of-the-art precision and recall in experiments with image retrieval.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [4.9387125968933105, 2.160557270050049]}, {"key": "", "year": "", "title": "Cassee2017analysing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Analysing the Performance of GPU Hash Tables for State Space Exploration\"\nauthors: Cassee Nathan  Eindhoven University of Technology, Eindhoven, The   Netherlands, Wijs Anton  Eindhoven University of Technology, Eindhoven, The   Netherlands\nconference: EPTCS\nyear: 2017\nbibkey: cassee2017analysing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1712.09494\"}\ntags: ['Graph']\n---\nIn the past few years, General Purpose Graphics Processors (GPUs) have been used to significantly speed up numerous applications. One of the areas in which GPUs have recently led to a significant speed-up is model checking. In model checking, state spaces, i.e., large directed graphs, are explored to verify whether models satisfy desirable properties. GPUexplore is a GPU-based model checker that uses a hash table to efficiently keep track of already explored states. As a large number of states is discovered and stored during such an exploration, the hash table should be able to quickly handle many inserts and queries concurrently. In this paper, we experimentally compare two different hash tables optimised for the GPU, one being the GPUexplore hash table, and the other using Cuckoo hashing. We compare the performance of both hash tables using random and non-random data obtained from model checking experiments, to analyse the applicability of the two hash tables for state space exploration. We conclude that Cuckoo hashing is three times faster than GPUexplore hashing for random data, and that Cuckoo hashing is five to nine times faster for non-random data. This suggests great potential to further speed up GPUexplore in the near future.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-15.85061264038086, -15.147135734558105]}, {"key": "", "year": "", "title": "Ceccarello2018fresh", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"FRESH: Fr\\'echet Similarity with Hashing\"\nauthors: Ceccarello Matteo, Driemel Anne, Silvestri Francesco\nconference: Proc. of Algorithms and Data Structures Symposium\nyear: 2018\nbibkey: ceccarello2018fresh\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1809.02350\"}\ntags: []\n---\nThis paper studies the $r$-range search problem for curves under the continuous Fr\\'echet distance: given a dataset $S$ of $n$ polygonal curves and a threshold $r&gt;0$, construct a data structure that, for any query curve $q$, efficiently returns all entries in $S$ with distance at most $r$ from $q$. We propose FRESH, an approximate and randomized approach for $r$-range search, that leverages on a locality sensitive hashing scheme for detecting candidate near neighbors of the query curve, and on a subsequent pruning step based on a cascade of curve simplifications. We experimentally compare \\fresh to exact and deterministic solutions, and we show that high performance can be reached by suitably relaxing precision and recall.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.95754623413086, -11.665718078613281]}, {"key": "", "year": "", "title": "Cerra2012a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A fast compression-based similarity measure with applications to content-based image retrieval\"\nauthors: Cerra Daniele, Datcu Mihai\nconference: Journal of Visual Communication and Image Representation, vol.\nyear: 2012\nbibkey: cerra2012a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1210.0758\"}\ntags: ['Image Retrieval']\n---\nCompression-based similarity measures are effectively employed in applications on diverse data types with a basically parameter-free approach. Nevertheless, there are problems in applying these techniques to medium-to-large datasets which have been seldom addressed. This paper proposes a similarity measure based on compression with dictionaries, the Fast Compression Distance (FCD), which reduces the complexity of these methods, without degradations in performance. On its basis a content-based color image retrieval system is defined, which can be compared to state-of-the-art methods based on invariant color features. Through the FCD a better understanding of compression-based techniques is achieved, by performing experiments on datasets which are larger than the ones analyzed so far in literature.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [15.006093978881836, 4.219074726104736]}, {"key": "", "year": "", "title": "Cerra2014authorship", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Authorship Analysis based on Data Compression\"\nauthors: Cerra Daniele, Datcu Mihai, Reinartz Peter\nconference: Arxiv\nyear: 2014\nbibkey: cerra2014authorship\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1402.3405\"}\ntags: ['ARXIV']\n---\nThis paper proposes to perform authorship analysis using the Fast Compression Distance (FCD), a similarity measure based on compression with dictionaries directly extracted from the written texts. The FCD computes a similarity between two documents through an effective binary search on the intersection set between the two related dictionaries. In the reported experiments the proposed method is applied to documents which are heterogeneous in style, written in five different languages and coming from different historical periods. Results are comparable to the state of the art and outperform traditional compression-based methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [16.781755447387695, -11.63003921508789]}, {"key": "", "year": "", "title": "Chadha2012comparative", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Comparative Study and Optimization of Feature-Extraction Techniques for Content based Image Retrieval\"\nauthors: Chadha Aman, Mallik Sushmit, Johar Ravdeep\nconference: International Journal of Computer Applications\nyear: 2012\nbibkey: chadha2012comparative\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1208.6335\"}\ntags: ['Image Retrieval']\n---\nThe aim of a Content-Based Image Retrieval (CBIR) system, also known as Query by Image Content (QBIC), is to help users to retrieve relevant images based on their contents. CBIR technologies provide a method to find images in large databases by using unique descriptors from a trained image. The image descriptors include texture, color, intensity and shape of the object inside an image. Several feature-extraction techniques viz., Average RGB, Color Moments, Co-occurrence, Local Color Histogram, Global Color Histogram and Geometric Moment have been critically compared in this paper. However, individually these techniques result in poor performance. So, combinations of these techniques have also been evaluated and results for the most efficient combination of techniques have been presented and optimized for each class of image query. We also propose an improvement in image retrieval performance by introducing the idea of Query modification through image cropping. It enables the user to identify a region of interest and modify the initial query to refine and personalize the image retrieval results.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [22.181238174438477, 12.01993179321289]}, {"key": "", "year": "", "title": "Chadha2016voronoi", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Voronoi-based compact image descriptors: Efficient Region-of-Interest retrieval with VLAD and deep-learning-based descriptors\"\nauthors: Chadha Aaron, Andreopoulos Yiannis\nconference: Arxiv\nyear: 2016\nbibkey: chadha2016voronoi\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1611.08906\"}\ntags: ['ARXIV', 'CNN', 'Deep Learning', 'Image Retrieval', 'TOM']\n---\nWe investigate the problem of image retrieval based on visual queries when the latter comprise arbitrary regions-of-interest (ROI) rather than entire images. Our proposal is a compact image descriptor that combines the state-of-the-art in content-based descriptor extraction with a multi-level, Voronoi-based spatial partitioning of each dataset image. The proposed multi-level Voronoi-based encoding uses a spatial hierarchical K-means over interest-point locations, and computes a content-based descriptor over each cell. In order to reduce the matching complexity with minimal or no sacrifice in retrieval performance: (i) we utilize the tree structure of the spatial hierarchical K-means to perform a top-to-bottom pruning for local similarity maxima; (ii) we propose a new image similarity score that combines relevant information from all partition levels into a single measure for similarity; (iii) we combine our proposal with a novel and efficient approach for optimal bit allocation within quantized descriptor representations. By deriving both a Voronoi-based VLAD descriptor (termed as Fast-VVLAD) and a Voronoi-based deep convolutional neural network (CNN) descriptor (termed as Fast-VDCNN), we demonstrate that our Voronoi-based framework is agnostic to the descriptor basis, and can easily be slotted into existing frameworks. Via a range of ROI queries in two standard datasets, it is shown that the Voronoi-based descriptors achieve comparable or higher mean Average Precision against conventional grid-based spatial search, while offering more than two-fold reduction in complexity. Finally, beyond ROI queries, we show that Voronoi partitioning improves the geometric invariance of compact CNN descriptors, thereby resulting in competitive performance to the current state-of-the-art on whole image retrieval.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.48839282989502, 24.010025024414062]}, {"key": "", "year": "", "title": "Chaidaroon2017variational", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Variational Deep Semantic Hashing for Text Documents\"\nauthors: Chaidaroon Suthee, Fang Yi\nconference: Arxiv\nyear: 2017\nbibkey: chaidaroon2017variational\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1708.03436\"}\ntags: ['ARXIV', 'Deep Learning', 'Supervised', 'Unsupervised']\n---\nAs the amount of textual data has been rapidly increasing over the past decade, efficient similarity search methods have become a crucial component of large-scale information retrieval systems. A popular strategy is to represent original data samples by compact binary codes through hashing. A spectrum of machine learning methods have been utilized, but they often lack expressiveness and flexibility in modeling to learn effective representations. The recent advances of deep learning in a wide range of applications has demonstrated its capability to learn robust and powerful feature representations for complex data. Especially, deep generative models naturally combine the expressiveness of probabilistic generative models with the high capacity of deep neural networks, which is very suitable for text modeling. However, little work has leveraged the recent progress in deep learning for text hashing. In this paper, we propose a series of novel deep document generative models for text hashing. The first proposed model is unsupervised while the second one is supervised by utilizing document labels/tags for hashing. The third model further considers document-specific factors that affect the generation of words. The probabilistic generative formulation of the proposed models provides a principled framework for model extension, uncertainty estimation, simulation, and interpretability. Based on variational inference and reparameterization, the proposed models can be interpreted as encoder-decoder deep neural networks and thus they are capable of learning complex nonlinear distributed representations of the original documents. We conduct a comprehensive set of experiments on four public testbeds. The experimental results have demonstrated the effectiveness of the proposed supervised learning models for text hashing.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-18.344533920288086, 9.155655860900879]}, {"key": "", "year": "", "title": "Chakrabarti2020efficient", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Efficient image retrieval using multi neural hash codes and bloom filters\"\nauthors: Chakrabarti Sourin\nconference: Arxiv\nyear: 2020\nbibkey: chakrabarti2020efficient\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2011.03234\"}\ntags: ['ARXIV', 'Image Retrieval', 'TIP']\n---\nThis paper aims to deliver an efficient and modified approach for image retrieval using multiple neural hash codes and limiting the number of queries using bloom filters by identifying false positives beforehand. Traditional approaches involving neural networks for image retrieval tasks tend to use higher layers for feature extraction. But it has been seen that the activations of lower layers have proven to be more effective in a number of scenarios. In our approach, we have leveraged the use of local deep convolutional neural networks which combines the powers of both the features of lower and higher layers for creating feature maps which are then compressed using PCA and fed to a bloom filter after binary sequencing using a modified multi k-means approach. The feature maps obtained are further used in the image retrieval process in a hierarchical coarse-to-fine manner by first comparing the images in the higher layers for semantically similar images and then gradually moving towards the lower layers searching for structural similarities. While searching, the neural hashes for the query image are again calculated and queried in the bloom filter which tells us whether the query image is absent in the set or maybe present. If the bloom filter doesn't necessarily rule out the query, then it goes into the image retrieval process. This approach can be particularly helpful in cases where the image store is distributed since the approach supports parallel querying.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [7.061871528625488, 6.920623779296875]}, {"key": "", "year": "", "title": "Chakraborty2022centre", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Centre Symmetric Quadruple Pattern: A Novel Descriptor for Facial Image Recognition and Retrieval\"\nauthors: Chakraborty Soumendu, Singh Satish Kumar, Chakraborty Pavan\nconference: Pattern Recognition Letters, vol-\nyear: 2022\nbibkey: chakraborty2022centre\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2201.00511\"}\ntags: []\n---\nFacial features are defined as the local relationships that exist amongst the pixels of a facial image. Hand-crafted descriptors identify the relationships of the pixels in the local neighbourhood defined by the kernel. Kernel is a two dimensional matrix which is moved across the facial image. Distinctive information captured by the kernel with limited number of pixel achieves satisfactory recognition and retrieval accuracies on facial images taken under constrained environment (controlled variations in light, pose, expressions, and background). To achieve similar accuracies under unconstrained environment local neighbourhood has to be increased, in order to encode more pixels. Increasing local neighbourhood also increases the feature length of the descriptor. In this paper we propose a hand-crafted descriptor namely Centre Symmetric Quadruple Pattern (CSQP), which is structurally symmetric and encodes the facial asymmetry in quadruple space. The proposed descriptor efficiently encodes larger neighbourhood with optimal number of binary bits. It has been shown using average entropy, computed over feature images encoded with the proposed descriptor, that the CSQP captures more meaningful information as compared to state of the art descriptors. The retrieval and recognition accuracies of the proposed descriptor has been compared with state of the art hand-crafted descriptors (CSLBP, CSLTP, LDP, LBP, SLBP and LDGP) on bench mark databases namely; LFW, Colour-FERET, and CASIA-face-v5. Result analysis shows that the proposed descriptor performs well under controlled as well as uncontrolled variations in pose, illumination, background and expressions.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [20.39212989807129, 21.298234939575195]}, {"key": "", "year": "", "title": "Chandrasekaran2017lattice", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Lattice-based Locality Sensitive Hashing is Optimal\"\nauthors: Chandrasekaran Karthekeyan, Dadush Daniel, Gandikota Venkata, Grigorescu Elena\nconference: Arxiv\nyear: 2017\nbibkey: chandrasekaran2017lattice\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1712.08558\"}\ntags: ['ARXIV', 'FOCS', 'LSH']\n---\nLocality sensitive hashing (LSH) was introduced by Indyk and Motwani (STOC `98) to give the first sublinear time algorithm for the c-approximate nearest neighbor (ANN) problem using only polynomial space. At a high level, an LSH family hashes \"nearby\" points to the same bucket and \"far away\" points to different buckets. The quality of measure of an LSH family is its LSH exponent, which helps determine both query time and space usage. In a seminal work, Andoni and Indyk (FOCS `06) constructed an LSH family based on random ball partitioning of space that achieves an LSH exponent of 1/c^2 for the l_2 norm, which was later shown to be optimal by Motwani, Naor and Panigrahy (SIDMA `07) and O'Donnell, Wu and Zhou (TOCT `14). Although optimal in the LSH exponent, the ball partitioning approach is computationally expensive. So, in the same work, Andoni and Indyk proposed a simpler and more practical hashing scheme based on Euclidean lattices and provided computational results using the 24-dimensional Leech lattice. However, no theoretical analysis of the scheme was given, thus leaving open the question of finding the exponent of lattice based LSH. In this work, we resolve this question by showing the existence of lattices achieving the optimal LSH exponent of 1/c^2 using techniques from the geometry of numbers. At a more conceptual level, our results show that optimal LSH space partitions can have periodic structure. Understanding the extent to which additional structure can be imposed on these partitions, e.g. to yield low space and query complexity, remains an important open problem.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-15.737495422363281, -24.290637969970703]}, {"key": "", "year": "", "title": "Chang2019semi", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Semi-Supervised Exploration in Image Retrieval\"\nauthors: Chang Cheng, Rai Himanshu, Gorti Satya Krishna, Ma Junwei, Liu Chundi, Yu Guangwei, Volkovs Maksims\nconference: Arxiv\nyear: 2019\nbibkey: chang2019semi\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1906.04944\"}\ntags: ['ARXIV', 'Graph', 'Image Retrieval', 'Semi Supervised', 'Supervised']\n---\nWe present our solution to Landmark Image Retrieval Challenge 2019. This challenge was based on the large Google Landmarks Dataset V2[9]. The goal was to retrieve all database images containing the same landmark for every provided query image. Our solution is a combination of global and local models to form an initial KNN graph. We then use a novel extension of the recently proposed graph traversal method EGT [1] referred to as semi-supervised EGT to refine the graph and retrieve better candidates.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [29.26460838317871, 2.675511598587036]}, {"key": "", "year": "", "title": "Chang2023balanced", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Balanced and Deterministic Weight-sharing Helps Network Performance\"\nauthors: Chang Oscar, Lipson Hod\nconference: Arxiv\nyear: 2023\nbibkey: chang2023balanced\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2312.08401\"}\ntags: ['ARXIV']\n---\nWeight-sharing plays a significant role in the success of many deep neural networks, by increasing memory efficiency and incorporating useful inductive priors about the problem into the network. But understanding how weight-sharing can be used effectively in general is a topic that has not been studied extensively. Chen et al. [2015] proposed HashedNets, which augments a multi-layer perceptron with a hash table, as a method for neural network compression. We generalize this method into a framework (ArbNets) that allows for efficient arbitrary weight-sharing, and use it to study the role of weight-sharing in neural networks. We show that common neural networks can be expressed as ArbNets with different hash functions. We also present two novel hash functions, the Dirichlet hash and the Neighborhood hash, and use them to demonstrate experimentally that balanced and deterministic weight-sharing helps with the performance of a neural network.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-21.561992645263672, 11.603591918945312]}, {"key": "", "year": "", "title": "Charikar2018hashing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hashing-Based-Estimators for Kernel Density in High Dimensions\"\nauthors: Charikar Moses, Siminelakis Paris\nconference: Arxiv\nyear: 2018\nbibkey: charikar2018hashing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1808.10530\"}\ntags: ['ARXIV']\n---\nGiven a set of points $P\\subset \\mathbb\\{R\\}^\\{d\\}$ and a kernel $k$, the Kernel Density Estimate at a point $x\\in\\mathbb\\{R\\}^\\{d\\}$ is defined as $\\mathrm\\{KDE\\}_\\{P\\}(x)=\\frac\\{1\\}\\{|P|\\}\\sum_\\{y\\in P\\} k(x,y)$. We study the problem of designing a data structure that given a data set $P$ and a kernel function, returns *approximations to the kernel density* of a query point in *sublinear time*. We introduce a class of unbiased estimators for kernel density implemented through locality-sensitive hashing, and give general theorems bounding the variance of such estimators. These estimators give rise to efficient data structures for estimating the kernel density in high dimensions for a variety of commonly used kernels. Our work is the first to provide data-structures with theoretical guarantees that improve upon simple random sampling in high dimensions.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-13.672281265258789, -25.543935775756836]}, {"key": "", "year": "", "title": "Charikar2018multi", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Multi-Resolution Hashing for Fast Pairwise Summations\"\nauthors: Charikar Moses, Siminelakis Paris\nconference: Arxiv\nyear: 2018\nbibkey: charikar2018multi\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1807.07635\"}\ntags: ['ARXIV', 'FOCS']\n---\nA basic computational primitive in the analysis of massive datasets is summing simple functions over a large number of objects. Modern applications pose an additional challenge in that such functions often depend on a parameter vector $y$ (query) that is unknown a priori. Given a set of points $X\\subset \\mathbb\\{R\\}^\\{d\\}$ and a pairwise function $w:\\mathbb\\{R\\}^\\{d\\}\\times \\mathbb\\{R\\}^\\{d\\}\\to [0,1]$, we study the problem of designing a data-structure that enables sublinear-time approximation of the summation $Z_\\{w\\}(y)=\\frac\\{1\\}\\{|X|\\}\\sum_\\{x\\in X\\}w(x,y)$ for any query $y\\in \\mathbb\\{R\\}^\\{d\\}$. By combining ideas from Harmonic Analysis (partitions of unity and approximation theory) with Hashing-Based-Estimators [Charikar, Siminelakis FOCS'17], we provide a general framework for designing such data structures through hashing that reaches far beyond what previous techniques allowed. A key design principle is a collection of $T\\geq 1$ hashing schemes with collision probabilities $p_\\{1\\},\\ldots, p_\\{T\\}$ such that $\\sup_\\{t\\in [T]\\}\\\\{p_\\{t\\}(x,y)\\\\} = \\Theta(\\sqrt\\{w(x,y)\\})$. This leads to a data-structure that approximates $Z_\\{w\\}(y)$ using a sub-linear number of samples from each hash family. Using this new framework along with Distance Sensitive Hashing [Aumuller, Christiani, Pagh, Silvestri PODS'18], we show that such a collection can be constructed and evaluated efficiently for any log-convex function $w(x,y)=e^\\{\\phi(\\langle x,y\\rangle)\\}$ of the inner product on the unit sphere $x,y\\in \\mathcal\\{S\\}^\\{d-1\\}$. Our method leads to data structures with sub-linear query time that significantly improve upon random sampling and can be used for Kernel Density or Partition Function Estimation. We provide extensions of our result from the sphere to $\\mathbb\\{R\\}^\\{d\\}$ and from scalar functions to vector functions.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-13.431012153625488, -24.024677276611328]}, {"key": "", "year": "", "title": "Chaudhary2012a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Hash based Approach for Secure Keyless Steganography in Lossless RGB Images\"\nauthors: Chaudhary Ankit, Vasavada J., Raheja J. L., Kumar S., Sharma M.\nconference: The\nyear: 2012\nbibkey: chaudhary2012a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1211.5614\"}\ntags: ['GAN', 'Graph']\n---\nThis paper proposes an improved steganography approach for hiding text messages in lossless RGB images. The objective of this work is to increase the security level and to improve the storage capacity with compression techniques. The security level is increased by randomly distributing the text message over the entire image instead of clustering within specific image portions. Storage capacity is increased by utilizing all the color channels for storing information and providing the source text message compression. The degradation of the images can be minimized by changing only one least significant bit per color channel for hiding the message, incurring a very little change in the original image. Using steganography alone with simple LSB has a potential problem that the secret message is easily detectable from the histogram analysis method. To improve the security as well as the image embedding capacity indirectly, a compression based scheme is introduced. Various tests have been done to check the storage capacity and message distribution. These testes show the superiority of the proposed approach with respect to other existing approaches.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [2.7074761390686035, 11.838611602783203]}, {"key": "", "year": "", "title": "Chaudhuri2019efficient", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Efficient Retrieval of Logos Using Rough Set Reducts\"\nauthors: Chaudhuri Ushasi, Bhowmick Partha, Mukhopadhyay Jayanta\nconference: Arxiv\nyear: 2019\nbibkey: chaudhuri2019efficient\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1904.05008\"}\ntags: ['ARXIV', 'Video Retrieval']\n---\nSearching for similar logos in the registered logo database is a very important and tedious task at the trademark office. Speed and accuracy are two aspects that one must attend to while developing a system for retrieval of logos. In this paper, we propose a rough-set based method to quantify the structural information in a logo image that can be used to efficiently index an image. A logo is split into a number of polygons, and for each polygon, we compute the tight upper and lower approximations based on the principles of a rough set. This representation is used for forming feature vectors for retrieval of logos. Experimentation on a standard data set shows the usefulness of the proposed technique. It is computationally efficient and also provides retrieval results at high accuracy.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [5.41778039932251, 22.170549392700195]}, {"key": "", "year": "", "title": "Chegrane2013simple", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Simple, compact and robust approximate string dictionary\"\nauthors: Chegrane Ibrahim, Belazzougui Djamal\nconference: Arxiv\nyear: 2013\nbibkey: chegrane2013simple\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1312.4678\"}\ntags: ['ARXIV']\n---\nThis paper is concerned with practical implementations of approximate string dictionaries that allow edit errors. In this problem, we have as input a dictionary $D$ of $d$ strings of total length $n$ over an alphabet of size $\\sigma$. Given a bound $k$ and a pattern $x$ of length $m$, a query has to return all the strings of the dictionary which are at edit distance at most $k$ from $x$, where the edit distance between two strings $x$ and $y$ is defined as the minimum-cost sequence of edit operations that transform $x$ into $y$. The cost of a sequence of operations is defined as the sum of the costs of the operations involved in the sequence. In this paper, we assume that each of these operations has unit cost and consider only three operations: deletion of one character, insertion of one character and substitution of a character by another. We present a practical implementation of the data structure we recently proposed and which works only for one error. We extend the scheme to $2\\leq k&lt;m$. Our implementation has many desirable properties: it has a very fast and space-efficient building algorithm. The dictionary data structure is compact and has fast and robust query time. Finally our data structure is simple to implement as it only uses basic techniques from the literature, mainly hashing (linear probing and hash signatures) and succinct data structures (bitvectors supporting rank queries).\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-11.710516929626465, -14.94676685333252]}, {"key": "", "year": "", "title": "Chen2015compressing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Compressing Neural Networks with the Hashing Trick\"\nauthors: Chen Wenlin, Wilson James T., Tyree Stephen, Weinberger Kilian Q., Chen Yixin\nconference: Arxiv\nyear: 2015\nbibkey: chen2015compressing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1504.04788\"}\ntags: ['ARXIV', 'Deep Learning']\n---\nAs deep nets are increasingly used in applications suited for mobile devices, a fundamental dilemma becomes apparent: the trend in deep learning is to grow models to absorb ever-increasing data set sizes; however mobile devices are designed with very little memory and cannot store such large models. We present a novel network architecture, HashedNets, that exploits inherent redundancy in neural networks to achieve drastic reductions in model sizes. HashedNets uses a low-cost hash function to randomly group connection weights into hash buckets, and all connections within the same hash bucket share a single parameter value. These parameters are tuned to adjust to the HashedNets weight sharing architecture with standard backprop during training. Our hashing procedure introduces no additional memory overhead, and we demonstrate on several benchmark data sets that HashedNets shrink the storage requirements of neural networks substantially while mostly preserving generalization performance.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-20.290346145629883, 13.096688270568848]}, {"key": "", "year": "", "title": "Chen2016revisiting", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Revisiting Winner Take All (WTA) Hashing for Sparse Datasets\"\nauthors: Chen Beidi, Shrivastava Anshumali\nconference: Arxiv\nyear: 2016\nbibkey: chen2016revisiting\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1612.01834\"}\ntags: ['ARXIV']\n---\nWTA (Winner Take All) hashing has been successfully applied in many large scale vision applications. This hashing scheme was tailored to take advantage of the comparative reasoning (or order based information), which showed significant accuracy improvements. In this paper, we identify a subtle issue with WTA, which grows with the sparsity of the datasets. This issue limits the discriminative power of WTA. We then propose a solution for this problem based on the idea of Densification which provably fixes the issue. Our experiments show that Densified WTA Hashing outperforms Vanilla WTA both in image classification and retrieval tasks consistently and significantly.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [7.4714436531066895, -4.650826930999756]}, {"key": "", "year": "", "title": "Chen2017derandomized", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Derandomized Balanced Allocation\"\nauthors: Chen Xue\nconference: Arxiv\nyear: 2017\nbibkey: chen2017derandomized\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1702.03375\"}\ntags: ['ARXIV']\n---\nIn this paper, we study the maximum loads of explicit hash families in the $d$-choice schemes when allocating sequentially $n$ balls into $n$ bins. We consider the \\emph{Uniform-Greedy} scheme, which provides $d$ independent bins for each ball and places the ball into the bin with the least load, and its non-uniform variant --- the \\emph{Always-Go-Left} scheme introduced by V\\\"ocking. We construct a hash family with $O(\\log n \\log \\log n)$ random bits based on the previous work of Celis et al. and show the following results. 1. With high probability, this hash family has a maximum load of $\\frac\\{\\log \\log n\\}\\{\\log d\\} + O(1)$ in the \\emph{Uniform-Greedy} scheme. 2. With high probability, it has a maximum load of $\\frac\\{\\log \\log n\\}\\{d \\log \\phi_d\\} + O(1)$ in the \\emph{Always-Go-Left} scheme for a constant $\\phi_d&gt;1.61$. The maximum loads of our hash family match the maximum loads of a perfectly random hash function in the \\emph{Uniform-Greedy} and \\emph{Always-Go-Left} scheme separately, up to the low order term of constants. Previously, the best known hash families matching the same maximum loads of a perfectly random hash function in $d$-choice schemes were $O(\\log n)$-wise independent functions, which needs $\\Theta(\\log^2 n)$ random bits.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-16.29071807861328, -21.090219497680664]}, {"key": "", "year": "", "title": "Chen2018improving", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Improving Deep Binary Embedding Networks by Order-aware Reweighting of Triplets\"\nauthors: Chen Jikai, Lai Hanjiang, Geng Libing, Pan Yan\nconference: Arxiv\nyear: 2018\nbibkey: chen2018improving\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1804.06061\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nIn this paper, we focus on triplet-based deep binary embedding networks for image retrieval task. The triplet loss has been shown to be most effective for the ranking problem. However, most of the previous works treat the triplets equally or select the hard triplets based on the loss. Such strategies do not consider the order relations, which is important for retrieval task. To this end, we propose an order-aware reweighting method to effectively train the triplet-based deep networks, which up-weights the important triplets and down-weights the uninformative triplets. First, we present the order-aware weighting factors to indicate the importance of the triplets, which depend on the rank order of binary codes. Then, we reshape the triplet loss to the squared triplet loss such that the loss function will put more weights on the important triplets. Extensive evaluations on four benchmark datasets show that the proposed method achieves significant performance compared with the state-of-the-art baselines.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [6.988358974456787, 5.284721374511719]}, {"key": "", "year": "", "title": "Chen2019efficient", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Efficient Object Embedding for Spliced Image Retrieval\"\nauthors: Chen Bor-Chun, Wu Zuxuan, Davis Larry S., Lim Ser-Nam\nconference: Arxiv\nyear: 2019\nbibkey: chen2019efficient\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1905.11903\"}\ntags: ['ARXIV', 'Image Retrieval', 'TIP']\n---\nDetecting spliced images is one of the emerging challenges in computer vision. Unlike prior methods that focus on detecting low-level artifacts generated during the manipulation process, we use an image retrieval approach to tackle this problem. When given a spliced query image, our goal is to retrieve the original image from a database of authentic images. To achieve this goal, we propose representing an image by its constituent objects based on the intuition that the finest granularity of manipulations is oftentimes at the object-level. We introduce a framework, object embeddings for spliced image retrieval (OE-SIR), that utilizes modern object detectors to localize object regions. Each region is then embedded and collectively used to represent the image. Further, we propose a student-teacher training paradigm for learning discriminative embeddings within object regions to avoid expensive multiple forward passes. Detailed analysis of the efficacy of different feature embedding models is also provided in this study. Extensive experimental results show that the OE-SIR achieves state-of-the-art performance in spliced image retrieval.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [3.101862668991089, 17.579076766967773]}, {"key": "", "year": "", "title": "Chen2019hadamard", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hadamard Codebook Based Deep Hashing\"\nauthors: Chen Shen, Cao Liujuan, Lin Mingbao, Wang Yan, Sun Xiaoshuai, Wu Chenglin, Qiu Jingfei, Ji Rongrong\nconference: Arxiv\nyear: 2019\nbibkey: chen2019hadamard\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1910.09182\"}\ntags: ['ARXIV', 'Image Retrieval', 'Supervised']\n---\nAs an approximate nearest neighbor search technique, hashing has been widely applied in large-scale image retrieval due to its excellent efficiency. Most supervised deep hashing methods have similar loss designs with embedding learning, while quantizing the continuous high-dim feature into compact binary space. We argue that the existing deep hashing schemes are defective in two issues that seriously affect the performance, i.e., bit independence and bit balance. The former refers to hash codes of different classes should be independent of each other, while the latter means each bit should have a balanced distribution of +1s and -1s. In this paper, we propose a novel supervised deep hashing method, termed Hadamard Codebook based Deep Hashing (HCDH), which solves the above two problems in a unified formulation. Specifically, we utilize an off-the-shelf algorithm to generate a binary Hadamard codebook to satisfy the requirement of bit independence and bit balance, which subsequently serves as the desired outputs of the hash functions learning. We also introduce a projection matrix to solve the inconsistency between the order of Hadamard matrix and the number of classes. Besides, the proposed HCDH further exploits the supervised labels by constructing a classifier on top of the outputs of hash functions. Extensive experiments demonstrate that HCDH can yield discriminative and balanced binary codes, which well outperforms many state-of-the-arts on three widely-used benchmarks.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-8.936481475830078, 0.4138137102127075]}, {"key": "", "year": "", "title": "Chen2019locality", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Locality-Sensitive Hashing for f-Divergences: Mutual Information Loss and Beyond\"\nauthors: Chen Lin, Esfandiari Hossein, Fu Thomas, Mirrokni Vahab S.\nconference: Arxiv\nyear: 2019\nbibkey: chen2019locality\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1910.12414\"}\ntags: ['ARXIV', 'LSH']\n---\nComputing approximate nearest neighbors in high dimensional spaces is a central problem in large-scale data mining with a wide range of applications in machine learning and data science. A popular and effective technique in computing nearest neighbors approximately is the locality-sensitive hashing (LSH) scheme. In this paper, we aim to develop LSH schemes for distance functions that measure the distance between two probability distributions, particularly for f-divergences as well as a generalization to capture mutual information loss. First, we provide a general framework to design LHS schemes for f-divergence distance functions and develop LSH schemes for the generalized Jensen-Shannon divergence and triangular discrimination in this framework. We show a two-sided approximation result for approximation of the generalized Jensen-Shannon divergence by the Hellinger distance, which may be of independent interest. Next, we show a general method of reducing the problem of designing an LSH scheme for a Krein kernel (which can be expressed as the difference of two positive definite kernels) to the problem of maximum inner product search. We exemplify this method by applying it to the mutual information loss, due to its several important applications such as model compression.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-4.89939022064209, -23.081497192382812]}, {"key": "", "year": "", "title": "Chen2019revisiting", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Revisiting Consistent Hashing with Bounded Loads\"\nauthors: Chen John, Coleman Ben, Shrivastava Anshumali\nconference: Arxiv\nyear: 2019\nbibkey: chen2019revisiting\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1908.08762\"}\ntags: ['ARXIV', 'GAN']\n---\nDynamic load balancing lies at the heart of distributed caching. Here, the goal is to assign objects (load) to servers (computing nodes) in a way that provides load balancing while at the same time dynamically adjusts to the addition or removal of servers. One essential requirement is that the addition or removal of small servers should not require us to recompute the complete assignment. A popular and widely adopted solution is the two-decade-old Consistent Hashing (CH). Recently, an elegant extension was provided to account for server bounds. In this paper, we identify that existing methodologies for CH and its variants suffer from cascaded overflow, leading to poor load balancing. This cascading effect leads to decreasing performance of the hashing procedure with increasing load. To overcome the cascading effect, we propose a simple solution to CH based on recent advances in fast minwise hashing. We show, both theoretically and empirically, that our proposed solution is significantly superior for load balancing and is optimal in many senses. On the AOL search dataset and Indiana University Clicks dataset with real user activity, our proposed solution reduces cache misses by several magnitudes.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-20.126522064208984, -7.593672275543213]}, {"key": "", "year": "", "title": "Chen2020making", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Making Online Sketching Hashing Even Faster\"\nauthors: Chen Xixian, Yang Haiqin, Zhao Shenglin, Lyu Michael R., King Irwin\nconference: IEEE Transactions on Knowledge and Data Engineering,\nyear: 2020\nbibkey: chen2020making\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2010.04948\"}\ntags: ['ACL', 'Streaming Data']\n---\nData-dependent hashing methods have demonstrated good performance in various machine learning applications to learn a low-dimensional representation from the original data. However, they still suffer from several obstacles: First, most of existing hashing methods are trained in a batch mode, yielding inefficiency for training streaming data. Second, the computational cost and the memory consumption increase extraordinarily in the big data setting, which perplexes the training procedure. Third, the lack of labeled data hinders the improvement of the model performance. To address these difficulties, we utilize online sketching hashing (OSH) and present a FasteR Online Sketching Hashing (FROSH) algorithm to sketch the data in a more compact form via an independent transformation. We provide theoretical justification to guarantee that our proposed FROSH consumes less time and achieves a comparable sketching precision under the same memory cost of OSH. We also extend FROSH to its distributed implementation, namely DFROSH, to further reduce the training time cost of FROSH while deriving the theoretical bound of the sketching precision. Finally, we conduct extensive experiments on both synthetic and real datasets to demonstrate the attractive merits of FROSH and DFROSH.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-16.46385383605957, -7.5913801193237305]}, {"key": "", "year": "", "title": "Chen2021a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A High-dimensional Sparse Fourier Transform in the Continuous Setting\"\nauthors: Chen Liang\nconference: There are some minor errors in the previous version, please refer to &lt;Inverse problems,\nyear: 2021\nbibkey: chen2021a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2102.10939\"}\ntags: []\n---\nIn this paper, we theoretically propose a new hashing scheme to establish the sparse Fourier transform in high-dimensional space. The estimation of the algorithm complexity shows that this sparse Fourier transform can overcome the curse of dimensionality. To the best of our knowledge, this is the first polynomial-time algorithm to recover the high-dimensional continuous frequencies.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-27.14032745361328, 0.6853358149528503]}, {"key": "", "year": "", "title": "Chen2021deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Learning to Ternary Hash Codes by Continuation\"\nauthors: Chen Mingrui, Li Weiyu, Lu Weizhi\nconference: Arxiv\nyear: 2021\nbibkey: chen2021deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2107.07987\"}\ntags: ['ARXIV', 'Deep Learning', 'Image Retrieval', 'Quantisation']\n---\nRecently, it has been observed that {0,1,-1}-ternary codes which are simply generated from deep features by hard thresholding, tend to outperform {-1,1}-binary codes in image retrieval. To obtain better ternary codes, we for the first time propose to jointly learn the features with the codes by appending a smoothed function to the networks. During training, the function could evolve into a non-smoothed ternary function by a continuation method. The method circumvents the difficulty of directly training discrete functions and reduces the quantization errors of ternary codes. Experiments show that the generated codes indeed could achieve higher retrieval accuracy.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-6.947490215301514, 15.845907211303711]}, {"key": "", "year": "", "title": "Chen2021dvhn", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"DVHN: A Deep Hashing Framework for Large-scale Vehicle Re-identification\"\nauthors: Chen Yongbiao, Zhang Sheng, Liu Fangxin, Wu Chenggang, Guo Kaicheng, Qi Zhengwei\nconference: Arxiv\nyear: 2021\nbibkey: chen2021dvhn\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2112.04937\"}\ntags: ['ARXIV']\n---\nIn this paper, we make the very first attempt to investigate the integration of deep hash learning with vehicle re-identification. We propose a deep hash-based vehicle re-identification framework, dubbed DVHN, which substantially reduces memory usage and promotes retrieval efficiency while reserving nearest neighbor search accuracy. Concretely,~DVHN directly learns discrete compact binary hash codes for each image by jointly optimizing the feature learning network and the hash code generating module. Specifically, we directly constrain the output from the convolutional neural network to be discrete binary codes and ensure the learned binary codes are optimal for classification. To optimize the deep discrete hashing framework, we further propose an alternating minimization method for learning binary similarity-preserved hashing codes. Extensive experiments on two widely-studied vehicle re-identification datasets- \\textbf{VehicleID} and \\textbf{VeRi}-~have demonstrated the superiority of our method against the state-of-the-art deep hash methods. \\textbf{DVHN} of $2048$ bits can achieve 13.94\\% and 10.21\\% accuracy improvement in terms of \\textbf{mAP} and \\textbf{Rank@1} for \\textbf{VehicleID (800)} dataset. For \\textbf{VeRi}, we achieve 35.45\\% and 32.72\\% performance gains for \\textbf{Rank@1} and \\textbf{mAP}, respectively.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-5.929802417755127, 3.5256974697113037]}, {"key": "", "year": "", "title": "Chen2021multi", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Multi-Level Visual Similarity Based Personalized Tourist Attraction Recommendation Using Geo-Tagged Photos\"\nauthors: Chen Ling, Lyu Dandan, Yu Shanshan, Chen Gencai\nconference: Arxiv\nyear: 2021\nbibkey: chen2021multi\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2109.08275\"}\ntags: ['ARXIV']\n---\nGeo-tagged photo based tourist attraction recommendation can discover users' travel preferences from their taken photos, so as to recommend suitable tourist attractions to them. However, existing visual content based methods cannot fully exploit the user and tourist attraction information of photos to extract visual features, and do not differentiate the significances of different photos. In this paper, we propose multi-level visual similarity based personalized tourist attraction recommendation using geo-tagged photos (MEAL). MEAL utilizes the visual contents of photos and interaction behavior data to obtain the final embeddings of users and tourist attractions, which are then used to predict the visit probabilities. Specifically, by crossing the user and tourist attraction information of photos, we define four visual similarity levels and introduce a corresponding quintuplet loss to embed the visual contents of photos. In addition, to capture the significances of different photos, we exploit the self-attention mechanism to obtain the visual representations of users and tourist attractions. We conducted experiments on a dataset crawled from Flickr, and the experimental results proved the advantage of this method.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [18.604032516479492, 24.489377975463867]}, {"key": "", "year": "", "title": "Chen2021transhash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"TransHash: Transformer-based Hamming Hashing for Efficient Image Retrieval\"\nauthors: Chen Yongbiao, Zhang Sheng, Liu Fangxin, Chang Zhigang, Ye Mang, Qi Zhengwei\nconference: Arxiv\nyear: 2021\nbibkey: chen2021transhash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2105.01823\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval']\n---\nDeep hamming hashing has gained growing popularity in approximate nearest neighbour search for large-scale image retrieval. Until now, the deep hashing for the image retrieval community has been dominated by convolutional neural network architectures, e.g. \\texttt{Resnet}\\cite{he2016deep}. In this paper, inspired by the recent advancements of vision transformers, we present \\textbf{Transhash}, a pure transformer-based framework for deep hashing learning. Concretely, our framework is composed of two major modules: (1) Based on \\textit{Vision Transformer} (ViT), we design a siamese vision transformer backbone for image feature extraction. To learn fine-grained features, we innovate a dual-stream feature learning on top of the transformer to learn discriminative global and local features. (2) Besides, we adopt a Bayesian learning scheme with a dynamically constructed similarity matrix to learn compact binary hash codes. The entire framework is jointly trained in an end-to-end manner.~To the best of our knowledge, this is the first work to tackle deep hashing learning problems without convolutional neural networks (\\textit{CNNs}). We perform comprehensive experiments on three widely-studied datasets: \\textbf{CIFAR-10}, \\textbf{NUSWIDE} and \\textbf{IMAGENET}. The experiments have evidenced our superiority against the existing state-of-the-art deep hashing methods. Specifically, we achieve 8.2\\%, 2.6\\%, 12.7\\% performance gains in terms of average \\textit{mAP} for different hash bit lengths on three public datasets, respectively.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-8.371421813964844, 5.982128143310547]}, {"key": "", "year": "", "title": "Chen2022intra", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Intra-Modal Constraint Loss For Image-Text Retrieval\"\nauthors: Chen Jianan, Zhang Lu, Wang Qiong, Bai Cong, Kpalma Kidiyo\nconference: Arxiv\nyear: 2022\nbibkey: chen2022intra\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2207.05024\"}   - {name: \"Code\", url: \"https://github.com/CanonChen/IMC.\"}\ntags: ['ARXIV', 'Cross Modal', 'Text Retrieval']\n---\nCross-modal retrieval has drawn much attention in both computer vision and natural language processing domains. With the development of convolutional and recurrent neural networks, the bottleneck of retrieval across image-text modalities is no longer the extraction of image and text features but an efficient loss function learning in embedding space. Many loss functions try to closer pairwise features from heterogeneous modalities. This paper proposes a method for learning joint embedding of images and texts using an intra-modal constraint loss function to reduce the violation of negative pairs from the same homogeneous modality. Experimental results show that our approach outperforms state-of-the-art bi-directional image-text retrieval methods on Flickr30K and Microsoft COCO datasets. Our code is publicly available: https://github.com/CanonChen/IMC.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [21.554533004760742, 4.505927085876465]}, {"key": "", "year": "", "title": "Chen2023bipartite", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Bipartite Graph Convolutional Hashing for Effective and Efficient Top-N Search in Hamming Space\"\nauthors: Chen Yankai, Fang Yixiang, Zhang Yifei, King Irwin\nconference: Arxiv\nyear: 2023\nbibkey: chen2023bipartite\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2304.00241\"}\ntags: ['ARXIV', 'Graph']\n---\nSearching on bipartite graphs is basal and versatile to many real-world Web applications, e.g., online recommendation, database retrieval, and query-document searching. Given a query node, the conventional approaches rely on the similarity matching with the vectorized node embeddings in the continuous Euclidean space. To efficiently manage intensive similarity computation, developing hashing techniques for graph structured data has recently become an emerging research direction. Despite the retrieval efficiency in Hamming space, prior work is however confronted with catastrophic performance decay. In this work, we investigate the problem of hashing with Graph Convolutional Network on bipartite graphs for effective Top-N search. We propose an end-to-end Bipartite Graph Convolutional Hashing approach, namely BGCH, which consists of three novel and effective modules: (1) adaptive graph convolutional hashing, (2) latent feature dispersion, and (3) Fourier serialized gradient estimation. Specifically, the former two modules achieve the substantial retention of the structural information against the inevitable information loss in hash encoding; the last module develops Fourier Series decomposition to the hashing function in the frequency domain mainly for more accurate gradient estimation. The extensive experiments on six real-world datasets not only show the performance superiority over the competing hashing-based counterparts, but also demonstrate the effectiveness of all proposed model components contained therein.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [2.7580089569091797, -28.877111434936523]}, {"key": "", "year": "", "title": "Chen2023homomorphic", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Homomorphic Hashing Based on Elliptic Curve Cryptography\"\nauthors: Chen Abel C. H.\nconference: Arxiv\nyear: 2023\nbibkey: chen2023homomorphic\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2302.03290\"}\ntags: ['ARXIV', 'Graph']\n---\nFor avoiding the exposure of plaintexts in cloud environments, some homomorphic hashing algorithms have been proposed to generate the hash value of each plaintext, and cloud environments only store the hash values and calculate the hash values for future needs. However, longer hash value generation time and longer hash value summary time may be required by these homomorphic hashing algorithms with higher security strengths. Therefore, this study proposes a homomorphic hashing based on elliptic curve cryptography (ECC) to provide a homomorphic hashing function in accordance with the characteristics of ECC. Furthermore, mathematical models and practical cases have been given to prove the proposed method. In experiments, the results show that the proposed method have higher efficiency with different security strengths.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-32.47886276245117, -5.57751989364624]}, {"key": "", "year": "", "title": "Chen2023supervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Supervised Auto-Encoding Twin-Bottleneck Hashing\"\nauthors: Chen Yuan, Marchand-Maillet St\u00e9phane\nconference: Arxiv\nyear: 2023\nbibkey: chen2023supervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2306.11122\"}\ntags: ['ARXIV', 'Graph', 'Supervised', 'Unsupervised']\n---\nDeep hashing has shown to be a complexity-efficient solution for the Approximate Nearest Neighbor search problem in high dimensional space. Many methods usually build the loss function from pairwise or triplet data points to capture the local similarity structure. Other existing methods construct the similarity graph and consider all points simultaneously. Auto-encoding Twin-bottleneck Hashing is one such method that dynamically builds the graph. Specifically, each input data is encoded into a binary code and a continuous variable, or the so-called twin bottlenecks. The similarity graph is then computed from these binary codes, which get updated consistently during the training. In this work, we generalize the original model into a supervised deep hashing network by incorporating the label information. In addition, we examine the differences of codes structure between these two networks and consider the class imbalance problem especially in multi-labeled datasets. Experiments on three datasets yield statistically significant improvement against the original model. Results are also comparable and competitive to other supervised methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [3.3912813663482666, -24.78510284423828]}, {"key": "", "year": "", "title": "Chen2024towards", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Towards Effective Top-N Hamming Search via Bipartite Graph Contrastive Hashing\"\nauthors: Chen Yankai, Fang Yixiang, Zhang Yifei, Ma Chenhao, Hong Yang, King Irwin\nconference: Arxiv\nyear: 2024\nbibkey: chen2024towards\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2408.09239\"}\ntags: ['ARXIV', 'Graph', 'Self Supervised', 'Supervised']\n---\nSearching on bipartite graphs serves as a fundamental task for various real-world applications, such as recommendation systems, database retrieval, and document querying. Conventional approaches rely on similarity matching in continuous Euclidean space of vectorized node embeddings. To handle intensive similarity computation efficiently, hashing techniques for graph-structured data have emerged as a prominent research direction. However, despite the retrieval efficiency in Hamming space, previous studies have encountered catastrophic performance decay. To address this challenge, we investigate the problem of hashing with Graph Convolutional Network for effective Top-N search. Our findings indicate the learning effectiveness of incorporating hashing techniques within the exploration of bipartite graph reception fields, as opposed to simply treating hashing as post-processing to output embeddings. To further enhance the model performance, we advance upon these findings and propose Bipartite Graph Contrastive Hashing (BGCH+). BGCH+ introduces a novel dual augmentation approach to both intermediate information and hash code outputs in the latent feature spaces, thereby producing more expressive and robust hash codes within a dual self-supervised learning paradigm. Comprehensive empirical analyses on six real-world benchmarks validate the effectiveness of our dual feature contrastive learning in boosting the performance of BGCH+ compared to existing approaches.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [2.5408573150634766, -29.410673141479492]}, {"key": "", "year": "", "title": "Cheng2018crh", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"CRH: A Simple Benchmark Approach to Continuous Hashing\"\nauthors: Cheng Miao, Tsoi Ah Chung\nconference: Arxiv\nyear: 2018\nbibkey: cheng2018crh\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1810.05730\"}\ntags: ['ARXIV']\n---\nIn recent years, the distinctive advancement of handling huge data promotes the evolution of ubiquitous computing and analysis technologies. With the constantly upward system burden and computational complexity, adaptive coding has been a fascinating topic for pattern analysis, with outstanding performance. In this work, a continuous hashing method, termed continuous random hashing (CRH), is proposed to encode sequential data stream, while ignorance of previously hashing knowledge is possible. Instead, a random selection idea is adopted to adaptively approximate the differential encoding patterns of data stream, e.g., streaming media, and iteration is avoided for stepwise learning. Experimental results demonstrate our method is able to provide outstanding performance, as a benchmark approach to continuous hashing.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-21.332408905029297, 1.8877829313278198]}, {"key": "", "year": "", "title": "Cheng2021cnn", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"CNN Retrieval based Unsupervised Metric Learning for Near-Duplicated Video Retrieval\"\nauthors: Cheng Hao, Wang Ping, Qi Chun\nconference: Arxiv\nyear: 2021\nbibkey: cheng2021cnn\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2105.14566\"}\ntags: ['ARXIV', 'CNN', 'Supervised', 'Unsupervised', 'Video Retrieval']\n---\nAs important data carriers, the drastically increasing number of multimedia videos often brings many duplicate and near-duplicate videos in the top results of search. Near-duplicate video retrieval (NDVR) can cluster and filter out the redundant contents. In this paper, the proposed NDVR approach extracts the frame-level video representation based on convolutional neural network (CNN) features from fully-connected layer and aggregated intermediate convolutional layers. Unsupervised metric learning is used for similarity measurement and feature matching. An efficient re-ranking algorithm combined with k-nearest neighborhood fuses the retrieval results from two levels of features and further improves the retrieval performance. Extensive experiments on the widely used CC\\_WEB\\_VIDEO dataset shows that the proposed approach exhibits superior performance over the state-of-the-art.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-1.3539650440216064, 27.571060180664062]}, {"key": "", "year": "", "title": "Choromanski2015efficient", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Efficient data hashing with structured binary embeddings\"\nauthors: Choromanski Krzysztof\nconference: Arxiv\nyear: 2015\nbibkey: choromanski2015efficient\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1505.03190\"}\ntags: ['ARXIV']\n---\nWe present here new mechanisms for hashing data via binary embeddings. Contrary to most of the techniques presented before, the embedding matrix of our mechanism is highly structured. That enables us to perform hashing more efficiently and use less memory. What is crucial and nonintuitive is the fact that imposing structured mechanism does not affect the quality of the produced hash. To the best of our knowledge, we are the first to give strong theoretical guarantees of the proposed binary hashing method by proving the efficiency of the mechanism for several classes of structured projection matrices. As a corollary, we obtain binary hashing mechanisms with strong concentration results for circulant and Topelitz matrices. Our approach is however much more general.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-28.47870635986328, -12.0558500289917]}, {"key": "", "year": "", "title": "Choumane2020friend", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Friend Recommendation based on Hashtags Analysis\"\nauthors: Choumane Ali, Ibrahim Zein Al Abidin\nconference: Journal of Computer Science: Theory and Application, vol.\nyear: 2020\nbibkey: choumane2020friend\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2003.03531\"}\ntags: []\n---\nSocial networks include millions of users constantly looking for new relationships for personal or professional purposes. Social network sites recommend friends based on relationship features and content information. A significant part of information shared every day is spread in Hashtags. None of the existing content-based recommender systems uses the semantic of hashtags while suggesting new friends. Currently, hashtags are considered as strings without looking at their meanings. Social network sites group together people sharing exactly the same hashtags and never semantically close ones. We think that hashtags encapsulate some people interests. In this paper, we propose a framework showing how a recommender system can benefit from hashtags to enrich users' profiles. This framework consists of three main components: (1) constructing user's profile based on shared hashtags, (2) matching method that computes semantic similarity between profiles, (3) grouping semantically close users using clustering technics. The proposed framework has been tested on a Twitter dataset from the Stanford Large Network Dataset Collection consisting of 81306 profiles.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-25.55942153930664, 10.914382934570312]}, {"key": "", "year": "", "title": "Chowdhury2019an", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"An Efficient Approach for Super and Nested Term Indexing and Retrieval\"\nauthors: Chowdhury Md Faisal Mahbub, Farrell Robert\nconference: Arxiv\nyear: 2019\nbibkey: chowdhury2019an\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1905.09761\"}\ntags: ['ARXIV']\n---\nThis paper describes a new approach, called Terminological Bucket Indexing (TBI), for efficient indexing and retrieval of both nested and super terms using a single method. We propose a hybrid data structure for facilitating faster indexing building. An evaluation of our approach with respect to widely used existing approaches on several publicly available dataset is provided. Compared to Trie based approaches, TBI provides comparable performance on nested term retrieval and far superior performance on super term retrieval. Compared to traditional hash table, TBI needs 80\\% less time for indexing.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [13.269834518432617, -5.827493190765381]}, {"key": "", "year": "", "title": "Christiani2016set", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Set Similarity Search Beyond MinHash\"\nauthors: Christiani Tobias, Pagh Rasmus\nconference: Arxiv\nyear: 2016\nbibkey: christiani2016set\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1612.07710\"}\ntags: ['ARXIV', 'LSH']\n---\nWe consider the problem of approximate set similarity search under Braun-Blanquet similarity $B(\\mathbf\\{x\\}, \\mathbf\\{y\\}) = |\\mathbf\\{x\\} \\cap \\mathbf\\{y\\}| / \\max(|\\mathbf\\{x\\}|, |\\mathbf\\{y\\}|)$. The $(b_2, b_2)$-approximate Braun-Blanquet similarity search problem is to preprocess a collection of sets $P$ such that, given a query set $\\mathbf\\{q\\}$, if there exists $\\mathbf\\{x\\} \\in P$ with $B(\\mathbf\\{q\\}, \\mathbf\\{x\\}) \\geq b_1$, then we can efficiently return $\\mathbf\\{x\\}' \\in P$ with $B(\\mathbf\\{q\\}, \\mathbf\\{x\\}') &gt; b_2$. We present a simple data structure that solves this problem with space usage $O(n^\\{1+\\rho\\}\\log n + \\sum_\\{\\mathbf\\{x\\} \\in P\\}|\\mathbf\\{x\\}|)$ and query time $O(|\\mathbf\\{q\\}|n^\\{\\rho\\} \\log n)$ where $n = |P|$ and $\\rho = \\log(1/b_1)/\\log(1/b_2)$. Making use of existing lower bounds for locality-sensitive hashing by O'Donnell et al. (TOCT 2014) we show that this value of $\\rho$ is tight across the parameter space, i.e., for every choice of constants $0 &lt; b_2 &lt; b_1 &lt; 1$. In the case where all sets have the same size our solution strictly improves upon the value of $\\rho$ that can be obtained through the use of state-of-the-art data-independent techniques in the Indyk-Motwani locality-sensitive hashing framework (STOC 1998) such as Broder's MinHash (CCS 1997) for Jaccard similarity and Andoni et al.'s cross-polytope LSH (NIPS 2015) for cosine similarity. Surprisingly, even though our solution is data-independent, for a large part of the parameter space we outperform the currently best data-dependent method by Andoni and Razenshteyn (STOC 2015).\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-11.221668243408203, -26.38559913635254]}, {"key": "", "year": "", "title": "Christiani2017fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast Locality-Sensitive Hashing Frameworks for Approximate Near Neighbor Search\"\nauthors: Christiani Tobias\nconference: Arxiv\nyear: 2017\nbibkey: christiani2017fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1708.07586\"}\ntags: ['ARXIV', 'FOCS', 'LSH']\n---\nThe Indyk-Motwani Locality-Sensitive Hashing (LSH) framework (STOC 1998) is a general technique for constructing a data structure to answer approximate near neighbor queries by using a distribution $\\mathcal\\{H\\}$ over locality-sensitive hash functions that partition space. For a collection of $n$ points, after preprocessing, the query time is dominated by $O(n^\\{\\rho\\} \\log n)$ evaluations of hash functions from $\\mathcal\\{H\\}$ and $O(n^\\{\\rho\\})$ hash table lookups and distance computations where $\\rho \\in (0,1)$ is determined by the locality-sensitivity properties of $\\mathcal\\{H\\}$. It follows from a recent result by Dahlgaard et al. (FOCS 2017) that the number of locality-sensitive hash functions can be reduced to $O(\\log^2 n)$, leaving the query time to be dominated by $O(n^\\{\\rho\\})$ distance computations and $O(n^\\{\\rho\\} \\log n)$ additional word-RAM operations. We state this result as a general framework and provide a simpler analysis showing that the number of lookups and distance computations closely match the Indyk-Motwani framework, making it a viable replacement in practice. Using ideas from another locality-sensitive hashing framework by Andoni and Indyk (SODA 2006) we are able to reduce the number of additional word-RAM operations to $O(n^\\rho)$.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-11.594330787658691, -22.548173904418945]}, {"key": "", "year": "", "title": "Christiani2017scalable", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Scalable and robust set similarity join\"\nauthors: Christiani Tobias, Pagh Rasmus, Sivertsen Johan\nconference: Arxiv\nyear: 2017\nbibkey: christiani2017scalable\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1707.06814\"}\ntags: ['ARXIV']\n---\nSet similarity join is a fundamental and well-studied database operator. It is usually studied in the exact setting where the goal is to compute all pairs of sets that exceed a given similarity threshold (measured e.g. as Jaccard similarity). But set similarity join is often used in settings where 100% recall may not be important --- indeed, where the exact set similarity join is itself only an approximation of the desired result set. We present a new randomized algorithm for set similarity join that can achieve any desired recall up to 100%, and show theoretically and empirically that it significantly improves on existing methods. The present state-of-the-art exact methods are based on prefix-filtering, the performance of which depends on the data set having many rare tokens. Our method is robust against the absence of such structure in the data. At 90% recall our algorithm is often more than an order of magnitude faster than state-of-the-art exact methods, depending on how well a data set lends itself to prefix filtering. Our experiments on benchmark data sets also show that the method is several times faster than comparable approximate methods. Our algorithm makes use of recent theoretical advances in high-dimensional sketching and indexing that we believe to be of wider relevance to the data engineering community.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [0.042038533836603165, -22.027589797973633]}, {"key": "", "year": "", "title": "Christiani2019algorithms", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Algorithms for Similarity Search and Pseudorandomness\"\nauthors: Christiani Tobias\nconference: Arxiv\nyear: 2019\nbibkey: christiani2019algorithms\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1906.09430\"}\ntags: ['ARXIV']\n---\nWe study the problem of approximate near neighbor (ANN) search and show the following results: - An improved framework for solving the ANN problem using locality-sensitive hashing, reducing the number of evaluations of locality-sensitive hash functions and the word-RAM complexity compared to the standard framework. - A framework for solving the ANN problem with space-time tradeoffs as well as tight upper and lower bounds for the space-time tradeoff of framework solutions to the ANN problem under cosine similarity. - A novel approach to solving the ANN problem on sets along with a matching lower bound, improving the state of the art. - A self-tuning version of the algorithm is shown through experiments to outperform existing similarity join algorithms. - Tight lower bounds for asymmetric locality-sensitive hashing which has applications to the approximate furthest neighbor problem, orthogonal vector search, and annulus queries. - A proof of the optimality of a well-known Boolean locality-sensitive hashing scheme. We study the problem of efficient algorithms for producing high-quality pseudorandom numbers and obtain the following results: - A deterministic algorithm for generating pseudorandom numbers of arbitrarily high quality in constant time using near-optimal space. - A randomized construction of a family of hash functions that outputs pseudorandom numbers of arbitrarily high quality with space usage and running time nearly matching known cell-probe lower bounds.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-8.886222839355469, -21.631441116333008]}, {"key": "", "year": "", "title": "Christiani2020dartminhash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"DartMinHash: Fast Sketching for Weighted Sets\"\nauthors: Christiani Tobias\nconference: Arxiv\nyear: 2020\nbibkey: christiani2020dartminhash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2005.11547\"}\ntags: ['ARXIV']\n---\nWeighted minwise hashing is a standard dimensionality reduction technique with applications to similarity search and large-scale kernel machines. We introduce a simple algorithm that takes a weighted set $x \\in \\mathbb\\{R\\}_\\{\\geq 0\\}^\\{d\\}$ and computes $k$ independent minhashes in expected time $O(k \\log k + \\Vert x \\Vert_\\{0\\}\\log( \\Vert x \\Vert_1 + 1/\\Vert x \\Vert_1))$, improving upon the state-of-the-art BagMinHash algorithm (KDD '18) and representing the fastest weighted minhash algorithm for sparse data. Our experiments show running times that scale better with $k$ and $\\Vert x \\Vert_0$ compared to ICWS (ICDM '10) and BagMinhash, obtaining $10$x speedups in common use cases. Our approach also gives rise to a technique for computing fully independent locality-sensitive hash values for $(L, K)$-parameterized approximate near neighbor search under weighted Jaccard similarity in optimal expected time $O(LK + \\Vert x \\Vert_0)$, improving on prior work even in the case of unweighted sets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-10.632241249084473, -20.73509407043457]}, {"key": "", "year": "", "title": "Chung2008tight", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Tight Bounds for Hashing Block Sources\"\nauthors: Chung Kai-Min, Vadhan Salil\nconference: Arxiv\nyear: 2008\nbibkey: chung2008tight\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/0806.1948\"}\ntags: ['ARXIV']\n---\nIt is known that if a 2-universal hash function $H$ is applied to elements of a {\\em block source} $(X_1,...,X_T)$, where each item $X_i$ has enough min-entropy conditioned on the previous items, then the output distribution $(H,H(X_1),...,H(X_T))$ will be ``close'' to the uniform distribution. We provide improved bounds on how much min-entropy per item is required for this to hold, both when we ask that the output be close to uniform in statistical distance and when we only ask that it be statistically close to a distribution with small collision probability. In both cases, we reduce the dependence of the min-entropy on the number $T$ of items from $2\\log T$ in previous work to $\\log T$, which we show to be optimal. This leads to corresponding improvements to the recent results of Mitzenmacher and Vadhan (SODA `08) on the analysis of hashing-based algorithms and data structures when the data items come from a block source.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-12.833251953125, -19.002010345458984]}, {"key": "", "year": "", "title": "Chung2022scaling", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Scaling Cross-Domain Content-Based Image Retrieval for E-commerce Snap and Search Application\"\nauthors: Chung Isaac Kwan Yin, Tran Minh, Nussinovitch Eran\nconference: Arxiv\nyear: 2022\nbibkey: chung2022scaling\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2204.11593\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nIn this industry talk at ECIR 2022, we illustrate how we approach the main challenges from large scale cross-domain content-based image retrieval using a cascade method and a combination of our visual search and classification capabilities. Specifically, we present a system that is able to handle the scale of the data for e-commerce usage and the cross-domain nature of the query and gallery image pools. We showcase the approach applied in real-world e-commerce snap and search use case and its impact on ranking and latency performance.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [27.730670928955078, 2.7852442264556885]}, {"key": "", "year": "", "title": "Cis\u0142ak2015a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A practical index for approximate dictionary matching with few mismatches\"\nauthors: Cis\u0142ak Aleksander, Grabowski Szymon\nconference: Arxiv\nyear: 2015\nbibkey: cis\u0142ak2015a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1501.04948\"}\ntags: ['ARXIV']\n---\nApproximate dictionary matching is a classic string matching problem (checking if a query string occurs in a collection of strings) with applications in, e.g., spellchecking, online catalogs, geolocation, and web searchers. We present a surprisingly simple solution called a split index, which is based on the Dirichlet principle, for matching a keyword with few mismatches, and experimentally show that it offers competitive space-time tradeoffs. Our implementation in the C++ language is focused mostly on data compaction, which is beneficial for the search speed (e.g., by being cache friendly). We compare our solution with other algorithms and we show that it performs better for the Hamming distance. Query times in the order of 1 microsecond were reported for one mismatch for the dictionary size of a few megabytes on a medium-end PC. We also demonstrate that a basic compression technique consisting in $q$-gram substitution can significantly reduce the index size (up to 50% of the input text size for the DNA), while still keeping the query time relatively low.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-2.267611503601074, -15.856780052185059]}, {"key": "", "year": "", "title": "Cis\u0142ak2017lightweight", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Lightweight Fingerprints for Fast Approximate Keyword Matching Using Bitwise Operations\"\nauthors: Cis\u0142ak Aleksander, Grabowski Szymon\nconference: Arxiv\nyear: 2017\nbibkey: cis\u0142ak2017lightweight\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1711.08475\"}\ntags: ['ARXIV']\n---\nWe aim to speed up approximate keyword matching by storing a lightweight, fixed-size block of data for each string, called a fingerprint. These work in a similar way to hash values; however, they can be also used for matching with errors. They store information regarding symbol occurrences using individual bits, and they can be compared against each other with a constant number of bitwise operations. In this way, certain strings can be deduced to be at least within the distance $k$ from each other (using Hamming or Levenshtein distance) without performing an explicit verification. We show experimentally that for a preprocessed collection of strings, fingerprints can provide substantial speedups for $k = 1$, namely over $2.5$ times for the Hamming distance and over $10$ times for the Levenshtein distance. Tests were conducted on synthetic and real-world English and URL data.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-24.302940368652344, -3.3948135375976562]}, {"key": "", "year": "", "title": "Cleveland2020content", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Content-based Music Similarity with Triplet Networks\"\nauthors: Cleveland Joseph, Cheng Derek, Zhou Michael, Joachims Thorsten, Turnbull Douglas\nconference: Arxiv\nyear: 2020\nbibkey: cleveland2020content\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2008.04938\"}\ntags: ['ARXIV']\n---\nWe explore the feasibility of using triplet neural networks to embed songs based on content-based music similarity. Our network is trained using triplets of songs such that two songs by the same artist are embedded closer to one another than to a third song by a different artist. We compare two models that are trained using different ways of picking this third song: at random vs. based on shared genre labels. Our experiments are conducted using songs from the Free Music Archive and use standard audio features. The initial results show that shallow Siamese networks can be used to embed music for a simple artist retrieval task.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [29.34844970703125, -9.010794639587402]}, {"key": "", "year": "", "title": "Coates2023identifying", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Identifying document similarity using a fast estimation of the Levenshtein Distance based on compression and signatures\"\nauthors: Coates Peter, Breitinger Frank\nconference: Arxiv\nyear: 2023\nbibkey: coates2023identifying\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2307.11496\"}\ntags: ['ARXIV']\n---\nIdentifying document similarity has many applications, e.g., source code analysis or plagiarism detection. However, identifying similarities is not trivial and can be time complex. For instance, the Levenshtein Distance is a common metric to define the similarity between two documents but has quadratic runtime which makes it impractical for large documents where large starts with a few hundred kilobytes. In this paper, we present a novel concept that allows estimating the Levenshtein Distance: the algorithm first compresses documents to signatures (similar to hash values) using a user-defined compression ratio. Signatures can then be compared against each other (some constrains apply) where the outcome is the estimated Levenshtein Distance. Our evaluation shows promising results in terms of runtime efficiency and accuracy. In addition, we introduce a significance score allowing examiners to set a threshold and identify related documents.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [15.840254783630371, -12.396864891052246]}, {"key": "", "year": "", "title": "Coluzzi2024binomialhash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"BinomialHash: A Constant Time, Minimal Memory Consistent Hash Algorithm\"\nauthors: Coluzzi Massimo, Brocco Amos, Antonucci Alessandro\nconference: Arxiv\nyear: 2024\nbibkey: coluzzi2024binomialhash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2406.19836\"}\ntags: ['ARXIV']\n---\nConsistent hashing is employed in distributed systems and networking applications to evenly and effectively distribute data across a cluster of nodes. This paper introduces BinomialHash, a consistent hashing algorithm that operates in constant time and requires minimal memory. We provide a detailed explanation of the algorithm, offer a pseudo-code implementation, and formally establish its strong theoretical guarantees.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-28.457666397094727, -14.051280975341797]}, {"key": "", "year": "", "title": "Conde2022general", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"General Image Descriptors for Open World Image Retrieval using ViT CLIP\"\nauthors: Conde Marcos V., Aerlic Ivan, J\u00e9gou Simon\nconference: Arxiv\nyear: 2022\nbibkey: conde2022general\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2210.11141\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nThe Google Universal Image Embedding (GUIE) Challenge is one of the first competitions in multi-domain image representations in the wild, covering a wide distribution of objects: landmarks, artwork, food, etc. This is a fundamental computer vision problem with notable applications in image retrieval, search engines and e-commerce. In this work, we explain our 4th place solution to the GUIE Challenge, and our \"bag of tricks\" to fine-tune zero-shot Vision Transformers (ViT) pre-trained using CLIP.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [29.271821975708008, 4.26561975479126]}, {"key": "", "year": "", "title": "Conjeti2016deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Residual Hashing\"\nauthors: Conjeti Sailesh, Roy Abhijit Guha, Katouzian Amin, Navab Nassir\nconference: Arxiv\nyear: 2016\nbibkey: conjeti2016deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1612.05400\"}\ntags: ['ARXIV', 'Image Retrieval', 'Quantisation', 'Supervised', 'TIP']\n---\nHashing aims at generating highly compact similarity preserving code words which are well suited for large-scale image retrieval tasks. Most existing hashing methods first encode the images as a vector of hand-crafted features followed by a separate binarization step to generate hash codes. This two-stage process may produce sub-optimal encoding. In this paper, for the first time, we propose a deep architecture for supervised hashing through residual learning, termed Deep Residual Hashing (DRH), for an end-to-end simultaneous representation learning and hash coding. The DRH model constitutes four key elements: (1) a sub-network with multiple stacked residual blocks; (2) hashing layer for binarization; (3) supervised retrieval loss function based on neighbourhood component analysis for similarity preserving embedding; and (4) hashing related losses and regularisation to control the quantization error and improve the quality of hash coding. We present results of extensive experiments on a large public chest x-ray image database with co-morbidities and discuss the outcome showing substantial improvements over the latest state-of-the art methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [4.518051624298096, 4.659256458282471]}, {"key": "", "year": "", "title": "Conjeti2017learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning Robust Hash Codes for Multiple Instance Image Retrieval\"\nauthors: Conjeti Sailesh, Paschali Magdalini, Katouzian Amin, Navab Nassir\nconference: Arxiv\nyear: 2017\nbibkey: conjeti2017learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1703.05724\"}\ntags: ['ARXIV', 'Graph', 'Image Retrieval', 'TIP', 'TOM']\n---\nIn this paper, for the first time, we introduce a multiple instance (MI) deep hashing technique for learning discriminative hash codes with weak bag-level supervision suited for large-scale retrieval. We learn such hash codes by aggregating deeply learnt hierarchical representations across bag members through a dedicated MI pool layer. For better trainability and retrieval quality, we propose a two-pronged approach that includes robust optimization and training with an auxiliary single instance hashing arm which is down-regulated gradually. We pose retrieval for tumor assessment as an MI problem because tumors often coexist with benign masses and could exhibit complementary signatures when scanned from different anatomical views. Experimental validations on benchmark mammography and histology datasets demonstrate improved retrieval performance over the state-of-the-art methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-8.0799560546875, 17.10740852355957]}, {"key": "", "year": "", "title": "Conway2018optimal", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Optimal Hashing in External Memory\"\nauthors: Conway Alex, Farach-Colton Martin, Shilane Philip\nconference: Arxiv\nyear: 2018\nbibkey: conway2018optimal\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1805.09423\"}\ntags: ['ARXIV']\n---\nHash tables are a ubiquitous class of dictionary data structures. However, standard hash table implementations do not translate well into the external memory model, because they do not incorporate locality for insertions. Iacono and Patracsu established an update/query tradeoff curve for external hash tables: a hash table that performs insertions in $O(\\lambda/B)$ amortized IOs requires $\\Omega(\\log_\\lambda N)$ expected IOs for queries, where $N$ is the number of items that can be stored in the data structure, $B$ is the size of a memory transfer, $M$ is the size of memory, and $\\lambda$ is a tuning parameter. They provide a hashing data structure that meets this curve for $\\lambda$ that is $\\Omega(\\log\\log M + \\log_M N)$. Their data structure, which we call an \\defn{IP hash table}, is complicated and, to the best of our knowledge, has not been implemented. In this paper, we present a new and much simpler optimal external memory hash table, the \\defn{Bundle of Arrays Hash Table} (BOA). BOAs are based on size-tiered LSMs, a well-studied data structure, and are almost as easy to implement. The BOA is optimal for a narrower range of $\\lambda$. However, the simplicity of BOAs allows them to be readily modified to achieve the following results: \\begin{itemize} \\item A new external memory data structure, the \\defn{Bundle of Trees Hash Table} (BOT), that matches the performance of the IP hash table, while retaining some of the simplicity of the BOAs. \\item The \\defn{cache-oblivious Bundle of Trees Hash Table} (COBOT), the first cache-oblivious hash table. This data structure matches the optimality of BOTs and IP hash tables over the same range of $\\lambda$. \\end{itemize}\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-20.514982223510742, -17.945289611816406]}, {"key": "", "year": "", "title": "Corbi\u00e8re2017leveraging", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Leveraging Weakly Annotated Data for Fashion Image Retrieval and Label Prediction\"\nauthors: Corbi\u00e8re Charles, Ben-Younes Hedi, Ram\u00e9 Alexandre, Ollion Charles\nconference: \nyear: 2017\nbibkey: corbi\u00e8re2017leveraging\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1709.09426\"}\ntags: ['Image Retrieval', 'Supervised', 'Weakly Supervised']\n---\nIn this paper, we present a method to learn a visual representation adapted for e-commerce products. Based on weakly supervised learning, our model learns from noisy datasets crawled on e-commerce website catalogs and does not require any manual labeling. We show that our representation can be used for downward classification tasks over clothing categories with different levels of granularity. We also demonstrate that the learnt representation is suitable for image retrieval. We achieve nearly state-of-art results on the DeepFashion In-Shop Clothes Retrieval and Categories Attributes Prediction tasks, without using the provided training set.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [6.921146392822266, 21.171817779541016]}, {"key": "", "year": "", "title": "Correya2018large", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Large-Scale Cover Song Detection in Digital Music Libraries Using Metadata, Lyrics and Audio Features\"\nauthors: Correya Albin Andrew, Hennequin Romain, Arcos Micka\u00ebl\nconference: Arxiv\nyear: 2018\nbibkey: correya2018large\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1808.10351\"}\ntags: ['ARXIV']\n---\nCover song detection is a very relevant task in Music Information Retrieval (MIR) studies and has been mainly addressed using audio-based systems. Despite its potential impact in industrial contexts, low performances and lack of scalability have prevented such systems from being adopted in practice for large applications. In this work, we investigate whether textual music information (such as metadata and lyrics) can be used along with audio for large-scale cover identification problem in a wide digital music library. We benchmark this problem using standard text and state of the art audio similarity measures. Our studies shows that these methods can significantly increase the accuracy and scalability of cover detection systems on Million Song Dataset (MSD) and Second Hand Song (SHS) datasets. By only leveraging standard tf-idf based text similarity measures on song titles and lyrics, we achieved 35.5% of absolute increase in mean average precision compared to the current scalable audio content-based state of the art methods on MSD. These experimental results suggests that new methodologies can be encouraged among researchers to leverage and identify more sophisticated NLP-based techniques to improve current cover song identification systems in digital music libraries with metadata.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [29.803848266601562, -6.157434940338135]}, {"key": "", "year": "", "title": "Coz2022post", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Post-quantum hash functions using $\\mathrm{SL}_n(\\mathbb{F}_p)$\"\nauthors: Coz Corentin Le, Battarbee Christopher, Flores Ram\u00f3n, Koberda Thomas, Kahrobaei Delaram\nconference: Arxiv\nyear: 2022\nbibkey: coz2022post\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2207.03987\"}\ntags: ['ARXIV', 'Graph']\n---\nWe define new families of Tillich-Z\\'emor hash functions, using higher dimensional special linear groups over finite fields as platforms. The Cayley graphs of these groups combine fast mixing properties and high girth, which together give rise to good preimage and collision resistance of the corresponding hash functions. We justify the claim that the resulting hash functions are post-quantum secure.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-29.720766067504883, -1.8749924898147583]}, {"key": "", "year": "", "title": "Cozzolino2017recasting", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Recasting Residual-based Local Descriptors as Convolutional Neural Networks: an Application to Image Forgery Detection\"\nauthors: Cozzolino Davide, Poggi Giovanni, Verdoliva Luisa\nconference: Arxiv\nyear: 2017\nbibkey: cozzolino2017recasting\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1703.04615\"}\ntags: ['ARXIV', 'CNN', 'Deep Learning']\n---\nLocal descriptors based on the image noise residual have proven extremely effective for a number of forensic applications, like forgery detection and localization. Nonetheless, motivated by promising results in computer vision, the focus of the research community is now shifting on deep learning. In this paper we show that a class of residual-based descriptors can be actually regarded as a simple constrained convolutional neural network (CNN). Then, by relaxing the constraints, and fine-tuning the net on a relatively small training set, we obtain a significant performance improvement with respect to the conventional detector.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [13.940113067626953, 24.66754150390625]}, {"key": "", "year": "", "title": "Cui2020exchnet", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"ExchNet: A Unified Hashing Network for Large-Scale Fine-Grained Image Retrieval\"\nauthors: Cui Quan, Jiang Qing-Yuan, Wei Xiu-Shen, Li Wu-Jun, Yoshie Osamu\nconference: Arxiv\nyear: 2020\nbibkey: cui2020exchnet\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2008.01369\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nRetrieving content relevant images from a large-scale fine-grained dataset could suffer from intolerably slow query speed and highly redundant storage cost, due to high-dimensional real-valued embeddings which aim to distinguish subtle visual differences of fine-grained objects. In this paper, we study the novel fine-grained hashing topic to generate compact binary codes for fine-grained images, leveraging the search and storage efficiency of hash learning to alleviate the aforementioned problems. Specifically, we propose a unified end-to-end trainable network, termed as ExchNet. Based on attention mechanisms and proposed attention constraints, it can firstly obtain both local and global features to represent object parts and whole fine-grained objects, respectively. Furthermore, to ensure the discriminative ability and semantic meaning's consistency of these part-level features across images, we design a local feature alignment approach by performing a feature exchanging operation. Later, an alternative learning algorithm is employed to optimize the whole ExchNet and then generate the final binary hash codes. Validated by extensive experiments, our proposal consistently outperforms state-of-the-art generic hashing methods on five fine-grained datasets, which shows our effectiveness. Moreover, compared with other approximate nearest neighbor methods, ExchNet achieves the best speed-up and storage reduction, revealing its efficiency and practicality.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [0.9106864929199219, 8.544434547424316]}, {"key": "", "year": "", "title": "Cunha2017fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast and Simple Jumbled Indexing for Binary RLE Strings\"\nauthors: Cunha Lu\u00eds, Dantas Simone, Gagie Travis, Wittler Roland, Kowada Luis, Stoye Jens\nconference: Arxiv\nyear: 2017\nbibkey: cunha2017fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1702.01280\"}\ntags: ['ARXIV']\n---\nImportant papers have appeared recently on the problem of indexing binary strings for jumbled pattern matching, and further lowering the time bounds in terms of the input size would now be a breakthrough with broad implications. We can still make progress on the problem, however, by considering other natural parameters. Badkobeh et al.\\ (IPL, 2013) and Amir et al.\\ (TCS, 2016) gave algorithms that index a binary string in $O (n + \\rho^2 \\log \\rho)$ time, where $n$ is the length and $\\rho$ is the number of runs, and Giaquinta and Grabowski (IPL, 2013) gave one that runs in $O (n + \\rho^2)$ time. In this paper we propose a new and very simple algorithm that also runs in $O(n + \\rho^2)$ time and can be extended either so that the index returns the position of a match (if there is one), or so that the algorithm uses only $O (n)$ bits of space.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-4.633456707000732, -13.916683197021484]}, {"key": "", "year": "", "title": "Curtin2016fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast approximate furthest neighbors with data-dependent hashing\"\nauthors: Curtin Ryan R., Gardner Andrew B.\nconference: Arxiv\nyear: 2016\nbibkey: curtin2016fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1605.09784\"}   - {name: \"Paper\", url: \"http://www.mlpack.org).\"}\ntags: ['ARXIV']\n---\nWe present a novel hashing strategy for approximate furthest neighbor search that selects projection bases using the data distribution. This strategy leads to an algorithm, which we call DrusillaHash, that is able to outperform existing approximate furthest neighbor strategies. Our strategy is motivated by an empirical study of the behavior of the furthest neighbor search problem, which lends intuition for where our algorithm is most useful. We also present a variant of the algorithm that gives an absolute approximation guarantee; to our knowledge, this is the first such approximate furthest neighbor hashing approach to give such a guarantee. Performance studies indicate that DrusillaHash can achieve comparable levels of approximation to other algorithms while giving up to an order of magnitude speedup. An implementation is available in the mlpack machine learning library (found at http://www.mlpack.org).\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [9.171537399291992, -15.386821746826172]}, {"key": "", "year": "", "title": "Curt\u00f32017segmentation", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Segmentation of Objects by Hashing\"\nauthors: Curt\u00f3 J. D., Zarza I. C., Smola Alex, van Gool Luc\nconference: Arxiv\nyear: 2017\nbibkey: curt\u00f32017segmentation\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1702.08160\"}\ntags: ['ARXIV', 'TOM']\n---\nWe propose a novel approach to address the problem of Simultaneous Detection and Segmentation introduced in [Hariharan et al 2014]. Using the hierarchical structures first presented in [Arbel\\'aez et al 2011] we use an efficient and accurate procedure that exploits the feature information of the hierarchy using Locality Sensitive Hashing. We build on recent work that utilizes convolutional neural networks to detect bounding boxes in an image [Ren et al 2015] and then use the top similar hierarchical region that best fits each bounding box after hashing, we call this approach C&amp;Z Segmentation. We then refine our final segmentation results by automatic hierarchical pruning. C&amp;Z Segmentation introduces a train-free alternative to Hypercolumns [Hariharan et al 2015]. We conduct extensive experiments on PASCAL VOC 2012 segmentation dataset, showing that C&amp;Z gives competitive state-of-the-art segmentations of objects.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [20.005157470703125, -6.805352687835693]}, {"key": "", "year": "", "title": "Dadaneh2020pairwise", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Pairwise Supervised Hashing with Bernoulli Variational Auto-Encoder and Self-Control Gradient Estimator\"\nauthors: Dadaneh Siamak Zamani, Boluki Shahin, Yin Mingzhang, Zhou Mingyuan, Qian Xiaoning\nconference: Uncertainty in Artificial Intelligence Conference\nyear: 2020\nbibkey: dadaneh2020pairwise\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2005.10477\"}\ntags: ['Supervised']\n---\nSemantic hashing has become a crucial component of fast similarity search in many large-scale information retrieval systems, in particular, for text data. Variational auto-encoders (VAEs) with binary latent variables as hashing codes provide state-of-the-art performance in terms of precision for document retrieval. We propose a pairwise loss function with discrete latent VAE to reward within-class similarity and between-class dissimilarity for supervised hashing. Instead of solving the optimization relying on existing biased gradient estimators, an unbiased low-variance gradient estimator is adopted to optimize the hashing function by evaluating the non-differentiable loss function over two correlated sets of binary hashing codes to control the variance of gradient estimates. This new semantic hashing framework achieves superior performance compared to the state-of-the-arts, as demonstrated by our comprehensive experiments.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-3.131803512573242, -3.3637681007385254]}, {"key": "", "year": "", "title": "Dahlgaard2014approximately", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Approximately Minwise Independence with Twisted Tabulation\"\nauthors: Dahlgaard S\u00f8ren, Thorup Mikkel\nconference: Arxiv\nyear: 2014\nbibkey: dahlgaard2014approximately\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1404.6724\"}\ntags: ['ARXIV', 'FOCS']\n---\nA random hash function $h$ is $\\varepsilon$-minwise if for any set $S$, $|S|=n$, and element $x\\in S$, $\\Pr[h(x)=\\min h(S)]=(1\\pm\\varepsilon)/n$. Minwise hash functions with low bias $\\varepsilon$ have widespread applications within similarity estimation. Hashing from a universe $[u]$, the twisted tabulation hashing of P\\v{a}tra\\c{s}cu and Thorup [SODA'13] makes $c=O(1)$ lookups in tables of size $u^\\{1/c\\}$. Twisted tabulation was invented to get good concentration for hashing based sampling. Here we show that twisted tabulation yields $\\tilde O(1/u^\\{1/c\\})$-minwise hashing. In the classic independence paradigm of Wegman and Carter [FOCS'79] $\\tilde O(1/u^\\{1/c\\})$-minwise hashing requires $\\Omega(\\log u)$-independence [Indyk SODA'99]. P\\v{a}tra\\c{s}cu and Thorup [STOC'11] had shown that simple tabulation, using same space and lookups yields $\\tilde O(1/n^\\{1/c\\})$-minwise independence, which is good for large sets, but useless for small sets. Our analysis uses some of the same methods, but is much cleaner bypassing a complicated induction argument.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-13.45357894897461, -22.304746627807617]}, {"key": "", "year": "", "title": "Dahlgaard2014hashing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hashing for statistics over k-partitions\"\nauthors: Dahlgaard S\u00f8ren, Knudsen Mathias B\u00e6k Tejs, Rotenberg Eva, Thorup Mikkel\nconference: Arxiv\nyear: 2014\nbibkey: dahlgaard2014hashing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1411.7191\"}\ntags: ['ARXIV', 'FOCS']\n---\nIn this paper we analyze a hash function for $k$-partitioning a set into bins, obtaining strong concentration bounds for standard algorithms combining statistics from each bin. This generic method was originally introduced by Flajolet and Martin~[FOCS'83] in order to save a factor $\\Omega(k)$ of time per element over $k$ independent samples when estimating the number of distinct elements in a data stream. It was also used in the widely used HyperLogLog algorithm of Flajolet et al.~[AOFA'97] and in large-scale machine learning by Li et al.~[NIPS'12] for minwise estimation of set similarity. The main issue of $k$-partition, is that the contents of different bins may be highly correlated when using popular hash functions. This means that methods of analyzing the marginal distribution for a single bin do not apply. Here we show that a tabulation based hash function, mixed tabulation, does yield strong concentration bounds on the most popular applications of $k$-partitioning similar to those we would get using a truly random hash function. The analysis is very involved and implies several new results of independent interest for both simple and double tabulation, e.g. a simple and efficient construction for invertible bloom filters and uniform hashing on a given set.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-12.937304496765137, -16.96912384033203]}, {"key": "", "year": "", "title": "Dahlgaard2017practical", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Practical Hash Functions for Similarity Estimation and Dimensionality Reduction\"\nauthors: Dahlgaard S\u00f8ren, Knudsen Mathias B\u00e6k Tejs, Thorup Mikkel\nconference: Arxiv\nyear: 2017\nbibkey: dahlgaard2017practical\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1711.08797\"}\ntags: ['ARXIV', 'FOCS', 'LSH', 'TIP']\n---\nHashing is a basic tool for dimensionality reduction employed in several aspects of machine learning. However, the perfomance analysis is often carried out under the abstract assumption that a truly random unit cost hash function is used, without concern for which concrete hash function is employed. The concrete hash function may work fine on sufficiently random input. The question is if it can be trusted in the real world when faced with more structured input. In this paper we focus on two prominent applications of hashing, namely similarity estimation with the one permutation hashing (OPH) scheme of Li et al. [NIPS'12] and feature hashing (FH) of Weinberger et al. [ICML'09], both of which have found numerous applications, i.e. in approximate near-neighbour search with LSH and large-scale classification with SVM. We consider mixed tabulation hashing of Dahlgaard et al.[FOCS'15] which was proved to perform like a truly random hash function in many applications, including OPH. Here we first show improved concentration bounds for FH with truly random hashing and then argue that mixed tabulation performs similar for sparse input. Our main contribution, however, is an experimental comparison of different hashing schemes when used inside FH, OPH, and LSH. We find that mixed tabulation hashing is almost as fast as the multiply-mod-prime scheme ax+b mod p. Mutiply-mod-prime is guaranteed to work well on sufficiently random data, but we demonstrate that in the above applications, it can lead to bias and poor concentration on both real-world and synthetic data. We also compare with the popular MurmurHash3, which has no proven guarantees. Mixed tabulation and MurmurHash3 both perform similar to truly random hashing in our experiments. However, mixed tabulation is 40% faster than MurmurHash3, and it has the proven guarantee of good performance on all possible input.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-14.385128021240234, -13.135534286499023]}, {"key": "", "year": "", "title": "Dai2017stochastic", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Stochastic Generative Hashing\"\nauthors: Dai Bo, Guo Ruiqi, Kumar Sanjiv, He Niao, Song Le\nconference: Arxiv\nyear: 2017\nbibkey: dai2017stochastic\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1701.02815\"}\ntags: ['ARXIV']\n---\nLearning-based binary hashing has become a powerful paradigm for fast search and retrieval in massive databases. However, due to the requirement of discrete outputs for the hash functions, learning such functions is known to be very challenging. In addition, the objective functions adopted by existing hashing techniques are mostly chosen heuristically. In this paper, we propose a novel generative approach to learn hash functions through Minimum Description Length principle such that the learned hash codes maximally compress the dataset and can also be used to regenerate the inputs. We also develop an efficient learning algorithm based on the stochastic distributional gradient, which avoids the notorious difficulty caused by binary output constraints, to jointly optimize the parameters of the hash function and the associated generative model. Extensive experiments on a variety of large-scale datasets show that the proposed method achieves better retrieval results than the existing state-of-the-art methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-18.235633850097656, -0.6429355144500732]}, {"key": "", "year": "", "title": "Dai2020convolutional", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Convolutional Embedding for Edit Distance\"\nauthors: Dai Xinyan, Yan Xiao, Zhou Kaiwen, Wang Yuxuan, Yang Han, Cheng James\nconference: Arxiv\nyear: 2020\nbibkey: dai2020convolutional\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2001.11692\"}\ntags: ['ARXIV', 'CNN', 'Deep Learning']\n---\nEdit-distance-based string similarity search has many applications such as spell correction, data de-duplication, and sequence alignment. However, computing edit distance is known to have high complexity, which makes string similarity search challenging for large datasets. In this paper, we propose a deep learning pipeline (called CNN-ED) that embeds edit distance into Euclidean distance for fast approximate similarity search. A convolutional neural network (CNN) is used to generate fixed-length vector embeddings for a dataset of strings and the loss function is a combination of the triplet loss and the approximation error. To justify our choice of using CNN instead of other structures (e.g., RNN) as the model, theoretical analysis is conducted to show that some basic operations in our CNN model preserve edit distance. Experimental results show that CNN-ED outperforms data-independent CGK embedding and RNN-based GRU embedding in terms of both accuracy and efficiency by a large margin. We also show that string similarity search can be significantly accelerated using CNN-based embeddings, sometimes by orders of magnitude.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [7.779980182647705, 28.65645408630371]}, {"key": "", "year": "", "title": "Dangelo2012from", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"From Bits to Images: Inversion of Local Binary Descriptors\"\nauthors: d'Angelo Emmanuel, jacques Laurent, Alahi Alexandre, Vandergheynst Pierre\nconference: Arxiv\nyear: 2012\nbibkey: dangelo2012from\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1211.1265\"}\ntags: ['ARXIV', 'TIP']\n---\nLocal Binary Descriptors are becoming more and more popular for image matching tasks, especially when going mobile. While they are extensively studied in this context, their ability to carry enough information in order to infer the original image is seldom addressed. In this work, we leverage an inverse problem approach to show that it is possible to directly reconstruct the image content from Local Binary Descriptors. This process relies on very broad assumptions besides the knowledge of the pattern of the descriptor at hand. This generalizes previous results that required either a prior learning database or non-binarized features. Furthermore, our reconstruction scheme reveals differences in the way different Local Binary Descriptors capture and encode image information. Hence, the potential applications of our work are multiple, ranging from privacy issues caused by eavesdropping image keypoints streamed by mobile devices to the design of better descriptors through the visualization and the analysis of their geometric content.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [6.6565093994140625, 12.950094223022461]}, {"key": "", "year": "", "title": "Davoodi2019forestdsh", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"ForestDSH: A Universal Hash Design for Discrete Probability Distributions\"\nauthors: Davoodi Arash Gholami, Chang Sean, Yoo Hyun Gon, Baweja Anubhav, Mongia Mihir, Mohimani Hosein\nconference: DAMI\nyear: 2019\nbibkey: davoodi2019forestdsh\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1905.04559\"}\ntags: ['LSH']\n---\nIn this paper, we consider the problem of classification of $M$ high dimensional queries $y^1,\\cdots,y^M\\in B^S$ to $N$ high dimensional classes $x^1,\\cdots,x^N\\in A^S$ where $A$ and $B$ are discrete alphabets and the probabilistic model that relates data to the classes $P(x,y)$ is known. This problem has applications in various fields including the database search problem in mass spectrometry. The problem is analogous to the nearest neighbor search problem, where the goal is to find the data point in a database that is the most similar to a query point. The state of the art method for solving an approximate version of the nearest neighbor search problem in high dimensions is locality sensitive hashing (LSH). LSH is based on designing hash functions that map near points to the same buckets with a probability higher than random (far) points. To solve our high dimensional classification problem, we introduce distribution sensitive hashes that map jointly generated pairs $(x,y)\\sim P$ to the same bucket with probability higher than random pairs $x\\sim P^A$ and $y\\sim P^B$, where $P^A$ and $P^B$ are the marginal probability distributions of $P$. We design distribution sensitive hashes using a forest of decision trees and we show that the complexity of search grows with $O(N^\\{\\lambda^*(P)\\})$ where $\\lambda^*(P)$ is expressed in an analytical form. We further show that the proposed hashes perform faster than state of the art approximate nearest neighbor search methods for a range of probability distributions, in both theory and simulations. Finally, we apply our method to the spectral library search problem in mass spectrometry, and show that it is an order of magnitude faster than the state of the art methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-8.620352745056152, -26.2574462890625]}, {"key": "", "year": "", "title": "Defranca2014iterative", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Iterative Universal Hash Function Generator for Minhashing\"\nauthors: de Franca Fabricio Olivetti\nconference: Arxiv\nyear: 2014\nbibkey: defranca2014iterative\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1401.6124\"}\ntags: ['ARXIV', 'TIP']\n---\nMinhashing is a technique used to estimate the Jaccard Index between two sets by exploiting the probability of collision in a random permutation. In order to speed up the computation, a random permutation can be approximated by using an universal hash function such as the $h_\\{a,b\\}$ function proposed by Carter and Wegman. A better estimate of the Jaccard Index can be achieved by using many of these hash functions, created at random. In this paper a new iterative procedure to generate a set of $h_\\{a,b\\}$ functions is devised that eliminates the need for a list of random values and avoid the multiplication operation during the calculation. The properties of the generated hash functions remains that of an universal hash function family. This is possible due to the random nature of features occurrence on sparse datasets. Results show that the uniformity of hashing the features is maintaned while obtaining a speed up of up to $1.38$ compared to the traditional approach.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-9.565159797668457, -14.436898231506348]}, {"key": "", "year": "", "title": "Deherve2014a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A perceptual hash function to store and retrieve large scale DNA sequences\"\nauthors: De Herve Jocelyn De Goer, Kang Myoung-Ah, Bailly Xavier, Nguifo Engelbert Mephu\nconference: Arxiv\nyear: 2014\nbibkey: deherve2014a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1412.5517\"}\ntags: ['ARXIV', 'Graph']\n---\nThis paper proposes a novel approach for storing and retrieving massive DNA sequences.. The method is based on a perceptual hash function, commonly used to determine the similarity between digital images, that we adapted for DNA sequences. Perceptual hash function presented here is based on a Discrete Cosine Transform Sign Only (DCT-SO). Each nucleotide is encoded as a fixed gray level intensity pixel and the hash is calculated from its significant frequency characteristics. This results to a drastic data reduction between the sequence and the perceptual hash. Unlike cryptographic hash functions, perceptual hashes are not affected by \"avalanche effect\" and thus can be compared. The similarity distance between two hashes is estimated with the Hamming Distance, which is used to retrieve DNA sequences. Experiments that we conducted show that our approach is relevant for storing massive DNA sequences, and retrieving them.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [22.413766860961914, -16.854080200195312]}, {"key": "", "year": "", "title": "Dellafiore2024upper", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Upper bounds on the rate of linear $q$-ary $k$-hash codes\"\nauthors: Della Fiore Stefano, Dalai Marco\nconference: Arxiv\nyear: 2024\nbibkey: dellafiore2024upper\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2401.16288\"}\ntags: ['ARXIV']\n---\nThis paper presents new upper bounds on the rate of linear $k$-hash codes in $\\mathbb\\{F\\}_q^n$, $q\\geq k$, that is, codes with the property that any $k$ distinct codewords are all simultaneously distinct in at least one coordinate.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [4.624318599700928, -18.228670120239258]}, {"key": "", "year": "", "title": "Delmas2022artemis", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"ARTEMIS: Attention-based Retrieval with Text-Explicit Matching and Implicit Similarity\"\nauthors: Delmas Ginger, de Rezende Rafael Sampaio, Csurka Gabriela, Larlus Diane\nconference: Arxiv\nyear: 2022\nbibkey: delmas2022artemis\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2203.08101\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nAn intuitive way to search for images is to use queries composed of an example image and a complementary text. While the first provides rich and implicit context for the search, the latter explicitly calls for new traits, or specifies how some elements of the example image should be changed to retrieve the desired target image. Current approaches typically combine the features of each of the two elements of the query into a single representation, which can then be compared to the ones of the potential target images. Our work aims at shedding new light on the task by looking at it through the prism of two familiar and related frameworks: text-to-image and image-to-image retrieval. Taking inspiration from them, we exploit the specific relation of each query element with the targeted image and derive light-weight attention mechanisms which enable to mediate between the two complementary modalities. We validate our approach on several retrieval benchmarks, querying with images and their associated free-form text modifiers. Our method obtains state-of-the-art results without resorting to side information, multi-level features, heavy pre-training nor large architectures as in previous works.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [22.906681060791016, 4.337223529815674]}, {"key": "", "year": "", "title": "Deng2017learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning Deep Similarity Models with Focus Ranking for Fabric Image Retrieval\"\nauthors: Deng Daiguo, Wang Ruomei, Wu Hefeng, He Huayong, Li Qi, Luo Xiaonan\nconference: Arxiv\nyear: 2017\nbibkey: deng2017learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1712.10211\"}\ntags: ['ARXIV', 'CNN', 'GAN', 'Image Retrieval']\n---\nFabric image retrieval is beneficial to many applications including clothing searching, online shopping and cloth modeling. Learning pairwise image similarity is of great importance to an image retrieval task. With the resurgence of Convolutional Neural Networks (CNNs), recent works have achieved significant progresses via deep representation learning with metric embedding, which drives similar examples close to each other in a feature space, and dissimilar ones apart from each other. In this paper, we propose a novel embedding method termed focus ranking that can be easily unified into a CNN for jointly learning image representations and metrics in the context of fine-grained fabric image retrieval. Focus ranking aims to rank similar examples higher than all dissimilar ones by penalizing ranking disorders via the minimization of the overall cost attributed to similar samples being ranked below dissimilar ones. At the training stage, training samples are organized into focus ranking units for efficient optimization. We build a large-scale fabric image retrieval dataset (FIRD) with about 25,000 images of 4,300 fabrics, and test the proposed model on the FIRD dataset. Experimental results show the superiority of the proposed model over existing metric embedding models.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [13.056876182556152, 8.690755844116211]}, {"key": "", "year": "", "title": "Deng2019triplet", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Triplet-Based Deep Hashing Network for Cross-Modal Retrieval\"\nauthors: Deng Cheng, Chen Zhaojia, Liu Xianglong, Gao Xinbo, Tao Dacheng\nconference: Arxiv\nyear: 2019\nbibkey: deng2019triplet\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1904.02449\"}\ntags: ['ARXIV', 'Cross Modal', 'Graph']\n---\nGiven the benefits of its low storage requirements and high retrieval efficiency, hashing has recently received increasing attention. In particular,cross-modal hashing has been widely and successfully used in multimedia similarity search applications. However, almost all existing methods employing cross-modal hashing cannot obtain powerful hash codes due to their ignoring the relative similarity between heterogeneous data that contains richer semantic information, leading to unsatisfactory retrieval performance. In this paper, we propose a triplet-based deep hashing (TDH) network for cross-modal retrieval. First, we utilize the triplet labels, which describes the relative relationships among three instances as supervision in order to capture more general semantic correlations between cross-modal instances. We then establish a loss function from the inter-modal view and the intra-modal view to boost the discriminative abilities of the hash codes. Finally, graph regularization is introduced into our proposed TDH method to preserve the original semantic similarity between hash codes in Hamming space. Experimental results show that our proposed method outperforms several state-of-the-art approaches on two popular cross-modal datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-7.948957443237305, -4.712928771972656]}, {"key": "", "year": "", "title": "Dereka2022deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Image Retrieval is not Robust to Label Noise\"\nauthors: Dereka Stanislav, Karpukhin Ivan, Kolesnikov Sergey\nconference: Arxiv\nyear: 2022\nbibkey: dereka2022deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2205.11195\"}\ntags: ['ARXIV', 'Deep Learning', 'Image Retrieval', 'Semi Supervised', 'Supervised']\n---\nLarge-scale datasets are essential for the success of deep learning in image retrieval. However, manual assessment errors and semi-supervised annotation techniques can lead to label noise even in popular datasets. As previous works primarily studied annotation quality in image classification tasks, it is still unclear how label noise affects deep learning approaches to image retrieval. In this work, we show that image retrieval methods are less robust to label noise than image classification ones. Furthermore, we, for the first time, investigate different types of label noise specific to image retrieval tasks and study their effect on model performance.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [10.772276878356934, 18.933944702148438]}, {"key": "", "year": "", "title": "Desai2024identity", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"IDentity with Locality: An ideal hash for gene sequence search\"\nauthors: Desai Aditya, Gupta Gaurav, Zhang Tianyi, Shrivastava Anshumali\nconference: Arxiv\nyear: 2024\nbibkey: desai2024identity\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2406.14901\"}\ntags: ['ARXIV', 'LSH']\n---\nGene sequence search is a fundamental operation in computational genomics. Due to the petabyte scale of genome archives, most gene search systems now use hashing-based data structures such as Bloom Filters (BF). The state-of-the-art systems such as Compact bit-slicing signature index (COBS) and Repeated And Merged Bloom filters (RAMBO) use BF with Random Hash (RH) functions for gene representation and identification. The standard recipe is to cast the gene search problem as a sequence of membership problems testing if each subsequent gene substring (called kmer) of Q is present in the set of kmers of the entire gene database D. We observe that RH functions, which are crucial to the memory and the computational advantage of BF, are also detrimental to the system performance of gene-search systems. While subsequent kmers being queried are likely very similar, RH, oblivious to any similarity, uniformly distributes the kmers to different parts of potentially large BF, thus triggering excessive cache misses and causing system slowdown. We propose a novel hash function called the Identity with Locality (IDL) hash family, which co-locates the keys close in input space without causing collisions. This approach ensures both cache locality and key preservation. IDL functions can be a drop-in replacement for RH functions and help improve the performance of information retrieval systems. We give a simple but practical construction of IDL function families and show that replacing the RH with IDL functions reduces cache misses by a factor of 5x, thus improving query and indexing times of SOTA methods such as COBS and RAMBO by factors up to 2x without compromising their quality. We also provide a theoretical analysis of the false positive rate of BF with IDL functions. Our hash function is the first study that bridges Locality Sensitive Hash (LSH) and RH to obtain cache efficiency.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-12.313499450683594, -7.888978481292725]}, {"key": "", "year": "", "title": "Dey2009hf", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"HF-hash : Hash Functions Using Restricted HFE Challenge-1\"\nauthors: Dey Dhananjoy, Mishra Prasanna Raghaw, Sengupta Indranath\nconference: Arxiv\nyear: 2009\nbibkey: dey2009hf\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/0909.1392\"}\ntags: ['ARXIV', 'Graph']\n---\nVulnerability of dedicated hash functions to various attacks has made the task of designing hash function much more challenging. This provides us a strong motivation to design a new cryptographic hash function viz. HF-hash. This is a hash function, whose compression function is designed by using first 32 polynomials of HFE Challenge-1 with 64 variables by forcing remaining 16 variables as zero. HF-hash gives 256 bits message digest and is as efficient as SHA-256. It is secure against the differential attack proposed by Chabaud and Joux as well as by Wang et. al. applied to SHA-0 and SHA-1.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-30.791915893554688, -3.5250296592712402]}, {"key": "", "year": "", "title": "Dey2010gb", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"GB-hash : Hash Functions Using Groebner Basis\"\nauthors: Dey Dhananjoy, Mishra1 Prasanna Raghaw, Sengupta Indranath\nconference: Arxiv\nyear: 2010\nbibkey: dey2010gb\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1011.5534\"}\ntags: ['ARXIV', 'Graph']\n---\nIn this paper we present an improved version of HF-hash, viz., GB-hash : Hash Functions Using Groebner Basis. In case of HF-hash, the compression function consists of 32 polynomials with 64 variables which were taken from the first 32 polynomials of hidden field equations challenge-1 by forcing last 16 variables as 0. In GB-hash we have designed the compression function in such way that these 32 polynomials with 64 variables form a minimal Groebner basis of the ideal generated by them with respect to graded lexicographical (grlex) ordering as well as with respect to graded reverse lexicographical (grevlex) ordering. In this paper we will prove that GB-hash is more secure than HF-hash as well as more secure than SHA-256. We have also compared the efficiency of our GB-hash with SHA-256 and HF-hash.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-29.471588134765625, -3.4377944469451904]}, {"key": "", "year": "", "title": "Dey2016local", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Local Binary Pattern for Word Spotting in Handwritten Historical Document\"\nauthors: Dey Sounak, Nicolaou Anguelos, Llados Josep, Pal Umapada\nconference: Arxiv\nyear: 2016\nbibkey: dey2016local\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1604.05907\"}\ntags: ['ARXIV', 'Supervised', 'Unsupervised']\n---\nDigital libraries store images which can be highly degraded and to index this kind of images we resort to word spot- ting as our information retrieval system. Information retrieval for handwritten document images is more challenging due to the difficulties in complex layout analysis, large variations of writing styles, and degradation or low quality of historical manuscripts. This paper presents a simple innovative learning-free method for word spotting from large scale historical documents combining Local Binary Pattern (LBP) and spatial sampling. This method offers three advantages: firstly, it operates in completely learning free paradigm which is very different from unsupervised learning methods, secondly, the computational time is significantly low because of the LBP features which are very fast to compute, and thirdly, the method can be used in scenarios where annotations are not available. Finally we compare the results of our proposed retrieval method with the other methods in the literature.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [16.394861221313477, 18.831645965576172]}, {"key": "", "year": "", "title": "Dey2018learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning Cross-Modal Deep Embeddings for Multi-Object Image Retrieval using Text and Sketch\"\nauthors: Dey Sounak, Dutta Anjan, Ghosh Suman K., Valveny Ernest, Llad\u00f3s Josep, Pal Umapada\nconference: Arxiv\nyear: 2018\nbibkey: dey2018learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1804.10819\"}\ntags: ['ARXIV', 'Cross Modal', 'Image Retrieval', 'TIP']\n---\nIn this work we introduce a cross modal image retrieval system that allows both text and sketch as input modalities for the query. A cross-modal deep network architecture is formulated to jointly model the sketch and text input modalities as well as the the image output modality, learning a common embedding between text and images and between sketches and images. In addition, an attention model is used to selectively focus the attention on the different objects of the image, allowing for retrieval with multiple objects in the query. Experiments show that the proposed method performs the best in both single and multiple object image retrieval in standard datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [25.646730422973633, 3.269047260284424]}, {"key": "", "year": "", "title": "Dharani2013content", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Content Based Image Retrieval System using Feature Classification with Modified KNN Algorithm\"\nauthors: Dharani T., Aroquiaraj I. Laurence\nconference: Arxiv\nyear: 2013\nbibkey: dharani2013content\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1307.4717\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nFeature means countenance, remote sensing scene objects with similar characteristics, associated to interesting scene elements in the image formation process. They are classified into three types in image processing, that is low, middle and high. Low level features are color, texture and middle level feature is shape and high level feature is semantic gap of objects. An image retrieval system is a computer system for browsing, searching and retrieving images from a large image database. Content Based Image Retrieval is a technique which uses visual features of image such as color, shape, texture to search user required image from large image database according to user requests in the form of a query. MKNN is an enhancing method of KNN. The proposed KNN classification is called MKNN. MKNN contains two parts for processing, they are validity of the train samples and applying weighted KNN. The validity of each point is computed according to its neighbors. In our proposal, Modified K-Nearest Neighbor can be considered a kind of weighted KNN so that the query label is approximated by weighting the neighbors of the query.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [19.134645462036133, 5.865972518920898]}, {"key": "", "year": "", "title": "Dias2022pattern", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Pattern Spotting and Image Retrieval in Historical Documents using Deep Hashing\"\nauthors: Dias Caio da S., Britto Alceu de S. Jr., Barddal Jean P., Heutte Laurent, Koerich Alessandro L.\nconference: Arxiv\nyear: 2022\nbibkey: dias2022pattern\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2208.02397\"}\ntags: ['ARXIV', 'Deep Learning', 'Image Retrieval']\n---\nThis paper presents a deep learning approach for image retrieval and pattern spotting in digital collections of historical documents. First, a region proposal algorithm detects object candidates in the document page images. Next, deep learning models are used for feature extraction, considering two distinct variants, which provide either real-valued or binary code representations. Finally, candidate images are ranked by computing the feature similarity with a given input query. A robust experimental protocol evaluates the proposed approach considering each representation scheme (real-valued and binary code) on the DocExplore image database. The experimental results show that the proposed deep models compare favorably to the state-of-the-art image retrieval approaches for images of historical documents, outperforming other deep models by 2.56 percentage points using the same techniques for pattern spotting. Besides, the proposed approach also reduces the search time by up to 200x and the storage cost up to 6,000x when compared to related works based on real-valued representations.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [20.10177993774414, 8.686793327331543]}, {"key": "", "year": "", "title": "Dickens2023matching", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Matching Noisy Keys for Obfuscation\"\nauthors: Dickens Charlie, Bax Eric\nconference: Arxiv\nyear: 2023\nbibkey: dickens2023matching\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2312.08981\"}\ntags: ['ARXIV']\n---\nData sketching has emerged as a key infrastructure for large-scale data analysis on streaming and distributed data. Merging sketches enables efficient estimation of cardinalities and frequency histograms over distributed data. However, merging sketches can require that each sketch stores hash codes for identifiers in different data sets or partitions, in order to perform effective matching. This can reveal identifiers during merging or across different data set or partition owners. This paper presents a framework to use noisy hash codes, with the noise level selected to obfuscate identifiers while allowing matching, with high probability. We give probabilistic error bounds on simultaneous obfuscation and matching, concluding that this is a viable approach.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [14.004557609558105, -11.66968059539795]}, {"key": "", "year": "", "title": "Ding2018mean", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Mean Local Group Average Precision (mLGAP): A New Performance Metric for Hashing-based Retrieval\"\nauthors: Ding Pak Lun Kevin, Li Yikang, Li Baoxin\nconference: Arxiv\nyear: 2018\nbibkey: ding2018mean\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1811.09763\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nThe research on hashing techniques for visual data is gaining increased attention in recent years due to the need for compact representations supporting efficient search/retrieval in large-scale databases such as online images. Among many possibilities, Mean Average Precision(mAP) has emerged as the dominant performance metric for hashing-based retrieval. One glaring shortcoming of mAP is its inability in balancing retrieval accuracy and utilization of hash codes: pushing a system to attain higher mAP will inevitably lead to poorer utilization of the hash codes. Poor utilization of the hash codes hinders good retrieval because of increased collision of samples in the hash space. This means that a model giving a higher mAP values does not necessarily do a better job in retrieval. In this paper, we introduce a new metric named Mean Local Group Average Precision (mLGAP) for better evaluation of the performance of hashing-based retrieval. The new metric provides a retrieval performance measure that also reconciles the utilization of hash codes, leading to a more practically meaningful performance metric than conventional ones like mAP. To this end, we start by mathematical analysis of the deficiencies of mAP for hashing-based retrieval. We then propose mLGAP and show why it is more appropriate for hashing-based retrieval. Experiments on image retrieval are used to demonstrate the effectiveness of the proposed metric.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [8.093572616577148, 10.721882820129395]}, {"key": "", "year": "", "title": "Ding2019bilinear", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Bilinear Supervised Hashing Based on 2D Image Features\"\nauthors: Ding Yujuan, Wong Wai Kueng, Lai Zhihui, Zhang Zheng\nconference: Arxiv\nyear: 2019\nbibkey: ding2019bilinear\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1901.01474\"}\ntags: ['ARXIV', 'CNN', 'Supervised']\n---\nHashing has been recognized as an efficient representation learning method to effectively handle big data due to its low computational complexity and memory cost. Most of the existing hashing methods focus on learning the low-dimensional vectorized binary features based on the high-dimensional raw vectorized features. However, studies on how to obtain preferable binary codes from the original 2D image features for retrieval is very limited. This paper proposes a bilinear supervised discrete hashing (BSDH) method based on 2D image features which utilizes bilinear projections to binarize the image matrix features such that the intrinsic characteristics in the 2D image space are preserved in the learned binary codes. Meanwhile, the bilinear projection approximation and vectorization binary codes regression are seamlessly integrated together to formulate the final robust learning framework. Furthermore, a discrete optimization strategy is developed to alternatively update each variable for obtaining the high-quality binary codes. In addition, two 2D image features, traditional SURF-based FVLAD feature and CNN-based AlexConv5 feature are designed for further improving the performance of the proposed BSDH method. Results of extensive experiments conducted on four benchmark datasets show that the proposed BSDH method almost outperforms all competing hashing methods with different input features by different evaluation protocols.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-0.8180676698684692, 2.8333330154418945]}, {"key": "", "year": "", "title": "Ding2021dynamic", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Dynamic Texture Recognition using PDV Hashing and Dictionary Learning on Multi-scale Volume Local Binary Pattern\"\nauthors: Ding Ruxin, Ren Jianfeng, Yu Heng, Li Jiawei\nconference: Arxiv\nyear: 2021\nbibkey: ding2021dynamic\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2111.12315\"}\ntags: ['ARXIV']\n---\nSpatial-temporal local binary pattern (STLBP) has been widely used in dynamic texture recognition. STLBP often encounters the high-dimension problem as its dimension increases exponentially, so that STLBP could only utilize a small neighborhood. To tackle this problem, we propose a method for dynamic texture recognition using PDV hashing and dictionary learning on multi-scale volume local binary pattern (PHD-MVLBP). Instead of forming very high-dimensional LBP histogram features, it first uses hash functions to map the pixel difference vectors (PDVs) to binary vectors, then forms a dictionary using the derived binary vector, and encodes them using the derived dictionary. In such a way, the PDVs are mapped to feature vectors of the size of dictionary, instead of LBP histograms of very high dimension. Such an encoding scheme could extract the discriminant information from videos in a much larger neighborhood effectively. The experimental results on two widely-used dynamic textures datasets, DynTex++ and UCLA, show the superiority performance of the proposed approach over the state-of-the-art methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [6.706488132476807, 10.545639038085938]}, {"key": "", "year": "", "title": "Do2015discrete", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Discrete Hashing with Deep Neural Network\"\nauthors: Do Thanh-Toan, Doan Anh-Zung, Cheung Ngai-Man\nconference: Arxiv\nyear: 2015\nbibkey: do2015discrete\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1508.07148\"}\ntags: ['ARXIV', 'Supervised']\n---\nThis paper addresses the problem of learning binary hash codes for large scale image search by proposing a novel hashing method based on deep neural network. The advantage of our deep model over previous deep model used in hashing is that our model contains necessary criteria for producing good codes such as similarity preserving, balance and independence. Another advantage of our method is that instead of relaxing the binary constraint of codes during the learning process as most previous works, in this paper, by introducing the auxiliary variable, we reformulate the optimization into two sub-optimization steps allowing us to efficiently solve binary constraints without any relaxation. The proposed method is also extended to the supervised hashing by leveraging the label information such that the learned binary codes preserve the pairwise label of inputs. The experimental results on three benchmark datasets show the proposed methods outperform state-of-the-art hashing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-15.931929588317871, 13.783767700195312]}, {"key": "", "year": "", "title": "Do2016binary", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Binary Hashing with Semidefinite Relaxation and Augmented Lagrangian\"\nauthors: Do Thanh-Toan, Doan Anh-Dzung, Nguyen Duc-Thanh, Cheung Ngai-Man\nconference: Arxiv\nyear: 2016\nbibkey: do2016binary\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1607.05396\"}\ntags: ['ARXIV', 'Supervised', 'Unsupervised']\n---\nThis paper proposes two approaches for inferencing binary codes in two-step (supervised, unsupervised) hashing. We first introduce an unified formulation for both supervised and unsupervised hashing. Then, we cast the learning of one bit as a Binary Quadratic Problem (BQP). We propose two approaches to solve BQP. In the first approach, we relax BQP as a semidefinite programming problem which its global optimum can be achieved. We theoretically prove that the objective value of the binary solution achieved by this approach is well bounded. In the second approach, we propose an augmented Lagrangian based approach to solve BQP directly without relaxing the binary constraint. Experimental results on three benchmark datasets show that our proposed methods compare favorably with the state of the art.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [6.333571434020996, -2.045229434967041]}, {"key": "", "year": "", "title": "Do2016embedding", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Embedding based on function approximation for large scale image search\"\nauthors: Do Thanh-Toan, Cheung Ngai-Man\nconference: Arxiv\nyear: 2016\nbibkey: do2016embedding\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1605.06914\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nThe objective of this paper is to design an embedding method that maps local features describing an image (e.g. SIFT) to a higher dimensional representation useful for the image retrieval problem. First, motivated by the relationship between the linear approximation of a nonlinear function in high dimensional space and the stateof-the-art feature representation used in image retrieval, i.e., VLAD, we propose a new approach for the approximation. The embedded vectors resulted by the function approximation process are then aggregated to form a single representation for image retrieval. Second, in order to make the proposed embedding method applicable to large scale problem, we further derive its fast version in which the embedded vectors can be efficiently computed, i.e., in the closed-form. We compare the proposed embedding methods with the state of the art in the context of image search under various settings: when the images are represented by medium length vectors, short vectors, or binary vectors. The experimental results show that the proposed embedding methods outperform existing the state of the art on the standard public image retrieval benchmarks.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [20.93610954284668, 16.390737533569336]}, {"key": "", "year": "", "title": "Do2016learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning to Hash with Binary Deep Neural Network\"\nauthors: Do Thanh-Toan, Doan Anh-Dzung, Cheung Ngai-Man\nconference: Arxiv\nyear: 2016\nbibkey: do2016learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1607.05140\"}\ntags: ['ARXIV', 'Supervised', 'Unsupervised']\n---\nThis work proposes deep network models and learning algorithms for unsupervised and supervised binary hashing. Our novel network design constrains one hidden layer to directly output the binary codes. This addresses a challenging issue in some previous works: optimizing non-smooth objective functions due to binarization. Moreover, we incorporate independence and balance properties in the direct and strict forms in the learning. Furthermore, we include similarity preserving property in our objective function. Our resulting optimization with these binary, independence, and balance constraints is difficult to solve. We propose to attack it with alternating optimization and careful relaxation. Experimental results on three benchmark datasets show that our proposed methods compare favorably with the state of the art.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-15.207358360290527, 13.873595237731934]}, {"key": "", "year": "", "title": "Do2017compact", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Compact Hash Code Learning with Binary Deep Neural Network\"\nauthors: Do Thanh-Toan, Hoang Tuan, Tan Dang-Khoa Le, Doan Anh-Dzung, Cheung Ngai-Man\nconference: Arxiv\nyear: 2017\nbibkey: do2017compact\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1712.02956\"}\ntags: ['ARXIV', 'Image Retrieval', 'Supervised', 'Unsupervised']\n---\nLearning compact binary codes for image retrieval problem using deep neural networks has recently attracted increasing attention. However, training deep hashing networks is challenging due to the binary constraints on the hash codes. In this paper, we propose deep network models and learning algorithms for learning binary hash codes given image representations under both unsupervised and supervised manners. The novelty of our network design is that we constrain one hidden layer to directly output the binary codes. This design has overcome a challenging problem in some previous works: optimizing non-smooth objective functions because of binarization. In addition, we propose to incorporate independence and balance properties in the direct and strict forms into the learning schemes. We also include a similarity preserving property in our objective functions. The resulting optimizations involving these binary, independence, and balance constraints are difficult to solve. To tackle this difficulty, we propose to learn the networks with alternating optimization and careful relaxation. Furthermore, by leveraging the powerful capacity of convolutional neural networks, we propose an end-to-end architecture that jointly learns to extract visual features and produce binary hash codes. Experimental results for the benchmark datasets show that the proposed methods compare favorably or outperform the state of the art.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-11.505810737609863, 11.353577613830566]}, {"key": "", "year": "", "title": "Do2017simultaneous", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Simultaneous Feature Aggregating and Hashing for Large-scale Image Search\"\nauthors: Do Thanh-Toan, Tan Dang-Khoa Le, Pham Trung T., Cheung Ngai-Man\nconference: Arxiv\nyear: 2017\nbibkey: do2017simultaneous\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1704.00860\"}\ntags: ['ARXIV']\n---\nIn most state-of-the-art hashing-based visual search systems, local image descriptors of an image are first aggregated as a single feature vector. This feature vector is then subjected to a hashing function that produces a binary hash code. In previous work, the aggregating and the hashing processes are designed independently. In this paper, we propose a novel framework where feature aggregating and hashing are designed simultaneously and optimized jointly. Specifically, our joint optimization produces aggregated representations that can be better reconstructed by some binary codes. This leads to more discriminative binary hash codes and improved retrieval accuracy. In addition, we also propose a fast version of the recently-proposed Binary Autoencoder to be used in our proposed framework. We perform extensive retrieval experiments on several benchmark datasets with both SIFT and convolutional features. Our results suggest that the proposed framework achieves significant improvements over the state of the art.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [19.408287048339844, 14.852715492248535]}, {"key": "", "year": "", "title": "Do2018binary", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Binary Constrained Deep Hashing Network for Image Retrieval without Manual Annotation\"\nauthors: Do Thanh-Toan, Hoang Tuan, Tan Dang-Khoa Le, Pham Trung, Le Huu, Cheung Ngai-Man, Reid Ian\nconference: Arxiv\nyear: 2018\nbibkey: do2018binary\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1802.07437\"}\ntags: ['ARXIV', 'Deep Learning', 'Image Retrieval', 'Quantisation', 'TOM']\n---\nLearning compact binary codes for image retrieval task using deep neural networks has attracted increasing attention recently. However, training deep hashing networks for the task is challenging due to the binary constraints on the hash codes, the similarity preserving property, and the requirement for a vast amount of labelled images. To the best of our knowledge, none of the existing methods has tackled all of these challenges completely in a unified framework. In this work, we propose a novel end-to-end deep learning approach for the task, in which the network is trained to produce binary codes directly from image pixels without the need of manual annotation. In particular, to deal with the non-smoothness of binary constraints, we propose a novel pairwise constrained loss function, which simultaneously encodes the distances between pairs of hash codes, and the binary quantization error. In order to train the network with the proposed loss function, we propose an efficient parameter learning algorithm. In addition, to provide similar / dissimilar training images to train the network, we exploit 3D models reconstructed from unlabelled images for automatic generation of enormous training image pairs. The extensive experiments on image retrieval benchmark datasets demonstrate the improvements of the proposed method over the state-of-the-art compact representation methods on the image retrieval problem.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-11.26351261138916, 11.602935791015625]}, {"key": "", "year": "", "title": "Do2018from", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"From Selective Deep Convolutional Features to Compact Binary Representations for Image Retrieval\"\nauthors: Do Thanh-Toan, Hoang Tuan, Tan Dang-Khoa Le, Le Huu, Nguyen Tam V., Cheung Ngai-Man\nconference: Arxiv\nyear: 2018\nbibkey: do2018from\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1802.02899\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval']\n---\nIn the large-scale image retrieval task, the two most important requirements are the discriminability of image representations and the efficiency in computation and storage of representations. Regarding the former requirement, Convolutional Neural Network (CNN) is proven to be a very powerful tool to extract highly discriminative local descriptors for effective image search. Additionally, in order to further improve the discriminative power of the descriptors, recent works adopt fine-tuned strategies. In this paper, taking a different approach, we propose a novel, computationally efficient, and competitive framework. Specifically, we firstly propose various strategies to compute masks, namely SIFT-mask, SUM-mask, and MAX-mask, to select a representative subset of local convolutional features and eliminate redundant features. Our in-depth analyses demonstrate that proposed masking schemes are effective to address the burstiness drawback and improve retrieval accuracy. Secondly, we propose to employ recent embedding and aggregating methods which can significantly boost the feature discriminability. Regarding the computation and storage efficiency, we include a hashing module to produce very compact binary image representations. Extensive experiments on six image retrieval benchmarks demonstrate that our proposed framework achieves the state-of-the-art retrieval performances.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.716010093688965, 15.874650955200195]}, {"key": "", "year": "", "title": "Do2019simultaneous", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Simultaneous Feature Aggregating and Hashing for Compact Binary Code Learning\"\nauthors: Do Thanh-Toan, Le Khoa, Hoang Tuan, Le Huu, Nguyen Tam V., Cheung Ngai-Man\nconference: Arxiv\nyear: 2019\nbibkey: do2019simultaneous\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1904.11820\"}\ntags: ['ARXIV', 'Deep Learning', 'Image Retrieval', 'Supervised', 'Unsupervised']\n---\nRepresenting images by compact hash codes is an attractive approach for large-scale content-based image retrieval. In most state-of-the-art hashing-based image retrieval systems, for each image, local descriptors are first aggregated as a global representation vector. This global vector is then subjected to a hashing function to generate a binary hash code. In previous works, the aggregating and the hashing processes are designed independently. Hence these frameworks may generate suboptimal hash codes. In this paper, we first propose a novel unsupervised hashing framework in which feature aggregating and hashing are designed simultaneously and optimized jointly. Specifically, our joint optimization generates aggregated representations that can be better reconstructed by some binary codes. This leads to more discriminative binary hash codes and improved retrieval accuracy. In addition, the proposed method is flexible. It can be extended for supervised hashing. When the data label is available, the framework can be adapted to learn binary codes which minimize the reconstruction loss w.r.t. label vectors. Furthermore, we also propose a fast version of the state-of-the-art hashing method Binary Autoencoder to be used in our proposed frameworks. Extensive experiments on benchmark datasets under various settings show that the proposed methods outperform state-of-the-art unsupervised and supervised hashing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-2.1224594116210938, 6.766666412353516]}, {"key": "", "year": "", "title": "Doan2020image", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Image Hashing by Minimizing Discrete Component-wise Wasserstein Distance\"\nauthors: Doan Khoa D., Manchanda Saurav, Badirli Sarkhan, Reddy Chandan K.\nconference: Arxiv\nyear: 2020\nbibkey: doan2020image\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2003.00134\"}   - {name: \"Code\", url: \"https://github.com/khoadoan/adversarial-hashing).\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nImage hashing is one of the fundamental problems that demand both efficient and effective solutions for various practical scenarios. Adversarial autoencoders are shown to be able to implicitly learn a robust, locality-preserving hash function that generates balanced and high-quality hash codes. However, the existing adversarial hashing methods are inefficient to be employed for large-scale image retrieval applications. Specifically, they require an exponential number of samples to be able to generate optimal hash codes and a significantly high computational cost to train. In this paper, we show that the high sample-complexity requirement often results in sub-optimal retrieval performance of the adversarial hashing methods. To address this challenge, we propose a new adversarial-autoencoder hashing approach that has a much lower sample requirement and computational cost. Specifically, by exploiting the desired properties of the hash function in the low-dimensional, discrete space, our method efficiently estimates a better variant of Wasserstein distance by averaging a set of easy-to-compute one-dimensional Wasserstein distances. The resulting hashing approach has an order-of-magnitude better sample complexity, thus better generalization property, compared to the other adversarial hashing methods. In addition, the computational cost is significantly reduced using our approach. We conduct experiments on several real-world datasets and show that the proposed method outperforms the competing hashing methods, achieving up to 10% improvement over the current state-of-the-art image hashing methods. The code accompanying this paper is available on Github (https://github.com/khoadoan/adversarial-hashing).\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-0.2264450490474701, 7.153921127319336]}, {"key": "", "year": "", "title": "Doan2022asymmetric", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Asymmetric Hashing for Fast Ranking via Neural Network Measures\"\nauthors: Doan Khoa, Tan Shulong, Zhao Weijie, Li Ping\nconference: Arxiv\nyear: 2022\nbibkey: doan2022asymmetric\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2211.00619\"}\ntags: ['ARXIV', 'Graph', 'LSH']\n---\nFast item ranking is an important task in recommender systems. In previous works, graph-based Approximate Nearest Neighbor (ANN) approaches have demonstrated good performance on item ranking tasks with generic searching/matching measures (including complex measures such as neural network measures). However, since these ANN approaches must go through the neural measures several times during ranking, the computation is not practical if the neural measure is a large network. On the other hand, fast item ranking using existing hashing-based approaches, such as Locality Sensitive Hashing (LSH), only works with a limited set of measures. Previous learning-to-hash approaches are also not suitable to solve the fast item ranking problem since they can take a significant amount of time and computation to train the hash functions. Hashing approaches, however, are attractive because they provide a principle and efficient way to retrieve candidate items. In this paper, we propose a simple and effective learning-to-hash approach for the fast item ranking problem that can be used for any type of measure, including neural network measures. Specifically, we solve this problem with an asymmetric hashing framework based on discrete inner product fitting. We learn a pair of related hash functions that map heterogeneous objects (e.g., users and items) into a common discrete space where the inner product of their binary codes reveals their true similarity defined via the original searching measure. The fast ranking problem is reduced to an ANN search via this asymmetric hashing scheme. Then, we propose a sampling strategy to efficiently select relevant and contrastive samples to train the hashing model. We empirically validate the proposed method against the existing state-of-the-art fast item ranking methods in several combinations of non-linear searching functions and prominent datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-0.6906917095184326, -25.876388549804688]}, {"key": "", "year": "", "title": "Doan2022coophash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"CoopHash: Cooperative Learning of Multipurpose Descriptor and Contrastive Pair Generator via Variational MCMC Teaching for Supervised Image Hashing\"\nauthors: Doan Khoa D., Xie Jianwen, Zhu Yaxuan, Zhao Yang, Li Ping\nconference: Arxiv\nyear: 2022\nbibkey: doan2022coophash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2210.04288\"}\ntags: ['ARXIV', 'GAN', 'Supervised', 'TIP', 'TOM']\n---\nLeveraging supervised information can lead to superior retrieval performance in the image hashing domain but the performance degrades significantly without enough labeled data. One effective solution to boost performance is to employ generative models, such as Generative Adversarial Networks (GANs), to generate synthetic data in an image hashing model. However, GAN-based methods are difficult to train, which prevents the hashing approaches from jointly training the generative models and the hash functions. This limitation results in sub-optimal retrieval performance. To overcome this limitation, we propose a novel framework, the generative cooperative hashing network, which is based on energy-based cooperative learning. This framework jointly learns a powerful generative representation of the data and a robust hash function via two components: a top-down contrastive pair generator that synthesizes contrastive images and a bottom-up multipurpose descriptor that simultaneously represents the images from multiple perspectives, including probability density, hash code, latent code, and category. The two components are jointly learned via a novel likelihood-based cooperative learning scheme. We conduct experiments on several real-world datasets and show that the proposed method outperforms the competing hashing supervised methods, achieving up to 10\\% relative improvement over the current state-of-the-art supervised hashing methods, and exhibits a significantly better performance in out-of-distribution retrieval.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-8.680505752563477, 9.219440460205078]}, {"key": "", "year": "", "title": "Doan2022one", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"One Loss for Quantization: Deep Hashing with Discrete Wasserstein Distributional Matching\"\nauthors: Doan Khoa D., Yang Peng, Li Ping\nconference: Arxiv\nyear: 2022\nbibkey: doan2022one\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2205.15721\"}\ntags: ['ARXIV', 'Quantisation', 'Supervised']\n---\nImage hashing is a principled approximate nearest neighbor approach to find similar items to a query in a large collection of images. Hashing aims to learn a binary-output function that maps an image to a binary vector. For optimal retrieval performance, producing balanced hash codes with low-quantization error to bridge the gap between the learning stage's continuous relaxation and the inference stage's discrete quantization is important. However, in the existing deep supervised hashing methods, coding balance and low-quantization error are difficult to achieve and involve several losses. We argue that this is because the existing quantization approaches in these methods are heuristically constructed and not effective to achieve these objectives. This paper considers an alternative approach to learning the quantization constraints. The task of learning balanced codes with low quantization error is re-formulated as matching the learned distribution of the continuous codes to a pre-defined discrete, uniform distribution. This is equivalent to minimizing the distance between two distributions. We then propose a computationally efficient distributional distance by leveraging the discrete property of the hash functions. This distributional distance is a valid distance and enjoys lower time and sample complexities. The proposed single-loss quantization objective can be integrated into any existing supervised hashing method to improve code balance and quantization error. Experiments confirm that the proposed approach substantially improves the performance of several representative hashing~methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-4.597836494445801, 3.772876024246216]}, {"key": "", "year": "", "title": "Dodds2018learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning Embeddings for Product Visual Search with Triplet Loss and Online Sampling\"\nauthors: Dodds Eric, Nguyen Huy, Herdade Simao, Culpepper Jack, Kae Andrew, Garrigues Pierre\nconference: Arxiv\nyear: 2018\nbibkey: dodds2018learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1810.04652\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nIn this paper, we propose learning an embedding function for content-based image retrieval within the e-commerce domain using the triplet loss and an online sampling method that constructs triplets from within a minibatch. We compare our method to several strong baselines as well as recent works on the DeepFashion and Stanford Online Product datasets. Our approach significantly outperforms the state-of-the-art on the DeepFashion dataset. With a modification to favor sampling minibatches from a single product category, the same approach demonstrates competitive results when compared to the state-of-the-art for the Stanford Online Products dataset.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [27.20977210998535, 2.739996910095215]}, {"key": "", "year": "", "title": "Dolhansky2020adversarial", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Adversarial collision attacks on image hashing functions\"\nauthors: Dolhansky Brian, Ferrer Cristian Canton\nconference: Arxiv\nyear: 2020\nbibkey: dolhansky2020adversarial\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2011.09473\"}\ntags: ['ARXIV']\n---\nHashing images with a perceptual algorithm is a common approach to solving duplicate image detection problems. However, perceptual image hashing algorithms are differentiable, and are thus vulnerable to gradient-based adversarial attacks. We demonstrate that not only is it possible to modify an image to produce an unrelated hash, but an exact image hash collision between a source and target image can be produced via minuscule adversarial perturbations. In a white box setting, these collisions can be replicated across nearly every image pair and hash type (including both deep and non-learned hashes). Furthermore, by attacking points other than the output of a hashing function, an attacker can avoid having to know the details of a particular algorithm, resulting in collisions that transfer across different hash sizes or model architectures. Using these techniques, an adversary can poison the image lookup table of a duplicate image detection service, resulting in undefined or unwanted behavior. Finally, we offer several potential mitigations to gradient-based image hash attacks.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-2.758009195327759, 10.024457931518555]}, {"key": "", "year": "", "title": "Domnita2020a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Genetic Algorithm for Obtaining Memory Constrained Near-Perfect Hashing\"\nauthors: Domnita Dan, Oprisa Ciprian\nconference: Arxiv\nyear: 2020\nbibkey: domnita2020a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2007.08311\"}\ntags: ['ARXIV']\n---\nThe problem of fast items retrieval from a fixed collection is often encountered in most computer science areas, from operating system components to databases and user interfaces. We present an approach based on hash tables that focuses on both minimizing the number of comparisons performed during the search and minimizing the total collection size. The standard open-addressing double-hashing approach is improved with a non-linear transformation that can be parametrized in order to ensure a uniform distribution of the data in the hash table. The optimal parameter is determined using a genetic algorithm. The paper results show that near-perfect hashing is faster than binary search, yet uses less memory than perfect hashing, being a good choice for memory-constrained applications where search time is also critical.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-23.538528442382812, -9.397751808166504]}, {"key": "", "year": "", "title": "Dong2016nist", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"NIST: An Image Classification Network to Image Semantic Retrieval\"\nauthors: Dong Le, Chen Xiuyuan, Mao Mengdie, Zhang Qianni\nconference: Arxiv\nyear: 2016\nbibkey: dong2016nist\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1607.00464\"}\ntags: ['ARXIV', 'ICIP', 'Image Retrieval']\n---\nThis paper proposes a classification network to image semantic retrieval (NIST) framework to counter the image retrieval challenge. Our approach leverages the successful classification network GoogleNet based on Convolutional Neural Networks to obtain the semantic feature matrix which contains the serial number of classes and corresponding probabilities. Compared with traditional image retrieval using feature matching to compute the similarity between two images, NIST leverages the semantic information to construct semantic feature matrix and uses the semantic distance algorithm to compute the similarity. Besides, the fusion strategy can significantly reduce storage and time consumption due to less classes participating in the last semantic distance computation. Experiments demonstrate that our NIST framework produces state-of-the-art results in retrieval experiments on MIRFLICKR-25K dataset.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [23.093692779541016, 9.95457649230957]}, {"key": "", "year": "", "title": "Dong2017video", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Video retrieval based on deep convolutional neural network\"\nauthors: Dong Yj, Li JG\nconference: Arxiv\nyear: 2017\nbibkey: dong2017video\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1712.00133\"}\ntags: ['ARXIV', 'Video Retrieval']\n---\nRecently, with the enormous growth of online videos, fast video retrieval research has received increasing attention. As an extension of image hashing techniques, traditional video hashing methods mainly depend on hand-crafted features and transform the real-valued features into binary hash codes. As videos provide far more diverse and complex visual information than images, extracting features from videos is much more challenging than that from images. Therefore, high-level semantic features to represent videos are needed rather than low-level hand-crafted methods. In this paper, a deep convolutional neural network is proposed to extract high-level semantic features and a binary hash function is then integrated into this framework to achieve an end-to-end optimization. Particularly, our approach also combines triplet loss function which preserves the relative similarity and difference of videos and classification loss function as the optimization objective. Experiments have been performed on two public datasets and the results demonstrate the superiority of our proposed method compared with other state-of-the-art video retrieval methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-1.1392709016799927, 28.366283416748047]}, {"key": "", "year": "", "title": "Dong2019document", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Document Hashing with Mixture-Prior Generative Models\"\nauthors: Dong Wei, Su Qinliang, Shen Dinghan, Chen Changyou\nconference: Arxiv\nyear: 2019\nbibkey: dong2019document\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1908.11078\"}\ntags: ['ARXIV', 'Supervised', 'Unsupervised']\n---\nHashing is promising for large-scale information retrieval tasks thanks to the efficiency of distance evaluation between binary codes. Generative hashing is often used to generate hashing codes in an unsupervised way. However, existing generative hashing methods only considered the use of simple priors, like Gaussian and Bernoulli priors, which limits these methods to further improve their performance. In this paper, two mixture-prior generative models are proposed, under the objective to produce high-quality hashing codes for documents. Specifically, a Gaussian mixture prior is first imposed onto the variational auto-encoder (VAE), followed by a separate step to cast the continuous latent representation of VAE into binary code. To avoid the performance loss caused by the separate casting, a model using a Bernoulli mixture prior is further developed, in which an end-to-end training is admitted by resorting to the straight-through (ST) discrete gradient estimator. Experimental results on several benchmark datasets demonstrate that the proposed methods, especially the one using Bernoulli mixture priors, consistently outperform existing ones by a substantial margin.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-8.201948165893555, -6.4627861976623535]}, {"key": "", "year": "", "title": "Dong2019learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning Space Partitions for Nearest Neighbor Search\"\nauthors: Dong Yihe, Indyk Piotr, Razenshteyn Ilya, Wagner Tal\nconference: Arxiv\nyear: 2019\nbibkey: dong2019learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1901.08544\"}\ntags: ['ARXIV', 'FOCS', 'Graph', 'LSH', 'Quantisation', 'Supervised']\n---\nSpace partitions of $\\mathbb\\{R\\}^d$ underlie a vast and important class of fast nearest neighbor search (NNS) algorithms. Inspired by recent theoretical work on NNS for general metric spaces [Andoni, Naor, Nikolov, Razenshteyn, Waingarten STOC 2018, FOCS 2018], we develop a new framework for building space partitions reducing the problem to balanced graph partitioning followed by supervised classification. We instantiate this general approach with the KaHIP graph partitioner [Sanders, Schulz SEA 2013] and neural networks, respectively, to obtain a new partitioning procedure called Neural Locality-Sensitive Hashing (Neural LSH). On several standard benchmarks for NNS, our experiments show that the partitions obtained by Neural LSH consistently outperform partitions found by quantization-based and tree-based methods as well as classic, data-oblivious LSH.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.04369831085205, -24.957672119140625]}, {"key": "", "year": "", "title": "Dong2020using", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Using Text to Teach Image Retrieval\"\nauthors: Dong Haoyu, Wang Ze, Qiu Qiang, Sapiro Guillermo\nconference: Arxiv\nyear: 2020\nbibkey: dong2020using\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2011.09928\"}\ntags: ['ARXIV', 'Graph', 'Image Retrieval']\n---\nImage retrieval relies heavily on the quality of the data modeling and the distance measurement in the feature space. Building on the concept of image manifold, we first propose to represent the feature space of images, learned via neural networks, as a graph. Neighborhoods in the feature space are now defined by the geodesic distance between images, represented as graph vertices or manifold samples. When limited images are available, this manifold is sparsely sampled, making the geodesic computation and the corresponding retrieval harder. To address this, we augment the manifold samples with geometrically aligned text, thereby using a plethora of sentences to teach us about images. In addition to extensive results on standard datasets illustrating the power of text to help in image retrieval, a new public dataset based on CLEVR is introduced to quantify the semantic similarity between visual data and text data. The experimental results show that the joint embedding manifold is a robust representation, allowing it to be a better basis to perform image retrieval given only an image and a textual instruction on the desired modifications over the image\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.784674644470215, -28.369213104248047]}, {"key": "", "year": "", "title": "Dong2021ash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"ASH: A Modern Framework for Parallel Spatial Hashing in 3D Perception\"\nauthors: Dong Wei, Lao Yixing, Kaess Michael, Koltun Vladlen\nconference: Arxiv\nyear: 2021\nbibkey: dong2021ash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2110.00511\"}   - {name: \"Paper\", url: \"http://www.open3d.org).\"}\ntags: ['ARXIV']\n---\nWe present ASH, a modern and high-performance framework for parallel spatial hashing on GPU. Compared to existing GPU hash map implementations, ASH achieves higher performance, supports richer functionality, and requires fewer lines of code (LoC) when used for implementing spatially varying operations from volumetric geometry reconstruction to differentiable appearance reconstruction. Unlike existing GPU hash maps, the ASH framework provides a versatile tensor interface, hiding low-level details from the users. In addition, by decoupling the internal hashing data structures and key-value data in buffers, we offer direct access to spatially varying data via indices, enabling seamless integration to modern libraries such as PyTorch. To achieve this, we 1) detach stored key-value data from the low-level hash map implementation; 2) bridge the pointer-first low level data structures to index-first high-level tensor interfaces via an index heap; 3) adapt both generic and non-generic integer-only hash map implementations as backends to operate on multi-dimensional keys. We first profile our hash map against state-of-the-art hash maps on synthetic data to show the performance gain from this architecture. We then show that ASH can consistently achieve higher performance on various large-scale 3D perception tasks with fewer LoC by showcasing several applications, including 1) point cloud voxelization, 2) retargetable volumetric scene reconstruction, 3) non-rigid point cloud registration and volumetric deformation, and 4) spatially varying geometry and appearance refinement. ASH and its example applications are open sourced in Open3D (http://www.open3d.org).\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-2.728116512298584, 4.060883522033691]}, {"key": "", "year": "", "title": "Dong2021dxhash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"DxHash: A Scalable Consistent Hash Based on the Pseudo-Random Sequence\"\nauthors: Dong Chao, Wang Fang, Feng Dan\nconference: Arxiv\nyear: 2021\nbibkey: dong2021dxhash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2107.07930\"}\ntags: ['ARXIV']\n---\nConsistent hashing (CH) has been pivotal as a data router and load balancer in diverse fields, including distributed databases, cloud infrastructure, and peer-to-peer networks. However, existing CH algorithms often fall short in simultaneously meeting various critical requirements, such as load balance, minimal disruption, statelessness, high lookup rate, small memory footprint, and low update overhead. To address these limitations, we introduce DxHash, a scalable consistent hashing algorithm based on pseudo-random sequences. To adjust workloads on heterogeneous nodes and enhance flexibility, we propose weighted DxHash. Through comprehensive evaluations, DxHash demonstrates substantial improvements across all six requirements compared to state-of-the-art alternatives. Notably, even when confronted with a 50% failure ratio in a cluster of one million nodes, DxHash maintains remarkable processing capabilities, handling up to 13.3 million queries per second.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-25.166433334350586, -11.520779609680176]}, {"key": "", "year": "", "title": "Dong2022learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning-Based Dimensionality Reduction for Computing Compact and Effective Local Feature Descriptors\"\nauthors: Dong Hao, Chen Xieyuanli, Dusmanu Mihai, Larsson Viktor, Pollefeys Marc, Stachniss Cyrill\nconference: Arxiv\nyear: 2022\nbibkey: dong2022learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2209.13586\"}   - {name: \"Code\", url: \"https://github.com/PRBonn/descriptor-dr.\"}\ntags: ['ARXIV', 'Image Retrieval', 'Self Supervised', 'Supervised', 'Unsupervised']\n---\nA distinctive representation of image patches in form of features is a key component of many computer vision and robotics tasks, such as image matching, image retrieval, and visual localization. State-of-the-art descriptors, from hand-crafted descriptors such as SIFT to learned ones such as HardNet, are usually high dimensional; 128 dimensions or even more. The higher the dimensionality, the larger the memory consumption and computational time for approaches using such descriptors. In this paper, we investigate multi-layer perceptrons (MLPs) to extract low-dimensional but high-quality descriptors. We thoroughly analyze our method in unsupervised, self-supervised, and supervised settings, and evaluate the dimensionality reduction results on four representative descriptors. We consider different applications, including visual localization, patch verification, image matching and retrieval. The experiments show that our lightweight MLPs achieve better dimensionality reduction than PCA. The lower-dimensional descriptors generated by our approach outperform the original higher-dimensional descriptors in downstream tasks, especially for the hand-crafted ones. The code will be available at https://github.com/PRBonn/descriptor-dr.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-0.12775954604148865, 21.355403900146484]}, {"key": "", "year": "", "title": "Dou2020learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning Global and Local Consistent Representations for Unsupervised Image Retrieval via Deep Graph Diffusion Networks\"\nauthors: Dou Zhiyong, Cui Haotian, Zhang Lin, Wang Bo\nconference: Arxiv\nyear: 2020\nbibkey: dou2020learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2001.01284\"}\ntags: ['ARXIV', 'Deep Learning', 'Graph', 'Image Retrieval', 'Supervised', 'Unsupervised']\n---\nDiffusion has shown great success in improving accuracy of unsupervised image retrieval systems by utilizing high-order structures of image manifold. However, existing diffusion methods suffer from three major limitations: 1) they usually rely on local structures without considering global manifold information; 2) they focus on improving pair-wise similarities within existing images input output transductively while lacking flexibility to learn representations for novel unseen instances inductively; 3) they fail to scale to large datasets due to prohibitive memory consumption and computational burden due to intrinsic high-order operations on the whole graph. In this paper, to address these limitations, we propose a novel method, Graph Diffusion Networks (GRAD-Net), that adopts graph neural networks (GNNs), a novel variant of deep learning algorithms on irregular graphs. GRAD-Net learns semantic representations by exploiting both local and global structures of image manifold in an unsupervised fashion. By utilizing sparse coding techniques, GRAD-Net not only preserves global information on the image manifold, but also enables scalable training and efficient querying. Experiments on several large benchmark datasets demonstrate effectiveness of our method over state-of-the-art diffusion algorithms for unsupervised image retrieval.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [3.732780933380127, -30.98729705810547]}, {"key": "", "year": "", "title": "Douze2016polysemous", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Polysemous codes\"\nauthors: Douze Matthijs, J\u00e9gou Herv\u00e9, Perronnin Florent\nconference: Arxiv\nyear: 2016\nbibkey: douze2016polysemous\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1609.01882\"}\ntags: ['ARXIV', 'CNN', 'GAN', 'Graph', 'Quantisation']\n---\nThis paper considers the problem of approximate nearest neighbor search in the compressed domain. We introduce polysemous codes, which offer both the distance estimation quality of product quantization and the efficient comparison of binary codes with Hamming distance. Their design is inspired by algorithms introduced in the 90's to construct channel-optimized vector quantizers. At search time, this dual interpretation accelerates the search. Most of the indexed vectors are filtered out with Hamming distance, letting only a fraction of the vectors to be ranked with an asymmetric distance estimator. The method is complementary with a coarse partitioning of the feature space such as the inverted multi-index. This is shown by our experiments performed on several public benchmarks such as the BIGANN dataset comprising one billion vectors, for which we report state-of-the-art results for query times below 0.3\\,millisecond per core. Last but not least, our approach allows the approximate computation of the k-NN graph associated with the Yahoo Flickr Creative Commons 100M, described by CNN image descriptors, in less than 8 hours on a single machine.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [7.089898586273193, -12.985197067260742]}, {"key": "", "year": "", "title": "Douze2018link", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Link and code: Fast indexing with graphs and compact regression codes\"\nauthors: Douze Matthijs, Sablayrolles Alexandre, J\u00e9gou Herv\u00e9\nconference: Arxiv\nyear: 2018\nbibkey: douze2018link\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1804.09996\"}\ntags: ['ARXIV', 'Graph', 'Quantisation']\n---\nSimilarity search approaches based on graph walks have recently attained outstanding speed-accuracy trade-offs, taking aside the memory requirements. In this paper, we revisit these approaches by considering, additionally, the memory constraint required to index billions of images on a single server. This leads us to propose a method based both on graph traversal and compact representations. We encode the indexed vectors using quantization and exploit the graph structure to refine the similarity estimation. In essence, our method takes the best of these two worlds: the search strategy is based on nested graphs, thereby providing high precision with a relatively small set of comparisons. At the same time it offers a significant memory compression. As a result, our approach outperforms the state of the art on operating points considering 64-128 bytes per vector, as demonstrated by our results on two billion-scale public benchmarks.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [6.896235466003418, -29.994979858398438]}, {"key": "", "year": "", "title": "Du2023bytecover3", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"ByteCover3: Accurate Cover Song Identification on Short Queries\"\nauthors: Du Xingjian, Wang Zijie, Liang Xia, Liang Huidong, Zhu Bilei, Ma Zejun\nconference: Arxiv\nyear: 2023\nbibkey: du2023bytecover3\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2303.11692\"}\ntags: ['ARXIV', 'Deep Learning', 'TIP']\n---\nDeep learning based methods have become a paradigm for cover song identification (CSI) in recent years, where the ByteCover systems have achieved state-of-the-art results on all the mainstream datasets of CSI. However, with the burgeon of short videos, many real-world applications require matching short music excerpts to full-length music tracks in the database, which is still under-explored and waiting for an industrial-level solution. In this paper, we upgrade the previous ByteCover systems to ByteCover3 that utilizes local features to further improve the identification performance of short music queries. ByteCover3 is designed with a local alignment loss (LAL) module and a two-stage feature retrieval pipeline, allowing the system to perform CSI in a more precise and efficient way. We evaluated ByteCover3 on multiple datasets with different benchmark settings, where ByteCover3 beat all the compared methods including its previous versions.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [31.770366668701172, -7.235401630401611]}, {"key": "", "year": "", "title": "Duarte2015bag", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Bag of Genres for Video Retrieval\"\nauthors: Duarte Leonardo A., Penatti Ot\u00e1vio A. B., Almeida Jurandy\nconference: in\nyear: 2015\nbibkey: duarte2015bag\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1506.00051\"}\ntags: ['TIP', 'Video Retrieval']\n---\nOften, videos are composed of multiple concepts or even genres. For instance, news videos may contain sports, action, nature, etc. Therefore, encoding the distribution of such concepts/genres in a compact and effective representation is a challenging task. In this sense, we propose the Bag of Genres representation, which is based on a visual dictionary defined by a genre classifier. Each visual word corresponds to a region in the classification space. The Bag of Genres video vector contains a summary of the activations of each genre in the video content. We evaluate the proposed method for video genre retrieval using the dataset of MediaEval Tagging Task of 2012 and for video event retrieval using the EVVE dataset. Results show that the proposed method achieves results comparable or superior to state-of-the-art methods, with the advantage of providing a much more compact representation than existing features.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [1.7478264570236206, 29.35906219482422]}, {"key": "", "year": "", "title": "Dubey2017face", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Face Retrieval using Frequency Decoded Local Descriptor\"\nauthors: Dubey Shiv Ram\nconference: Arxiv\nyear: 2017\nbibkey: dubey2017face\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1709.06508\"}\ntags: ['ARXIV', 'TIP']\n---\nThe local descriptors have been the backbone of most of the computer vision problems. Most of the existing local descriptors are generated over the raw input images. In order to increase the discriminative power of the local descriptors, some researchers converted the raw image into multiple images with the help of some high and low pass frequency filters, then the local descriptors are computed over each filtered image and finally concatenated into a single descriptor. By doing so, these approaches do not utilize the inter frequency relationship which causes the less improvement in the discriminative power of the descriptor that could be achieved. In this paper, this problem is solved by utilizing the decoder concept of multi-channel decoded local binary pattern over the multi-frequency patterns. A frequency decoded local binary pattern (FDLBP) is proposed with two decoders. Each decoder works with one low frequency pattern and two high frequency patterns. Finally, the descriptors from both decoders are concatenated to form the single descriptor. The face retrieval experiments are conducted over four benchmarks and challenging databases such as PaSC, LFW, PubFig, and ESSEX. The experimental results confirm the superiority of the FDLBP descriptor as compared to the state-of-the-art descriptors such as LBP, SOBEL_LBP, BoF_LBP, SVD_S_LBP, mdLBP, etc.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [15.753527641296387, 16.600631713867188]}, {"key": "", "year": "", "title": "Dubey2021vision", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Vision Transformer Hashing for Image Retrieval\"\nauthors: Dubey Shiv Ram, Singh Satish Kumar, Chu Wei-Ta\nconference: Arxiv\nyear: 2021\nbibkey: dubey2021vision\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2109.12564\"}   - {name: \"Code\", url: \"https://github.com/shivram1987/VisionTransformerHashing}.\"}\ntags: ['ARXIV', 'Deep Learning', 'Image Retrieval', 'Quantisation', 'Supervised']\n---\nDeep learning has shown a tremendous growth in hashing techniques for image retrieval. Recently, Transformer has emerged as a new architecture by utilizing self-attention without convolution. Transformer is also extended to Vision Transformer (ViT) for the visual recognition with a promising performance on ImageNet. In this paper, we propose a Vision Transformer based Hashing (VTS) for image retrieval. We utilize the pre-trained ViT on ImageNet as the backbone network and add the hashing head. The proposed VTS model is fine tuned for hashing under six different image retrieval frameworks, including Deep Supervised Hashing (DSH), HashNet, GreedyHash, Improved Deep Hashing Network (IDHN), Deep Polarized Network (DPN) and Central Similarity Quantization (CSQ) with their objective functions. We perform the extensive experiments on CIFAR10, ImageNet, NUS-Wide, and COCO datasets. The proposed VTS based image retrieval outperforms the recent state-of-the-art hashing techniques with a great margin. We also find the proposed VTS model as the backbone network is better than the existing networks, such as AlexNet and ResNet. The code is released at \\url{https://github.com/shivram1987/VisionTransformerHashing}.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-7.988698482513428, 10.262131690979004]}, {"key": "", "year": "", "title": "Dubey2024transformer", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Transformer-based Clipped Contrastive Quantization Learning for Unsupervised Image Retrieval\"\nauthors: Dubey Ayush, Dubey Shiv Ram, Singh Satish Kumar, Chu Wei-Ta\nconference: Arxiv\nyear: 2024\nbibkey: dubey2024transformer\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2401.15362\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval', 'Quantisation', 'Self Supervised', 'Supervised', 'Unsupervised']\n---\nUnsupervised image retrieval aims to learn the important visual characteristics without any given level to retrieve the similar images for a given query image. The Convolutional Neural Network (CNN)-based approaches have been extensively exploited with self-supervised contrastive learning for image hashing. However, the existing approaches suffer due to lack of effective utilization of global features by CNNs and biased-ness created by false negative pairs in the contrastive learning. In this paper, we propose a TransClippedCLR model by encoding the global context of an image using Transformer having local context through patch based processing, by generating the hash codes through product quantization and by avoiding the potential false negative pairs through clipped contrastive learning. The proposed model is tested with superior performance for unsupervised image retrieval on benchmark datasets, including CIFAR10, NUS-Wide and Flickr25K, as compared to the recent state-of-the-art deep models. The results using the proposed clipped contrastive learning are greatly improved on all datasets as compared to same backbone network with vanilla contrastive learning.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [3.601332426071167, 15.679351806640625]}, {"key": "", "year": "", "title": "Dubiner2008bucketing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Bucketing Coding and Information Theory for the Statistical High Dimensional Nearest Neighbor Problem\"\nauthors: Dubiner Moshe\nconference: Arxiv\nyear: 2008\nbibkey: dubiner2008bucketing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/0810.4182\"}\ntags: ['ARXIV']\n---\nConsider the problem of finding high dimensional approximate nearest neighbors, where the data is generated by some known probabilistic model. We will investigate a large natural class of algorithms which we call bucketing codes. We will define bucketing information, prove that it bounds the performance of all bucketing codes, and that the bucketing information bound can be asymptotically attained by randomly constructed bucketing codes. For example suppose we have n Bernoulli(1/2) very long (length d--&gt;infinity) sequences of bits. Let n-2m sequences be completely independent, while the remaining 2m sequences are composed of m independent pairs. The interdependence within each pair is that their bits agree with probability 1/2&lt;p&lt;=1. It is well known how to find most pairs with high probability by performing order of n^{\\log_{2}2/p} comparisons. We will see that order of n^{1/p+\\epsilon} comparisons suffice, for any \\epsilon&gt;0. Moreover if one sequence out of each pair belongs to a a known set of n^{(2p-1)^{2}-\\epsilon} sequences, than pairing can be done using order n comparisons!\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-7.709838390350342, -24.206029891967773]}, {"key": "", "year": "", "title": "Duda2012optimal", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Optimal compression of hash-origin prefix trees\"\nauthors: Duda Jarek\nconference: Arxiv\nyear: 2012\nbibkey: duda2012optimal\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1206.4555\"}\ntags: ['ARXIV']\n---\nThere is a common problem of operating on hash values of elements of some database. In this paper there will be analyzed informational content of such general task and how to practically approach such found lower boundaries. Minimal prefix tree which distinguish elements turns out to require asymptotically only about 2.77544 bits per element, while standard approaches use a few times more. While being certain of working inside the database, the cost of distinguishability can be reduced further to about 2.33275 bits per elements. Increasing minimal depth of nodes to reduce probability of false positives leads to simple relation with average depth of such random tree, which is asymptotically larger by about 1.33275 bits than lg(n) of the perfect binary tree. This asymptotic case can be also seen as a way to optimally encode n large unordered numbers - saving lg(n!) bits of information about their ordering, which can be the major part of contained information. This ability itself allows to reduce memory requirements even to about 0.693 of required in Bloom filter for the same false positive probability.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-22.993024826049805, -7.859443664550781]}, {"key": "", "year": "", "title": "Duda2016distortion", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Distortion-Resistant Hashing for rapid search of similar DNA subsequence\"\nauthors: Duda Jarek\nconference: Arxiv\nyear: 2016\nbibkey: duda2016distortion\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1602.05889\"}\ntags: ['ARXIV']\n---\nOne of the basic tasks in bioinformatics is localizing a short subsequence $S$, read while sequencing, in a long reference sequence $R$, like the human geneome. A natural rapid approach would be finding a hash value for $S$ and compare it with a prepared database of hash values for each of length $|S|$ subsequences of $R$. The problem with such approach is that it would only spot a perfect match, while in reality there are lots of small changes: substitutions, deletions and insertions. This issue could be repaired if having a hash function designed to tolerate some small distortion accordingly to an alignment metric (like Needleman-Wunch): designed to make that two similar sequences should most likely give the same hash value. This paper discusses construction of Distortion-Resistant Hashing (DRH) to generate such fingerprints for rapid search of similar subsequences. The proposed approach is based on the rate distortion theory: in a nearly uniform subset of length $|S|$ sequences, the hash value represents the closest sequence to $S$. This gives some control of the distance of collisions: sequences having the same hash value.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [22.38941764831543, -16.94805145263672]}, {"key": "", "year": "", "title": "Eghbali2016fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast Cosine Similarity Search in Binary Space with Angular Multi-index Hashing\"\nauthors: Eghbali Sepehr, Tahvildari Ladan\nconference: Arxiv\nyear: 2016\nbibkey: eghbali2016fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1610.00574\"}\ntags: ['ARXIV', 'TIP']\n---\nGiven a large dataset of binary codes and a binary query point, we address how to efficiently find $K$ codes in the dataset that yield the largest cosine similarities to the query. The straightforward answer to this problem is to compare the query with all items in the dataset, but this is practical only for small datasets. One potential solution to enhance the search time and achieve sublinear cost is to use a hash table populated with binary codes of the dataset and then look up the nearby buckets to the query to retrieve the nearest neighbors. However, if codes are compared in terms of cosine similarity rather than the Hamming distance, then the main issue is that the order of buckets to probe is not evident. To examine this issue, we first elaborate on the connection between the Hamming distance and the cosine similarity. Doing this allows us to systematically find the probing sequence in the hash table. However, solving the nearest neighbor search with a single table is only practical for short binary codes. To address this issue, we propose the angular multi-index hashing search algorithm which relies on building multiple hash tables on binary code substrings. The proposed search algorithm solves the exact angular $K$ nearest neighbor problem in a time that is often orders of magnitude faster than the linear scan baseline and even approximation methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-7.341410160064697, -16.484012603759766]}, {"key": "", "year": "", "title": "Eghbali2019deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Spherical Quantization for Image Search\"\nauthors: Eghbali Sepehr, Tahvildari Ladan\nconference: Arxiv\nyear: 2019\nbibkey: eghbali2019deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1906.02865\"}\ntags: ['ARXIV', 'Image Retrieval', 'Quantisation', 'Supervised']\n---\nHashing methods, which encode high-dimensional images with compact discrete codes, have been widely applied to enhance large-scale image retrieval. In this paper, we put forward Deep Spherical Quantization (DSQ), a novel method to make deep convolutional neural networks generate supervised and compact binary codes for efficient image search. Our approach simultaneously learns a mapping that transforms the input images into a low-dimensional discriminative space, and quantizes the transformed data points using multi-codebook quantization. To eliminate the negative effect of norm variance on codebook learning, we force the network to L_2 normalize the extracted features and then quantize the resulting vectors using a new supervised quantization technique specifically designed for points lying on a unit hypersphere. Furthermore, we introduce an easy-to-implement extension of our quantization technique that enforces sparsity on the codebooks. Extensive experiments demonstrate that DSQ and its sparse variant can generate semantically separable compact binary codes outperforming many state-of-the-art image retrieval methods on three benchmarks.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [8.043183326721191, 8.992485046386719]}, {"key": "", "year": "", "title": "Eisa2013enhancing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Enhancing the retrieval performance by combing the texture and edge features\"\nauthors: Eisa Mohamed, Eletrebi Amira, Elhenawy Ebrahim\nconference: Arxiv\nyear: 2013\nbibkey: eisa2013enhancing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1301.2542\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nIn this paper, anew algorithm which is based on geometrical moments and local binary patterns (LBP) for content based image retrieval (CBIR) is proposed. In geometrical moments, each vector is compared with the all other vectors for edge map generation. The same concept is utilized at LBP calculation which is generating nine LBP patterns from a given 3x3 pattern. Finally, nine LBP histograms are calculated which are used as a feature vector for image retrieval. Moments are important features used in recognition of different types of images. Two experiments have been carried out for proving the worth of our algorithm. The results after being investigated shows a significant improvement in terms of their evaluation measures as compared to LBP and other existing transform domain techniques.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [23.988569259643555, 8.009713172912598]}, {"key": "", "year": "", "title": "Elgohary2013embed", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Embed and Conquer: Scalable Embeddings for Kernel k-Means on MapReduce\"\nauthors: Elgohary Ahmed, Farahat Ahmed K., Kamel Mohamed S., Karray Fakhri\nconference: Arxiv\nyear: 2013\nbibkey: elgohary2013embed\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1311.2334\"}\ntags: ['ARXIV']\n---\nThe kernel $k$-means is an effective method for data clustering which extends the commonly-used $k$-means algorithm to work on a similarity matrix over complex data structures. The kernel $k$-means algorithm is however computationally very complex as it requires the complete data matrix to be calculated and stored. Further, the kernelized nature of the kernel $k$-means algorithm hinders the parallelization of its computations on modern infrastructures for distributed computing. In this paper, we are defining a family of kernel-based low-dimensional embeddings that allows for scaling kernel $k$-means on MapReduce via an efficient and unified parallelization strategy. Afterwards, we propose two methods for low-dimensional embedding that adhere to our definition of the embedding family. Exploiting the proposed parallelization strategy, we present two scalable MapReduce algorithms for kernel $k$-means. We demonstrate the effectiveness and efficiency of the proposed algorithms through an empirical evaluation on benchmark data sets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [4.743539333343506, -22.08338737487793]}, {"key": "", "year": "", "title": "Elhenawy2016content", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Content-Based Image Retrieval Using Multiresolution Analysis Of Shape-Based Classified Images\"\nauthors: El-Henawy I. M., Ahmed Kareem\nconference: Global Journal of Computers &amp; Technology\nyear: 2016\nbibkey: elhenawy2016content\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1610.02509\"}\ntags: ['Image Retrieval']\n---\nContent-Based Image Retrieval (CBIR) systems have been widely used for a wide range of applications such as Art collections, Crime prevention and Intellectual property. In this paper, a novel CBIR system, which utilizes visual contents (color, texture and shape) of an image to retrieve images, is proposed. The proposed system builds three feature vectors and stores them into MySQL database. The first feature vector uses descriptive statistics to describe the distribution of data in each channel of RGB channels of the image. The second feature vector describes the texture using eigenvalues of the 39 sub-bands that are generated after applying four levels 2D DWT in each channel (red, green and blue channels) of the image. These wavelets sub-bands perfectly describes the horizontal, vertical and diagonal edges that exist in the multi-resolution analysis of the image. The third feature vector describes the basic shapes that exist in the skeletonization version of the black and white representation of the image. Experimental results on a private MYSQL database that consists of 10000 images, using color, texture, shape and stored relevance feedbacks, showed 96.4% average correct retrieval rate in an efficient recovery time.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [23.74445343017578, 10.803685188293457]}, {"key": "", "year": "", "title": "Elnouby2021training", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Training Vision Transformers for Image Retrieval\"\nauthors: El-Nouby Alaaeldin, Neverova Natalia, Laptev Ivan, J\u00e9gou Herv\u00e9\nconference: Arxiv\nyear: 2021\nbibkey: elnouby2021training\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2102.05644\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nTransformers have shown outstanding results for natural language understanding and, more recently, for image classification. We here extend this work and propose a transformer-based approach for image retrieval: we adopt vision transformers for generating image descriptors and train the resulting model with a metric learning objective, which combines a contrastive loss with a differential entropy regularizer. Our results show consistent and significant improvements of transformers over convolution-based approaches. In particular, our method outperforms the state of the art on several public benchmarks for category-level retrieval, namely Stanford Online Product, In-Shop and CUB-200. Furthermore, our experiments on ROxford and RParis also show that, in comparable settings, transformers are competitive for particular object retrieval, especially in the regime of short vector representations and low-resolution images.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [7.849157333374023, 15.952176094055176]}, {"key": "", "year": "", "title": "Engels2021practical", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Practical Near Neighbor Search via Group Testing\"\nauthors: Engels Joshua, Coleman Benjamin, Shrivastava Anshumali\nconference: Arxiv\nyear: 2021\nbibkey: engels2021practical\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2106.11565\"}\ntags: ['ARXIV', 'LSH']\n---\nWe present a new algorithm for the approximate near neighbor problem that combines classical ideas from group testing with locality-sensitive hashing (LSH). We reduce the near neighbor search problem to a group testing problem by designating neighbors as \"positives,\" non-neighbors as \"negatives,\" and approximate membership queries as group tests. We instantiate this framework using distance-sensitive Bloom Filters to Identify Near-Neighbor Groups (FLINNG). We prove that FLINNG has sub-linear query time and show that our algorithm comes with a variety of practical advantages. For example, FLINNG can be constructed in a single pass through the data, consists entirely of efficient integer operations, and does not require any distance computations. We conduct large-scale experiments on high-dimensional search tasks such as genome search, URL similarity search, and embedding search over the massive YFCC100M dataset. In our comparison with leading algorithms such as HNSW and FAISS, we find that FLINNG can provide up to a 10x query speedup with substantially smaller indexing time and memory.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [9.610289573669434, -15.334136962890625]}, {"key": "", "year": "", "title": "Eppstein2014wear", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Wear Minimization for Cuckoo Hashing: How Not to Throw a Lot of Eggs into One Basket\"\nauthors: Eppstein David, Goodrich Michael T., Mitzenmacher Michael, Pszona Pawe\u0142\nconference: Arxiv\nyear: 2014\nbibkey: eppstein2014wear\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1404.0286\"}\ntags: ['ARXIV']\n---\nWe study wear-leveling techniques for cuckoo hashing, showing that it is possible to achieve a memory wear bound of $\\log\\log n+O(1)$ after the insertion of $n$ items into a table of size $Cn$ for a suitable constant $C$ using cuckoo hashing. Moreover, we study our cuckoo hashing method empirically, showing that it significantly improves on the memory wear performance for classic cuckoo hashing and linear probing in practice.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-34.04328536987305, -0.6661349534988403]}, {"key": "", "year": "", "title": "Ercoli2016compact", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Compact Hash Codes for Efficient Visual Descriptors Retrieval in Large Scale Databases\"\nauthors: Ercoli Simone, Bertini Marco, Del Bimbo Alberto\nconference: Arxiv\nyear: 2016\nbibkey: ercoli2016compact\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1605.02892\"}\ntags: ['ARXIV', 'CNN', 'GAN', 'TIP']\n---\nIn this paper we present an efficient method for visual descriptors retrieval based on compact hash codes computed using a multiple k-means assignment. The method has been applied to the problem of approximate nearest neighbor (ANN) search of local and global visual content descriptors, and it has been tested on different datasets: three large scale public datasets of up to one billion descriptors (BIGANN) and, supported by recent progress in convolutional neural networks (CNNs), also on the CIFAR-10 and MNIST datasets. Experimental results show that, despite its simplicity, the proposed method obtains a very high performance that makes it superior to more complex state-of-the-art methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [16.221433639526367, 2.087155342102051]}, {"key": "", "year": "", "title": "Ertl2017superminhash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"SuperMinHash - A New Minwise Hashing Algorithm for Jaccard Similarity Estimation\"\nauthors: Ertl Otmar\nconference: Arxiv\nyear: 2017\nbibkey: ertl2017superminhash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1706.05698\"}\ntags: ['ARXIV']\n---\nThis paper presents a new algorithm for calculating hash signatures of sets which can be directly used for Jaccard similarity estimation. The new approach is an improvement over the MinHash algorithm, because it has a better runtime behavior and the resulting signatures allow a more precise estimation of the Jaccard index.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-26.419567108154297, -0.9400556683540344]}, {"key": "", "year": "", "title": "Ertl2018bagminhash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"BagMinHash - Minwise Hashing Algorithm for Weighted Sets\"\nauthors: Ertl Otmar\nconference: Arxiv\nyear: 2018\nbibkey: ertl2018bagminhash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1802.03914\"}\ntags: ['ARXIV']\n---\nMinwise hashing has become a standard tool to calculate signatures which allow direct estimation of Jaccard similarities. While very efficient algorithms already exist for the unweighted case, the calculation of signatures for weighted sets is still a time consuming task. BagMinHash is a new algorithm that can be orders of magnitude faster than current state of the art without any particular restrictions or assumptions on weights or data dimensionality. Applied to the special case of unweighted sets, it represents the first efficient algorithm producing independent signature components. A series of tests finally verifies the new algorithm and also reveals limitations of other approaches published in the recent past.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-24.410905838012695, -1.6426689624786377]}, {"key": "", "year": "", "title": "Ertl2019probminhash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"ProbMinHash -- A Class of Locality-Sensitive Hash Algorithms for the (Probability) Jaccard Similarity\"\nauthors: Ertl Otmar\nconference: Arxiv\nyear: 2019\nbibkey: ertl2019probminhash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1911.00675\"}\ntags: ['ARXIV']\n---\nThe probability Jaccard similarity was recently proposed as a natural generalization of the Jaccard similarity to measure the proximity of sets whose elements are associated with relative frequencies or probabilities. In combination with a hash algorithm that maps those weighted sets to compact signatures which allow fast estimation of pairwise similarities, it constitutes a valuable method for big data applications such as near-duplicate detection, nearest neighbor search, or clustering. This paper introduces a class of one-pass locality-sensitive hash algorithms that are orders of magnitude faster than the original approach. The performance gain is achieved by calculating signature components not independently, but collectively. Four different algorithms are proposed based on this idea. Two of them are statistically equivalent to the original approach and can be used as drop-in replacements. The other two may even improve the estimation error by introducing statistical dependence between signature components. Moreover, the presented techniques can be specialized for the conventional Jaccard similarity, resulting in highly efficient algorithms that outperform traditional minwise hashing and that are able to compete with the state of the art.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-2.499223232269287, -10.189873695373535]}, {"key": "", "year": "", "title": "Ertl2024jumpbackhash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"JumpBackHash: Say Goodbye to the Modulo Operation to Distribute Keys Uniformly to Buckets\"\nauthors: Ertl Otmar\nconference: Arxiv\nyear: 2024\nbibkey: ertl2024jumpbackhash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2403.18682\"}\ntags: ['ARXIV']\n---\nThe distribution of keys to a given number of buckets is a fundamental task in distributed data processing and storage. A simple, fast, and therefore popular approach is to map the hash values of keys to buckets based on the remainder after dividing by the number of buckets. Unfortunately, these mappings are not stable when the number of buckets changes, which can lead to severe spikes in system resource utilization, such as network or database requests. Consistent hash algorithms can minimize remappings, but are either significantly slower than the modulo-based approach, require floating-point arithmetic, or are based on a family of hash functions rarely available in standard libraries. This paper introduces JumpBackHash, which uses only integer arithmetic and a standard pseudorandom generator. Due to its speed and simple implementation, it can safely replace the modulo-based approach to improve assignment and system stability. A production-ready Java implementation of JumpBackHash has been released as part of the Hash4j open source library.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-25.159658432006836, -13.359993934631348]}, {"key": "", "year": "", "title": "Esen2016large", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Large-Scale Video Search with Efficient Temporal Voting Structure\"\nauthors: Esen Ersin, Ozkan Savas, Atil Ilkay\nconference: Arxiv\nyear: 2016\nbibkey: esen2016large\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1607.07160\"}\ntags: ['ARXIV']\n---\nIn this work, we propose a fast content-based video querying system for large-scale video search. The proposed system is distinguished from similar works with two major contributions. First contribution is superiority of joint usage of repeated content representation and efficient hashing mechanisms. Repeated content representation is utilized with a simple yet robust feature, which is based on edge energy of frames. Each of the representation is converted into hash code with Hamming Embedding method for further queries. Second contribution is novel queue-based voting scheme that leads to modest memory requirements with gradual memory allocation capability, contrary to complete brute-force temporal voting schemes. This aspect enables us to make queries on large video databases conveniently, even on commodity computers with limited memory capacity. Our results show that the system can respond to video queries on a large video database with fast query times, high recall rate and very low memory and disk requirements.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-0.32451027631759644, 29.19565773010254]}, {"key": "", "year": "", "title": "Esposito2019recsplit", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"RecSplit: Minimal Perfect Hashing via Recursive Splitting\"\nauthors: Esposito Emmanuel, Graf Thomas Mueller, Vigna Sebastiano\nconference: Arxiv\nyear: 2019\nbibkey: esposito2019recsplit\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1910.06416\"}\ntags: ['ARXIV']\n---\nA minimal perfect hash function bijectively maps a key set $S$ out of a universe $U$ into the first $|S|$ natural numbers. Minimal perfect hash functions are used, for example, to map irregularly-shaped keys, such as string, in a compact space so that metadata can then be simply stored in an array. While it is known that just $1.44$ bits per key are necessary to store a minimal perfect function, no published technique can go below $2$ bits per key in practice. We propose a new technique for storing minimal perfect hash functions with expected linear construction time and expected constant lookup time that makes it possible to build for the first time, for example, structures which need $1.56$ bits per key, that is, within $8.3$% of the lower bound, in less than $2$ ms per key. We show that instances of our construction are able to simultaneously beat the construction time, space usage and lookup time of the state-of-the-art data structure reaching $2$ bits per key. Moreover, we provide parameter choices giving structures which are competitive with alternative, larger-size data structures in terms of space and lookup time. The construction of our data structures can be easily parallelized or mapped on distributed computational units (e.g., within the MapReduce framework), and structures larger than the available RAM can be directly built in mass storage.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-17.85880470275879, -17.00749969482422]}, {"key": "", "year": "", "title": "Fadaei2019content", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Content-based image retrieval speedup\"\nauthors: Fadaei Sadegh, Rashno Abdolreza, Rashno Elyas\nconference: \nyear: 2019\nbibkey: fadaei2019content\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1911.11379\"}\ntags: ['Image Retrieval']\n---\nContent-based image retrieval (CBIR) is a task of retrieving images from their contents. Since retrieval process is a time-consuming task in large image databases, acceleration methods can be very useful. This paper presents a novel method to speed up CBIR systems. In the proposed method, first Zernike moments are extracted from query image and an interval is calculated for that query. Images in database which are out of the interval are ignored in retrieval process. Therefore, a database reduction occurs before retrieval which leads to speed up. It is shown that in reduced database, relevant images to query image are preserved and irrelevant images are throwed away. Therefore, the proposed method speed up retrieval process and preserve CBIR accuracy, simultaneously.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [16.337587356567383, 12.940044403076172]}, {"key": "", "year": "", "title": "Faghri2017vse", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"VSE++: Improving Visual-Semantic Embeddings with Hard Negatives\"\nauthors: Faghri Fartash, Fleet David J., Kiros Jamie Ryan, Fidler Sanja\nconference: Arxiv\nyear: 2017\nbibkey: faghri2017vse\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1707.05612\"}\ntags: ['ARXIV', 'Cross Modal', 'Image Retrieval']\n---\nWe present a new technique for learning visual-semantic embeddings for cross-modal retrieval. Inspired by hard negative mining, the use of hard negatives in structured prediction, and ranking loss functions, we introduce a simple change to common loss functions used for multi-modal embeddings. That, combined with fine-tuning and use of augmented data, yields significant gains in retrieval performance. We showcase our approach, VSE++, on MS-COCO and Flickr30K datasets, using ablation studies and comparisons with existing methods. On MS-COCO our approach outperforms state-of-the-art methods by 8.8% in caption retrieval and 11.3% in image retrieval (at R@1).\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [23.463109970092773, 3.4156041145324707]}, {"key": "", "year": "", "title": "Fang2020attention", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Attention-based Saliency Hashing for Ophthalmic Image Retrieval\"\nauthors: Fang Jiansheng, Xu Yanwu, Zhang Xiaoqing, Hu Yan, Liu Jiang\nconference: Arxiv\nyear: 2020\nbibkey: fang2020attention\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2012.03466\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nDeep hashing methods have been proved to be effective for the large-scale medical image search assisting reference-based diagnosis for clinicians. However, when the salient region plays a maximal discriminative role in ophthalmic image, existing deep hashing methods do not fully exploit the learning ability of the deep network to capture the features of salient regions pointedly. The different grades or classes of ophthalmic images may be share similar overall performance but have subtle differences that can be differentiated by mining salient regions. To address this issue, we propose a novel end-to-end network, named Attention-based Saliency Hashing (ASH), for learning compact hash-code to represent ophthalmic images. ASH embeds a spatial-attention module to focus more on the representation of salient regions and highlights their essential role in differentiating ophthalmic images. Benefiting from the spatial-attention module, the information of salient regions can be mapped into the hash-code for similarity calculation. In the training stage, we input the image pairs to share the weights of the network, and a pairwise loss is designed to maximize the discriminability of the hash-code. In the retrieval stage, ASH obtains the hash-code by inputting an image with an end-to-end manner, then the hash-code is used to similarity calculation to return the most similar images. Extensive experiments on two different modalities of ophthalmic image datasets demonstrate that the proposed ASH can further improve the retrieval performance compared to the state-of-the-art deep hashing methods due to the huge contributions of the spatial-attention module.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [28.520729064941406, 23.79627799987793]}, {"key": "", "year": "", "title": "Fang2021combating", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Combating Ambiguity for Hash-code Learning in Medical Instance Retrieval\"\nauthors: Fang Jiansheng, Fu Huazhu, Zeng Dan, Yan Xiao, Yan Yuguang, Liu Jiang\nconference: Arxiv\nyear: 2021\nbibkey: fang2021combating\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2105.08872\"}\ntags: ['ARXIV']\n---\nWhen encountering a dubious diagnostic case, medical instance retrieval can help radiologists make evidence-based diagnoses by finding images containing instances similar to a query case from a large image database. The similarity between the query case and retrieved similar cases is determined by visual features extracted from pathologically abnormal regions. However, the manifestation of these regions often lacks specificity, i.e., different diseases can have the same manifestation, and different manifestations may occur at different stages of the same disease. To combat the manifestation ambiguity in medical instance retrieval, we propose a novel deep framework called Y-Net, encoding images into compact hash-codes generated from convolutional features by feature aggregation. Y-Net can learn highly discriminative convolutional features by unifying the pixel-wise segmentation loss and classification loss. The segmentation loss allows exploring subtle spatial differences for good spatial-discriminability while the classification loss utilizes class-aware semantic information for good semantic-separability. As a result, Y-Net can enhance the visual features in pathologically abnormal regions and suppress the disturbing of the background during model training, which could effectively embed discriminative features into the hash-codes in the retrieval stage. Extensive experiments on two medical image datasets demonstrate that Y-Net can alleviate the ambiguity of pathologically abnormal regions and its retrieval performance outperforms the state-of-the-art method by an average of 9.27\\% on the returned list of 10.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [28.286548614501953, 23.91611671447754]}, {"key": "", "year": "", "title": "Fang2021deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Triplet Hashing Network for Case-based Medical Image Retrieval\"\nauthors: Fang Jiansheng, Fu Huazhu, Liu Jiang\nconference: Arxiv\nyear: 2021\nbibkey: fang2021deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2101.12346\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nDeep hashing methods have been shown to be the most efficient approximate nearest neighbor search techniques for large-scale image retrieval. However, existing deep hashing methods have a poor small-sample ranking performance for case-based medical image retrieval. The top-ranked images in the returned query results may be as a different class than the query image. This ranking problem is caused by classification, regions of interest (ROI), and small-sample information loss in the hashing space. To address the ranking problem, we propose an end-to-end framework, called Attention-based Triplet Hashing (ATH) network, to learn low-dimensional hash codes that preserve the classification, ROI, and small-sample information. We embed a spatial-attention module into the network structure of our ATH to focus on ROI information. The spatial-attention module aggregates the spatial information of feature maps by utilizing max-pooling, element-wise maximum, and element-wise mean operations jointly along the channel axis. The triplet cross-entropy loss can help to map the classification information of images and similarity between images into the hash codes. Extensive experiments on two case-based medical datasets demonstrate that our proposed ATH can further improve the retrieval performance compared to the state-of-the-art deep hashing methods and boost the ranking performance for small samples. Compared to the other loss methods, the triplet cross-entropy loss can enhance the classification performance and hash code-discriminability\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [28.551307678222656, 23.93008041381836]}, {"key": "", "year": "", "title": "Faro2008efficient", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Efficient Pattern Matching on Binary Strings\"\nauthors: Faro Simone, Lecroq Thierry\nconference: Arxiv\nyear: 2008\nbibkey: faro2008efficient\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/0810.2390\"}\ntags: ['ARXIV']\n---\nThe binary string matching problem consists in finding all the occurrences of a pattern in a text where both strings are built on a binary alphabet. This is an interesting problem in computer science, since binary data are omnipresent in telecom and computer network applications. Moreover the problem finds applications also in the field of image processing and in pattern matching on compressed texts. Recently it has been shown that adaptations of classical exact string matching algorithms are not very efficient on binary data. In this paper we present two efficient algorithms for the problem adapted to completely avoid any reference to bits allowing to process pattern and text byte by byte. Experimental results show that the new algorithms outperform existing solutions in most cases.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [0.6262240409851074, -10.435115814208984]}, {"key": "", "year": "", "title": "Fedorov2016large", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Large scale near-duplicate image retrieval using Triples of Adjacent Ranked Features (TARF) with embedded geometric information\"\nauthors: Fedorov Sergei, Kacher Olga\nconference: Arxiv\nyear: 2016\nbibkey: fedorov2016large\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1603.06093\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nMost approaches to large-scale image retrieval are based on the construction of the inverted index of local image descriptors or visual words. A search in such an index usually results in a large number of candidates. This list of candidates is then re-ranked with the help of a geometric verification, using a RANSAC algorithm, for example. In this paper we propose a feature representation, which is built as a combination of three local descriptors. It allows one to significantly decrease the number of false matches and to shorten the list of candidates after the initial search in the inverted index. This combination of local descriptors is both reproducible and highly discriminative, and thus can be efficiently used for large-scale near-duplicate image retrieval.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [19.833951950073242, 14.90182113647461]}, {"key": "", "year": "", "title": "Feng2014learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning to Rank Binary Codes\"\nauthors: Feng Jie, Liu Wei, Wang Yan\nconference: Arxiv\nyear: 2014\nbibkey: feng2014learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1410.5524\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nBinary codes have been widely used in vision problems as a compact feature representation to achieve both space and time advantages. Various methods have been proposed to learn data-dependent hash functions which map a feature vector to a binary code. However, considerable data information is inevitably lost during the binarization step which also causes ambiguity in measuring sample similarity using Hamming distance. Besides, the learned hash functions cannot be changed after training, which makes them incapable of adapting to new data outside the training data set. To address both issues, in this paper we propose a flexible bitwise weight learning framework based on the binary codes obtained by state-of-the-art hashing methods, and incorporate the learned weights into the weighted Hamming distance computation. We then formulate the proposed framework as a ranking problem and leverage the Ranking SVM model to offline tackle the weight learning. The framework is further extended to an online mode which updates the weights at each time new data comes, thereby making it scalable to large and dynamic data sets. Extensive experimental results demonstrate significant performance gains of using binary codes with bitwise weighting in image retrieval tasks. It is appealing that the online weight learning leads to comparable accuracy with its offline counterpart, which thus makes our approach practical for realistic applications.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [0.07032900303602219, 2.460928440093994]}, {"key": "", "year": "", "title": "Feng2016deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Image Set Hashing\"\nauthors: Feng Jie, Karaman Svebor, Jhuo I-Hong, Chang Shih-Fu\nconference: Arxiv\nyear: 2016\nbibkey: feng2016deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1606.05381\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval', 'TIP']\n---\nIn applications involving matching of image sets, the information from multiple images must be effectively exploited to represent each set. State-of-the-art methods use probabilistic distribution or subspace to model a set and use specific distance measure to compare two sets. These methods are slow to compute and not compact to use in a large scale scenario. Learning-based hashing is often used in large scale image retrieval as they provide a compact representation of each sample and the Hamming distance can be used to efficiently compare two samples. However, most hashing methods encode each image separately and discard knowledge that multiple images in the same set represent the same object or person. We investigate the set hashing problem by combining both set representation and hashing in a single deep neural network. An image set is first passed to a CNN module to extract image features, then these features are aggregated using two types of set feature to capture both set specific and database-wide distribution information. The computed set feature is then fed into a multilayer perceptron to learn a compact binary embedding. Triplet loss is used to train the network by forming set similarity relations using class labels. We extensively evaluate our approach on datasets used for image matching and show highly competitive performance compared to state-of-the-art methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-1.4796478748321533, 18.37384796142578]}, {"key": "", "year": "", "title": "Feng2023towards", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Towards Efficient Deep Hashing Retrieval: Condensing Your Data via Feature-Embedding Matching\"\nauthors: Feng Tao, Zhang Jie, Wang Peizheng, Wang Zhijie\nconference: Arxiv\nyear: 2023\nbibkey: feng2023towards\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2305.18076\"}\ntags: ['ARXIV']\n---\nThe expenses involved in training state-of-the-art deep hashing retrieval models have witnessed an increase due to the adoption of more sophisticated models and large-scale datasets. Dataset Distillation (DD) or Dataset Condensation(DC) focuses on generating smaller synthetic dataset that retains the original information. Nevertheless, existing DD methods face challenges in maintaining a trade-off between accuracy and efficiency. And the state-of-the-art dataset distillation methods can not expand to all deep hashing retrieval methods. In this paper, we propose an efficient condensation framework that addresses these limitations by matching the feature-embedding between synthetic set and real set. Furthermore, we enhance the diversity of features by incorporating the strategies of early-stage augmented models and multi-formation. Extensive experiments provide compelling evidence of the remarkable superiority of our approach, both in terms of performance and efficiency, compared to state-of-the-art baseline methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-18.272937774658203, 4.4604411125183105]}, {"key": "", "year": "", "title": "Ferdowsi2017a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A multi-layer network based on Sparse Ternary Codes for universal vector compression\"\nauthors: Ferdowsi Sohrab, Voloshynovskiy Slava, Kostadinov Dimche\nconference: Arxiv\nyear: 2017\nbibkey: ferdowsi2017a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1710.11510\"}\ntags: ['ARXIV', 'TIP']\n---\nWe present the multi-layer extension of the Sparse Ternary Codes (STC) for fast similarity search where we focus on the reconstruction of the database vectors from the ternary codes. To consider the trade-offs between the compactness of the STC and the quality of the reconstructed vectors, we study the rate-distortion behavior of these codes under different setups. We show that a single-layer code cannot achieve satisfactory results at high rates. Therefore, we extend the concept of STC to multiple layers and design the ML-STC, a codebook-free system that successively refines the reconstruction of the residuals of previous layers. While the ML-STC keeps the sparse ternary structure of the single-layer STC and hence is suitable for fast similarity search in large-scale databases, we show its superior rate-distortion performance on both model-based synthetic data and public large-scale databases, as compared to several binary hashing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.30268383026123, -8.310688018798828]}, {"key": "", "year": "", "title": "Ferdowsi2017sparse", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Sparse Ternary Codes for similarity search have higher coding gain than dense binary codes\"\nauthors: Ferdowsi Sohrab, Voloshynovskiy Slava, Kostadinov Dimche, Holotyak Taras\nconference: Arxiv\nyear: 2017\nbibkey: ferdowsi2017sparse\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1701.07675\"}\ntags: ['ARXIV']\n---\nThis paper addresses the problem of Approximate Nearest Neighbor (ANN) search in pattern recognition where feature vectors in a database are encoded as compact codes in order to speed-up the similarity search in large-scale databases. Considering the ANN problem from an information-theoretic perspective, we interpret it as an encoding, which maps the original feature vectors to a less entropic sparse representation while requiring them to be as informative as possible. We then define the coding gain for ANN search using information-theoretic measures. We next show that the classical approach to this problem, which consists of binarization of the projected vectors is sub-optimal. Instead, a properly designed ternary encoding achieves higher coding gains and lower complexity.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.723938941955566, -8.606006622314453]}, {"key": "", "year": "", "title": "Fernandez2022active", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Active Image Indexing\"\nauthors: Fernandez Pierre, Douze Matthijs, J\u00e9gou Herv\u00e9, Furon Teddy\nconference: Arxiv\nyear: 2022\nbibkey: fernandez2022active\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2210.10620\"}\ntags: ['ARXIV', 'Quantisation']\n---\nImage copy detection and retrieval from large databases leverage two components. First, a neural network maps an image to a vector representation, that is relatively robust to various transformations of the image. Second, an efficient but approximate similarity search algorithm trades scalability (size and speed) against quality of the search, thereby introducing a source of error. This paper improves the robustness of image copy detection with active indexing, that optimizes the interplay of these two components. We reduce the quantization loss of a given image representation by making imperceptible changes to the image before its release. The loss is back-propagated through the deep neural network back to the image, under perceptual constraints. These modifications make the image more retrievable. Our experiments show that the retrieval and copy detection of activated images is significantly improved. For instance, activation improves by $+40\\%$ the Recall1@1 on various image transformations, and for several popular indexing structures based on product quantization and locality sensitivity hashing.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [10.512752532958984, 5.4426960945129395]}, {"key": "", "year": "", "title": "Ferragina2023learned", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learned Monotone Minimal Perfect Hashing\"\nauthors: Ferragina Paolo, Lehmann Hans-Peter, Sanders Peter, Vinciguerra Giorgio\nconference: Arxiv\nyear: 2023\nbibkey: ferragina2023learned\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2304.11012\"}\ntags: ['ARXIV']\n---\nA Monotone Minimal Perfect Hash Function (MMPHF) constructed on a set S of keys is a function that maps each key in S to its rank. On keys not in S, the function returns an arbitrary value. Applications range from databases, search engines, data encryption, to pattern-matching algorithms. In this paper, we describe LeMonHash, a new technique for constructing MMPHFs for integers. The core idea of LeMonHash is surprisingly simple and effective: we learn a monotone mapping from keys to their rank via an error-bounded piecewise linear model (the PGM-index), and then we solve the collisions that might arise among keys mapping to the same rank estimate by associating small integers with them in a retrieval data structure (BuRR). On synthetic random datasets, LeMonHash needs 34% less space than the next larger competitor, while achieving about 16 times faster queries. On real-world datasets, the space usage is very close to or much better than the best competitors, while achieving up to 19 times faster queries than the next larger competitor. As far as the construction of LeMonHash is concerned, we get an improvement by a factor of up to 2, compared to the competitor with the next best space usage. We also investigate the case of keys being variable-length strings, introducing the so-called LeMonHash-VL: it needs space within 13% of the best competitors while achieving up to 3 times faster queries than the next larger competitor.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-16.17300033569336, -16.94782257080078]}, {"key": "", "year": "", "title": "Ferraro2023contrastive", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Contrastive Learning for Cross-modal Artist Retrieval\"\nauthors: Ferraro Andres, Kim Jaehun, Oramas Sergio, Ehmann Andreas, Gouyon Fabien\nconference: Arxiv\nyear: 2023\nbibkey: ferraro2023contrastive\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2308.06556\"}\ntags: ['ARXIV', 'Cross Modal', 'TIP']\n---\nMusic retrieval and recommendation applications often rely on content features encoded as embeddings, which provide vector representations of items in a music dataset. Numerous complementary embeddings can be derived from processing items originally represented in several modalities, e.g., audio signals, user interaction data, or editorial data. However, data of any given modality might not be available for all items in any music dataset. In this work, we propose a method based on contrastive learning to combine embeddings from multiple modalities and explore the impact of the presence or absence of embeddings from diverse modalities in an artist similarity task. Experiments on two datasets suggest that our contrastive method outperforms single-modality embeddings and baseline algorithms for combining modalities, both in terms of artist retrieval accuracy and coverage. Improvements with respect to other methods are particularly significant for less popular query artists. We demonstrate our method successfully combines complementary information from diverse modalities, and is more robust to missing modality data (i.e., it better handles the retrieval of artists with different modality embeddings than the query artist's).\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [28.937049865722656, -7.849250316619873]}, {"key": "", "year": "", "title": "Forcen2020co", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Co-occurrence of deep convolutional features for image search\"\nauthors: Forcen J. I., Pagola Miguel, Barrenechea Edurne, Bustince Humberto\nconference: Arxiv\nyear: 2020\nbibkey: forcen2020co\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2003.13827\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval']\n---\nImage search can be tackled using deep features from pre-trained Convolutional Neural Networks (CNN). The feature map from the last convolutional layer of a CNN encodes descriptive information from which a discriminative global descriptor can be obtained. We propose a new representation of co-occurrences from deep convolutional features to extract additional relevant information from this last convolutional layer. Combining this co-occurrence map with the feature map, we achieve an improved image representation. We present two different methods to get the co-occurrence representation, the first one based on direct aggregation of activations, and the second one, based on a trainable co-occurrence representation. The image descriptors derived from our methodology improve the performance in very well-known image retrieval datasets as we prove in the experiments.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.776589393615723, 27.385114669799805]}, {"key": "", "year": "", "title": "Fountoulakis2010on", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"On the Insertion Time of Cuckoo Hashing\"\nauthors: Fountoulakis Nikolaos, Panagiotou Konstantinos, Steger Angelika\nconference: Arxiv\nyear: 2010\nbibkey: fountoulakis2010on\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1006.1231\"}\ntags: ['ARXIV']\n---\nCuckoo hashing is an efficient technique for creating large hash tables with high space utilization and guaranteed constant access times. There, each item can be placed in a location given by any one out of k different hash functions. In this paper we investigate further the random walk heuristic for inserting in an online fashion new items into the hash table. Provided that k &gt; 2 and that the number of items in the table is below (but arbitrarily close) to the theoretically achievable load threshold, we show a polylogarithmic bound for the maximum insertion time that holds with high probability.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-25.512359619140625, -7.413407325744629]}, {"key": "", "year": "", "title": "Frei2023bounds", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Bounds for c-Ideal Hashing\"\nauthors: Frei Fabian, Wehner David\nconference: Arxiv\nyear: 2023\nbibkey: frei2023bounds\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2301.13832\"}\ntags: ['ARXIV']\n---\nIn this paper, we analyze hashing from a worst-case perspective. To this end, we study a new property of hash families that is strongly related to d-perfect hashing, namely c-ideality. On the one hand, this notion generalizes the definition of perfect hashing, which has been studied extensively; on the other hand, it provides a direct link to the notion of c-approximativity. We focus on the usually neglected case where the average load \\alpha is at least 1 and prove upper and lower parametrized bounds on the minimal size of c-ideal hash families. As an aside, we show how c-ideality helps to analyze the advice complexity of hashing. The concept of advice, introduced a decade ago, lets us measure the information content of an online problem. We prove hashing's advice complexity to be linear in the hash table size.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-21.931537628173828, -1.2420830726623535]}, {"key": "", "year": "", "title": "Freksen2018fully", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fully Understanding the Hashing Trick\"\nauthors: Freksen Casper Benjamin, Kamma Lior, Larsen Kasper Green\nconference: Arxiv\nyear: 2018\nbibkey: freksen2018fully\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1805.08539\"}\ntags: ['ARXIV']\n---\nFeature hashing, also known as {\\em the hashing trick}, introduced by Weinberger et al. (2009), is one of the key techniques used in scaling-up machine learning algorithms. Loosely speaking, feature hashing uses a random sparse projection matrix $A : \\mathbb\\{R\\}^n \\to \\mathbb\\{R\\}^m$ (where $m \\ll n$) in order to reduce the dimension of the data from $n$ to $m$ while approximately preserving the Euclidean norm. Every column of $A$ contains exactly one non-zero entry, equals to either $-1$ or $1$. Weinberger et al. showed tail bounds on $\\|Ax\\|_2^2$. Specifically they showed that for every $\\varepsilon, \\delta$, if $\\|x\\|_\\{\\infty\\} / \\|x\\|_2$ is sufficiently small, and $m$ is sufficiently large, then $$\\Pr[ \\; | \\;\\|Ax\\|_2^2 - \\|x\\|_2^2\\; | &lt; \\varepsilon \\|x\\|_2^2 \\;] \\ge 1 - \\delta \\;.$$ These bounds were later extended by Dasgupta \\etal (2010) and most recently refined by Dahlgaard et al. (2017), however, the true nature of the performance of this key technique, and specifically the correct tradeoff between the pivotal parameters $\\|x\\|_\\{\\infty\\} / \\|x\\|_2, m, \\varepsilon, \\delta$ remained an open question. We settle this question by giving tight asymptotic bounds on the exact tradeoff between the central parameters, thus providing a complete understanding of the performance of feature hashing. We complement the asymptotic bound with empirical data, which shows that the constants \"hiding\" in the asymptotic notation are, in fact, very close to $1$, thus further illustrating the tightness of the presented bounds in practice.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-13.196026802062988, -22.929656982421875]}, {"key": "", "year": "", "title": "Frieze2016on", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"On the insertion time of random walk cuckoo hashing\"\nauthors: Frieze Alan, Johansson Tony\nconference: Arxiv\nyear: 2016\nbibkey: frieze2016on\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1602.04652\"}\ntags: ['ARXIV']\n---\nCuckoo Hashing is a hashing scheme invented by Pagh and Rodler. It uses $d\\geq 2$ distinct hash functions to insert items into the hash table. It has been an open question for some time as to the expected time for Random Walk Insertion to add items. We show that if the number of hash functions $d=O(1)$ is sufficiently large, then the expected insertion time is $O(1)$ per item.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-25.94630241394043, -7.054570198059082]}, {"key": "", "year": "", "title": "Fu2016auto", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Auto-JacoBin: Auto-encoder Jacobian Binary Hashing\"\nauthors: Fu Xiping, McCane Brendan, Mills Steven, Albert Michael, Szymanski Lech\nconference: Arxiv\nyear: 2016\nbibkey: fu2016auto\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1602.08127\"}\ntags: ['ARXIV']\n---\nBinary codes can be used to speed up nearest neighbor search tasks in large scale data sets as they are efficient for both storage and retrieval. In this paper, we propose a robust auto-encoder model that preserves the geometric relationships of high-dimensional data sets in Hamming space. This is done by considering a noise-removing function in a region surrounding the manifold where the training data points lie. This function is defined with the property that it projects the data points near the manifold into the manifold wisely, and we approximate this function by its first order approximation. Experimental results show that the proposed method achieves better than state-of-the-art results on three large scale high dimensional data sets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.609179496765137, -6.558657169342041]}, {"key": "", "year": "", "title": "Fu2018neurons", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Neurons Merging Layer: Towards Progressive Redundancy Reduction for Deep Supervised Hashing\"\nauthors: Fu Chaoyou, Song Liangchen, Wu Xiang, Wang Guoli, He Ran\nconference: Arxiv\nyear: 2018\nbibkey: fu2018neurons\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1809.02302\"}\ntags: ['ARXIV', 'Graph', 'Supervised', 'TIP']\n---\nDeep supervised hashing has become an active topic in information retrieval. It generates hashing bits by the output neurons of a deep hashing network. During binary discretization, there often exists much redundancy between hashing bits that degenerates retrieval performance in terms of both storage and accuracy. This paper proposes a simple yet effective Neurons Merging Layer (NMLayer) for deep supervised hashing. A graph is constructed to represent the redundancy relationship between hashing bits that is used to guide the learning of a hashing network. Specifically, it is dynamically learned by a novel mechanism defined in our active and frozen phases. According to the learned relationship, the NMLayer merges the redundant neurons together to balance the importance of each output neuron. Moreover, multiple NMLayers are progressively trained for a deep hashing network to learn a more compact hashing code from a long redundant code. Extensive experiments on four datasets demonstrate that our proposed method outperforms state-of-the-art hashing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-18.09235382080078, 12.76843547821045]}, {"key": "", "year": "", "title": "Fu2020deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Momentum Uncertainty Hashing\"\nauthors: Fu Chaoyou, Wang Guoli, Wu Xiang, Zhang Qian, He Ran\nconference: Arxiv\nyear: 2020\nbibkey: fu2020deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2009.08012\"}\ntags: ['ARXIV']\n---\nCombinatorial optimization (CO) has been a hot research topic because of its theoretic and practical importance. As a classic CO problem, deep hashing aims to find an optimal code for each data from finite discrete possibilities, while the discrete nature brings a big challenge to the optimization process. Previous methods usually mitigate this challenge by binary approximation, substituting binary codes for real-values via activation functions or regularizations. However, such approximation leads to uncertainty between real-values and binary ones, degrading retrieval performance. In this paper, we propose a novel Deep Momentum Uncertainty Hashing (DMUH). It explicitly estimates the uncertainty during training and leverages the uncertainty information to guide the approximation process. Specifically, we model bit-level uncertainty via measuring the discrepancy between the output of a hashing network and that of a momentum-updated network. The discrepancy of each bit indicates the uncertainty of the hashing network to the approximate output of that bit. Meanwhile, the mean discrepancy of all bits in a hashing code can be regarded as image-level uncertainty. It embodies the uncertainty of the hashing network to the corresponding input image. The hashing bit and image with higher uncertainty are paid more attention during optimization. To the best of our knowledge, this is the first work to study the uncertainty in hashing bits. Extensive experiments are conducted on four datasets to verify the superiority of our method, including CIFAR-10, NUS-WIDE, MS-COCO, and a million-scale dataset Clothing1M. Our method achieves the best performance on all of the datasets and surpasses existing state-of-the-art methods by a large margin.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-13.179539680480957, -12.699033737182617]}, {"key": "", "year": "", "title": "Gagie2013compressed", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Compressed Spaced Suffix Arrays\"\nauthors: Gagie Travis, Manzini Giovanni, Valenzuela Daniel\nconference: Arxiv\nyear: 2013\nbibkey: gagie2013compressed\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1312.3422\"}\ntags: ['ARXIV']\n---\nSpaced seeds are important tools for similarity search in bioinformatics, and using several seeds together often significantly improves their performance. With existing approaches, however, for each seed we keep a separate linear-size data structure, either a hash table or a spaced suffix array (SSA). In this paper we show how to compress SSAs relative to normal suffix arrays (SAs) and still support fast random access to them. We first prove a theoretical upper bound on the space needed to store an SSA when we already have the SA. We then present experiments indicating that our approach works even better in practice.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [20.06822967529297, -17.51695442199707]}, {"key": "", "year": "", "title": "Gagie2014searching", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Searching and Indexing Genomic Databases via Kernelization\"\nauthors: Gagie Travis, Puglisi Simon J.\nconference: Arxiv\nyear: 2014\nbibkey: gagie2014searching\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1412.1591\"}\ntags: ['ARXIV', 'Survey Paper']\n---\nThe rapid advance of DNA sequencing technologies has yielded databases of thousands of genomes. To search and index these databases effectively, it is important that we take advantage of the similarity between those genomes. Several authors have recently suggested searching or indexing only one reference genome and the parts of the other genomes where they differ. In this paper we survey the twenty-year history of this idea and discuss its relation to kernelization in parameterized complexity.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [20.687950134277344, -16.705780029296875]}, {"key": "", "year": "", "title": "Gagie2014suffix", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Suffix Arrays for Spaced-SNP Databases\"\nauthors: Gagie Travis\nconference: Arxiv\nyear: 2014\nbibkey: gagie2014suffix\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1407.0114\"}\ntags: ['ARXIV']\n---\nSingle-nucleotide polymorphisms (SNPs) account for most variations between human genomes. We show how, if the genomes in a database differ only by a reasonable number of SNPs and the substrings between those SNPs are unique, then we can store a fast compressed suffix array for that database.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [20.558269500732422, -16.409461975097656]}, {"key": "", "year": "", "title": "Gajic2019bag", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Bag of Negatives for Siamese Architectures\"\nauthors: Gajic Bojana, Amato Ariel, Baldrich Ramon, Gatta Carlo\nconference: Arxiv\nyear: 2019\nbibkey: gajic2019bag\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1908.02391\"}\ntags: ['ARXIV']\n---\nTraining a Siamese architecture for re-identification with a large number of identities is a challenging task due to the difficulty of finding relevant negative samples efficiently. In this work we present Bag of Negatives (BoN), a method for accelerated and improved training of Siamese networks that scales well on datasets with a very large number of identities. BoN is an efficient and loss-independent method, able to select a bag of high quality negatives, based on a novel online hashing strategy.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-15.539196968078613, 16.10303497314453]}, {"key": "", "year": "", "title": "Gan2023binary", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Binary Embedding-based Retrieval at Tencent\"\nauthors: Gan Yukang, Ge Yixiao, Zhou Chang, Su Shupeng, Xu Zhouchuan, Xu Xuyuan, Hui Quanchao, Chen Xiang, Wang Yexin, Shan Ying\nconference: Arxiv\nyear: 2023\nbibkey: gan2023binary\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2302.08714\"}\ntags: ['ARXIV', 'TIP', 'TOM']\n---\nLarge-scale embedding-based retrieval (EBR) is the cornerstone of search-related industrial applications. Given a user query, the system of EBR aims to identify relevant information from a large corpus of documents that may be tens or hundreds of billions in size. The storage and computation turn out to be expensive and inefficient with massive documents and high concurrent queries, making it difficult to further scale up. To tackle the challenge, we propose a binary embedding-based retrieval (BEBR) engine equipped with a recurrent binarization algorithm that enables customized bits per dimension. Specifically, we compress the full-precision query and document embeddings, formulated as float vectors in general, into a composition of multiple binary vectors using a lightweight transformation model with residual multilayer perception (MLP) blocks. We can therefore tailor the number of bits for different applications to trade off accuracy loss and cost savings. Importantly, we enable task-agnostic efficient training of the binarization model using a new embedding-to-embedding strategy. We also exploit the compatible training of binary embeddings so that the BEBR engine can support indexing among multiple embedding versions within a unified system. To further realize efficient search, we propose Symmetric Distance Calculation (SDC) to achieve lower response time than Hamming codes. We successfully employed the introduced BEBR to Tencent products, including Sogou, Tencent Video, QQ World, etc. The binarization algorithm can be seamlessly generalized to various tasks with multiple modalities. Extensive experiments on offline benchmarks and online A/B tests demonstrate the efficiency and effectiveness of our method, significantly saving 30%~50% index costs with almost no loss of accuracy at the system level.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-6.696770668029785, -1.776777982711792]}, {"key": "", "year": "", "title": "Gao2021backdoor", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Backdoor Attack on Hash-based Image Retrieval via Clean-label Data Poisoning\"\nauthors: Gao Kuofeng, Bai Jiawang, Chen Bin, Wu Dongxian, Xia Shu-Tao\nconference: Arxiv\nyear: 2021\nbibkey: gao2021backdoor\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2109.08868\"}   - {name: \"Code\", url: \"https://github.com/KuofengGao/CIBA.\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nA backdoored deep hashing model is expected to behave normally on original query images and return the images with the target label when a specific trigger pattern presents. To this end, we propose the confusing perturbations-induced backdoor attack (CIBA). It injects a small number of poisoned images with the correct label into the training data, which makes the attack hard to be detected. To craft the poisoned images, we first propose the confusing perturbations to disturb the hashing code learning. As such, the hashing model can learn more about the trigger. The confusing perturbations are imperceptible and generated by optimizing the intra-class dispersion and inter-class shift in the Hamming space. We then employ the targeted adversarial patch as the backdoor trigger to improve the attack performance. We have conducted extensive experiments to verify the effectiveness of our proposed CIBA. Our code is available at https://github.com/KuofengGao/CIBA.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-8.50863265991211, 12.328213691711426]}, {"key": "", "year": "", "title": "Gao2022long", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Long-tail Cross Modal Hashing\"\nauthors: Gao Zijun, Wang Jun, Yu Guoxian, Yan Zhongmin, Domeniconi Carlotta, Zhang Jinglin\nconference: Arxiv\nyear: 2022\nbibkey: gao2022long\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2211.15162\"}\ntags: ['ARXIV', 'Cross Modal']\n---\nExisting Cross Modal Hashing (CMH) methods are mainly designed for balanced data, while imbalanced data with long-tail distribution is more general in real-world. Several long-tail hashing methods have been proposed but they can not adapt for multi-modal data, due to the complex interplay between labels and individuality and commonality information of multi-modal data. Furthermore, CMH methods mostly mine the commonality of multi-modal data to learn hash codes, which may override tail labels encoded by the individuality of respective modalities. In this paper, we propose LtCMH (Long-tail CMH) to handle imbalanced multi-modal data. LtCMH firstly adopts auto-encoders to mine the individuality and commonality of different modalities by minimizing the dependency between the individuality of respective modalities and by enhancing the commonality of these modalities. Then it dynamically combines the individuality and commonality with direct features extracted from respective modalities to create meta features that enrich the representation of tail labels, and binaries meta features to generate hash codes. LtCMH significantly outperforms state-of-the-art baselines on long-tail datasets and holds a better (or comparable) performance on datasets with balanced labels.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-5.2591753005981445, -1.9458955526351929]}, {"key": "", "year": "", "title": "Garcia2017learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning Non-Metric Visual Similarity for Image Retrieval\"\nauthors: Garcia Noa, Vogiatzis George\nconference: Arxiv\nyear: 2017\nbibkey: garcia2017learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1709.01353\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nMeasuring visual similarity between two or more instances within a data distribution is a fundamental task in image retrieval. Theoretically, non-metric distances are able to generate a more complex and accurate similarity model than metric distances, provided that the non-linear data distribution is precisely captured by the system. In this work, we explore neural networks models for learning a non-metric similarity function for instance search. We argue that non-metric similarity functions based on neural networks can build a better model of human visual perception than standard metric distances. As our proposed similarity function is differentiable, we explore a real end-to-end trainable approach for image retrieval, i.e. we learn the weights from the input image pixels to the final similarity score. Experimental evaluation shows that non-metric similarity networks are able to learn visual similarities between images and improve performance on top of state-of-the-art image representations, boosting results in standard image retrieval datasets with respect standard metric distances.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [14.575085639953613, 5.719843864440918]}, {"key": "", "year": "", "title": "Garg2010close", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Close Clustering Based Automated Color Image Annotation\"\nauthors: Garg Ankit, Dwivedi Rahul, Asawa Krishna\nconference: Arxiv\nyear: 2010\nbibkey: garg2010close\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1008.0336\"}\ntags: ['ARXIV', 'TOM']\n---\nMost image-search approaches today are based on the text based tags associated with the images which are mostly human generated and are subject to various kinds of errors. The results of a query to the image database thus can often be misleading and may not satisfy the requirements of the user. In this work we propose our approach to automate this tagging process of images, where image results generated can be fine filtered based on a probabilistic tagging mechanism. We implement a tool which helps to automate the tagging process by maintaining a training database, wherein the system is trained to identify certain set of input images, the results generated from which are used to create a probabilistic tagging mechanism. Given a certain set of segments in an image it calculates the probability of presence of particular keywords. This probability table is further used to generate the candidate tags for input images.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [23.797334671020508, 13.80910587310791]}, {"key": "", "year": "", "title": "Garg2017kernelized", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Kernelized Hashcode Representations for Relation Extraction\"\nauthors: Garg Sahil, Galstyan Aram, Steeg Greg Ver, Rish Irina, Cecchi Guillermo, Gao Shuyang\nconference: Arxiv\nyear: 2017\nbibkey: garg2017kernelized\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1711.04044\"}\ntags: ['ARXIV', 'Graph', 'LSH']\n---\nKernel methods have produced state-of-the-art results for a number of NLP tasks such as relation extraction, but suffer from poor scalability due to the high cost of computing kernel similarities between natural language structures. A recently proposed technique, kernelized locality-sensitive hashing (KLSH), can significantly reduce the computational cost, but is only applicable to classifiers operating on kNN graphs. Here we propose to use random subspaces of KLSH codes for efficiently constructing an explicit representation of NLP structures suitable for general classification methods. Further, we propose an approach for optimizing the KLSH model for classification problems by maximizing an approximation of mutual information between the KLSH codes (feature vectors) and the class labels. We evaluate the proposed approach on biomedical relation extraction datasets, and observe significant and robust improvements in accuracy w.r.t. state-of-the-art classifiers, along with drastic (orders-of-magnitude) speedup compared to conventional kernel methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-18.022741317749023, 19.336097717285156]}, {"key": "", "year": "", "title": "Garg2019nearly", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Nearly-Unsupervised Hashcode Representations for Relation Extraction\"\nauthors: Garg Sahil, Galstyan Aram, Steeg Greg Ver, Cecchi Guillermo\nconference: Arxiv\nyear: 2019\nbibkey: garg2019nearly\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1909.03881\"}\ntags: ['ARXIV', 'Semi Supervised', 'Supervised', 'Unsupervised']\n---\nRecently, kernelized locality sensitive hashcodes have been successfully employed as representations of natural language text, especially showing high relevance to biomedical relation extraction tasks. In this paper, we propose to optimize the hashcode representations in a nearly unsupervised manner, in which we only use data points, but not their class labels, for learning. The optimized hashcode representations are then fed to a supervised classifier following the prior work. This nearly unsupervised approach allows fine-grained optimization of each hash function, which is particularly suitable for building hashcode representations generalizing from a training set to a test set. We empirically evaluate the proposed approach for biomedical relation extraction tasks, obtaining significant accuracy improvements w.r.t. state-of-the-art supervised and semi-supervised approaches.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-17.987682342529297, 19.266571044921875]}, {"key": "", "year": "", "title": "Gaskill2019the", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"The Bitwise Hashing Trick for Personalized Search\"\nauthors: Gaskill Braddock\nconference: Applied Artificial Intelligence, Volume\nyear: 2019\nbibkey: gaskill2019the\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1910.08646\"}\ntags: ['Volume']\n---\nMany real world problems require fast and efficient lexical comparison of large numbers of short text strings. Search personalization is one such domain. We introduce the use of feature bit vectors using the hashing trick for improving relevance in personalized search and other personalization applications. We present results of several lexical hashing and comparison methods. These methods are applied to a user's historical behavior and are used to predict future behavior. Using a single bit per dimension instead of floating point results in an order of magnitude decrease in data structure size, while preserving or even improving quality. We use real data to simulate a search personalization task. A simple method for combining bit vectors demonstrates an order of magnitude improvement in compute time on the task with only a small decrease in accuracy.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [3.4360857009887695, -5.355950832366943]}, {"key": "", "year": "", "title": "Gattupalli2018weakly", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Weakly Supervised Deep Image Hashing through Tag Embeddings\"\nauthors: Gattupalli Vijetha, Zhuo Yaoxin, Li Baoxin\nconference: Arxiv\nyear: 2018\nbibkey: gattupalli2018weakly\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1806.05804\"}\ntags: ['ARXIV', 'Image Retrieval', 'Supervised', 'Weakly Supervised']\n---\nMany approaches to semantic image hashing have been formulated as supervised learning problems that utilize images and label information to learn the binary hash codes. However, large-scale labeled image data is expensive to obtain, thus imposing a restriction on the usage of such algorithms. On the other hand, unlabelled image data is abundant due to the existence of many Web image repositories. Such Web images may often come with images tags that contain useful information, although raw tags, in general, do not readily lead to semantic labels. Motivated by this scenario, we formulate the problem of semantic image hashing as a weakly-supervised learning problem. We utilize the information contained in the user-generated tags associated with the images to learn the hash codes. More specifically, we extract the word2vec semantic embeddings of the tags and use the information contained in them for constraining the learning. Accordingly, we name our model Weakly Supervised Deep Hashing using Tag Embeddings (WDHT). WDHT is tested for the task of semantic image retrieval and is compared against several state-of-art models. Results show that our approach sets a new state-of-art in the area of weekly supervised image hashing.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-5.019091606140137, 14.928279876708984]}, {"key": "", "year": "", "title": "Gawrychowski2011pattern", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Pattern matching in Lempel-Ziv compressed strings: fast, simple, and deterministic\"\nauthors: Gawrychowski Pawel\nconference: Arxiv\nyear: 2011\nbibkey: gawrychowski2011pattern\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1104.4203\"}\ntags: ['ARXIV']\n---\nCountless variants of the Lempel-Ziv compression are widely used in many real-life applications. This paper is concerned with a natural modification of the classical pattern matching problem inspired by the popularity of such compression methods: given an uncompressed pattern s[1..m] and a Lempel-Ziv representation of a string t[1..N], does s occur in t? Farach and Thorup gave a randomized O(nlog^2(N/n)+m) time solution for this problem, where n is the size of the compressed representation of t. We improve their result by developing a faster and fully deterministic O(nlog(N/n)+m) time algorithm with the same space complexity. Note that for highly compressible texts, log(N/n) might be of order n, so for such inputs the improvement is very significant. A (tiny) fragment of our method can be used to give an asymptotically optimal solution for the substring hashing problem considered by Farach and Muthukrishnan.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-2.553990602493286, -8.78580379486084]}, {"key": "", "year": "", "title": "Ge2017some", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Some intriguing upper bounds for separating hash families\"\nauthors: Ge Gennian, Shangguan Chong, Wang Xin\nconference: Arxiv\nyear: 2017\nbibkey: ge2017some\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1707.01758\"}\ntags: ['ARXIV', 'Graph']\n---\nAn $N\\times n$ matrix on $q$ symbols is called $\\\\{w_1,\\ldots,w_t\\\\}$-separating if for arbitrary $t$ pairwise disjoint column sets $C_1,\\ldots,C_t$ with $|C_i|=w_i$ for $1\\le i\\le t$, there exists a row $f$ such that $f(C_1),\\ldots,f(C_t)$ are also pairwise disjoint, where $f(C_i)$ denotes the collection of components of $C_i$ restricted to row $f$. Given integers $N,q$ and $w_1,\\ldots,w_t$, denote by $C(N,q,\\\\{w_1,\\ldots,w_t\\\\})$ the maximal $n$ such that a corresponding matrix does exist. The determination of $C(N,q,\\\\{w_1,\\ldots,w_t\\\\})$ has received remarkable attentions during the recent years. The main purpose of this paper is to introduce two novel methodologies to attack the upper bound of $C(N,q,\\\\{w_1,\\ldots,w_t\\\\})$. The first one is a combination of the famous graph removal lemma in extremal graph theory and a Johnson-type recursive inequality in coding theory, and the second one is the probabilistic method. As a consequence, we obtain several intriguing upper bounds for some parameters of $C(N,q,\\\\{w_1,\\ldots,w_t\\\\})$, which significantly improve the previously known results.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-9.33163833618164, -29.0956974029541]}, {"key": "", "year": "", "title": "Geng2018regularizing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Regularizing Deep Hashing Networks Using GAN Generated Fake Images\"\nauthors: Geng Libing, Pan Yan, Chen Jikai, Lai Hanjiang\nconference: Arxiv\nyear: 2018\nbibkey: geng2018regularizing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1803.09466\"}\ntags: ['ARXIV', 'GAN', 'Image Retrieval']\n---\nRecently, deep-networks-based hashing (deep hashing) has become a leading approach for large-scale image retrieval. It aims to learn a compact bitwise representation for images via deep networks, so that similar images are mapped to nearby hash codes. Since a deep network model usually has a large number of parameters, it may probably be too complicated for the training data we have, leading to model over-fitting. To address this issue, in this paper, we propose a simple two-stage pipeline to learn deep hashing models, by regularizing the deep hashing networks using fake images. The first stage is to generate fake images from the original training set without extra data, via a generative adversarial network (GAN). In the second stage, we propose a deep architec- ture to learn hash functions, in which we use a maximum-entropy based loss to incorporate the newly created fake images by the GAN. We show that this loss acts as a strong regularizer of the deep architecture, by penalizing low-entropy output hash codes. This loss can also be interpreted as a model ensemble by simultaneously training many network models with massive weight sharing but over different training sets. Empirical evaluation results on several benchmark datasets show that the proposed method has superior performance gains over state-of-the-art hashing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-9.39746379852295, 7.865565776824951]}, {"key": "", "year": "", "title": "Gennaro2016large", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Large Scale Deep Convolutional Neural Network Features Search with Lucene\"\nauthors: Gennaro Claudio\nconference: Arxiv\nyear: 2016\nbibkey: gennaro2016large\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1603.09687\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nIn this work, we propose an approach to index Deep Convolutional Neural Network Features to support efficient content-based retrieval on large image databases. To this aim, we have converted the these features into a textual form, to index them into an inverted index by means of Lucene. In this way, we were able to set up a robust retrieval system that combines full-text search with content-based image retrieval capabilities. We evaluated different strategies of textual representation in order to optimize the index occupation and the query response time. In order to show that our approach is able to handle large datasets, we have developed a web-based prototype that provides an interface for combined textual and visual searching into a dataset of about 100 million of images.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [26.85183334350586, 9.35810375213623]}, {"key": "", "year": "", "title": "Gerritse2020graph", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Graph-Embedding Empowered Entity Retrieval\"\nauthors: Gerritse Emma J., Hasibi Faegheh, de Vries Arjen P.\nconference: Advances in Information Retrieval. ECIR\nyear: 2020\nbibkey: gerritse2020graph\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2005.02843\"}\ntags: ['Graph']\n---\nIn this research, we improve upon the current state of the art in entity retrieval by re-ranking the result list using graph embeddings. The paper shows that graph embeddings are useful for entity-oriented search tasks. We demonstrate empirically that encoding information from the knowledge graph into (graph) embeddings contributes to a higher increase in effectiveness of entity retrieval results than using plain word embeddings. We analyze the impact of the accuracy of the entity linker on the overall retrieval effectiveness. Our analysis further deploys the cluster hypothesis to explain the observed advantages of graph embeddings over the more widely used word embeddings, for user tasks involving ranking entities.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.234695434570312, -26.496929168701172]}, {"key": "", "year": "", "title": "Geva2012topsig", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"TopSig: Topology Preserving Document Signatures\"\nauthors: Geva Shlomo, De Vries Christopher M.\nconference: Arxiv\nyear: 2012\nbibkey: geva2012topsig\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1204.5373\"}\ntags: ['ARXIV', 'Text Retrieval']\n---\nPerformance comparisons between File Signatures and Inverted Files for text retrieval have previously shown several significant shortcomings of file signatures relative to inverted files. The inverted file approach underpins most state-of-the-art search engine algorithms, such as Language and Probabilistic models. It has been widely accepted that traditional file signatures are inferior alternatives to inverted files. This paper describes TopSig, a new approach to the construction of file signatures. Many advances in semantic hashing and dimensionality reduction have been made in recent times, but these were not so far linked to general purpose, signature file based, search engines. This paper introduces a different signature file approach that builds upon and extends these recent advances. We are able to demonstrate significant improvements in the performance of signature file based indexing and retrieval, performance that is comparable to that of state of the art inverted file based systems, including Language models and BM25. These findings suggest that file signatures offer a viable alternative to inverted files in suitable settings and from the theoretical perspective it positions the file signatures model in the class of Vector Space retrieval models.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-5.831359386444092, -6.943772792816162]}, {"key": "", "year": "", "title": "Ghosh2015query", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Query by String word spotting based on character bi-gram indexing\"\nauthors: Ghosh Suman K., Valveny Ernest\nconference: Arxiv\nyear: 2015\nbibkey: ghosh2015query\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1505.07778\"}\ntags: ['ARXIV']\n---\nIn this paper we propose a segmentation-free query by string word spotting method. Both the documents and query strings are encoded using a recently proposed word representa- tion that projects images and strings into a common atribute space based on a pyramidal histogram of characters(PHOC). These attribute models are learned using linear SVMs over the Fisher Vector representation of the images along with the PHOC labels of the corresponding strings. In order to search through the whole page, document regions are indexed per character bi- gram using a similar attribute representation. On top of that, we propose an integral image representation of the document using a simplified version of the attribute model for efficient computation. Finally we introduce a re-ranking step in order to boost retrieval performance. We show state-of-the-art results for segmentation-free query by string word spotting in single-writer and multi-writer standard datasets\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [23.304901123046875, 1.4989362955093384]}, {"key": "", "year": "", "title": "Gillard2023unified", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Unified Functional Hashing in Automatic Machine Learning\"\nauthors: Gillard Ryan, Jonany Stephen, Miao Yingjie, Munn Michael, de Souza Connal, Dungay Jonathan, Liang Chen, So David R., Le Quoc V., Real Esteban\nconference: Arxiv\nyear: 2023\nbibkey: gillard2023unified\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2302.05433\"}\ntags: ['ARXIV', 'Graph', 'TIP', 'TOM']\n---\nThe field of Automatic Machine Learning (AutoML) has recently attained impressive results, including the discovery of state-of-the-art machine learning solutions, such as neural image classifiers. This is often done by applying an evolutionary search method, which samples multiple candidate solutions from a large space and evaluates the quality of each candidate through a long training process. As a result, the search tends to be slow. In this paper, we show that large efficiency gains can be obtained by employing a fast unified functional hash, especially through the functional equivalence caching technique, which we also present. The central idea is to detect by hashing when the search method produces equivalent candidates, which occurs very frequently, and this way avoid their costly re-evaluation. Our hash is \"functional\" in that it identifies equivalent candidates even if they were represented or coded differently, and it is \"unified\" in that the same algorithm can hash arbitrary representations; e.g. compute graphs, imperative code, or lambda functions. As evidence, we show dramatic improvements on multiple AutoML domains, including neural architecture search and algorithm discovery. Finally, we consider the effect of hash collisions, evaluation noise, and search distribution through empirical analysis. Altogether, we hope this paper may serve as a guide to hashing techniques in AutoML.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [1.0129003524780273, -30.07554817199707]}, {"key": "", "year": "", "title": "Gillick2018end", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"End-to-End Retrieval in Continuous Space\"\nauthors: Gillick Daniel, Presta Alessandro, Tomar Gaurav Singh\nconference: Arxiv\nyear: 2018\nbibkey: gillick2018end\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1811.08008\"}\ntags: ['ARXIV']\n---\nMost text-based information retrieval (IR) systems index objects by words or phrases. These discrete systems have been augmented by models that use embeddings to measure similarity in continuous space. But continuous-space models are typically used just to re-rank the top candidates. We consider the problem of end-to-end continuous retrieval, where standard approximate nearest neighbor (ANN) search replaces the usual discrete inverted index, and rely entirely on distances between learned embeddings. By training simple models specifically for retrieval, with an appropriate model architecture, we improve on a discrete baseline by 8% and 26% (MAP) on two similar-question retrieval tasks. We also discuss the problem of evaluation for retrieval systems, and show how to modify existing pairwise similarity datasets for this purpose.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [14.433337211608887, -8.404674530029297]}, {"key": "", "year": "", "title": "Gillick2019learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning Dense Representations for Entity Retrieval\"\nauthors: Gillick Daniel, Kulkarni Sayali, Lansing Larry, Presta Alessandro, Baldridge Jason, Ie Eugene, Garcia-Olano Diego\nconference: Arxiv\nyear: 2019\nbibkey: gillick2019learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1909.10506\"}\ntags: ['ARXIV', 'Supervised', 'Unsupervised']\n---\nWe show that it is feasible to perform entity linking by training a dual encoder (two-tower) model that encodes mentions and entities in the same dense vector space, where candidate entities are retrieved by approximate nearest neighbor search. Unlike prior work, this setup does not rely on an alias table followed by a re-ranker, and is thus the first fully learned entity retrieval model. We show that our dual encoder, trained using only anchor-text links in Wikipedia, outperforms discrete alias table and BM25 baselines, and is competitive with the best comparable results on the standard TACKBP-2010 dataset. In addition, it can retrieve candidates extremely fast, and generalizes well to a new dataset derived from Wikinews. On the modeling side, we demonstrate the dramatic value of an unsupervised negative mining algorithm for this task.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-15.285025596618652, 15.989097595214844]}, {"key": "", "year": "", "title": "Gilreath2004hash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hash sort: A linear time complexity multiple-dimensional sort algorithm\"\nauthors: Gilreath William F.\nconference: Proceedings of First Southern Symposium on Computing December\nyear: 2004\nbibkey: gilreath2004hash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/cs/0408040\"}\ntags: ['GAN', 'TIP']\n---\nSorting and hashing are two completely different concepts in computer science, and appear mutually exclusive to one another. Hashing is a search method using the data as a key to map to the location within memory, and is used for rapid storage and retrieval. Sorting is a process of organizing data from a random permutation into an ordered arrangement, and is a common activity performed frequently in a variety of applications. Almost all conventional sorting algorithms work by comparison, and in doing so have a linearithmic greatest lower bound on the algorithmic time complexity. Any improvement in the theoretical time complexity of a sorting algorithm can result in overall larger gains in implementation performance.. A gain in algorithmic performance leads to much larger gains in speed for the application that uses the sort algorithm. Such a sort algorithm needs to use an alternative method for ordering the data than comparison, to exceed the linearithmic time complexity boundary on algorithmic performance. The hash sort is a general purpose non-comparison based sorting algorithm by hashing, which has some interesting features not found in conventional sorting algorithms. The hash sort asymptotically outperforms the fastest traditional sorting algorithm, the quick sort. The hash sort algorithm has a linear time complexity factor -- even in the worst case. The hash sort opens an area for further work and investigation into alternative means of sorting.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-20.052875518798828, -3.951265811920166]}, {"key": "", "year": "", "title": "Gog2014compact", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Compact Indexes for Flexible Top-k Retrieval\"\nauthors: Gog Simon, Petri Matthias\nconference: Arxiv\nyear: 2014\nbibkey: gog2014compact\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1406.3170\"}\ntags: ['ARXIV']\n---\nWe engineer a self-index based retrieval system capable of rank-safe evaluation of top-k queries. The framework generalizes the GREEDY approach of Culpepper et al. (ESA 2010) to handle multi-term queries, including over phrases. We propose two techniques which significantly reduce the ranking time for a wide range of popular Information Retrieval (IR) relevance measures, such as TFxIDF and BM25. First, we reorder elements in the document array according to document weight. Second, we introduce the repetition array, which generalizes Sadakane's (JDA 2007) document frequency structure to document subsets. Combining document and repetition array, we achieve attractive functionality-space trade-offs. We provide an extensive evaluation of our system on terabyte-sized IR collections.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [2.6147477626800537, -6.970605850219727]}, {"key": "", "year": "", "title": "Gominski2019challenging", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Challenging deep image descriptors for retrieval in heterogeneous iconographic collections\"\nauthors: Gominski Dimitri  LaSTIG, Poreba Martyna  LaSTIG, Gouet-Brunet Val\u00e9rie  LaSTIG, Chen Liming  LaSTIG\nconference: Arxiv\nyear: 2019\nbibkey: gominski2019challenging\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1909.08866\"}\ntags: ['ARXIV', 'Deep Learning', 'Graph', 'Image Retrieval']\n---\nThis article proposes to study the behavior of recent and efficient state-of-the-art deep-learning based image descriptors for content-based image retrieval, facing a panel of complex variations appearing in heterogeneous image datasets, in particular in cultural collections that may involve multi-source, multi-date and multi-view Permission to make digital\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [28.62541961669922, 2.4102466106414795]}, {"key": "", "year": "", "title": "Goncalves2023geometric", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Geometric Covering using Random Fields\"\nauthors: Goncalves Felipe, Keren Daniel, Shahar Amit, Yehuda Gal\nconference: Arxiv\nyear: 2023\nbibkey: goncalves2023geometric\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2311.14082\"}\ntags: ['ARXIV', 'LSH']\n---\nA set of vectors $S \\subseteq \\mathbb\\{R\\}^d$ is $(k_1,\\varepsilon)$-clusterable if there are $k_1$ balls of radius $\\varepsilon$ that cover $S$. A set of vectors $S \\subseteq \\mathbb\\{R\\}^d$ is $(k_2,\\delta)$-far from being clusterable if there are at least $k_2$ vectors in $S$, with all pairwise distances at least $\\delta$. We propose a probabilistic algorithm to distinguish between these two cases. Our algorithm reaches a decision by only looking at the extreme values of a scalar valued hash function, defined by a random field, on $S$; hence, it is especially suitable in distributed and online settings. An important feature of our method is that the algorithm is oblivious to the number of vectors: in the online setting, for example, the algorithm stores only a constant number of scalars, which is independent of the stream length. We introduce random field hash functions, which are a key ingredient in our paradigm. Random field hash functions generalize locality-sensitive hashing (LSH). In addition to the LSH requirement that ``nearby vectors are hashed to similar values\", our hash function also guarantees that the ``hash values are (nearly) independent random variables for distant vectors\". We formulate necessary conditions for the kernels which define the random fields applied to our problem, as well as a measure of kernel optimality, for which we provide a bound. Then, we propose a method to construct kernels which approximate the optimal one.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-14.59875774383545, -24.159343719482422]}, {"key": "", "year": "", "title": "Gong2022improving", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Improving Visual-Semantic Embeddings by Learning Semantically-Enhanced Hard Negatives for Cross-modal Information Retrieval\"\nauthors: Gong Yan, Cosma Georgina\nconference: Pattern Recognition\nyear: 2022\nbibkey: gong2022improving\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2210.04754\"}\ntags: ['Cross Modal']\n---\nVisual Semantic Embedding (VSE) aims to extract the semantics of images and their descriptions, and embed them into the same latent space for cross-modal information retrieval. Most existing VSE networks are trained by adopting a hard negatives loss function which learns an objective margin between the similarity of relevant and irrelevant image-description embedding pairs. However, the objective margin in the hard negatives loss function is set as a fixed hyperparameter that ignores the semantic differences of the irrelevant image-description pairs. To address the challenge of measuring the optimal similarities between image-description pairs before obtaining the trained VSE networks, this paper presents a novel approach that comprises two main parts: (1) finds the underlying semantics of image descriptions; and (2) proposes a novel semantically enhanced hard negatives loss function, where the learning objective is dynamically determined based on the optimal similarity scores between irrelevant image-description pairs. Extensive experiments were carried out by integrating the proposed methods into five state-of-the-art VSE networks that were applied to three benchmark datasets for cross-modal information retrieval tasks. The results revealed that the proposed methods achieved the best performance and can also be adopted by existing and future VSE networks.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [4.523339748382568, 12.746030807495117]}, {"key": "", "year": "", "title": "Gong2022vit2hash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"ViT2Hash: Unsupervised Information-Preserving Hashing\"\nauthors: Gong Qinkang, Wang Liangdao, Lai Hanjiang, Pan Yan, Yin Jian\nconference: Arxiv\nyear: 2022\nbibkey: gong2022vit2hash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2201.05541\"}\ntags: ['ARXIV', 'Quantisation', 'Supervised', 'Unsupervised']\n---\nUnsupervised image hashing, which maps images into binary codes without supervision, is a compressor with a high compression rate. Hence, how to preserving meaningful information of the original data is a critical problem. Inspired by the large-scale vision pre-training model, known as ViT, which has shown significant progress for learning visual representations, in this paper, we propose a simple information-preserving compressor to finetune the ViT model for the target unsupervised hashing task. Specifically, from pixels to continuous features, we first propose a feature-preserving module, using the corrupted image as input to reconstruct the original feature from the pre-trained ViT model and the complete image, so that the feature extractor can focus on preserving the meaningful information of original data. Secondly, from continuous features to hash codes, we propose a hashing-preserving module, which aims to keep the semantic information from the pre-trained ViT model by using the proposed Kullback-Leibler divergence loss. Besides, the quantization loss and the similarity loss are added to minimize the quantization error. Our method is very simple and achieves a significantly higher degree of MAP on three benchmark image datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [2.4233815670013428, 12.046893119812012]}, {"key": "", "year": "", "title": "Gonthier2020multiple", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Multiple instance learning on deep features for weakly supervised object detection with extreme domain shifts\"\nauthors: Gonthier Nicolas, Ladjal Sa\u00efd, Gousseau Yann\nconference: Computer Vision and Image Understanding\nyear: 2020\nbibkey: gonthier2020multiple\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2008.01178\"}\ntags: ['Graph', 'Supervised', 'TIP', 'Weakly Supervised']\n---\nWeakly supervised object detection (WSOD) using only image-level annotations has attracted a growing attention over the past few years. Whereas such task is typically addressed with a domain-specific solution focused on natural images, we show that a simple multiple instance approach applied on pre-trained deep features yields excellent performances on non-photographic datasets, possibly including new classes. The approach does not include any fine-tuning or cross-domain learning and is therefore efficient and possibly applicable to arbitrary datasets and classes. We investigate several flavors of the proposed approach, some including multi-layers perceptron and polyhedral classifiers. Despite its simplicity, our method shows competitive results on a range of publicly available datasets, including paintings (People-Art, IconArt), watercolors, cliparts and comics and allows to quickly learn unseen visual categories.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [6.954825401306152, 20.600364685058594]}, {"key": "", "year": "", "title": "Gordo2016deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Image Retrieval: Learning global representations for image search\"\nauthors: Gordo Albert, Almazan Jon, Revaud Jerome, Larlus Diane\nconference: Arxiv\nyear: 2016\nbibkey: gordo2016deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1604.01325\"}\ntags: ['ARXIV', 'Image Retrieval', 'TOM']\n---\nWe propose a novel approach for instance-level image retrieval. It produces a global and compact fixed-length representation for each image by aggregating many region-wise descriptors. In contrast to previous works employing pre-trained deep networks as a black box to produce features, our method leverages a deep architecture trained for the specific task of image retrieval. Our contribution is twofold: (i) we leverage a ranking framework to learn convolution and projection weights that are used to build the region features; and (ii) we employ a region proposal network to learn which regions should be pooled to form the final global descriptor. We show that using clean training data is key to the success of our approach. To that aim, we use a large scale but noisy landmark dataset and develop an automatic cleaning approach. The proposed architecture produces a global image representation in a single forward pass. Our approach significantly outperforms previous approaches based on global descriptors on standard datasets. It even surpasses most prior works based on costly local descriptor indexing and spatial verification. Additional material is available at www.xrce.xerox.com/Deep-Image-Retrieval.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [17.086523056030273, 15.34947395324707]}, {"key": "", "year": "", "title": "Gordon2008optimal", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Optimal hash functions for approximate closest pairs on the n-cube\"\nauthors: Gordon Daniel M., Miller Victor, Ostapenko Peter\nconference: Arxiv\nyear: 2008\nbibkey: gordon2008optimal\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/0806.3284\"}\ntags: ['ARXIV']\n---\nOne way to find closest pairs in large datasets is to use hash functions. In recent years locality-sensitive hash functions for various metrics have been given: projecting an n-cube onto k bits is simple hash function that performs well. In this paper we investigate alternatives to projection. For various parameters hash functions given by complete decoding algorithms for codes work better, and asymptotically random codes perform better than projection.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [3.9961137771606445, -11.314019203186035]}, {"key": "", "year": "", "title": "Gottlieb2014near", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Near-optimal sample compression for nearest neighbors\"\nauthors: Gottlieb Lee-Ad, Kontorovich Aryeh, Nisnevitch Pinhas\nconference: Arxiv\nyear: 2014\nbibkey: gottlieb2014near\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1404.3368\"}\ntags: ['ARXIV']\n---\nWe present the first sample compression algorithm for nearest neighbors with non-trivial performance guarantees. We complement these guarantees by demonstrating almost matching hardness lower bounds, which show that our bound is nearly optimal. Our result yields new insight into margin-based nearest neighbor classification in metric spaces and allows us to significantly sharpen and simplify existing bounds. Some encouraging empirical results are also presented.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [10.883888244628906, -17.62379264831543]}, {"key": "", "year": "", "title": "Grabowski2014two", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Two simple full-text indexes based on the suffix array\"\nauthors: Grabowski Szymon, Raniszewski Marcin\nconference: Arxiv\nyear: 2014\nbibkey: grabowski2014two\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1405.5919\"}\ntags: ['ARXIV']\n---\nWe propose two suffix array inspired full-text indexes. One, called SA-hash, augments the suffix array with a hash table to speed up pattern searches due to significantly narrowed search interval before the binary search phase. The other, called FBCSA, is a compact data structure, similar to M{\\\"a}kinen's compact suffix array, but working on fixed sized blocks. Experiments on the Pizza~\\&amp;~Chili 200\\,MB datasets show that SA-hash is about 2--3 times faster in pattern searches (counts) than the standard suffix array, for the price of requiring $0.2n-1.1n$ bytes of extra space, where $n$ is the text length, and setting a minimum pattern length. FBCSA is relatively fast in single cell accesses (a few times faster than related indexes at about the same or better compression), but not competitive if many consecutive cells are to be extracted. Still, for the task of extracting, e.g., 10 successive cells its time-space relation remains attractive.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-3.1314878463745117, -14.0088529586792]}, {"key": "", "year": "", "title": "Grabowski2021space", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Space-Efficient Huffman Codes Revisited\"\nauthors: Grabowski Szymon, K\u00f6ppl Dominik\nconference: Arxiv\nyear: 2021\nbibkey: grabowski2021space\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2108.05495\"}\ntags: ['ARXIV', 'Graph']\n---\nCanonical Huffman code is an optimal prefix-free compression code whose codewords enumerated in the lexicographical order form a list of binary words in non-decreasing lengths. Gagie et al. (2015) gave a representation of this coding capable to encode or decode a symbol in constant worst case time. It uses $\\sigma \\lg \\ell_\\{\\text\\{max\\}\\} + o(\\sigma) + O(\\ell_\\{\\text\\{max\\}\\}^2)$ bits of space, where $\\sigma$ and $\\ell_\\{\\text\\{max\\}\\}$ are the alphabet size and maximum codeword length, respectively. We refine their representation to reduce the space complexity to $\\sigma \\lg \\ell_\\{\\text\\{max\\}\\} (1 + o(1))$ bits while preserving the constant encode and decode times. Our algorithmic idea can be applied to any canonical code.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-3.222058057785034, -24.451679229736328]}, {"key": "", "year": "", "title": "Green2019hashgraph", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"HashGraph -- Scalable Hash Tables Using A Sparse Graph Data Structure\"\nauthors: Green Oded\nconference: Arxiv\nyear: 2019\nbibkey: green2019hashgraph\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1907.02900\"}\ntags: ['ARXIV', 'Graph']\n---\nHash tables are ubiquitous and used in a wide range of applications for efficient probing of large and unsorted data. If designed properly, hash-tables can enable efficients look ups in a constant number of operations or commonly referred to as O(1) operations. As data sizes continue to grow and data becomes less structured (as is common for big-data applications), the need for efficient and scalable hash table also grows. In this paper we introduce HashGraph, a new scalable approach for building hash tables that uses concepts taken from sparse graph representations--hence the name HashGraph. We show two different variants of HashGraph, a simple algorithm that outlines the method to create the hash-table and an advanced method that creates the hash table in a more efficient manner (with an improved memory access pattern). HashGraph shows a new way to deal with hash-collisions that does not use \"open-addressing\" or \"chaining\", yet has all the benefits of both these approaches. HashGraph currently works for static inputs, though recent progress with dynamic graph data structures suggest that HashGraph might be extended to dynamic inputs as well. We show that HashGraph can deal with a large number of hash-values per entry without loss of performance as most open-addressing and chaining approaches have. Further, we show that HashGraph is indifferent to the load-factor. Lastly, we show a new probing algorithm for the second phase of value lookups. Given the above, HashGraph is extremely fast and outperforms several state of the art hash-table implementations. The implementation of HashGraph in this paper is for NVIDIA GPUs, though HashGraph is not architecture dependent. Using a NVIDIA GV100 GPU, HashGraph is anywhere from 2X-8X faster than cuDPP, WarpDrive, and cuDF. HashGraph is able to build a hash-table at a rate of 2.5 billion keys per second and can probe at nearly the same rate.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-20.839561462402344, -14.48990535736084]}, {"key": "", "year": "", "title": "Grossi2011fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast Compressed Tries through Path Decompositions\"\nauthors: Grossi Roberto, Ottaviano Giuseppe\nconference: Arxiv\nyear: 2011\nbibkey: grossi2011fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1111.5220\"}\ntags: ['ARXIV', 'Graph']\n---\nTries are popular data structures for storing a set of strings, where common prefixes are represented by common root-to-node paths. Over fifty years of usage have produced many variants and implementations to overcome some of their limitations. We explore new succinct representations of path-decomposed tries and experimentally evaluate the corresponding reduction in space usage and memory latency, comparing with the state of the art. We study two cases of applications: (1) a compressed dictionary for (compressed) strings, and (2) a monotone minimal perfect hash for strings that preserves their lexicographic order. For (1), we obtain data structures that outperform other state-of-the-art compressed dictionaries in space efficiency, while obtaining predictable query times that are competitive with data structures preferred by the practitioners. In (2), our tries perform several times faster than other trie-based monotone perfect hash functions, while occupying nearly the same space.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-2.0334105491638184, -12.515091896057129]}, {"key": "", "year": "", "title": "Grossi2018round", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Round-Hashing for Data Storage: Distributed Servers and External-Memory Tables\"\nauthors: Grossi Roberto, Versari Luca\nconference: Arxiv\nyear: 2018\nbibkey: grossi2018round\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1805.03158\"}\ntags: ['ARXIV']\n---\nThis paper proposes round-hashing, which is suitable for data storage on distributed servers and for implementing external-memory tables in which each lookup retrieves at most a single block of external memory, using a stash. For data storage, round-hashing is like consistent hashing as it avoids a full rehashing of the keys when new servers are added. Experiments show that the speed to serve requests is tenfold or more than the state of the art. In distributed data storage, this guarantees better throughput for serving requests and, moreover, greatly reduces decision times for which data should move to new servers as rescanning data is much faster.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-25.935585021972656, -9.557406425476074]}, {"key": "", "year": "", "title": "Gu2015cross", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Cross-Modality Hashing with Partial Correspondence\"\nauthors: Gu Yun, Xue Haoyang, Yang Jie\nconference: Arxiv\nyear: 2015\nbibkey: gu2015cross\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1502.05224\"}\ntags: ['ARXIV', 'Cross Modal']\n---\nLearning a hashing function for cross-media search is very desirable due to its low storage cost and fast query speed. However, the data crawled from Internet cannot always guarantee good correspondence among different modalities which affects the learning for hashing function. In this paper, we focus on cross-modal hashing with partially corresponded data. The data without full correspondence are made in use to enhance the hashing performance. The experiments on Wiki and NUS-WIDE datasets demonstrates that the proposed method outperforms some state-of-the-art hashing approaches with fewer correspondence information.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-15.173486709594727, 0.5760051012039185]}, {"key": "", "year": "", "title": "Gu2018unsupervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Unsupervised Hashtag Retrieval and Visualization for Crisis Informatics\"\nauthors: Gu Yao, Kejriwal Mayank\nconference: Arxiv\nyear: 2018\nbibkey: gu2018unsupervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1801.05906\"}\ntags: ['ARXIV', 'Supervised', 'TIP', 'Unsupervised']\n---\nIn social media like Twitter, hashtags carry a lot of semantic information and can be easily distinguished from the main text. Exploring and visualizing the space of hashtags in a meaningful way can offer important insights into a dataset, especially in crisis situations. In this demonstration paper, we present a functioning prototype, HashViz, that ingests a corpus of tweets collected in the aftermath of a crisis situation (such as the Las Vegas shootings) and uses the fastText bag-of-tricks semantic embedding algorithm (from Facebook Research) to embed words and hashtags into a vector space. Hashtag vectors obtained in this way can be visualized using the t-SNE dimensionality reduction algorithm in 2D. Although multiple Twitter visualization platforms exist, HashViz is distinguished by being simple, scalable, interactive and portable enough to be deployed on a server for million-tweet corpora collected in the aftermath of arbitrary disasters, without special-purpose installation, technical expertise, manual supervision or costly software or infrastructure investment. Although simple, we show that HashViz offers an intuitive way to summarize, and gain insight into, a developing crisis situation. HashViz is also completely unsupervised, requiring no manual inputs to go from a raw corpus to a visualization and search interface. Using the recent Las Vegas mass shooting massacre as a case study, we illustrate the potential of HashViz using only a web browser on the client side.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-28.716632843017578, 11.835542678833008]}, {"key": "", "year": "", "title": "Gu2022accelerating", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Accelerating Code Search with Deep Hashing and Code Classification\"\nauthors: Gu Wenchao, Wang Yanlin, Du Lun, Zhang Hongyu, Han Shi, Zhang Dongmei, Lyu Michael R.\nconference: Arxiv\nyear: 2022\nbibkey: gu2022accelerating\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2203.15287\"}\ntags: ['ARXIV', 'Deep Learning']\n---\nCode search is to search reusable code snippets from source code corpus based on natural languages queries. Deep learning-based methods of code search have shown promising results. However, previous methods focus on retrieval accuracy but lacked attention to the efficiency of the retrieval process. We propose a novel method CoSHC to accelerate code search with deep hashing and code classification, aiming to perform an efficient code search without sacrificing too much accuracy. To evaluate the effectiveness of CoSHC, we apply our method to five code search models. Extensive experimental results indicate that compared with previous code search baselines, CoSHC can save more than 90% of retrieval time meanwhile preserving at least 99% of retrieval accuracy.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [17.287097930908203, -6.906111240386963]}, {"key": "", "year": "", "title": "Guha2012image", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Image Similarity Using Sparse Representation and Compression Distance\"\nauthors: Guha Tanaya, Ward Rabab K.\nconference: Arxiv\nyear: 2012\nbibkey: guha2012image\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1206.2627\"}\ntags: ['ARXIV']\n---\nA new line of research uses compression methods to measure the similarity between signals. Two signals are considered similar if one can be compressed significantly when the information of the other is known. The existing compression-based similarity methods, although successful in the discrete one dimensional domain, do not work well in the context of images. This paper proposes a sparse representation-based approach to encode the information content of an image using information from the other image, and uses the compactness (sparsity) of the representation as a measure of its compressibility (how much can the image be compressed) with respect to the other image. The more sparse the representation of an image, the better it can be compressed and the more it is similar to the other image. The efficacy of the proposed measure is demonstrated through the high accuracies achieved in image clustering, retrieval and classification.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [14.926360130310059, 4.155576229095459]}, {"key": "", "year": "", "title": "Gui2019fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast Supervised Discrete Hashing\"\nauthors: Gui Jie, Liu Tongliang, Sun Zhenan, Tao Dacheng, Tan Tieniu\nconference: Arxiv\nyear: 2019\nbibkey: gui2019fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1904.03556\"}\ntags: ['ARXIV', 'Supervised']\n---\nLearning-based hashing algorithms are ``hot topics\" because they can greatly increase the scale at which existing methods operate. In this paper, we propose a new learning-based hashing method called ``fast supervised discrete hashing\" (FSDH) based on ``supervised discrete hashing\" (SDH). Regressing the training examples (or hash code) to the corresponding class labels is widely used in ordinary least squares regression. Rather than adopting this method, FSDH uses a very simple yet effective regression of the class labels of training examples to the corresponding hash code to accelerate the algorithm. To the best of our knowledge, this strategy has not previously been used for hashing. Traditional SDH decomposes the optimization into three sub-problems, with the most critical sub-problem - discrete optimization for binary hash codes - solved using iterative discrete cyclic coordinate descent (DCC), which is time-consuming. However, FSDH has a closed-form solution and only requires a single rather than iterative hash code-solving step, which is highly efficient. Furthermore, FSDH is usually faster than SDH for solving the projection matrix for least squares regression, making FSDH generally faster than SDH. For example, our results show that FSDH is about 12-times faster than SDH when the number of hashing bits is 128 on the CIFAR-10 data base, and FSDH is about 151-times faster than FastHash when the number of hashing bits is 64 on the MNIST data-base. Our experimental results show that FSDH is not only fast, but also outperforms other comparative methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-16.70882225036621, -9.579710006713867]}, {"key": "", "year": "", "title": "Gui2019supervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Supervised Discrete Hashing with Relaxation\"\nauthors: Gui Jie, Liu Tongliang, Sun Zhenan, Tao Dacheng, Tan Tieniu\nconference: Arxiv\nyear: 2019\nbibkey: gui2019supervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1904.03549\"}\ntags: ['ARXIV', 'Supervised', 'Unsupervised']\n---\nData-dependent hashing has recently attracted attention due to being able to support efficient retrieval and storage of high-dimensional data such as documents, images, and videos. In this paper, we propose a novel learning-based hashing method called \"Supervised Discrete Hashing with Relaxation\" (SDHR) based on \"Supervised Discrete Hashing\" (SDH). SDH uses ordinary least squares regression and traditional zero-one matrix encoding of class label information as the regression target (code words), thus fixing the regression target. In SDHR, the regression target is instead optimized. The optimized regression target matrix satisfies a large margin constraint for correct classification of each example. Compared with SDH, which uses the traditional zero-one matrix, SDHR utilizes the learned regression target matrix and, therefore, more accurately measures the classification error of the regression model and is more flexible. As expected, SDHR generally outperforms SDH. Experimental results on two large-scale image datasets (CIFAR-10 and MNIST) and a large-scale and challenging face dataset (FRGC) demonstrate the effectiveness and efficiency of SDHR.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-7.316346645355225, 9.287102699279785]}, {"key": "", "year": "", "title": "Guo2014on", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"On tight bounds for binary frameproof codes\"\nauthors: Guo Chuan, Stinson Douglas R., van Trung Tran\nconference: Arxiv\nyear: 2014\nbibkey: guo2014on\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1406.6920\"}\ntags: ['ARXIV']\n---\nIn this paper, we study $w$-frameproof codes, which are equivalent to $\\\\{1,w\\\\}$-separating hash families. Our main results concern binary codes, which are defined over an alphabet of two symbols. For all $w \\geq 3$, and for $w+1 \\leq N \\leq 3w$, we show that an $SHF(N; n,2, \\\\{1,w \\\\})$ exists only if $n \\leq N$, and an $SHF(N; N,2, \\\\{1,w \\\\})$ must be a permutation matrix of degree $N$.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [4.969207286834717, -18.188583374023438]}, {"key": "", "year": "", "title": "Guo2015a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A tight bound on the size of certain separating hash families\"\nauthors: Guo Chuan, Stinson Douglas R.\nconference: Arxiv\nyear: 2015\nbibkey: guo2015a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1510.00293\"}\ntags: ['ARXIV']\n---\nIn this paper, we present a new lower bound on the size of separating hash families of type {w_1^{q-1},w_2} where w_1 &lt; w_2. Our result extends the paper by Guo et al. on binary frameproof codes. This bound compares well against known general bounds, and is especially useful when trying to bound the size of strong separating hash families. We also show that our new bound is tight by constructing hash families that meet the new bound with equality.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [5.5659871101379395, -17.942842483520508]}, {"key": "", "year": "", "title": "Guo2015cnn", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"CNN Based Hashing for Image Retrieval\"\nauthors: Guo Jinma, Li Jianmin\nconference: Arxiv\nyear: 2015\nbibkey: guo2015cnn\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1509.01354\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval', 'Supervised']\n---\nAlong with data on the web increasing dramatically, hashing is becoming more and more popular as a method of approximate nearest neighbor search. Previous supervised hashing methods utilized similarity/dissimilarity matrix to get semantic information. But the matrix is not easy to construct for a new dataset. Rather than to reconstruct the matrix, we proposed a straightforward CNN-based hashing method, i.e. binarilizing the activations of a fully connected layer with threshold 0 and taking the binary result as hash codes. This method achieved the best performance on CIFAR-10 and was comparable with the state-of-the-art on MNIST. And our experiments on CIFAR-10 suggested that the signs of activations may carry more information than the relative values of activations between samples, and that the co-adaption between feature extractor and hash functions is important for hashing.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [9.414395332336426, 27.562461853027344]}, {"key": "", "year": "", "title": "Guo2019deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Hashing for Signed Social Network Embedding\"\nauthors: Guo Jia-Nan, Mao Xian-Ling, Jiang Xiao-Jian, Sun Ying-Xiang, Wei Wei, Huang He-Yan\nconference: Arxiv\nyear: 2019\nbibkey: guo2019deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1908.04007\"}\ntags: ['ARXIV']\n---\nNetwork embedding is a promising way of network representation, facilitating many signed social network processing and analysis tasks such as link prediction and node classification. Recently, feature hashing has been adopted in several existing embedding algorithms to improve the efficiency, which has obtained a great success. However, the existing feature hashing based embedding algorithms only consider the positive links in signed social networks. Intuitively, negative links can also help improve the performance. Thus, in this paper, we propose a novel deep hashing method for signed social network embedding by considering simultaneously positive and negative links. Extensive experiments show that the proposed method performs better than several state-of-the-art baselines through link prediction task over two real-world signed social networks.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-22.700075149536133, 9.830130577087402]}, {"key": "", "year": "", "title": "Guo2020deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Kernel Supervised Hashing for Node Classification in Structural Networks\"\nauthors: Guo Jia-Nan, Mao Xian-Ling, Lin Shu-Yang, Wei Wei, Huang Heyan\nconference: Arxiv\nyear: 2020\nbibkey: guo2020deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2010.13582\"}\ntags: ['ARXIV', 'Supervised', 'TIP']\n---\nNode classification in structural networks has been proven to be useful in many real world applications. With the development of network embedding, the performance of node classification has been greatly improved. However, nearly all the existing network embedding based methods are hard to capture the actual category features of a node because of the linearly inseparable problem in low-dimensional space; meanwhile they cannot incorporate simultaneously network structure information and node label information into network embedding. To address the above problems, in this paper, we propose a novel Deep Kernel Supervised Hashing (DKSH) method to learn the hashing representations of nodes for node classification. Specifically, a deep multiple kernel learning is first proposed to map nodes into suitable Hilbert space to deal with linearly inseparable problem. Then, instead of only considering structural similarity between two nodes, a novel similarity matrix is designed to merge both network structure information and node label information. Supervised by the similarity matrix, the learned hashing representations of nodes simultaneously preserve the two kinds of information well from the learned Hilbert space. Extensive experiments show that the proposed method significantly outperforms the state-of-the-art baselines over three real world benchmark datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-21.73556900024414, 10.098160743713379]}, {"key": "", "year": "", "title": "Gupta2010hashing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hashing Image Patches for Zooming\"\nauthors: Gupta Mithun Das\nconference: Arxiv\nyear: 2010\nbibkey: gupta2010hashing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1004.3980\"}\ntags: ['ARXIV', 'LSH']\n---\nIn this paper we present a Bayesian image zooming/super-resolution algorithm based on a patch based representation. We work on a patch based model with overlap and employ a Locally Linear Embedding (LLE) based approach as our data fidelity term in the Bayesian inference. The image prior imposes continuity constraints across the overlapping patches. We apply an error back-projection technique, with an approximate cross bilateral filter. The problem of nearest neighbor search is handled by a variant of the locality sensitive hashing (LSH) scheme. The novelty of our work lies in the speed up achieved by the hashing scheme and the robustness and inherent modularity and parallel structure achieved by the LLE setup. The ill-posedness of the image reconstruction problem is handled by the introduction of regularization priors which encode the knowledge present in vast collections of natural images. We present comparative results for both run-time as well as visual image quality based measurements.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [7.971924304962158, 2.1024155616760254]}, {"key": "", "year": "", "title": "Gupta2022medical", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Medical Image Retrieval via Nearest Neighbor Search on Pre-trained Image Features\"\nauthors: Gupta Deepak, Loane Russell, Gayen Soumya, Demner-Fushman Dina\nconference: Arxiv\nyear: 2022\nbibkey: gupta2022medical\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2210.02401\"}   - {name: \"Code\", url: \"https://github.com/deepaknlp/DLS.\"}\ntags: ['ARXIV', 'Image Retrieval', 'TIP']\n---\nNearest neighbor search (NNS) aims to locate the points in high-dimensional space that is closest to the query point. The brute-force approach for finding the nearest neighbor becomes computationally infeasible when the number of points is large. The NNS has multiple applications in medicine, such as searching large medical imaging databases, disease classification, diagnosis, etc. With a focus on medical imaging, this paper proposes DenseLinkSearch an effective and efficient algorithm that searches and retrieves the relevant images from heterogeneous sources of medical images. Towards this, given a medical database, the proposed algorithm builds the index that consists of pre-computed links of each point in the database. The search algorithm utilizes the index to efficiently traverse the database in search of the nearest neighbor. We extensively tested the proposed NNS approach and compared the performance with state-of-the-art NNS approaches on benchmark datasets and our created medical image datasets. The proposed approach outperformed the existing approach in terms of retrieving accurate neighbors and retrieval speed. We also explore the role of medical image feature representation in content-based medical image retrieval tasks. We propose a Transformer-based feature representation technique that outperformed the existing pre-trained Transformer approach on CLEF 2011 medical image retrieval task. The source code of our experiments are available at https://github.com/deepaknlp/DLS.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [28.804670333862305, 22.883806228637695]}, {"key": "", "year": "", "title": "Gupta2022zero", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Zero-Shot Sketch Based Image Retrieval using Graph Transformer\"\nauthors: Gupta Sumrit, Chaudhuri Ushasi, Banerjee Biplab\nconference: Arxiv\nyear: 2022\nbibkey: gupta2022zero\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2201.10185\"}\ntags: ['ARXIV', 'Graph', 'Image Retrieval']\n---\nThe performance of a zero-shot sketch-based image retrieval (ZS-SBIR) task is primarily affected by two challenges. The substantial domain gap between image and sketch features needs to be bridged, while at the same time the side information has to be chosen tactfully. Existing literature has shown that varying the semantic side information greatly affects the performance of ZS-SBIR. To this end, we propose a novel graph transformer based zero-shot sketch-based image retrieval (GTZSR) framework for solving ZS-SBIR tasks which uses a novel graph transformer to preserve the topology of the classes in the semantic space and propagates the context-graph of the classes within the embedding features of the visual space. To bridge the domain gap between the visual features, we propose minimizing the Wasserstein distance between images and sketches in a learned domain-shared space. We also propose a novel compatibility loss that further aligns the two visual domains by bridging the domain gap of one class with respect to the domain gap of all other classes in the training set. Experimental results obtained on the extended Sketchy, TU-Berlin, and QuickDraw datasets exhibit sharp improvements over the existing state-of-the-art methods in both ZS-SBIR and generalized ZS-SBIR.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [10.243997573852539, -30.25688934326172]}, {"key": "", "year": "", "title": "G\u00e9raud2019quotient", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Quotient Hash Tables - Efficiently Detecting Duplicates in Streaming Data\"\nauthors: G\u00e9raud R\u00e9mi, Lombard-Platet Marius, Naccache David\nconference: Arxiv\nyear: 2019\nbibkey: g\u00e9raud2019quotient\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1901.04358\"}\ntags: ['ARXIV', 'Streaming Data']\n---\nThis article presents the Quotient Hash Table (QHT) a new data structure for duplicate detection in unbounded streams. QHTs stem from a corrected analysis of streaming quotient filters (SQFs), resulting in a 33\\% reduction in memory usage for equal performance. We provide a new and thorough analysis of both algorithms, with results of interest to other existing constructions. We also introduce an optimised version of our new data structure dubbed Queued QHT with Duplicates (QQHTD). Finally we discuss the effect of adversarial inputs for hash-based duplicate filters similar to QHT.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-0.7570534348487854, -6.72947359085083]}, {"key": "", "year": "", "title": "Hadwiger2022deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Metric Color Embeddings for Splicing Localization in Severely Degraded Images\"\nauthors: Hadwiger Benjamin, Riess Christian\nconference: Arxiv\nyear: 2022\nbibkey: hadwiger2022deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2206.10737\"}\ntags: ['ARXIV', 'TIP']\n---\nOne common task in image forensics is to detect spliced images, where multiple source images are composed to one output image. Most of the currently best performing splicing detectors leverage high-frequency artifacts. However, after an image underwent strong compression, most of the high frequency artifacts are not available anymore. In this work, we explore an alternative approach to splicing detection, which is potentially better suited for images in-the-wild, subject to strong compression and downsampling. Our proposal is to model the color formation of an image. The color formation largely depends on variations at the scale of scene objects, and is hence much less dependent on high-frequency artifacts. We learn a deep metric space that is on one hand sensitive to illumination color and camera white-point estimation, but on the other hand insensitive to variations in object color. Large distances in the embedding space indicate that two image regions either stem from different scenes or different cameras. In our evaluation, we show that the proposed embedding space outperforms the state of the art on images that have been subject to strong compression and downsampling. We confirm in two further experiments the dual nature of the metric space, namely to both characterize the acquisition camera and the scene illuminant color. As such, this work resides at the intersection of physics-based and statistical forensics with benefits from both sides.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [2.130340337753296, 6.972987174987793]}, {"key": "", "year": "", "title": "Hamann2019hamming", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hamming Sentence Embeddings for Information Retrieval\"\nauthors: Hamann Felix, Kurz Nadja, Ulges Adrian\nconference: Arxiv\nyear: 2019\nbibkey: hamann2019hamming\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1908.05541\"}\ntags: ['ARXIV']\n---\nIn retrieval applications, binary hashes are known to offer significant improvements in terms of both memory and speed. We investigate the compression of sentence embeddings using a neural encoder-decoder architecture, which is trained by minimizing reconstruction error. Instead of employing the original real-valued embeddings, we use latent representations in Hamming space produced by the encoder for similarity calculations. In quantitative experiments on several benchmarks for semantic similarity tasks, we show that our compressed hamming embeddings yield a comparable performance to uncompressed embeddings (Sent2Vec, InferSent, Glove-BoW), at compression ratios of up to 256:1. We further demonstrate that our model strongly decorrelates input features, and that the compressor generalizes well when pre-trained on Wikipedia sentences. We publish the source code on Github and all experimental results.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-0.6502234935760498, -1.261317253112793]}, {"key": "", "year": "", "title": "Han2017mild", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"MILD: Multi-Index hashing for Loop closure Detection\"\nauthors: Han Lei, Fang Lu\nconference: Arxiv\nyear: 2017\nbibkey: han2017mild\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1702.08780\"}\ntags: ['ARXIV']\n---\nLoop Closure Detection (LCD) has been proved to be extremely useful in global consistent visual Simultaneously Localization and Mapping (SLAM) and appearance-based robot relocalization. Methods exploiting binary features in bag of words representation have recently gained a lot of popularity for their efficiency, but suffer from low recall due to the inherent drawback that high dimensional binary feature descriptors lack well-defined centroids. In this paper, we propose a realtime LCD approach called MILD (Multi-Index Hashing for Loop closure Detection), in which image similarity is measured by feature matching directly to achieve high recall without introducing extra computational complexity with the aid of Multi-Index Hashing (MIH). A theoretical analysis of the approximate image similarity measurement using MIH is presented, which reveals the trade-off between efficiency and accuracy from a probabilistic perspective. Extensive comparisons with state-of-the-art LCD methods demonstrate the superiority of MILD in both efficiency and accuracy.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [1.925493836402893, 10.368807792663574]}, {"key": "", "year": "", "title": "Han2023a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Comprehensive Survey on Vector Database: Storage and Retrieval Technique, Challenge\"\nauthors: Han Yikun, Liu Chunjiang, Wang Pengfei\nconference: Arxiv\nyear: 2023\nbibkey: han2023a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2310.11703\"}\ntags: ['ARXIV', 'Graph', 'Quantisation', 'Survey Paper']\n---\nA vector database is used to store high-dimensional data that cannot be characterized by traditional DBMS. Although there are not many articles describing existing or introducing new vector database architectures, the approximate nearest neighbor search problem behind vector databases has been studied for a long time, and considerable related algorithmic articles can be found in the literature. This article attempts to comprehensively review relevant algorithms to provide a general understanding of this booming research area. The basis of our framework categorises these studies by the approach of solving ANNS problem, respectively hash-based, tree-based, graph-based and quantization-based approaches. Then we present an overview of existing challenges for vector databases. Lastly, we sketch how vector databases can be combined with large language models and provide new possibilities.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [9.039329528808594, -9.308333396911621]}, {"key": "", "year": "", "title": "Han2024hashing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hashing based Contrastive Learning for Virtual Screening\"\nauthors: Han Jin, Hong Yun, Li Wu-Jun\nconference: Arxiv\nyear: 2024\nbibkey: han2024hashing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2407.19790\"}\ntags: ['ARXIV', 'Deep Learning']\n---\nVirtual screening (VS) is a critical step in computer-aided drug discovery, aiming to identify molecules that bind to a specific target receptor like protein. Traditional VS methods, such as docking, are often too time-consuming for screening large-scale molecular databases. Recent advances in deep learning have demonstrated that learning vector representations for both proteins and molecules using contrastive learning can outperform traditional docking methods. However, given that target databases often contain billions of molecules, real-valued vector representations adopted by existing methods can still incur significant memory and time costs in VS. To address this problem, in this paper we propose a hashing-based contrastive learning method, called DrugHash, for VS. DrugHash treats VS as a retrieval task that uses efficient binary hash codes for retrieval. In particular, DrugHash designs a simple yet effective hashing strategy to enable end-to-end learning of binary hash codes for both protein and molecule modalities, which can dramatically reduce the memory and time costs with higher accuracy compared with existing methods. Experimental results show that DrugHash can outperform existing methods to achieve state-of-the-art accuracy, with a memory saving of 32$\\times$ and a speed improvement of 3.5$\\times$.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [21.766389846801758, -20.95290184020996]}, {"key": "", "year": "", "title": "Hansen2019unsupervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Unsupervised Neural Generative Semantic Hashing\"\nauthors: Hansen Casper, Hansen Christian, Simonsen Jakob Grue, Alstrup Stephen, Lioma Christina\nconference: Arxiv\nyear: 2019\nbibkey: hansen2019unsupervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1906.00671\"}\ntags: ['ARXIV', 'Supervised', 'Unsupervised']\n---\nFast similarity search is a key component in large-scale information retrieval, where semantic hashing has become a popular strategy for representing documents as binary hash codes. Recent advances in this area have been obtained through neural network based models: generative models trained by learning to reconstruct the original documents. We present a novel unsupervised generative semantic hashing approach, \\textit{Ranking based Semantic Hashing} (RBSH) that consists of both a variational and a ranking based component. Similarly to variational autoencoders, the variational component is trained to reconstruct the original document conditioned on its generated hash code, and as in prior work, it only considers documents individually. The ranking component solves this limitation by incorporating inter-document similarity into the hash code generation, modelling document ranking through a hinge loss. To circumvent the need for labelled data to compute the hinge loss, we use a weak labeller and thus keep the approach fully unsupervised. Extensive experimental evaluation on four publicly available datasets against traditional baselines and recent state-of-the-art methods for semantic hashing shows that RBSH significantly outperforms all other methods across all evaluated hash code lengths. In fact, RBSH hash codes are able to perform similarly to state-of-the-art hash codes while using 2-4x fewer bits.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-8.793871879577637, -2.3763210773468018]}, {"key": "", "year": "", "title": "Hansen2020content", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Content-aware Neural Hashing for Cold-start Recommendation\"\nauthors: Hansen Casper, Hansen Christian, Simonsen Jakob Grue, Alstrup Stephen, Lioma Christina\nconference: Arxiv\nyear: 2020\nbibkey: hansen2020content\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2006.00617\"}\ntags: ['ARXIV']\n---\nContent-aware recommendation approaches are essential for providing meaningful recommendations for \\textit{new} (i.e., \\textit{cold-start}) items in a recommender system. We present a content-aware neural hashing-based collaborative filtering approach (NeuHash-CF), which generates binary hash codes for users and items, such that the highly efficient Hamming distance can be used for estimating user-item relevance. NeuHash-CF is modelled as an autoencoder architecture, consisting of two joint hashing components for generating user and item hash codes. Inspired from semantic hashing, the item hashing component generates a hash code directly from an item's content information (i.e., it generates cold-start and seen item hash codes in the same manner). This contrasts existing state-of-the-art models, which treat the two item cases separately. The user hash codes are generated directly based on user id, through learning a user embedding matrix. We show experimentally that NeuHash-CF significantly outperforms state-of-the-art baselines by up to 12\\% NDCG and 13\\% MRR in cold-start recommendation settings, and up to 4\\% in both NDCG and MRR in standard settings where all items are present while training. Our approach uses 2-4x shorter hash codes, while obtaining the same or better performance compared to the state of the art, thus consequently also enabling a notable storage reduction.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [0.27089646458625793, -4.451014041900635]}, {"key": "", "year": "", "title": "Hansen2020unsupervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Unsupervised Semantic Hashing with Pairwise Reconstruction\"\nauthors: Hansen Casper, Hansen Christian, Simonsen Jakob Grue, Alstrup Stephen, Lioma Christina\nconference: Arxiv\nyear: 2020\nbibkey: hansen2020unsupervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2007.00380\"}\ntags: ['ARXIV', 'Supervised', 'Unsupervised', 'Weakly Supervised']\n---\nSemantic Hashing is a popular family of methods for efficient similarity search in large-scale datasets. In Semantic Hashing, documents are encoded as short binary vectors (i.e., hash codes), such that semantic similarity can be efficiently computed using the Hamming distance. Recent state-of-the-art approaches have utilized weak supervision to train better performing hashing models. Inspired by this, we present Semantic Hashing with Pairwise Reconstruction (PairRec), which is a discrete variational autoencoder based hashing model. PairRec first encodes weakly supervised training pairs (a query document and a semantically similar document) into two hash codes, and then learns to reconstruct the same query document from both of these hash codes (i.e., pairwise reconstruction). This pairwise reconstruction enables our model to encode local neighbourhood structures within the hash code directly through the decoder. We experimentally compare PairRec to traditional and state-of-the-art approaches, and obtain significant performance improvements in the task of document similarity search.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-3.9959287643432617, -2.298468828201294]}, {"key": "", "year": "", "title": "Hansen2021projected", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Projected Hamming Dissimilarity for Bit-Level Importance Coding in Collaborative Filtering\"\nauthors: Hansen Christian, Hansen Casper, Simonsen Jakob Grue, Lioma Christina\nconference: Arxiv\nyear: 2021\nbibkey: hansen2021projected\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2103.14455\"}\ntags: ['ARXIV']\n---\nWhen reasoning about tasks that involve large amounts of data, a common approach is to represent data items as objects in the Hamming space where operations can be done efficiently and effectively. Object similarity can then be computed by learning binary representations (hash codes) of the objects and computing their Hamming distance. While this is highly efficient, each bit dimension is equally weighted, which means that potentially discriminative information of the data is lost. A more expressive alternative is to use real-valued vector representations and compute their inner product; this allows varying the weight of each dimension but is many magnitudes slower. To fix this, we derive a new way of measuring the dissimilarity between two objects in the Hamming space with binary weighting of each dimension (i.e., disabling bits): we consider a field-agnostic dissimilarity that projects the vector of one object onto the vector of the other. When working in the Hamming space, this results in a novel projected Hamming dissimilarity, which by choice of projection, effectively allows a binary importance weighting of the hash code of one object through the hash code of the other. We propose a variational hashing model for learning hash codes optimized for this projected Hamming dissimilarity, and experimentally evaluate it in collaborative filtering experiments. The resultant hash codes lead to effectiveness gains of up to +7% in NDCG and +14% in MRR compared to state-of-the-art hashing-based collaborative filtering baselines, while requiring no additional storage and no computational overhead compared to using the Hamming distance.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-8.533207893371582, 1.2130587100982666]}, {"key": "", "year": "", "title": "Hansen2021representation", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Representation Learning for Efficient and Effective Similarity Search and Recommendation\"\nauthors: Hansen Casper\nconference: Arxiv\nyear: 2021\nbibkey: hansen2021representation\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2109.01815\"}\ntags: ['ARXIV']\n---\nHow data is represented and operationalized is critical for building computational solutions that are both effective and efficient. A common approach is to represent data objects as binary vectors, denoted \\textit{hash codes}, which require little storage and enable efficient similarity search through direct indexing into a hash table or through similarity computations in an appropriate space. Due to the limited expressibility of hash codes, compared to real-valued representations, a core open challenge is how to generate hash codes that well capture semantic content or latent properties using a small number of bits, while ensuring that the hash codes are distributed in a way that does not reduce their search efficiency. State of the art methods use representation learning for generating such hash codes, focusing on neural autoencoder architectures where semantics are encoded into the hash codes by learning to reconstruct the original inputs of the hash codes. This thesis addresses the above challenge and makes a number of contributions to representation learning that (i) improve effectiveness of hash codes through more expressive representations and a more effective similarity measure than the current state of the art, namely the Hamming distance, and (ii) improve efficiency of hash codes by learning representations that are especially suited to the choice of search method. The contributions are empirically validated on several tasks related to similarity search and recommendation.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-5.060635089874268, -4.749185085296631]}, {"key": "", "year": "", "title": "Hansen2021unsupervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Unsupervised Multi-Index Semantic Hashing\"\nauthors: Hansen Christian, Hansen Casper, Simonsen Jakob Grue, Alstrup Stephen, Lioma Christina\nconference: Arxiv\nyear: 2021\nbibkey: hansen2021unsupervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2103.14460\"}\ntags: ['ARXIV', 'Supervised', 'Unsupervised']\n---\nSemantic hashing represents documents as compact binary vectors (hash codes) and allows both efficient and effective similarity search in large-scale information retrieval. The state of the art has primarily focused on learning hash codes that improve similarity search effectiveness, while assuming a brute-force linear scan strategy for searching over all the hash codes, even though much faster alternatives exist. One such alternative is multi-index hashing, an approach that constructs a smaller candidate set to search over, which depending on the distribution of the hash codes can lead to sub-linear search time. In this work, we propose Multi-Index Semantic Hashing (MISH), an unsupervised hashing model that learns hash codes that are both effective and highly efficient by being optimized for multi-index hashing. We derive novel training objectives, which enable to learn hash codes that reduce the candidate sets produced by multi-index hashing, while being end-to-end trainable. In fact, our proposed training objectives are model agnostic, i.e., not tied to how the hash codes are generated specifically in MISH, and are straight-forward to include in existing and future semantic hashing models. We experimentally compare MISH to state-of-the-art semantic hashing baselines in the task of document similarity search. We find that even though multi-index hashing also improves the efficiency of the baselines compared to a linear scan, they are still upwards of 33% slower than MISH, while MISH is still able to obtain state-of-the-art effectiveness.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-9.855020523071289, -1.8119298219680786]}, {"key": "", "year": "", "title": "Harandi2014expanding", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Expanding the Family of Grassmannian Kernels: An Embedding Perspective\"\nauthors: Harandi Mehrtash T., Salzmann Mathieu, Jayasumana Sadeep, Hartley Richard, Li Hongdong\nconference: Arxiv\nyear: 2014\nbibkey: harandi2014expanding\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1407.1123\"}\ntags: ['ARXIV']\n---\nModeling videos and image-sets as linear subspaces has proven beneficial for many visual recognition tasks. However, it also incurs challenges arising from the fact that linear subspaces do not obey Euclidean geometry, but lie on a special type of Riemannian manifolds known as Grassmannian. To leverage the techniques developed for Euclidean spaces (e.g, support vector machines) with subspaces, several recent studies have proposed to embed the Grassmannian into a Hilbert space by making use of a positive definite kernel. Unfortunately, only two Grassmannian kernels are known, none of which -as we will show- is universal, which limits their ability to approximate a target function arbitrarily well. Here, we introduce several positive definite Grassmannian kernels, including universal ones, and demonstrate their superiority over previously-known kernels in various tasks, such as classification, clustering, sparse coding and hashing.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [10.298246383666992, 9.747579574584961]}, {"key": "", "year": "", "title": "Harpeled2010approximate", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Approximate Nearest Neighbor Search for Low Dimensional Queries\"\nauthors: Har-Peled Sariel, Kumar Nirman\nconference: Arxiv\nyear: 2010\nbibkey: harpeled2010approximate\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1007.3296\"}\ntags: ['ARXIV']\n---\nWe study the Approximate Nearest Neighbor problem for metric spaces where the query points are constrained to lie on a subspace of low doubling dimension, while the data is high-dimensional. We show that this problem can be solved efficiently despite the high dimensionality of the data.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [10.359175682067871, -18.846193313598633]}, {"key": "", "year": "", "title": "Harvey2024explicit", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Explicit Orthogonal Arrays and Universal Hashing with Arbitrary Parameters\"\nauthors: Harvey Nicholas, Sahami Arvin\nconference: Arxiv\nyear: 2024\nbibkey: harvey2024explicit\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2405.08787\"}\ntags: ['ARXIV']\n---\nOrthogonal arrays are a type of combinatorial design that were developed in the 1940s in the design of statistical experiments. In 1947, Rao proved a lower bound on the size of any orthogonal array, and raised the problem of constructing arrays of minimum size. Kuperberg, Lovett and Peled (2017) gave a non-constructive existence proof of orthogonal arrays whose size is near-optimal (i.e., within a polynomial of Rao's lower bound), leaving open the question of an algorithmic construction. We give the first explicit, deterministic, algorithmic construction of orthogonal arrays achieving near-optimal size for all parameters. Our construction uses algebraic geometry codes. In pseudorandomness, the notions of $t$-independent generators or $t$-independent hash functions are equivalent to orthogonal arrays. Classical constructions of $t$-independent hash functions are known when the size of the codomain is a prime power, but very few constructions are known for an arbitrary codomain. Our construction yields algorithmically efficient $t$-independent hash functions for arbitrary domain and codomain.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-4.9795684814453125, -25.932193756103516]}, {"key": "", "year": "", "title": "Hassanat2014dimensionality", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Dimensionality Invariant Similarity Measure\"\nauthors: Hassanat Ahmad Basheer\nconference: J Am Sci\nyear: 2014\nbibkey: hassanat2014dimensionality\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1409.0923\"}\ntags: ['Supervised']\n---\nThis paper presents a new similarity measure to be used for general tasks including supervised learning, which is represented by the K-nearest neighbor classifier (KNN). The proposed similarity measure is invariant to large differences in some dimensions in the feature space. The proposed metric is proved mathematically to be a metric. To test its viability for different applications, the KNN used the proposed metric for classifying test examples chosen from a number of real datasets. Compared to some other well known metrics, the experimental results show that the proposed metric is a promising distance measure for the KNN classifier with strong potential for a wide range of applications.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [2.1996912956237793, -19.87820816040039]}, {"key": "", "year": "", "title": "Hayashi2013more", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"More Efficient Privacy Amplification with Less Random Seeds via Dual Universal Hash Function\"\nauthors: Hayashi Masahito, Tsurumaru Toyohiro\nconference: IEEE Transactions on Information Theory, Volume\nyear: 2013\nbibkey: hayashi2013more\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1311.5322\"}\ntags: ['Volume']\n---\nWe explicitly construct random hash functions for privacy amplification (extractors) that require smaller random seed lengths than the previous literature, and still allow efficient implementations with complexity $O(n\\log n)$ for input length $n$. The key idea is the concept of dual universal$_2$ hash function introduced recently. We also use a new method for constructing extractors by concatenating $\\delta$-almost dual universal$_2$ hash functions with other extractors. Besides minimizing seed lengths, we also introduce methods that allow one to use non-uniform random seeds for extractors. These methods can be applied to a wide class of extractors, including dual universal$_2$ hash function, as well as to conventional universal$_2$ hash functions.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-7.7190632820129395, -10.340758323669434]}, {"key": "", "year": "", "title": "Hayashi2013security", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Security analysis of epsilon-almost dual universal2 hash functions: smoothing of min entropy vs. smoothing of R\\'enyi entropy of order 2\"\nauthors: Hayashi Masahito\nconference: IEEE Transactions on Information Theory, Volume\nyear: 2013\nbibkey: hayashi2013security\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1309.1596\"}\ntags: ['Volume']\n---\nRecently, $\\varepsilon$-almost dual universal$_2$ hash functions has been proposed as a new and wider class of hash functions. Using this class of hash functions, several efficient hash functions were proposed. This paper evaluates the security performance when we apply this kind of hash functions. We evaluate the security in several kinds of setting based on the $L_1$ distinguishability criterion and the modified mutual information criterion. The obtained evaluation is based on smoothing of R\\'{e}nyi entropy of order 2 and/or min entropy. We clarify the difference between these two methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-29.75360107421875, -1.020776391029358]}, {"key": "", "year": "", "title": "He2012on", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"On the Difficulty of Nearest Neighbor Search\"\nauthors: He Junfeng  Columbia University, Kumar Sanjiv  Google Research, Chang Shih-Fu  Columbia University\nconference: Arxiv\nyear: 2012\nbibkey: he2012on\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1206.6411\"}\ntags: ['ARXIV']\n---\nFast approximate nearest neighbor (NN) search in large databases is becoming popular. Several powerful learning-based formulations have been proposed recently. However, not much attention has been paid to a more fundamental question: how difficult is (approximate) nearest neighbor search in a given data set? And which data properties affect the difficulty of nearest neighbor search and how? This paper introduces the first concrete measure called Relative Contrast that can be used to evaluate the influence of several crucial data characteristics such as dimensionality, sparsity, and database size simultaneously in arbitrary normed metric spaces. Moreover, we present a theoretical analysis to prove how the difficulty measure (relative contrast) determines/affects the complexity of Local Sensitive Hashing, a popular approximate NN search method. Relative contrast also provides an explanation for a family of heuristic hashing algorithms with good practical performance based on PCA. Finally, we show that most of the previous works in measuring NN search meaningfulness/difficulty can be derived as special asymptotic cases for dense vectors of the proposed measure.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-6.683353424072266, -13.4063138961792]}, {"key": "", "year": "", "title": "He2017hashing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hashing as Tie-Aware Learning to Rank\"\nauthors: He Kun, Cakir Fatih, Bargal Sarah Adel, Sclaroff Stan\nconference: Arxiv\nyear: 2017\nbibkey: he2017hashing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1705.08562\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nHashing, or learning binary embeddings of data, is frequently used in nearest neighbor retrieval. In this paper, we develop learning to rank formulations for hashing, aimed at directly optimizing ranking-based evaluation metrics such as Average Precision (AP) and Normalized Discounted Cumulative Gain (NDCG). We first observe that the integer-valued Hamming distance often leads to tied rankings, and propose to use tie-aware versions of AP and NDCG to evaluate hashing for retrieval. Then, to optimize tie-aware ranking metrics, we derive their continuous relaxations, and perform gradient-based optimization with deep neural networks. Our results establish the new state-of-the-art for image retrieval by Hamming ranking in common benchmarks.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-5.431623935699463, 18.333593368530273]}, {"key": "", "year": "", "title": "He2019one", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"One Network for Multi-Domains: Domain Adaptive Hashing with Intersectant Generative Adversarial Network\"\nauthors: He Tao, Li Yuan-Fang, Gao Lianli, Zhang Dongxiang, Song Jingkuan\nconference: Arxiv\nyear: 2019\nbibkey: he2019one\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1907.00612\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nWith the recent explosive increase of digital data, image recognition and retrieval become a critical practical application. Hashing is an effective solution to this problem, due to its low storage requirement and high query speed. However, most of past works focus on hashing in a single (source) domain. Thus, the learned hash function may not adapt well in a new (target) domain that has a large distributional difference with the source domain. In this paper, we explore an end-to-end domain adaptive learning framework that simultaneously and precisely generates discriminative hash codes and classifies target domain images. Our method encodes two domains images into a semantic common space, followed by two independent generative adversarial networks arming at crosswise reconstructing two domains' images, reducing domain disparity and improving alignment in the shared space. We evaluate our framework on {four} public benchmark datasets, all of which show that our method is superior to the other state-of-the-art methods on the tasks of object recognition and image retrieval.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-0.9414212703704834, 10.067992210388184]}, {"key": "", "year": "", "title": "He2021unsupervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Unsupervised Domain-adaptive Hash for Networks\"\nauthors: He Tao, Gao Lianli, Song Jingkuan, Li Yuan-Fang\nconference: Arxiv\nyear: 2021\nbibkey: he2021unsupervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2108.09136\"}\ntags: ['ARXIV', 'Supervised', 'TIP', 'Unsupervised']\n---\nAbundant real-world data can be naturally represented by large-scale networks, which demands efficient and effective learning algorithms. At the same time, labels may only be available for some networks, which demands these algorithms to be able to adapt to unlabeled networks. Domain-adaptive hash learning has enjoyed considerable success in the computer vision community in many practical tasks due to its lower cost in both retrieval time and storage footprint. However, it has not been applied to multiple-domain networks. In this work, we bridge this gap by developing an unsupervised domain-adaptive hash learning method for networks, dubbed UDAH. Specifically, we develop four {task-specific yet correlated} components: (1) network structure preservation via a hard groupwise contrastive loss, (2) relaxation-free supervised hashing, (3) cross-domain intersected discriminators, and (4) semantic center alignment. We conduct a wide range of experiments to evaluate the effectiveness and efficiency of our method on a range of tasks including link prediction, node classification, and neighbor recommendation. Our evaluation results demonstrate that our model achieves better performance than the state-of-the-art conventional discrete embedding methods over all the tasks.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-21.39812660217285, 10.130284309387207]}, {"key": "", "year": "", "title": "He2024bit", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Bit-mask Robust Contrastive Knowledge Distillation for Unsupervised Semantic Hashing\"\nauthors: He Liyang, Huang Zhenya, Liu Jiayu, Chen Enhong, Wang Fei, Sha Jing, Wang Shijin\nconference: Arxiv\nyear: 2024\nbibkey: he2024bit\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2403.06071\"}   - {name: \"Code\", url: \"https://github.com/hly1998/BRCD.\"}\ntags: ['ARXIV', 'Supervised', 'Unsupervised']\n---\nUnsupervised semantic hashing has emerged as an indispensable technique for fast image search, which aims to convert images into binary hash codes without relying on labels. Recent advancements in the field demonstrate that employing large-scale backbones (e.g., ViT) in unsupervised semantic hashing models can yield substantial improvements. However, the inference delay has become increasingly difficult to overlook. Knowledge distillation provides a means for practical model compression to alleviate this delay. Nevertheless, the prevailing knowledge distillation approaches are not explicitly designed for semantic hashing. They ignore the unique search paradigm of semantic hashing, the inherent necessities of the distillation process, and the property of hash codes. In this paper, we propose an innovative Bit-mask Robust Contrastive knowledge Distillation (BRCD) method, specifically devised for the distillation of semantic hashing models. To ensure the effectiveness of two kinds of search paradigms in the context of semantic hashing, BRCD first aligns the semantic spaces between the teacher and student models through a contrastive knowledge distillation objective. Additionally, to eliminate noisy augmentations and ensure robust optimization, a cluster-based method within the knowledge distillation process is introduced. Furthermore, through a bit-level analysis, we uncover the presence of redundancy bits resulting from the bit independence property. To mitigate these effects, we introduce a bit mask mechanism in our knowledge distillation objective. Finally, extensive experiments not only showcase the noteworthy performance of our BRCD method in comparison to other knowledge distillation methods but also substantiate the generality of our methods across diverse semantic hashing models and backbones. The code for BRCD is available at https://github.com/hly1998/BRCD.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-16.081159591674805, 8.993572235107422]}, {"key": "", "year": "", "title": "He2024hybridhash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"HybridHash: Hybrid Convolutional and Self-Attention Deep Hashing for Image Retrieval\"\nauthors: He Chao, Wei Hongxi\nconference: Arxiv\nyear: 2024\nbibkey: he2024hybridhash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2405.07524\"}   - {name: \"Code\", url: \"https://github.com/shuaichaochao/HybridHash.\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nDeep image hashing aims to map input images into simple binary hash codes via deep neural networks and thus enable effective large-scale image retrieval. Recently, hybrid networks that combine convolution and Transformer have achieved superior performance on various computer tasks and have attracted extensive attention from researchers. Nevertheless, the potential benefits of such hybrid networks in image retrieval still need to be verified. To this end, we propose a hybrid convolutional and self-attention deep hashing method known as HybridHash. Specifically, we propose a backbone network with stage-wise architecture in which the block aggregation function is introduced to achieve the effect of local self-attention and reduce the computational complexity. The interaction module has been elaborately designed to promote the communication of information between image blocks and to enhance the visual representations. We have conducted comprehensive experiments on three widely used datasets: CIFAR-10, NUS-WIDE and IMAGENET. The experimental results demonstrate that the method proposed in this paper has superior performance with respect to state-of-the-art deep hashing methods. Source code is available https://github.com/shuaichaochao/HybridHash.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [4.880336761474609, 6.813130855560303]}, {"key": "", "year": "", "title": "Heddes2022hyperdimensional", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hyperdimensional Hashing: A Robust and Efficient Dynamic Hash Table\"\nauthors: Heddes Mike, Nunes Igor, Givargis Tony, Nicolau Alexandru, Veidenbaum Alex\nconference: Arxiv\nyear: 2022\nbibkey: heddes2022hyperdimensional\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2205.07850\"}\ntags: ['ARXIV']\n---\nMost cloud services and distributed applications rely on hashing algorithms that allow dynamic scaling of a robust and efficient hash table. Examples include AWS, Google Cloud and BitTorrent. Consistent and rendezvous hashing are algorithms that minimize key remapping as the hash table resizes. While memory errors in large-scale cloud deployments are common, neither algorithm offers both efficiency and robustness. Hyperdimensional Computing is an emerging computational model that has inherent efficiency, robustness and is well suited for vector or hardware acceleration. We propose Hyperdimensional (HD) hashing and show that it has the efficiency to be deployed in large systems. Moreover, a realistic level of memory errors causes more than 20% mismatches for consistent hashing while HD hashing remains unaffected.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-25.248693466186523, -11.21475601196289]}, {"key": "", "year": "", "title": "Hegeman2024compact", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Compact Parallel Hash Tables on the GPU\"\nauthors: Hegeman Steef, W\u00f6ltgens Daan, Wijs Anton, Laarman Alfons\nconference: Arxiv\nyear: 2024\nbibkey: hegeman2024compact\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2406.09255\"}\ntags: ['ARXIV']\n---\nOn the GPU, hash table operation speed is determined in large part by cache line efficiency, and state-of-the-art hashing schemes thus divide tables into cache line-sized buckets. This raises the question whether performance can be further improved by increasing the number of entries that fit in such buckets. Known compact hashing techniques have not yet been adapted to the massively parallel setting, nor have they been evaluated on the GPU. We consider a compact version of bucketed cuckoo hashing, and a version of compact iceberg hashing suitable for the GPU. We discuss the tables from a theoretical perspective, and provide an open source implementation of both schemes in CUDA for comparative benchmarking. In terms of performance, the state-of-the-art cuckoo hashing benefits from compactness on lookups and insertions (most experiments show at least 10-20% increase in throughput), and the iceberg table benefits significantly, to the point of being comparable to compact cuckoo hashing--while supporting performant dynamic operation.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-18.30526351928711, -11.663073539733887]}, {"key": "", "year": "", "title": "Helbling2020directed", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Directed Graph Hashing\"\nauthors: Helbling Caleb\nconference: Arxiv\nyear: 2020\nbibkey: helbling2020directed\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2002.06653\"}\ntags: ['ARXIV', 'Graph', 'TOM']\n---\nThis paper presents several algorithms for hashing directed graphs. The algorithms given are capable of hashing entire graphs as well as assigning hash values to specific nodes in a given graph. The notion of node symmetry is made precise via computation of vertex orbits and the graph automorphism group, and nodes that are symmetrically identical are assigned equal hashes. We also present a novel Merkle-style hashing algorithm that seeks to fulfill the recursive principle that a hash of a node should depend only on the hash of its neighbors. This algorithm works even in the presence of cycles, which would not be possible with a naive approach. Structurally hashing trees has seen widespread use in blockchain, source code version control, and web applications. Despite the popularity of tree hashing, directed graph hashing remains unstudied in the literature. Our algorithms open new possibilities to hashing both directed graphs and more complex data structures that can be reduced to directed graphs such as hypergraphs.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [6.358807563781738, -32.0909423828125]}, {"key": "", "year": "", "title": "Helmer2018a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Similarity Measure for Weaving Patterns in Textiles\"\nauthors: Helmer Sven, Ngo Vuong M.\nconference: SIGIR\nyear: 2018\nbibkey: helmer2018a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1810.04604\"}\ntags: ['Graph']\n---\nWe propose a novel approach for measuring the similarity between weaving patterns that can provide similarity-based search functionality for textile archives. We represent textile structures using hypergraphs and extract multisets of k-neighborhoods from these graphs. The resulting multisets are then compared using Jaccard coefficients, Hamming distances, and cosine measures. We evaluate the different variants of our similarity measure experimentally, showing that it can be implemented efficiently and illustrating its quality using it to cluster and query a data set containing more than a thousand textile samples.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.404234886169434, -22.44410514831543]}, {"key": "", "year": "", "title": "Hemati2020a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A non-alternating graph hashing algorithm for large scale image search\"\nauthors: Hemati Sobhan, Mehdizavareh Mohammad Hadi, Chenouri Shojaeddin, Tizhoosh Hamid R\nconference: Arxiv\nyear: 2020\nbibkey: hemati2020a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2012.13138\"}\ntags: ['ARXIV', 'Graph']\n---\nIn the era of big data, methods for improving memory and computational efficiency have become crucial for successful deployment of technologies. Hashing is one of the most effective approaches to deal with computational limitations that come with big data. One natural way for formulating this problem is spectral hashing that directly incorporates affinity to learn binary codes. However, due to binary constraints, the optimization becomes intractable. To mitigate this challenge, different relaxation approaches have been proposed to reduce the computational load of obtaining binary codes and still attain a good solution. The problem with all existing relaxation methods is resorting to one or more additional auxiliary variables to attain high quality binary codes while relaxing the problem. The existence of auxiliary variables leads to coordinate descent approach which increases the computational complexity. We argue that introducing these variables is unnecessary. To this end, we propose a novel relaxed formulation for spectral hashing that adds no additional variables to the problem. Furthermore, instead of solving the problem in original space where number of variables is equal to the data points, we solve the problem in a much smaller space and retrieve the binary codes from this solution. This trick reduces both the memory and computational complexity at the same time. We apply two optimization techniques, namely projected gradient and optimization on manifold, to obtain the solution. Using comprehensive experiments on four public datasets, we show that the proposed efficient spectral hashing (ESH) algorithm achieves highly competitive retrieval performance compared with state of the art at low complexity.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [0.8854431509971619, -27.88740348815918]}, {"key": "", "year": "", "title": "Hemati2021beyond", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Beyond Neighbourhood-Preserving Transformations for Quantization-Based Unsupervised Hashing\"\nauthors: Hemati Sobhan, Tizhoosh H. R.\nconference: Arxiv\nyear: 2021\nbibkey: hemati2021beyond\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2110.00216\"}\ntags: ['ARXIV', 'Quantisation', 'Supervised', 'Unsupervised']\n---\nAn effective unsupervised hashing algorithm leads to compact binary codes preserving the neighborhood structure of data as much as possible. One of the most established schemes for unsupervised hashing is to reduce the dimensionality of data and then find a rigid (neighbourhood-preserving) transformation that reduces the quantization error. Although employing rigid transformations is effective, we may not reduce quantization loss to the ultimate limits. As well, reducing dimensionality and quantization loss in two separate steps seems to be sub-optimal. Motivated by these shortcomings, we propose to employ both rigid and non-rigid transformations to reduce quantization error and dimensionality simultaneously. We relax the orthogonality constraint on the projection in a PCA-formulation and regularize this by a quantization term. We show that both the non-rigid projection matrix and rotation matrix contribute towards minimizing quantization loss but in different ways. A scalable nested coordinate descent approach is proposed to optimize this mixed-integer optimization problem. We evaluate the proposed method on five public benchmark datasets providing almost half a million images. Comparative results indicate that the proposed method mostly outperforms state-of-art linear methods and competes with end-to-end deep solutions.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-4.031496047973633, 2.5843002796173096]}, {"key": "", "year": "", "title": "Heo2023robust", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Robust Camera Pose Refinement for Multi-Resolution Hash Encoding\"\nauthors: Heo Hwan, Kim Taekyung, Lee Jiyoung, Lee Jaewon, Kim Soohyun, Kim Hyunwoo J., Kim Jin-Hwa\nconference: Arxiv\nyear: 2023\nbibkey: heo2023robust\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2302.01571\"}\ntags: ['ARXIV']\n---\nMulti-resolution hash encoding has recently been proposed to reduce the computational cost of neural renderings, such as NeRF. This method requires accurate camera poses for the neural renderings of given scenes. However, contrary to previous methods jointly optimizing camera poses and 3D scenes, the naive gradient-based camera pose refinement method using multi-resolution hash encoding severely deteriorates performance. We propose a joint optimization algorithm to calibrate the camera pose and learn a geometric representation using efficient multi-resolution hash encoding. Showing that the oscillating gradient flows of hash encoding interfere with the registration of camera poses, our method addresses the issue by utilizing smooth interpolation weighting to stabilize the gradient oscillation for the ray samplings across hash grids. Moreover, the curriculum training procedure helps to learn the level-wise hash encoding, further increasing the pose refinement. Experiments on the novel-view synthesis datasets validate that our learning frameworks achieve state-of-the-art performance and rapid convergence of neural rendering, even when initial camera poses are unknown.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-9.548908233642578, 10.64382266998291]}, {"key": "", "year": "", "title": "Hiemstra2010mirex", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"MIREX: MapReduce Information Retrieval Experiments\"\nauthors: Hiemstra Djoerd, Hauff Claudia\nconference: Arxiv\nyear: 2010\nbibkey: hiemstra2010mirex\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1004.4489\"}   - {name: \"Paper\", url: \"http://mirex.sourceforge.net\"}\ntags: ['ARXIV']\n---\nWe propose to use MapReduce to quickly test new retrieval approaches on a cluster of machines by sequentially scanning all documents. We present a small case study in which we use a cluster of 15 low cost ma- chines to search a web crawl of 0.5 billion pages showing that sequential scanning is a viable approach to running large-scale information retrieval experiments with little effort. The code is available to other researchers at: http://mirex.sourceforge.net\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [19.588743209838867, -13.808537483215332]}, {"key": "", "year": "", "title": "Hinami2017region", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Region-Based Image Retrieval Revisited\"\nauthors: Hinami Ryota, Matsui Yusuke, Satoh Shin'ichi\nconference: Arxiv\nyear: 2017\nbibkey: hinami2017region\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1709.09106\"}\ntags: ['ARXIV', 'CNN', 'Deep Learning', 'Image Retrieval', 'TIP']\n---\nRegion-based image retrieval (RBIR) technique is revisited. In early attempts at RBIR in the late 90s, researchers found many ways to specify region-based queries and spatial relationships; however, the way to characterize the regions, such as by using color histograms, were very poor at that time. Here, we revisit RBIR by incorporating semantic specification of objects and intuitive specification of spatial relationships. Our contributions are the following. First, to support multiple aspects of semantic object specification (category, instance, and attribute), we propose a multitask CNN feature that allows us to use deep learning technique and to jointly handle multi-aspect object specification. Second, to help users specify spatial relationships among objects in an intuitive way, we propose recommendation techniques of spatial relationships. In particular, by mining the search results, a system can recommend feasible spatial relationships among the objects. The system also can recommend likely spatial relationships by assigned object category names based on language prior. Moreover, object-level inverted indexing supports very fast shortlist generation, and re-ranking based on spatial constraints provides users with instant RBIR experiences.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [21.625980377197266, 14.12060546875]}, {"key": "", "year": "", "title": "Hoang2017enhance", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Enhance Feature Discrimination for Unsupervised Hashing\"\nauthors: Hoang Tuan, Do Thanh-Toan, Tan Dang-Khoa Le, Cheung Ngai-Man\nconference: Arxiv\nyear: 2017\nbibkey: hoang2017enhance\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1704.01754\"}\ntags: ['ARXIV', 'Quantisation', 'Supervised', 'Unsupervised']\n---\nWe introduce a novel approach to improve unsupervised hashing. Specifically, we propose a very efficient embedding method: Gaussian Mixture Model embedding (Gemb). The proposed method, using Gaussian Mixture Model, embeds feature vector into a low-dimensional vector and, simultaneously, enhances the discriminative property of features before passing them into hashing. Our experiment shows that the proposed method boosts the hashing performance of many state-of-the-art, e.g. Binary Autoencoder (BA) [1], Iterative Quantization (ITQ) [2], in standard evaluation metrics for the three main benchmark datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [5.089974403381348, -2.9796082973480225]}, {"key": "", "year": "", "title": "Hoang2017selective", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Selective Deep Convolutional Features for Image Retrieval\"\nauthors: Hoang Tuan, Do Thanh-Toan, Tan Dang-Khoa Le, Cheung Ngai-Man\nconference: Arxiv\nyear: 2017\nbibkey: hoang2017selective\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1707.00809\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval']\n---\nConvolutional Neural Network (CNN) is a very powerful approach to extract discriminative local descriptors for effective image search. Recent work adopts fine-tuned strategies to further improve the discriminative power of the descriptors. Taking a different approach, in this paper, we propose a novel framework to achieve competitive retrieval performance. Firstly, we propose various masking schemes, namely SIFT-mask, SUM-mask, and MAX-mask, to select a representative subset of local convolutional features and remove a large number of redundant features. We demonstrate that this can effectively address the burstiness issue and improve retrieval accuracy. Secondly, we propose to employ recent embedding and aggregating methods to further enhance feature discriminability. Extensive experiments demonstrate that our proposed framework achieves state-of-the-art retrieval accuracy.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [13.3410062789917, 26.215564727783203]}, {"key": "", "year": "", "title": "Hoang2018simultaneous", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Simultaneous Compression and Quantization: A Joint Approach for Efficient Unsupervised Hashing\"\nauthors: Hoang Tuan, Do Thanh-Toan, Le Huu, Le-Tan Dang-Khoa, Cheung Ngai-Man\nconference: Arxiv\nyear: 2018\nbibkey: hoang2018simultaneous\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1802.06645\"}\ntags: ['ARXIV', 'GAN', 'Image Retrieval', 'Quantisation', 'Supervised', 'Unsupervised']\n---\nFor unsupervised data-dependent hashing, the two most important requirements are to preserve similarity in the low-dimensional feature space and to minimize the binary quantization loss. A well-established hashing approach is Iterative Quantization (ITQ), which addresses these two requirements in separate steps. In this paper, we revisit the ITQ approach and propose novel formulations and algorithms to the problem. Specifically, we propose a novel approach, named Simultaneous Compression and Quantization (SCQ), to jointly learn to compress (reduce dimensionality) and binarize input data in a single formulation under strict orthogonal constraint. With this approach, we introduce a loss function and its relaxed version, termed Orthonormal Encoder (OnE) and Orthogonal Encoder (OgE) respectively, which involve challenging binary and orthogonal constraints. We propose to attack the optimization using novel algorithms based on recent advances in cyclic coordinate descent approach. Comprehensive experiments on unsupervised image retrieval demonstrate that our proposed methods consistently outperform other state-of-the-art hashing methods. Notably, our proposed methods outperform recent deep neural networks and GAN based hashing in accuracy, while being very computationally-efficient.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-5.578415393829346, 1.519800066947937]}, {"key": "", "year": "", "title": "Hoang2020unsupervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Unsupervised Deep Cross-modality Spectral Hashing\"\nauthors: Hoang Tuan, Do Thanh-Toan, Nguyen Tam V., Cheung Ngai-Man\nconference: Arxiv\nyear: 2020\nbibkey: hoang2020unsupervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2008.00223\"}\ntags: ['ARXIV', 'CNN', 'Cross Modal', 'Supervised', 'Unsupervised']\n---\nThis paper presents a novel framework, namely Deep Cross-modality Spectral Hashing (DCSH), to tackle the unsupervised learning problem of binary hash codes for efficient cross-modal retrieval. The framework is a two-step hashing approach which decouples the optimization into (1) binary optimization and (2) hashing function learning. In the first step, we propose a novel spectral embedding-based algorithm to simultaneously learn single-modality and binary cross-modality representations. While the former is capable of well preserving the local structure of each modality, the latter reveals the hidden patterns from all modalities. In the second step, to learn mapping functions from informative data inputs (images and word embeddings) to binary codes obtained from the first step, we leverage the powerful CNN for images and propose a CNN-based deep architecture to learn text modality. Quantitative evaluations on three standard benchmark datasets demonstrate that the proposed DCSH method consistently outperforms other state-of-the-art methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [7.913113117218018, 29.065628051757812]}, {"key": "", "year": "", "title": "Hoang2021multi", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Multi-Modal Mutual Information Maximization: A Novel Approach for Unsupervised Deep Cross-Modal Hashing\"\nauthors: Hoang Tuan, Do Thanh-Toan, Nguyen Tam V., Cheung Ngai-Man\nconference: Arxiv\nyear: 2021\nbibkey: hoang2021multi\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2112.06489\"}\ntags: ['ARXIV', 'Cross Modal', 'Supervised', 'Unsupervised']\n---\nIn this paper, we adopt the maximizing mutual information (MI) approach to tackle the problem of unsupervised learning of binary hash codes for efficient cross-modal retrieval. We proposed a novel method, dubbed Cross-Modal Info-Max Hashing (CMIMH). First, to learn informative representations that can preserve both intra- and inter-modal similarities, we leverage the recent advances in estimating variational lower-bound of MI to maximize the MI between the binary representations and input features and between binary representations of different modalities. By jointly maximizing these MIs under the assumption that the binary representations are modelled by multivariate Bernoulli distributions, we can learn binary representations, which can preserve both intra- and inter-modal similarities, effectively in a mini-batch manner with gradient descent. Furthermore, we find out that trying to minimize the modality gap by learning similar binary representations for the same instance from different modalities could result in less informative representations. Hence, balancing between reducing the modality gap and losing modality-private information is important for the cross-modal retrieval tasks. Quantitative evaluations on standard benchmark datasets demonstrate that the proposed method consistently outperforms other state-of-the-art cross-modal retrieval methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-4.5898661613464355, 1.8246811628341675]}, {"key": "", "year": "", "title": "Hoe2021one", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"One Loss for All: Deep Hashing with a Single Cosine Similarity based Learning Objective\"\nauthors: Hoe Jiun Tian, Ng Kam Woh, Zhang Tianyu, Chan Chee Seng, Song Yi-Zhe, Xiang Tao\nconference: Arxiv\nyear: 2021\nbibkey: hoe2021one\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2109.14449\"}   - {name: \"Code\", url: \"https://github.com/kamwoh/orthohash\"}\ntags: ['ARXIV', 'Quantisation']\n---\nA deep hashing model typically has two main learning objectives: to make the learned binary hash codes discriminative and to minimize a quantization error. With further constraints such as bit balance and code orthogonality, it is not uncommon for existing models to employ a large number (&gt;4) of losses. This leads to difficulties in model training and subsequently impedes their effectiveness. In this work, we propose a novel deep hashing model with only a single learning objective. Specifically, we show that maximizing the cosine similarity between the continuous codes and their corresponding binary orthogonal codes can ensure both hash code discriminativeness and quantization error minimization. Further, with this learning objective, code balancing can be achieved by simply using a Batch Normalization (BN) layer and multi-label classification is also straightforward with label smoothing. The result is an one-loss deep hashing model that removes all the hassles of tuning the weights of various losses. Importantly, extensive experiments show that our model is highly effective, outperforming the state-of-the-art multi-loss hashing models on three large-scale instance retrieval benchmarks, often by significant margins. Code is available at https://github.com/kamwoh/orthohash\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-10.454207420349121, 0.8559761643409729]}, {"key": "", "year": "", "title": "Holden2023identifying", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Identifying reducible k-tuples of vectors with subspace-proximity sensitive hashing/filtering\"\nauthors: Holden Gabriella, Shiu Daniel, Strutt Lauren\nconference: Arxiv\nyear: 2023\nbibkey: holden2023identifying\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2310.08416\"}\ntags: ['ARXIV']\n---\nWe introduce and analyse a family of hash and predicate functions that are more likely to produce collisions for small reducible configurations of vectors. These may offer practical improvements to lattice sieving for short vectors. In particular, in one asymptotic regime the family exhibits significantly different convergent behaviour than existing hash functions and predicates.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [9.40507698059082, -11.126431465148926]}, {"key": "", "year": "", "title": "Hor2019image", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Image retrieval approach based on local texture information derived from predefined patterns and spatial domain information\"\nauthors: Hor Nazgol, Fekri-Ershad Shervan\nconference: International Journal of Computer Science Engineering\nyear: 2019\nbibkey: hor2019image\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1912.12978\"}\ntags: ['Image Retrieval']\n---\nWith the development of Information technology and communication, a large part of the databases is dedicated to images and videos. Thus retrieving images related to a query image from a large database has become an important area of research in computer vision. Until now, there are various methods of image retrieval that try to define image contents by texture, color or shape properties. In this paper, a method is presented for image retrieval based on a combination of local texture information derived from two different texture descriptors. First, the color channels of the input image are separated. The texture information is extracted using two descriptors such as evaluated local binary patterns and predefined pattern units. After extracting the features, the similarity matching is done based on distance criteria. The performance of the proposed method is evaluated in terms of precision and recall on the Simplicity database. The comparative results showed that the proposed approach offers higher precision rate than many known methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [19.496366500854492, 10.770506858825684]}, {"key": "", "year": "", "title": "Houen2023a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Sparse Johnson-Lindenstrauss Transform using Fast Hashing\"\nauthors: Houen Jakob B\u00e6k Tejs, Thorup Mikkel\nconference: Arxiv\nyear: 2023\nbibkey: houen2023a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2305.03110\"}\ntags: ['ARXIV', 'FOCS']\n---\nThe \\emph{Sparse Johnson-Lindenstrauss Transform} of Kane and Nelson (SODA 2012) provides a linear dimensionality-reducing map $A \\in \\mathbb\\{R\\}^\\{m \\times u\\}$ in $\\ell_2$ that preserves distances up to distortion of $1 + \\varepsilon$ with probability $1 - \\delta$, where $m = O(\\varepsilon^\\{-2\\} \\log 1/\\delta)$ and each column of $A$ has $O(\\varepsilon m)$ non-zero entries. The previous analyses of the Sparse Johnson-Lindenstrauss Transform all assumed access to a $\\Omega(\\log 1/\\delta)$-wise independent hash function. The main contribution of this paper is a more general analysis of the Sparse Johnson-Lindenstrauss Transform with less assumptions on the hash function. We also show that the \\emph{Mixed Tabulation hash function} of Dahlgaard, Knudsen, Rotenberg, and Thorup (FOCS 2015) satisfies the conditions of our analysis, thus giving us the first analysis of a Sparse Johnson-Lindenstrauss Transform that works with a practical hash function.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-12.575225830078125, -21.833152770996094]}, {"key": "", "year": "", "title": "Hsia2018representation", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Representation Learning for Image-based Music Recommendation\"\nauthors: Hsia Chih-Chun, Lai Kwei-Herng, Chen Yian, Wang Chuan-Ju, Tsai Ming-Feng\nconference: Arxiv\nyear: 2018\nbibkey: hsia2018representation\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1808.09198\"}\ntags: ['ARXIV']\n---\nImage perception is one of the most direct ways to provide contextual information about a user concerning his/her surrounding environment; hence images are a suitable proxy for contextual recommendation. We propose a novel representation learning framework for image-based music recommendation that bridges the heterogeneity gap between music and image data; the proposed method is a key component for various contextual recommendation tasks. Preliminary experiments show that for an image-to-song retrieval task, the proposed method retrieves relevant or conceptually similar songs for input images.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [31.214006423950195, -2.719951868057251]}, {"key": "", "year": "", "title": "Hsieh2016fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast Binary Embedding via Circulant Downsampled Matrix -- A Data-Independent Approach\"\nauthors: Hsieh Sung-Hsien, Lu Chun-Shien, Pei Soo-Chang\nconference: Arxiv\nyear: 2016\nbibkey: hsieh2016fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1601.06342\"}\ntags: ['ARXIV', 'TIP']\n---\nBinary embedding of high-dimensional data aims to produce low-dimensional binary codes while preserving discriminative power. State-of-the-art methods often suffer from high computation and storage costs. We present a simple and fast embedding scheme by first downsampling N-dimensional data into M-dimensional data and then multiplying the data with an MxM circulant matrix. Our method requires O(N +M log M) computation and O(N) storage costs. We prove if data have sparsity, our scheme can achieve similarity-preserving well. Experiments further demonstrate that though our method is cost-effective and fast, it still achieves comparable performance in image applications.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [8.504289627075195, -2.8026623725891113]}, {"key": "", "year": "", "title": "Hu2012combined", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Combined Descriptors in Spatial Pyramid Domain for Image Classification\"\nauthors: Hu Junlin, Guo Ping\nconference: Arxiv\nyear: 2012\nbibkey: hu2012combined\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1210.0386\"}\ntags: ['ARXIV', 'Quantisation']\n---\nRecently spatial pyramid matching (SPM) with scale invariant feature transform (SIFT) descriptor has been successfully used in image classification. Unfortunately, the codebook generation and feature quantization procedures using SIFT feature have the high complexity both in time and space. To address this problem, in this paper, we propose an approach which combines local binary patterns (LBP) and three-patch local binary patterns (TPLBP) in spatial pyramid domain. The proposed method does not need to learn the codebook and feature quantization processing, hence it becomes very efficient. Experiments on two popular benchmark datasets demonstrate that the proposed method always significantly outperforms the very popular SPM based SIFT descriptor method both in time and classification accuracy.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [13.989348411560059, 2.6755101680755615]}, {"key": "", "year": "", "title": "Hu2017supervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Supervised Hashing based on Energy Minimization\"\nauthors: Hu Zihao, Luo Xiyi, Lu Hongtao, Yu Yong\nconference: Arxiv\nyear: 2017\nbibkey: hu2017supervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1712.00573\"}\ntags: ['ARXIV', 'Supervised', 'Unsupervised']\n---\nRecently, supervised hashing methods have attracted much attention since they can optimize retrieval speed and storage cost while preserving semantic information. Because hashing codes learning is NP-hard, many methods resort to some form of relaxation technique. But the performance of these methods can easily deteriorate due to the relaxation. Luckily, many supervised hashing formulations can be viewed as energy functions, hence solving hashing codes is equivalent to learning marginals in the corresponding conditional random field (CRF). By minimizing the KL divergence between a fully factorized distribution and the Gibbs distribution of this CRF, a set of consistency equations can be obtained, but updating them in parallel may not yield a local optimum since the variational lower bound is not guaranteed to increase. In this paper, we use a linear approximation of the sigmoid function to convert these consistency equations to linear systems, which have a closed-form solution. By applying this novel technique to two classical hashing formulations KSH and SPLH, we obtain two new methods called EM (energy minimizing based)-KSH and EM-SPLH. Experimental results on three datasets show the superiority of our methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-12.338967323303223, -3.9959983825683594]}, {"key": "", "year": "", "title": "Hu2017twitter100k", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Twitter100k: A Real-world Dataset for Weakly Supervised Cross-Media Retrieval\"\nauthors: Hu Yuting, Zheng Liang, Yang Yi, Huang Yongfeng\nconference: Arxiv\nyear: 2017\nbibkey: hu2017twitter100k\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1703.06618\"}\ntags: ['ARXIV', 'GAN', 'Supervised', 'Weakly Supervised']\n---\nThis paper contributes a new large-scale dataset for weakly supervised cross-media retrieval, named Twitter100k. Current datasets, such as Wikipedia, NUS Wide and Flickr30k, have two major limitations. First, these datasets are lacking in content diversity, i.e., only some pre-defined classes are covered. Second, texts in these datasets are written in well-organized language, leading to inconsistency with realistic applications. To overcome these drawbacks, the proposed Twitter100k dataset is characterized by two aspects: 1) it has 100,000 image-text pairs randomly crawled from Twitter and thus has no constraint in the image categories; 2) text in Twitter100k is written in informal language by the users. Since strongly supervised methods leverage the class labels that may be missing in practice, this paper focuses on weakly supervised learning for cross-media retrieval, in which only text-image pairs are exploited during training. We extensively benchmark the performance of four subspace learning methods and three variants of the Correspondence AutoEncoder, along with various text features on Wikipedia, Flickr30k and Twitter100k. Novel insights are provided. As a minor contribution, inspired by the characteristic of Twitter100k, we propose an OCR-based cross-media retrieval method. In experiment, we show that the proposed OCR-based method improves the baseline performance.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-14.78237533569336, 18.380456924438477]}, {"key": "", "year": "", "title": "Hu2018deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep LDA Hashing\"\nauthors: Hu Di, Nie Feiping, Li Xuelong\nconference: Arxiv\nyear: 2018\nbibkey: hu2018deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1810.03402\"}\ntags: ['ARXIV', 'Supervised']\n---\nThe conventional supervised hashing methods based on classification do not entirely meet the requirements of hashing technique, but Linear Discriminant Analysis (LDA) does. In this paper, we propose to perform a revised LDA objective over deep networks to learn efficient hashing codes in a truly end-to-end fashion. However, the complicated eigenvalue decomposition within each mini-batch in every epoch has to be faced with when simply optimizing the deep network w.r.t. the LDA objective. In this work, the revised LDA objective is transformed into a simple least square problem, which naturally overcomes the intractable problems and can be easily solved by the off-the-shelf optimizer. Such deep extension can also overcome the weakness of LDA Hashing in the limited linear projection and feature learning. Amounts of experiments are conducted on three benchmark datasets. The proposed Deep LDA Hashing shows nearly 70 points improvement over the conventional one on the CIFAR-10 dataset. It also beats several state-of-the-art methods on various metrics.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-19.194734573364258, 2.6756410598754883]}, {"key": "", "year": "", "title": "Hu2018from", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"From Hashing to CNNs: Training BinaryWeight Networks via Hashing\"\nauthors: Hu Qinghao, Wang Peisong, Cheng Jian\nconference: Arxiv\nyear: 2018\nbibkey: hu2018from\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1802.02733\"}\ntags: ['ARXIV', 'CNN']\n---\nDeep convolutional neural networks (CNNs) have shown appealing performance on various computer vision tasks in recent years. This motivates people to deploy CNNs to realworld applications. However, most of state-of-art CNNs require large memory and computational resources, which hinders the deployment on mobile devices. Recent studies show that low-bit weight representation can reduce much storage and memory demand, and also can achieve efficient network inference. To achieve this goal, we propose a novel approach named BWNH to train Binary Weight Networks via Hashing. In this paper, we first reveal the strong connection between inner-product preserving hashing and binary weight networks, and show that training binary weight networks can be intrinsically regarded as a hashing problem. Based on this perspective, we propose an alternating optimization method to learn the hash codes instead of directly learning binary weights. Extensive experiments on CIFAR10, CIFAR100 and ImageNet demonstrate that our proposed BWNH outperforms current state-of-art by a large margin.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [9.826550483703613, 29.794435501098633]}, {"key": "", "year": "", "title": "Hu2020creating", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Creating Something from Nothing: Unsupervised Knowledge Distillation for Cross-Modal Hashing\"\nauthors: Hu Hengtong, Xie Lingxi, Hong Richang, Tian Qi\nconference: Arxiv\nyear: 2020\nbibkey: hu2020creating\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2004.00280\"}\ntags: ['ARXIV', 'Cross Modal', 'Supervised', 'Unsupervised']\n---\nIn recent years, cross-modal hashing (CMH) has attracted increasing attentions, mainly because its potential ability of mapping contents from different modalities, especially in vision and language, into the same space, so that it becomes efficient in cross-modal data retrieval. There are two main frameworks for CMH, differing from each other in whether semantic supervision is required. Compared to the unsupervised methods, the supervised methods often enjoy more accurate results, but require much heavier labors in data annotation. In this paper, we propose a novel approach that enables guiding a supervised method using outputs produced by an unsupervised method. Specifically, we make use of teacher-student optimization for propagating knowledge. Experiments are performed on two popular CMH benchmarks, i.e., the MIRFlickr and NUS-WIDE datasets. Our approach outperforms all existing unsupervised methods by a large margin.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-16.212390899658203, 9.061511993408203]}, {"key": "", "year": "", "title": "Hu2020efficient", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Efficient Approximate Nearest Neighbor Search for Multiple Weighted $l_{p\\leq2}$ Distance Functions\"\nauthors: Hu Huan, Li Jianzhong\nconference: Arxiv\nyear: 2020\nbibkey: hu2020efficient\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2011.11907\"}\ntags: ['ARXIV', 'LSH', 'TIP']\n---\nNearest neighbor search is fundamental to a wide range of applications. Since the exact nearest neighbor search suffers from the \"curse of dimensionality\", approximate approaches, such as Locality-Sensitive Hashing (LSH), are widely used to trade a little query accuracy for a much higher query efficiency. In many scenarios, it is necessary to perform nearest neighbor search under multiple weighted distance functions in high-dimensional spaces. This paper considers the important problem of supporting efficient approximate nearest neighbor search for multiple weighted distance functions in high-dimensional spaces. To the best of our knowledge, prior work can only solve the problem for the $l_2$ distance. However, numerous studies have shown that the $l_p$ distance with $p\\in(0,2)$ could be more effective than the $l_2$ distance in high-dimensional spaces. We propose a novel method, WLSH, to address the problem for the $l_p$ distance for $p\\in(0,2]$. WLSH takes the LSH approach and can theoretically guarantee both the efficiency of processing queries and the accuracy of query results while minimizing the required total number of hash tables. We conduct extensive experiments on synthetic and real data sets, and the results show that WLSH achieves high performance in terms of query efficiency, query accuracy and space consumption.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-6.402889728546143, -21.235422134399414]}, {"key": "", "year": "", "title": "Hu2021towards", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Towards Unsupervised Sketch-based Image Retrieval\"\nauthors: Hu Conghui, Yang Yongxin, Li Yunpeng, Hospedales Timothy M., Song Yi-Zhe\nconference: Arxiv\nyear: 2021\nbibkey: hu2021towards\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2105.08237\"}\ntags: ['ARXIV', 'Image Retrieval', 'Supervised', 'Unsupervised']\n---\nThe practical value of existing supervised sketch-based image retrieval (SBIR) algorithms is largely limited by the requirement for intensive data collection and labeling. In this paper, we present the first attempt at unsupervised SBIR to remove the labeling cost (both category annotations and sketch-photo pairings) that is conventionally needed for training. Existing single-domain unsupervised representation learning methods perform poorly in this application, due to the unique cross-domain (sketch and photo) nature of the problem. We therefore introduce a novel framework that simultaneously performs sketch-photo domain alignment and semantic-aware representation learning. Technically this is underpinned by introducing joint distribution optimal transport (JDOT) to align data from different domains, which we extend with trainable cluster prototypes and feature memory banks to further improve scalability and efficacy. Extensive experiments show that our framework achieves excellent performance in the new unsupervised setting, and performs comparably or better than state-of-the-art in the zero-shot setting.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [5.464369773864746, 18.541889190673828]}, {"key": "", "year": "", "title": "Hu2022badhash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"BadHash: Invisible Backdoor Attacks against Deep Hashing with Clean Label\"\nauthors: Hu Shengshan, Zhou Ziqi, Zhang Yechao, Zhang Leo Yu, Zheng Yifeng, HE Yuanyuan, Jin Hai\nconference: Arxiv\nyear: 2022\nbibkey: hu2022badhash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2207.00278\"}\ntags: ['ARXIV', 'GAN', 'Image Retrieval', 'TIP']\n---\nDue to its powerful feature learning capability and high efficiency, deep hashing has achieved great success in large-scale image retrieval. Meanwhile, extensive works have demonstrated that deep neural networks (DNNs) are susceptible to adversarial examples, and exploring adversarial attack against deep hashing has attracted many research efforts. Nevertheless, backdoor attack, another famous threat to DNNs, has not been studied for deep hashing yet. Although various backdoor attacks have been proposed in the field of image classification, existing approaches failed to realize a truly imperceptive backdoor attack that enjoys invisible triggers and clean label setting simultaneously, and they also cannot meet the intrinsic demand of image retrieval backdoor. In this paper, we propose BadHash, the first generative-based imperceptible backdoor attack against deep hashing, which can effectively generate invisible and input-specific poisoned images with clean label. Specifically, we first propose a new conditional generative adversarial network (cGAN) pipeline to effectively generate poisoned samples. For any given benign image, it seeks to generate a natural-looking poisoned counterpart with a unique invisible trigger. In order to improve the attack effectiveness, we introduce a label-based contrastive learning network LabCLN to exploit the semantic characteristics of different labels, which are subsequently used for confusing and misleading the target model to learn the embedded trigger. We finally explore the mechanism of backdoor attacks on image retrieval in the hash space. Extensive experiments on multiple benchmark datasets verify that BadHash can generate imperceptible poisoned samples with strong attack ability and transferability over state-of-the-art deep hashing schemes.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-8.532212257385254, 12.287221908569336]}, {"key": "", "year": "", "title": "Hu2022feature", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Feature Representation Learning for Unsupervised Cross-domain Image Retrieval\"\nauthors: Hu Conghui, Lee Gim Hee\nconference: Arxiv\nyear: 2022\nbibkey: hu2022feature\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2207.09721\"}   - {name: \"Code\", url: \"https://github.com/conghuihu/UCDIR.\"}\ntags: ['ARXIV', 'Image Retrieval', 'Supervised', 'Unsupervised']\n---\nCurrent supervised cross-domain image retrieval methods can achieve excellent performance. However, the cost of data collection and labeling imposes an intractable barrier to practical deployment in real applications. In this paper, we investigate the unsupervised cross-domain image retrieval task, where class labels and pairing annotations are no longer a prerequisite for training. This is an extremely challenging task because there is no supervision for both in-domain feature representation learning and cross-domain alignment. We address both challenges by introducing: 1) a new cluster-wise contrastive learning mechanism to help extract class semantic-aware features, and 2) a novel distance-of-distance loss to effectively measure and minimize the domain discrepancy without any external supervision. Experiments on the Office-Home and DomainNet datasets consistently show the superior image retrieval accuracies of our framework over state-of-the-art approaches. Our source code can be found at https://github.com/conghuihu/UCDIR.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [5.554551601409912, 17.662033081054688]}, {"key": "", "year": "", "title": "Huang2015hash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hash Function Learning via Codewords\"\nauthors: Huang Yinjie, Georgiopoulos Michael, Anagnostopoulos Georgios C.\nconference: Arxiv\nyear: 2015\nbibkey: huang2015hash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1508.03285\"}\ntags: ['ARXIV', 'Image Retrieval', 'Semi Supervised', 'Supervised', 'Unsupervised']\n---\nIn this paper we introduce a novel hash learning framework that has two main distinguishing features, when compared to past approaches. First, it utilizes codewords in the Hamming space as ancillary means to accomplish its hash learning task. These codewords, which are inferred from the data, attempt to capture similarity aspects of the data's hash codes. Secondly and more importantly, the same framework is capable of addressing supervised, unsupervised and, even, semi-supervised hash learning tasks in a natural manner. A series of comparative experiments focused on content-based image retrieval highlights its performance advantages.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-14.711795806884766, 12.424951553344727]}, {"key": "", "year": "", "title": "Huang2016local", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Local Similarity-Aware Deep Feature Embedding\"\nauthors: Huang Chen, Loy Chen Change, Tang Xiaoou\nconference: Arxiv\nyear: 2016\nbibkey: huang2016local\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1610.08904\"}\ntags: ['ACL', 'ARXIV', 'Image Retrieval']\n---\nExisting deep embedding methods in vision tasks are capable of learning a compact Euclidean space from images, where Euclidean distances correspond to a similarity metric. To make learning more effective and efficient, hard sample mining is usually employed, with samples identified through computing the Euclidean feature distance. However, the global Euclidean distance cannot faithfully characterize the true feature similarity in a complex visual feature space, where the intraclass distance in a high-density region may be larger than the interclass distance in low-density regions. In this paper, we introduce a Position-Dependent Deep Metric (PDDM) unit, which is capable of learning a similarity metric adaptive to local feature structure. The metric can be used to select genuinely hard samples in a local neighborhood to guide the deep embedding learning in an online and robust manner. The new layer is appealing in that it is pluggable to any convolutional networks and is trained end-to-end. Our local similarity-aware feature embedding not only demonstrates faster convergence and boosted performance on two complex image retrieval datasets, its large margin nature also leads to superior generalization results under the large and open set scenarios of transfer learning and zero-shot learning on ImageNet 2010 and ImageNet-10K datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.953651428222656, 7.85537052154541]}, {"key": "", "year": "", "title": "Huang2017online", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Online Hashing\"\nauthors: Huang Long-Kai, Yang Qiang, Zheng Wei-Shi\nconference: Arxiv\nyear: 2017\nbibkey: huang2017online\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1704.01897\"}\ntags: ['ARXIV', 'TIP']\n---\nAlthough hash function learning algorithms have achieved great success in recent years, most existing hash models are off-line, which are not suitable for processing sequential or online data. To address this problem, this work proposes an online hash model to accommodate data coming in stream for online learning. Specifically, a new loss function is proposed to measure the similarity loss between a pair of data samples in hamming space. Then, a structured hash model is derived and optimized in a passive-aggressive way. Theoretical analysis on the upper bound of the cumulative loss for the proposed online hash model is provided. Furthermore, we extend our online hashing from a single-model to a multi-model online hashing that trains multiple models so as to retain diverse online hashing models in order to avoid biased update. The competitive efficiency and effectiveness of the proposed online hash models are verified through extensive experiments on several large-scale datasets as compared to related hashing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-19.631343841552734, -0.2791537344455719]}, {"key": "", "year": "", "title": "Huang2017unsupervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Unsupervised Triplet Hashing for Fast Image Retrieval\"\nauthors: Huang Shanshan, Xiong Yichao, Zhang Ya, Wang Jia\nconference: Arxiv\nyear: 2017\nbibkey: huang2017unsupervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1702.08798\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval', 'Quantisation', 'Supervised', 'Unsupervised']\n---\nHashing has played a pivotal role in large-scale image retrieval. With the development of Convolutional Neural Network (CNN), hashing learning has shown great promise. But existing methods are mostly tuned for classification, which are not optimized for retrieval tasks, especially for instance-level retrieval. In this study, we propose a novel hashing method for large-scale image retrieval. Considering the difficulty in obtaining labeled datasets for image retrieval task in large scale, we propose a novel CNN-based unsupervised hashing method, namely Unsupervised Triplet Hashing (UTH). The unsupervised hashing network is designed under the following three principles: 1) more discriminative representations for image retrieval; 2) minimum quantization loss between the original real-valued feature descriptors and the learned hash codes; 3) maximum information entropy for the learned hash codes. Extensive experiments on CIFAR-10, MNIST and In-shop datasets have shown that UTH outperforms several state-of-the-art unsupervised hashing methods in terms of retrieval accuracy.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [4.908245086669922, 25.4916934967041]}, {"key": "", "year": "", "title": "Huang2019learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning Hash Function through Codewords\"\nauthors: Huang Yinjie, Georgiopoulos Michael, Anagnostopoulos Georgios C.\nconference: Arxiv\nyear: 2019\nbibkey: huang2019learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1902.08639\"}\ntags: ['ARXIV', 'Image Retrieval', 'Semi Supervised', 'Supervised', 'TOM', 'Unsupervised']\n---\nIn this paper, we propose a novel hash learning approach that has the following main distinguishing features, when compared to past frameworks. First, the codewords are utilized in the Hamming space as ancillary techniques to accomplish its hash learning task. These codewords, which are inferred from the data, attempt to capture grouping aspects of the data's hash codes. Furthermore, the proposed framework is capable of addressing supervised, unsupervised and, even, semi-supervised hash learning scenarios. Additionally, the framework adopts a regularization term over the codewords, which automatically chooses the codewords for the problem. To efficiently solve the problem, one Block Coordinate Descent algorithm is showcased in the paper. We also show that one step of the algorithms can be casted into several Support Vector Machine problems which enables our algorithms to utilize efficient software package. For the regularization term, a closed form solution of the proximal operator is provided in the paper. A series of comparative experiments focused on content-based image retrieval highlights its performance advantages.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-14.5203275680542, 12.31907844543457]}, {"key": "", "year": "", "title": "Hudson2023if", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"If At First You Don't Succeed: Test Time Re-ranking for Zero-shot, Cross-domain Retrieval\"\nauthors: Hudson Finlay G. C., Smith William A. P.\nconference: Arxiv\nyear: 2023\nbibkey: hudson2023if\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2303.17703\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nIn this paper we propose a novel method for zero-shot, cross-domain image retrieval in which we make two key contributions. The first is a test-time re-ranking procedure that enables query-gallery pairs, without meaningful shared visual features, to be matched by incorporating gallery-gallery ranks into an iterative re-ranking process. The second is the use of cross-attention at training time and knowledge distillation to encourage cross-attention-like features to be extracted at test time from a single image. When combined with the Vision Transformer architecture and zero-shot retrieval losses, our approach yields state-of-the-art results on the Sketchy and TU-Berlin sketch-based image retrieval benchmarks. However, unlike many previous methods, none of the components in our approach are engineered specifically towards the sketch-based image retrieval task - it can be generally applied to any cross-domain, zero-shot retrieval task. We therefore also show results on zero-shot cartoon-to-photo retrieval using the Office-Home dataset.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [5.358205795288086, 19.587642669677734]}, {"key": "", "year": "", "title": "Hussain2014pinview", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"PinView: Implicit Feedback in Content-Based Image Retrieval\"\nauthors: Hussain Zakria, Klami Arto, Kujala Jussi, Leung Alex P., Pasupa Kitsuchart, Auer Peter, Kaski Samuel, Laaksonen Jorma, Shawe-Taylor John\nconference: Arxiv\nyear: 2014\nbibkey: hussain2014pinview\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1410.0471\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nThis paper describes PinView, a content-based image retrieval system that exploits implicit relevance feedback collected during a search session. PinView contains several novel methods to infer the intent of the user. From relevance feedback, such as eye movements or pointer clicks, and visual features of images, PinView learns a similarity metric between images which depends on the current interests of the user. It then retrieves images with a specialized online learning algorithm that balances the tradeoff between exploring new images and exploiting the already inferred interests of the user. We have integrated PinView to the content-based image retrieval system PicSOM, which enables applying PinView to real-world image databases. With the new algorithms PinView outperforms the original PicSOM, and in online experiments with real users the combination of implicit and explicit feedback gives the best results.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [25.8498477935791, 11.83725357055664]}, {"key": "", "year": "", "title": "Hyv\u00f6nen2015fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast k-NN search\"\nauthors: Hyv\u00f6nen Ville, Pitk\u00e4nen Teemu, Tasoulis Sotiris, J\u00e4\u00e4saari Elias, Tuomainen Risto, Wang Liang, Corander Jukka, Roos Teemu\nconference: IEEE International Conference on Big Data\nyear: 2015\nbibkey: hyv\u00f6nen2015fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1509.06957\"}\ntags: ['TIP']\n---\nEfficient index structures for fast approximate nearest neighbor queries are required in many applications such as recommendation systems. In high-dimensional spaces, many conventional methods suffer from excessive usage of memory and slow response times. We propose a method where multiple random projection trees are combined by a novel voting scheme. The key idea is to exploit the redundancy in a large number of candidate sets obtained by independently generated random projections in order to reduce the number of expensive exact distance evaluations. The method is straightforward to implement using sparse projections which leads to a reduced memory footprint and fast index construction. Furthermore, it enables grouping of the required computations into big matrix multiplications, which leads to additional savings due to cache effects and low-level parallelization. We demonstrate by extensive experiments on a wide variety of data sets that the method is faster than existing partitioning tree or hashing based approaches, making it the fastest available technique on high accuracy levels.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-1.9666324853897095, -14.283477783203125]}, {"key": "", "year": "", "title": "Iida2020a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Privacy-Preserving Content-Based Image Retrieval Scheme Allowing Mixed Use Of Encrypted And Plain Images\"\nauthors: Iida Kenta, Kiya Hitoshi\nconference: Arxiv\nyear: 2020\nbibkey: iida2020a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2011.00270\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nIn this paper, we propose a novel content based-image retrieval scheme allowing the mixed use of encrypted and plain images for the first time. In the proposed scheme, images are encrypted by a block-scrambling method developed for encryption-then-compression (EtC) systems. The encrypted images, referred to as EtC images, can be compressed with JPEG, as well as for plain images. Image descriptors used for the proposed retrieval is designed to avoid the effect of image encryption. As a result, the use of EtC images and the descriptors allows us to carry out retrieval of both encrypted images and plain ones. In an experiment, the proposed scheme is demonstrated to have the same performance as conventional retrieval methods with plain images, even under the mixed use of plain images and EtC ones.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [18.035202026367188, 13.070018768310547]}, {"key": "", "year": "", "title": "Ileri2013shortest", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Shortest Unique Substring Query Revisited\"\nauthors: \u0130leri Atalay Mert, K\u00fclekci M. O\u011fuzhan, Xu Bojian\nconference: Arxiv\nyear: 2013\nbibkey: ileri2013shortest\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1312.2738\"}\ntags: ['ARXIV']\n---\nWe revisit the problem of finding shortest unique substring (SUS) proposed recently by [6]. We propose an optimal $O(n)$ time and space algorithm that can find an SUS for every location of a string of size $n$. Our algorithm significantly improves the $O(n^2)$ time complexity needed by [6]. We also support finding all the SUSes covering every location, whereas the solution in [6] can find only one SUS for every location. Further, our solution is simpler and easier to implement and can also be more space efficient in practice, since we only use the inverse suffix array and longest common prefix array of the string, while the algorithm in [6] uses the suffix tree of the string and other auxiliary data structures. Our theoretical results are validated by an empirical study that shows our algorithm is much faster and more space-saving than the one in [6].\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-4.535674095153809, -13.909406661987305]}, {"key": "", "year": "", "title": "Indyk2018approximate", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Approximate Nearest Neighbors in Limited Space\"\nauthors: Indyk Piotr, Wagner Tal\nconference: Arxiv\nyear: 2018\nbibkey: indyk2018approximate\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1807.00112\"}\ntags: ['ARXIV']\n---\nWe consider the $(1+\\epsilon)$-approximate nearest neighbor search problem: given a set $X$ of $n$ points in a $d$-dimensional space, build a data structure that, given any query point $y$, finds a point $x \\in X$ whose distance to $y$ is at most $(1+\\epsilon) \\min_\\{x \\in X\\} \\|x-y\\|$ for an accuracy parameter $\\epsilon \\in (0,1)$. Our main result is a data structure that occupies only $O(\\epsilon^\\{-2\\} n \\log(n) \\log(1/\\epsilon))$ bits of space, assuming all point coordinates are integers in the range $\\\\{-n^\\{O(1)\\} \\ldots n^\\{O(1)\\}\\\\}$, i.e., the coordinates have $O(\\log n)$ bits of precision. This improves over the best previously known space bound of $O(\\epsilon^\\{-2\\} n \\log(n)^2)$, obtained via the randomized dimensionality reduction method of Johnson and Lindenstrauss (1984). We also consider the more general problem of estimating all distances from a collection of query points to all data points $X$, and provide almost tight upper and lower bounds for the space complexity of this problem.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-10.457690238952637, -25.81875991821289]}, {"key": "", "year": "", "title": "Indyk2023worst", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Worst-case Performance of Popular Approximate Nearest Neighbor Search Implementations: Guarantees and Limitations\"\nauthors: Indyk Piotr, Xu Haike\nconference: Arxiv\nyear: 2023\nbibkey: indyk2023worst\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2310.19126\"}\ntags: ['ARXIV', 'Graph']\n---\nGraph-based approaches to nearest neighbor search are popular and powerful tools for handling large datasets in practice, but they have limited theoretical guarantees. We study the worst-case performance of recent graph-based approximate nearest neighbor search algorithms, such as HNSW, NSG and DiskANN. For DiskANN, we show that its \"slow preprocessing\" version provably supports approximate nearest neighbor search query with constant approximation ratio and poly-logarithmic query time, on data sets with bounded \"intrinsic\" dimension. For the other data structure variants studied, including DiskANN with \"fast preprocessing\", HNSW and NSG, we present a family of instances on which the empirical query time required to achieve a \"reasonable\" accuracy is linear in instance size. For example, for DiskANN, we show that the query procedure can take at least $0.1 n$ steps on instances of size $n$ before it encounters any of the $5$ nearest neighbors of the query.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [8.274886131286621, -27.13798713684082]}, {"key": "", "year": "", "title": "Iscen2014memory", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Memory vectors for similarity search in high-dimensional spaces\"\nauthors: Iscen Ahmet, Furon Teddy, Gripon Vincent, Rabbat Michael, J\u00e9gou Herv\u00e9\nconference: Arxiv\nyear: 2014\nbibkey: iscen2014memory\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1412.3328\"}\ntags: ['ARXIV']\n---\nWe study an indexing architecture to store and search in a database of high-dimensional vectors from the perspective of statistical signal processing and decision theory. This architecture is composed of several memory units, each of which summarizes a fraction of the database by a single representative vector. The potential similarity of the query to one of the vectors stored in the memory unit is gauged by a simple correlation with the memory unit's representative vector. This representative optimizes the test of the following hypothesis: the query is independent from any vector in the memory unit vs. the query is a simple perturbation of one of the stored vectors. Compared to exhaustive search, our approach finds the most similar database vectors significantly faster without a noticeable reduction in search quality. Interestingly, the reduction of complexity is provably better in high-dimensional spaces. We empirically demonstrate its practical interest in a large-scale image search scenario with off-the-shelf state-of-the-art descriptors.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [8.745256423950195, -9.145609855651855]}, {"key": "", "year": "", "title": "Iscen2017fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast Spectral Ranking for Similarity Search\"\nauthors: Iscen Ahmet, Avrithis Yannis, Tolias Giorgos, Furon Teddy, Chum Ondrej\nconference: Arxiv\nyear: 2017\nbibkey: iscen2017fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1703.06935\"}\ntags: ['ARXIV', 'Deep Learning', 'Graph']\n---\nDespite the success of deep learning on representing images for particular object retrieval, recent studies show that the learned representations still lie on manifolds in a high dimensional space. This makes the Euclidean nearest neighbor search biased for this task. Exploring the manifolds online remains expensive even if a nearest neighbor graph has been computed offline. This work introduces an explicit embedding reducing manifold search to Euclidean search followed by dot product similarity search. This is equivalent to linear graph filtering of a sparse signal in the frequency domain. To speed up online search, we compute an approximate Fourier basis of the graph offline. We improve the state of art on particular object retrieval datasets including the challenging Instre dataset containing small objects. At a scale of 10^5 images, the offline cost is only a few hours, while query time is comparable to standard similarity search.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [7.305793762207031, -27.514116287231445]}, {"key": "", "year": "", "title": "Ishikawa2015pairwise", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Pairwise Rotation Hashing for High-dimensional Features\"\nauthors: Ishikawa Kohta, Sato Ikuro, Ambai Mitsuru\nconference: Arxiv\nyear: 2015\nbibkey: ishikawa2015pairwise\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1501.07422\"}\ntags: ['ARXIV', 'Quantisation']\n---\nBinary Hashing is widely used for effective approximate nearest neighbors search. Even though various binary hashing methods have been proposed, very few methods are feasible for extremely high-dimensional features often used in visual tasks today. We propose a novel highly sparse linear hashing method based on pairwise rotations. The encoding cost of the proposed algorithm is $\\mathrm\\{O\\}(n \\log n)$ for n-dimensional features, whereas that of the existing state-of-the-art method is typically $\\mathrm\\{O\\}(n^2)$. The proposed method is also remarkably faster in the learning phase. Along with the efficiency, the retrieval accuracy is comparable to or slightly outperforming the state-of-the-art. Pairwise rotations used in our method are formulated from an analytical study of the trade-off relationship between quantization error and entropy of binary codes. Although these hashing criteria are widely used in previous researches, its analytical behavior is rarely studied. All building blocks of our algorithm are based on the analytical solution, and it thus provides a fairly simple and efficient procedure.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-8.246967315673828, -15.233545303344727]}, {"key": "", "year": "", "title": "Islam2010a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Miniature-Based Image Retrieval System\"\nauthors: Islam Md. Saiful, Ali Md. Haider\nconference: Dhaka University Journal of Science,Vol.\nyear: 2010\nbibkey: islam2010a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1008.3346\"}\ntags: ['Graph', 'Image Retrieval']\n---\nDue to the rapid development of World Wide Web (WWW) and imaging technology, more and more images are available in the Internet and stored in databases. Searching the related images by the querying image is becoming tedious and difficult. Most of the images on the web are compressed by methods based on discrete cosine transform (DCT) including Joint Photographic Experts Group(JPEG) and H.261. This paper presents an efficient content-based image indexing technique for searching similar images using discrete cosine transform features. Experimental results demonstrate its superiority with the existing techniques.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [17.474536895751953, -25.017751693725586]}, {"key": "", "year": "", "title": "Ivanchykhin2016regular", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Regular and almost universal hashing: an efficient implementation\"\nauthors: Ivanchykhin Dmytro, Ignatchenko Sergey, Lemire Daniel\nconference: Software: Practice and Experience\nyear: 2016\nbibkey: ivanchykhin2016regular\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1609.09840\"}\ntags: ['Graph', 'Survey Paper']\n---\nRandom hashing can provide guarantees regarding the performance of data structures such as hash tables---even in an adversarial setting. Many existing families of hash functions are universal: given two data objects, the probability that they have the same hash value is low given that we pick hash functions at random. However, universality fails to ensure that all hash functions are well behaved. We further require regularity: when picking data objects at random they should have a low probability of having the same hash value, for any fixed hash function. We present the efficient implementation of a family of non-cryptographic hash functions (PM+) offering good running times, good memory usage as well as distinguishing theoretical guarantees: almost universality and component-wise regularity. On a variety of platforms, our implementations are comparable to the state of the art in performance. On recent Intel processors, PM+ achieves a speed of 4.7 bytes per cycle for 32-bit outputs and 3.3 bytes per cycle for 64-bit outputs. We review vectorization through SIMD instructions (e.g., AVX2) and optimizations for superscalar execution.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-22.113574981689453, -14.386303901672363]}, {"key": "", "year": "", "title": "Jacob2018leveraging", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Leveraging Implicit Spatial Information in Global Features for Image Retrieval\"\nauthors: Jacob Pierre, Picard David, Histace Aymeric, Klein Edouard\nconference: Arxiv\nyear: 2018\nbibkey: jacob2018leveraging\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1806.08991\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nMost image retrieval methods use global features that aggregate local distinctive patterns into a single representation. However, the aggregation process destroys the relative spatial information by considering orderless sets of local descriptors. We propose to integrate relative spatial information into the aggregation process by taking into account co-occurrences of local patterns in a tensor framework. The resulting signature called Improved Spatial Tensor Aggregation (ISTA) is able to reach state of the art performances on well known datasets such as Holidays, Oxford5k and Paris6k.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [19.869754791259766, 18.560649871826172]}, {"key": "", "year": "", "title": "Jafari2019efficient", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Efficient Bitmap-based Indexing and Retrieval of Similarity Search Image Queries\"\nauthors: Jafari Omid, Nagarkar Parth, Monta\u00f1o Jonathan\nconference: \nyear: 2019\nbibkey: jafari2019efficient\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1912.07101\"}\ntags: ['LSH']\n---\nFinding similar images is a necessary operation in many multimedia applications. Images are often represented and stored as a set of high-dimensional features, which are extracted using localized feature extraction algorithms. Locality Sensitive Hashing is one of the most popular approximate processing techniques for finding similar points in high-dimensional spaces. Locality Sensitive Hashing (LSH) and its variants are designed to find similar points, but they are not designed to find objects (such as images, which are made up of a collection of points) efficiently. In this paper, we propose an index structure, Bitmap-Image LSH (bImageLSH), for efficient processing of high-dimensional images. Using a real dataset, we experimentally show the performance benefit of our novel design while keeping the accuracy of the image results high.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [17.667247772216797, 5.630845069885254]}, {"key": "", "year": "", "title": "Jafari2022experimental", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Experimental Analysis of Machine Learning Techniques for Finding Search Radius in Locality Sensitive Hashing\"\nauthors: Jafari Omid, Nagarkar Parth\nconference: Arxiv\nyear: 2022\nbibkey: jafari2022experimental\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2211.09093\"}\ntags: ['ARXIV', 'LSH']\n---\nFinding similar data in high-dimensional spaces is one of the important tasks in multimedia applications. Approaches introduced to find exact searching techniques often use tree-based index structures which are known to suffer from the curse of the dimensionality problem that limits their performance. Approximate searching techniques prefer performance over accuracy and they return good enough results while achieving a better performance. Locality Sensitive Hashing (LSH) is one of the most popular approximate nearest neighbor search techniques for high-dimensional spaces. One of the most time-consuming processes in LSH is to find the neighboring points in the projected spaces. An improved LSH-based index structure, called radius-optimized Locality Sensitive Hashing (roLSH) has been proposed to utilize Machine Learning and efficiently find these neighboring points; thus, further improve the overall performance of LSH. In this paper, we extend roLSH by experimentally studying the effect of different types of famous Machine Learning techniques on overall performance. We compare ten regression techniques on four real-world datasets and show that Neural Network-based techniques are the best fit to be used in roLSH as their accuracy and performance trade-off are the best compared to the other techniques.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-0.4447758197784424, -28.311168670654297]}, {"key": "", "year": "", "title": "Jain2016approximate", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Approximate search with quantized sparse representations\"\nauthors: Jain Himalaya, P\u00e9rez Patrick, Gribonval R\u00e9mi, Zepeda Joaquin, J\u00e9gou Herv\u00e9\nconference: Arxiv\nyear: 2016\nbibkey: jain2016approximate\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1608.03308\"}\ntags: ['ARXIV', 'GAN', 'Quantisation', 'TOM']\n---\nThis paper tackles the task of storing a large collection of vectors, such as visual descriptors, and of searching in it. To this end, we propose to approximate database vectors by constrained sparse coding, where possible atom weights are restricted to belong to a finite subset. This formulation encompasses, as particular cases, previous state-of-the-art methods such as product or residual quantization. As opposed to traditional sparse coding methods, quantized sparse coding includes memory usage as a design constraint, thereby allowing us to index a large collection such as the BIGANN billion-sized benchmark. Our experiments, carried out on standard benchmarks, show that our formulation leads to competitive solutions when considering different trade-offs between learning/coding time, index size and search quality.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [9.760747909545898, -8.594476699829102]}, {"key": "", "year": "", "title": "Jain2017learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning a Complete Image Indexing Pipeline\"\nauthors: Jain Himalaya, Zepeda Joaquin, P\u00e9rez Patrick, Gribonval R\u00e9mi\nconference: Arxiv\nyear: 2017\nbibkey: jain2017learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1712.04480\"}\ntags: ['ARXIV', 'Deep Learning', 'Supervised', 'Unsupervised']\n---\nTo work at scale, a complete image indexing system comprises two components: An inverted file index to restrict the actual search to only a subset that should contain most of the items relevant to the query; An approximate distance computation mechanism to rapidly scan these lists. While supervised deep learning has recently enabled improvements to the latter, the former continues to be based on unsupervised clustering in the literature. In this work, we propose a first system that learns both components within a unifying neural framework of structured binary encoding.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.941038131713867, 19.51685905456543]}, {"key": "", "year": "", "title": "Jain2017subic", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"SUBIC: A supervised, structured binary code for image search\"\nauthors: Jain Himalaya, Zepeda Joaquin, P\u00e9rez Patrick, Gribonval R\u00e9mi\nconference: Arxiv\nyear: 2017\nbibkey: jain2017subic\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1708.02932\"}\ntags: ['ARXIV', 'Deep Learning', 'Quantisation', 'Supervised', 'Unsupervised']\n---\nFor large-scale visual search, highly compressed yet meaningful representations of images are essential. Structured vector quantizers based on product quantization and its variants are usually employed to achieve such compression while minimizing the loss of accuracy. Yet, unlike binary hashing schemes, these unsupervised methods have not yet benefited from the supervision, end-to-end learning and novel architectures ushered in by the deep learning revolution. We hence propose herein a novel method to make deep convolutional neural networks produce supervised, compact, structured binary codes for visual search. Our method makes use of a novel block-softmax non-linearity and of batch-based entropy losses that together induce structure in the learned encodings. We show that our method outperforms state-of-the-art compact representations based on deep hashing or structured quantization in single and cross-domain category retrieval, instance retrieval and classification. We make our code and models publicly available online.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [10.693196296691895, 17.962400436401367]}, {"key": "", "year": "", "title": "James2019deephashing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"DeepHashing using TripletLoss\"\nauthors: James Jithin\nconference: Arxiv\nyear: 2019\nbibkey: james2019deephashing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1912.10822\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nHashing is one of the most efficient techniques for approximate nearest neighbour search for large scale image retrieval. Most of the techniques are based on hand-engineered features and do not give optimal results all the time. Deep Convolutional Neural Networks have proven to generate very effective representation of images that are used for various computer vision tasks and inspired by this there have been several Deep Hashing models like Wang et al. (2016) have been proposed. These models train on the triplet loss function which can be used to train models with superior representation capabilities. Taking the latest advancements in training using the triplet loss I propose new techniques that help the Deep Hash-ing models train more faster and efficiently. Experiment result1show that using the more efficient techniques for training on the triplet loss, we have obtained a 5%percent improvement in our model compared to the original work of Wang et al.(2016). Using a larger model and more training data we can drastically improve the performance using the techniques we propose\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-4.300444602966309, 10.875572204589844]}, {"key": "", "year": "", "title": "Jang2020generalized", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Generalized Product Quantization Network for Semi-supervised Image Retrieval\"\nauthors: Jang Young Kyun, Cho Nam Ik\nconference: Arxiv\nyear: 2020\nbibkey: jang2020generalized\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2002.11281\"}\ntags: ['ARXIV', 'Deep Learning', 'Image Retrieval', 'Quantisation', 'Semi Supervised', 'Supervised']\n---\nImage retrieval methods that employ hashing or vector quantization have achieved great success by taking advantage of deep learning. However, these approaches do not meet expectations unless expensive label information is sufficient. To resolve this issue, we propose the first quantization-based semi-supervised image retrieval scheme: Generalized Product Quantization (GPQ) network. We design a novel metric learning strategy that preserves semantic similarity between labeled data, and employ entropy regularization term to fully exploit inherent potentials of unlabeled data. Our solution increases the generalization capacity of the quantization network, which allows overcoming previous limitations in the retrieval community. Extensive experimental results demonstrate that GPQ yields state-of-the-art performance on large-scale real image benchmark datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [9.048188209533691, 18.184432983398438]}, {"key": "", "year": "", "title": "Jang2021deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Hash Distillation for Image Retrieval\"\nauthors: Jang Young Kyun, Gu Geonmo, Ko Byungsoo, Kang Isaac, Cho Nam Ik\nconference: Arxiv\nyear: 2021\nbibkey: jang2021deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2112.08816\"}\ntags: ['ARXIV', 'Image Retrieval', 'Quantisation']\n---\nIn hash-based image retrieval systems, degraded or transformed inputs usually generate different codes from the original, deteriorating the retrieval accuracy. To mitigate this issue, data augmentation can be applied during training. However, even if augmented samples of an image are similar in real feature space, the quantization can scatter them far away in Hamming space. This results in representation discrepancies that can impede training and degrade performance. In this work, we propose a novel self-distilled hashing scheme to minimize the discrepancy while exploiting the potential of augmented data. By transferring the hash knowledge of the weakly-transformed samples to the strong ones, we make the hash code insensitive to various transformations. We also introduce hash proxy-based similarity learning and binary cross entropy-based quantization loss to provide fine quality hash codes. Ultimately, we construct a deep hashing framework that not only improves the existing deep hashing approaches, but also achieves the state-of-the-art retrieval results. Extensive experiments are conducted and confirm the effectiveness of our work.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-3.568110227584839, 12.138497352600098]}, {"key": "", "year": "", "title": "Jang2021self", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Self-supervised Product Quantization for Deep Unsupervised Image Retrieval\"\nauthors: Jang Young Kyun, Cho Nam Ik\nconference: Arxiv\nyear: 2021\nbibkey: jang2021self\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2109.02244\"}\ntags: ['ARXIV', 'Deep Learning', 'Image Retrieval', 'Quantisation', 'Self Supervised', 'Supervised', 'Unsupervised']\n---\nSupervised deep learning-based hash and vector quantization are enabling fast and large-scale image retrieval systems. By fully exploiting label annotations, they are achieving outstanding retrieval performances compared to the conventional methods. However, it is painstaking to assign labels precisely for a vast amount of training data, and also, the annotation process is error-prone. To tackle these issues, we propose the first deep unsupervised image retrieval method dubbed Self-supervised Product Quantization (SPQ) network, which is label-free and trained in a self-supervised manner. We design a Cross Quantized Contrastive learning strategy that jointly learns codewords and deep visual descriptors by comparing individually transformed images (views). Our method analyzes the image contents to extract descriptive features, allowing us to understand image representations for accurate retrieval. By conducting extensive experiments on benchmarks, we demonstrate that the proposed method yields state-of-the-art results even without supervised pretraining.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [3.9664390087127686, 17.065113067626953]}, {"key": "", "year": "", "title": "Jang2021similarity", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Similarity Guided Deep Face Image Retrieval\"\nauthors: Jang Young Kyun, Cho Nam Ik\nconference: Arxiv\nyear: 2021\nbibkey: jang2021similarity\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2107.05025\"}\ntags: ['ARXIV', 'Image Retrieval', 'Supervised']\n---\nFace image retrieval, which searches for images of the same identity from the query input face image, is drawing more attention as the size of the image database increases rapidly. In order to conduct fast and accurate retrieval, a compact hash code-based methods have been proposed, and recently, deep face image hashing methods with supervised classification training have shown outstanding performance. However, classification-based scheme has a disadvantage in that it cannot reveal complex similarities between face images into the hash code learning. In this paper, we attempt to improve the face image retrieval quality by proposing a Similarity Guided Hashing (SGH) method, which gently considers self and pairwise-similarity simultaneously. SGH employs various data augmentations designed to explore elaborate similarities between face images, solving both intra and inter identity-wise difficulties. Extensive experimental results on the protocols with existing benchmarks and an additionally proposed large scale higher resolution face image dataset demonstrate that our SGH delivers state-of-the-art retrieval performance.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [5.518404960632324, 9.193190574645996]}, {"key": "", "year": "", "title": "Jang2024distilling", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Distilling Vision-Language Pretraining for Efficient Cross-Modal Retrieval\"\nauthors: Jang Young Kyun, Kim Donghyun, Lim Ser-nam\nconference: Arxiv\nyear: 2024\nbibkey: jang2024distilling\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2405.14726\"}\ntags: ['ARXIV', 'Cross Modal', 'Quantisation', 'Supervised']\n---\n``Learning to hash'' is a practical solution for efficient retrieval, offering fast search speed and low storage cost. It is widely applied in various applications, such as image-text cross-modal search. In this paper, we explore the potential of enhancing the performance of learning to hash with the proliferation of powerful large pre-trained models, such as Vision-Language Pre-training (VLP) models. We introduce a novel method named Distillation for Cross-Modal Quantization (DCMQ), which leverages the rich semantic knowledge of VLP models to improve hash representation learning. Specifically, we use the VLP as a `teacher' to distill knowledge into a `student' hashing model equipped with codebooks. This process involves the replacement of supervised labels, which are composed of multi-hot vectors and lack semantics, with the rich semantics of VLP. In the end, we apply a transformation termed Normalization with Paired Consistency (NPC) to achieve a discriminative target for distillation. Further, we introduce a new quantization method, Product Quantization with Gumbel (PQG) that promotes balanced codebook learning, thereby improving the retrieval performance. Extensive benchmark testing demonstrates that DCMQ consistently outperforms existing supervised cross-modal hashing approaches, showcasing its significant potential.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-14.684603691101074, 8.346057891845703]}, {"key": "", "year": "", "title": "Janson2005individual", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Individual displacements in hashing with coalesced chains\"\nauthors: Janson Svante\nconference: Arxiv\nyear: 2005\nbibkey: janson2005individual\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/math/0502232\"}\ntags: ['ARXIV']\n---\nWe study the asymptotic distribution of the displacements in hashing with coalesced chains, for both late-insertion and early-insertion. Asymptotic formulas for means and variances follow. The method uses Poissonization and some stochastic calculus.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.242905616760254, -12.851335525512695]}, {"key": "", "year": "", "title": "Janson2014a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A unified approach to linear probing hashing with buckets\"\nauthors: Janson Svante, Viola Alfredo\nconference: Arxiv\nyear: 2014\nbibkey: janson2014a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1410.5967\"}\ntags: ['ARXIV']\n---\nWe give a unified analysis of linear probing hashing with a general bucket size. We use both a combinatorial approach, giving exact formulas for generating functions, and a probabilistic approach, giving simple derivations of asymptotic results. Both approaches complement nicely, and give a good insight in the relation between linear probing and random walks. A key methodological contribution, at the core of Analytic Combinatorics, is the use of the symbolic method (based on q-calculus) to directly derive the generating functions to analyze.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.245441436767578, -11.960531234741211]}, {"key": "", "year": "", "title": "Jayaram2024data", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Data-Dependent LSH for the Earth Mover's Distance\"\nauthors: Jayaram Rajesh, Waingarten Erik, Zhang Tian\nconference: Arxiv\nyear: 2024\nbibkey: jayaram2024data\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2403.05041\"}\ntags: ['ARXIV', 'LSH']\n---\nWe give new data-dependent locality sensitive hashing schemes (LSH) for the Earth Mover's Distance ($\\mathsf\\{EMD\\}$), and as a result, improve the best approximation for nearest neighbor search under $\\mathsf\\{EMD\\}$ by a quadratic factor. Here, the metric $\\mathsf\\{EMD\\}_s(\\mathbb\\{R\\}^d,\\ell_p)$ consists of sets of $s$ vectors in $\\mathbb\\{R\\}^d$, and for any two sets $x,y$ of $s$ vectors the distance $\\mathsf\\{EMD\\}(x,y)$ is the minimum cost of a perfect matching between $x,y$, where the cost of matching two vectors is their $\\ell_p$ distance. Previously, Andoni, Indyk, and Krauthgamer gave a (data-independent) locality-sensitive hashing scheme for $\\mathsf\\{EMD\\}_s(\\mathbb\\{R\\}^d,\\ell_p)$ when $p \\in [1,2]$ with approximation $O(\\log^2 s)$. By being data-dependent, we improve the approximation to $\\tilde\\{O\\}(\\log s)$. Our main technical contribution is to show that for any distribution $\\mu$ supported on the metric $\\mathsf\\{EMD\\}_s(\\mathbb\\{R\\}^d, \\ell_p)$, there exists a data-dependent LSH for dense regions of $\\mu$ which achieves approximation $\\tilde\\{O\\}(\\log s)$, and that the data-independent LSH actually achieves a $\\tilde\\{O\\}(\\log s)$-approximation outside of those dense regions. Finally, we show how to \"glue\" together these two hashing schemes without any additional loss in the approximation. Beyond nearest neighbor search, our data-dependent LSH also gives optimal (distributional) sketches for the Earth Mover's Distance. By known sketching lower bounds, this implies that our LSH is optimal (up to $\\mathrm\\{poly\\}(\\log \\log s)$ factors) among those that collide close points with constant probability.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-11.14263916015625, -26.64961814880371]}, {"key": "", "year": "", "title": "Jenicek2019linking", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Linking Art through Human Poses\"\nauthors: Jenicek Tomas, Chum Ond\u0159ej\nconference: Arxiv\nyear: 2019\nbibkey: jenicek2019linking\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1907.03537\"}\ntags: ['ARXIV', 'Image Retrieval', 'TOM']\n---\nWe address the discovery of composition transfer in artworks based on their visual content. Automated analysis of large art collections, which are growing as a result of art digitization among museums and galleries, is an important tool for art history and assists cultural heritage preservation. Modern image retrieval systems offer good performance on visually similar artworks, but fail in the cases of more abstract composition transfer. The proposed approach links artworks through a pose similarity of human figures depicted in images. Human figures are the subject of a large fraction of visual art from middle ages to modernity and their distinctive poses were often a source of inspiration among artists. The method consists of two steps -- fast pose matching and robust spatial verification. We experimentally show that explicit human pose matching is superior to standard content-based image retrieval methods on a manually annotated art composition transfer dataset.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [26.519256591796875, -5.354398250579834]}, {"key": "", "year": "", "title": "Jeong2018efficient", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Efficient end-to-end learning for quantizable representations\"\nauthors: Jeong Yeonwoo, Song Hyun Oh\nconference: Arxiv\nyear: 2018\nbibkey: jeong2018efficient\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1805.05809\"}   - {name: \"Code\", url: \"https://github.com/maestrojeong/Deep-Hash-Table-ICML18\"}\ntags: ['ARXIV']\n---\nEmbedding representation learning via neural networks is at the core foundation of modern similarity based search. While much effort has been put in developing algorithms for learning binary hamming code representations for search efficiency, this still requires a linear scan of the entire dataset per each query and trades off the search accuracy through binarization. To this end, we consider the problem of directly learning a quantizable embedding representation and the sparse binary hash code end-to-end which can be used to construct an efficient hash table not only providing significant search reduction in the number of data but also achieving the state of the art search accuracy outperforming previous state of the art deep metric learning methods. We also show that finding the optimal sparse binary hash code in a mini-batch can be computed exactly in polynomial time by solving a minimum cost flow problem. Our results on Cifar-100 and on ImageNet datasets show the state of the art search accuracy in precision@k and NMI metrics while providing up to 98X and 478X search speedup respectively over exhaustive linear search. The source code is available at https://github.com/maestrojeong/Deep-Hash-Table-ICML18\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-18.45717430114746, 6.472238540649414]}, {"key": "", "year": "", "title": "Jeong2019end", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"End-to-End Efficient Representation Learning via Cascading Combinatorial Optimization\"\nauthors: Jeong Yeonwoo, Kim Yoonsung, Song Hyun Oh\nconference: Arxiv\nyear: 2019\nbibkey: jeong2019end\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1902.10990\"}\ntags: ['ARXIV', 'Quantisation']\n---\nWe develop hierarchically quantized efficient embedding representations for similarity-based search and show that this representation provides not only the state of the art performance on the search accuracy but also provides several orders of speed up during inference. The idea is to hierarchically quantize the representation so that the quantization granularity is greatly increased while maintaining the accuracy and keeping the computational complexity low. We also show that the problem of finding the optimal sparse compound hash code respecting the hierarchical structure can be optimized in polynomial time via minimum cost flow in an equivalent flow network. This allows us to train the method end-to-end in a mini-batch stochastic gradient descent setting. Our experiments on Cifar100 and ImageNet datasets show the state of the art search accuracy while providing several orders of magnitude search speedup respectively over exhaustive linear search over the dataset.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [6.8723344802856445, -6.3399739265441895]}, {"key": "", "year": "", "title": "Jhuo2017set", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Set-to-Set Hashing with Applications in Visual Recognition\"\nauthors: Jhuo I-Hong, Wang Jun\nconference: Arxiv\nyear: 2017\nbibkey: jhuo2017set\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1711.00888\"}\ntags: ['ARXIV', 'TIP']\n---\nVisual data, such as an image or a sequence of video frames, is often naturally represented as a point set. In this paper, we consider the fundamental problem of finding a nearest set from a collection of sets, to a query set. This problem has obvious applications in large-scale visual retrieval and recognition, and also in applied fields beyond computer vision. One challenge stands out in solving the problem---set representation and measure of similarity. Particularly, the query set and the sets in dataset collection can have varying cardinalities. The training collection is large enough such that linear scan is impractical. We propose a simple representation scheme that encodes both statistical and structural information of the sets. The derived representations are integrated in a kernel framework for flexible similarity measurement. For the query set process, we adopt a learning-to-hash pipeline that turns the kernel representations into hash bits based on simple learners, using multiple kernel learning. Experiments on two visual retrieval datasets show unambiguously that our set-to-set hashing framework outperforms prior methods that do not take the set-to-set search setting.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-3.6443560123443604, 17.89592170715332]}, {"key": "", "year": "", "title": "Ji2011image", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Image Retrieval Method Using Top-surf Descriptor\"\nauthors: Ji Ye\nconference: Arxiv\nyear: 2011\nbibkey: ji2011image\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1104.0579\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nThis report presents the results and details of a content-based image retrieval project using the Top-surf descriptor. The experimental results are preliminary, however, it shows the capability of deducing objects from parts of the objects or from the objects that are similar. This paper uses a dataset consisting of 1200 images of which 800 images are equally divided into 8 categories, namely airplane, beach, motorbike, forest, elephants, horses, bus and building, while the other 400 images are randomly picked from the Internet. The best results achieved are from building category.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [27.580913543701172, 14.36644458770752]}, {"key": "", "year": "", "title": "Ji2018attribute", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Attribute-Guided Network for Cross-Modal Zero-Shot Hashing\"\nauthors: Ji Zhong, Sun Yuxin, Yu Yunlong, Pang Yanwei, Han Jungong\nconference: Arxiv\nyear: 2018\nbibkey: ji2018attribute\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1802.01943\"}\ntags: ['ARXIV', 'Cross Modal', 'Image Retrieval']\n---\nZero-Shot Hashing aims at learning a hashing model that is trained only by instances from seen categories but can generate well to those of unseen categories. Typically, it is achieved by utilizing a semantic embedding space to transfer knowledge from seen domain to unseen domain. Existing efforts mainly focus on single-modal retrieval task, especially Image-Based Image Retrieval (IBIR). However, as a highlighted research topic in the field of hashing, cross-modal retrieval is more common in real world applications. To address the Cross-Modal Zero-Shot Hashing (CMZSH) retrieval task, we propose a novel Attribute-Guided Network (AgNet), which can perform not only IBIR, but also Text-Based Image Retrieval (TBIR). In particular, AgNet aligns different modal data into a semantically rich attribute space, which bridges the gap caused by modality heterogeneity and zero-shot setting. We also design an effective strategy that exploits the attribute to guide the generation of hash codes for image and text within the same network. Extensive experimental results on three benchmark datasets (AwA, SUN, and ImageNet) demonstrate the superiority of AgNet on both cross-modal and single-modal zero-shot image retrieval tasks.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-3.258466958999634, 7.210268020629883]}, {"key": "", "year": "", "title": "Jia2022fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast Online Hashing with Multi-Label Projection\"\nauthors: Jia Wenzhe, Cao Yuan, Liu Junwei, Gui Jie\nconference: Arxiv\nyear: 2022\nbibkey: jia2022fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2212.03112\"}\ntags: ['ARXIV']\n---\nHashing has been widely researched to solve the large-scale approximate nearest neighbor search problem owing to its time and storage superiority. In recent years, a number of online hashing methods have emerged, which can update the hash functions to adapt to the new stream data and realize dynamic retrieval. However, existing online hashing methods are required to update the whole database with the latest hash functions when a query arrives, which leads to low retrieval efficiency with the continuous increase of the stream data. On the other hand, these methods ignore the supervision relationship among the examples, especially in the multi-label case. In this paper, we propose a novel Fast Online Hashing (FOH) method which only updates the binary codes of a small part of the database. To be specific, we first build a query pool in which the nearest neighbors of each central point are recorded. When a new query arrives, only the binary codes of the corresponding potential neighbors are updated. In addition, we create a similarity matrix which takes the multi-label supervision information into account and bring in the multi-label projection loss to further preserve the similarity among the multi-label data. The experimental results on two common benchmarks show that the proposed FOH can achieve dramatic superiority on query time up to 6.28 seconds less than state-of-the-art baselines with competitive retrieval accuracy.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-10.819478034973145, -8.004490852355957]}, {"key": "", "year": "", "title": "Jian2020fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast top-K Cosine Similarity Search through XOR-Friendly Binary Quantization on GPUs\"\nauthors: Jian Xiaozheng, Lu Jianqiu, Yuan Zexi, Li Ao\nconference: Arxiv\nyear: 2020\nbibkey: jian2020fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2008.02002\"}\ntags: ['ARXIV', 'Quantisation', 'TIP']\n---\nWe explore the use of GPU for accelerating large scale nearest neighbor search and we propose a fast vector-quantization-based exhaustive nearest neighbor search algorithm that can achieve high accuracy without any indexing construction specifically designed for cosine similarity. This algorithm uses a novel XOR-friendly binary quantization method to encode floating-point numbers such that high-complexity multiplications can be optimized as low-complexity bitwise operations. Experiments show that, our quantization method takes short preprocessing time, and helps make the search speed of our exhaustive search method much more faster than that of popular approximate nearest neighbor algorithms when high accuracy is needed.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [6.502269268035889, -15.145708084106445]}, {"key": "", "year": "", "title": "Jiang2014revisiting", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Revisiting Kernelized Locality-Sensitive Hashing for Improved Large-Scale Image Retrieval\"\nauthors: Jiang Ke, Que Qichao, Kulis Brian\nconference: Arxiv\nyear: 2014\nbibkey: jiang2014revisiting\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1411.4199\"}\ntags: ['ARXIV', 'Image Retrieval', 'LSH']\n---\nWe present a simple but powerful reinterpretation of kernelized locality-sensitive hashing (KLSH), a general and popular method developed in the vision community for performing approximate nearest-neighbor searches in an arbitrary reproducing kernel Hilbert space (RKHS). Our new perspective is based on viewing the steps of the KLSH algorithm in an appropriately projected space, and has several key theoretical and practical benefits. First, it eliminates the problematic conceptual difficulties that are present in the existing motivation of KLSH. Second, it yields the first formal retrieval performance bounds for KLSH. Third, our analysis reveals two techniques for boosting the empirical performance of KLSH. We evaluate these extensions on several large-scale benchmark image retrieval data sets, and show that our analysis leads to improved recall performance of at least 12%, and sometimes much higher, over the standard KLSH method.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [8.901629447937012, 8.609309196472168]}, {"key": "", "year": "", "title": "Jiang2016deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Cross-Modal Hashing\"\nauthors: Jiang Qing-Yuan, Li Wu-Jun\nconference: Arxiv\nyear: 2016\nbibkey: jiang2016deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1602.02255\"}\ntags: ['ARXIV', 'Cross Modal']\n---\nDue to its low storage cost and fast query speed, cross-modal hashing (CMH) has been widely used for similarity search in multimedia retrieval applications. However, almost all existing CMH methods are based on hand-crafted features which might not be optimally compatible with the hash-code learning procedure. As a result, existing CMH methods with handcrafted features may not achieve satisfactory performance. In this paper, we propose a novel cross-modal hashing method, called deep crossmodal hashing (DCMH), by integrating feature learning and hash-code learning into the same framework. DCMH is an end-to-end learning framework with deep neural networks, one for each modality, to perform feature learning from scratch. Experiments on two real datasets with text-image modalities show that DCMH can outperform other baselines to achieve the state-of-the-art performance in cross-modal retrieval applications.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-14.510064125061035, 0.3562636971473694]}, {"key": "", "year": "", "title": "Jiang2017asymmetric", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Asymmetric Deep Supervised Hashing\"\nauthors: Jiang Qing-Yuan, Li Wu-Jun\nconference: Arxiv\nyear: 2017\nbibkey: jiang2017asymmetric\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1707.08325\"}\ntags: ['ARXIV', 'Supervised']\n---\nHashing has been widely used for large-scale approximate nearest neighbor search because of its storage and search efficiency. Recent work has found that deep supervised hashing can significantly outperform non-deep supervised hashing in many applications. However, most existing deep supervised hashing methods adopt a symmetric strategy to learn one deep hash function for both query points and database (retrieval) points. The training of these symmetric deep supervised hashing methods is typically time-consuming, which makes them hard to effectively utilize the supervised information for cases with large-scale database. In this paper, we propose a novel deep supervised hashing method, called asymmetric deep supervised hashing (ADSH), for large-scale nearest neighbor search. ADSH treats the query points and database points in an asymmetric way. More specifically, ADSH learns a deep hash function only for query points, while the hash codes for database points are directly learned. The training of ADSH is much more efficient than that of traditional symmetric deep supervised hashing methods. Experiments show that ADSH can achieve state-of-the-art performance in real applications.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-13.72111988067627, -3.3712124824523926]}, {"key": "", "year": "", "title": "Jiang2017deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Discrete Supervised Hashing\"\nauthors: Jiang Qing-Yuan, Cui Xue, Li Wu-Jun\nconference: Arxiv\nyear: 2017\nbibkey: jiang2017deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1707.09905\"}\ntags: ['ARXIV', 'Image Retrieval', 'Supervised', 'Unsupervised']\n---\nHashing has been widely used for large-scale search due to its low storage cost and fast query speed. By using supervised information, supervised hashing can significantly outperform unsupervised hashing. Recently, discrete supervised hashing and deep hashing are two representative progresses in supervised hashing. On one hand, hashing is essentially a discrete optimization problem. Hence, utilizing supervised information to directly guide discrete (binary) coding procedure can avoid sub-optimal solution and improve the accuracy. On the other hand, deep hashing, which integrates deep feature learning and hash-code learning into an end-to-end architecture, can enhance the feedback between feature learning and hash-code learning. The key in discrete supervised hashing is to adopt supervised information to directly guide the discrete coding procedure in hashing. The key in deep hashing is to adopt the supervised information to directly guide the deep feature learning procedure. However, there have not existed works which can use the supervised information to directly guide both discrete coding procedure and deep feature learning procedure in the same framework. In this paper, we propose a novel deep hashing method, called deep discrete supervised hashing (DDSH), to address this problem. DDSH is the first deep hashing method which can utilize supervised information to directly guide both discrete coding procedure and deep feature learning procedure, and thus enhance the feedback between these two important procedures. Experiments on three real datasets show that DDSH can outperform other state-of-the-art baselines, including both discrete hashing and deep hashing baselines, for image retrieval.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-13.159953117370605, -2.1994121074676514]}, {"key": "", "year": "", "title": "Jiang2017discrete", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Discrete Latent Factor Model for Cross-Modal Hashing\"\nauthors: Jiang Qing-Yuan, Li Wu-Jun\nconference: Arxiv\nyear: 2017\nbibkey: jiang2017discrete\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1707.08322\"}\ntags: ['ARXIV', 'Cross Modal']\n---\nDue to its storage and retrieval efficiency, cross-modal hashing~(CMH) has been widely used for cross-modal similarity search in multimedia applications. According to the training strategy, existing CMH methods can be mainly divided into two categories: relaxation-based continuous methods and discrete methods. In general, the training of relaxation-based continuous methods is faster than discrete methods, but the accuracy of relaxation-based continuous methods is not satisfactory. On the contrary, the accuracy of discrete methods is typically better than relaxation-based continuous methods, but the training of discrete methods is time-consuming. In this paper, we propose a novel CMH method, called discrete latent factor model based cross-modal hashing~(DLFH), for cross modal similarity search. DLFH is a discrete method which can directly learn the binary hash codes for CMH. At the same time, the training of DLFH is efficient. Experiments on real datasets show that DLFH can achieve significantly better accuracy than existing methods, and the training time of DLFH is comparable to that of relaxation-based continuous methods which are much faster than existing discrete methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-12.897889137268066, -4.676486968994141]}, {"key": "", "year": "", "title": "Jiang2019graph", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Graph-based Multi-view Binary Learning for Image Clustering\"\nauthors: Jiang Guangqi, Wang Huibing, Peng Jinjia, Chen Dongyan, Fu Xianping\nconference: Arxiv\nyear: 2019\nbibkey: jiang2019graph\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1912.05159\"}\ntags: ['ARXIV', 'Graph', 'TIP', 'TOM']\n---\nHashing techniques, also known as binary code learning, have recently gained increasing attention in large-scale data analysis and storage. Generally, most existing hash clustering methods are single-view ones, which lack complete structure or complementary information from multiple views. For cluster tasks, abundant prior researches mainly focus on learning discrete hash code while few works take original data structure into consideration. To address these problems, we propose a novel binary code algorithm for clustering, which adopts graph embedding to preserve the original data structure, called (Graph-based Multi-view Binary Learning) GMBL in this paper. GMBL mainly focuses on encoding the information of multiple views into a compact binary code, which explores complementary information from multiple views. In particular, in order to maintain the graph-based structure of the original data, we adopt a Laplacian matrix to preserve the local linear relationship of the data and map it to the Hamming space. Considering different views have distinctive contributions to the final clustering results, GMBL adopts a strategy of automatically assign weights for each view to better guide the clustering. Finally, An alternating iterative optimization method is adopted to optimize discrete binary codes directly instead of relaxing the binary constraint in two steps. Experiments on five public datasets demonstrate the superiority of our proposed method compared with previous approaches in terms of clustering performance.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [4.520995616912842, -28.122474670410156]}, {"key": "", "year": "", "title": "Jiang2019on", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"On the Evaluation Metric for Hashing\"\nauthors: Jiang Qing-Yuan, Li Ming-Wei, Li Wu-Jun\nconference: Arxiv\nyear: 2019\nbibkey: jiang2019on\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1905.10951\"}\ntags: ['ARXIV']\n---\nDue to its low storage cost and fast query speed, hashing has been widely used for large-scale approximate nearest neighbor (ANN) search. Bucket search, also called hash lookup, can achieve fast query speed with a sub-linear time cost based on the inverted index table constructed from hash codes. Many metrics have been adopted to evaluate hashing algorithms. However, all existing metrics are improper to evaluate the hash codes for bucket search. On one hand, all existing metrics ignore the retrieval time cost which is an important factor reflecting the performance of search. On the other hand, some of them, such as mean average precision (MAP), suffer from the uncertainty problem as the ranked list is based on integer-valued Hamming distance, and are insensitive to Hamming radius as these metrics only depend on relative Hamming distance. Other metrics, such as precision at Hamming radius R, fail to evaluate global performance as these metrics only depend on one specific Hamming radius. In this paper, we first point out the problems of existing metrics which have been ignored by the hashing community, and then propose a novel evaluation metric called radius aware mean average precision (RAMAP) to evaluate hash codes for bucket search. Furthermore, two coding strategies are also proposed to qualitatively show the problems of existing metrics. Experiments demonstrate that our proposed RAMAP can provide more proper evaluation than existing metrics.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-18.19413185119629, -10.35984992980957]}, {"key": "", "year": "", "title": "Jie2013a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Novel Block-DCT and PCA Based Image Perceptual Hashing Algorithm\"\nauthors: Jie Zeng\nconference: Arxiv\nyear: 2013\nbibkey: jie2013a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1306.4079\"}\ntags: ['ARXIV']\n---\nImage perceptual hashing finds applications in content indexing, large-scale image database management, certification and authentication and digital watermarking. We propose a Block-DCT and PCA based image perceptual hash in this article and explore the algorithm in the application of tamper detection. The main idea of the algorithm is to integrate color histogram and DCT coefficients of image blocks as perceptual feature, then to compress perceptual features as inter-feature with PCA, and to threshold to create a robust hash. The robustness and discrimination properties of the proposed algorithm are evaluated in detail. Our algorithms first construct a secondary image, derived from input image by pseudo-randomly extracting features that approximately capture semi-global geometric characteristics. From the secondary image (which does not perceptually resemble the input), we further extract the final features which can be used as a hash value (and can be further suitably quantized). In this paper, we use spectral matrix invariants as embodied by Singular Value Decomposition. Surprisingly, formation of the secondary image turns out be quite important since it not only introduces further robustness, but also enhances the security properties. Indeed, our experiments reveal that our hashing algorithms extract most of the geometric information from the images and hence are robust to severe perturbations (e.g. up to %50 cropping by area with 20 degree rotations) on images while avoiding misclassification. Experimental results show that the proposed image perceptual hash algorithm can effectively address the tamper detection problem with advantageous robustness and discrimination.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [1.4665577411651611, 6.848099231719971]}, {"key": "", "year": "", "title": "Jin2017ranking", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Ranking Based Locality Sensitive Hashing Enabled Cancelable Biometrics: Index-of-Max Hashing\"\nauthors: Jin Zhe, Lai Yen-Lung, Hwang Jung-Yeon, Kim Soohyung, Teoh Andrew Beng Jin\nconference: Arxiv\nyear: 2017\nbibkey: jin2017ranking\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1703.05455\"}\ntags: ['ARXIV']\n---\nIn this paper, we propose a ranking based locality sensitive hashing inspired two-factor cancelable biometrics, dubbed \"Index-of-Max\" (IoM) hashing for biometric template protection. With externally generated random parameters, IoM hashing transforms a real-valued biometric feature vector into discrete index (max ranked) hashed code. We demonstrate two realizations from IoM hashing notion, namely Gaussian Random Projection based and Uniformly Random Permutation based hashing schemes. The discrete indices representation nature of IoM hashed codes enjoy serveral merits. Firstly, IoM hashing empowers strong concealment to the biometric information. This contributes to the solid ground of non-invertibility guarantee. Secondly, IoM hashing is insensitive to the features magnitude, hence is more robust against biometric features variation. Thirdly, the magnitude-independence trait of IoM hashing makes the hash codes being scale-invariant, which is critical for matching and feature alignment. The experimental results demonstrate favorable accuracy performance on benchmark FVC2002 and FVC2004 fingerprint databases. The analyses justify its resilience to the existing and newly introduced security and privacy attacks as well as satisfy the revocability and unlinkability criteria of cancelable biometrics.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-4.869551658630371, 0.9231612682342529]}, {"key": "", "year": "", "title": "Jin2018deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Saliency Hashing\"\nauthors: Jin Sheng, Yao Hongxun, Sun Xiaoshuai, Zhou Shangchen, Zhang Lei, Hua Xiansheng\nconference: Arxiv\nyear: 2018\nbibkey: jin2018deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1807.01459\"}\ntags: ['ARXIV', 'Quantisation', 'TOM']\n---\nIn recent years, hashing methods have been proved to be effective and efficient for the large-scale Web media search. However, the existing general hashing methods have limited discriminative power for describing fine-grained objects that share similar overall appearance but have subtle difference. To solve this problem, we for the first time introduce the attention mechanism to the learning of fine-grained hashing codes. Specifically, we propose a novel deep hashing model, named deep saliency hashing (DSaH), which automatically mines salient regions and learns semantic-preserving hashing codes simultaneously. DSaH is a two-step end-to-end model consisting of an attention network and a hashing network. Our loss function contains three basic components, including the semantic loss, the saliency loss, and the quantization loss. As the core of DSaH, the saliency loss guides the attention network to mine discriminative regions from pairs of images. We conduct extensive experiments on both fine-grained and general retrieval datasets for performance evaluation. Experimental results on fine-grained datasets, including Oxford Flowers-17, Stanford Dogs-120, and CUB Bird demonstrate that our DSaH performs the best for fine-grained retrieval task and beats the strongest competitor (DTQ) by approximately 10% on both Stanford Dogs-120 and CUB Bird. DSaH is also comparable to several state-of-the-art hashing methods on general datasets, including CIFAR-10 and NUS-WIDE.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-4.117441177368164, 6.0180888175964355]}, {"key": "", "year": "", "title": "Jin2018unsupervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Unsupervised Semantic Deep Hashing\"\nauthors: Jin Sheng\nconference: Arxiv\nyear: 2018\nbibkey: jin2018unsupervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1803.06911\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval', 'Quantisation', 'Supervised', 'Unsupervised']\n---\nIn recent years, deep hashing methods have been proved to be efficient since it employs convolutional neural network to learn features and hashing codes simultaneously. However, these methods are mostly supervised. In real-world application, it is a time-consuming and overloaded task for annotating a large number of images. In this paper, we propose a novel unsupervised deep hashing method for large-scale image retrieval. Our method, namely unsupervised semantic deep hashing (\\textbf{USDH}), uses semantic information preserved in the CNN feature layer to guide the training of network. We enforce four criteria on hashing codes learning based on VGG-19 model: 1) preserving relevant information of feature space in hashing space; 2) minimizing quantization loss between binary-like codes and hashing codes; 3) improving the usage of each bit in hashing codes by using maximum information entropy, and 4) invariant to image rotation. Extensive experiments on CIFAR-10, NUSWIDE have demonstrated that \\textbf{USDH} outperforms several state-of-the-art unsupervised hashing methods for image retrieval. We also conduct experiments on Oxford 17 datasets for fine-grained classification to verify its efficiency for other computer vision tasks.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-10.662824630737305, 10.545377731323242]}, {"key": "", "year": "", "title": "Jin2019deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Semantic Multimodal Hashing Network for Scalable Image-Text and Video-Text Retrievals\"\nauthors: Jin Lu, Li Zechao, Tang Jinhui\nconference: Arxiv\nyear: 2019\nbibkey: jin2019deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1901.02662\"}\ntags: ['ARXIV', 'CNN', 'Cross Modal', 'Text Retrieval']\n---\nHashing has been widely applied to multimodal retrieval on large-scale multimedia data due to its efficiency in computation and storage. In this article, we propose a novel deep semantic multimodal hashing network (DSMHN) for scalable image-text and video-text retrieval. The proposed deep hashing framework leverages 2-D convolutional neural networks (CNN) as the backbone network to capture the spatial information for image-text retrieval, while the 3-D CNN as the backbone network to capture the spatial and temporal information for video-text retrieval. In the DSMHN, two sets of modality-specific hash functions are jointly learned by explicitly preserving both intermodality similarities and intramodality semantic labels. Specifically, with the assumption that the learned hash codes should be optimal for the classification task, two stream networks are jointly trained to learn the hash functions by embedding the semantic labels on the resultant hash codes. Moreover, a unified deep multimodal hashing framework is proposed to learn compact and high-quality hash codes by exploiting the feature representation learning, intermodality similarity-preserving learning, semantic label-preserving learning, and hash function learning with different types of loss functions simultaneously. The proposed DSMHN method is a generic and scalable deep hashing framework for both image-text and video-text retrievals, which can be flexibly integrated with different types of loss functions. We conduct extensive experiments for both single modal- and cross-modal-retrieval tasks on four widely used multimodal-retrieval data sets. Experimental results on both image-text- and video-text-retrieval tasks demonstrate that the DSMHN significantly outperforms the state-of-the-art methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-13.984864234924316, 5.049050331115723]}, {"key": "", "year": "", "title": "Jin2019ssah", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"SSAH: Semi-supervised Adversarial Deep Hashing with Self-paced Hard Sample Generation\"\nauthors: Jin Sheng, Zhou Shangchen, Liu Yao, Chen Chao, Sun Xiaoshuai, Yao Hongxun, Hua Xiansheng\nconference: Arxiv\nyear: 2019\nbibkey: jin2019ssah\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1911.08688\"}\ntags: ['ARXIV', 'GAN', 'Semi Supervised', 'Supervised']\n---\nDeep hashing methods have been proved to be effective and efficient for large-scale Web media search. The success of these data-driven methods largely depends on collecting sufficient labeled data, which is usually a crucial limitation in practical cases. The current solutions to this issue utilize Generative Adversarial Network (GAN) to augment data in semi-supervised learning. However, existing GAN-based methods treat image generations and hashing learning as two isolated processes, leading to generation ineffectiveness. Besides, most works fail to exploit the semantic information in unlabeled data. In this paper, we propose a novel Semi-supervised Self-pace Adversarial Hashing method, named SSAH to solve the above problems in a unified framework. The SSAH method consists of an adversarial network (A-Net) and a hashing network (H-Net). To improve the quality of generative images, first, the A-Net learns hard samples with multi-scale occlusions and multi-angle rotated deformations which compete against the learning of accurate hashing codes. Second, we design a novel self-paced hard generation policy to gradually increase the hashing difficulty of generated samples. To make use of the semantic information in unlabeled ones, we propose a semi-supervised consistent loss. The experimental results show that our method can significantly improve state-of-the-art models on both the widely-used hashing datasets and fine-grained datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-12.105164527893066, -1.7426587343215942]}, {"key": "", "year": "", "title": "Johnvictor2014survey", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Survey on Sparse Coded Features for Content Based Face Image Retrieval\"\nauthors: Johnvictor D., Selvavinayagam G.\nconference: International Journal of Computer Trends and Technology\nyear: 2014\nbibkey: johnvictor2014survey\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1402.4888\"}\ntags: ['Image Retrieval', 'Survey Paper', 'TIP']\n---\nContent based image retrieval, a technique which uses visual contents of image to search images from large scale image databases according to users' interests. This paper provides a comprehensive survey on recent technology used in the area of content based face image retrieval. Nowadays digital devices and photo sharing sites are getting more popularity, large human face photos are available in database. Multiple types of facial features are used to represent discriminality on large scale human facial image database. Searching and mining of facial images are challenging problems and important research issues. Sparse representation on features provides significant improvement in indexing related images to query image.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [26.502731323242188, 11.866830825805664]}, {"key": "", "year": "", "title": "Joslyn2018deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Segment Hash Learning for Music Generation\"\nauthors: Joslyn Kevin, Zhuang Naifan, Hua Kien A.\nconference: Arxiv\nyear: 2018\nbibkey: joslyn2018deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1805.12176\"}\ntags: ['ARXIV', 'Deep Learning']\n---\nMusic generation research has grown in popularity over the past decade, thanks to the deep learning revolution that has redefined the landscape of artificial intelligence. In this paper, we propose a novel approach to music generation inspired by musical segment concatenation methods and hash learning algorithms. Given a segment of music, we use a deep recurrent neural network and ranking-based hash learning to assign a forward hash code to the segment to retrieve candidate segments for continuation with matching backward hash codes. The proposed method is thus called Deep Segment Hash Learning (DSHL). To the best of our knowledge, DSHL is the first end-to-end segment hash learning method for music generation, and the first to use pair-wise training with segments of music. We demonstrate that this method is capable of generating music which is both original and enjoyable, and that DSHL offers a promising new direction for music generation research.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-19.157772064208984, 10.760029792785645]}, {"key": "", "year": "", "title": "Joulin2016fasttextzip", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"FastText.zip: Compressing text classification models\"\nauthors: Joulin Armand, Grave Edouard, Bojanowski Piotr, Douze Matthijs, J\u00e9gou H\u00e9rve, Mikolov Tomas\nconference: Arxiv\nyear: 2016\nbibkey: joulin2016fasttextzip\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1612.03651\"}\ntags: ['ARXIV', 'Quantisation']\n---\nWe consider the problem of producing compact architectures for text classification, such that the full model fits in a limited amount of memory. After considering different solutions inspired by the hashing literature, we propose a method built upon product quantization to store word embeddings. While the original technique leads to a loss in accuracy, we adapt this method to circumvent quantization artefacts. Our experiments carried out on several benchmarks show that our approach typically requires two orders of magnitude less memory than fastText while being only slightly inferior with respect to accuracy. As a result, it outperforms the state of the art by a good margin in terms of the compromise between memory usage and accuracy.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [9.136762619018555, -7.499457359313965]}, {"key": "", "year": "", "title": "Juan2019graph", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Graph-RISE: Graph-Regularized Image Semantic Embedding\"\nauthors: Juan Da-Cheng, Lu Chun-Ta, Li Zhen, Peng Futang, Timofeev Aleksei, Chen Yi-Ting, Gao Yaxi, Duerig Tom, Tomkins Andrew, Ravi Sujith\nconference: Arxiv\nyear: 2019\nbibkey: juan2019graph\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1902.10814\"}\ntags: ['ARXIV', 'Graph', 'Image Retrieval']\n---\nLearning image representations to capture fine-grained semantics has been a challenging and important task enabling many applications such as image search and clustering. In this paper, we present Graph-Regularized Image Semantic Embedding (Graph-RISE), a large-scale neural graph learning framework that allows us to train embeddings to discriminate an unprecedented O(40M) ultra-fine-grained semantic labels. Graph-RISE outperforms state-of-the-art image embedding algorithms on several evaluation tasks, including image classification and triplet ranking. We provide case studies to demonstrate that, qualitatively, image retrieval based on Graph-RISE effectively captures semantics and, compared to the state-of-the-art, differentiates nuances at levels that are closer to human-perception.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.647595405578613, -28.222728729248047]}, {"key": "", "year": "", "title": "Jun2019combination", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Combination of Multiple Global Descriptors for Image Retrieval\"\nauthors: Jun HeeJae, Ko Byungsoo, Kim Youngjoon, Kim Insik, Kim Jongtack\nconference: Arxiv\nyear: 2019\nbibkey: jun2019combination\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1903.10663\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval', 'TIP']\n---\nRecent studies in image retrieval task have shown that ensembling different models and combining multiple global descriptors lead to performance improvement. However, training different models for the ensemble is not only difficult but also inefficient with respect to time and memory. In this paper, we propose a novel framework that exploits multiple global descriptors to get an ensemble effect while it can be trained in an end-to-end manner. The proposed framework is flexible and expandable by the global descriptor, CNN backbone, loss, and dataset. Moreover, we investigate the effectiveness of combining multiple global descriptors with quantitative and qualitative analysis. Our extensive experiments show that the combined descriptor outperforms a single global descriptor, as it can utilize different types of feature properties. In the benchmark evaluation, the proposed framework achieves the state-of-the-art performance on the CARS196, CUB200-2011, In-shop Clothes, and Stanford Online Products on image retrieval tasks. Our model implementations and pretrained models are publicly available.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [13.80231761932373, 17.378664016723633]}, {"key": "", "year": "", "title": "Jung2011efficient", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Efficient Error-Correcting Geocoding\"\nauthors: Jung Christian, Karch Daniel, Knopp Sebastian, Luxen Dennis, Sanders Peter\nconference: Arxiv\nyear: 2011\nbibkey: jung2011efficient\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1102.3306\"}\ntags: ['ARXIV', 'Graph']\n---\nWe study the problem of resolving a perhaps misspelled address of a location into geographic coordinates of latitude and longitude. Our data structure solves this problem within a few milliseconds even for misspelled and fragmentary queries. Compared to major geographic search engines such as Google or Bing we achieve results of significantly better quality.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [10.479578018188477, -19.629579544067383]}, {"key": "", "year": "", "title": "Junussov2019note", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Note on distance matrix hashing\"\nauthors: Junussov I. A.\nconference: Arxiv\nyear: 2019\nbibkey: junussov2019note\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1901.09505\"}\ntags: ['ARXIV']\n---\nHashing algorithm of dynamical set of distances is described. Proposed hashing function is residual. Data structure which implementation accelerates computations is presented\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.634804725646973, -12.974259376525879]}, {"key": "", "year": "", "title": "Junzhou2013csift", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"CSIFT Based Locality-constrained Linear Coding for Image Classification\"\nauthors: Junzhou Chen, Qing Li, Qiang Peng, Wong Kin Hong\nconference: Arxiv\nyear: 2013\nbibkey: junzhou2013csift\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1309.7484\"}\ntags: ['ARXIV']\n---\nIn the past decade, SIFT descriptor has been witnessed as one of the most robust local invariant feature descriptors and widely used in various vision tasks. Most traditional image classification systems depend on the luminance-based SIFT descriptors, which only analyze the gray level variations of the images. Misclassification may happen since their color contents are ignored. In this article, we concentrate on improving the performance of existing image classification algorithms by adding color information. To achieve this purpose, different kinds of colored SIFT descriptors are introduced and implemented. Locality-constrained Linear Coding (LLC), a state-of-the-art sparse coding technology, is employed to construct the image classification system for the evaluation. The real experiments are carried out on several benchmarks. With the enhancements of color SIFT, the proposed image classification system obtains approximate 3% improvement of classification accuracy on the Caltech-101 dataset and approximate 4% improvement of classification accuracy on the Caltech-256 dataset.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [17.574207305908203, 16.890451431274414]}, {"key": "", "year": "", "title": "Juvekar2024cos", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"COS-Mix: Cosine Similarity and Distance Fusion for Improved Information Retrieval\"\nauthors: Juvekar Kush, Purwar Anupam\nconference: Arxiv\nyear: 2024\nbibkey: juvekar2024cos\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2406.00638\"}\ntags: ['ARXIV']\n---\nThis study proposes a novel hybrid retrieval strategy for Retrieval-Augmented Generation (RAG) that integrates cosine similarity and cosine distance measures to improve retrieval performance, particularly for sparse data. The traditional cosine similarity measure is widely used to capture the similarity between vectors in high-dimensional spaces. However, it has been shown that this measure can yield arbitrary results in certain scenarios. To address this limitation, we incorporate cosine distance measures to provide a complementary perspective by quantifying the dissimilarity between vectors. Our approach is experimented on proprietary data, unlike recent publications that have used open-source datasets. The proposed method demonstrates enhanced retrieval performance and provides a more comprehensive understanding of the semantic relationships between documents or items. This hybrid strategy offers a promising solution for efficiently and accurately retrieving relevant information in knowledge-intensive applications, leveraging techniques such as BM25 (sparse) retrieval , vector (Dense) retrieval, and cosine distance based retrieval to facilitate efficient information retrieval.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [15.316668510437012, -2.997664451599121]}, {"key": "", "year": "", "title": "J\u00e9gou2011anti", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Anti-sparse coding for approximate nearest neighbor search\"\nauthors: J\u00e9gou Herv\u00e9  INRIA - IRISA, Furon Teddy  INRIA - IRISA, Fuchs Jean-Jacques  INRIA - IRISA\nconference: Arxiv\nyear: 2011\nbibkey: j\u00e9gou2011anti\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1110.3767\"}\ntags: ['ARXIV']\n---\nThis paper proposes a binarization scheme for vectors of high dimension based on the recent concept of anti-sparse coding, and shows its excellent performance for approximate nearest neighbor search. Unlike other binarization schemes, this framework allows, up to a scaling factor, the explicit reconstruction from the binary representation of the original vector. The paper also shows that random projections which are used in Locality Sensitive Hashing algorithms, are significantly outperformed by regular frames for both synthetic and real data if the number of bits exceeds the vector dimensionality, i.e., when high precision is required.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [9.243194580078125, -11.929545402526855]}, {"key": "", "year": "", "title": "J\u00fanior2018application", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Application-Specific System Processor for the SHA-1 Hash Algorithm\"\nauthors: J\u00fanior Carlos E. B. S., Torquato Matheus F., Fernandes Marcelo A. C.\nconference: Arxiv\nyear: 2018\nbibkey: j\u00fanior2018application\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1901.04989\"}\ntags: ['ARXIV']\n---\nThis work proposes an Application-Specific System Processor (ASSP) hardware for the Secure Hash Algorithm 1 (SHA-1) algorithm. The proposed hardware was implemented in a Field Programmable Gate Array (FPGA) Xilinx Virtex 6 xc6vlx240t-1ff1156. The throughput and the occupied area were analyzed for several implementations in parallel instances of the hash algorithm. The results showed that the hardware proposed for the SHA-1 achieved a throughput of 0.644 Gbps for a single instance and slightly more than 28 Gbps for 48 instances in a single FPGA. Various applications such as password recovery, password validation, and high volume data integrity checking can be performed efficiently and quickly with an ASSP for SHA1.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-32.19890213012695, -0.062281277030706406]}, {"key": "", "year": "", "title": "Kaga2019pdh", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"PDH : Probabilistic deep hashing based on MAP estimation of Hamming distance\"\nauthors: Kaga Yosuke, Fujio Masakazu, Takahashi Kenta, Ohki Tetsushi, Nishigaki Masakatsu\nconference: \nyear: 2019\nbibkey: kaga2019pdh\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1905.08501\"}\ntags: ['Image Retrieval', 'TIP']\n---\nWith the growth of image on the web, research on hashing which enables high-speed image retrieval has been actively studied. In recent years, various hashing methods based on deep neural networks have been proposed and achieved higher precision than the other hashing methods. In these methods, multiple losses for hash codes and the parameters of neural networks are defined. They generate hash codes that minimize the weighted sum of the losses. Therefore, an expert has to tune the weights for the losses heuristically, and the probabilistic optimality of the loss function cannot be explained. In order to generate explainable hash codes without weight tuning, we theoretically derive a single loss function with no hyperparameters for the hash code from the probability distribution of the images. By generating hash codes that minimize this loss function, highly accurate image retrieval with probabilistic optimality is performed. We evaluate the performance of hashing using MNIST, CIFAR-10, SVHN and show that the proposed method outperforms the state-of-the-art hashing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-0.2753930985927582, 10.960898399353027]}, {"key": "", "year": "", "title": "Kalantidis2016loh", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"LOH and behold: Web-scale visual search, recommendation and clustering using Locally Optimized Hashing\"\nauthors: Kalantidis Yannis, Kennedy Lyndon, Nguyen Huy, Mellina Clayton, Shamma David A.\nconference: Arxiv\nyear: 2016\nbibkey: kalantidis2016loh\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1604.06480\"}\ntags: ['ARXIV', 'Graph', 'Quantisation']\n---\nWe propose a novel hashing-based matching scheme, called Locally Optimized Hashing (LOH), based on a state-of-the-art quantization algorithm that can be used for efficient, large-scale search, recommendation, clustering, and deduplication. We show that matching with LOH only requires set intersections and summations to compute and so is easily implemented in generic distributed computing systems. We further show application of LOH to: a) large-scale search tasks where performance is on par with other state-of-the-art hashing approaches; b) large-scale recommendation where queries consisting of thousands of images can be used to generate accurate recommendations from collections of hundreds of millions of images; and c) efficient clustering with a graph-based algorithm that can be scaled to massive collections in a distributed environment or can be used for deduplication for small collections, like search results, performing better than traditional hashing approaches while only requiring a few milliseconds to run. In this paper we experiment on datasets of up to 100 million images, but in practice our system can scale to larger collections and can be used for other types of data that have a vector representation in a Euclidean space.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [4.671030521392822, -22.173261642456055]}, {"key": "", "year": "", "title": "Kanda2019b", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"$b$-Bit Sketch Trie: Scalable Similarity Search on Integer Sketches\"\nauthors: Kanda Shunsuke, Tabei Yasuo\nconference: Arxiv\nyear: 2019\nbibkey: kanda2019b\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1910.08278\"}\ntags: ['ARXIV']\n---\nRecently, randomly mapping vectorial data to strings of discrete symbols (i.e., sketches) for fast and space-efficient similarity searches has become popular. Such random mapping is called similarity-preserving hashing and approximates a similarity metric by using the Hamming distance. Although many efficient similarity searches have been proposed, most of them are designed for binary sketches. Similarity searches on integer sketches are in their infancy. In this paper, we present a novel space-efficient trie named $b$-bit sketch trie on integer sketches for scalable similarity searches by leveraging the idea behind succinct data structures (i.e., space-efficient data structures while supporting various data operations in the compressed format) and a favorable property of integer sketches as fixed-length strings. Our experimental results obtained using real-world datasets show that a trie-based index is built from integer sketches and efficiently performs similarity searches on the index by pruning useless portions of the search space, which greatly improves the search time and space-efficiency of the similarity search. The experimental results show that our similarity search is at most one order of magnitude faster than state-of-the-art similarity searches. Besides, our method needs only 10 GiB of memory on a billion-scale database, while state-of-the-art similarity searches need 29 GiB of memory.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-2.5582199096679688, -21.47640037536621]}, {"key": "", "year": "", "title": "Kanda2020dynamic", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Dynamic Similarity Search on Integer Sketches\"\nauthors: Kanda Shunsuke, Tabei Yasuo\nconference: Arxiv\nyear: 2020\nbibkey: kanda2020dynamic\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2009.11559\"}\ntags: ['ARXIV']\n---\nSimilarity-preserving hashing is a core technique for fast similarity searches, and it randomly maps data points in a metric space to strings of discrete symbols (i.e., sketches) in the Hamming space. While traditional hashing techniques produce binary sketches, recent ones produce integer sketches for preserving various similarity measures. However, most similarity search methods are designed for binary sketches and inefficient for integer sketches. Moreover, most methods are either inapplicable or inefficient for dynamic datasets, although modern real-world datasets are updated over time. We propose dynamic filter trie (DyFT), a dynamic similarity search method for both binary and integer sketches. An extensive experimental analysis using large real-world datasets shows that DyFT performs superiorly with respect to scalability, time performance, and memory efficiency. For example, on a huge dataset of 216 million data points, DyFT performs a similarity search 6,000 times faster than a state-of-the-art method while reducing to one-thirteenth in memory.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-2.4735772609710693, -21.458660125732422]}, {"key": "", "year": "", "title": "Kang2020learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning to Embed Categorical Features without Embedding Tables for Recommendation\"\nauthors: Kang Wang-Cheng, Cheng Derek Zhiyuan, Yao Tiansheng, Yi Xinyang, Chen Ting, Hong Lichan, Chi Ed H.\nconference: Arxiv\nyear: 2020\nbibkey: kang2020learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2010.10784\"}\ntags: ['ARXIV', 'TIP']\n---\nEmbedding learning of categorical features (e.g. user/item IDs) is at the core of various recommendation models including matrix factorization and neural collaborative filtering. The standard approach creates an embedding table where each row represents a dedicated embedding vector for every unique feature value. However, this method fails to efficiently handle high-cardinality features and unseen feature values (e.g. new video ID) that are prevalent in real-world recommendation systems. In this paper, we propose an alternative embedding framework Deep Hash Embedding (DHE), replacing embedding tables by a deep embedding network to compute embeddings on the fly. DHE first encodes the feature value to a unique identifier vector with multiple hashing functions and transformations, and then applies a DNN to convert the identifier vector to an embedding. The encoding module is deterministic, non-learnable, and free of storage, while the embedding network is updated during the training time to learn embedding generation. Empirical results show that DHE achieves comparable AUC against the standard one-hot full embedding, with smaller model sizes. Our work sheds light on the design of DNN-based alternative embedding schemes for categorical features without using embedding table lookup.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-13.54879379272461, 20.02090072631836]}, {"key": "", "year": "", "title": "Kanizo2010maximum", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Maximum Bipartite Matching Size And Application to Cuckoo Hashing\"\nauthors: Kanizo Yossi, Hay David, Keslassy Isaac\nconference: Arxiv\nyear: 2010\nbibkey: kanizo2010maximum\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1007.1946\"}\ntags: ['ARXIV', 'Graph', 'TIP']\n---\nCuckoo hashing with a stash is a robust multiple choice hashing scheme with high memory utilization that can be used in many network device applications. Unfortunately, for memory loads beyond 0.5, little is known on its performance. In this paper, we analyze its average performance over such loads. We tackle this problem by recasting the problem as an analysis of the expected maximum matching size of a given random bipartite graph. We provide exact results for any finite system, and also deduce asymptotic results as the memory size increases. We further consider other variants of this problem, and finally evaluate the performance of our models on Internet backbone traces. More generally, our results give a tight lower bound on the size of the stash needed for any multiple-choice hashing scheme.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-24.674222946166992, -8.158745765686035]}, {"key": "", "year": "", "title": "Kannan2010an", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"An Effective Method of Image Retrieval using Image Mining Techniques\"\nauthors: Kannan A., Mohan V., Anbazhagan N.\nconference: Arxiv\nyear: 2010\nbibkey: kannan2010an\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1012.0223\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nThe present research scholars are having keen interest in doing their research activities in the area of Data mining all over the world. Especially, [13]Mining Image data is the one of the essential features in this present scenario since image data plays vital role in every aspect of the system such as business for marketing, hospital for surgery, engineering for construction, Web for publication and so on. The other area in the Image mining system is the Content-Based Image Retrieval (CBIR) which performs retrieval based on the similarity defined in terms of extracted features with more objectiveness. The drawback in CBIR is the features of the query image alone are considered. Hence, a new technique called Image retrieval based on optimum clusters is proposed for improving user interaction with image retrieval systems by fully exploiting the similarity information. The index is created by describing the images according to their color characteristics, with compact feature vectors, that represent typical color distributions [12].\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [20.86077880859375, 10.203398704528809]}, {"key": "", "year": "", "title": "Kaplan2020locality", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Locality Sensitive Hashing for Set-Queries, Motivated by Group Recommendations\"\nauthors: Kaplan Haim, Tenenbaum Jay\nconference: Arxiv\nyear: 2020\nbibkey: kaplan2020locality\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2004.07286\"}\ntags: ['ARXIV', 'LSH']\n---\nLocality Sensitive Hashing (LSH) is an effective method to index a set of points such that we can efficiently find the nearest neighbors of a query point. We extend this method to our novel Set-query LSH (SLSH), such that it can find the nearest neighbors of a set of points, given as a query. Let $ s(x,y) $ be the similarity between two points $ x $ and $ y $. We define a similarity between a set $ Q$ and a point $ x $ by aggregating the similarities $ s(p,x) $ for all $ p\\in Q $. For example, we can take $ s(p,x) $ to be the angular similarity between $ p $ and $ x $ (i.e., $1-\\{\\angle (x,p)\\}/\\{\\pi\\}$), and aggregate by arithmetic or geometric averaging, or taking the lowest similarity. We develop locality sensitive hash families and data structures for a large set of such arithmetic and geometric averaging similarities, and analyze their collision probabilities. We also establish an analogous framework and hash families for distance functions. Specifically, we give a structure for the euclidean distance aggregated by either averaging or taking the maximum. We leverage SLSH to solve a geometric extension of the approximate near neighbors problem. In this version, we consider a metric for which the unit ball is an ellipsoid and its orientation is specified with the query. An important application that motivates our work is group recommendation systems. Such a system embeds movies and users in the same feature space, and the task of recommending a movie for a group to watch together, translates to a set-query $ Q $ using an appropriate similarity.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-7.075808048248291, -25.408288955688477]}, {"key": "", "year": "", "title": "Kaplan2021locality", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Locality Sensitive Hashing for Efficient Similar Polygon Retrieval\"\nauthors: Kaplan Haim, Tenenbaum Jay\nconference: Arxiv\nyear: 2021\nbibkey: kaplan2021locality\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2101.04339\"}\ntags: ['ARXIV', 'LSH']\n---\nLocality Sensitive Hashing (LSH) is an effective method of indexing a set of items to support efficient nearest neighbors queries in high-dimensional spaces. The basic idea of LSH is that similar items should produce hash collisions with higher probability than dissimilar items. We study LSH for (not necessarily convex) polygons, and use it to give efficient data structures for similar shape retrieval. Arkin et al. represent polygons by their \"turning function\" - a function which follows the angle between the polygon's tangent and the $ x $-axis while traversing the perimeter of the polygon. They define the distance between polygons to be variations of the $ L_p $ (for $p=1,2$) distance between their turning functions. This metric is invariant under translation, rotation and scaling (and the selection of the initial point on the perimeter) and therefore models well the intuitive notion of shape resemblance. We develop and analyze LSH near neighbor data structures for several variations of the $ L_p $ distance for functions (for $p=1,2$). By applying our schemes to the turning functions of a collection of polygons we obtain efficient near neighbor LSH-based structures for polygons. To tune our structures to turning functions of polygons, we prove some new properties of these turning functions that may be of independent interest. As part of our analysis, we address the following problem which is of independent interest. Find the vertical translation of a function $ f $ that is closest in $ L_1 $ distance to a function $ g $. We prove tight bounds on the approximation guarantee obtained by the translation which is equal to the difference between the averages of $ g $ and $ f $.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-9.0760498046875, -23.922588348388672]}, {"key": "", "year": "", "title": "Kapralov2024on", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"On the adversarial robustness of Locality-Sensitive Hashing in Hamming space\"\nauthors: Kapralov Michael, Makarov Mikhail, Sohler Christian\nconference: Arxiv\nyear: 2024\nbibkey: kapralov2024on\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2402.09707\"}\ntags: ['ARXIV']\n---\nLocality-sensitive hashing~[Indyk,Motwani'98] is a classical data structure for approximate nearest neighbor search. It allows, after a close to linear time preprocessing of the input dataset, to find an approximately nearest neighbor of any fixed query in sublinear time in the dataset size. The resulting data structure is randomized and succeeds with high probability for every fixed query. In many modern applications of nearest neighbor search the queries are chosen adaptively. In this paper, we study the robustness of the locality-sensitive hashing to adaptive queries in Hamming space. We present a simple adversary that can, under mild assumptions on the initial point set, provably find a query to the approximate near neighbor search data structure that the data structure fails on. Crucially, our adaptive algorithm finds the hard query exponentially faster than random sampling.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [8.454719543457031, -15.362303733825684]}, {"key": "", "year": "", "title": "Kapu\u015bniak2023learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning Genomic Sequence Representations using Graph Neural Networks over De Bruijn Graphs\"\nauthors: Kapu\u015bniak Kacper, Burger Manuel, R\u00e4tsch Gunnar, Joudaki Amir\nconference: Arxiv\nyear: 2023\nbibkey: kapu\u015bniak2023learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2312.03865\"}\ntags: ['ARXIV', 'Graph', 'Self Supervised', 'Supervised']\n---\nThe rapid expansion of genomic sequence data calls for new methods to achieve robust sequence representations. Existing techniques often neglect intricate structural details, emphasizing mainly contextual information. To address this, we developed k-mer embeddings that merge contextual and structural string information by enhancing De Bruijn graphs with structural similarity connections. Subsequently, we crafted a self-supervised method based on Contrastive Learning that employs a heterogeneous Graph Convolutional Network encoder and constructs positive pairs based on node similarities. Our embeddings consistently outperform prior techniques for Edit Distance Approximation and Closest String Retrieval tasks.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.21667766571045, -25.519792556762695]}, {"key": "", "year": "", "title": "Karaman2019unsupervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Unsupervised Rank-Preserving Hashing for Large-Scale Image Retrieval\"\nauthors: Karaman Svebor, Lin Xudong, Hu Xuefeng, Chang Shih-Fu\nconference: Arxiv\nyear: 2019\nbibkey: karaman2019unsupervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1903.01545\"}\ntags: ['ARXIV', 'Graph', 'Image Retrieval', 'Supervised', 'TIP', 'Unsupervised']\n---\nWe propose an unsupervised hashing method which aims to produce binary codes that preserve the ranking induced by a real-valued representation. Such compact hash codes enable the complete elimination of real-valued feature storage and allow for significant reduction of the computation complexity and storage cost of large-scale image retrieval applications. Specifically, we learn a neural network-based model, which transforms the input representation into a binary representation. We formalize the training objective of the network in an intuitive and effective way, considering each training sample as a query and aiming to obtain the same retrieval results using the produced hash codes as those obtained with the original features. This training formulation directly optimizes the hashing model for the target usage of the hash codes it produces. We further explore the addition of a decoder trained to obtain an approximated reconstruction of the original features. At test time, we retrieved the most promising database samples with an efficient graph-based search procedure using only our hash codes and perform re-ranking using the reconstructed features, thus without needing to access the original features at all. Experiments conducted on multiple publicly available large-scale datasets show that our method consistently outperforms all compared state-of-the-art unsupervised hashing methods and that the reconstruction procedure can effectively boost the search accuracy with a minimal constant additional cost.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-8.299722671508789, 4.798903942108154]}, {"key": "", "year": "", "title": "Karjalainen2024fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast Redescription Mining Using Locality-Sensitive Hashing\"\nauthors: Karjalainen Maiju, Galbrun Esther, Miettinen Pauli\nconference: Arxiv\nyear: 2024\nbibkey: karjalainen2024fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2406.04148\"}\ntags: ['ARXIV']\n---\nRedescription mining is a data analysis technique that has found applications in diverse fields. The most used redescription mining approaches involve two phases: finding matching pairs among data attributes and extending the pairs. This process is relatively efficient when the number of attributes remains limited and when the attributes are Boolean, but becomes almost intractable when the data consist of many numerical attributes. In this paper, we present new algorithms that perform the matching and extension orders of magnitude faster than the existing approaches. Our algorithms are based on locality-sensitive hashing with a tailored approach to handle the discretisation of numerical attributes as used in redescription mining.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.151808738708496, -10.45080852508545]}, {"key": "", "year": "", "title": "Karunanayake2020a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Multi-modal Neural Embeddings Approach for Detecting Mobile Counterfeit Apps: A Case Study on Google Play Store\"\nauthors: Karunanayake Naveen, Rajasegaran Jathushan, Gunathillake Ashanie, Seneviratne Suranga, Jourjon Guillaume\nconference: Arxiv\nyear: 2020\nbibkey: karunanayake2020a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2006.02231\"}\ntags: ['ARXIV', 'Deep Learning']\n---\nCounterfeit apps impersonate existing popular apps in attempts to misguide users to install them for various reasons such as collecting personal information or spreading malware. Many counterfeits can be identified once installed, however even a tech-savvy user may struggle to detect them before installation. To this end, this paper proposes to leverage the recent advances in deep learning methods to create image and text embeddings so that counterfeit apps can be efficiently identified when they are submitted for publication. We show that a novel approach of combining content embeddings and style embeddings outperforms the baseline methods for image similarity such as SIFT, SURF, and various image hashing methods. We first evaluate the performance of the proposed method on two well-known datasets for evaluating image similarity methods and show that content, style, and combined embeddings increase precision@k and recall@k by 10%-15% and 12%-25%, respectively when retrieving five nearest neighbours. Second, specifically for the app counterfeit detection problem, combined content and style embeddings achieve 12% and 14% increase in precision@k and recall@k, respectively compared to the baseline methods. Third, we present an analysis of approximately 1.2 million apps from Google Play Store and identify a set of potential counterfeits for top-10,000 popular apps. Under a conservative assumption, we were able to find 2,040 potential counterfeits that contain malware in a set of 49,608 apps that showed high similarity to one of the top-10,000 popular apps in Google Play Store. We also find 1,565 potential counterfeits asking for at least five additional dangerous permissions than the original app and 1,407 potential counterfeits having at least five extra third party advertisement libraries.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-24.658723831176758, 16.4710636138916]}, {"key": "", "year": "", "title": "Kaser2012strongly", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Strongly universal string hashing is fast\"\nauthors: Kaser Owen, Lemire Daniel\nconference: Computer Journal\nyear: 2012\nbibkey: kaser2012strongly\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1202.4961\"}\ntags: ['TIP']\n---\nWe present fast strongly universal string hashing families: they can process data at a rate of 0.2 CPU cycle per byte. Maybe surprisingly, we find that these families---though they require a large buffer of random numbers---are often faster than popular hash functions with weaker theoretical guarantees. Moreover, conventional wisdom is that hash functions with fewer multiplications are faster. Yet we find that they may fail to be faster due to operation pipelining. We present experimental results on several processors including low-powered processors. Our tests include hash functions designed for processors with the Carry-Less Multiplication (CLMUL) instruction set. We also prove, using accessible proofs, the strong universality of our families.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-22.26426124572754, -11.794862747192383]}, {"key": "", "year": "", "title": "Kehl2016hashmod", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hashmod: A Hashing Method for Scalable 3D Object Detection\"\nauthors: Kehl Wadim, Tombari Federico, Navab Nassir, Ilic Slobodan, Lepetit Vincent\nconference: Arxiv\nyear: 2016\nbibkey: kehl2016hashmod\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1607.06062\"}\ntags: ['ARXIV']\n---\nWe present a scalable method for detecting objects and estimating their 3D poses in RGB-D data. To this end, we rely on an efficient representation of object views and employ hashing techniques to match these views against the input frame in a scalable way. While a similar approach already exists for 2D detection, we show how to extend it to estimate the 3D pose of the detected objects. In particular, we explore different hashing strategies and identify the one which is more suitable to our problem. We show empirically that the complexity of our method is sublinear with the number of objects and we enable detection and pose estimation of many 3D objects with high accuracy while outperforming the state-of-the-art in terms of runtime.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [21.5814208984375, 0.28460416197776794]}, {"key": "", "year": "", "title": "Keisler2020visual", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Visual search over billions of aerial and satellite images\"\nauthors: Keisler Ryan, Skillman Samuel W., Gonnabathula Sunny, Poehnelt Justin, Rudelis Xander, Warren Michael S.\nconference: Arxiv\nyear: 2020\nbibkey: keisler2020visual\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2002.02624\"}   - {name: \"Paper\", url: \"https://search.descarteslabs.com.\"}\ntags: ['ARXIV']\n---\nWe present a system for performing visual search over billions of aerial and satellite images. The purpose of visual search is to find images that are visually similar to a query image. We define visual similarity using 512 abstract visual features generated by a convolutional neural network that has been trained on aerial and satellite imagery. The features are converted to binary values to reduce data and compute requirements. We employ a hash-based search using Bigtable, a scalable database service from Google Cloud. Searching the continental United States at 1-meter pixel resolution, corresponding to approximately 2 billion images, takes approximately 0.1 seconds. This system enables real-time visual search over the surface of the earth, and an interactive demo is available at https://search.descarteslabs.com.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [19.216062545776367, -3.0845303535461426]}, {"key": "", "year": "", "title": "Kelly2019lock", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Lock-Free Hopscotch Hashing\"\nauthors: Kelly Robert, Pearlmutter Barak A., Maguire Phil\nconference: Arxiv\nyear: 2019\nbibkey: kelly2019lock\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1911.03028\"}\ntags: ['ARXIV']\n---\nIn this paper we present a lock-free version of Hopscotch Hashing. Hopscotch Hashing is an open addressing algorithm originally proposed by Herlihy, Shavit, and Tzafrir, which is known for fast performance and excellent cache locality. The algorithm allows users of the table to skip or jump over irrelevant entries, allowing quick search, insertion, and removal of entries. Unlike traditional linear probing, Hopscotch Hashing is capable of operating under a high load factor, as probe counts remain small. Our lock-free version improves on both speed, cache locality, and progress guarantees of the original, being a chimera of two concurrent hash tables. We compare our data structure to various other lock-free and blocking hashing algorithms and show that its performance is in many cases superior to existing strategies. The proposed lock-free version overcomes some of the drawbacks associated with the original blocking version, leading to a substantial boost in scalability while maintaining attractive features like physical deletion or probe-chain compression.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-25.752405166625977, -13.254890441894531]}, {"key": "", "year": "", "title": "Kennedy2016fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast Cross-Polytope Locality-Sensitive Hashing\"\nauthors: Kennedy Christopher, Ward Rachel\nconference: Arxiv\nyear: 2016\nbibkey: kennedy2016fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1602.06922\"}\ntags: ['ARXIV', 'LSH']\n---\nWe provide a variant of cross-polytope locality sensitive hashing with respect to angular distance which is provably optimal in asymptotic sensitivity and enjoys $\\mathcal\\{O\\}(d \\ln d )$ hash computation time. Building on a recent result (by Andoni, Indyk, Laarhoven, Razenshteyn, Schmidt, 2015), we show that optimal asymptotic sensitivity for cross-polytope LSH is retained even when the dense Gaussian matrix is replaced by a fast Johnson-Lindenstrauss transform followed by discrete pseudo-rotation, reducing the hash computation time from $\\mathcal\\{O\\}(d^2)$ to $\\mathcal\\{O\\}(d \\ln d )$. Moreover, our scheme achieves the optimal rate of convergence for sensitivity. By incorporating a low-randomness Johnson-Lindenstrauss transform, our scheme can be modified to require only $\\mathcal\\{O\\}(\\ln^9(d))$ random bits\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-12.009632110595703, -21.473201751708984]}, {"key": "", "year": "", "title": "Khasanova2016multi", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Multi-modal image retrieval with random walk on multi-layer graphs\"\nauthors: Khasanova Renata, Dong Xiaowen, Frossard Pascal\nconference: Arxiv\nyear: 2016\nbibkey: khasanova2016multi\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1607.03406\"}\ntags: ['ARXIV', 'Graph', 'Image Retrieval']\n---\nThe analysis of large collections of image data is still a challenging problem due to the difficulty of capturing the true concepts in visual data. The similarity between images could be computed using different and possibly multimodal features such as color or edge information or even text labels. This motivates the design of image analysis solutions that are able to effectively integrate the multi-view information provided by different feature sets. We therefore propose a new image retrieval solution that is able to sort images through a random walk on a multi-layer graph, where each layer corresponds to a different type of information about the image data. We study in depth the design of the image graph and propose in particular an effective method to select the edge weights for the multi-layer graph, such that the image ranking scores are optimised. We then provide extensive experiments in different real-world photo collections, which confirm the high performance of our new image retrieval algorithm that generally surpasses state-of-the-art solutions due to a more meaningful image similarity computation.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.482912063598633, -29.934551239013672]}, {"key": "", "year": "", "title": "Kho2018fixed", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fixed-length Bit-string Representation of Fingerprint by Normalized Local Structures\"\nauthors: Kho Jun Beom, Teoh Andrew B. J., Lee Wonjune, Kim Jaihie\nconference: Arxiv\nyear: 2018\nbibkey: kho2018fixed\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1811.11489\"}\ntags: ['ARXIV']\n---\nIn this paper, we propose a method to represent a fingerprint image by an ordered, fixed-length bit-string providing improved accuracy performance, faster matching time and compressibility. First, we devise a novel minutia-based local structure modeled by a mixture of 2D elliptical Gaussian functions in the pixel space. Each local structure is mapped to the Euclidean space by normalizing the local structure with the number of minutiae that associates to it. This simple yet crucial crux enables fast dissimilarity computation of two local structures with Euclidean distance without distortion. A complementary texture-based local structure to the minutia-based local structure is also introduced whereby both can be compressed via principal component analysis and fused easily in the Euclidean space. The fused local structure is then converted to a K-bit ordered string via a K-means clustering algorithm. This chain of computation with sole use of Euclidean distance is vital for speedy and discriminative bit-string conversion. The accuracy can be further improved by a finger-specific bit-training algorithm in which two criteria are leveraged to select useful bit positions for matching. Experiments are performed on Fingerprint Verification Competition (FVC) databases for comparison with existing techniques to show the superiority of the proposed method.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [8.618791580200195, -0.03337956219911575]}, {"key": "", "year": "", "title": "Khrulkov2019hyperbolic", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hyperbolic Image Embeddings\"\nauthors: Khrulkov Valentin, Mirvakhabova Leyla, Ustinova Evgeniya, Oseledets Ivan, Lempitsky Victor\nconference: Arxiv\nyear: 2019\nbibkey: khrulkov2019hyperbolic\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1904.02239\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nComputer vision tasks such as image classification, image retrieval and few-shot learning are currently dominated by Euclidean and spherical embeddings, so that the final decisions about class belongings or the degree of similarity are made using linear hyperplanes, Euclidean distances, or spherical geodesic distances (cosine similarity). In this work, we demonstrate that in many practical scenarios hyperbolic embeddings provide a better alternative.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [28.691234588623047, 1.5364118814468384]}, {"key": "", "year": "", "title": "Kim2015bilinear", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Bilinear Random Projections for Locality-Sensitive Binary Codes\"\nauthors: Kim Saehoon, Choi Seungjin\nconference: Arxiv\nyear: 2015\nbibkey: kim2015bilinear\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1506.01092\"}\ntags: ['ARXIV', 'LSH', 'Quantisation']\n---\nLocality-sensitive hashing (LSH) is a popular data-independent indexing method for approximate similarity search, where random projections followed by quantization hash the points from the database so as to ensure that the probability of collision is much higher for objects that are close to each other than for those that are far apart. Most of high-dimensional visual descriptors for images exhibit a natural matrix structure. When visual descriptors are represented by high-dimensional feature vectors and long binary codes are assigned, a random projection matrix requires expensive complexities in both space and time. In this paper we analyze a bilinear random projection method where feature matrices are transformed to binary codes by two smaller random projection matrices. We base our theoretical analysis on extending Raginsky and Lazebnik's result where random Fourier features are composed with random binary quantizers to form locality sensitive binary codes. To this end, we answer the following two questions: (1) whether a bilinear random projection also yields similarity-preserving binary codes; (2) whether a bilinear random projection yields performance gain or loss, compared to a large linear projection. Regarding the first question, we present upper and lower bounds on the expected Hamming distance between binary codes produced by bilinear random projections. In regards to the second question, we analyze the upper and lower bounds on covariance between two bits of binary codes, showing that the correlation between two bits is small. Numerical experiments on MNIST and Flickr45K datasets confirm the validity of our method.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-7.677270412445068, -23.76679229736328]}, {"key": "", "year": "", "title": "Kim2019nearest", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Nearest Neighbor Search-Based Bitwise Source Separation Using Discriminant Winner-Take-All Hashing\"\nauthors: Kim Sunwoo, Kim Minje\nconference: Arxiv\nyear: 2019\nbibkey: kim2019nearest\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1908.09799\"}\ntags: ['ACL', 'ARXIV']\n---\nWe propose an iteration-free source separation algorithm based on Winner-Take-All (WTA) hash codes, which is a faster, yet accurate alternative to a complex machine learning model for single-channel source separation in a resource-constrained environment. We first generate random permutations with WTA hashing to encode the shape of the multidimensional audio spectrum to a reduced bitstring representation. A nearest neighbor search on the hash codes of an incoming noisy spectrum as the query string results in the closest matches among the hashed mixture spectra. Using the indices of the matching frames, we obtain the corresponding ideal binary mask vectors for denoising. Since both the training data and the search operation are bitwise, the procedure can be done efficiently in hardware implementations. Experimental results show that the WTA hash codes are discriminant and provide an affordable dictionary search mechanism that leads to a competent performance compared to a comprehensive model and oracle masking.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-4.256521224975586, -8.710896492004395]}, {"key": "", "year": "", "title": "Kim2022improving", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Improving Cross-Modal Retrieval with Set of Diverse Embeddings\"\nauthors: Kim Dongwon, Kim Namyup, Kwak Suha\nconference: Arxiv\nyear: 2022\nbibkey: kim2022improving\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2211.16761\"}\ntags: ['ARXIV', 'Cross Modal']\n---\nCross-modal retrieval across image and text modalities is a challenging task due to its inherent ambiguity: An image often exhibits various situations, and a caption can be coupled with diverse images. Set-based embedding has been studied as a solution to this problem. It seeks to encode a sample into a set of different embedding vectors that capture different semantics of the sample. In this paper, we present a novel set-based embedding method, which is distinct from previous work in two aspects. First, we present a new similarity function called smooth-Chamfer similarity, which is designed to alleviate the side effects of existing similarity functions for set-based embedding. Second, we propose a novel set prediction module to produce a set of embedding vectors that effectively captures diverse semantics of input by the slot attention mechanism. Our method is evaluated on the COCO and Flickr30K datasets across different visual backbones, where it outperforms existing methods including ones that demand substantially larger computation at inference.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [18.598806381225586, 3.3493945598602295]}, {"key": "", "year": "", "title": "Kim2024lycon", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"LyCon: Lyrics Reconstruction from the Bag-of-Words Using Large Language Models\"\nauthors: Kim Haven, Choi Kahyun\nconference: Arxiv\nyear: 2024\nbibkey: kim2024lycon\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2408.14750\"}\ntags: ['ARXIV']\n---\nThis paper addresses the unique challenge of conducting research in lyric studies, where direct use of lyrics is often restricted due to copyright concerns. Unlike typical data, internet-sourced lyrics are frequently protected under copyright law, necessitating alternative approaches. Our study introduces a novel method for generating copyright-free lyrics from publicly available Bag-of-Words (BoW) datasets, which contain the vocabulary of lyrics but not the lyrics themselves. Utilizing metadata associated with BoW datasets and large language models, we successfully reconstructed lyrics. We have compiled and made available a dataset of reconstructed lyrics, LyCon, aligned with metadata from renowned sources including the Million Song Dataset, Deezer Mood Detection Dataset, and AllMusic Genre Dataset, available for public access. We believe that the integration of metadata such as mood annotations or genres enables a variety of academic experiments on lyrics, such as conditional lyric generation.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [29.619230270385742, -5.5381669998168945]}, {"key": "", "year": "", "title": "Klassen2011independence", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Independence of Tabulation-Based Hash Classes\"\nauthors: Klassen Toryn Qwyllyn, Woelfel Philipp\nconference: Arxiv\nyear: 2011\nbibkey: klassen2011independence\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1112.3323\"}\ntags: ['ARXIV']\n---\nA tabulation-based hash function maps a key into d derived characters indexing random values in tables that are then combined with bitwise xor operations to give the hash. Thorup and Zhang (2004) presented d-wise independent tabulation-based hash classes that use linear maps over finite fields to map a key, considered as a vector (a,b), to derived characters. We show that a variant where the derived characters are a+b*i for i=0,..., q-1 (using integer arithmetic) yielding (2d-1)-wise independence. Our analysis is based on an algebraic property that characterizes k-wise independence of tabulation-based hashing schemes, and combines this characterization with a geometric argument. We also prove a non-trivial lower bound on the number of derived characters necessary for k-wise independence with our and related hash classes.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-26.687856674194336, -3.585635185241699]}, {"key": "", "year": "", "title": "Klein2015a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A conditional Berry-Esseen bound and a conditional large deviation result without Laplace transform. Application to hashing with linear probing\"\nauthors: Klein Thierry, Lagnoux Agn\u00e8s, Petit Pierre\nconference: Arxiv\nyear: 2015\nbibkey: klein2015a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1503.08848\"}\ntags: ['ARXIV']\n---\n\\noindent We study the asymptotic behavior of a sum of independent and identically distributed random variables conditioned by a sum of independent and identically distributed integer-valued random variables. We prove a Berry-Esseen bound in a general setting and a large deviation result when the Laplace transform of the underlying distribution is not defined in a neighborhood of zero. Then we present several combinatorial applications. In particular, we prove a large deviation result for the model of hashing with linear probing.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-32.46229553222656, -8.389237403869629]}, {"key": "", "year": "", "title": "Klein2017end", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"End-to-End Supervised Product Quantization for Image Search and Retrieval\"\nauthors: Klein Benjamin, Wolf Lior\nconference: Arxiv\nyear: 2017\nbibkey: klein2017end\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1711.08589\"}\ntags: ['ARXIV', 'Quantisation', 'Supervised', 'Unsupervised']\n---\nProduct Quantization, a dictionary based hashing method, is one of the leading unsupervised hashing techniques. While it ignores the labels, it harnesses the features to construct look up tables that can approximate the feature space. In recent years, several works have achieved state of the art results on hashing benchmarks by learning binary representations in a supervised manner. This work presents Deep Product Quantization (DPQ), a technique that leads to more accurate retrieval and classification than the latest state of the art methods, while having similar computational complexity and memory footprint as the Product Quantization method. To our knowledge, this is the first work to introduce a dictionary-based representation that is inspired by Product Quantization and which is learned end-to-end, and thus benefits from the supervised signal. DPQ explicitly learns soft and hard representations to enable an efficient and accurate asymmetric search, by using a straight-through estimator. Our method obtains state of the art results on an extensive array of retrieval and classification experiments.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-8.825644493103027, 15.253181457519531]}, {"key": "", "year": "", "title": "Klein2021learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning Query Expansion over the Nearest Neighbor Graph\"\nauthors: Klein Benjamin, Wolf Lior\nconference: Arxiv\nyear: 2021\nbibkey: klein2021learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2112.02666\"}\ntags: ['ARXIV', 'Graph', 'Supervised']\n---\nQuery Expansion (QE) is a well established method for improving retrieval metrics in image search applications. When using QE, the search is conducted on a new query vector, constructed using an aggregation function over the query and images from the database. Recent works gave rise to QE techniques in which the aggregation function is learned, whereas previous techniques were based on hand-crafted aggregation functions, e.g., taking the mean of the query's nearest neighbors. However, most QE methods have focused on aggregation functions that work directly over the query and its immediate nearest neighbors. In this work, a hierarchical model, Graph Query Expansion (GQE), is presented, which is learned in a supervised manner and performs aggregation over an extended neighborhood of the query, thus increasing the information used from the database when computing the query expansion, and using the structure of the nearest neighbors graph. The technique achieves state-of-the-art results over known benchmarks.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.579056739807129, -26.768918991088867]}, {"key": "", "year": "", "title": "Knudsen2015quicksort", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Quicksort, Largest Bucket, and Min-Wise Hashing with Limited Independence\"\nauthors: Knudsen Mathias B\u00e6k Tejs, St\u00f6ckel Morten\nconference: Arxiv\nyear: 2015\nbibkey: knudsen2015quicksort\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1502.05729\"}\ntags: ['ARXIV']\n---\nRandomized algorithms and data structures are often analyzed under the assumption of access to a perfect source of randomness. The most fundamental metric used to measure how \"random\" a hash function or a random number generator is, is its independence: a sequence of random variables is said to be $k$-independent if every variable is uniform and every size $k$ subset is independent. In this paper we consider three classic algorithms under limited independence. We provide new bounds for randomized quicksort, min-wise hashing and largest bucket size under limited independence. Our results can be summarized as follows. -Randomized quicksort. When pivot elements are computed using a $5$-independent hash function, Karloff and Raghavan, J.ACM'93 showed $O ( n \\log n)$ expected worst-case running time for a special version of quicksort. We improve upon this, showing that the same running time is achieved with only $4$-independence. -Min-wise hashing. For a set $A$, consider the probability of a particular element being mapped to the smallest hash value. It is known that $5$-independence implies the optimal probability $O (1 /n)$. Broder et al., STOC'98 showed that $2$-independence implies it is $O(1 / \\sqrt\\{|A|\\})$. We show a matching lower bound as well as new tight bounds for $3$- and $4$-independent hash functions. -Largest bucket. We consider the case where $n$ balls are distributed to $n$ buckets using a $k$-independent hash function and analyze the largest bucket size. Alon et. al, STOC'97 showed that there exists a $2$-independent hash function implying a bucket of size $\\Omega ( n^\\{1/2\\})$. We generalize the bound, providing a $k$-independent family of functions that imply size $\\Omega ( n^\\{1/k\\})$.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-15.87542724609375, -20.6562557220459]}, {"key": "", "year": "", "title": "Knudsen2017linear", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Linear Hashing is Awesome\"\nauthors: Knudsen Mathias B\u00e6k Tejs\nconference: Arxiv\nyear: 2017\nbibkey: knudsen2017linear\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1706.02783\"}\ntags: ['ARXIV', 'TIP']\n---\nWe consider the hash function $h(x) = ((ax+b) \\bmod p) \\bmod n$ where $a,b$ are chosen uniformly at random from $\\\\{0,1,\\ldots,p-1\\\\}$. We prove that when we use $h(x)$ in hashing with chaining to insert $n$ elements into a table of size $n$ the expected length of the longest chain is $\\tilde\\{O\\}\\!\\left(n^\\{1/3\\}\\right)$. The proof also generalises to give the same bound when we use the multiply-shift hash function by Dietzfelbinger et al. [Journal of Algorithms 1997].\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-28.261640548706055, -5.814858913421631]}, {"key": "", "year": "", "title": "Knuth1998linear", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Linear probing and graphs\"\nauthors: Knuth Donald E.\nconference: Algorithmica\nyear: 1998\nbibkey: knuth1998linear\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/cs/9801103\"}\ntags: ['Graph']\n---\nMallows and Riordan showed in 1968 that labeled trees with a small number of inversions are related to labeled graphs that are connected and sparse. Wright enumerated sparse connected graphs in 1977, and Kreweras related the inversions of trees to the so-called ``parking problem'' in 1980. A~combination of these three results leads to a surprisingly simple analysis of the behavior of hashing by linear probing, including higher moments of the cost of successful search.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [7.379820346832275, -31.648494720458984]}, {"key": "", "year": "", "title": "Ko2019a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Benchmark on Tricks for Large-scale Image Retrieval\"\nauthors: Ko Byungsoo, Shin Minchul, Gu Geonmo, Jun HeeJae, Lee Tae Kwan, Kim Youngjoon\nconference: Arxiv\nyear: 2019\nbibkey: ko2019a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1907.11854\"}\ntags: ['ARXIV', 'Deep Learning', 'Image Retrieval']\n---\nMany studies have been performed on metric learning, which has become a key ingredient in top-performing methods of instance-level image retrieval. Meanwhile, less attention has been paid to pre-processing and post-processing tricks that can significantly boost performance. Furthermore, we found that most previous studies used small scale datasets to simplify processing. Because the behavior of a feature representation in a deep learning model depends on both domain and data, it is important to understand how model behave in large-scale environments when a proper combination of retrieval tricks is used. In this paper, we extensively analyze the effect of well-known pre-processing, post-processing tricks, and their combination for large-scale image retrieval. We found that proper use of these tricks can significantly improve model performance without necessitating complex architecture or introducing loss, as confirmed by achieving a competitive result on the Google Landmark Retrieval Challenge 2019.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [9.106298446655273, 20.285423278808594]}, {"key": "", "year": "", "title": "Ko2021low", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Low-Precision Quantization for Efficient Nearest Neighbor Search\"\nauthors: Ko Anthony, Keivanloo Iman, Lakshman Vihan, Schkufza Eric\nconference: Arxiv\nyear: 2021\nbibkey: ko2021low\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2110.08919\"}\ntags: ['ARXIV', 'Quantisation', 'TIP']\n---\nFast k-Nearest Neighbor search over real-valued vector spaces (KNN) is an important algorithmic task for information retrieval and recommendation systems. We present a method for using reduced precision to represent vectors through quantized integer values, enabling both a reduction in the memory overhead of indexing these vectors and faster distance computations at query time. While most traditional quantization techniques focus on minimizing the reconstruction error between a point and its uncompressed counterpart, we focus instead on preserving the behavior of the underlying distance metric. Furthermore, our quantization approach is applied at the implementation level and can be combined with existing KNN algorithms. Our experiments on both open source and proprietary datasets across multiple popular KNN frameworks validate that quantized distance metrics can reduce memory by 60% and improve query throughput by 30%, while incurring only a 2% reduction in recall.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [0.4944111406803131, -15.69894027709961]}, {"key": "", "year": "", "title": "Kodali2022hashset", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"HashSet -- A Dataset For Hashtag Segmentation\"\nauthors: Kodali Prashant, Bhatnagar Akshala, Ahuja Naman, Shrivastava Manish, Kumaraguru Ponnurangam\nconference: Arxiv\nyear: 2022\nbibkey: kodali2022hashset\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2201.06741\"}\ntags: ['ARXIV', 'Supervised']\n---\nHashtag segmentation is the task of breaking a hashtag into its constituent tokens. Hashtags often encode the essence of user-generated posts, along with information like topic and sentiment, which are useful in downstream tasks. Hashtags prioritize brevity and are written in unique ways -- transliterating and mixing languages, spelling variations, creative named entities. Benchmark datasets used for the hashtag segmentation task -- STAN, BOUN -- are small in size and extracted from a single set of tweets. However, datasets should reflect the variations in writing styles of hashtags and also account for domain and language specificity, failing which the results will misrepresent model performance. We argue that model performance should be assessed on a wider variety of hashtags, and datasets should be carefully curated. To this end, we propose HashSet, a dataset comprising of: a) 1.9k manually annotated dataset; b) 3.3M loosely supervised dataset. HashSet dataset is sampled from a different set of tweets when compared to existing datasets and provides an alternate distribution of hashtags to build and validate hashtag segmentation models. We show that the performance of SOTA models for Hashtag Segmentation drops substantially on proposed dataset, indicating that the proposed dataset provides an alternate set of hashtags to train and assess models.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-25.76779556274414, 7.7604498863220215]}, {"key": "", "year": "", "title": "Komorowski2017evaluation", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Evaluation of Hashing Methods Performance on Binary Feature Descriptors\"\nauthors: Komorowski Jacek, Trzcinski Tomasz\nconference: Arxiv\nyear: 2017\nbibkey: komorowski2017evaluation\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1707.06825\"}\ntags: ['ARXIV', 'Semi Supervised', 'Supervised', 'Unsupervised']\n---\nIn this paper we evaluate performance of data-dependent hashing methods on binary data. The goal is to find a hashing method that can effectively produce lower dimensional binary representation of 512-bit FREAK descriptors. A representative sample of recent unsupervised, semi-supervised and supervised hashing methods was experimentally evaluated on large datasets of labelled binary FREAK feature descriptors.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-11.948837280273438, 16.600887298583984]}, {"key": "", "year": "", "title": "Komorowski2017random", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Random Binary Trees for Approximate Nearest Neighbour Search in Binary Space\"\nauthors: Komorowski Michal, Trzcinski Tomasz\nconference: Arxiv\nyear: 2017\nbibkey: komorowski2017random\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1708.02976\"}\ntags: ['ARXIV', 'LSH']\n---\nApproximate nearest neighbour (ANN) search is one of the most important problems in computer science fields such as data mining or computer vision. In this paper, we focus on ANN for high-dimensional binary vectors and we propose a simple yet powerful search method that uses Random Binary Search Trees (RBST). We apply our method to a dataset of 1.25M binary local feature descriptors obtained from a real-life image-based localisation system provided by Google as a part of Project Tango. An extensive evaluation of our method against the state-of-the-art variations of Locality Sensitive Hashing (LSH), namely Uniform LSH and Multi-probe LSH, shows the superiority of our method in terms of retrieval precision with performance boost of over 20%\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [8.633437156677246, -13.391631126403809]}, {"key": "", "year": "", "title": "Kong2016coarse2fine", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Coarse2Fine: Two-Layer Fusion For Image Retrieval\"\nauthors: Kong Gaipeng, Dong Le, Dong Wenpu, Zheng Liang, Tian Qi\nconference: Arxiv\nyear: 2016\nbibkey: kong2016coarse2fine\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1607.00719\"}\ntags: ['ARXIV', 'Image Retrieval', 'TIP']\n---\nThis paper addresses the problem of large-scale image retrieval. We propose a two-layer fusion method which takes advantage of global and local cues and ranks database images from coarse to fine (C2F). Departing from the previous methods fusing multiple image descriptors simultaneously, C2F is featured by a layered procedure composed by filtering and refining. In particular, C2F consists of three components. 1) Distractor filtering. With holistic representations, noise images are filtered out from the database, so the number of candidate images to be used for comparison with the query can be greatly reduced. 2) Adaptive weighting. For a certain query, the similarity of candidate images can be estimated by holistic similarity scores in complementary to the local ones. 3) Candidate refining. Accurate retrieval is conducted via local features, combining the pre-computed adaptive weights. Experiments are presented on two benchmarks, \\emph{i.e.,} Holidays and Ukbench datasets. We show that our method outperforms recent fusion methods in terms of storage consumption and computation complexity, and that the accuracy is competitive to the state-of-the-arts.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [20.42185401916504, 17.711490631103516]}, {"key": "", "year": "", "title": "Konoshima2012hyperplane", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hyperplane Arrangements and Locality-Sensitive Hashing with Lift\"\nauthors: Konoshima Makiko, Noma Yui\nconference: Arxiv\nyear: 2012\nbibkey: konoshima2012hyperplane\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1212.6110\"}\ntags: ['ARXIV']\n---\nLocality-sensitive hashing converts high-dimensional feature vectors, such as image and speech, into bit arrays and allows high-speed similarity calculation with the Hamming distance. There is a hashing scheme that maps feature vectors to bit arrays depending on the signs of the inner products between feature vectors and the normal vectors of hyperplanes placed in the feature space. This hashing can be seen as a discretization of the feature space by hyperplanes. If labels for data are given, one can determine the hyperplanes by using learning algorithms. However, many proposed learning methods do not consider the hyperplanes' offsets. Not doing so decreases the number of partitioned regions, and the correlation between Hamming distances and Euclidean distances becomes small. In this paper, we propose a lift map that converts learning algorithms without the offsets to the ones that take into account the offsets. With this method, the learning methods without the offsets give the discretizations of spaces as if it takes into account the offsets. For the proposed method, we input several high-dimensional feature data sets and studied the relationship between the statistical characteristics of data, the number of hyperplanes, and the effect of the proposed method.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [10.92611026763916, -0.6834675669670105]}, {"key": "", "year": "", "title": "Konoshima2012locality", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Locality-Sensitive Hashing with Margin Based Feature Selection\"\nauthors: Konoshima Makiko, Noma Yui\nconference: Arxiv\nyear: 2012\nbibkey: konoshima2012locality\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1209.5833\"}\ntags: ['ARXIV']\n---\nWe propose a learning method with feature selection for Locality-Sensitive Hashing. Locality-Sensitive Hashing converts feature vectors into bit arrays. These bit arrays can be used to perform similarity searches and personal authentication. The proposed method uses bit arrays longer than those used in the end for similarity and other searches and by learning selects the bits that will be used. We demonstrated this method can effectively perform optimization for cases such as fingerprint images with a large number of labels and extremely few data that share the same labels, as well as verifying that it is also effective for natural images, handwritten digits, and speech features.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [2.628591299057007, -10.181268692016602]}, {"key": "", "year": "", "title": "Korfhage2023elastichash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"ElasticHash: Semantic Image Similarity Search by Deep Hashing with Elasticsearch\"\nauthors: Korfhage Nikolaus, M\u00fchling Markus, Freisleben Bernd\nconference: The\nyear: 2023\nbibkey: korfhage2023elastichash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2305.04710\"}\ntags: []\n---\nWe present ElasticHash, a novel approach for high-quality, efficient, and large-scale semantic image similarity search. It is based on a deep hashing model to learn hash codes for fine-grained image similarity search in natural images and a two-stage method for efficiently searching binary hash codes using Elasticsearch (ES). In the first stage, a coarse search based on short hash codes is performed using multi-index hashing and ES terms lookup of neighboring hash codes. In the second stage, the list of results is re-ranked by computing the Hamming distance on long hash codes. We evaluate the retrieval performance of \\textit{ElasticHash} for more than 120,000 query images on about 6.9 million database images of the OpenImages data set. The results show that our approach achieves high-quality retrieval results and low search latencies.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [3.2669386863708496, -0.3508552610874176]}, {"key": "", "year": "", "title": "Korytkowski2015bag", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Bag-of-Features Image Indexing and Classification in Microsoft SQL Server Relational Database\"\nauthors: Korytkowski Marcin, Scherer Rafal, Staszewski Pawel, Woldan Piotr\nconference: Arxiv\nyear: 2015\nbibkey: korytkowski2015bag\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1506.07950\"}\ntags: ['ARXIV']\n---\nThis paper presents a novel relational database architecture aimed to visual objects classification and retrieval. The framework is based on the bag-of-features image representation model combined with the Support Vector Machine classification and is integrated in a Microsoft SQL Server database.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [32.60264587402344, 4.926049709320068]}, {"key": "", "year": "", "title": "Korzeniowski2021artist", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Artist Similarity with Graph Neural Networks\"\nauthors: Korzeniowski Filip, Oramas Sergio, Gouyon Fabien\nconference: Arxiv\nyear: 2021\nbibkey: korzeniowski2021artist\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2107.14541\"}\ntags: ['ARXIV', 'GAN', 'Graph']\n---\nArtist similarity plays an important role in organizing, understanding, and subsequently, facilitating discovery in large collections of music. In this paper, we present a hybrid approach to computing similarity between artists using graph neural networks trained with triplet loss. The novelty of using a graph neural network architecture is to combine the topology of a graph of artist connections with content features to embed artists into a vector space that encodes similarity. To evaluate the proposed method, we compile the new OLGA dataset, which contains artist similarities from AllMusic, together with content features from AcousticBrainz. With 17,673 artists, this is the largest academic artist similarity dataset that includes content-based features to date. Moreover, we also showcase the scalability of our approach by experimenting with a much larger proprietary dataset. Results show the superiority of the proposed approach over current state-of-the-art methods for music similarity. Finally, we hope that the OLGA dataset will facilitate research on data-driven models for artist similarity.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [28.944515228271484, -9.67680835723877]}, {"key": "", "year": "", "title": "Koutaki2016fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast Supervised Discrete Hashing and its Analysis\"\nauthors: Koutaki Gou, Shirai Keiichiro, Ambai Mitsuru\nconference: Arxiv\nyear: 2016\nbibkey: koutaki2016fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1611.10017\"}\ntags: ['ARXIV', 'Image Retrieval', 'Quantisation', 'Supervised']\n---\nIn this paper, we propose a learning-based supervised discrete hashing method. Binary hashing is widely used for large-scale image retrieval as well as video and document searches because the compact representation of binary code is essential for data storage and reasonable for query searches using bit-operations. The recently proposed Supervised Discrete Hashing (SDH) efficiently solves mixed-integer programming problems by alternating optimization and the Discrete Cyclic Coordinate descent (DCC) method. We show that the SDH model can be simplified without performance degradation based on some preliminary experiments; we call the approximate model for this the \"Fast SDH\" (FSDH) model. We analyze the FSDH model and provide a mathematically exact solution for it. In contrast to SDH, our model does not require an alternating optimization algorithm and does not depend on initial values. FSDH is also easier to implement than Iterative Quantization (ITQ). Experimental results involving a large-scale database showed that FSDH outperforms conventional SDH in terms of precision, recall, and computation time.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-17.751802444458008, -4.309558391571045]}, {"key": "", "year": "", "title": "Kraus2015nearbucket", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"NearBucket-LSH: Efficient Similarity Search in P2P Networks\"\nauthors: Kraus Naama, Carmel David, Keidar Idit, Orenbach Meni\nconference: Arxiv\nyear: 2015\nbibkey: kraus2015nearbucket\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1511.07148\"}\ntags: ['ARXIV', 'GAN', 'LSH']\n---\nWe present NearBucket-LSH, an effective algorithm for similarity search in large-scale distributed online social networks organized as peer-to-peer overlays. As communication is a dominant consideration in distributed systems, we focus on minimizing the network cost while guaranteeing good search quality. Our algorithm is based on Locality Sensitive Hashing (LSH), which limits the search to collections of objects, called buckets, that have a high probability to be similar to the query. More specifically, NearBucket-LSH employs an LSH extension that searches in near buckets, and improves search quality but also significantly increases the network cost. We decrease the network cost by considering the internals of both LSH and the P2P overlay, and harnessing their properties to our needs. We show that our NearBucket-LSH increases search quality for a given network cost compared to previous art. In many cases, the search quality increases by more than 50%.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [3.1840012073516846, -23.26906967163086]}, {"key": "", "year": "", "title": "Krishna2019video", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Video Segment Copy Detection Using Memory Constrained Hierarchical Batch-Normalized LSTM Autoencoder\"\nauthors: Krishna Arjun, Ibrahim A S Akil Arif\nconference: Arxiv\nyear: 2019\nbibkey: krishna2019video\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1911.09518\"}\ntags: ['ARXIV', 'Deep Learning']\n---\nIn this report, we introduce a video hashing method for scalable video segment copy detection. The objective of video segment copy detection is to find the video (s) present in a large database, one of whose segments (cropped in time) is a (transformed) copy of the given query video. This transformation may be temporal (for example frame dropping, change in frame rate) or spatial (brightness and contrast change, addition of noise etc.) in nature although the primary focus of this report is detecting temporal attacks. The video hashing method proposed by us uses a deep learning neural network to learn variable length binary hash codes for the entire video considering both temporal and spatial features into account. This is in contrast to most existing video hashing methods, as they use conventional image hashing techniques to obtain hash codes for a video after extracting features for every frame or certain key frames, in which case the temporal information present in the video is not exploited. Our hashing method is specifically resilient to time cropping making it extremely useful in video segment copy detection. Experimental results obtained on the large augmented dataset consisting of around 25,000 videos with segment copies demonstrate the efficacy of our proposed video hashing method.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-0.09864380955696106, 27.87177276611328]}, {"key": "", "year": "", "title": "Kr\u010d\u00e1l2021hierarchical", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hierarchical Bitmap Indexing for Range and Membership Queries on Multidimensional Arrays\"\nauthors: Kr\u010d\u00e1l Lubo\u0161, Ho Shen-Shyang, Holub Jan\nconference: Arxiv\nyear: 2021\nbibkey: kr\u010d\u00e1l2021hierarchical\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2108.13735\"}\ntags: ['ARXIV']\n---\nTraditional indexing techniques commonly employed in da\\-ta\\-ba\\-se systems perform poorly on multidimensional array scientific data. Bitmap indices are widely used in commercial databases for processing complex queries, due to their effective use of bit-wise operations and space-efficiency. However, bitmap indices apply natively to relational or linearized datasets, which is especially notable in binned or compressed indices. We propose a new method for multidimensional array indexing that overcomes the dimensionality-induced inefficiencies. The hierarchical indexing method is based on $n$-di\\-men\\-sional sparse trees for dimension partitioning, with bound number of individual, adaptively binned indices for attribute partitioning. This indexing performs well on range involving both dimensions and attributes, as it prunes the search space early, avoids reading entire index data, and does at most a single index traversal. Moreover, the indexing is easily extensible to membership queries. The indexing method was implemented on top of a state of the art bitmap indexing library Fastbit. We show that the hierarchical bitmap index outperforms conventional bitmap indexing built on auxiliary attribute for each dimension. Furthermore, the adaptive binning significantly reduces the amount of bins and therefore memory requirements.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-1.5266071557998657, -17.832738876342773]}, {"key": "", "year": "", "title": "Kulkarni2016similarity", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Similarity preserving compressions of high dimensional sparse data\"\nauthors: Kulkarni Raghav, Pratap Rameshwar\nconference: Arxiv\nyear: 2016\nbibkey: kulkarni2016similarity\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1612.06057\"}\ntags: ['ARXIV']\n---\nThe rise of internet has resulted in an explosion of data consisting of millions of articles, images, songs, and videos. Most of this data is high dimensional and sparse. The need to perform an efficient search for similar objects in such high dimensional big datasets is becoming increasingly common. Even with the rapid growth in computing power, the brute-force search for such a task is impractical and at times impossible. Therefore it is quite natural to investigate the techniques that compress the dimension of the data-set while preserving the similarity between data objects. In this work, we propose an efficient compression scheme mapping binary vectors into binary vectors and simultaneously preserving Hamming distance and Inner Product. The length of our compression depends only on the sparsity and is independent of the dimension of the data. Moreover our schemes provide one-shot solution for Hamming distance and Inner Product, and work in the streaming setting as well. In contrast with the \"local projection\" strategies used by most of the previous schemes, our scheme combines (using sparsity) the following two strategies: $1.$ Partitioning the dimensions into several buckets, $2.$ Then obtaining \"global linear summaries\" in each of these buckets. We generalize our scheme for real-valued data and obtain compressions for Euclidean distance, Inner Product, and $k$-way Inner Product.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-9.97469425201416, -10.018631935119629]}, {"key": "", "year": "", "title": "Kumar2018automatic", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Automatic Feature Weight Determination using Indexing and Pseudo-Relevance Feedback for Multi-feature Content-Based Image Retrieval\"\nauthors: Kumar Asheet, Choudhary Shivam, Khokhar Vaibhav Singh, Meena Vikas, Chattopadhyay Chiranjoy\nconference: Arxiv\nyear: 2018\nbibkey: kumar2018automatic\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1812.04215\"}\ntags: ['ARXIV', 'Image Retrieval', 'TOM']\n---\nContent-based image retrieval (CBIR) is one of the most active research areas in multimedia information retrieval. Given a query image, the task is to search relevant images in a repository. Low level features like color, texture, and shape feature vectors of an image are always considered to be an important attribute in CBIR system. Thus the performance of the CBIR system can be enhanced by combining these feature vectors. In this paper, we propose a novel CBIR framework by applying to index using multiclass SVM and finding the appropriate weights of the individual features automatically using the relevance ratio and mean difference. We have taken four feature descriptors to represent color, texture and shape features. During retrieval, feature vectors of query image are combined, weighted and compared with feature vectors of images in the database to rank order the results. Experiments were performed on four benchmark datasets and performance is compared with existing techniques to validate the superiority of our proposed framework.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [22.750272750854492, 10.756406784057617]}, {"key": "", "year": "", "title": "Kumar2018deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Barcodes for Fast Retrieval of Histopathology Scans\"\nauthors: Kumar Meghana Dinesh, Babaie Morteza, Tizhoosh Hamid\nconference: Arxiv\nyear: 2018\nbibkey: kumar2018deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1805.08833\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nWe investigate the concept of deep barcodes and propose two methods to generate them in order to expedite the process of classification and retrieval of histopathology images. Since binary search is computationally less expensive, in terms of both speed and storage, deep barcodes could be useful when dealing with big data retrieval. Our experiments use the dataset Kimia Path24 to test three pre-trained networks for image retrieval. The dataset consists of 27,055 training images in 24 different classes with large variability, and 1,325 test images for testing. Apart from the high-speed and efficiency, results show a surprising retrieval accuracy of 71.62% for deep barcodes, as compared to 68.91% for deep features and 68.53% for compressed deep features.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [14.666606903076172, -0.03941866010427475]}, {"key": "", "year": "", "title": "Kumar2019from", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"From Fully Supervised to Zero Shot Settings for Twitter Hashtag Recommendation\"\nauthors: Kumar Abhay, Jain Nishant, Tripathi Suraj, Singh Chirag\nconference: Arxiv\nyear: 2019\nbibkey: kumar2019from\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1906.04914\"}\ntags: ['ARXIV', 'CNN', 'Deep Learning', 'Supervised']\n---\nWe propose a comprehensive end-to-end pipeline for Twitter hashtags recommendation system including data collection, supervised training setting and zero shot training setting. In the supervised training setting, we have proposed and compared the performance of various deep learning architectures, namely Convolutional Neural Network (CNN), Recurrent Neural Network (RNN) and Transformer Network. However, it is not feasible to collect data for all possible hashtag labels and train a classifier model on them. To overcome this limitation, we propose a Zero Shot Learning (ZSL) paradigm for predicting unseen hashtag labels by learning the relationship between the semantic space of tweets and the embedding space of hashtag labels. We evaluated various state-of-the-art ZSL methods like Convex combination of Semantic Embedding (ConSE), Embarrassingly Simple Zero-Shot Learning (ESZSL) and Deep Embedding Model for Zero-Shot Learning (DEM-ZSL) for the hashtag recommendation task. We demonstrate the effectiveness and scalability of ZSL methods for the recommendation of unseen hashtags. To the best of our knowledge, this is the first quantitative evaluation of ZSL methods to date for unseen hashtags recommendations from tweet text.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-13.758907318115234, 20.023771286010742]}, {"key": "", "year": "", "title": "Kume2021development", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Development of Semantic Web-based Imaging Database for Biological Morphome\"\nauthors: Kume Satoshi, Masuya Hiroshi, Maeda Mitsuyo, Suga Mitsuo, Kataoka Yosky, Kobayashi Norio\nconference: JIST\nyear: 2021\nbibkey: kume2021development\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2110.12058\"}\ntags: ['Graph', 'TOM']\n---\nWe introduce the RIKEN Microstructural Imaging Metadatabase, a semantic web-based imaging database in which image metadata are described using the Resource Description Framework (RDF) and detailed biological properties observed in the images can be represented as Linked Open Data. The metadata are used to develop a large-scale imaging viewer that provides a straightforward graphical user interface to visualise a large microstructural tiling image at the gigabyte level. We applied the database to accumulate comprehensive microstructural imaging data produced by automated scanning electron microscopy. As a result, we have successfully managed vast numbers of images and their metadata, including the interpretation of morphological phenotypes occurring in sub-cellular components and biosamples captured in the images. We also discuss advanced utilisation of morphological imaging data that can be promoted by this database.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [28.03325080871582, 7.295139789581299]}, {"key": "", "year": "", "title": "Kuo2016de", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"De-Hashing: Server-Side Context-Aware Feature Reconstruction for Mobile Visual Search\"\nauthors: Kuo Yin-Hsi, Hsu Winston H.\nconference: Arxiv\nyear: 2016\nbibkey: kuo2016de\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1606.08999\"}\ntags: ['ARXIV', 'Video Retrieval']\n---\nDue to the prevalence of mobile devices, mobile search becomes a more convenient way than desktop search. Different from the traditional desktop search, mobile visual search needs more consideration for the limited resources on mobile devices (e.g., bandwidth, computing power, and memory consumption). The state-of-the-art approaches show that bag-of-words (BoW) model is robust for image and video retrieval; however, the large vocabulary tree might not be able to be loaded on the mobile device. We observe that recent works mainly focus on designing compact feature representations on mobile devices for bandwidth-limited network (e.g., 3G) and directly adopt feature matching on remote servers (cloud). However, the compact (binary) representation might fail to retrieve target objects (images, videos). Based on the hashed binary codes, we propose a de-hashing process that reconstructs BoW by leveraging the computing power of remote servers. To mitigate the information loss from binary codes, we further utilize contextual information (e.g., GPS) to reconstruct a context-aware BoW for better retrieval results. Experiment results show that the proposed method can achieve competitive retrieval accuracy as BoW while only transmitting few bits from mobile devices.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-23.367931365966797, 16.97554588317871]}, {"key": "", "year": "", "title": "Kurpicz2022pachash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"PaCHash: Packed and Compressed Hash Tables\"\nauthors: Kurpicz Florian, Lehmann Hans-Peter, Sanders Peter\nconference: Arxiv\nyear: 2022\nbibkey: kurpicz2022pachash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2205.04745\"}\ntags: ['ARXIV']\n---\nWe introduce PaCHash, a hash table that stores its objects contiguously in an array without intervening space, even if the objects have variable size. In particular, each object can be compressed using standard compression techniques. A small search data structure allows locating the objects in constant expected time. PaCHash is most naturally described as a static external hash table where it needs a constant number of bits of internal memory per block of external memory. Here, in some sense, PaCHash beats a lower bound on the space consumption of k-perfect hashing. An implementation for fast SSDs needs about 5 bits of internal memory per block of external memory, requires only one disk access (of variable length) per search operation, and has small internal search overhead compared to the disk access cost. Our experiments show that it has lower space consumption than all previous approaches even when considering objects of identical size.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-24.63668441772461, -15.674381256103516]}, {"key": "", "year": "", "title": "Kutlu2017grayscale", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Grayscale Image Authentication using Neural Hashing\"\nauthors: Kutlu Yakup, Yay\u0131k Apdullah\nconference: Arxiv\nyear: 2017\nbibkey: kutlu2017grayscale\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1703.00726\"}\ntags: ['ARXIV']\n---\nMany different approaches for neural network based hash functions have been proposed. Statistical analysis must correlate security of them. This paper proposes novel neural hashing approach for gray scale image authentication. The suggested system is rapid, robust, useful and secure. Proposed hash function generates hash values using neural network one-way property and non-linear techniques. As a result security and performance analysis are performed and satisfying results are achieved. These features are dominant reasons for preferring against traditional ones.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-31.02910804748535, 3.6709673404693604]}, {"key": "", "year": "", "title": "K\u00f6ppl2019separate", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Separate Chaining Meets Compact Hashing\"\nauthors: K\u00f6ppl Dominik\nconference: Arxiv\nyear: 2019\nbibkey: k\u00f6ppl2019separate\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1905.00163\"}\ntags: ['ARXIV']\n---\nWhile separate chaining is a common strategy for resolving collisions in a hash table taught in most textbooks, compact hashing is a less common technique for saving space when hashing integers whose domain is relatively small with respect to the problem size. It is widely believed that hash tables waste a considerable amount of memory, as they either leave allocated space untouched (open addressing) or store additional pointers (separate chaining). For the former, Cleary introduced the compact hashing technique that stores only a part of a key to save space. However, as can be seen by the line of research focusing on compact hash tables with open addressing, there is additional information, called displacement, required for restoring a key. There are several representations of this displacement information with different space and time trade-offs. In this article, we introduce a separate chaining hash table that applies the compact hashing technique without the need for the displacement information. Practical evaluations reveal that insertions in this hash table are faster or use less space than all previously known compact hash tables on modern computer architectures when storing sufficiently large satellite data.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-18.88825035095215, -9.711424827575684]}, {"key": "", "year": "", "title": "Laarhoven2019polytopes", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Polytopes, lattices, and spherical codes for the nearest neighbor problem\"\nauthors: Laarhoven Thijs\nconference: ICALP\nyear: 2019\nbibkey: laarhoven2019polytopes\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1907.04628\"}\ntags: ['FOCS']\n---\nWe study locality-sensitive hash methods for the nearest neighbor problem for the angular distance, focusing on the approach of first projecting down onto a low-dimensional subspace, and then partitioning the projected vectors according to Voronoi cells induced by a suitable spherical code. This approach generalizes and interpolates between the fast but suboptimal hyperplane hashing of Charikar [STOC'02] and the asymptotically optimal but practically often slower hash families of Andoni-Indyk [FOCS'06], Andoni-Indyk-Nguyen-Razenshteyn [SODA'14] and Andoni-Indyk-Laarhoven-Razenshteyn-Schmidt [NIPS'15]. We set up a framework for analyzing the performance of any spherical code in this context, and we provide results for various codes from the literature, such as those related to regular polytopes and root lattices. Similar to hyperplane hashing, and unlike cross-polytope hashing, our analysis of collision probabilities and query exponents is exact and does not hide order terms which vanish only for large $d$, facilitating an easy parameter selection. For the two-dimensional case, we derive closed-form expressions for arbitrary spherical codes, and we show that the equilateral triangle is optimal, achieving a better performance than the two-dimensional analogues of hyperplane and cross-polytope hashing. In three and four dimensions, we numerically find that the tetrahedron, $5$-cell, and $16$-cell achieve the best query exponents, while in five or more dimensions orthoplices appear to outperform regular simplices, as well as the root lattice families $A_k$ and $D_k$. We argue that in higher dimensions, larger spherical codes will likely exist which will outperform orthoplices in theory, and we argue why using the $D_k$ root lattices will likely lead to better results in practice, due to a better trade-off between the asymptotic query exponent and the concrete costs of hashing.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-8.755054473876953, -22.569416046142578]}, {"key": "", "year": "", "title": "Lai2015simultaneous", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Simultaneous Feature Learning and Hash Coding with Deep Neural Networks\"\nauthors: Lai Hanjiang, Pan Yan, Liu Ye, Yan Shuicheng\nconference: Arxiv\nyear: 2015\nbibkey: lai2015simultaneous\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1504.03410\"}\ntags: ['ARXIV', 'Image Retrieval', 'Quantisation', 'Supervised', 'TIP', 'Unsupervised']\n---\nSimilarity-preserving hashing is a widely-used method for nearest neighbour search in large-scale image retrieval tasks. For most existing hashing methods, an image is first encoded as a vector of hand-engineering visual features, followed by another separate projection or quantization step that generates binary codes. However, such visual feature vectors may not be optimally compatible with the coding process, thus producing sub-optimal hashing codes. In this paper, we propose a deep architecture for supervised hashing, in which images are mapped into binary codes via carefully designed deep neural networks. The pipeline of the proposed deep architecture consists of three building blocks: 1) a sub-network with a stack of convolution layers to produce the effective intermediate image features; 2) a divide-and-encode module to divide the intermediate image features into multiple branches, each encoded into one hash bit; and 3) a triplet ranking loss designed to characterize that one image is more similar to the second image than to the third one. Extensive evaluations on several benchmark image datasets show that the proposed simultaneous feature learning and hash coding pipeline brings substantial improvements over other state-of-the-art supervised or unsupervised hashing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [4.1153788566589355, 6.280028343200684]}, {"key": "", "year": "", "title": "Lai2016instance", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Instance-Aware Hashing for Multi-Label Image Retrieval\"\nauthors: Lai Hanjiang, Yan Pan, Shu Xiangbo, Wei Yunchao, Yan Shuicheng\nconference: Arxiv\nyear: 2016\nbibkey: lai2016instance\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1603.03234\"}\ntags: ['ARXIV', 'GAN', 'Image Retrieval', 'Supervised', 'TIP', 'Unsupervised']\n---\nSimilarity-preserving hashing is a commonly used method for nearest neighbour search in large-scale image retrieval. For image retrieval, deep-networks-based hashing methods are appealing since they can simultaneously learn effective image representations and compact hash codes. This paper focuses on deep-networks-based hashing for multi-label images, each of which may contain objects of multiple categories. In most existing hashing methods, each image is represented by one piece of hash code, which is referred to as semantic hashing. This setting may be suboptimal for multi-label image retrieval. To solve this problem, we propose a deep architecture that learns \\textbf{instance-aware} image representations for multi-label image data, which are organized in multiple groups, with each group containing the features for one category. The instance-aware representations not only bring advantages to semantic hashing, but also can be used in category-aware hashing, in which an image is represented by multiple pieces of hash codes and each piece of code corresponds to a category. Extensive evaluations conducted on several benchmark datasets demonstrate that, for both semantic hashing and category-aware hashing, the proposed method shows substantial improvement over the state-of-the-art supervised and unsupervised hashing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [4.426345348358154, 5.813103199005127]}, {"key": "", "year": "", "title": "Lai2017improved", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Improved Search in Hamming Space using Deep Multi-Index Hashing\"\nauthors: Lai Hanjiang, Pan Yan\nconference: Arxiv\nyear: 2017\nbibkey: lai2017improved\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1710.06993\"}\ntags: ['ARXIV', 'Image Retrieval', 'TIP']\n---\nSimilarity-preserving hashing is a widely-used method for nearest neighbour search in large-scale image retrieval tasks. There has been considerable research on generating efficient image representation via the deep-network-based hashing methods. However, the issue of efficient searching in the deep representation space remains largely unsolved. To this end, we propose a simple yet efficient deep-network-based multi-index hashing method for simultaneously learning the powerful image representation and the efficient searching. To achieve these two goals, we introduce the multi-index hashing (MIH) mechanism into the proposed deep architecture, which divides the binary codes into multiple substrings. Due to the non-uniformly distributed codes will result in inefficiency searching, we add the two balanced constraints at feature-level and instance-level, respectively. Extensive evaluations on several benchmark image retrieval datasets show that the learned balanced binary codes bring dramatic speedups and achieve comparable performance over the existing baselines.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [3.960026741027832, 6.582729816436768]}, {"key": "", "year": "", "title": "Lai2017transductive", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Transductive Zero-Shot Hashing via Coarse-to-Fine Similarity Mining\"\nauthors: Lai Hanjiang, Pan Yan\nconference: Arxiv\nyear: 2017\nbibkey: lai2017transductive\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1711.02856\"}\ntags: ['ARXIV']\n---\nZero-shot Hashing (ZSH) is to learn hashing models for novel/target classes without training data, which is an important and challenging problem. Most existing ZSH approaches exploit transfer learning via an intermediate shared semantic representations between the seen/source classes and novel/target classes. However, due to having disjoint, the hash functions learned from the source dataset are biased when applied directly to the target classes. In this paper, we study the transductive ZSH, i.e., we have unlabeled data for novel classes. We put forward a simple yet efficient joint learning approach via coarse-to-fine similarity mining which transfers knowledges from source data to target data. It mainly consists of two building blocks in the proposed deep architecture: 1) a shared two-streams network, which the first stream operates on the source data and the second stream operates on the unlabeled data, to learn the effective common image representations, and 2) a coarse-to-fine module, which begins with finding the most representative images from target classes and then further detect similarities among these images, to transfer the similarities of the source data to the target data in a greedy fashion. Extensive evaluation results on several benchmark datasets demonstrate that the proposed hashing method achieves significant improvement over the state-of-the-art methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-10.029685974121094, 2.3052167892456055]}, {"key": "", "year": "", "title": "Lakehal2011new", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"New Method for 3D Shape Retrieval\"\nauthors: Lakehal Abdelghni, Beqqali Omar El\nconference: Arxiv\nyear: 2011\nbibkey: lakehal2011new\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1111.1752\"}\ntags: ['ARXIV']\n---\nThe recent technological progress in acquisition, modeling and processing of 3D data leads to the proliferation of a large number of 3D objects databases. Consequently, the techniques used for content based 3D retrieval has become necessary. In this paper, we introduce a new method for 3D objects recognition and retrieval by using a set of binary images CLI (Characteristic level images). We propose a 3D indexing and search approach based on the similarity between characteristic level images using Hu moments for it indexing. To measure the similarity between 3D objects we compute the Hausdorff distance between a vectors descriptor. The performance of this new approach is evaluated at set of 3D object of well known database, is NTU (National Taiwan University) database.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [20.744831085205078, -0.13425637781620026]}, {"key": "", "year": "", "title": "Lamberger2012memoryless", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Memoryless Near-Collisions, Revisited\"\nauthors: Lamberger Mario, Teufl Elmar\nconference: Arxiv\nyear: 2012\nbibkey: lamberger2012memoryless\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1209.4255\"}\ntags: ['ARXIV', 'Graph']\n---\nIn this paper we discuss the problem of generically finding near-collisions for cryptographic hash functions in a memoryless way. A common approach is to truncate several output bits of the hash function and to look for collisions of this modified function. In two recent papers, an enhancement to this approach was introduced which is based on classical cycle-finding techniques and covering codes. This paper investigates two aspects of the problem of memoryless near-collisions. Firstly, we give a full treatment of the trade-off between the number of truncated bits and the success-probability of the truncation based approach. Secondly, we demonstrate the limits of cycle-finding methods for finding near-collisions by showing that, opposed to the collision case, a memoryless variant cannot match the query-complexity of the \"memory-full\" birthday-like near-collision finding method.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-30.528322219848633, -5.415036201477051]}, {"key": "", "year": "", "title": "Lamping2014a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Fast, Minimal Memory, Consistent Hash Algorithm\"\nauthors: Lamping John, Veach Eric\nconference: Arxiv\nyear: 2014\nbibkey: lamping2014a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1406.2294\"}\ntags: ['ARXIV']\n---\nWe present jump consistent hash, a fast, minimal memory, consistent hash algorithm that can be expressed in about 5 lines of code. In comparison to the algorithm of Karger et al., jump consistent hash requires no storage, is faster, and does a better job of evenly dividing the key space among the buckets and of evenly dividing the workload when the number of buckets changes. Its main limitation is that the buckets must be numbered sequentially, which makes it more suitable for data storage applications than for distributed web caching.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-25.181840896606445, -15.535972595214844]}, {"key": "", "year": "", "title": "Laskar2017context", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Context Aware Query Image Representation for Particular Object Retrieval\"\nauthors: Laskar Zakaria, Kannala Juho\nconference: Arxiv\nyear: 2017\nbibkey: laskar2017context\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1703.01226\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval']\n---\nThe current models of image representation based on Convolutional Neural Networks (CNN) have shown tremendous performance in image retrieval. Such models are inspired by the information flow along the visual pathway in the human visual cortex. We propose that in the field of particular object retrieval, the process of extracting CNN representations from query images with a given region of interest (ROI) can also be modelled by taking inspiration from human vision. Particularly, we show that by making the CNN pay attention on the ROI while extracting query image representation leads to significant improvement over the baseline methods on challenging Oxford5k and Paris6k datasets. Furthermore, we propose an extension to a recently introduced encoding method for CNN representations, regional maximum activations of convolutions (R-MAC). The proposed extension weights the regional representations using a novel saliency measure prior to aggregation. This leads to further improvement in retrieval accuracy.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.378922462463379, 26.88810157775879]}, {"key": "", "year": "", "title": "Lassance2022composite", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Composite Code Sparse Autoencoders for first stage retrieval\"\nauthors: Lassance Carlos, Formal Thibault, Clinchant Stephane\nconference: Arxiv\nyear: 2022\nbibkey: lassance2022composite\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2204.07023\"}\ntags: ['ARXIV', 'Graph', 'Image Retrieval', 'Quantisation', 'Supervised']\n---\nWe propose a Composite Code Sparse Autoencoder (CCSA) approach for Approximate Nearest Neighbor (ANN) search of document representations based on Siamese-BERT models. In Information Retrieval (IR), the ranking pipeline is generally decomposed in two stages: the first stage focus on retrieving a candidate set from the whole collection. The second stage re-ranks the candidate set by relying on more complex models. Recently, Siamese-BERT models have been used as first stage ranker to replace or complement the traditional bag-of-word models. However, indexing and searching a large document collection require efficient similarity search on dense vectors and this is why ANN techniques come into play. Since composite codes are naturally sparse, we first show how CCSA can learn efficient parallel inverted index thanks to an uniformity regularizer. Second, CCSA can be used as a binary quantization method and we propose to combine it with the recent graph based ANN techniques. Our experiments on MSMARCO dataset reveal that CCSA outperforms IVF with product quantization. Furthermore, CCSA binary quantization is beneficial for the index size, and memory usage for the graph-based HNSW method, while maintaining a good level of recall and MRR. Third, we compare with recent supervised quantization methods for image retrieval and find that CCSA is able to outperform them.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [10.105009078979492, 4.799576759338379]}, {"key": "", "year": "", "title": "Lav2020proximity", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Proximity Preserving Binary Code using Signed Graph-Cut\"\nauthors: Lav Inbal, Avidan Shai, Singer Yoram, Hel-Or Yacov\nconference: AAAI Conference on Artificial Intelligence , Feb.\nyear: 2020\nbibkey: lav2020proximity\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2002.01793\"}\ntags: ['Graph']\n---\nWe introduce a binary embedding framework, called Proximity Preserving Code (PPC), which learns similarity and dissimilarity between data points to create a compact and affinity-preserving binary code. This code can be used to apply fast and memory-efficient approximation to nearest-neighbor searches. Our framework is flexible, enabling different proximity definitions between data points. In contrast to previous methods that extract binary codes based on unsigned graph partitioning, our system models the attractive and repulsive forces in the data by incorporating positive and negative graph weights. The proposed framework is shown to boil down to finding the minimal cut of a signed graph, a problem known to be NP-hard. We offer an efficient approximation and achieve superior results by constructing the code bit after bit. We show that the proposed approximation is superior to the commonly used spectral methods with respect to both accuracy and complexity. Thus, it is useful for many other problems that can be translated into signed graph cut.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [4.629916667938232, -25.742027282714844]}, {"key": "", "year": "", "title": "Le2015image", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Image Retrieval System Base on EMD Similarity Measure and S-Tree\"\nauthors: Le Thanh Manh, Van Thanh The\nconference: Arxiv\nyear: 2015\nbibkey: le2015image\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1506.01165\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nThe paper approaches the binary signature for each image based on the percentage of the pixels in each color images, at the same time the paper builds a similar measure between images based on EMD (Earth Mover's Distance). Besides, the paper proceeded to create the S-tree based on the similar measure EMD to store the image's binary signatures to quickly query image signature data. From there, the paper build an image retrieval algorithm and CBIR (Content-Based Image Retrieval) based on a similar measure EMD and S-tree. Based on this theory, the paper proceeded to build application and experimental assessment of the process of querying image on the database system which have over 10,000 images.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [29.47984504699707, 9.191822052001953]}, {"key": "", "year": "", "title": "Lecroq2023optimal", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Optimal-Hash Exact String Matching Algorithms\"\nauthors: Lecroq Thierry\nconference: Arxiv\nyear: 2023\nbibkey: lecroq2023optimal\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2303.05799\"}\ntags: ['ARXIV']\n---\nString matching is the problem of finding all the occurrences of a pattern in a text. We propose improved versions of the fast family of string matching algorithms based on hashing $q$-grams. The improvement consists of considering minimal values $q$ such that each $q$-grams of the pattern has a unique hash value. The new algorithms are fastest than algorithm of the HASH family for short patterns on large size alphabets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [0.7945870757102966, -11.898006439208984]}, {"key": "", "year": "", "title": "Lecroq2024fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast computation of the period and of the shortest cover of a string using its Character-Distance-Sampling representation\"\nauthors: Lecroq Thierry, Marino Francesco Pio\nconference: Arxiv\nyear: 2024\nbibkey: lecroq2024fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2407.18216\"}\ntags: ['ARXIV']\n---\nComputing regularities in strings is essential for a better understanding of their structures. Among regularities, periods and covers are the easiest to compute and the more informative. Lately new interesting string matching results have been achieved using different sampling techniques. One of these technique, called Character-Distance-Sampling (\\texttt{CDS}) consists of representing a string by storing the distance between the positions of selected characters called pivots. Here we select as pivots only the first character of the string and use its \\texttt{CDS} representation for computing its period and its shortest cover. Experimental results show that the proposed methods are much faster than classical methods for computing these two features.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-2.1670563220977783, -11.489678382873535]}, {"key": "", "year": "", "title": "Lee2011similarity", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Similarity Join Size Estimation using Locality Sensitive Hashing\"\nauthors: Lee Hongrae  University of British Columbia, Ng Raymond T.  University of British Columbia, Shim Kyuseok  Seoul National University\nconference: Proceedings of the VLDB Endowment\nyear: 2011\nbibkey: lee2011similarity\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1104.3212\"}\ntags: ['LSH']\n---\nSimilarity joins are important operations with a broad range of applications. In this paper, we study the problem of vector similarity join size estimation (VSJ). It is a generalization of the previously studied set similarity join size estimation (SSJ) problem and can handle more interesting cases such as TF-IDF vectors. One of the key challenges in similarity join size estimation is that the join size can change dramatically depending on the input similarity threshold. We propose a sampling based algorithm that uses the Locality-Sensitive-Hashing (LSH) scheme. The proposed algorithm LSH-SS uses an LSH index to enable effective sampling even at high thresholds. We compare the proposed technique with random sampling and the state-of-the-art technique for SSJ (adapted to VSJ) and demonstrate LSH-SS offers more accurate estimates at both high and low similarity thresholds and small variance using real-world data sets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [15.254075050354004, -14.13148307800293]}, {"key": "", "year": "", "title": "Lehmann2022sichash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"SicHash -- Small Irregular Cuckoo Tables for Perfect Hashing\"\nauthors: Lehmann Hans-Peter, Sanders Peter, Walzer Stefan\nconference: Arxiv\nyear: 2022\nbibkey: lehmann2022sichash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2210.01560\"}\ntags: ['ARXIV']\n---\nA Perfect Hash Function (PHF) is a hash function that has no collisions on a given input set. PHFs can be used for space efficient storage of data in an array, or for determining a compact representative of each object in the set. In this paper, we present the PHF construction algorithm SicHash - Small Irregular Cuckoo Tables for Perfect Hashing. At its core, SicHash uses a known technique: It places objects in a cuckoo hash table and then stores the final hash function choice of each object in a retrieval data structure. We combine the idea with irregular cuckoo hashing, where each object has a different number of hash functions. Additionally, we use many small tables that we overload beyond their asymptotic maximum load factor. The most space efficient competitors often use brute force methods to determine the PHFs. SicHash provides a more direct construction algorithm that only rarely needs to recompute parts. Our implementation improves the state of the art in terms of space usage versus construction time for a wide range of configurations. At the same time, it provides very fast queries.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-23.11438751220703, -15.748407363891602]}, {"key": "", "year": "", "title": "Lehmann2023shockhash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"ShockHash: Near Optimal-Space Minimal Perfect Hashing Beyond Brute-Force\"\nauthors: Lehmann Hans-Peter, Sanders Peter, Walzer Stefan\nconference: Arxiv\nyear: 2023\nbibkey: lehmann2023shockhash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2310.14959\"}\ntags: ['ARXIV', 'Graph']\n---\nA minimal perfect hash function (MPHF) maps a set S of n keys to the first n integers without collisions. There is a lower bound of n*log(e)=1.44n bits needed to represent an MPHF. This can be reached by a brute-force algorithm that tries e^n hash function seeds in expectation and stores the first seed leading to an MPHF. The most space-efficient previous algorithms for constructing MPHFs all use such a brute-force approach as a basic building block. In this paper, we introduce ShockHash - Small, heavily overloaded cuckoo hash tables for minimal perfect hashing. ShockHash uses two hash functions h_0 and h_1, hoping for the existence of a function f : S-&gt;{0, 1} such that x -&gt; h_{f(x)}(x) is an MPHF on S. It then uses a 1-bit retrieval data structure to store f using n + o(n) bits. In graph terminology, ShockHash generates n-edge random graphs until stumbling on a pseudoforest - where each component contains as many edges as nodes. Using cuckoo hashing, ShockHash then derives an MPHF from the pseudoforest in linear time. We show that ShockHash needs to try only about (e/2)^n=1.359^n seeds in expectation. This reduces the space for storing the seed by roughly n bits (maintaining the asymptotically optimal space consumption) and speeds up construction by almost a factor of 2^n compared to brute-force. Bipartite ShockHash reduces the expected construction time again to 1.166^n by maintaining a pool of candidate hash functions and checking all possible pairs. ShockHash as a building block within the RecSplit framework can be constructed up to 3 orders of magnitude faster than competing approaches. It can build an MPHF for 10 million keys with 1.489 bits per key in about half an hour. When instead using ShockHash after an efficient k-perfect hash function, it achieves space usage similar to the best competitors, while being significantly faster to construct and query.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-16.345609664916992, -18.379362106323242]}, {"key": "", "year": "", "title": "Lehmann2023sliding", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Sliding Block Hashing (Slick) -- Basic Algorithmic Ideas\"\nauthors: Lehmann Hans-Peter, Sanders Peter, Walzer Stefan\nconference: Arxiv\nyear: 2023\nbibkey: lehmann2023sliding\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2304.09283\"}\ntags: ['ARXIV']\n---\nWe present {\\bf Sli}ding Blo{\\bf ck} Hashing (Slick), a simple hash table data structure that combines high performance with very good space efficiency. This preliminary report outlines avenues for analysis and implementation that we intend to pursue.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-31.35579490661621, -14.280847549438477]}, {"key": "", "year": "", "title": "Lei2020locality", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Locality-Sensitive Hashing Scheme based on Longest Circular Co-Substring\"\nauthors: Lei Yifan, Huang Qiang, Kankanhalli Mohan, Tung Anthony K. H.\nconference: Arxiv\nyear: 2020\nbibkey: lei2020locality\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2004.05345\"}\ntags: ['ARXIV', 'LSH']\n---\nLocality-Sensitive Hashing (LSH) is one of the most popular methods for $c$-Approximate Nearest Neighbor Search ($c$-ANNS) in high-dimensional spaces. In this paper, we propose a novel LSH scheme based on the Longest Circular Co-Substring (LCCS) search framework (LCCS-LSH) with a theoretical guarantee. We introduce a novel concept of LCCS and a new data structure named Circular Shift Array (CSA) for $k$-LCCS search. The insight of LCCS search framework is that close data objects will have a longer LCCS than the far-apart ones with high probability. LCCS-LSH is \\emph{LSH-family-independent}, and it supports $c$-ANNS with different kinds of distance metrics. We also introduce a multi-probe version of LCCS-LSH and conduct extensive experiments over five real-life datasets. The experimental results demonstrate that LCCS-LSH outperforms state-of-the-art LSH schemes.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [7.55177116394043, -15.881063461303711]}, {"key": "", "year": "", "title": "Lemire2006one", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"One-Pass, One-Hash n-Gram Statistics Estimation\"\nauthors: Lemire Daniel, Kaser Owen\nconference: Arxiv\nyear: 2006\nbibkey: lemire2006one\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/cs/0610010\"}\ntags: ['ARXIV']\n---\nIn multimedia, text or bioinformatics databases, applications query sequences of n consecutive symbols called n-grams. Estimating the number of distinct n-grams is a view-size estimation problem. While view sizes can be estimated by sampling under statistical assumptions, we desire an unassuming algorithm with universally valid accuracy bounds. Most related work has focused on repeatedly hashing the data, which is prohibitive for large data sources. We prove that a one-pass one-hash algorithm is sufficient for accurate estimates if the hashing is sufficiently independent. To reduce costs further, we investigate recursive random hashing algorithms and show that they are sufficiently independent in practice. We compare our running times with exact counts using suffix arrays and show that, while we use hardly any storage, we are an order of magnitude faster. The approach further is extended to a one-pass/one-hash computation of n-gram entropy and iceberg counts. The experiments use a large collection of English text from the Gutenberg Project as well as synthetic data.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-21.208328247070312, -10.071662902832031]}, {"key": "", "year": "", "title": "Lemire2007recursive", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Recursive n-gram hashing is pairwise independent, at best\"\nauthors: Lemire Daniel, Kaser Owen\nconference: Computer Speech &amp; Language\nyear: 2007\nbibkey: lemire2007recursive\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/0705.4676\"}\ntags: []\n---\nMany applications use sequences of n consecutive symbols (n-grams). Hashing these n-grams can be a performance bottleneck. For more speed, recursive hash families compute hash values by updating previous values. We prove that recursive hash families cannot be more than pairwise independent. While hashing by irreducible polynomials is pairwise independent, our implementations either run in time O(n) or use an exponential amount of memory. As a more scalable alternative, we make hashing by cyclic polynomials pairwise independent by ignoring n-1 bits. Experimentally, we show that hashing by cyclic polynomials is is twice as fast as hashing by irreducible polynomials. We also show that randomized Karp-Rabin hash families are not pairwise independent.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-22.122058868408203, -10.923758506774902]}, {"key": "", "year": "", "title": "Lemire2010the", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"The universality of iterated hashing over variable-length strings\"\nauthors: Lemire Daniel\nconference: Discrete Applied Mathematics\nyear: 2010\nbibkey: lemire2010the\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1008.1715\"}\ntags: []\n---\nIterated hash functions process strings recursively, one character at a time. At each iteration, they compute a new hash value from the preceding hash value and the next character. We prove that iterated hashing can be pairwise independent, but never 3-wise independent. We show that it can be almost universal over strings much longer than the number of hash values; we bound the maximal string length given the collision probability.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-29.48405647277832, -5.322140216827393]}, {"key": "", "year": "", "title": "Lemire2015faster", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Faster 64-bit universal hashing using carry-less multiplications\"\nauthors: Lemire Daniel, Kaser Owen\nconference: Journal of Cryptographic Engineering, Volume\nyear: 2015\nbibkey: lemire2015faster\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1503.03465\"}\ntags: ['TIP', 'Volume']\n---\nIntel and AMD support the Carry-less Multiplication (CLMUL) instruction set in their x64 processors. We use CLMUL to implement an almost universal 64-bit hash family (CLHASH). We compare this new family with what might be the fastest almost universal family on x64 processors (VHASH). We find that CLHASH is at least 60% faster. We also compare CLHASH with a popular hash function designed for speed (Google's CityHash). We find that CLHASH is 40% faster than CityHash on inputs larger than 64 bytes and just as fast otherwise.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-26.996177673339844, -10.883938789367676]}, {"key": "", "year": "", "title": "Lepage2023lrvs", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"LRVS-Fashion: Extending Visual Search with Referring Instructions\"\nauthors: Lepage Simon, Mary J\u00e9r\u00e9mie, Picard David\nconference: Arxiv\nyear: 2023\nbibkey: lepage2023lrvs\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2306.02928\"}   - {name: \"Paper\", url: \"https://huggingface.co/datasets/Slep/LAION-RVS-Fashion\"}\ntags: ['ARXIV', 'Supervised', 'Weakly Supervised']\n---\nThis paper introduces a new challenge for image similarity search in the context of fashion, addressing the inherent ambiguity in this domain stemming from complex images. We present Referred Visual Search (RVS), a task allowing users to define more precisely the desired similarity, following recent interest in the industry. We release a new large public dataset, LRVS-Fashion, consisting of 272k fashion products with 842k images extracted from fashion catalogs, designed explicitly for this task. However, unlike traditional visual search methods in the industry, we demonstrate that superior performance can be achieved by bypassing explicit object detection and adopting weakly-supervised conditional contrastive learning on image tuples. Our method is lightweight and demonstrates robustness, reaching Recall at one superior to strong detection-based baselines against 2M distractors. The dataset is available at https://huggingface.co/datasets/Slep/LAION-RVS-Fashion .\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [23.86046028137207, 4.855893135070801]}, {"key": "", "year": "", "title": "Lessley2018data", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Data-Parallel Hashing Techniques for GPU Architectures\"\nauthors: Lessley Brenton\nconference: Arxiv\nyear: 2018\nbibkey: lessley2018data\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1807.04345\"}\ntags: ['ARXIV', 'Graph']\n---\nHash tables are one of the most fundamental data structures for effectively storing and accessing sparse data, with widespread usage in domains ranging from computer graphics to machine learning. This study surveys the state-of-the-art research on data-parallel hashing techniques for emerging massively-parallel, many-core GPU architectures. Key factors affecting the performance of different hashing schemes are discovered and used to suggest best practices and pinpoint areas for further research.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-31.034029006958008, -11.64327335357666]}, {"key": "", "year": "", "title": "Leu2023fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast Consistent Hashing in Constant Time\"\nauthors: Leu Eric\nconference: Arxiv\nyear: 2023\nbibkey: leu2023fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2307.12448\"}\ntags: ['ARXIV']\n---\nConsistent hashing is a technique that can minimize key remapping when the number of hash buckets changes. The paper proposes a fast consistent hash algorithm (called power consistent hash) that has $O(1)$ expected time for key lookup, independent of the number of buckets. Hash values are computed in real time. No search data structure is constructed to store bucket ranges or key mappings. The algorithm has a lightweight design using $O(1)$ space with superior scalability. In particular, it uses two auxiliary hash functions to achieve distribution uniformity and $O(1)$ expected time for key lookup. Furthermore, it performs consistent hashing such that only a minimal number of keys are remapped when the number of buckets changes. Consistent hashing has a wide range of use cases, including load balancing, distributed caching, and distributed key-value stores. The proposed algorithm is faster than well-known consistent hash algorithms with $O(\\log n)$ lookup time.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-26.7672176361084, -14.62013053894043]}, {"key": "", "year": "", "title": "Levi2015latch", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"LATCH: Learned Arrangements of Three Patch Codes\"\nauthors: Levi Gil, Hassner Tal\nconference: Arxiv\nyear: 2015\nbibkey: levi2015latch\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1501.03719\"}\ntags: ['ARXIV']\n---\nWe present a novel means of describing local image appearances using binary strings. Binary descriptors have drawn increasing interest in recent years due to their speed and low memory footprint. A known shortcoming of these representations is their inferior performance compared to larger, histogram based descriptors such as the SIFT. Our goal is to close this performance gap while maintaining the benefits attributed to binary representations. To this end we propose the Learned Arrangements of Three Patch Codes descriptors, or LATCH. Our key observation is that existing binary descriptors are at an increased risk from noise and local appearance variations. This, as they compare the values of pixel pairs; changes to either of the pixels can easily lead to changes in descriptor values, hence damaging its performance. In order to provide more robustness, we instead propose a novel means of comparing pixel patches. This ostensibly small change, requires a substantial redesign of the descriptors themselves and how they are produced. Our resulting LATCH representation is rigorously compared to state-of-the-art binary descriptors and shown to provide far better performance for similar computation and space requirements.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-0.3633880913257599, 22.35415267944336]}, {"key": "", "year": "", "title": "Leybovich2021efficient", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Efficient Approximate Search for Sets of Vectors\"\nauthors: Leybovich Michael, Shmueli Oded\nconference: Arxiv\nyear: 2021\nbibkey: leybovich2021efficient\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2107.06817\"}\ntags: ['ARXIV', 'Graph', 'LSH', 'Quantisation']\n---\nWe consider a similarity measure between two sets $A$ and $B$ of vectors, that balances the average and maximum cosine distance between pairs of vectors, one from set $A$ and one from set $B$. As a motivation for this measure, we present lineage tracking in a database. To practically realize this measure, we need an approximate search algorithm that given a set of vectors $A$ and sets of vectors $B_1,...,B_n$, the algorithm quickly locates the set $B_i$ that maximizes the similarity measure. For the case where all sets are singleton sets, essentially each is a single vector, there are known efficient approximate search algorithms, e.g., approximated versions of tree search algorithms, locality-sensitive hashing (LSH), vector quantization (VQ) and proximity graph algorithms. In this work, we present approximate search algorithms for the general case. The underlying idea in these algorithms is encoding a set of vectors via a \"long\" single vector. The proposed approximate approach achieves significant performance gains over an optimized, exact search on vector sets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [1.6707403659820557, -22.309589385986328]}, {"key": "", "year": "", "title": "Li2006cascade", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Cascade hash tables: a series of multilevel double hashing schemes with O(1) worst case lookup time\"\nauthors: Li Shaohua\nconference: Arxiv\nyear: 2006\nbibkey: li2006cascade\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/cs/0608037\"}\ntags: ['ARXIV']\n---\nIn this paper, the author proposes a series of multilevel double hashing schemes called cascade hash tables. They use several levels of hash tables. In each table, we use the common double hashing scheme. Higher level hash tables work as fail-safes of lower level hash tables. By this strategy, it could effectively reduce collisions in hash insertion. Thus it gains a constant worst case lookup time with a relatively high load factor(70%-85%) in random experiments. Different parameters of cascade hash tables are tested.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-27.90420150756836, -4.329549312591553]}, {"key": "", "year": "", "title": "Li2009b", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"b-Bit Minwise Hashing\"\nauthors: Li Ping, Konig Arnd Christian\nconference: Arxiv\nyear: 2009\nbibkey: li2009b\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/0910.3349\"}\ntags: ['ARXIV']\n---\nThis paper establishes the theoretical framework of b-bit minwise hashing. The original minwise hashing method has become a standard technique for estimating set similarity (e.g., resemblance) with applications in information retrieval, data management, social networks and computational advertising. By only storing the lowest $b$ bits of each (minwise) hashed value (e.g., b=1 or 2), one can gain substantial advantages in terms of computational efficiency and storage space. We prove the basic theoretical results and provide an unbiased estimator of the resemblance for any b. We demonstrate that, even in the least favorable scenario, using b=1 may reduce the storage space at least by a factor of 21.3 (or 10.7) compared to using b=64 (or b=32), if one is interested in resemblance &gt; 0.5.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-0.6047542095184326, -8.566251754760742]}, {"key": "", "year": "", "title": "Li2011accurate", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Accurate Estimators for Improving Minwise Hashing and b-Bit Minwise Hashing\"\nauthors: Li Ping, Konig Christian\nconference: Arxiv\nyear: 2011\nbibkey: li2011accurate\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1108.0895\"}\ntags: ['ARXIV']\n---\nMinwise hashing is the standard technique in the context of search and databases for efficiently estimating set (e.g., high-dimensional 0/1 vector) similarities. Recently, b-bit minwise hashing was proposed which significantly improves upon the original minwise hashing in practice by storing only the lowest b bits of each hashed value, as opposed to using 64 bits. b-bit hashing is particularly effective in applications which mainly concern sets of high similarities (e.g., the resemblance &gt;0.5). However, there are other important applications in which not just pairs of high similarities matter. For example, many learning algorithms require all pairwise similarities and it is expected that only a small fraction of the pairs are similar. Furthermore, many applications care more about containment (e.g., how much one object is contained by another object) than the resemblance. In this paper, we show that the estimators for minwise hashing and b-bit minwise hashing used in the current practice can be systematically improved and the improvements are most significant for set pairs of low resemblance and high containment.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-0.73245769739151, -8.639715194702148]}, {"key": "", "year": "", "title": "Li2011b", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"b-Bit Minwise Hashing for Large-Scale Linear SVM\"\nauthors: Li Ping, Moore Joshua, Konig Christian\nconference: Arxiv\nyear: 2011\nbibkey: li2011b\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1105.4385\"}\ntags: ['ARXIV']\n---\nIn this paper, we propose to (seamlessly) integrate b-bit minwise hashing with linear SVM to substantially improve the training (and testing) efficiency using much smaller memory, with essentially no loss of accuracy. Theoretically, we prove that the resemblance matrix, the minwise hashing matrix, and the b-bit minwise hashing matrix are all positive definite matrices (kernels). Interestingly, our proof for the positive definiteness of the b-bit minwise hashing kernel naturally suggests a simple strategy to integrate b-bit hashing with linear SVM. Our technique is particularly useful when the data can not fit in memory, which is an increasingly critical issue in large-scale machine learning. Our preliminary experimental results on a publicly available webspam dataset (350K samples and 16 million dimensions) verified the effectiveness of our algorithm. For example, the training time was reduced to merely a few seconds. In addition, our technique can be easily extended to many other linear and nonlinear machine learning applications such as logistic regression.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-18.319000244140625, -5.551466941833496]}, {"key": "", "year": "", "title": "Li2011hashing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hashing Algorithms for Large-Scale Learning\"\nauthors: Li Ping, Shrivastava Anshumali, Moore Joshua, Konig Arnd Christian\nconference: Arxiv\nyear: 2011\nbibkey: li2011hashing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1106.0967\"}\ntags: ['ARXIV']\n---\nIn this paper, we first demonstrate that b-bit minwise hashing, whose estimators are positive definite kernels, can be naturally integrated with learning algorithms such as SVM and logistic regression. We adopt a simple scheme to transform the nonlinear (resemblance) kernel into linear (inner product) kernel; and hence large-scale problems can be solved extremely efficiently. Our method provides a simple effective solution to large-scale learning in massive and extremely high-dimensional datasets, especially when data do not fit in memory. We then compare b-bit minwise hashing with the Vowpal Wabbit (VW) algorithm (which is related the Count-Min (CM) sketch). Interestingly, VW has the same variances as random projections. Our theoretical and empirical comparisons illustrate that usually $b$-bit minwise hashing is significantly more accurate (at the same storage) than VW (and random projections) in binary data. Furthermore, $b$-bit minwise hashing can be combined with VW to achieve further improvements in terms of training speed, especially when $b$ is large.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-18.19240951538086, -5.210054874420166]}, {"key": "", "year": "", "title": "Li2011training", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Training Logistic Regression and SVM on 200GB Data Using b-Bit Minwise Hashing and Comparisons with Vowpal Wabbit (VW)\"\nauthors: Li Ping, Shrivastava Anshumali, Konig Christian\nconference: Arxiv\nyear: 2011\nbibkey: li2011training\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1108.3072\"}\ntags: ['ARXIV']\n---\nWe generated a dataset of 200 GB with 10^9 features, to test our recent b-bit minwise hashing algorithms for training very large-scale logistic regression and SVM. The results confirm our prior work that, compared with the VW hashing algorithm (which has the same variance as random projections), b-bit minwise hashing is substantially more accurate at the same storage. For example, with merely 30 hashed values per data point, b-bit minwise hashing can achieve similar accuracies as VW with 2^14 hashed values per data point. We demonstrate that the preprocessing cost of b-bit minwise hashing is roughly on the same order of magnitude as the data loading time. Furthermore, by using a GPU, the preprocessing cost can be reduced to a small fraction of the data loading time. Minwise hashing has been widely used in industry, at least in the context of search. One reason for its popularity is that one can efficiently simulate permutations by (e.g.,) universal hashing. In other words, there is no need to store the permutation matrix. In this paper, we empirically verify this practice, by demonstrating that even using the simplest 2-universal hashing does not degrade the learning performance.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-18.465938568115234, -6.016845703125]}, {"key": "", "year": "", "title": "Li2012b", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"b-Bit Minwise Hashing in Practice: Large-Scale Batch and Online Learning and Using GPUs for Fast Preprocessing with Simple Hash Functions\"\nauthors: Li Ping, Shrivastava Anshumali, Konig Arnd Christian\nconference: Arxiv\nyear: 2012\nbibkey: li2012b\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1205.2958\"}\ntags: ['ARXIV']\n---\nIn this paper, we study several critical issues which must be tackled before one can apply b-bit minwise hashing to the volumes of data often used industrial applications, especially in the context of search. 1. (b-bit) Minwise hashing requires an expensive preprocessing step that computes k (e.g., 500) minimal values after applying the corresponding permutations for each data vector. We developed a parallelization scheme using GPUs and observed that the preprocessing time can be reduced by a factor of 20-80 and becomes substantially smaller than the data loading time. 2. One major advantage of b-bit minwise hashing is that it can substantially reduce the amount of memory required for batch learning. However, as online algorithms become increasingly popular for large-scale learning in the context of search, it is not clear if b-bit minwise yields significant improvements for them. This paper demonstrates that $b$-bit minwise hashing provides an effective data size/dimension reduction scheme and hence it can dramatically reduce the data loading time for each epoch of the online training process. This is significant because online learning often requires many (e.g., 10 to 100) epochs to reach a sufficient accuracy. 3. Another critical issue is that for very large data sets it becomes impossible to store a (fully) random permutation matrix, due to its space requirements. Our paper is the first study to demonstrate that $b$-bit minwise hashing implemented using simple hash functions, e.g., the 2-universal (2U) and 4-universal (4U) hash families, can produce very similar learning results as using fully random permutations. Experiments on datasets of up to 200GB are presented.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-16.781999588012695, -8.5044527053833]}, {"key": "", "year": "", "title": "Li2012one", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"One Permutation Hashing for Efficient Search and Learning\"\nauthors: Li Ping, Owen Art, Zhang Cun-Hui\nconference: Arxiv\nyear: 2012\nbibkey: li2012one\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1208.1259\"}\ntags: ['ARXIV']\n---\nRecently, the method of b-bit minwise hashing has been applied to large-scale linear learning and sublinear time near-neighbor search. The major drawback of minwise hashing is the expensive preprocessing cost, as the method requires applying (e.g.,) k=200 to 500 permutations on the data. The testing time can also be expensive if a new data point (e.g., a new document or image) has not been processed, which might be a significant issue in user-facing applications. We develop a very simple solution based on one permutation hashing. Conceptually, given a massive binary data matrix, we permute the columns only once and divide the permuted columns evenly into k bins; and we simply store, for each data vector, the smallest nonzero location in each bin. The interesting probability analysis (which is validated by experiments) reveals that our one permutation scheme should perform very similarly to the original (k-permutation) minwise hashing. In fact, the one permutation scheme can be even slightly more accurate, due to the \"sample-without-replacement\" effect. Our experiments with training linear SVM and logistic regression on the webspam dataset demonstrate that this one permutation hashing scheme can achieve the same (or even slightly better) accuracies compared to the original k-permutation scheme. To test the robustness of our method, we also experiment with the small news20 dataset which is very sparse and has merely on average 500 nonzeros in each data vector. Interestingly, our one permutation scheme noticeably outperforms the k-permutation scheme when k is not too small on the news20 dataset. In summary, our method can achieve at least the same accuracy as the original k-permutation scheme, at merely 1/k of the original preprocessing cost.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-16.005950927734375, -12.897574424743652]}, {"key": "", "year": "", "title": "Li2013learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning Hash Functions Using Column Generation\"\nauthors: Li Xi, Lin Guosheng, Shen Chunhua, Hengel Anton van den, Dick Anthony\nconference: Arxiv\nyear: 2013\nbibkey: li2013learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1303.0339\"}\ntags: ['ARXIV']\n---\nFast nearest neighbor searching is becoming an increasingly important tool in solving many large-scale problems. Recently a number of approaches to learning data-dependent hash functions have been developed. In this work, we propose a column generation based method for learning data-dependent hash functions on the basis of proximity comparison information. Given a set of triplets that encode the pairwise proximity comparison information, our method learns hash functions that preserve the relative comparison relationships in the data as well as possible within the large-margin learning framework. The learning procedure is implemented using column generation and hence is named CGHash. At each iteration of the column generation procedure, the best hash function is selected. Unlike most other hashing methods, our method generalizes to new data points naturally; and has a training objective which is convex, thus ensuring that the global optimum can be identified. Experiments demonstrate that the proposed method learns compact binary codes and that its retrieval performance compares favorably with state-of-the-art methods when tested on a few benchmark datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-19.753740310668945, -2.3123672008514404]}, {"key": "", "year": "", "title": "Li2014coding", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Coding for Random Projections and Approximate Near Neighbor Search\"\nauthors: Li Ping, Mitzenmacher Michael, Shrivastava Anshumali\nconference: Arxiv\nyear: 2014\nbibkey: li2014coding\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1403.8144\"}\ntags: ['ARXIV', 'Quantisation']\n---\nThis technical note compares two coding (quantization) schemes for random projections in the context of sub-linear time approximate near neighbor search. The first scheme is based on uniform quantization while the second scheme utilizes a uniform quantization plus a uniformly random offset (which has been popular in practice). The prior work compared the two schemes in the context of similarity estimation and training linear classifiers, with the conclusion that the step of random offset is not necessary and may hurt the performance (depending on the similarity level). The task of near neighbor search is related to similarity estimation with importance distinctions and requires own study. In this paper, we demonstrate that in the context of near neighbor search, the step of random offset is not needed either and may hurt the performance (sometimes significantly so, depending on the similarity and other parameters).\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.767302513122559, -17.4818172454834]}, {"key": "", "year": "", "title": "Li2015binary", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Binary Speaker Embedding\"\nauthors: Li Lantian, Wang Dong, Xing Chao, Yu Kaimin, Zheng Thomas Fang\nconference: Arxiv\nyear: 2015\nbibkey: li2015binary\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1510.05937\"}\ntags: ['ARXIV', 'LSH']\n---\nThe popular i-vector model represents speakers as low-dimensional continuous vectors (i-vectors), and hence it is a way of continuous speaker embedding. In this paper, we investigate binary speaker embedding, which transforms i-vectors to binary vectors (codes) by a hash function. We start from locality sensitive hashing (LSH), a simple binarization approach where binary codes are derived from a set of random hash functions. A potential problem of LSH is that the randomly sampled hash functions might be suboptimal. We therefore propose an improved Hamming distance learning approach, where the hash function is learned by a variable-sized block training that projects each dimension of the original i-vectors to variable-sized binary codes independently. Our experiments show that binary speaker embedding can deliver competitive or even better results on both speaker verification and identification tasks, while the memory usage and the computation cost are significantly reduced.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.145867347717285, -3.9475808143615723]}, {"key": "", "year": "", "title": "Li2015fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast k-Nearest Neighbour Search via Dynamic Continuous Indexing\"\nauthors: Li Ke, Malik Jitendra\nconference: Arxiv\nyear: 2015\nbibkey: li2015fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1512.00442\"}\ntags: ['ARXIV', 'LSH', 'TOM']\n---\nExisting methods for retrieving k-nearest neighbours suffer from the curse of dimensionality. We argue this is caused in part by inherent deficiencies of space partitioning, which is the underlying strategy used by most existing methods. We devise a new strategy that avoids partitioning the vector space and present a novel randomized algorithm that runs in time linear in dimensionality of the space and sub-linear in the intrinsic dimensionality and the size of the dataset and takes space constant in dimensionality of the space and linear in the size of the dataset. The proposed algorithm allows fine-grained control over accuracy and speed on a per-query basis, automatically adapts to variations in data density, supports dynamic updates to the dataset and is easy-to-implement. We show appealing theoretical properties and demonstrate empirically that the proposed algorithm outperforms locality-sensitivity hashing (LSH) in terms of approximation quality, speed and space efficiency.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [0.02003704197704792, -15.848371505737305]}, {"key": "", "year": "", "title": "Li2015feature", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Feature Learning based Deep Supervised Hashing with Pairwise Labels\"\nauthors: Li Wu-Jun, Wang Sheng, Kang Wang-Cheng\nconference: Arxiv\nyear: 2015\nbibkey: li2015feature\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1511.03855\"}\ntags: ['ARXIV', 'Image Retrieval', 'Supervised']\n---\nRecent years have witnessed wide application of hashing for large-scale image retrieval. However, most existing hashing methods are based on hand-crafted features which might not be optimally compatible with the hashing procedure. Recently, deep hashing methods have been proposed to perform simultaneous feature learning and hash-code learning with deep neural networks, which have shown better performance than traditional hashing methods with hand-crafted features. Most of these deep hashing methods are supervised whose supervised information is given with triplet labels. For another common application scenario with pairwise labels, there have not existed methods for simultaneous feature learning and hash-code learning. In this paper, we propose a novel deep hashing method, called deep pairwise-supervised hashing(DPSH), to perform simultaneous feature learning and hash-code learning for applications with pairwise labels. Experiments on real datasets show that our DPSH method can outperform other methods to achieve the state-of-the-art performance in image retrieval applications.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-2.1783251762390137, 16.00779914855957]}, {"key": "", "year": "", "title": "Li2015rank", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Rank Subspace Learning for Compact Hash Codes\"\nauthors: Li Kai, Qi Guojun, Ye Jun, Hua Kien A.\nconference: Arxiv\nyear: 2015\nbibkey: li2015rank\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1503.05951\"}\ntags: ['ARXIV', 'Quantisation', 'Supervised', 'Unsupervised']\n---\nThe era of Big Data has spawned unprecedented interests in developing hashing algorithms for efficient storage and fast nearest neighbor search. Most existing work learn hash functions that are numeric quantizations of feature values in projected feature space. In this work, we propose a novel hash learning framework that encodes feature's rank orders instead of numeric values in a number of optimal low-dimensional ranking subspaces. We formulate the ranking subspace learning problem as the optimization of a piece-wise linear convex-concave function and present two versions of our algorithm: one with independent optimization of each hash bit and the other exploiting a sequential learning framework. Our work is a generalization of the Winner-Take-All (WTA) hash family and naturally enjoys all the numeric stability benefits of rank correlation measures while being optimized to achieve high precision at very short code length. We compare with several state-of-the-art hashing algorithms in both supervised and unsupervised domain, showing superior performance in a number of data sets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-19.269067764282227, -2.660404682159424]}, {"key": "", "year": "", "title": "Li20162", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"2-Bit Random Projections, NonLinear Estimators, and Approximate Near Neighbor Search\"\nauthors: Li Ping, Mitzenmacher Michael, Shrivastava Anshumali\nconference: Arxiv\nyear: 2016\nbibkey: li20162\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1602.06577\"}\ntags: ['ARXIV', 'Quantisation']\n---\nThe method of random projections has become a standard tool for machine learning, data mining, and search with massive data at Web scale. The effective use of random projections requires efficient coding schemes for quantizing (real-valued) projected data into integers. In this paper, we focus on a simple 2-bit coding scheme. In particular, we develop accurate nonlinear estimators of data similarity based on the 2-bit strategy. This work will have important practical applications. For example, in the task of near neighbor search, a crucial step (often called re-ranking) is to compute or estimate data similarities once a set of candidate data points have been identified by hash table techniques. This re-ranking step can take advantage of the proposed coding scheme and estimator. As a related task, in this paper, we also study a simple uniform quantization scheme for the purpose of building hash tables with projected data. Our analysis shows that typically only a small number of bits are needed. For example, when the target similarity level is high, 2 or 3 bits might be sufficient. When the target similarity level is not so high, it is preferable to use only 1 or 2 bits. Therefore, a 2-bit scheme appears to be overall a good choice for the task of sublinear time approximate near neighbor search via hash tables. Combining these results, we conclude that 2-bit random projections should be recommended for approximate near neighbor search and similarity estimation. Extensive experimental results are provided.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-6.81447172164917, -23.622631072998047]}, {"key": "", "year": "", "title": "Li2016a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A New Manifold Distance Measure for Visual Object Categorization\"\nauthors: Li Fengfu, Huang Xiayuan, Qiao Hong, Zhang Bo\nconference: Arxiv\nyear: 2016\nbibkey: li2016a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1605.03865\"}\ntags: ['ARXIV']\n---\nManifold distances are very effective tools for visual object recognition. However, most of the traditional manifold distances between images are based on the pixel-level comparison and thus easily affected by image rotations and translations. In this paper, we propose a new manifold distance to model the dissimilarities between visual objects based on the Complex Wavelet Structural Similarity (CW-SSIM) index. The proposed distance is more robust to rotations and translations of images than the traditional manifold distance and the CW-SSIM index based distance. In addition, the proposed distance is combined with the $k$-medoids clustering method to derive a new clustering method for visual object categorization. Experiments on Coil-20, Coil-100 and Olivetti Face Databases show that the proposed distance measure is better for visual object categorization than both the traditional manifold distances and the CW-SSIM index based distances.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [16.74195671081543, 3.433210611343384]}, {"key": "", "year": "", "title": "Li2016generalized", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Generalized Intersection Kernel\"\nauthors: Li Ping\nconference: Arxiv\nyear: 2016\nbibkey: li2016generalized\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1612.09283\"}\ntags: ['ARXIV']\n---\nFollowing the very recent line of work on the ``generalized min-max'' (GMM) kernel, this study proposes the ``generalized intersection'' (GInt) kernel and the related ``normalized generalized min-max'' (NGMM) kernel. In computer vision, the (histogram) intersection kernel has been popular, and the GInt kernel generalizes it to data which can have both negative and positive entries. Through an extensive empirical classification study on 40 datasets from the UCI repository, we are able to show that this (tuning-free) GInt kernel performs fairly well. The empirical results also demonstrate that the NGMM kernel typically outperforms the GInt kernel. Interestingly, the NGMM kernel has another interpretation --- it is the ``asymmetrically transformed'' version of the GInt kernel, based on the idea of ``asymmetric hashing''. Just like the GMM kernel, the NGMM kernel can be efficiently linearized through (e.g.,) generalized consistent weighted sampling (GCWS), as empirically validated in our study. Owing to the discrete nature of hashed values, it also provides a scheme for approximate near neighbor search.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-3.615643262863159, -15.941317558288574]}, {"key": "", "year": "", "title": "Li2017deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Binary Reconstruction for Cross-modal Hashing\"\nauthors: Li Xuelong, Hu Di, Nie Feiping\nconference: Arxiv\nyear: 2017\nbibkey: li2017deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1708.05127\"}\ntags: ['ARXIV', 'Cross Modal', 'GAN', 'Image Retrieval', 'Supervised', 'Unsupervised']\n---\nWith the increasing demand of massive multimodal data storage and organization, cross-modal retrieval based on hashing technique has drawn much attention nowadays. It takes the binary codes of one modality as the query to retrieve the relevant hashing codes of another modality. However, the existing binary constraint makes it difficult to find the optimal cross-modal hashing function. Most approaches choose to relax the constraint and perform thresholding strategy on the real-value representation instead of directly solving the original objective. In this paper, we first provide a concrete analysis about the effectiveness of multimodal networks in preserving the inter- and intra-modal consistency. Based on the analysis, we provide a so-called Deep Binary Reconstruction (DBRC) network that can directly learn the binary hashing codes in an unsupervised fashion. The superiority comes from a proposed simple but efficient activation function, named as Adaptive Tanh (ATanh). The ATanh function can adaptively learn the binary codes and be trained via back-propagation. Extensive experiments on three benchmark datasets demonstrate that DBRC outperforms several state-of-the-art methods in both image2text and text2image retrieval task.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-12.209417343139648, 9.958166122436523]}, {"key": "", "year": "", "title": "Li2017fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast k-Nearest Neighbour Search via Prioritized DCI\"\nauthors: Li Ke, Malik Jitendra\nconference: Arxiv\nyear: 2017\nbibkey: li2017fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1703.00440\"}\ntags: ['ARXIV', 'LSH']\n---\nMost exact methods for k-nearest neighbour search suffer from the curse of dimensionality; that is, their query times exhibit exponential dependence on either the ambient or the intrinsic dimensionality. Dynamic Continuous Indexing (DCI) offers a promising way of circumventing the curse and successfully reduces the dependence of query time on intrinsic dimensionality from exponential to sublinear. In this paper, we propose a variant of DCI, which we call Prioritized DCI, and show a remarkable improvement in the dependence of query time on intrinsic dimensionality. In particular, a linear increase in intrinsic dimensionality, or equivalently, an exponential increase in the number of points near a query, can be mostly counteracted with just a linear increase in space. We also demonstrate empirically that Prioritized DCI significantly outperforms prior methods. In particular, relative to Locality-Sensitive Hashing (LSH), Prioritized DCI reduces the number of distance evaluations by a factor of 14 to 116 and the memory consumption by a factor of 21.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [0.4459800720214844, -15.751286506652832]}, {"key": "", "year": "", "title": "Li2018dual", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Dual Asymmetric Deep Hashing Learning\"\nauthors: Li Jinxing, Zhang Bob, Lu Guangming, Zhang David\nconference: Arxiv\nyear: 2018\nbibkey: li2018dual\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1801.08360\"}\ntags: ['ARXIV', 'Deep Learning', 'Supervised', 'Unsupervised']\n---\nDue to the impressive learning power, deep learning has achieved a remarkable performance in supervised hash function learning. In this paper, we propose a novel asymmetric supervised deep hashing method to preserve the semantic structure among different categories and generate the binary codes simultaneously. Specifically, two asymmetric deep networks are constructed to reveal the similarity between each pair of images according to their semantic labels. The deep hash functions are then learned through two networks by minimizing the gap between the learned features and discrete codes. Furthermore, since the binary codes in the Hamming space also should keep the semantic affinity existing in the original space, another asymmetric pairwise loss is introduced to capture the similarity between the binary codes and real-value features. This asymmetric loss not only improves the retrieval performance, but also contributes to a quick convergence at the training phase. By taking advantage of the two-stream deep structures and two types of asymmetric pairwise functions, an alternating algorithm is designed to optimize the deep features and high-quality binary codes efficiently. Experimental results on three real-world datasets substantiate the effectiveness and superiority of our approach as compared with state-of-the-art.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-14.71789264678955, 7.3013834953308105]}, {"key": "", "year": "", "title": "Li2018self", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Self-Supervised Adversarial Hashing Networks for Cross-Modal Retrieval\"\nauthors: Li Chao, Deng Cheng, Li Ning, Liu Wei, Gao Xinbo, Tao Dacheng\nconference: Arxiv\nyear: 2018\nbibkey: li2018self\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1804.01223\"}\ntags: ['ARXIV', 'Cross Modal', 'Deep Learning', 'Self Supervised', 'Supervised']\n---\nThanks to the success of deep learning, cross-modal retrieval has made significant progress recently. However, there still remains a crucial bottleneck: how to bridge the modality gap to further enhance the retrieval accuracy. In this paper, we propose a self-supervised adversarial hashing (\\textbf{SSAH}) approach, which lies among the early attempts to incorporate adversarial learning into cross-modal hashing in a self-supervised fashion. The primary contribution of this work is that two adversarial networks are leveraged to maximize the semantic correlation and consistency of the representations between different modalities. In addition, we harness a self-supervised semantic network to discover high-level semantic information in the form of multi-label annotations. Such information guides the feature learning process and preserves the modality relationships in both the common semantic space and the Hamming space. Extensive experiments carried out on three benchmark datasets validate that the proposed SSAH surpasses the state-of-the-art methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-16.162139892578125, 6.382749080657959]}, {"key": "", "year": "", "title": "Li2019coupled", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Coupled CycleGAN: Unsupervised Hashing Network for Cross-Modal Retrieval\"\nauthors: Li Chao, Deng Cheng, Wang Lei, Xie De, Liu Xianglong\nconference: Arxiv\nyear: 2019\nbibkey: li2019coupled\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1903.02149\"}\ntags: ['ARXIV', 'Cross Modal', 'Deep Learning', 'GAN', 'Supervised', 'Unsupervised']\n---\nIn recent years, hashing has attracted more and more attention owing to its superior capacity of low storage cost and high query efficiency in large-scale cross-modal retrieval. Benefiting from deep leaning, continuously compelling results in cross-modal retrieval community have been achieved. However, existing deep cross-modal hashing methods either rely on amounts of labeled information or have no ability to learn an accuracy correlation between different modalities. In this paper, we proposed Unsupervised coupled Cycle generative adversarial Hashing networks (UCH), for cross-modal retrieval, where outer-cycle network is used to learn powerful common representation, and inner-cycle network is explained to generate reliable hash codes. Specifically, our proposed UCH seamlessly couples these two networks with generative adversarial mechanism, which can be optimized simultaneously to learn representation and hash codes. Extensive experiments on three popular benchmark datasets show that the proposed UCH outperforms the state-of-the-art unsupervised cross-modal hashing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-8.644454956054688, -3.1099488735198975]}, {"key": "", "year": "", "title": "Li2019deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Multi-Index Hashing for Person Re-Identification\"\nauthors: Li Ming-Wei, Jiang Qing-Yuan, Li Wu-Jun\nconference: Arxiv\nyear: 2019\nbibkey: li2019deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1905.10980\"}\ntags: ['ARXIV']\n---\nTraditional person re-identification (ReID) methods typically represent person images as real-valued features, which makes ReID inefficient when the gallery set is extremely large. Recently, some hashing methods have been proposed to make ReID more efficient. However, these hashing methods will deteriorate the accuracy in general, and the efficiency of them is still not high enough. In this paper, we propose a novel hashing method, called deep multi-index hashing (DMIH), to improve both efficiency and accuracy for ReID. DMIH seamlessly integrates multi-index hashing and multi-branch based networks into the same framework. Furthermore, a novel block-wise multi-index hashing table construction approach and a search-aware multi-index (SAMI) loss are proposed in DMIH to improve the search efficiency. Experiments on three widely used datasets show that DMIH can outperform other state-of-the-art baselines, including both hashing methods and real-valued methods, in terms of both efficiency and accuracy.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [0.39941710233688354, 14.94279670715332]}, {"key": "", "year": "", "title": "Li2019learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning Content-Weighted Deep Image Compression\"\nauthors: Li Mu, Zuo Wangmeng, Gu Shuhang, You Jane, Zhang David\nconference: Arxiv\nyear: 2019\nbibkey: li2019learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1904.00664\"}\ntags: ['ARXIV']\n---\nLearning-based lossy image compression usually involves the joint optimization of rate-distortion performance. Most existing methods adopt spatially invariant bit length allocation and incorporate discrete entropy approximation to constrain compression rate. Nonetheless, the information content is spatially variant, where the regions with complex and salient structures generally are more essential to image compression. Taking the spatial variation of image content into account, this paper presents a content-weighted encoder-decoder model, which involves an importance map subnet to produce the importance mask for locally adaptive bit rate allocation. Consequently, the summation of importance mask can thus be utilized as an alternative of entropy estimation for compression rate control. Furthermore, the quantized representations of the learned code and importance map are still spatially dependent, which can be losslessly compressed using arithmetic coding. To compress the codes effectively and efficiently, we propose a trimmed convolutional network to predict the conditional probability of quantized codes. Experiments show that the proposed method can produce visually much better results, and performs favorably in comparison with deep and traditional lossy image compression approaches.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [8.179634094238281, 4.750388145446777]}, {"key": "", "year": "", "title": "Li2019push", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Push for Quantization: Deep Fisher Hashing\"\nauthors: Li Yunqiang, Pei Wenjie, zha Yufei, van Gemert Jan\nconference: Arxiv\nyear: 2019\nbibkey: li2019push\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1909.00206\"}\ntags: ['ARXIV', 'Deep Learning', 'Quantisation']\n---\nCurrent massive datasets demand light-weight access for analysis. Discrete hashing methods are thus beneficial because they map high-dimensional data to compact binary codes that are efficient to store and process, while preserving semantic similarity. To optimize powerful deep learning methods for image hashing, gradient-based methods are required. Binary codes, however, are discrete and thus have no continuous derivatives. Relaxing the problem by solving it in a continuous space and then quantizing the solution is not guaranteed to yield separable binary codes. The quantization needs to be included in the optimization. In this paper we push for quantization: We optimize maximum class separability in the binary space. We introduce a margin on distances between dissimilar image pairs as measured in the binary space. In addition to pair-wise distances, we draw inspiration from Fisher's Linear Discriminant Analysis (Fisher LDA) to maximize the binary distances between classes and at the same time minimize the binary distance of images within the same class. Experiments on CIFAR-10, NUS-WIDE and ImageNet100 demonstrate compact codes comparing favorably to the current state of the art.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [1.1265133619308472, 2.905229091644287]}, {"key": "", "year": "", "title": "Li2020deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Unsupervised Image Hashing by Maximizing Bit Entropy\"\nauthors: Li Yunqiang, van Gemert Jan\nconference: Arxiv\nyear: 2020\nbibkey: li2020deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2012.12334\"}\ntags: ['ARXIV', 'Supervised', 'Unsupervised']\n---\nUnsupervised hashing is important for indexing huge image or video collections without having expensive annotations available. Hashing aims to learn short binary codes for compact storage and efficient semantic retrieval. We propose an unsupervised deep hashing layer called Bi-half Net that maximizes entropy of the binary codes. Entropy is maximal when both possible values of the bit are uniformly (half-half) distributed. To maximize bit entropy, we do not add a term to the loss function as this is difficult to optimize and tune. Instead, we design a new parameter-free network layer to explicitly force continuous image features to approximate the optimal half-half bit distribution. This layer is shown to minimize a penalized term of the Wasserstein distance between the learned continuous image features and the optimal half-half bit distribution. Experimental results on the image datasets Flickr25k, Nus-wide, Cifar-10, Mscoco, Mnist and the video datasets Ucf-101 and Hmdb-51 show that our approach leads to compact codes and compares favorably to the current state-of-the-art.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [2.1249523162841797, 12.65829086303711]}, {"key": "", "year": "", "title": "Li2020hamming", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hamming OCR: A Locality Sensitive Hashing Neural Network for Scene Text Recognition\"\nauthors: Li Bingcong, Tang Xin, Qi Xianbiao, Chen Yihao, Xiao Rong\nconference: Arxiv\nyear: 2020\nbibkey: li2020hamming\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2009.10874\"}\ntags: ['ARXIV', 'LSH', 'TIP']\n---\nRecently, inspired by Transformer, self-attention-based scene text recognition approaches have achieved outstanding performance. However, we find that the size of model expands rapidly with the lexicon increasing. Specifically, the number of parameters for softmax classification layer and output embedding layer are proportional to the vocabulary size. It hinders the development of a lightweight text recognition model especially applied for Chinese and multiple languages. Thus, we propose a lightweight scene text recognition model named Hamming OCR. In this model, a novel Hamming classifier, which adopts locality sensitive hashing (LSH) algorithm to encode each character, is proposed to replace the softmax regression and the generated LSH code is directly employed to replace the output embedding. We also present a simplified transformer decoder to reduce the number of parameters by removing the feed-forward network and using cross-layer parameter sharing technique. Compared with traditional methods, the number of parameters in both classification and embedding layers is independent on the size of vocabulary, which significantly reduces the storage requirement without loss of accuracy. Experimental results on several datasets, including four public benchmaks and a Chinese text dataset synthesized by SynthText with more than 20,000 characters, shows that Hamming OCR achieves competitive results.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [5.76258659362793, 11.366022109985352]}, {"key": "", "year": "", "title": "Li2020multiple", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Multiple Code Hashing for Efficient Image Retrieval\"\nauthors: Li Ming-Wei, Jiang Qing-Yuan, Li Wu-Jun\nconference: Arxiv\nyear: 2020\nbibkey: li2020multiple\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2008.01503\"}\ntags: ['ARXIV', 'Image Retrieval', 'TIP']\n---\nDue to its low storage cost and fast query speed, hashing has been widely used in large-scale image retrieval tasks. Hash bucket search returns data points within a given Hamming radius to each query, which can enable search at a constant or sub-linear time cost. However, existing hashing methods cannot achieve satisfactory retrieval performance for hash bucket search in complex scenarios, since they learn only one hash code for each image. More specifically, by using one hash code to represent one image, existing methods might fail to put similar image pairs to the buckets with a small Hamming distance to the query when the semantic information of images is complex. As a result, a large number of hash buckets need to be visited for retrieving similar images, based on the learned codes. This will deteriorate the efficiency of hash bucket search. In this paper, we propose a novel hashing framework, called multiple code hashing (MCH), to improve the performance of hash bucket search. The main idea of MCH is to learn multiple hash codes for each image, with each code representing a different region of the image. Furthermore, we propose a deep reinforcement learning algorithm to learn the parameters in MCH. To the best of our knowledge, this is the first work that proposes to learn multiple hash codes for each image in image retrieval. Experiments demonstrate that MCH can achieve a significant improvement in hash bucket search, compared with existing methods that learn only one hash code for each image.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-0.34590455889701843, 7.913773536682129]}, {"key": "", "year": "", "title": "Li2020perceptual", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Perceptual Robust Hashing for Color Images with Canonical Correlation Analysis\"\nauthors: Li Xinran, Qin Chuan, Qian Zhenxing, Yao Heng, Zhang Xinpeng\nconference: Arxiv\nyear: 2020\nbibkey: li2020perceptual\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2012.04312\"}\ntags: ['ARXIV']\n---\nIn this paper, a novel perceptual image hashing scheme for color images is proposed based on ring-ribbon quadtree and color vector angle. First, original image is subjected to normalization and Gaussian low-pass filtering to produce a secondary image, which is divided into a series of ring-ribbons with different radii and the same number of pixels. Then, both textural and color features are extracted locally and globally. Quadtree decomposition (QD) is applied on luminance values of the ring-ribbons to extract local textural features, and the gray level co-occurrence matrix (GLCM) is used to extract global textural features. Local color features of significant corner points on outer boundaries of ring-ribbons are extracted through color vector angles (CVA), and color low-order moments (CLMs) is utilized to extract global color features. Finally, two types of feature vectors are fused via canonical correlation analysis (CCA) to prodcue the final hash after scrambling. Compared with direct concatenation, the CCA feature fusion method improves classification performance, which better reflects overall correlation between two sets of feature vectors. Receiver operating characteristic (ROC) curve shows that our scheme has satisfactory performances with respect to robustness, discrimination and security, which can be effectively used in copy detection and content authentication.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [5.555186748504639, 5.912532329559326]}, {"key": "", "year": "", "title": "Li2020task", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Task-adaptive Asymmetric Deep Cross-modal Hashing\"\nauthors: Li Fengling, Wang Tong, Zhu Lei, Zhang Zheng, Wang Xinhua\nconference: Arxiv\nyear: 2020\nbibkey: li2020task\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2004.00197\"}\ntags: ['ARXIV', 'Cross Modal', 'Supervised', 'Unsupervised']\n---\nSupervised cross-modal hashing aims to embed the semantic correlations of heterogeneous modality data into the binary hash codes with discriminative semantic labels. Because of its advantages on retrieval and storage efficiency, it is widely used for solving efficient cross-modal retrieval. However, existing researches equally handle the different tasks of cross-modal retrieval, and simply learn the same couple of hash functions in a symmetric way for them. Under such circumstance, the uniqueness of different cross-modal retrieval tasks are ignored and sub-optimal performance may be brought. Motivated by this, we present a Task-adaptive Asymmetric Deep Cross-modal Hashing (TA-ADCMH) method in this paper. It can learn task-adaptive hash functions for two sub-retrieval tasks via simultaneous modality representation and asymmetric hash learning. Unlike previous cross-modal hashing approaches, our learning framework jointly optimizes semantic preserving that transforms deep features of multimedia data into binary hash codes, and the semantic regression which directly regresses query modality representation to explicit label. With our model, the binary codes can effectively preserve semantic correlations across different modalities, meanwhile, adaptively capture the query semantics. The superiority of TA-ADCMH is proved on two standard datasets from many aspects.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-5.378818035125732, -2.676800012588501]}, {"key": "", "year": "", "title": "Li2020topology", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Topology-Aware Hashing for Effective Control Flow Graph Similarity Analysis\"\nauthors: Li Yuping, Jang Jiong, Ou Xinming\nconference: In International Conference on Security and Privacy in Communication Systems, pp.\nyear: 2020\nbibkey: li2020topology\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2004.06563\"}\ntags: ['Graph']\n---\nControl Flow Graph (CFG) similarity analysis is an essential technique for a variety of security analysis tasks, including malware detection and malware clustering. Even though various algorithms have been developed, existing CFG similarity analysis methods still suffer from limited efficiency, accuracy, and usability. In this paper, we propose a novel fuzzy hashing scheme called topology-aware hashing (TAH) for effective and efficient CFG similarity analysis. Given the CFGs constructed from program binaries, we extract blended n-gram graphical features of the CFGs, encode the graphical features into numeric vectors (called graph signatures), and then measure the graph similarity by comparing the graph signatures. We further employ a fuzzy hashing technique to convert the numeric graph signatures into smaller fixed-size fuzzy hash signatures for efficient similarity calculation. Our comprehensive evaluation demonstrates that TAH is more effective and efficient compared to existing CFG comparison techniques. To demonstrate the applicability of TAH to real-world security analysis tasks, we develop a binary similarity analysis tool based on TAH, and show that it outperforms existing similarity analysis tools while conducting malware clustering.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [3.1695163249969482, -25.504106521606445]}, {"key": "", "year": "", "title": "Li2021c", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"C-OPH: Improving the Accuracy of One Permutation Hashing (OPH) with Circulant Permutations\"\nauthors: Li Xiaoyun, Li Ping\nconference: Arxiv\nyear: 2021\nbibkey: li2021c\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2111.09544\"}\ntags: ['ARXIV']\n---\nMinwise hashing (MinHash) is a classical method for efficiently estimating the Jaccrad similarity in massive binary (0/1) data. To generate $K$ hash values for each data vector, the standard theory of MinHash requires $K$ independent permutations. Interestingly, the recent work on \"circulant MinHash\" (C-MinHash) has shown that merely two permutations are needed. The first permutation breaks the structure of the data and the second permutation is re-used $K$ time in a circulant manner. Surprisingly, the estimation accuracy of C-MinHash is proved to be strictly smaller than that of the original MinHash. The more recent work further demonstrates that practically only one permutation is needed. Note that C-MinHash is different from the well-known work on \"One Permutation Hashing (OPH)\" published in NIPS'12. OPH and its variants using different \"densification\" schemes are popular alternatives to the standard MinHash. The densification step is necessary in order to deal with empty bins which exist in One Permutation Hashing. In this paper, we propose to incorporate the essential ideas of C-MinHash to improve the accuracy of One Permutation Hashing. Basically, we develop a new densification method for OPH, which achieves the smallest estimation variance compared to all existing densification schemes for OPH. Our proposed method is named C-OPH (Circulant OPH). After the initial permutation (which breaks the existing structure of the data), C-OPH only needs a \"shorter\" permutation of length $D/K$ (instead of $D$), where $D$ is the original data dimension and $K$ is the total number of bins in OPH. This short permutation is re-used in $K$ bins in a circulant shifting manner. It can be shown that the estimation variance of the Jaccard similarity is strictly smaller than that of the existing (densified) OPH methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-13.51402473449707, -18.937503814697266]}, {"key": "", "year": "", "title": "Li2022adaptive", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Adaptive Structural Similarity Preserving for Unsupervised Cross Modal Hashing\"\nauthors: Li Liang, Zheng Baihua, Sun Weiwei\nconference: Arxiv\nyear: 2022\nbibkey: li2022adaptive\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2207.04214\"}\ntags: ['ARXIV', 'Cross Modal', 'Graph', 'Supervised', 'Unsupervised']\n---\nCross-modal hashing is an important approach for multimodal data management and application. Existing unsupervised cross-modal hashing algorithms mainly rely on data features in pre-trained models to mine their similarity relationships. However, their optimization objectives are based on the static metric between the original uni-modal features, without further exploring data correlations during the training. In addition, most of them mainly focus on association mining and alignment among pairwise instances in continuous space but ignore the latent structural correlations contained in the semantic hashing space. In this paper, we propose an unsupervised hash learning framework, namely Adaptive Structural Similarity Preservation Hashing (ASSPH), to solve the above problems. Firstly, we propose an adaptive learning scheme, with limited data and training batches, to enrich semantic correlations of unlabeled instances during the training process and meanwhile to ensure a smooth convergence of the training process. Secondly, we present an asymmetric structural semantic representation learning scheme. We introduce structural semantic metrics based on graph adjacency relations during the semantic reconstruction and correlation mining stage and meanwhile align the structure semantics in the hash space with an asymmetric binary optimization process. Finally, we conduct extensive experiments to validate the enhancements of our work in comparison with existing works.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [1.7176454067230225, -29.99410629272461]}, {"key": "", "year": "", "title": "Li2022asymmetric", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Asymmetric Scalable Cross-modal Hashing\"\nauthors: Li Wenyun, Pun Chi-Man\nconference: Arxiv\nyear: 2022\nbibkey: li2022asymmetric\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2207.12650\"}\ntags: ['ARXIV', 'Cross Modal']\n---\nCross-modal hashing is a successful method to solve large-scale multimedia retrieval issue. A lot of matrix factorization-based hashing methods are proposed. However, the existing methods still struggle with a few problems, such as how to generate the binary codes efficiently rather than directly relax them to continuity. In addition, most of the existing methods choose to use an $n\\times n$ similarity matrix for optimization, which makes the memory and computation unaffordable. In this paper we propose a novel Asymmetric Scalable Cross-Modal Hashing (ASCMH) to address these issues. It firstly introduces a collective matrix factorization to learn a common latent space from the kernelized features of different modalities, and then transforms the similarity matrix optimization to a distance-distance difference problem minimization with the help of semantic labels and common latent space. Hence, the computational complexity of the $n\\times n$ asymmetric optimization is relieved. In the generation of hash codes we also employ an orthogonal constraint of label information, which is indispensable for search accuracy. So the redundancy of computation can be much reduced. For efficient optimization and scalable to large-scale datasets, we adopt the two-step approach rather than optimizing simultaneously. Extensive experiments on three benchmark datasets: Wiki, MIRFlickr-25K, and NUS-WIDE, demonstrate that our ASCMH outperforms the state-of-the-art cross-modal hashing methods in terms of accuracy and efficiency.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-14.046359062194824, -8.707317352294922]}, {"key": "", "year": "", "title": "Li2022vgstore", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"VGStore: A Multimodal Extension to SPARQL for Querying RDF Scene Graph\"\nauthors: Li Yanzeng, Zheng Zilong, Han Wenjuan, Zou Lei\nconference: Arxiv\nyear: 2022\nbibkey: li2022vgstore\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2209.02981\"}\ntags: ['ARXIV', 'GAN', 'Graph', 'TOM']\n---\nSemantic Web technology has successfully facilitated many RDF models with rich data representation methods. It also has the potential ability to represent and store multimodal knowledge bases such as multimodal scene graphs. However, most existing query languages, especially SPARQL, barely explore the implicit multimodal relationships like semantic similarity, spatial relations, etc. We first explored this issue by organizing a large-scale scene graph dataset, namely Visual Genome, in the RDF graph database. Based on the proposed RDF-stored multimodal scene graph, we extended SPARQL queries to answer questions containing relational reasoning about color, spatial, etc. Further demo (i.e., VGStore) shows the effectiveness of customized queries and displaying multimodal data.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [14.818653106689453, -24.919971466064453]}, {"key": "", "year": "", "title": "Li2023differentially", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Differentially Private One Permutation Hashing and Bin-wise Consistent Weighted Sampling\"\nauthors: Li Xiaoyun, Li Ping\nconference: Arxiv\nyear: 2023\nbibkey: li2023differentially\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2306.07674\"}\ntags: ['ARXIV']\n---\nMinwise hashing (MinHash) is a standard algorithm widely used in the industry, for large-scale search and learning applications with the binary (0/1) Jaccard similarity. One common use of MinHash is for processing massive n-gram text representations so that practitioners do not have to materialize the original data (which would be prohibitive). Another popular use of MinHash is for building hash tables to enable sub-linear time approximate near neighbor (ANN) search. MinHash has also been used as a tool for building large-scale machine learning systems. The standard implementation of MinHash requires applying $K$ random permutations. In comparison, the method of one permutation hashing (OPH), is an efficient alternative of MinHash which splits the data vectors into $K$ bins and generates hash values within each bin. OPH is substantially more efficient and also more convenient to use. In this paper, we combine the differential privacy (DP) with OPH (as well as MinHash), to propose the DP-OPH framework with three variants: DP-OPH-fix, DP-OPH-re and DP-OPH-rand, depending on which densification strategy is adopted to deal with empty bins in OPH. A detailed roadmap to the algorithm design is presented along with the privacy analysis. An analytical comparison of our proposed DP-OPH methods with the DP minwise hashing (DP-MH) is provided to justify the advantage of DP-OPH. Experiments on similarity search confirm the merits of DP-OPH, and guide the choice of the proper variant in different practical scenarios. Our technique is also extended to bin-wise consistent weighted sampling (BCWS) to develop a new DP algorithm called DP-BCWS for non-binary data. Experiments on classification tasks demonstrate that DP-BCWS is able to achieve excellent utility at around $\\epsilon = 5\\sim 10$, where $\\epsilon$ is the standard parameter in the language of $(\\epsilon, \\delta)$-DP.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-12.813417434692383, -16.24052619934082]}, {"key": "", "year": "", "title": "Li2023dual", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Dual-Stream Knowledge-Preserving Hashing for Unsupervised Video Retrieval\"\nauthors: Li Pandeng, Xie Hongtao, Ge Jiannan, Zhang Lei, Min Shaobo, Zhang Yongdong\nconference: Arxiv\nyear: 2023\nbibkey: li2023dual\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2310.08009\"}\ntags: ['ARXIV', 'Supervised', 'Unsupervised', 'Video Retrieval']\n---\nUnsupervised video hashing usually optimizes binary codes by learning to reconstruct input videos. Such reconstruction constraint spends much effort on frame-level temporal context changes without focusing on video-level global semantics that are more useful for retrieval. Hence, we address this problem by decomposing video information into reconstruction-dependent and semantic-dependent information, which disentangles the semantic extraction from reconstruction constraint. Specifically, we first design a simple dual-stream structure, including a temporal layer and a hash layer. Then, with the help of semantic similarity knowledge obtained from self-supervision, the hash layer learns to capture information for semantic retrieval, while the temporal layer learns to capture the information for reconstruction. In this way, the model naturally preserves the disentangled semantics into binary codes. Validated by comprehensive experiments, our method consistently outperforms the state-of-the-arts on three video benchmarks.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-0.46396738290786743, 26.93344497680664]}, {"key": "", "year": "", "title": "Li2023locality", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Locality Preserving Multiview Graph Hashing for Large Scale Remote Sensing Image Search\"\nauthors: Li Wenyun, Zhong Guo, Lu Xingyu, Pun Chi-Man\nconference: Arxiv\nyear: 2023\nbibkey: li2023locality\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2304.04368\"}\ntags: ['ARXIV', 'Graph']\n---\nHashing is very popular for remote sensing image search. This article proposes a multiview hashing with learnable parameters to retrieve the queried images for a large-scale remote sensing dataset. Existing methods always neglect that real-world remote sensing data lies on a low-dimensional manifold embedded in high-dimensional ambient space. Unlike previous methods, this article proposes to learn the consensus compact codes in a view-specific low-dimensional subspace. Furthermore, we have added a hyperparameter learnable module to avoid complex parameter tuning. In order to prove the effectiveness of our method, we carried out experiments on three widely used remote sensing data sets and compared them with seven state-of-the-art methods. Extensive experiments show that the proposed method can achieve competitive results compared to the other method.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-0.21919281780719757, 12.105968475341797]}, {"key": "", "year": "", "title": "Li2023pb", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Pb-Hash: Partitioned b-bit Hashing\"\nauthors: Li Ping, Zhao Weijie\nconference: Arxiv\nyear: 2023\nbibkey: li2023pb\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2306.15944\"}\ntags: ['ARXIV', 'Deep Learning']\n---\nMany hashing algorithms including minwise hashing (MinHash), one permutation hashing (OPH), and consistent weighted sampling (CWS) generate integers of $B$ bits. With $k$ hashes for each data vector, the storage would be $B\\times k$ bits; and when used for large-scale learning, the model size would be $2^B\\times k$, which can be expensive. A standard strategy is to use only the lowest $b$ bits out of the $B$ bits and somewhat increase $k$, the number of hashes. In this study, we propose to re-use the hashes by partitioning the $B$ bits into $m$ chunks, e.g., $b\\times m =B$. Correspondingly, the model size becomes $m\\times 2^b \\times k$, which can be substantially smaller than the original $2^B\\times k$. Our theoretical analysis reveals that by partitioning the hash values into $m$ chunks, the accuracy would drop. In other words, using $m$ chunks of $B/m$ bits would not be as accurate as directly using $B$ bits. This is due to the correlation from re-using the same hash. On the other hand, our analysis also shows that the accuracy would not drop much for (e.g.,) $m=2\\sim 4$. In some regions, Pb-Hash still works well even for $m$ much larger than 4. We expect Pb-Hash would be a good addition to the family of hashing methods/applications and benefit industrial practitioners. We verify the effectiveness of Pb-Hash in machine learning tasks, for linear SVM models as well as deep learning models. Since the hashed data are essentially categorical (ID) features, we follow the standard practice of using embedding tables for each hash. With Pb-Hash, we need to design an effective strategy to combine $m$ embeddings. Our study provides an empirical evaluation on four pooling schemes: concatenation, max pooling, mean pooling, and product pooling. There is no definite answer which pooling would be always better and we leave that for future study.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-16.014392852783203, -12.629125595092773]}, {"key": "", "year": "", "title": "Li2024comae", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"COMAE: COMprehensive Attribute Exploration for Zero-shot Hashing\"\nauthors: Li Yuqi, Long Qingqing, Zhou Yihang, Cao Ning, Liu Shuai, Zheng Fang, Zhu Zhihong, Ning Zhiyuan, Xiao Meng, Wang Xuezhi, Wang Pengfei, Zhou Yuanchun\nconference: Arxiv\nyear: 2024\nbibkey: li2024comae\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2402.16424\"}\ntags: ['ARXIV']\n---\nZero-shot hashing (ZSH) has shown excellent success owing to its efficiency and generalization in large-scale retrieval scenarios. While considerable success has been achieved, there still exist urgent limitations. Existing works ignore the locality relationships of representations and attributes, which have effective transferability between seeable classes and unseeable classes. Also, the continuous-value attributes are not fully harnessed. In response, we conduct a COMprehensive Attribute Exploration for ZSH, named COMAE, which depicts the relationships from seen classes to unseen ones through three meticulously designed explorations, i.e., point-wise, pair-wise and class-wise consistency constraints. By regressing attributes from the proposed attribute prototype network, COMAE learns the local features that are relevant to the visual attributes. Then COMAE utilizes contrastive learning to comprehensively depict the context of attributes, rather than instance-independent optimization. Finally, the class-wise constraint is designed to cohesively learn the hash code, image representation, and visual attributes more effectively. Experimental results on the popular ZSH datasets demonstrate that COMAE outperforms state-of-the-art hashing techniques, especially in scenarios with a larger number of unseen label classes.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-12.51335620880127, 0.0998648852109909]}, {"key": "", "year": "", "title": "Lian2007one", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"One-way Hash Function Based on Neural Network\"\nauthors: Lian Shiguo, Sun Jinsheng, Wang Zhiquan\nconference: Arxiv\nyear: 2007\nbibkey: lian2007one\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/0707.4032\"}\ntags: ['ARXIV']\n---\nA hash function is constructed based on a three-layer neural network. The three neuron-layers are used to realize data confusion, diffusion and compression respectively, and the multi-block hash mode is presented to support the plaintext with variable length. Theoretical analysis and experimental results show that this hash function is one-way, with high key sensitivity and plaintext sensitivity, and secure against birthday attacks or meet-in-the-middle attacks. Additionally, the neural network's property makes it practical to realize in a parallel way. These properties make it a suitable choice for data signature or authentication.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-30.708356857299805, 2.7762808799743652]}, {"key": "", "year": "", "title": "Liang2013image", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Image Retrieval using Histogram Factorization and Contextual Similarity Learning\"\nauthors: Liang Liu\nconference: Arxiv\nyear: 2013\nbibkey: liang2013image\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1304.1995\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nImage retrieval has been a top topic in the field of both computer vision and machine learning for a long time. Content based image retrieval, which tries to retrieve images from a database visually similar to a query image, has attracted much attention. Two most important issues of image retrieval are the representation and ranking of the images. Recently, bag-of-words based method has shown its power as a representation method. Moreover, nonnegative matrix factorization is also a popular way to represent the data samples. In addition, contextual similarity learning has also been studied and proven to be an effective method for the ranking problem. However, these technologies have never been used together. In this paper, we developed an effective image retrieval system by representing each image using the bag-of-words method as histograms, and then apply the nonnegative matrix factorization to factorize the histograms, and finally learn the ranking score using the contextual similarity learning method. The proposed novel system is evaluated on a large scale image database and the effectiveness is shown.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [25.32607078552246, 13.407630920410156]}, {"key": "", "year": "", "title": "Liang2023learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning Compact Compositional Embeddings via Regularized Pruning for Recommendation\"\nauthors: Liang Xurong, Chen Tong, Nguyen Quoc Viet Hung, Li Jianxin, Yin Hongzhi\nconference: Arxiv\nyear: 2023\nbibkey: liang2023learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2309.03518\"}   - {name: \"Code\", url: \"https://github.com/xurong-liang/CERP.\"}\ntags: ['ARXIV']\n---\nLatent factor models are the dominant backbones of contemporary recommender systems (RSs) given their performance advantages, where a unique vector embedding with a fixed dimensionality (e.g., 128) is required to represent each entity (commonly a user/item). Due to the large number of users and items on e-commerce sites, the embedding table is arguably the least memory-efficient component of RSs. For any lightweight recommender that aims to efficiently scale with the growing size of users/items or to remain applicable in resource-constrained settings, existing solutions either reduce the number of embeddings needed via hashing, or sparsify the full embedding table to switch off selected embedding dimensions. However, as hash collision arises or embeddings become overly sparse, especially when adapting to a tighter memory budget, those lightweight recommenders inevitably have to compromise their accuracy. To this end, we propose a novel compact embedding framework for RSs, namely Compositional Embedding with Regularized Pruning (CERP). Specifically, CERP represents each entity by combining a pair of embeddings from two independent, substantially smaller meta-embedding tables, which are then jointly pruned via a learnable element-wise threshold. In addition, we innovatively design a regularized pruning mechanism in CERP, such that the two sparsified meta-embedding tables are encouraged to encode information that is mutually complementary. Given the compatibility with agnostic latent factor models, we pair CERP with two popular recommendation models for extensive experiments, where results on two real-world datasets under different memory budgets demonstrate its superiority against state-of-the-art baselines. The codebase of CERP is available in https://github.com/xurong-liang/CERP.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [1.0617069005966187, -5.937431812286377]}, {"key": "", "year": "", "title": "Liao2020embedding", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Embedding Compression with Isotropic Iterative Quantization\"\nauthors: Liao Siyu, Chen Jie, Wang Yanzhi, Qiu Qinru, Yuan Bo\nconference: Arxiv\nyear: 2020\nbibkey: liao2020embedding\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2001.05314\"}\ntags: ['ARXIV', 'Deep Learning', 'Image Retrieval', 'Quantisation']\n---\nContinuous representation of words is a standard component in deep learning-based NLP models. However, representing a large vocabulary requires significant memory, which can cause problems, particularly on resource-constrained platforms. Therefore, in this paper we propose an isotropic iterative quantization (IIQ) approach for compressing embedding vectors into binary ones, leveraging the iterative quantization technique well established for image retrieval, while satisfying the desired isotropic property of PMI based models. Experiments with pre-trained embeddings (i.e., GloVe and HDC) demonstrate a more than thirty-fold compression ratio with comparable and sometimes even improved performance over the original real-valued embedding vectors.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.773414611816406, -4.037317276000977]}, {"key": "", "year": "", "title": "Liao2022supervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Supervised Metric Learning to Rank for Retrieval via Contextual Similarity Optimization\"\nauthors: Liao Christopher, Tsiligkaridis Theodoros, Kulis Brian\nconference: Arxiv\nyear: 2022\nbibkey: liao2022supervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2210.01908\"}   - {name: \"Code\", url: \"https://github.com/Chris210634/metric-learning-using-contextual-similarity\"}\ntags: ['ARXIV', 'Image Retrieval', 'Supervised', 'TIP', 'Unsupervised']\n---\nThere is extensive interest in metric learning methods for image retrieval. Many metric learning loss functions focus on learning a correct ranking of training samples, but strongly overfit semantically inconsistent labels and require a large amount of data. To address these shortcomings, we propose a new metric learning method, called contextual loss, which optimizes contextual similarity in addition to cosine similarity. Our contextual loss implicitly enforces semantic consistency among neighbors while converging to the correct ranking. We empirically show that the proposed loss is more robust to label noise, and is less prone to overfitting even when a large portion of train data is withheld. Extensive experiments demonstrate that our method achieves a new state-of-the-art across four image retrieval benchmarks and multiple different evaluation settings. Code is available at: https://github.com/Chris210634/metric-learning-using-contextual-similarity\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [14.230207443237305, 7.632795333862305]}, {"key": "", "year": "", "title": "Lillis2017hierarchical", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hierarchical Bloom Filter Trees for Approximate Matching\"\nauthors: Lillis David, Breitinger Frank, Scanlon Mark\nconference: Arxiv\nyear: 2017\nbibkey: lillis2017hierarchical\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1712.04544\"}\ntags: ['ARXIV']\n---\nBytewise approximate matching algorithms have in recent years shown significant promise in de- tecting files that are similar at the byte level. This is very useful for digital forensic investigators, who are regularly faced with the problem of searching through a seized device for pertinent data. A common scenario is where an investigator is in possession of a collection of \"known-illegal\" files (e.g. a collection of child abuse material) and wishes to find whether copies of these are stored on the seized device. Approximate matching addresses shortcomings in traditional hashing, which can only find identical files, by also being able to deal with cases of merged files, embedded files, partial files, or if a file has been changed in any way. Most approximate matching algorithms work by comparing pairs of files, which is not a scalable approach when faced with large corpora. This paper demonstrates the effectiveness of using a \"Hierarchical Bloom Filter Tree\" (HBFT) data structure to reduce the running time of collection-against-collection matching, with a specific focus on the MRSH-v2 algorithm. Three experiments are discussed, which explore the effects of different configurations of HBFTs. The proposed approach dramatically reduces the number of pairwise comparisons required, and demonstrates substantial speed gains, while maintaining effectiveness.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-3.9932940006256104, -6.048769950866699]}, {"key": "", "year": "", "title": "Limasset2017fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast and scalable minimal perfect hashing for massive key sets\"\nauthors: Limasset Antoine, Rizk Guillaume, Chikhi Rayan, Peterlongo Pierre\nconference: Arxiv\nyear: 2017\nbibkey: limasset2017fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1702.03154\"}   - {name: \"Code\", url: \"https://github.com/rizkg/BBHash\"}\ntags: ['ARXIV']\n---\nMinimal perfect hash functions provide space-efficient and collision-free hashing on static sets. Existing algorithms and implementations that build such functions have practical limitations on the number of input elements they can process, due to high construction time, RAM or external memory usage. We revisit a simple algorithm and show that it is highly competitive with the state of the art, especially in terms of construction time and memory usage. We provide a parallel C++ implementation called BBhash. It is capable of creating a minimal perfect hash function of $10^\\{10\\}$ elements in less than 7 minutes using 8 threads and 5 GB of memory, and the resulting function uses 3.7 bits/element. To the best of our knowledge, this is also the first implementation that has been successfully tested on an input of cardinality $10^\\{12\\}$. Source code: https://github.com/rizkg/BBHash\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-25.973541259765625, -16.850034713745117]}, {"key": "", "year": "", "title": "Lin2012density", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Density Sensitive Hashing\"\nauthors: Lin Yue, Cai Deng, Li Cheng\nconference: Arxiv\nyear: 2012\nbibkey: lin2012density\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1205.2930\"}\ntags: ['ARXIV', 'LSH']\n---\nNearest neighbors search is a fundamental problem in various research fields like machine learning, data mining and pattern recognition. Recently, hashing-based approaches, e.g., Locality Sensitive Hashing (LSH), are proved to be effective for scalable high dimensional nearest neighbors search. Many hashing algorithms found their theoretic root in random projection. Since these algorithms generate the hash tables (projections) randomly, a large number of hash tables (i.e., long codewords) are required in order to achieve both high precision and recall. To address this limitation, we propose a novel hashing algorithm called {\\em Density Sensitive Hashing} (DSH) in this paper. DSH can be regarded as an extension of LSH. By exploring the geometric structure of the data, DSH avoids the purely random projections selection and uses those projective functions which best agree with the distribution of the data. Extensive experimental results on real-world data sets have shown that the proposed method achieves better performance compared to the state-of-the-art hashing approaches.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-6.296975612640381, -12.254555702209473]}, {"key": "", "year": "", "title": "Lin2013a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A General Two-Step Approach to Learning-Based Hashing\"\nauthors: Lin Guosheng, Shen Chunhua, Suter David, Hengel Anton van den\nconference: Arxiv\nyear: 2013\nbibkey: lin2013a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1309.1853\"}\ntags: ['ARXIV']\n---\nMost existing approaches to hashing apply a single form of hash function, and an optimization process which is typically deeply coupled to this specific form. This tight coupling restricts the flexibility of the method to respond to the data, and can result in complex optimization problems that are difficult to solve. Here we propose a flexible yet simple framework that is able to accommodate different types of loss functions and hash functions. This framework allows a number of existing approaches to hashing to be placed in context, and simplifies the development of new problem-specific hashing methods. Our framework decomposes hashing learning problem into two steps: hash bit learning and hash function learning based on the learned bits. The first step can typically be formulated as binary quadratic problems, and the second step can be accomplished by training standard binary classifiers. Both problems have been extensively studied in the literature. Our extensive experiments demonstrate that the proposed framework is effective, flexible and outperforms the state-of-the-art.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-19.237802505493164, -0.9077662825584412]}, {"key": "", "year": "", "title": "Lin2014fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast Supervised Hashing with Decision Trees for High-Dimensional Data\"\nauthors: Lin Guosheng, Shen Chunhua, Shi Qinfeng, Hengel Anton van den, Suter David\nconference: Arxiv\nyear: 2014\nbibkey: lin2014fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1404.1561\"}\ntags: ['ARXIV', 'Graph', 'Supervised', 'Unsupervised']\n---\nSupervised hashing aims to map the original features to compact binary codes that are able to preserve label based similarity in the Hamming space. Non-linear hash functions have demonstrated the advantage over linear ones due to their powerful generalization capability. In the literature, kernel functions are typically used to achieve non-linearity in hashing, which achieve encouraging retrieval performance at the price of slow evaluation and training time. Here we propose to use boosted decision trees for achieving non-linearity in hashing, which are fast to train and evaluate, hence more suitable for hashing with high dimensional data. In our approach, we first propose sub-modular formulations for the hashing binary code inference problem and an efficient GraphCut based block search method for solving large-scale inference. Then we learn hash functions by training boosted decision trees to fit the binary codes. Experiments demonstrate that our proposed method significantly outperforms most state-of-the-art methods in retrieval precision and training time. Especially for high-dimensional data, our method is orders of magnitude faster than many methods in terms of training time.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-18.413894653320312, -2.3682448863983154]}, {"key": "", "year": "", "title": "Lin2014optimizing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Optimizing Ranking Measures for Compact Binary Code Learning\"\nauthors: Lin Guosheng, Shen Chunhua, Wu Jianxin\nconference: Arxiv\nyear: 2014\nbibkey: lin2014optimizing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1407.1151\"}\ntags: ['ARXIV', 'Deep Learning', 'Graph', 'Image Retrieval']\n---\nHashing has proven a valuable tool for large-scale information retrieval. Despite much success, existing hashing methods optimize over simple objectives such as the reconstruction error or graph Laplacian related loss functions, instead of the performance evaluation criteria of interest---multivariate performance measures such as the AUC and NDCG. Here we present a general framework (termed StructHash) that allows one to directly optimize multivariate performance measures. The resulting optimization problem can involve exponentially or infinitely many variables and constraints, which is more challenging than standard structured output learning. To solve the StructHash optimization problem, we use a combination of column generation and cutting-plane techniques. We demonstrate the generality of StructHash by applying it to ranking prediction and image retrieval, and show that it outperforms a few state-of-the-art hashing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [5.920522689819336, -28.111005783081055]}, {"key": "", "year": "", "title": "Lin2014supervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Supervised Hashing Using Graph Cuts and Boosted Decision Trees\"\nauthors: Lin Guosheng, Shen Chunhua, Hengel Anton van den\nconference: Arxiv\nyear: 2014\nbibkey: lin2014supervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1408.5574\"}\ntags: ['ARXIV', 'Graph', 'Image Retrieval', 'Supervised', 'Unsupervised']\n---\nEmbedding image features into a binary Hamming space can improve both the speed and accuracy of large-scale query-by-example image retrieval systems. Supervised hashing aims to map the original features to compact binary codes in a manner which preserves the label-based similarities of the original data. Most existing approaches apply a single form of hash function, and an optimization process which is typically deeply coupled to this specific form. This tight coupling restricts the flexibility of those methods, and can result in complex optimization problems that are difficult to solve. In this work we proffer a flexible yet simple framework that is able to accommodate different types of loss functions and hash functions. The proposed framework allows a number of existing approaches to hashing to be placed in context, and simplifies the development of new problem-specific hashing methods. Our framework decomposes the into two steps: binary code (hash bits) learning, and hash function learning. The first step can typically be formulated as a binary quadratic problem, and the second step can be accomplished by training standard binary classifiers. For solving large-scale binary code inference, we show how to ensure that the binary quadratic problems are submodular such that an efficient graph cut approach can be used. To achieve efficiency as well as efficacy on large-scale high-dimensional data, we propose to use boosted decision trees as the hash functions, which are nonlinear, highly descriptive, and very fast to train and evaluate. Experiments demonstrate that our proposed method significantly outperforms most state-of-the-art methods, especially on high-dimensional data.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [3.868171453475952, -28.90290069580078]}, {"key": "", "year": "", "title": "Lin2015deephash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"DeepHash: Getting Regularization, Depth and Fine-Tuning Right\"\nauthors: Lin Jie, Morere Olivier, Chandrasekhar Vijay, Veillard Antoine, Goh Hanlin\nconference: Arxiv\nyear: 2015\nbibkey: lin2015deephash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1501.04711\"}\ntags: ['ARXIV']\n---\nThis work focuses on representing very high-dimensional global image descriptors using very compact 64-1024 bit binary hashes for instance retrieval. We propose DeepHash: a hashing scheme based on deep networks. Key to making DeepHash work at extremely low bitrates are three important considerations -- regularization, depth and fine-tuning -- each requiring solutions specific to the hashing problem. In-depth evaluation shows that our scheme consistently outperforms state-of-the-art methods across all data sets for both Fisher Vectors and Deep Convolutional Neural Network features, by up to 20 percent over other schemes. The retrieval performance with 256-bit hashes is close to that of the uncompressed floating point features -- a remarkable 512 times compression.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-28.823993682861328, -9.395566940307617]}, {"key": "", "year": "", "title": "Lin2015implicit", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Implicit Sparse Code Hashing\"\nauthors: Lin Tsung-Yu, Ke Tsung-Wei, Liu Tyng-Luh\nconference: Arxiv\nyear: 2015\nbibkey: lin2015implicit\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1512.00130\"}\ntags: ['ARXIV', 'Supervised', 'Unsupervised']\n---\nWe address the problem of converting large-scale high-dimensional image data into binary codes so that approximate nearest-neighbor search over them can be efficiently performed. Different from most of the existing unsupervised approaches for yielding binary codes, our method is based on a dimensionality-reduction criterion that its resulting mapping is designed to preserve the image relationships entailed by the inner products of sparse codes, rather than those implied by the Euclidean distances in the ambient space. While the proposed formulation does not require computing any sparse codes, the underlying computation model still inevitably involves solving an unmanageable eigenproblem when extremely high-dimensional descriptors are used. To overcome the difficulty, we consider the column-sampling technique and presume a special form of rotation matrix to facilitate subproblem decomposition. We test our method on several challenging image datasets and demonstrate its effectiveness by comparing with state-of-the-art binary coding techniques.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [8.793756484985352, -2.6090826988220215]}, {"key": "", "year": "", "title": "Lin2015tiny", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Tiny Descriptors for Image Retrieval with Unsupervised Triplet Hashing\"\nauthors: Lin Jie, Mor\u00e8re Olivier, Petta Julie, Chandrasekhar Vijay, Veillard Antoine\nconference: Arxiv\nyear: 2015\nbibkey: lin2015tiny\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1511.03055\"}\ntags: ['ARXIV', 'CNN', 'Deep Learning', 'Image Retrieval', 'Supervised', 'TIP', 'Unsupervised']\n---\nA typical image retrieval pipeline starts with the comparison of global descriptors from a large database to find a short list of candidate matches. A good image descriptor is key to the retrieval pipeline and should reconcile two contradictory requirements: providing recall rates as high as possible and being as compact as possible for fast matching. Following the recent successes of Deep Convolutional Neural Networks (DCNN) for large scale image classification, descriptors extracted from DCNNs are increasingly used in place of the traditional hand crafted descriptors such as Fisher Vectors (FV) with better retrieval performances. Nevertheless, the dimensionality of a typical DCNN descriptor --extracted either from the visual feature pyramid or the fully-connected layers-- remains quite high at several thousands of scalar values. In this paper, we propose Unsupervised Triplet Hashing (UTH), a fully unsupervised method to compute extremely compact binary hashes --in the 32-256 bits range-- from high-dimensional global descriptors. UTH consists of two successive deep learning steps. First, Stacked Restricted Boltzmann Machines (SRBM), a type of unsupervised deep neural nets, are used to learn binary embedding functions able to bring the descriptor size down to the desired bitrate. SRBMs are typically able to ensure a very high compression rate at the expense of loosing some desirable metric properties of the original DCNN descriptor space. Then, triplet networks, a rank learning scheme based on weight sharing nets is used to fine-tune the binary embedding functions to retain as much as possible of the useful metric properties of the original space. A thorough empirical evaluation conducted on multiple publicly available dataset using DCNN descriptors shows that our method is able to significantly outperform state-of-the-art unsupervised schemes in the target bit range.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-6.1473069190979, 2.060800790786743]}, {"key": "", "year": "", "title": "Lin2016structured", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Structured Learning of Binary Codes with Column Generation\"\nauthors: Lin Guosheng, Liu Fayao, Shen Chunhua, Wu Jianxin, Shen Heng Tao\nconference: Arxiv\nyear: 2016\nbibkey: lin2016structured\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1602.06654\"}\ntags: ['ARXIV', 'Graph', 'Image Retrieval']\n---\nHashing methods aim to learn a set of hash functions which map the original features to compact binary codes with similarity preserving in the Hamming space. Hashing has proven a valuable tool for large-scale information retrieval. We propose a column generation based binary code learning framework for data-dependent hash function learning. Given a set of triplets that encode the pairwise similarity comparison information, our column generation based method learns hash functions that preserve the relative comparison relations within the large-margin learning framework. Our method iteratively learns the best hash functions during the column generation procedure. Existing hashing methods optimize over simple objectives such as the reconstruction error or graph Laplacian related loss functions, instead of the performance evaluation criteria of interest---multivariate performance measures such as the AUC and NDCG. Our column generation based method can be further generalized from the triplet loss to a general structured learning based framework that allows one to directly optimize multivariate performance measures. For optimizing general ranking measures, the resulting optimization problem can involve exponentially or infinitely many variables and constraints, which is more challenging than standard structured output learning. We use a combination of column generation and cutting-plane techniques to solve the optimization problem. To speed-up the training we further explore stage-wise training and propose to use a simplified NDCG loss for efficient inference. We demonstrate the generality of our method by applying it to ranking prediction and image retrieval, and show that it outperforms a few state-of-the-art hashing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-17.602031707763672, -2.2542004585266113]}, {"key": "", "year": "", "title": "Lin2018towards", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Towards a Theoretical Understanding of Hashing-Based Neural Nets\"\nauthors: Lin Yibo, Song Zhao, Yang Lin F.\nconference: Arxiv\nyear: 2018\nbibkey: lin2018towards\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1812.10244\"}\ntags: ['ARXIV', 'Deep Learning']\n---\nParameter reduction has been an important topic in deep learning due to the ever-increasing size of deep neural network models and the need to train and run them on resource limited machines. Despite many efforts in this area, there were no rigorous theoretical guarantees on why existing neural net compression methods should work. In this paper, we provide provable guarantees on some hashing-based parameter reduction methods in neural nets. First, we introduce a neural net compression scheme based on random linear sketching (which is usually implemented efficiently via hashing), and show that the sketched (smaller) network is able to approximate the original network on all input data coming from any smooth and well-conditioned low-dimensional manifold. The sketched network can also be trained directly via back-propagation. Next, we study the previously proposed HashedNets architecture and show that the optimization landscape of one-hidden-layer HashedNets has a local strong convexity property similar to a normal fully connected neural network. We complement our theoretical results with empirical verifications.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-19.832294464111328, 13.163212776184082]}, {"key": "", "year": "", "title": "Lin2019hadamard", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hadamard Matrix Guided Online Hashing\"\nauthors: Lin Mingbao, Ji Rongrong, Liu Hong, Sun Xiaoshuai, Chen Shen, Tian Qi\nconference: Arxiv\nyear: 2019\nbibkey: lin2019hadamard\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1905.04454\"}   - {name: \"Code\", url: \"https://github.com/lmbxmu/mycode.\"}\ntags: ['ARXIV', 'LSH', 'Supervised']\n---\nOnline image hashing has attracted increasing research attention recently, which receives large-scale data in a streaming manner to update the hash functions on-the-fly. Its key challenge lies in the difficulty of balancing the learning timeliness and model accuracy. To this end, most works follow a supervised setting, i.e., using class labels to boost the hashing performance, which defects in two aspects: First, strong constraints, e.g., orthogonal or similarity preserving, are used, which however are typically relaxed and lead to large accuracy drop. Second, large amounts of training batches are required to learn the up-to-date hash functions, which largely increase the learning complexity. To handle the above challenges, a novel supervised online hashing scheme termed Hadamard Matrix Guided Online Hashing (HMOH) is proposed in this paper. Our key innovation lies in introducing Hadamard matrix, which is an orthogonal binary matrix built via Sylvester method. In particular, to release the need of strong constraints, we regard each column of Hadamard matrix as the target code for each class label, which by nature satisfies several desired properties of hashing codes. To accelerate the online training, LSH is first adopted to align the lengths of target code and to-be-learned binary code. We then treat the learning of hash functions as a set of binary classification problems to fit the assigned target code. Finally, extensive experiments demonstrate the superior accuracy and efficiency of the proposed method over various state-of-the-art methods. Codes are available at https://github.com/lmbxmu/mycode.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-14.81674575805664, 10.023308753967285]}, {"key": "", "year": "", "title": "Lin2019supervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Supervised Online Hashing via Similarity Distribution Learning\"\nauthors: Lin Mingbao, Ji Rongrong, Chen Shen, Zheng Feng, Sun Xiaoshuai, Zhang Baochang, Cao Liujuan, Guo Guodong, Huang Feiyue\nconference: Arxiv\nyear: 2019\nbibkey: lin2019supervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1905.13382\"}\ntags: ['ARXIV', 'Streaming Data', 'Supervised', 'Unsupervised']\n---\nOnline hashing has attracted extensive research attention when facing streaming data. Most online hashing methods, learning binary codes based on pairwise similarities of training instances, fail to capture the semantic relationship, and suffer from a poor generalization in large-scale applications due to large variations. In this paper, we propose to model the similarity distributions between the input data and the hashing codes, upon which a novel supervised online hashing method, dubbed as Similarity Distribution based Online Hashing (SDOH), is proposed, to keep the intrinsic semantic relationship in the produced Hamming space. Specifically, we first transform the discrete similarity matrix into a probability matrix via a Gaussian-based normalization to address the extremely imbalanced distribution issue. And then, we introduce a scaling Student t-distribution to solve the challenging initialization problem, and efficiently bridge the gap between the known and unknown distributions. Lastly, we align the two distributions via minimizing the Kullback-Leibler divergence (KL-diverence) with stochastic gradient descent (SGD), by which an intuitive similarity constraint is imposed to update hashing model on the new streaming data with a powerful generalizing ability to the past data. Extensive experiments on three widely-used benchmarks validate the superiority of the proposed SDOH over the state-of-the-art methods in the online retrieval task.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-8.319167137145996, -0.4874614477157593]}, {"key": "", "year": "", "title": "Lin2019towards", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Towards Optimal Discrete Online Hashing with Balanced Similarity\"\nauthors: Lin Mingbao, Ji Rongrong, Liu Hong, Sun Xiaoshuai, Wu Yongjian, Wu Yunsheng\nconference: Arxiv\nyear: 2019\nbibkey: lin2019towards\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1901.10185\"}\ntags: ['ARXIV', 'Graph', 'Streaming Data', 'Supervised']\n---\nWhen facing large-scale image datasets, online hashing serves as a promising solution for online retrieval and prediction tasks. It encodes the online streaming data into compact binary codes, and simultaneously updates the hash functions to renew codes of the existing dataset. To this end, the existing methods update hash functions solely based on the new data batch, without investigating the correlation between such new data and the existing dataset. In addition, existing works update the hash functions using a relaxation process in its corresponding approximated continuous space. And it remains as an open problem to directly apply discrete optimizations in online hashing. In this paper, we propose a novel supervised online hashing method, termed Balanced Similarity for Online Discrete Hashing (BSODH), to solve the above problems in a unified framework. BSODH employs a well-designed hashing algorithm to preserve the similarity between the streaming data and the existing dataset via an asymmetric graph regularization. We further identify the \"data-imbalance\" problem brought by the constructed asymmetric graph, which restricts the application of discrete optimization in our problem. Therefore, a novel balanced similarity is further proposed, which uses two equilibrium factors to balance the similar and dissimilar weights and eventually enables the usage of discrete optimizations. Extensive experiments conducted on three widely-used benchmarks demonstrate the advantages of the proposed method over the state-of-the-art methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [1.257855772972107, -26.307138442993164]}, {"key": "", "year": "", "title": "Lin2020fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast Class-wise Updating for Online Hashing\"\nauthors: Lin Mingbao, Ji Rongrong, Sun Xiaoshuai, Zhang Baochang, Huang Feiyue, Tian Yonghong, Tao Dacheng\nconference: Arxiv\nyear: 2020\nbibkey: lin2020fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2012.00318\"}\ntags: ['ARXIV', 'Supervised']\n---\nOnline image hashing has received increasing research attention recently, which processes large-scale data in a streaming fashion to update the hash functions on-the-fly. To this end, most existing works exploit this problem under a supervised setting, i.e., using class labels to boost the hashing performance, which suffers from the defects in both adaptivity and efficiency: First, large amounts of training batches are required to learn up-to-date hash functions, which leads to poor online adaptivity. Second, the training is time-consuming, which contradicts with the core need of online learning. In this paper, a novel supervised online hashing scheme, termed Fast Class-wise Updating for Online Hashing (FCOH), is proposed to address the above two challenges by introducing a novel and efficient inner product operation. To achieve fast online adaptivity, a class-wise updating method is developed to decompose the binary code learning and alternatively renew the hash functions in a class-wise fashion, which well addresses the burden on large amounts of training batches. Quantitatively, such a decomposition further leads to at least 75% storage saving. To further achieve online efficiency, we propose a semi-relaxation optimization, which accelerates the online training by treating different binary constraints independently. Without additional constraints and variables, the time complexity is significantly reduced. Such a scheme is also quantitatively shown to well preserve past information during updating hashing functions. We have quantitatively demonstrated that the collective effort of class-wise updating and semi-relaxation optimization provides a superior performance comparing to various state-of-the-art methods, which is verified through extensive experiments on three widely-used datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-14.477453231811523, -6.780750274658203]}, {"key": "", "year": "", "title": "Lin2021deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Self-Adaptive Hashing for Image Retrieval\"\nauthors: Lin Qinghong, Chen Xiaojun, Zhang Qin, Tian Shangxuan, Chen Yudong\nconference: Arxiv\nyear: 2021\nbibkey: lin2021deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2108.07094\"}\ntags: ['ARXIV', 'Deep Learning', 'Image Retrieval', 'Supervised', 'Unsupervised']\n---\nHashing technology has been widely used in image retrieval due to its computational and storage efficiency. Recently, deep unsupervised hashing methods have attracted increasing attention due to the high cost of human annotations in the real world and the superiority of deep learning technology. However, most deep unsupervised hashing methods usually pre-compute a similarity matrix to model the pairwise relationship in the pre-trained feature space. Then this similarity matrix would be used to guide hash learning, in which most of the data pairs are treated equivalently. The above process is confronted with the following defects: 1) The pre-computed similarity matrix is inalterable and disconnected from the hash learning process, which cannot explore the underlying semantic information. 2) The informative data pairs may be buried by the large number of less-informative data pairs. To solve the aforementioned problems, we propose a Deep Self-Adaptive Hashing (DSAH) model to adaptively capture the semantic information with two special designs: Adaptive Neighbor Discovery (AND) and Pairwise Information Content (PIC). Firstly, we adopt the AND to initially construct a neighborhood-based similarity matrix, and then refine this initial similarity matrix with a novel update strategy to further investigate the semantic structure behind the learned representation. Secondly, we measure the priorities of data pairs with PIC and assign adaptive weights to them, which is relies on the assumption that more dissimilar data pairs contain more discriminative information for hash learning. Extensive experiments on several datasets demonstrate that the above two technologies facilitate the deep hashing model to achieve superior performance.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-6.7276177406311035, 8.078076362609863]}, {"key": "", "year": "", "title": "Lin2022deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Unsupervised Hashing with Latent Semantic Components\"\nauthors: Lin Qinghong, Chen Xiaojun, Zhang Qin, Cai Shaotian, Zhao Wenzhe, Wang Hongfa\nconference: Arxiv\nyear: 2022\nbibkey: lin2022deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2203.09420\"}\ntags: ['ARXIV', 'GAN', 'Image Retrieval', 'Supervised', 'TIP', 'Unsupervised']\n---\nDeep unsupervised hashing has been appreciated in the regime of image retrieval. However, most prior arts failed to detect the semantic components and their relationships behind the images, which makes them lack discriminative power. To make up the defect, we propose a novel Deep Semantic Components Hashing (DSCH), which involves a common sense that an image normally contains a bunch of semantic components with homology and co-occurrence relationships. Based on this prior, DSCH regards the semantic components as latent variables under the Expectation-Maximization framework and designs a two-step iterative algorithm with the objective of maximum likelihood of training data. Firstly, DSCH constructs a semantic component structure by uncovering the fine-grained semantics components of images with a Gaussian Mixture Modal~(GMM), where an image is represented as a mixture of multiple components, and the semantics co-occurrence are exploited. Besides, coarse-grained semantics components, are discovered by considering the homology relationships between fine-grained components, and the hierarchy organization is then constructed. Secondly, DSCH makes the images close to their semantic component centers at both fine-grained and coarse-grained levels, and also makes the images share similar semantic components close to each other. Extensive experiments on three benchmark datasets demonstrate that the proposed hierarchical semantic components indeed facilitate the hashing model to achieve superior performance.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-2.084136724472046, 12.88732624053955]}, {"key": "", "year": "", "title": "Lin2024enhancing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Enhancing Historical Image Retrieval with Compositional Cues\"\nauthors: Lin Tingyu, Sablatnig Robert\nconference: Arxiv\nyear: 2024\nbibkey: lin2024enhancing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2403.14287\"}   - {name: \"Code\", url: \"https://github.com/linty5/CCBIR\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval']\n---\nIn analyzing vast amounts of digitally stored historical image data, existing content-based retrieval methods often overlook significant non-semantic information, limiting their effectiveness for flexible exploration across varied themes. To broaden the applicability of image retrieval methods for diverse purposes and uncover more general patterns, we innovatively introduce a crucial factor from computational aesthetics, namely image composition, into this topic. By explicitly integrating composition-related information extracted by CNN into the designed retrieval model, our method considers both the image's composition rules and semantic information. Qualitative and quantitative experiments demonstrate that the image retrieval network guided by composition information outperforms those relying solely on content information, facilitating the identification of images in databases closer to the target image in human perception. Please visit https://github.com/linty5/CCBIR to try our codes.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [16.010986328125, 18.024776458740234]}, {"key": "", "year": "", "title": "Lins2003phorma", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"PHORMA: Perfectly Hashable Order Restricted Multidimensional Arrays\"\nauthors: Lins Lauro, Lins Sostenes, Melo Silvio\nconference: Arxiv\nyear: 2003\nbibkey: lins2003phorma\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/cs/0301021\"}\ntags: ['ARXIV', 'Graph']\n---\nIn this paper we propose a simple and efficient data structure yielding a perfect hashing of quite general arrays. The data structure is named phorma, which is an acronym for perfectly hashable order restricted multidimensional array. Keywords: Perfect hash function, Digraph, Implicit enumeration, Nijenhuis-Wilf combinatorial family.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-29.971424102783203, -14.215044975280762]}, {"key": "", "year": "", "title": "Liu2012compact", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Compact Hyperplane Hashing with Bilinear Functions\"\nauthors: Liu Wei  Columbia University, Wang Jun  IBM T. J. Watson Research   Center, Mu Yadong  Columbia University, Kumar Sanjiv  Google, Chang Shih-Fu  Columbia University\nconference: Arxiv\nyear: 2012\nbibkey: liu2012compact\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1206.4618\"}\ntags: ['ARXIV']\n---\nHyperplane hashing aims at rapidly searching nearest points to a hyperplane, and has shown practical impact in scaling up active learning with SVMs. Unfortunately, the existing randomized methods need long hash codes to achieve reasonable search accuracy and thus suffer from reduced search speed and large memory overhead. To this end, this paper proposes a novel hyperplane hashing technique which yields compact hash codes. The key idea is the bilinear form of the proposed hash functions, which leads to higher collision probability than the existing hyperplane hash functions when using random projections. To further increase the performance, we propose a learning based framework in which the bilinear functions are directly learned from the data. This results in short yet discriminative codes, and also boosts the search performance over the random projection based solutions. Large-scale active learning experiments carried out on two datasets with up to one million samples demonstrate the overall superiority of the proposed approach.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-5.3858160972595215, -11.722369194030762]}, {"key": "", "year": "", "title": "Liu2015accelerated", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Accelerated Distance Computation with Encoding Tree for High Dimensional Data\"\nauthors: Liu Shicong, Shao Junru, Lu Hongtao\nconference: Arxiv\nyear: 2015\nbibkey: liu2015accelerated\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1509.05186\"}\ntags: ['ARXIV', 'Quantisation']\n---\nWe propose a novel distance to calculate distance between high dimensional vector pairs, utilizing vector quantization generated encodings. Vector quantization based methods are successful in handling large scale high dimensional data. These methods compress vectors into short encodings, and allow efficient distance computation between an uncompressed vector and compressed dataset without decompressing explicitly. However for large datasets, these distance computing methods perform excessive computations. We avoid excessive computations by storing the encodings on an Encoding Tree(E-Tree), interestingly the memory consumption is also lowered. We also propose Encoding Forest(E-Forest) to further lower the computation cost. E-Tree and E-Forest is compatible with various existing quantization-based methods. We show by experiments our methods speed-up distance computing for high dimensional data drastically, and various existing algorithms can benefit from our methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [6.652350425720215, -12.345335960388184]}, {"key": "", "year": "", "title": "Liu2015hclae", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"HCLAE: High Capacity Locally Aggregating Encodings for Approximate Nearest Neighbor Search\"\nauthors: Liu Shicong, Shao Junru, Lu Hongtao\nconference: Arxiv\nyear: 2015\nbibkey: liu2015hclae\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1509.05194\"}\ntags: ['ARXIV', 'Quantisation']\n---\nVector quantization-based approaches are successful to solve Approximate Nearest Neighbor (ANN) problems which are critical to many applications. The idea is to generate effective encodings to allow fast distance approximation. We propose quantization-based methods should partition the data space finely and exhibit locality of the dataset to allow efficient non-exhaustive search. In this paper, we introduce the concept of High Capacity Locality Aggregating Encodings (HCLAE) to this end, and propose Dictionary Annealing (DA) to learn HCLAE by a simulated annealing procedure. The quantization error is lower than other state-of-the-art. The algorithms of DA can be easily extended to an online learning scheme, allowing effective handle of large scale data. Further, we propose Aggregating-Tree (A-Tree), a non-exhaustive search method using HCLAE to perform efficient ANN-Search. A-Tree achieves magnitudes of speed-up on ANN-Search tasks, compared to the state-of-the-art.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [6.806925296783447, -12.493717193603516]}, {"key": "", "year": "", "title": "Liu2015indexing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Indexing of CNN Features for Large Scale Image Search\"\nauthors: Liu Ruoyu, Zhao Yao, Wei Shikui, Yang Yi\nconference: Arxiv\nyear: 2015\nbibkey: liu2015indexing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1508.00217\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval', 'Quantisation', 'Supervised', 'TIP', 'Unsupervised']\n---\nThe convolutional neural network (CNN) features can give a good description of image content, which usually represent images with unique global vectors. Although they are compact compared to local descriptors, they still cannot efficiently deal with large-scale image retrieval due to the cost of the linear incremental computation and storage. To address this issue, we build a simple but effective indexing framework based on inverted table, which significantly decreases both the search time and memory usage. In addition, several strategies are fully investigated under an indexing framework to adapt it to CNN features and compensate for quantization errors. First, we use multiple assignment for the query and database images to increase the probability of relevant images' co-existing in the same Voronoi cells obtained via the clustering algorithm. Then, we introduce embedding codes to further improve precision by removing false matches during a search. We demonstrate that by using hashing schemes to calculate the embedding codes and by changing the ranking rule, indexing framework speeds can be greatly improved. Extensive experiments conducted on several unsupervised and supervised benchmarks support these results and the superiority of the proposed indexing framework. We also provide a fair comparison between the popular CNN features.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.13294506072998, 29.66522789001465]}, {"key": "", "year": "", "title": "Liu2015projection", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Projection Bank: From High-dimensional Data to Medium-length Binary Codes\"\nauthors: Liu Li, Yu Mengyang, Shao Ling\nconference: Arxiv\nyear: 2015\nbibkey: liu2015projection\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1509.04916\"}\ntags: ['ARXIV']\n---\nRecently, very high-dimensional feature representations, e.g., Fisher Vector, have achieved excellent performance for visual recognition and retrieval. However, these lengthy representations always cause extremely heavy computational and storage costs and even become unfeasible in some large-scale applications. A few existing techniques can transfer very high-dimensional data into binary codes, but they still require the reduced code length to be relatively long to maintain acceptable accuracies. To target a better balance between computational efficiency and accuracies, in this paper, we propose a novel embedding method called Binary Projection Bank (BPB), which can effectively reduce the very high-dimensional representations to medium-dimensional binary codes without sacrificing accuracies. Instead of using conventional single linear or bilinear projections, the proposed method learns a bank of small projections via the max-margin constraint to optimally preserve the intrinsic data similarity. We have systematically evaluated the proposed method on three datasets: Flickr 1M, ILSVR2010 and UCF101, showing competitive retrieval and recognition accuracies compared with state-of-the-art approaches, but with a significantly smaller memory footprint and lower coding complexity.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-5.909709930419922, -15.642085075378418]}, {"key": "", "year": "", "title": "Liu2016accurate", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Accurate Deep Representation Quantization with Gradient Snapping Layer for Similarity Search\"\nauthors: Liu Shicong, Lu Hongtao\nconference: Arxiv\nyear: 2016\nbibkey: liu2016accurate\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1610.09645\"}\ntags: ['ARXIV', 'Quantisation']\n---\nRecent advance of large scale similarity search involves using deeply learned representations to improve the search accuracy and use vector quantization methods to increase the search speed. However, how to learn deep representations that strongly preserve similarities between data pairs and can be accurately quantized via vector quantization remains a challenging task. Existing methods simply leverage quantization loss and similarity loss, which result in unexpectedly biased back-propagating gradients and affect the search performances. To this end, we propose a novel gradient snapping layer (GSL) to directly regularize the back-propagating gradient towards a neighboring codeword, the generated gradients are un-biased for reducing similarity loss and also propel the learned representations to be accurately quantized. Joint deep representation and vector quantization learning can be easily performed by alternatively optimize the quantization codebook and the deep neural network. The proposed framework is compatible with various existing vector quantization approaches. Experimental results demonstrate that the proposed framework is effective, flexible and outperforms the state-of-the-art large scale similarity search methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [14.850829124450684, -2.011883497238159]}, {"key": "", "year": "", "title": "Liu2016dual", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Dual Purpose Hashing\"\nauthors: Liu Haomiao, Wang Ruiping, Shan Shiguang, Chen Xilin\nconference: Arxiv\nyear: 2016\nbibkey: liu2016dual\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1607.05529\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval', 'TIP']\n---\nRecent years have seen more and more demand for a unified framework to address multiple realistic image retrieval tasks concerning both category and attributes. Considering the scale of modern datasets, hashing is favorable for its low complexity. However, most existing hashing methods are designed to preserve one single kind of similarity, thus improper for dealing with the different tasks simultaneously. To overcome this limitation, we propose a new hashing method, named Dual Purpose Hashing (DPH), which jointly preserves the category and attribute similarities by exploiting the Convolutional Neural Network (CNN) models to hierarchically capture the correlations between category and attributes. Since images with both category and attribute labels are scarce, our method is designed to take the abundant partially labelled images on the Internet as training inputs. With such a framework, the binary codes of new-coming images can be readily obtained by quantizing the network outputs of a binary-like layer, and the attributes can be recovered from the codes easily. Experiments on two large-scale datasets show that our dual purpose hash codes can achieve comparable or even better performance than those state-of-the-art methods specifically designed for each individual retrieval task, while being more compact than the compared methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-1.6394504308700562, 9.309781074523926]}, {"key": "", "year": "", "title": "Liu2016generalized", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Generalized residual vector quantization for large scale data\"\nauthors: Liu Shicong, Shao Junru, Lu Hongtao\nconference: Arxiv\nyear: 2016\nbibkey: liu2016generalized\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1609.05345\"}\ntags: ['ARXIV', 'Quantisation', 'Survey Paper']\n---\nVector quantization is an essential tool for tasks involving large scale data, for example, large scale similarity search, which is crucial for content-based information retrieval and analysis. In this paper, we propose a novel vector quantization framework that iteratively minimizes quantization error. First, we provide a detailed review on a relevant vector quantization method named \\textit{residual vector quantization} (RVQ). Next, we propose \\textit{generalized residual vector quantization} (GRVQ) to further improve over RVQ. Many vector quantization methods can be viewed as the special cases of our proposed framework. We evaluate GRVQ on several large scale benchmark datasets for large scale search, classification and object retrieval. We compared GRVQ with existing methods in detail. Extensive experiments demonstrate our GRVQ framework substantially outperforms existing methods in term of quantization accuracy and computation efficiency.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.139698028564453, -8.729589462280273]}, {"key": "", "year": "", "title": "Liu2016generating", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Generating Binary Tags for Fast Medical Image Retrieval Based on Convolutional Nets and Radon Transform\"\nauthors: Liu Xinran, Tizhoosh Hamid R., Kofman Jonathan\nconference: Arxiv\nyear: 2016\nbibkey: liu2016generating\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1604.04676\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval']\n---\nContent-based image retrieval (CBIR) in large medical image archives is a challenging and necessary task. Generally, different feature extraction methods are used to assign expressive and invariant features to each image such that the search for similar images comes down to feature classification and/or matching. The present work introduces a new image retrieval method for medical applications that employs a convolutional neural network (CNN) with recently introduced Radon barcodes. We combine neural codes for global classification with Radon barcodes for the final retrieval. We also examine image search based on regions of interest (ROI) matching after image retrieval. The IRMA dataset with more than 14,000 x-rays images is used to evaluate the performance of our method. Experimental results show that our approach is superior to many published works.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [28.318288803100586, 20.47130584716797]}, {"key": "", "year": "", "title": "Liu2016ordinal", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Ordinal Constrained Binary Code Learning for Nearest Neighbor Search\"\nauthors: Liu Hong, Ji Rongrong, Wu Yongjian, Huang Feiyue\nconference: Arxiv\nyear: 2016\nbibkey: liu2016ordinal\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1611.06362\"}\ntags: ['ARXIV', 'Graph']\n---\nRecent years have witnessed extensive attention in binary code learning, a.k.a. hashing, for nearest neighbor search problems. It has been seen that high-dimensional data points can be quantized into binary codes to give an efficient similarity approximation via Hamming distance. Among existing schemes, ranking-based hashing is recent promising that targets at preserving ordinal relations of ranking in the Hamming space to minimize retrieval loss. However, the size of the ranking tuples, which shows the ordinal relations, is quadratic or cubic to the size of training samples. By given a large-scale training data set, it is very expensive to embed such ranking tuples in binary code learning. Besides, it remains a dificulty to build ranking tuples efficiently for most ranking-preserving hashing, which are deployed over an ordinal graph-based setting. To handle these problems, we propose a novel ranking-preserving hashing method, dubbed Ordinal Constraint Hashing (OCH), which efficiently learns the optimal hashing functions with a graph-based approximation to embed the ordinal relations. The core idea is to reduce the size of ordinal graph with ordinal constraint projection, which preserves the ordinal relations through a small data set (such as clusters or random samples). In particular, to learn such hash functions effectively, we further relax the discrete constraints and design a specific stochastic gradient decent algorithm for optimization. Experimental results on three large-scale visual search benchmark datasets, i.e. LabelMe, Tiny100K and GIST1M, show that the proposed OCH method can achieve superior performance over the state-of-the-arts approaches.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [1.526024341583252, -27.963048934936523]}, {"key": "", "year": "", "title": "Liu2016perceptual", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Perceptual uniform descriptor and Ranking on manifold: A bridge between image representation and ranking for image retrieval\"\nauthors: Liu Shenglan, Wu Jun, Feng Lin, Liu Yang, Qiao Hong, Sun Wenbo Luo Muxin, Wang Wei\nconference: Arxiv\nyear: 2016\nbibkey: liu2016perceptual\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1609.07615\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nIncompatibility of image descriptor and ranking is always neglected in image retrieval. In this paper, manifold learning and Gestalt psychology theory are involved to solve the incompatibility problem. A new holistic descriptor called Perceptual Uniform Descriptor (PUD) based on Gestalt psychology is proposed, which combines color and gradient direction to imitate the human visual uniformity. PUD features in the same class images distributes on one manifold in most cases because PUD improves the visual uniformity of the traditional descriptors. Thus, we use manifold ranking and PUD to realize image retrieval. Experiments were carried out on five benchmark data sets, and the proposed method can greatly improve the accuracy of image retrieval. Our experimental results in the Ukbench and Corel-1K datasets demonstrated that N-S score reached to 3.58 (HSV 3.4) and mAP to 81.77% (ODBTC 77.9%) respectively by utilizing PUD which has only 280 dimension. The results are higher than other holistic image descriptors (even some local ones) and state-of-the-arts retrieval methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [10.415252685546875, 17.246170043945312]}, {"key": "", "year": "", "title": "Liu2016supervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Supervised Matrix Factorization for Cross-Modality Hashing\"\nauthors: Liu Hong, Ji Rongrong, Wu Yongjian, Hua Gang\nconference: Arxiv\nyear: 2016\nbibkey: liu2016supervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1603.05572\"}\ntags: ['ARXIV', 'Cross Modal', 'Graph', 'Quantisation', 'Supervised', 'Unsupervised']\n---\nMatrix factorization has been recently utilized for the task of multi-modal hashing for cross-modality visual search, where basis functions are learned to map data from different modalities to the same Hamming embedding. In this paper, we propose a novel cross-modality hashing algorithm termed Supervised Matrix Factorization Hashing (SMFH) which tackles the multi-modal hashing problem with a collective non-matrix factorization across the different modalities. In particular, SMFH employs a well-designed binary code learning algorithm to preserve the similarities among multi-modal original features through a graph regularization. At the same time, semantic labels, when available, are incorporated into the learning procedure. We conjecture that all these would facilitate to preserve the most relevant information during the binary quantization process, and hence improve the retrieval accuracy. We demonstrate the superior performance of SMFH on three cross-modality visual search benchmarks, i.e., the PASCAL-Sentence, Wiki, and NUS-WIDE, with quantitative comparison to various state-of-the-art methods\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [2.255218267440796, -29.997949600219727]}, {"key": "", "year": "", "title": "Liu2017deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Hashing with Category Mask for Fast Video Retrieval\"\nauthors: Liu Xu, Zhao Lili, Ding Dajun, Dong Yajiao\nconference: Arxiv\nyear: 2017\nbibkey: liu2017deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1712.08315\"}\ntags: ['ARXIV', 'Supervised', 'Video Retrieval']\n---\nThis paper proposes an end-to-end deep hashing framework with category mask for fast video retrieval. We train our network in a supervised way by fully exploiting inter-class diversity and intra-class identity. Classification loss is optimized to maximize inter-class diversity, while intra-pair is introduced to learn representative intra-class identity. We investigate the binary bits distribution related to categories and find out that the effectiveness of binary bits is highly correlated with data categories, and some bits may degrade classification performance of some categories. We then design hash code generation scheme with category mask to filter out bits with negative contribution. Experimental results demonstrate the proposed method outperforms several state-of-the-arts under various evaluation metrics on public datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-6.975714206695557, 17.89285659790039]}, {"key": "", "year": "", "title": "Liu2017end", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"End-to-end Binary Representation Learning via Direct Binary Embedding\"\nauthors: Liu Liu, Rahimpour Alireza, Taalimi Ali, Qi Hairong\nconference: Arxiv\nyear: 2017\nbibkey: liu2017end\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1703.04960\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval', 'Quantisation']\n---\nLearning binary representation is essential to large-scale computer vision tasks. Most existing algorithms require a separate quantization constraint to learn effective hashing functions. In this work, we present Direct Binary Embedding (DBE), a simple yet very effective algorithm to learn binary representation in an end-to-end fashion. By appending an ingeniously designed DBE layer to the deep convolutional neural network (DCNN), DBE learns binary code directly from the continuous DBE layer activation without quantization error. By employing the deep residual network (ResNet) as DCNN component, DBE captures rich semantics from images. Furthermore, in the effort of handling multilabel images, we design a joint cross entropy loss that includes both softmax cross entropy and weighted binary cross entropy in consideration of the correlation and independence of labels, respectively. Extensive experiments demonstrate the significant superiority of DBE over state-of-the-art methods on tasks of natural object recognition, image retrieval and image annotation.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-9.70403003692627, 14.378410339355469]}, {"key": "", "year": "", "title": "Liu2017neural", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Neural method for Explicit Mapping of Quasi-curvature Locally Linear Embedding in image retrieval\"\nauthors: Liu Shenglan, Wu Jun, Feng Lin, Wang Feilong\nconference: Arxiv\nyear: 2017\nbibkey: liu2017neural\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1703.03957\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nThis paper proposed a new explicit nonlinear dimensionality reduction using neural networks for image retrieval tasks. We first proposed a Quasi-curvature Locally Linear Embedding (QLLE) for training set. QLLE guarantees the linear criterion in neighborhood of each sample. Then, a neural method (NM) is proposed for out-of-sample problem. Combining QLLE and NM, we provide a explicit nonlinear dimensionality reduction approach for efficient image retrieval. The experimental results in three benchmark datasets illustrate that our method can get better performance than other state-of-the-art out-of-sample methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [14.349344253540039, 22.938779830932617]}, {"key": "", "year": "", "title": "Liu2018discriminative", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Discriminative Cross-View Binary Representation Learning\"\nauthors: Liu Liu, Qi Hairong\nconference: WACV\nyear: 2018\nbibkey: liu2018discriminative\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1804.01233\"}\ntags: ['CNN', 'Cross Modal', 'Image Retrieval', 'Quantisation']\n---\nLearning compact representation is vital and challenging for large scale multimedia data. Cross-view/cross-modal hashing for effective binary representation learning has received significant attention with exponentially growing availability of multimedia content. Most existing cross-view hashing algorithms emphasize the similarities in individual views, which are then connected via cross-view similarities. In this work, we focus on the exploitation of the discriminative information from different views, and propose an end-to-end method to learn semantic-preserving and discriminative binary representation, dubbed Discriminative Cross-View Hashing (DCVH), in light of learning multitasking binary representation for various tasks including cross-view retrieval, image-to-image retrieval, and image annotation/tagging. The proposed DCVH has the following key components. First, it uses convolutional neural network (CNN) based nonlinear hashing functions and multilabel classification for both images and texts simultaneously. Such hashing functions achieve effective continuous relaxation during training without explicit quantization loss by using Direct Binary Embedding (DBE) layers. Second, we propose an effective view alignment via Hamming distance minimization, which is efficiently accomplished by bit-wise XOR operation. Extensive experiments on two image-text benchmark datasets demonstrate that DCVH outperforms state-of-the-art cross-view hashing algorithms as well as single-view image hashing algorithms. In addition, DCVH can provide competitive performance for image annotation/tagging.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-13.542618751525879, 5.34745979309082]}, {"key": "", "year": "", "title": "Liu2018fusion", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fusion Hashing: A General Framework for Self-improvement of Hashing\"\nauthors: Liu Xingbo, Nie Xiushan, Yin Yilong\nconference: Arxiv\nyear: 2018\nbibkey: liu2018fusion\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1810.00644\"}\ntags: ['ARXIV']\n---\nHashing has been widely used for efficient similarity search based on its query and storage efficiency. To obtain better precision, most studies focus on designing different objective functions with different constraints or penalty terms that consider neighborhood information. In this paper, in contrast to existing hashing methods, we propose a novel generalized framework called fusion hashing (FH) to improve the precision of existing hashing methods without adding new constraints or penalty terms. In the proposed FH, given an existing hashing method, we first execute it several times to get several different hash codes for a set of training samples. We then propose two novel fusion strategies that combine these different hash codes into one set of final hash codes. Based on the final hash codes, we learn a simple linear hash function for the samples that can significantly improve model precision. In general, the proposed FH can be adopted in existing hashing method and achieve more precise and stable performance compared to the original hashing method with little extra expenditure in terms of time and space. Extensive experiments were performed based on three benchmark datasets and the results demonstrate the superior performance of the proposed framework\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-10.329230308532715, -6.779277801513672]}, {"key": "", "year": "", "title": "Liu2018mtfh", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"MTFH: A Matrix Tri-Factorization Hashing Framework for Efficient Cross-Modal Retrieval\"\nauthors: Liu Xin, Hu Zhikai, Ling Haibin, Cheung Yiu-ming\nconference: IEEE Transactions on Pattern Analysis and Machine Intelligence,\nyear: 2018\nbibkey: liu2018mtfh\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1805.01963\"}\ntags: ['Cross Modal']\n---\nHashing has recently sparked a great revolution in cross-modal retrieval because of its low storage cost and high query speed. Recent cross-modal hashing methods often learn unified or equal-length hash codes to represent the multi-modal data and make them intuitively comparable. However, such unified or equal-length hash representations could inherently sacrifice their representation scalability because the data from different modalities may not have one-to-one correspondence and could be encoded more efficiently by different hash codes of unequal lengths. To mitigate these problems, this paper exploits a related and relatively unexplored problem: encode the heterogeneous data with varying hash lengths and generalize the cross-modal retrieval in various challenging scenarios. To this end, a generalized and flexible cross-modal hashing framework, termed Matrix Tri-Factorization Hashing (MTFH), is proposed to work seamlessly in various settings including paired or unpaired multi-modal data, and equal or varying hash length encoding scenarios. More specifically, MTFH exploits an efficient objective function to flexibly learn the modality-specific hash codes with different length settings, while synchronously learning two semantic correlation matrices to semantically correlate the different hash representations for heterogeneous data comparable. As a result, the derived hash codes are more semantically meaningful for various challenging cross-modal retrieval tasks. Extensive experiments evaluated on public benchmark datasets highlight the superiority of MTFH under various retrieval scenarios and show its competitive performance with the state-of-the-arts.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-10.036727905273438, -3.906973123550415]}, {"key": "", "year": "", "title": "Liu2019cross", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Cross-modal Zero-shot Hashing\"\nauthors: Liu Xuanwu, Li Zhao, Wang Jun, Yu Guoxian, Domeniconi Carlotta, Zhang Xiangliang\nconference: Arxiv\nyear: 2019\nbibkey: liu2019cross\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1908.07388\"}\ntags: ['ARXIV', 'Cross Modal']\n---\nHashing has been widely studied for big data retrieval due to its low storage cost and fast query speed. Zero-shot hashing (ZSH) aims to learn a hashing model that is trained using only samples from seen categories, but can generalize well to samples of unseen categories. ZSH generally uses category attributes to seek a semantic embedding space to transfer knowledge from seen categories to unseen ones. As a result, it may perform poorly when labeled data are insufficient. ZSH methods are mainly designed for single-modality data, which prevents their application to the widely spread multi-modal data. On the other hand, existing cross-modal hashing solutions assume that all the modalities share the same category labels, while in practice the labels of different data modalities may be different. To address these issues, we propose a general Cross-modal Zero-shot Hashing (CZHash) solution to effectively leverage unlabeled and labeled multi-modality data with different label spaces. CZHash first quantifies the composite similarity between instances using label and feature information. It then defines an objective function to achieve deep feature learning compatible with the composite similarity preserving, category attribute space learning, and hashing coding function learning. CZHash further introduces an alternative optimization procedure to jointly optimize these learning objectives. Experiments on benchmark multi-modal datasets show that CZHash significantly outperforms related representative hashing approaches both on effectiveness and adaptability.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-9.9341459274292, 0.9385537505149841]}, {"key": "", "year": "", "title": "Liu2019deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Triplet Quantization\"\nauthors: Liu Bin, Cao Yue, Long Mingsheng, Wang Jianmin, Wang Jingdong\nconference: Arxiv\nyear: 2019\nbibkey: liu2019deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1902.00153\"}\ntags: ['ARXIV', 'Deep Learning', 'Image Retrieval', 'Quantisation']\n---\nDeep hashing establishes efficient and effective image retrieval by end-to-end learning of deep representations and hash codes from similarity data. We present a compact coding solution, focusing on deep learning to quantization approach that has shown superior performance over hashing solutions for similarity retrieval. We propose Deep Triplet Quantization (DTQ), a novel approach to learning deep quantization models from the similarity triplets. To enable more effective triplet training, we design a new triplet selection approach, Group Hard, that randomly selects hard triplets in each image group. To generate compact binary codes, we further apply a triplet quantization with weak orthogonality during triplet training. The quantization loss reduces the codebook redundancy and enhances the quantizability of deep representations through back-propagation. Extensive experiments demonstrate that DTQ can generate high-quality and compact binary codes, which yields state-of-the-art image retrieval performance on three benchmark datasets, NUS-WIDE, CIFAR-10, and MS-COCO.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [5.81527853012085, 8.113061904907227]}, {"key": "", "year": "", "title": "Liu2019mutual", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Mutual Linear Regression-based Discrete Hashing\"\nauthors: Liu Xingbo, Nie Xiushan, Yin Yilong\nconference: Arxiv\nyear: 2019\nbibkey: liu2019mutual\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1904.00744\"}\ntags: ['ARXIV', 'Supervised']\n---\nLabel information is widely used in hashing methods because of its effectiveness of improving the precision. The existing hashing methods always use two different projections to represent the mutual regression between hash codes and class labels. In contrast to the existing methods, we propose a novel learning-based hashing method termed stable supervised discrete hashing with mutual linear regression (S2DHMLR) in this study, where only one stable projection is used to describe the linear correlation between hash codes and corresponding labels. To the best of our knowledge, this strategy has not been used for hashing previously. In addition, we further use a boosting strategy to improve the final performance of the proposed method without adding extra constraints and with little extra expenditure in terms of time and space. Extensive experiments conducted on three image benchmarks demonstrate the superior performance of the proposed method.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-17.86690902709961, 1.5378992557525635]}, {"key": "", "year": "", "title": "Liu2019optimal", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Optimal Projection Guided Transfer Hashing for Image Retrieval\"\nauthors: Liu Ji, Zhang Lei\nconference: Arxiv\nyear: 2019\nbibkey: liu2019optimal\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1903.00252\"}   - {name: \"Code\", url: \"https://github.com/liuji93/GTH.\"}\ntags: ['ARXIV', 'Image Retrieval', 'Supervised', 'Unsupervised']\n---\nRecently, learning to hash has been widely studied for image retrieval thanks to the computation and storage efficiency of binary codes. For most existing learning to hash methods, sufficient training images are required and used to learn precise hashing codes. However, in some real-world applications, there are not always sufficient training images in the domain of interest. In addition, some existing supervised approaches need a amount of labeled data, which is an expensive process in term of time, label and human expertise. To handle such problems, inspired by transfer learning, we propose a simple yet effective unsupervised hashing method named Optimal Projection Guided Transfer Hashing (GTH) where we borrow the images of other different but related domain i.e., source domain to help learn precise hashing codes for the domain of interest i.e., target domain. Besides, we propose to seek for the maximum likelihood estimation (MLE) solution of the hashing functions of target and source domains due to the domain gap. Furthermore,an alternating optimization method is adopted to obtain the two projections of target and source domains such that the domain hashing disparity is reduced gradually. Extensive experiments on various benchmark databases verify that our method outperforms many state-of-the-art learning to hash methods. The implementation details are available at https://github.com/liuji93/GTH.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-6.072489261627197, 6.271877765655518]}, {"key": "", "year": "", "title": "Liu2019query", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Query-Adaptive Hash Code Ranking for Large-Scale Multi-View Visual Search\"\nauthors: Liu Xianglong, Huang Lei, Deng Cheng, Lang Bo, Tao Dacheng\nconference: Arxiv\nyear: 2019\nbibkey: liu2019query\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1904.08623\"}\ntags: ['ARXIV', 'Graph', 'Quantisation', 'TIP']\n---\nHash based nearest neighbor search has become attractive in many applications. However, the quantization in hashing usually degenerates the discriminative power when using Hamming distance ranking. Besides, for large-scale visual search, existing hashing methods cannot directly support the efficient search over the data with multiple sources, and while the literature has shown that adaptively incorporating complementary information from diverse sources or views can significantly boost the search performance. To address the problems, this paper proposes a novel and generic approach to building multiple hash tables with multiple views and generating fine-grained ranking results at bitwise and tablewise levels. For each hash table, a query-adaptive bitwise weighting is introduced to alleviate the quantization loss by simultaneously exploiting the quality of hash functions and their complement for nearest neighbor search. From the tablewise aspect, multiple hash tables are built for different data views as a joint index, over which a query-specific rank fusion is proposed to rerank all results from the bitwise ranking by diffusing in a graph. Comprehensive experiments on image search over three well-known benchmarks show that the proposed method achieves up to 17.11% and 20.28% performance gains on single and multiple table search over state-of-the-art methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [1.7228749990463257, -25.594444274902344]}, {"key": "", "year": "", "title": "Liu2019ranking", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Ranking-based Deep Cross-modal Hashing\"\nauthors: Liu Xuanwu, Yu Guoxian, Domeniconi Carlotta, Wang Jun, Ren Yazhou, Guo Maozu\nconference: Arxiv\nyear: 2019\nbibkey: liu2019ranking\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1905.04450\"}\ntags: ['ARXIV', 'Cross Modal', 'Semi Supervised', 'Supervised', 'TIP']\n---\nCross-modal hashing has been receiving increasing interests for its low storage cost and fast query speed in multi-modal data retrievals. However, most existing hashing methods are based on hand-crafted or raw level features of objects, which may not be optimally compatible with the coding process. Besides, these hashing methods are mainly designed to handle simple pairwise similarity. The complex multilevel ranking semantic structure of instances associated with multiple labels has not been well explored yet. In this paper, we propose a ranking-based deep cross-modal hashing approach (RDCMH). RDCMH firstly uses the feature and label information of data to derive a semi-supervised semantic ranking list. Next, to expand the semantic representation power of hand-crafted features, RDCMH integrates the semantic ranking information into deep cross-modal hashing and jointly optimizes the compatible parameters of deep feature representations and of hashing functions. Experiments on real multi-modal datasets show that RDCMH outperforms other competitive baselines and achieves the state-of-the-art performance in cross-modal retrieval applications.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-8.14219856262207, -4.408385276794434]}, {"key": "", "year": "", "title": "Liu2019weakly", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Weakly-paired Cross-Modal Hashing\"\nauthors: Liu Xuanwu, Wang Jun, Yu Guoxian, Domeniconi Carlotta, Zhang Xiangliang\nconference: Arxiv\nyear: 2019\nbibkey: liu2019weakly\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1905.12203\"}\ntags: ['ARXIV', 'Cross Modal']\n---\nHashing has been widely adopted for large-scale data retrieval in many domains, due to its low storage cost and high retrieval speed. Existing cross-modal hashing methods optimistically assume that the correspondence between training samples across modalities are readily available. This assumption is unrealistic in practical applications. In addition, these methods generally require the same number of samples across different modalities, which restricts their flexibility. We propose a flexible cross-modal hashing approach (Flex-CMH) to learn effective hashing codes from weakly-paired data, whose correspondence across modalities are partially (or even totally) unknown. FlexCMH first introduces a clustering-based matching strategy to explore the local structure of each cluster, and thus to find the potential correspondence between clusters (and samples therein) across modalities. To reduce the impact of an incomplete correspondence, it jointly optimizes in a unified objective function the potential correspondence, the cross-modal hashing functions derived from the correspondence, and a hashing quantitative loss. An alternative optimization technique is also proposed to coordinate the correspondence and hash functions, and to reinforce the reciprocal effects of the two objectives. Experiments on publicly multi-modal datasets show that FlexCMH achieves significantly better results than state-of-the-art methods, and it indeed offers a high degree of flexibility for practical cross-modal hashing tasks.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-13.411568641662598, -5.014536380767822]}, {"key": "", "year": "", "title": "Liu2020reinforcing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Reinforcing Short-Length Hashing\"\nauthors: Liu Xingbo, Nie Xiushan, Dai Qi, Huang Yupan, Yin Yilong\nconference: Arxiv\nyear: 2020\nbibkey: liu2020reinforcing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2004.11511\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nDue to the compelling efficiency in retrieval and storage, similarity-preserving hashing has been widely applied to approximate nearest neighbor search in large-scale image retrieval. However, existing methods have poor performance in retrieval using an extremely short-length hash code due to weak ability of classification and poor distribution of hash bit. To address this issue, in this study, we propose a novel reinforcing short-length hashing (RSLH). In this proposed RSLH, mutual reconstruction between the hash representation and semantic labels is performed to preserve the semantic information. Furthermore, to enhance the accuracy of hash representation, a pairwise similarity matrix is designed to make a balance between accuracy and training expenditure on memory. In addition, a parameter boosting strategy is integrated to reinforce the precision with hash bits fusion. Extensive experiments on three large-scale image benchmarks demonstrate the superior performance of RSLH under various short-length hashing scenarios.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [0.4609058201313019, 9.330801963806152]}, {"key": "", "year": "", "title": "Liu2020shuffle", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Shuffle and Learn: Minimizing Mutual Information for Unsupervised Hashing\"\nauthors: Liu Fangrui, Liu Zheng\nconference: Arxiv\nyear: 2020\nbibkey: liu2020shuffle\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2011.10239\"}\ntags: ['ARXIV', 'Image Retrieval', 'Supervised', 'Unsupervised']\n---\nUnsupervised binary representation allows fast data retrieval without any annotations, enabling practical application like fast person re-identification and multimedia retrieval. It is argued that conflicts in binary space are one of the major barriers to high-performance unsupervised hashing as current methods failed to capture the precise code conflicts in the full domain. A novel relaxation method called Shuffle and Learn is proposed to tackle code conflicts in the unsupervised hash. Approximated derivatives for joint probability and the gradients for the binary layer are introduced to bridge the update from the hash to the input. Proof on $\\epsilon$-Convergence of joint probability with approximated derivatives is provided to guarantee the preciseness on update applied on the mutual information. The proposed algorithm is carried out with iterative global updates to minimize mutual information, diverging the code before regular unsupervised optimization. Experiments suggest that the proposed method can relax the code optimization from local optimum and help to generate binary representations that are more discriminative and informative without any annotations. Performance benchmarks on image retrieval with the unsupervised binary code are conducted on three open datasets, and the model achieves state-of-the-art accuracy on image retrieval task for all those datasets. Datasets and reproducible code are provided.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [2.205021381378174, 13.170662879943848]}, {"key": "", "year": "", "title": "Liu2021fddh", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"FDDH: Fast Discriminative Discrete Hashing for Large-Scale Cross-Modal Retrieval\"\nauthors: Liu Xin, Wang Xingzhi, Cheung Yiu-ming\nconference: IEEE Transactions on Neural Networks and Learning Systems,\nyear: 2021\nbibkey: liu2021fddh\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2105.07128\"}   - {name: \"Code\", url: \"https://github.com/starxliu/FDDH.\"}\ntags: ['Cross Modal', 'Quantisation', 'Streaming Data']\n---\nCross-modal hashing, favored for its effectiveness and efficiency, has received wide attention to facilitating efficient retrieval across different modalities. Nevertheless, most existing methods do not sufficiently exploit the discriminative power of semantic information when learning the hash codes, while often involving time-consuming training procedure for handling the large-scale dataset. To tackle these issues, we formulate the learning of similarity-preserving hash codes in terms of orthogonally rotating the semantic data so as to minimize the quantization loss of mapping such data to hamming space, and propose an efficient Fast Discriminative Discrete Hashing (FDDH) approach for large-scale cross-modal retrieval. More specifically, FDDH introduces an orthogonal basis to regress the targeted hash codes of training examples to their corresponding semantic labels, and utilizes \"-dragging technique to provide provable large semantic margins. Accordingly, the discriminative power of semantic information can be explicitly captured and maximized. Moreover, an orthogonal transformation scheme is further proposed to map the nonlinear embedding data into the semantic subspace, which can well guarantee the semantic consistency between the data feature and its semantic representation. Consequently, an efficient closed form solution is derived for discriminative hash code learning, which is very computationally efficient. In addition, an effective and stable online learning strategy is presented for optimizing modality-specific projection functions, featuring adaptivity to different training sizes and streaming data. The proposed FDDH approach theoretically approximates the bi-Lipschitz continuity, runs sufficiently fast, and also significantly improves the retrieval performance over the state-of-the-art methods. The source code is released at: https://github.com/starxliu/FDDH.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-13.111518859863281, 7.7372517585754395]}, {"key": "", "year": "", "title": "Liu2021ternary", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Ternary Hashing\"\nauthors: Liu Chang, Fan Lixin, Ng Kam Woh, Jin Yilun, Ju Ce, Zhang Tianyu, Chan Chee Seng, Yang Qiang\nconference: Arxiv\nyear: 2021\nbibkey: liu2021ternary\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2103.09173\"}\ntags: ['ARXIV']\n---\nThis paper proposes a novel ternary hash encoding for learning to hash methods, which provides a principled more efficient coding scheme with performances better than those of the state-of-the-art binary hashing counterparts. Two kinds of axiomatic ternary logic, Kleene logic and {\\L}ukasiewicz logic are adopted to calculate the Ternary Hamming Distance (THD) for both the learning/encoding and testing/querying phases. Our work demonstrates that, with an efficient implementation of ternary logic on standard binary machines, the proposed ternary hashing is compared favorably to the binary hashing methods with consistent improvements of retrieval mean average precision (mAP) ranging from 1\\% to 5.9\\% as shown in CIFAR10, NUS-WIDE and ImageNet100 datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-17.293773651123047, 2.19644832611084]}, {"key": "", "year": "", "title": "Liu2022dimension", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Dimension Reduction for Efficient Dense Retrieval via Conditional Autoencoder\"\nauthors: Liu Zhenghao, Zhang Han, Xiong Chenyan, Liu Zhiyuan, Gu Yu, Li Xiaohua\nconference: Arxiv\nyear: 2022\nbibkey: liu2022dimension\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2205.03284\"}   - {name: \"Code\", url: \"https://github.com/NEUIR/ConAE.\"}\ntags: ['ARXIV']\n---\nDense retrievers encode queries and documents and map them in an embedding space using pre-trained language models. These embeddings need to be high-dimensional to fit training signals and guarantee the retrieval effectiveness of dense retrievers. However, these high-dimensional embeddings lead to larger index storage and higher retrieval latency. To reduce the embedding dimensions of dense retrieval, this paper proposes a Conditional Autoencoder (ConAE) to compress the high-dimensional embeddings to maintain the same embedding distribution and better recover the ranking features. Our experiments show that ConAE is effective in compressing embeddings by achieving comparable ranking performance with its teacher model and making the retrieval system more efficient. Our further analyses show that ConAE can alleviate the redundancy of the embeddings of dense retrieval with only one linear layer. All codes of this work are available at https://github.com/NEUIR/ConAE.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-16.448930740356445, 9.183478355407715]}, {"key": "", "year": "", "title": "Liu2022prototype", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Prototype-Based Layered Federated Cross-Modal Hashing\"\nauthors: Liu Jiale, Zhan Yu-Wei, Luo Xin, Chen Zhen-Duo, Wang Yongxin, Xu Xin-Shun\nconference: Arxiv\nyear: 2022\nbibkey: liu2022prototype\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2210.15678\"}\ntags: ['ARXIV', 'Cross Modal']\n---\nRecently, deep cross-modal hashing has gained increasing attention. However, in many practical cases, data are distributed and cannot be collected due to privacy concerns, which greatly reduces the cross-modal hashing performance on each client. And due to the problems of statistical heterogeneity, model heterogeneity, and forcing each client to accept the same parameters, applying federated learning to cross-modal hash learning becomes very tricky. In this paper, we propose a novel method called prototype-based layered federated cross-modal hashing. Specifically, the prototype is introduced to learn the similarity between instances and classes on server, reducing the impact of statistical heterogeneity (non-IID) on different clients. And we monitor the distance between local and global prototypes to further improve the performance. To realize personalized federated learning, a hypernetwork is deployed on server to dynamically update different layers' weights of local model. Experimental results on benchmark datasets show that our method outperforms state-of-the-art methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-14.09129810333252, -1.0149720907211304]}, {"key": "", "year": "", "title": "Liu2023can", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Can LSH (Locality-Sensitive Hashing) Be Replaced by Neural Network\"\nauthors: Liu Renyang, Zhao Jun, Chu Xing, Liang Yu, Zhou Wei, He Jing\nconference: Arxiv\nyear: 2023\nbibkey: liu2023can\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2310.09806\"}\ntags: ['ARXIV', 'GAN', 'Graph', 'LSH']\n---\nWith the rapid development of GPU (Graphics Processing Unit) technologies and neural networks, we can explore more appropriate data structures and algorithms. Recent progress shows that neural networks can partly replace traditional data structures. In this paper, we proposed a novel DNN (Deep Neural Network)-based learned locality-sensitive hashing, called LLSH, to efficiently and flexibly map high-dimensional data to low-dimensional space. LLSH replaces the traditional LSH (Locality-sensitive Hashing) function families with parallel multi-layer neural networks, which reduces the time and memory consumption and guarantees query accuracy simultaneously. The proposed LLSH demonstrate the feasibility of replacing the hash index with learning-based neural networks and open a new door for developers to design and configure data organization more accurately to improve information-searching performance. Extensive experiments on different types of datasets show the superiority of the proposed method in query accuracy, time consumption, and memory usage.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-16.768898010253906, 14.154949188232422]}, {"key": "", "year": "", "title": "Liu2023hs", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"HS-GCN: Hamming Spatial Graph Convolutional Networks for Recommendation\"\nauthors: Liu Han, Wei Yinwei, Yin Jianhua, Nie Liqiang\nconference: Arxiv\nyear: 2023\nbibkey: liu2023hs\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2301.05430\"}\ntags: ['ARXIV', 'Graph', 'TIP']\n---\nAn efficient solution to the large-scale recommender system is to represent users and items as binary hash codes in the Hamming space. Towards this end, existing methods tend to code users by modeling their Hamming similarities with the items they historically interact with, which are termed as the first-order similarities in this work. Despite their efficiency, these methods suffer from the suboptimal representative capacity, since they forgo the correlation established by connecting multiple first-order similarities, i.e., the relation among the indirect instances, which could be defined as the high-order similarity. To tackle this drawback, we propose to model both the first- and the high-order similarities in the Hamming space through the user-item bipartite graph. Therefore, we develop a novel learning to hash framework, namely Hamming Spatial Graph Convolutional Networks (HS-GCN), which explicitly models the Hamming similarity and embeds it into the codes of users and items. Extensive experiments on three public benchmark datasets demonstrate that our proposed model significantly outperforms several state-of-the-art hashing models, and obtains performance comparable with the real-valued recommendation models.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [3.668790817260742, -26.987354278564453]}, {"key": "", "year": "", "title": "Liu2023sparse", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Sparse-Inductive Generative Adversarial Hashing for Nearest Neighbor Search\"\nauthors: Liu Hong\nconference: Arxiv\nyear: 2023\nbibkey: liu2023sparse\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2306.06928\"}\ntags: ['ARXIV', 'Quantisation', 'Supervised', 'Unsupervised']\n---\nUnsupervised hashing has received extensive research focus on the past decade, which typically aims at preserving a predefined metric (i.e. Euclidean metric) in the Hamming space. To this end, the encoding functions of the existing hashing are typically quasi-isometric, which devote to reducing the quantization loss from the target metric space to the discrete Hamming space. However, it is indeed problematic to directly minimize such error, since such mentioned two metric spaces are heterogeneous, and the quasi-isometric mapping is non-linear. The former leads to inconsistent feature distributions, while the latter leads to problematic optimization issues. In this paper, we propose a novel unsupervised hashing method, termed Sparsity-Induced Generative Adversarial Hashing (SiGAH), to encode large-scale high-dimensional features into binary codes, which well solves the two problems through a generative adversarial training framework. Instead of minimizing the quantization loss, our key innovation lies in enforcing the learned Hamming space to have similar data distribution to the target metric space via a generative model. In particular, we formulate a ReLU-based neural network as a generator to output binary codes and an MSE-loss based auto-encoder network as a discriminator, upon which a generative adversarial learning is carried out to train hash functions. Furthermore, to generate the synthetic features from the hash codes, a compressed sensing procedure is introduced into the generative model, which enforces the reconstruction boundary of binary codes to be consistent with that of original features. Finally, such generative adversarial framework can be trained via the Adam optimizer. Experimental results on four benchmarks, i.e., Tiny100K, GIST1M, Deep1M, and MNIST, have shown that the proposed SiGAH has superior performance over the state-of-the-art approaches.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-10.605259895324707, 5.356685638427734]}, {"key": "", "year": "", "title": "Liu2024novel", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Novel Artistic Scene-Centric Datasets for Effective Transfer Learning in Fragrant Spaces\"\nauthors: Liu Shumei, Huang Haiting, Zinnen Mathias, Maier Andreas, Christlein Vincent\nconference: Arxiv\nyear: 2024\nbibkey: liu2024novel\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2407.11701\"}   - {name: \"Paper\", url: \"https://zenodo.org/doi/10.5281/zenodo.11584328.\"}\ntags: ['ARXIV']\n---\nOlfaction, often overlooked in cultural heritage studies, holds profound significance in shaping human experiences and identities. Examining historical depictions of olfactory scenes can offer valuable insights into the role of smells in history. We show that a transfer-learning approach using weakly labeled training data can remarkably improve the classification of fragrant spaces and, more generally, artistic scene depictions. We fine-tune Places365-pre-trained models by querying two cultural heritage data sources and using the search terms as supervision signal. The models are evaluated on two manually corrected test splits. This work lays a foundation for further exploration of fragrant spaces recognition and artistic scene classification. All images and labels are released as the ArtPlaces dataset at https://zenodo.org/doi/10.5281/zenodo.11584328.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [24.827787399291992, 4.311798572540283]}, {"key": "", "year": "", "title": "Loncaric2018convolutional", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Convolutional Hashing for Automated Scene Matching\"\nauthors: Loncaric Martin, Liu Bowei, Weber Ryan\nconference: Arxiv\nyear: 2018\nbibkey: loncaric2018convolutional\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1802.03101\"}\ntags: ['ARXIV', 'TOM']\n---\nWe present a powerful new loss function and training scheme for learning binary hash functions. In particular, we demonstrate our method by creating for the first time a neural network that outperforms state-of-the-art Haar wavelets and color layout descriptors at the task of automated scene matching. By accurately relating distance on the manifold of network outputs to distance in Hamming space, we achieve a 100-fold reduction in nontrivial false positive rate and significantly higher true positive rate. We expect our insights to provide large wins for hashing models applied to other information retrieval hashing tasks as well.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-18.83808135986328, 16.192365646362305]}, {"key": "", "year": "", "title": "Loncaric2018learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning Hash Codes via Hamming Distance Targets\"\nauthors: Loncaric Martin, Liu Bowei, Weber Ryan\nconference: Arxiv\nyear: 2018\nbibkey: loncaric2018learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1810.01008\"}\ntags: ['ARXIV']\n---\nWe present a powerful new loss function and training scheme for learning binary hash codes with any differentiable model and similarity function. Our loss function improves over prior methods by using log likelihood loss on top of an accurate approximation for the probability that two inputs fall within a Hamming distance target. Our novel training scheme obtains a good estimate of the true gradient by better sampling inputs and evaluating loss terms between all pairs of inputs in each minibatch. To fully leverage the resulting hashes, we use multi-indexing. We demonstrate that these techniques provide large improvements to a similarity search tasks. We report the best results to date on competitive information retrieval tasks for ImageNet and SIFT 1M, improving MAP from 73% to 84% and reducing query cost by a factor of 2-8, respectively.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [0.23995648324489594, 0.0941939502954483]}, {"key": "", "year": "", "title": "Long2015composite", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Composite Correlation Quantization for Efficient Multimodal Retrieval\"\nauthors: Long Mingsheng, Cao Yue, Wang Jianmin, Yu Philip S.\nconference: Arxiv\nyear: 2015\nbibkey: long2015composite\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1504.04818\"}\ntags: ['ARXIV', 'Cross Modal', 'Quantisation', 'TIP']\n---\nEfficient similarity retrieval from large-scale multimodal database is pervasive in modern search engines and social networks. To support queries across content modalities, the system should enable cross-modal correlation and computation-efficient indexing. While hashing methods have shown great potential in achieving this goal, current attempts generally fail to learn isomorphic hash codes in a seamless scheme, that is, they embed multiple modalities in a continuous isomorphic space and separately threshold embeddings into binary codes, which incurs substantial loss of retrieval accuracy. In this paper, we approach seamless multimodal hashing by proposing a novel Composite Correlation Quantization (CCQ) model. Specifically, CCQ jointly finds correlation-maximal mappings that transform different modalities into isomorphic latent space, and learns composite quantizers that convert the isomorphic latent features into compact binary codes. An optimization framework is devised to preserve both intra-modal similarity and inter-modal correlation through minimizing both reconstruction and quantization errors, which can be trained from both paired and partially paired data in linear time. A comprehensive set of experiments clearly show the superior effectiveness and efficiency of CCQ against the state of the art hashing methods for both unimodal and cross-modal retrieval.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-4.324961185455322, -3.8659465312957764]}, {"key": "", "year": "", "title": "Long2018a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Filter of Minhash for Image Similarity Measures\"\nauthors: Long Jun, Liu Qunfeng, Yuan Xinpan, Zhang Chengyuan, Liu Junfeng\nconference: Arxiv\nyear: 2018\nbibkey: long2018a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1807.02895\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nImage similarity measures play an important role in nearest neighbor search and duplicate detection for large-scale image datasets. Recently, Minwise Hashing (or Minhash) and its related hashing algorithms have achieved great performances in large-scale image retrieval systems. However, there are a large number of comparisons for image pairs in these applications, which may spend a lot of computation time and affect the performance. In order to quickly obtain the pairwise images that theirs similarities are higher than the specific threshold T (e.g., 0.5), we propose a dynamic threshold filter of Minwise Hashing for image similarity measures. It greatly reduces the calculation time by terminating the unnecessary comparisons in advance. We also find that the filter can be extended to other hashing algorithms, on when the estimator satisfies the binomial distribution, such as b-Bit Minwise Hashing, One Permutation Hashing, etc. In this pager, we use the Bag-of-Visual-Words (BoVW) model based on the Scale Invariant Feature Transform (SIFT) to represent the image features. We have proved that the filter is correct and effective through the experiment on real image datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [6.702389717102051, 6.8678436279296875]}, {"key": "", "year": "", "title": "Long2022adaptive", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Adaptive Asymmetric Label-guided Hashing for Multimedia Search\"\nauthors: Long Yitian\nconference: Arxiv\nyear: 2022\nbibkey: long2022adaptive\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2207.12625\"}\ntags: ['ACL', 'ARXIV', 'Cross Modal', 'Quantisation', 'Supervised']\n---\nWith the rapid growth of multimodal media data on the Web in recent years, hash learning methods as a way to achieve efficient and flexible cross-modal retrieval of massive multimedia data have received a lot of attention from the current Web resource retrieval research community. Existing supervised hashing methods simply transform label information into pairwise similarity information to guide hash learning, leading to a potential risk of semantic error in the face of multi-label data. In addition, most existing hash optimization methods solve NP-hard optimization problems by employing approximate approximation strategies based on relaxation strategies, leading to a large quantization error. In order to address above obstacles, we present a simple yet efficient Adaptive Asymmetric Label-guided Hashing, named A2LH, for Multimedia Search. Specifically, A2LH is a two-step hashing method. In the first step, we design an association representation model between the different modality representations and semantic label representation separately, and use the semantic label representation as an intermediate bridge to solve the semantic gap existing between different modalities. In addition, we present an efficient discrete optimization algorithm for solving the quantization error problem caused by relaxation-based optimization algorithms. In the second step, we leverage the generated hash codes to learn the hash mapping functions. The experimental results show that our proposed method achieves optimal performance on all compared baseline methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-14.894567489624023, 4.7721357345581055]}, {"key": "", "year": "", "title": "Long2024cfir", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"CFIR: Fast and Effective Long-Text To Image Retrieval for Large Corpora\"\nauthors: Long Zijun, Ge Xuri, Mccreadie Richard, Jose Joemon\nconference: Arxiv\nyear: 2024\nbibkey: long2024cfir\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2402.15276\"}   - {name: \"Code\", url: \"https://github.com/longkukuhi/CFIR.\"}\ntags: ['ARXIV', 'Image Retrieval', 'TIP', 'TOM']\n---\nText-to-image retrieval aims to find the relevant images based on a text query, which is important in various use-cases, such as digital libraries, e-commerce, and multimedia databases. Although Multimodal Large Language Models (MLLMs) demonstrate state-of-the-art performance, they exhibit limitations in handling large-scale, diverse, and ambiguous real-world needs of retrieval, due to the computation cost and the injective embeddings they produce. This paper presents a two-stage Coarse-to-Fine Index-shared Retrieval (CFIR) framework, designed for fast and effective large-scale long-text to image retrieval. The first stage, Entity-based Ranking (ER), adapts to long-text query ambiguity by employing a multiple-queries-to-multiple-targets paradigm, facilitating candidate filtering for the next stage. The second stage, Summary-based Re-ranking (SR), refines these rankings using summarized queries. We also propose a specialized Decoupling-BEiT-3 encoder, optimized for handling ambiguous user needs and both stages, which also enhances computational efficiency through vector-based similarity inference. Evaluation on the AToMiC dataset reveals that CFIR surpasses existing MLLMs by up to 11.06% in Recall@1000, while reducing training and retrieval times by 68.75% and 99.79%, respectively. We will release our code to facilitate future research at https://github.com/longkukuhi/CFIR.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.579771995544434, 12.424221992492676]}, {"key": "", "year": "", "title": "Louren\u00e7o2019hierarchy", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hierarchy-of-Visual-Words: a Learning-based Approach for Trademark Image Retrieval\"\nauthors: Louren\u00e7o V\u00edtor N., Silva Gabriela G., Fernandes Leandro A. F.\nconference: Arxiv\nyear: 2019\nbibkey: louren\u00e7o2019hierarchy\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1908.02786\"}\ntags: ['ARXIV', 'GAN', 'Image Retrieval']\n---\nIn this paper, we present the Hierarchy-of-Visual-Words (HoVW), a novel trademark image retrieval (TIR) method that decomposes images into simpler geometric shapes and defines a descriptor for binary trademark image representation by encoding the hierarchical arrangement of component shapes. The proposed hierarchical organization of visual data stores each component shape as a visual word. It is capable of representing the geometry of individual elements and the topology of the trademark image, making the descriptor robust against linear as well as to some level of nonlinear transformation. Experiments show that HoVW outperforms previous TIR methods on the MPEG-7 CE-1 and MPEG-7 CE-2 image databases.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [24.992040634155273, 2.3899590969085693]}, {"key": "", "year": "", "title": "Louza2019algorithms", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Algorithms to compute the Burrows-Wheeler Similarity Distribution\"\nauthors: Louza Felipe A., Telles Guilherme P., Gog Simon, Zhao Liang\nconference: Arxiv\nyear: 2019\nbibkey: louza2019algorithms\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1903.10583\"}\ntags: ['ARXIV']\n---\nThe Burrows-Wheeler transform (BWT) is a well studied text transformation widely used in data compression and text indexing. The BWT of two strings can also provide similarity measures between them, based on the observation that the more their symbols are intermixed in the transformation, the more the strings are similar. In this article we present two new algorithms to compute similarity measures based on the BWT for string collections. In particular, we present practical and theoretical improvements to the computation of the Burrows-Wheeler similarity distribution for all pairs of strings in a collection. Our algorithms take advantage of the BWT computed for the concatenation of all strings, and use compressed data structures that allow reducing the running time with a small memory footprint, as shown by a set of experiments with real and artificial datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [16.30098533630371, -14.944073677062988]}, {"key": "", "year": "", "title": "Lu2013finding", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Finding More Relevance: Propagating Similarity on Markov Random Field for Image Retrieval\"\nauthors: Lu Peng, Peng Xujun, Zhu Xinshan, Wang Xiaojie\nconference: Arxiv\nyear: 2013\nbibkey: lu2013finding\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1312.7085\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nTo effectively retrieve objects from large corpus with high accuracy is a challenge task. In this paper, we propose a method that propagates visual feature level similarities on a Markov random field (MRF) to obtain a high level correspondence in image space for image pairs. The proposed correspondence between image pair reflects not only the similarity of low-level visual features but also the relations built through other images in the database and it can be easily integrated into the existing bag-of-visual-words(BoW) based systems to reduce the missing rate. We evaluate our method on the standard Oxford-5K, Oxford-105K and Paris-6K dataset. The experiment results show that the proposed method significantly improves the retrieval accuracy on three datasets and exceeds the current state-of-the-art retrieval performance.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [17.06538963317871, 3.98372483253479]}, {"key": "", "year": "", "title": "Lu2014efficient", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Efficient Image Categorization with Sparse Fisher Vector\"\nauthors: Lu Xiankai, Fang Zheng, Xu Tao, Zhang Haiting, Tuo Hongya\nconference: Arxiv\nyear: 2014\nbibkey: lu2014efficient\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1410.3905\"}\ntags: ['ARXIV']\n---\nIn object recognition, Fisher vector (FV) representation is one of the state-of-art image representations ways at the expense of dense, high dimensional features and increased computation time. A simplification of FV is attractive, so we propose Sparse Fisher vector (SFV). By incorporating locality strategy, we can accelerate the Fisher coding step in image categorization which is implemented from a collective of local descriptors. Combining with pooling step, we explore the relationship between coding step and pooling step to give a theoretical explanation about SFV. Experiments on benchmark datasets have shown that SFV leads to a speedup of several-fold of magnitude compares with FV, while maintaining the categorization performance. In addition, we demonstrate how SFV preserves the consistence in representation of similar local features.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [23.687679290771484, 17.324203491210938]}, {"key": "", "year": "", "title": "Lu2018fmhash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"FMHash: Deep Hashing of In-Air-Handwriting for User Identification\"\nauthors: Lu Duo, Huang Dijiang, Rai Anshul\nconference: Arxiv\nyear: 2018\nbibkey: lu2018fmhash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1806.03574\"}\ntags: ['ARXIV']\n---\nMany mobile systems and wearable devices, such as Virtual Reality (VR) or Augmented Reality (AR) headsets, lack a keyboard or touchscreen to type an ID and password for signing into a virtual website. However, they are usually equipped with gesture capture interfaces to allow the user to interact with the system directly with hand gestures. Although gesture-based authentication has been well-studied, less attention is paid to the gesture-based user identification problem, which is essentially an input method of account ID and an efficient searching and indexing method of a database of gesture signals. In this paper, we propose FMHash (i.e., Finger Motion Hash), a user identification framework that can generate a compact binary hash code from a piece of in-air-handwriting of an ID string. This hash code enables indexing and fast search of a large account database using the in-air-handwriting by a hash table. To demonstrate the effectiveness of the framework, we implemented a prototype and achieved &gt;99.5% precision and &gt;92.6% recall with exact hash code match on a dataset of 200 accounts collected by us. The ability of hashing in-air-handwriting pattern to binary code can be used to achieve convenient sign-in and sign-up with in-air-handwriting gesture ID on future mobile and wearable systems connected to the Internet.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-28.759174346923828, 11.859138488769531]}, {"key": "", "year": "", "title": "Lu2021deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Asymmetric Hashing with Dual Semantic Regression and Class Structure Quantization\"\nauthors: Lu Jianglin, Wang Hailing, Zhou Jie, Yan Mengfan, Wen Jiajun\nconference: Arxiv\nyear: 2021\nbibkey: lu2021deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2110.12478\"}\ntags: ['ARXIV', 'Graph', 'Image Retrieval', 'Quantisation']\n---\nRecently, deep hashing methods have been widely used in image retrieval task. Most existing deep hashing approaches adopt one-to-one quantization to reduce information loss. However, such class-unrelated quantization cannot give discriminative feedback for network training. In addition, these methods only utilize single label to integrate supervision information of data for hashing function learning, which may result in inferior network generalization performance and relatively low-quality hash codes since the inter-class information of data is totally ignored. In this paper, we propose a dual semantic asymmetric hashing (DSAH) method, which generates discriminative hash codes under three-fold constraints. Firstly, DSAH utilizes class prior to conduct class structure quantization so as to transmit class information during the quantization process. Secondly, a simple yet effective label mechanism is designed to characterize both the intra-class compactness and inter-class separability of data, thereby achieving semantic-sensitive binary code learning. Finally, a meaningful pairwise similarity preserving loss is devised to minimize the distances between class-related network outputs based on an affinity graph. With these three main components, high-quality hash codes can be generated through network. Extensive experiments conducted on various datasets demonstrate the superiority of DSAH in comparison with state-of-the-art deep hashing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-9.656028747558594, 2.7891619205474854]}, {"key": "", "year": "", "title": "Lu2021learnable", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learnable Locality-Sensitive Hashing for Video Anomaly Detection\"\nauthors: Lu Yue, Cao Congqi, Zhang Yanning\nconference: Arxiv\nyear: 2021\nbibkey: lu2021learnable\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2111.07839\"}\ntags: ['ARXIV', 'LSH']\n---\nVideo anomaly detection (VAD) mainly refers to identifying anomalous events that have not occurred in the training set where only normal samples are available. Existing works usually formulate VAD as a reconstruction or prediction problem. However, the adaptability and scalability of these methods are limited. In this paper, we propose a novel distance-based VAD method to take advantage of all the available normal data efficiently and flexibly. In our method, the smaller the distance between a testing sample and normal samples, the higher the probability that the testing sample is normal. Specifically, we propose to use locality-sensitive hashing (LSH) to map samples whose similarity exceeds a certain threshold into the same bucket in advance. In this manner, the complexity of near neighbor search is cut down significantly. To make the samples that are semantically similar get closer and samples not similar get further apart, we propose a novel learnable version of LSH that embeds LSH into a neural network and optimizes the hash functions with contrastive learning strategy. The proposed method is robust to data imbalance and can handle the large intra-class variations in normal data flexibly. Besides, it has a good ability of scalability. Extensive experiments demonstrate the superiority of our method, which achieves new state-of-the-art results on VAD benchmarks.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-9.788702964782715, 9.422584533691406]}, {"key": "", "year": "", "title": "Lu2021slosh", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"SLOSH: Set LOcality Sensitive Hashing via Sliced-Wasserstein Embeddings\"\nauthors: Lu Yuzhe, Liu Xinran, Soltoggio Andrea, Kolouri Soheil\nconference: Arxiv\nyear: 2021\nbibkey: lu2021slosh\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2112.05872\"}   - {name: \"Code\", url: \"https://github.com/mint-vu/SLOSH}{https://github.com/mint-vu/SLOSH}.\"}\ntags: ['ARXIV']\n---\nLearning from set-structured data is an essential problem with many applications in machine learning and computer vision. This paper focuses on non-parametric and data-independent learning from set-structured data using approximate nearest neighbor (ANN) solutions, particularly locality-sensitive hashing. We consider the problem of set retrieval from an input set query. Such retrieval problem requires: 1) an efficient mechanism to calculate the distances/dissimilarities between sets, and 2) an appropriate data structure for fast nearest neighbor search. To that end, we propose Sliced-Wasserstein set embedding as a computationally efficient \"set-2-vector\" mechanism that enables downstream ANN, with theoretical guarantees. The set elements are treated as samples from an unknown underlying distribution, and the Sliced-Wasserstein distance is used to compare sets. We demonstrate the effectiveness of our algorithm, denoted as Set-LOcality Sensitive Hashing (SLOSH), on various set retrieval datasets and compare our proposed embedding with standard set embedding approaches, including Generalized Mean (GeM) embedding/pooling, Featurewise Sort Pooling (FSPool), and Covariance Pooling and show consistent improvement in retrieval results. The code for replicating our results is available here: \\href{https://github.com/mint-vu/SLOSH}{https://github.com/mint-vu/SLOSH}.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-10.984968185424805, 4.319559097290039]}, {"key": "", "year": "", "title": "Lu2021visualsparta", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"VisualSparta: An Embarrassingly Simple Approach to Large-scale Text-to-Image Search with Weighted Bag-of-words\"\nauthors: Lu Xiaopeng, Zhao Tiancheng, Lee Kyusong\nconference: Arxiv\nyear: 2021\nbibkey: lu2021visualsparta\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2101.00265\"}\ntags: ['ARXIV', 'Cross Modal', 'Image Retrieval']\n---\nText-to-image retrieval is an essential task in cross-modal information retrieval, i.e., retrieving relevant images from a large and unlabelled dataset given textual queries. In this paper, we propose VisualSparta, a novel (Visual-text Sparse Transformer Matching) model that shows significant improvement in terms of both accuracy and efficiency. VisualSparta is capable of outperforming previous state-of-the-art scalable methods in MSCOCO and Flickr30K. We also show that it achieves substantial retrieving speed advantages, i.e., for a 1 million image index, VisualSparta using CPU gets ~391X speedup compared to CPU vector search and ~5.4X speedup compared to vector search with GPU acceleration. Experiments show that this speed advantage even gets bigger for larger datasets because VisualSparta can be efficiently implemented as an inverted index. To the best of our knowledge, VisualSparta is the first transformer-based text-to-image retrieval model that can achieve real-time searching for large-scale datasets, with significant accuracy improvement compared to previous state-of-the-art methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.341371536254883, 11.816755294799805]}, {"key": "", "year": "", "title": "Lu2022asymmetric", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Asymmetric Transfer Hashing with Adaptive Bipartite Graph Learning\"\nauthors: Lu Jianglin, Zhou Jie, Chen Yudong, Pedrycz Witold, Hung Kwok-Wai\nconference: Arxiv\nyear: 2022\nbibkey: lu2022asymmetric\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2206.12592\"}\ntags: ['ARXIV', 'Graph', 'Semi Supervised', 'Supervised', 'Unsupervised']\n---\nThanks to the efficient retrieval speed and low storage consumption, learning to hash has been widely used in visual retrieval tasks. However, existing hashing methods assume that the query and retrieval samples lie in homogeneous feature space within the same domain. As a result, they cannot be directly applied to heterogeneous cross-domain retrieval. In this paper, we propose a Generalized Image Transfer Retrieval (GITR) problem, which encounters two crucial bottlenecks: 1) the query and retrieval samples may come from different domains, leading to an inevitable {domain distribution gap}; 2) the features of the two domains may be heterogeneous or misaligned, bringing up an additional {feature gap}. To address the GITR problem, we propose an Asymmetric Transfer Hashing (ATH) framework with its unsupervised/semi-supervised/supervised realizations. Specifically, ATH characterizes the domain distribution gap by the discrepancy between two asymmetric hash functions, and minimizes the feature gap with the help of a novel adaptive bipartite graph constructed on cross-domain data. By jointly optimizing asymmetric hash functions and the bipartite graph, not only can knowledge transfer be achieved but information loss caused by feature alignment can also be avoided. Meanwhile, to alleviate negative transfer, the intrinsic geometrical structure of single-domain data is preserved by involving a domain affinity graph. Extensive experiments on both single-domain and cross-domain benchmarks under different GITR subtasks indicate the superiority of our ATH method in comparison with the state-of-the-art hashing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [2.2576746940612793, -27.966083526611328]}, {"key": "", "year": "", "title": "Lu2023attributes", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Attributes Grouping and Mining Hashing for Fine-Grained Image Retrieval\"\nauthors: Lu Xin, Chen Shikun, Cao Yichao, Zhou Xin, Lu Xiaobo\nconference: Proceedings of the\nyear: 2023\nbibkey: lu2023attributes\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2311.06067\"}\ntags: ['Image Retrieval', 'TIP']\n---\nIn recent years, hashing methods have been popular in the large-scale media search for low storage and strong representation capabilities. To describe objects with similar overall appearance but subtle differences, more and more studies focus on hashing-based fine-grained image retrieval. Existing hashing networks usually generate both local and global features through attention guidance on the same deep activation tensor, which limits the diversity of feature representations. To handle this limitation, we substitute convolutional descriptors for attention-guided features and propose an Attributes Grouping and Mining Hashing (AGMH), which groups and embeds the category-specific visual attributes in multiple descriptors to generate a comprehensive feature representation for efficient fine-grained image retrieval. Specifically, an Attention Dispersion Loss (ADL) is designed to force the descriptors to attend to various local regions and capture diverse subtle details. Moreover, we propose a Stepwise Interactive External Attention (SIEA) to mine critical attributes in each descriptor and construct correlations between fine-grained attributes and objects. The attention mechanism is dedicated to learning discrete attributes, which will not cost additional computations in hash codes generation. Finally, the compact binary codes are learned by preserving pairwise similarities. Experimental results demonstrate that AGMH consistently yields the best performance against state-of-the-art methods on fine-grained benchmark datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [1.5746328830718994, 9.405482292175293]}, {"key": "", "year": "", "title": "Lunga2017hashed", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hashed Binary Search Sampling for Convolutional Network Training with Large Overhead Image Patches\"\nauthors: Lunga Dalton, Yang Lexie, Bhaduri Budhendra\nconference: Arxiv\nyear: 2017\nbibkey: lunga2017hashed\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1707.05685\"}\ntags: ['ARXIV', 'Graph', 'Supervised']\n---\nVery large overhead imagery associated with ground truth maps has the potential to generate billions of training image patches for machine learning algorithms. However, random sampling selection criteria often leads to redundant and noisy-image patches for model training. With minimal research efforts behind this challenge, the current status spells missed opportunities to develop supervised learning algorithms that generalize over wide geographical scenes. In addition, much of the computational cycles for large scale machine learning are poorly spent crunching through noisy and redundant image patches. We demonstrate a potential framework to address these challenges specifically, while evaluating a human settlement detection task. A novel binary search tree sampling scheme is fused with a kernel based hashing procedure that maps image patches into hash-buckets using binary codes generated from image content. The framework exploits inherent redundancy within billions of image patches to promote mostly high variance preserving samples for accelerating algorithmic training and increasing model generalization.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-11.750083923339844, 13.084555625915527]}, {"key": "", "year": "", "title": "Luo2016ssh", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"SSH (Sketch, Shingle, &amp; Hash) for Indexing Massive-Scale Time Series\"\nauthors: Luo Chen, Shrivastava Anshumali\nconference: Arxiv\nyear: 2016\nbibkey: luo2016ssh\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1610.07328\"}\ntags: ['ARXIV']\n---\nSimilarity search on time series is a frequent operation in large-scale data-driven applications. Sophisticated similarity measures are standard for time series matching, as they are usually misaligned. Dynamic Time Warping or DTW is the most widely used similarity measure for time series because it combines alignment and matching at the same time. However, the alignment makes DTW slow. To speed up the expensive similarity search with DTW, branch and bound based pruning strategies are adopted. However, branch and bound based pruning are only useful for very short queries (low dimensional time series), and the bounds are quite weak for longer queries. Due to the loose bounds branch and bound pruning strategy boils down to a brute-force search. To circumvent this issue, we design SSH (Sketch, Shingle, &amp; Hashing), an efficient and approximate hashing scheme which is much faster than the state-of-the-art branch and bound searching technique: the UCR suite. SSH uses a novel combination of sketching, shingling and hashing techniques to produce (probabilistic) indexes which align (near perfectly) with DTW similarity measure. The generated indexes are then used to create hash buckets for sub-linear search. Our results show that SSH is very effective for longer time sequence and prunes around 95% candidates, leading to the massive speedup in search with DTW. Empirical results on two large-scale benchmark time series data show that our proposed method can be around 20 times faster than the state-of-the-art package (UCR suite) without any significant loss in accuracy.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-5.377130031585693, -19.238483428955078]}, {"key": "", "year": "", "title": "Luo2018collaborative", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Collaborative Learning for Extremely Low Bit Asymmetric Hashing\"\nauthors: Luo Yadan, Huang Zi, Li Yang, Shen Fumin, Yang Yang, Cui Peng\nconference: Arxiv\nyear: 2018\nbibkey: luo2018collaborative\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1809.09329\"}\ntags: ['ARXIV', 'Image Retrieval', 'TIP']\n---\nHashing techniques are in great demand for a wide range of real-world applications such as image retrieval and network compression. Nevertheless, existing approaches could hardly guarantee a satisfactory performance with the extremely low-bit (e.g., 4-bit) hash codes due to the severe information loss and the shrink of the discrete solution space. In this paper, we propose a novel \\textit{Collaborative Learning} strategy that is tailored for generating high-quality low-bit hash codes. The core idea is to jointly distill bit-specific and informative representations for a group of pre-defined code lengths. The learning of short hash codes among the group can benefit from the manifold shared with other long codes, where multiple views from different hash codes provide the supplementary guidance and regularization, making the convergence faster and more stable. To achieve that, an asymmetric hashing framework with two variants of multi-head embedding structures is derived, termed as Multi-head Asymmetric Hashing (MAH), leading to great efficiency of training and querying. Extensive experiments on three benchmark datasets have been conducted to verify the superiority of the proposed MAH, and have shown that the 8-bit hash codes generated by MAH achieve $94.3\\%$ of the MAP (Mean Average Precision (MAP)) score on the CIFAR-10 dataset, which significantly surpasses the performance of the 48-bit codes by the state-of-the-arts in image retrieval tasks.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-6.656577110290527, 5.516707420349121]}, {"key": "", "year": "", "title": "Luo2018deepsic", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"DeepSIC: Deep Semantic Image Compression\"\nauthors: Luo Sihui, Yang Yezhou, Song Mingli\nconference: Arxiv\nyear: 2018\nbibkey: luo2018deepsic\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1801.09468\"}\ntags: ['ARXIV']\n---\nIncorporating semantic information into the codecs during image compression can significantly reduce the repetitive computation of fundamental semantic analysis (such as object recognition) in client-side applications. The same practice also enable the compressed code to carry the image semantic information during storage and transmission. In this paper, we propose a concept called Deep Semantic Image Compression (DeepSIC) and put forward two novel architectures that aim to reconstruct the compressed image and generate corresponding semantic representations at the same time. The first architecture performs semantic analysis in the encoding process by reserving a portion of the bits from the compressed code to store the semantic representations. The second performs semantic analysis in the decoding step with the feature maps that are embedded in the compressed code. In both architectures, the feature maps are shared by the compression and the semantic analytics modules. To validate our approaches, we conduct experiments on the publicly available benchmarking datasets and achieve promising results. We also provide a thorough analysis of the advantages and disadvantages of the proposed technique.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [14.724632263183594, 14.990406036376953]}, {"key": "", "year": "", "title": "Luo2019snap", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Snap and Find: Deep Discrete Cross-domain Garment Image Retrieval\"\nauthors: Luo Yadan, Wang Ziwei, Huang Zi, Yang Yang, Lu Huimin\nconference: Arxiv\nyear: 2019\nbibkey: luo2019snap\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1904.02887\"}\ntags: ['ARXIV', 'Image Retrieval', 'TOM']\n---\nWith the increasing number of online stores, there is a pressing need for intelligent search systems to understand the item photos snapped by customers and search against large-scale product databases to find their desired items. However, it is challenging for conventional retrieval systems to match up the item photos captured by customers and the ones officially released by stores, especially for garment images. To bridge the customer- and store- provided garment photos, existing studies have been widely exploiting the clothing attributes (\\textit{e.g.,} black) and landmarks (\\textit{e.g.,} collar) to learn a common embedding space for garment representations. Unfortunately they omit the sequential correlation of attributes and consume large quantity of human labors to label the landmarks. In this paper, we propose a deep multi-task cross-domain hashing termed \\textit{DMCH}, in which cross-domain embedding and sequential attribute learning are modeled simultaneously. Sequential attribute learning not only provides the semantic guidance for embedding, but also generates rich attention on discriminative local details (\\textit{e.g.,} black buttons) of clothing items without requiring extra landmark labels. This leads to promising performance and 306$\\times$ boost on efficiency when compared with the state-of-the-art models, which is demonstrated through rigorous experiments on two public fashion datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [8.475895881652832, 13.123230934143066]}, {"key": "", "year": "", "title": "Luo2020a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Survey on Deep Hashing Methods\"\nauthors: Luo Xiao, Wang Haixin, Wu Daqing, Chen Chong, Deng Minghua, Huang Jianqiang, Hua Xian-Sheng\nconference: Arxiv\nyear: 2020\nbibkey: luo2020a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2003.03369\"}\ntags: ['ARXIV', 'Deep Learning', 'Quantisation', 'Self Supervised', 'Semi Supervised', 'Supervised', 'Survey Paper', 'Unsupervised']\n---\nNearest neighbor search aims to obtain the samples in the database with the smallest distances from them to the queries, which is a basic task in a range of fields, including computer vision and data mining. Hashing is one of the most widely used methods for its computational and storage efficiency. With the development of deep learning, deep hashing methods show more advantages than traditional methods. In this survey, we detailedly investigate current deep hashing algorithms including deep supervised hashing and deep unsupervised hashing. Specifically, we categorize deep supervised hashing methods into pairwise methods, ranking-based methods, pointwise methods as well as quantization according to how measuring the similarities of the learned hash codes. Moreover, deep unsupervised hashing is categorized into similarity reconstruction-based methods, pseudo-label-based methods and prediction-free self-supervised learning-based methods based on their semantic learning manners. We also introduce three related important topics including semi-supervised deep hashing, domain adaption deep hashing and multi-modal deep hashing. Meanwhile, we present some commonly used public datasets and the scheme to measure the performance of deep hashing algorithms. Finally, we discuss some potential research directions in conclusion.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-11.524885177612305, 3.622396469116211]}, {"key": "", "year": "", "title": "Luo2020cimon", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"CIMON: Towards High-quality Hash Codes\"\nauthors: Luo Xiao, Wu Daqing, Ma Zeyu, Chen Chong, Deng Minghua, Ma Jinwen, Jin Zhongming, Huang Jianqiang, Hua Xian-Sheng\nconference: Arxiv\nyear: 2020\nbibkey: luo2020cimon\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2010.07804\"}\ntags: ['ARXIV', 'Supervised', 'Unsupervised']\n---\nRecently, hashing is widely used in approximate nearest neighbor search for its storage and computational efficiency. Most of the unsupervised hashing methods learn to map images into semantic similarity-preserving hash codes by constructing local semantic similarity structure from the pre-trained model as the guiding information, i.e., treating each point pair similar if their distance is small in feature space. However, due to the inefficient representation ability of the pre-trained model, many false positives and negatives in local semantic similarity will be introduced and lead to error propagation during the hash code learning. Moreover, few of the methods consider the robustness of models, which will cause instability of hash codes to disturbance. In this paper, we propose a new method named {\\textbf{C}}omprehensive s{\\textbf{I}}milarity {\\textbf{M}}ining and c{\\textbf{O}}nsistency lear{\\textbf{N}}ing (CIMON). First, we use global refinement and similarity statistical distribution to obtain reliable and smooth guidance. Second, both semantic and contrastive consistency learning are introduced to derive both disturb-invariant and discriminative hash codes. Extensive experiments on several benchmark datasets show that the proposed method outperforms a wide range of state-of-the-art methods in both retrieval performance and robustness.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-7.25669002532959, 1.4942892789840698]}, {"key": "", "year": "", "title": "Luo2021deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Unsupervised Hashing by Distilled Smooth Guidance\"\nauthors: Luo Xiao, Ma Zeyu, Wu Daqing, Zhong Huasong, Chen Chong, Ma Jinwen, Deng Minghua\nconference: ICME\nyear: 2021\nbibkey: luo2021deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2105.06125\"}\ntags: ['Supervised', 'Unsupervised']\n---\nHashing has been widely used in approximate nearest neighbor search for its storage and computational efficiency. Deep supervised hashing methods are not widely used because of the lack of labeled data, especially when the domain is transferred. Meanwhile, unsupervised deep hashing models can hardly achieve satisfactory performance due to the lack of reliable similarity signals. To tackle this problem, we propose a novel deep unsupervised hashing method, namely Distilled Smooth Guidance (DSG), which can learn a distilled dataset consisting of similarity signals as well as smooth confidence signals. To be specific, we obtain the similarity confidence weights based on the initial noisy similarity signals learned from local structures and construct a priority loss function for smooth similarity-preserving learning. Besides, global information based on clustering is utilized to distill the image pairs by removing contradictory similarity signals. Extensive experiments on three widely used benchmark datasets show that the proposed DSG consistently outperforms the state-of-the-art search methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-6.895843982696533, -0.2726188600063324]}, {"key": "", "year": "", "title": "Luo2024fine", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fine-Grained Embedding Dimension Optimization During Training for Recommender Systems\"\nauthors: Luo Qinyi, Wang Penghan, Zhang Wei, Lai Fan, Mao Jiachen, Wei Xiaohan, Song Jun, Tsai Wei-Yu, Yang Shuai, Hu Yuxi, Qian Xuehai\nconference: Arxiv\nyear: 2024\nbibkey: luo2024fine\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2401.04408\"}\ntags: ['ARXIV', 'Deep Learning']\n---\nHuge embedding tables in modern Deep Learning Recommender Models (DLRM) require prohibitively large memory during training and inference. Aiming to reduce the memory footprint of training, this paper proposes FIne-grained In-Training Embedding Dimension optimization (FIITED). Given the observation that embedding vectors are not equally important, FIITED adjusts the dimension of each individual embedding vector continuously during training, assigning longer dimensions to more important embeddings while adapting to dynamic changes in data. A novel embedding storage system based on virtually-hashed physically-indexed hash tables is designed to efficiently implement the embedding dimension adjustment and effectively enable memory saving. Experiments on two industry models show that FIITED is able to reduce the size of embeddings by more than 65% while maintaining the trained model's quality, saving significantly more memory than a state-of-the-art in-training embedding pruning method. On public click-through rate prediction datasets, FIITED is able to prune up to 93.75%-99.75% embeddings without significant accuracy loss.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-20.564334869384766, 4.580927848815918]}, {"key": "", "year": "", "title": "Lyou2024modality", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Modality-Aware Representation Learning for Zero-shot Sketch-based Image Retrieval\"\nauthors: Lyou Eunyi, Lee Doyeon, Kim Jooeun, Lee Joonseok\nconference: Arxiv\nyear: 2024\nbibkey: lyou2024modality\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2401.04860\"}\ntags: ['ARXIV', 'Cross Modal', 'Image Retrieval', 'Text Retrieval']\n---\nZero-shot learning offers an efficient solution for a machine learning model to treat unseen categories, avoiding exhaustive data collection. Zero-shot Sketch-based Image Retrieval (ZS-SBIR) simulates real-world scenarios where it is hard and costly to collect paired sketch-photo samples. We propose a novel framework that indirectly aligns sketches and photos by contrasting them through texts, removing the necessity of access to sketch-photo pairs. With an explicit modality encoding learned from data, our approach disentangles modality-agnostic semantics from modality-specific information, bridging the modality gap and enabling effective cross-modal content retrieval within a joint latent space. From comprehensive experiments, we verify the efficacy of the proposed model on ZS-SBIR, and it can be also applied to generalized and fine-grained settings.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [5.595108509063721, 18.81671142578125]}, {"key": "", "year": "", "title": "Ma2019hierarchy", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hierarchy Neighborhood Discriminative Hashing for An Unified View of Single-Label and Multi-Label Image retrieval\"\nauthors: Ma Lei, Li Hongliang, Wu Qingbo, Meng Fanman, Ngan King Ngi\nconference: Arxiv\nyear: 2019\nbibkey: ma2019hierarchy\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1901.03060\"}\ntags: ['ARXIV', 'Graph', 'Image Retrieval', 'Supervised']\n---\nRecently, deep supervised hashing methods have become popular for large-scale image retrieval task. To preserve the semantic similarity notion between examples, they typically utilize the pairwise supervision or the triplet supervised information for hash learning. However, these methods usually ignore the semantic class information which can help the improvement of the semantic discriminative ability of hash codes. In this paper, we propose a novel hierarchy neighborhood discriminative hashing method. Specifically, we construct a bipartite graph to build coarse semantic neighbourhood relationship between the sub-class feature centers and the embeddings features. Moreover, we utilize the pairwise supervised information to construct the fined semantic neighbourhood relationship between embeddings features. Finally, we propose a hierarchy neighborhood discriminative hashing loss to unify the single-label and multilabel image retrieval problem with a one-stream deep neural network architecture. Experimental results on two largescale datasets demonstrate that the proposed method can outperform the state-of-the-art hashing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-4.814508438110352, 12.839818954467773]}, {"key": "", "year": "", "title": "Ma2021hierarchical", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hierarchical Similarity Learning for Language-based Product Image Retrieval\"\nauthors: Ma Zhe, Liu Fenghao, Dong Jianfeng, Qu Xiaoye, He Yuan, Ji Shouling\nconference: Arxiv\nyear: 2021\nbibkey: ma2021hierarchical\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2102.09375\"}   - {name: \"Code\", url: \"https://github.com/liufh1/hsl.\"}\ntags: ['ARXIV', 'Cross Modal', 'Image Retrieval', 'TIP']\n---\nThis paper aims for the language-based product image retrieval task. The majority of previous works have made significant progress by designing network structure, similarity measurement, and loss function. However, they typically perform vision-text matching at certain granularity regardless of the intrinsic multiple granularities of images. In this paper, we focus on the cross-modal similarity measurement, and propose a novel Hierarchical Similarity Learning (HSL) network. HSL first learns multi-level representations of input data by stacked encoders, and object-granularity similarity and image-granularity similarity are computed at each level. All the similarities are combined as the final hierarchical cross-modal similarity. Experiments on a large-scale product retrieval dataset demonstrate the effectiveness of our proposed method. Code and data are available at https://github.com/liufh1/hsl.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [21.723388671875, 3.095778703689575]}, {"key": "", "year": "", "title": "Ma2021muver", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"MuVER: Improving First-Stage Entity Retrieval with Multi-View Entity Representations\"\nauthors: Ma Xinyin, Jiang Yong, Bach Nguyen, Wang Tao, Huang Zhongqiang, Huang Fei, Lu Weiming\nconference: Arxiv\nyear: 2021\nbibkey: ma2021muver\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2109.05716\"}\ntags: ['ARXIV']\n---\nEntity retrieval, which aims at disambiguating mentions to canonical entities from massive KBs, is essential for many tasks in natural language processing. Recent progress in entity retrieval shows that the dual-encoder structure is a powerful and efficient framework to nominate candidates if entities are only identified by descriptions. However, they ignore the property that meanings of entity mentions diverge in different contexts and are related to various portions of descriptions, which are treated equally in previous works. In this work, we propose Multi-View Entity Representations (MuVER), a novel approach for entity retrieval that constructs multi-view representations for entity descriptions and approximates the optimal view for mentions via a heuristic searching method. Our method achieves the state-of-the-art performance on ZESHEL and improves the quality of candidates on three standard Entity Linking datasets\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [16.45351791381836, -6.083137035369873]}, {"key": "", "year": "", "title": "Ma2021rank", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Rank-Consistency Deep Hashing for Scalable Multi-Label Image Search\"\nauthors: Ma Cheng, Lu Jiwen, Zhou Jie\nconference: IEEE Transactions on Multimedia,\nyear: 2021\nbibkey: ma2021rank\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2102.01486\"}\ntags: ['Image Retrieval', 'TIP']\n---\nAs hashing becomes an increasingly appealing technique for large-scale image retrieval, multi-label hashing is also attracting more attention for the ability to exploit multi-level semantic contents. In this paper, we propose a novel deep hashing method for scalable multi-label image search. Unlike existing approaches with conventional objectives such as contrast and triplet losses, we employ a rank list, rather than pairs or triplets, to provide sufficient global supervision information for all the samples. Specifically, a new rank-consistency objective is applied to align the similarity orders from two spaces, the original space and the hamming space. A powerful loss function is designed to penalize the samples whose semantic similarity and hamming distance are mismatched in two spaces. Besides, a multi-label softmax cross-entropy loss is presented to enhance the discriminative power with a concise formulation of the derivative function. In order to manipulate the neighborhood structure of the samples with different labels, we design a multi-label clustering loss to cluster the hashing vectors of the samples with the same labels by reducing the distances between the samples and their multiple corresponding class centers. The state-of-the-art experimental results achieved on three public multi-label datasets, MIRFLICKR-25K, IAPRTC12 and NUS-WIDE, demonstrate the effectiveness of the proposed method.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [4.398961067199707, 5.324576377868652]}, {"key": "", "year": "", "title": "Ma2022deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Forest with Hashing Screening and Window Screening\"\nauthors: Ma Pengfei, Wu Youxi, Li Yan, Guo Lei, Jiang He, Zhu Xingquan, Wu Xindong\nconference: Arxiv\nyear: 2022\nbibkey: ma2022deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2207.11951\"}\ntags: ['ARXIV', 'Deep Learning']\n---\nAs a novel deep learning model, gcForest has been widely used in various applications. However, the current multi-grained scanning of gcForest produces many redundant feature vectors, and this increases the time cost of the model. To screen out redundant feature vectors, we introduce a hashing screening mechanism for multi-grained scanning and propose a model called HW-Forest which adopts two strategies, hashing screening and window screening. HW-Forest employs perceptual hashing algorithm to calculate the similarity between feature vectors in hashing screening strategy, which is used to remove the redundant feature vectors produced by multi-grained scanning and can significantly decrease the time cost and memory consumption. Furthermore, we adopt a self-adaptive instance screening strategy to improve the performance of our approach, called window screening, which can achieve higher accuracy without hyperparameter tuning on different datasets. Our experimental results show that HW-Forest has higher accuracy than other models, and the time cost is also reduced.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [3.0734429359436035, 21.14704704284668]}, {"key": "", "year": "", "title": "Macdonald2021on", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"On Approximate Nearest Neighbour Selection for Multi-Stage Dense Retrieval\"\nauthors: Macdonald Craig, Tonellotto Nicola\nconference: Arxiv\nyear: 2021\nbibkey: macdonald2021on\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2108.11480\"}\ntags: ['ARXIV', 'TIP']\n---\nDense retrieval, which describes the use of contextualised language models such as BERT to identify documents from a collection by leveraging approximate nearest neighbour (ANN) techniques, has been increasing in popularity. Two families of approaches have emerged, depending on whether documents and queries are represented by single or multiple embeddings. ColBERT, the exemplar of the latter, uses an ANN index and approximate scores to identify a set of candidate documents for each query embedding, which are then re-ranked using accurate document representations. In this manner, a large number of documents can be retrieved for each query, hindering the efficiency of the approach. In this work, we investigate the use of ANN scores for ranking the candidate documents, in order to decrease the number of candidate documents being fully scored. Experiments conducted on the MSMARCO passage ranking corpus demonstrate that, by cutting of the candidate set by using the approximate scores to only 200 documents, we can still obtain an effective ranking without statistically significant differences in effectiveness, and resulting in a 2x speedup in efficiency.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [15.167440414428711, -7.688982009887695]}, {"key": "", "year": "", "title": "Madden2024assessing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Assessing the Adversarial Security of Perceptual Hashing Algorithms\"\nauthors: Madden Jordan, Bhavsar Moxanki, Dorje Lhamo, Li Xiaohua\nconference: Arxiv\nyear: 2024\nbibkey: madden2024assessing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2406.00918\"}\ntags: ['ARXIV']\n---\nPerceptual hashing algorithms (PHAs) are utilized extensively for identifying illegal online content. Given their crucial role in sensitive applications, understanding their security strengths and weaknesses is critical. This paper compares three major PHAs deployed widely in practice: PhotoDNA, PDQ, and NeuralHash, and assesses their robustness against three typical attacks: normal image editing attacks, malicious adversarial attacks, and hash inversion attacks. Contrary to prevailing studies, this paper reveals that these PHAs exhibit resilience to black-box adversarial attacks when realistic constraints regarding the distortion and query budget are applied, attributed to the unique property of random hash variations. Moreover, this paper illustrates that original images can be reconstructed from the hash bits, raising significant privacy concerns. By comprehensively exposing their security vulnerabilities, this paper contributes to the ongoing efforts aimed at enhancing the security of PHAs for effective deployment.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-31.410247802734375, 7.3769025802612305]}, {"key": "", "year": "", "title": "Mafla2020stacmr", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"StacMR: Scene-Text Aware Cross-Modal Retrieval\"\nauthors: Mafla Andr\u00e9s, de Rezende Rafael Sampaio, G\u00f3mez Llu\u00eds, Larlus Diane, Karatzas Dimosthenis\nconference: Arxiv\nyear: 2020\nbibkey: mafla2020stacmr\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2012.04329\"}   - {name: \"Paper\", url: \"http://europe.naverlabs.com/stacmr\"}\ntags: ['ARXIV', 'Cross Modal', 'Graph']\n---\nRecent models for cross-modal retrieval have benefited from an increasingly rich understanding of visual scenes, afforded by scene graphs and object interactions to mention a few. This has resulted in an improved matching between the visual representation of an image and the textual representation of its caption. Yet, current visual representations overlook a key aspect: the text appearing in images, which may contain crucial information for retrieval. In this paper, we first propose a new dataset that allows exploration of cross-modal retrieval where images contain scene-text instances. Then, armed with this dataset, we describe several approaches which leverage scene text, including a better scene-text aware cross-modal retrieval method which uses specialized representations for text from the captions and text from the visual scene, and reconcile them in a common embedding space. Extensive experiments confirm that cross-modal retrieval approaches benefit from scene text and highlight interesting research questions worth exploring further. Dataset and code are available at http://europe.naverlabs.com/stacmr\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [26.278940200805664, 3.855210065841675]}, {"key": "", "year": "", "title": "Magliani2018a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Dense-Depth Representation for VLAD descriptors in Content-Based Image Retrieval\"\nauthors: Magliani Federico, Fontanini Tomaso, Prati Andrea\nconference: Arxiv\nyear: 2018\nbibkey: magliani2018a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1808.05022\"}\ntags: ['ARXIV', 'CNN', 'Deep Learning', 'Image Retrieval']\n---\nThe recent advances brought by deep learning allowed to improve the performance in image retrieval tasks. Through the many convolutional layers, available in a Convolutional Neural Network (CNN), it is possible to obtain a hierarchy of features from the evaluated image. At every step, the patches extracted are smaller than the previous levels and more representative. Following this idea, this paper introduces a new detector applied on the feature maps extracted from pre-trained CNN. Specifically, this approach lets to increase the number of features in order to increase the performance of the aggregation algorithms like the most famous and used VLAD embedding. The proposed approach is tested on different public datasets: Holidays, Oxford5k, Paris6k and UKB.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.064943313598633, 26.042322158813477]}, {"key": "", "year": "", "title": "Magliani2018an", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"An accurate retrieval through R-MAC+ descriptors for landmark recognition\"\nauthors: Magliani Federico, Prati Andrea\nconference: Arxiv\nyear: 2018\nbibkey: magliani2018an\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1806.08565\"}\ntags: ['ARXIV', 'CNN']\n---\nThe landmark recognition problem is far from being solved, but with the use of features extracted from intermediate layers of Convolutional Neural Networks (CNNs), excellent results have been obtained. In this work, we propose some improvements on the creation of R-MAC descriptors in order to make the newly-proposed R-MAC+ descriptors more representative than the previous ones. However, the main contribution of this paper is a novel retrieval technique, that exploits the fine representativeness of the MAC descriptors of the database images. Using this descriptors called \"db regions\" during the retrieval stage, the performance is greatly improved. The proposed method is tested on different public datasets: Oxford5k, Paris6k and Holidays. It outperforms the state-of-the- art results on Holidays and reached excellent results on Oxford5k and Paris6k, overcame only by approaches based on fine-tuning strategies.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.532980918884277, 30.61448097229004]}, {"key": "", "year": "", "title": "Magliani2018efficient", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Efficient Nearest Neighbors Search for Large-Scale Landmark Recognition\"\nauthors: Magliani Federico, Fontanini Tomaso, Prati Andrea\nconference: Arxiv\nyear: 2018\nbibkey: magliani2018efficient\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1806.05946\"}\ntags: ['ARXIV']\n---\nThe problem of landmark recognition has achieved excellent results in small-scale datasets. When dealing with large-scale retrieval, issues that were irrelevant with small amount of data, quickly become fundamental for an efficient retrieval phase. In particular, computational time needs to be kept as low as possible, whilst the retrieval accuracy has to be preserved as much as possible. In this paper we propose a novel multi-index hashing method called Bag of Indexes (BoI) for Approximate Nearest Neighbors (ANN) search. It allows to drastically reduce the query time and outperforms the accuracy results compared to the state-of-the-art methods for large-scale landmark recognition. It has been demonstrated that this family of algorithms can be applied on different embedding techniques like VLAD and R-MAC obtaining excellent results in very short times on different public datasets: Holidays+Flickr1M, Oxford105k and Paris106k.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [2.301591396331787, -15.576377868652344]}, {"key": "", "year": "", "title": "Maheshwari2021scene", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Scene Graph Embeddings Using Relative Similarity Supervision\"\nauthors: Maheshwari Paridhi, Chaudhry Ritwick, Vinay Vishwa\nconference: Arxiv\nyear: 2021\nbibkey: maheshwari2021scene\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2104.02381\"}\ntags: ['ARXIV', 'Graph', 'Image Retrieval', 'TIP']\n---\nScene graphs are a powerful structured representation of the underlying content of images, and embeddings derived from them have been shown to be useful in multiple downstream tasks. In this work, we employ a graph convolutional network to exploit structure in scene graphs and produce image embeddings useful for semantic image retrieval. Different from classification-centric supervision traditionally available for learning image representations, we address the task of learning from relative similarity labels in a ranking context. Rooted within the contrastive learning paradigm, we propose a novel loss function that operates on pairs of similar and dissimilar images and imposes relative ordering between them in embedding space. We demonstrate that this Ranking loss, coupled with an intuitive triple sampling strategy, leads to robust representations that outperform well-known contrastive losses on the retrieval task. In addition, we provide qualitative evidence of how retrieved results that utilize structured scene information capture the global context of the scene, different from visual similarity search.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.71717357635498, -28.707542419433594]}, {"key": "", "year": "", "title": "Maier2016concurrent", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Concurrent Hash Tables: Fast and General(!)\"\nauthors: Maier Tobias, Sanders Peter, Dementiev Roman\nconference: Arxiv\nyear: 2016\nbibkey: maier2016concurrent\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1601.04017\"}\ntags: ['ARXIV']\n---\nConcurrent hash tables are one of the most important concurrent data structures with numerous applications. Since hash table accesses can dominate the execution time of the overall application, we need implementations that achieve good speedup. Unfortunately, currently available concurrent hashing libraries turn out to be far away from this requirement in particular when contention on some elements occurs. Our starting point for better performing data structures is a fast and simple lock-free concurrent hash table based on linear probing that is limited to word-sized key-value types and does not support dynamic size adaptation. We explain how to lift these limitations in a provably scalable way and demonstrate that dynamic growing has a performance overhead comparable to the same generalization in sequential hash tables. We perform extensive experiments comparing the performance of our implementations with six of the most widely used concurrent hash tables. Ours are considerably faster than the best algorithms with similar restrictions and an order of magnitude faster than the best more general tables. In some extreme cases, the difference even approaches four orders of magnitude.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-23.28459930419922, -12.046504974365234]}, {"key": "", "year": "", "title": "Maier2017dynamic", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Dynamic Space Efficient Hashing\"\nauthors: Maier Tobias, Sanders Peter\nconference: Arxiv\nyear: 2017\nbibkey: maier2017dynamic\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1705.00997\"}\ntags: ['ARXIV']\n---\nWe consider space efficient hash tables that can grow and shrink dynamically and are always highly space efficient, i.e., their space consumption is always close to the lower bound even while growing and when taking into account storage that is only needed temporarily. None of the traditionally used hash tables have this property. We show how known approaches like linear probing and bucket cuckoo hashing can be adapted to this scenario by subdividing them into many subtables or using virtual memory overcommitting. However, these rather straightforward solutions suffer from slow amortized insertion times due to frequent reallocation in small increments. Our main result is DySECT ({\\bf Dy}namic {\\bf S}pace {\\bf E}fficient {\\bf C}uckoo {\\bf T}able) which avoids these problems. DySECT consists of many subtables which grow by doubling their size. The resulting inhomogeneity in subtable sizes is equalized by the flexibility available in bucket cuckoo hashing where each element can go to several buckets each of which containing several cells. Experiments indicate that DySECT works well with load factors up to 98\\%. With up to 2.7 times better performance than the next best solution.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-19.426435470581055, -13.397890090942383]}, {"key": "", "year": "", "title": "Maitinshepard2016elliptic", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Elliptic Curve Multiset Hash\"\nauthors: Maitin-Shepard Jeremy, Tibouchi Mehdi, Aranha Diego\nconference: Arxiv\nyear: 2016\nbibkey: maitinshepard2016elliptic\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1601.06502\"}\ntags: ['ARXIV']\n---\nA homomorphic, or incremental, multiset hash function, associates a hash value to arbitrary collections of objects (with possible repetitions) in such a way that the hash of the union of two collections is easy to compute from the hashes of the two collections themselves: it is simply their sum under a suitable group operation. In particular, hash values of large collections can be computed incrementally and/or in parallel. Homomorphic hashing is thus a very useful primitive with applications ranging from database integrity verification to streaming set/multiset comparison and network coding. Unfortunately, constructions of homomorphic hash functions in the literature are hampered by two main drawbacks: they tend to be much longer than usual hash functions at the same security level (e.g. to achieve a collision resistance of 2^128, they are several thousand bits long, as opposed to 256 bits for usual hash functions), and they are also quite slow. In this paper, we introduce the Elliptic Curve Multiset Hash (ECMH), which combines a usual bit string-valued hash function like BLAKE2 with an efficient encoding into binary elliptic curves to overcome both difficulties. On the one hand, the size of ECMH digests is essentially optimal: 2m-bit hash values provide O(2^m) collision resistance. On the other hand, we demonstrate a highly-efficient software implementation of ECMH, which our thorough empirical evaluation shows to be capable of processing over 3 million set elements per second on a 4 GHz Intel Haswell machine at the 128-bit security level---many times faster than previous practical methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-20.077449798583984, -15.735467910766602]}, {"key": "", "year": "", "title": "Maity2023image", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Image Hash Minimization for Tamper Detection\"\nauthors: Maity Subhajit, Karsh Ram Kumar\nconference: \nyear: 2023\nbibkey: maity2023image\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2305.17748\"}\ntags: []\n---\nTamper detection using image hash is a very common problem of modern days. Several research and advancements have already been done to address this problem. However, most of the existing methods lack the accuracy of tamper detection when the tampered area is low, as well as requiring long image hashes. In this paper, we propose a novel method objectively to minimize the hash length while enhancing the performance at low tampered area.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-3.398155689239502, 22.628639221191406]}, {"key": "", "year": "", "title": "Maji2020cbir", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"CBIR using features derived by Deep Learning\"\nauthors: Maji Subhadip, Bose Smarajit\nconference: Arxiv\nyear: 2020\nbibkey: maji2020cbir\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2002.07877\"}\ntags: ['ARXIV', 'Deep Learning', 'Image Retrieval']\n---\nIn a Content Based Image Retrieval (CBIR) System, the task is to retrieve similar images from a large database given a query image. The usual procedure is to extract some useful features from the query image, and retrieve images which have similar set of features. For this purpose, a suitable similarity measure is chosen, and images with high similarity scores are retrieved. Naturally the choice of these features play a very important role in the success of this system, and high level features are required to reduce the semantic gap. In this paper, we propose to use features derived from pre-trained network models from a deep-learning convolution network trained for a large image classification problem. This approach appears to produce vastly superior results for a variety of databases, and it outperforms many contemporary CBIR systems. We analyse the retrieval time of the method, and also propose a pre-clustering of the database based on the above-mentioned features which yields comparable results in a much shorter time in most of the cases.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [19.108251571655273, 9.926910400390625]}, {"key": "", "year": "", "title": "Malali2022learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning to embed semantic similarity for joint image-text retrieval\"\nauthors: Malali Noam, Keller Yosi\nconference: Arxiv\nyear: 2022\nbibkey: malali2022learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2210.03838\"}\ntags: ['ARXIV', 'Deep Learning', 'Quantisation', 'Text Retrieval']\n---\nWe present a deep learning approach for learning the joint semantic embeddings of images and captions in a Euclidean space, such that the semantic similarity is approximated by the L2 distances in the embedding space. For that, we introduce a metric learning scheme that utilizes multitask learning to learn the embedding of identical semantic concepts using a center loss. By introducing a differentiable quantization scheme into the end-to-end trainable network, we derive a semantic embedding of semantically similar concepts in Euclidean space. We also propose a novel metric learning formulation using an adaptive margin hinge loss, that is refined during the training phase. The proposed scheme was applied to the MS-COCO, Flicke30K and Flickr8K datasets, and was shown to compare favorably with contemporary state-of-the-art approaches.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [17.092025756835938, 7.920055866241455]}, {"key": "", "year": "", "title": "Manandhar2019semantic", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Semantic Granularity Metric Learning for Visual Search\"\nauthors: Manandhar Dipu, Bastan Muhammet, Yap Kim-Hui\nconference: Arxiv\nyear: 2019\nbibkey: manandhar2019semantic\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1911.06047\"}\ntags: ['ARXIV', 'CNN', 'GAN', 'TIP']\n---\nDeep metric learning applied to various applications has shown promising results in identification, retrieval and recognition. Existing methods often do not consider different granularity in visual similarity. However, in many domain applications, images exhibit similarity at multiple granularities with visual semantic concepts, e.g. fashion demonstrates similarity ranging from clothing of the exact same instance to similar looks/design or a common category. Therefore, training image triplets/pairs used for metric learning inherently possess different degree of information. However, the existing methods often treats them with equal importance during training. This hinders capturing the underlying granularities in feature similarity required for effective visual search. In view of this, we propose a new deep semantic granularity metric learning (SGML) that develops a novel idea of leveraging attribute semantic space to capture different granularity of similarity, and then integrate this information into deep metric learning. The proposed method simultaneously learns image attributes and embeddings using multitask CNNs. The two tasks are not only jointly optimized but are further linked by the semantic granularity similarity mappings to leverage the correlations between the tasks. To this end, we propose a new soft-binomial deviance loss that effectively integrates the degree of information in training samples, which helps to capture visual similarity at multiple granularities. Compared to recent ensemble-based methods, our framework is conceptually elegant, computationally simple and provides better performance. We perform extensive experiments on benchmark metric learning datasets and demonstrate that our method outperforms recent state-of-the-art methods, e.g., 1-4.5\\% improvement in Recall@1 over the previous state-of-the-arts [1],[2] on DeepFashion In-Shop dataset.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [13.099209785461426, 8.14869213104248]}, {"key": "", "year": "", "title": "Mandal2020a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Novel Incremental Cross-Modal Hashing Approach\"\nauthors: Mandal Devraj, Biswas Soma\nconference: Arxiv\nyear: 2020\nbibkey: mandal2020a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2002.00677\"}\ntags: ['ARXIV', 'Cross Modal']\n---\nCross-modal retrieval deals with retrieving relevant items from one modality, when provided with a search query from another modality. Hashing techniques, where the data is represented as binary bits have specifically gained importance due to the ease of storage, fast computations and high accuracy. In real world, the number of data categories is continuously increasing, which requires algorithms capable of handling this dynamic scenario. In this work, we propose a novel incremental cross-modal hashing algorithm termed \"iCMH\", which can adapt itself to handle incoming data of new categories. The proposed approach consists of two sequential stages, namely, learning the hash codes and training the hash functions. At every stage, a small amount of old category data termed \"exemplars\" is is used so as not to forget the old data while trying to learn for the new incoming data, i.e. to avoid catastrophic forgetting. In the first stage, the hash codes for the exemplars is used, and simultaneously, hash codes for the new data is computed such that it maintains the semantic relations with the existing data. For the second stage, we propose both a non-deep and deep architectures to learn the hash functions effectively. Extensive experiments across a variety of cross-modal datasets and comparisons with state-of-the-art cross-modal algorithms shows the usefulness of our approach.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-16.79364013671875, -1.2409296035766602]}, {"key": "", "year": "", "title": "Manek2017pruning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Pruning Convolutional Neural Networks for Image Instance Retrieval\"\nauthors: Manek Gaurav, Lin Jie, Chandrasekhar Vijay, Duan Lingyu, Giduthuri Sateesh, Li Xiaoli, Poggio Tomaso\nconference: Arxiv\nyear: 2017\nbibkey: manek2017pruning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1707.05455\"}\ntags: ['ARXIV', 'CNN']\n---\nIn this work, we focus on the problem of image instance retrieval with deep descriptors extracted from pruned Convolutional Neural Networks (CNN). The objective is to heavily prune convolutional edges while maintaining retrieval performance. To this end, we introduce both data-independent and data-dependent heuristics to prune convolutional edges, and evaluate their performance across various compression rates with different deep descriptors over several benchmark datasets. Further, we present an end-to-end framework to fine-tune the pruned network, with a triplet loss function specially designed for the retrieval task. We show that the combination of heuristic pruning and fine-tuning offers 5x compression rate without considerable loss in retrieval performance.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [13.912874221801758, 25.999736785888672]}, {"key": "", "year": "", "title": "Marchet2017a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A resource-frugal probabilistic dictionary and applications in bioinformatics\"\nauthors: Marchet Camille, Lecompte Lolita, Limasset Antoine, Bittner Lucie, Peterlongo Pierre\nconference: Arxiv\nyear: 2017\nbibkey: marchet2017a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1703.00667\"}\ntags: ['ARXIV']\n---\nIndexing massive data sets is extremely expensive for large scale problems. In many fields, huge amounts of data are currently generated, however extracting meaningful information from voluminous data sets, such as computing similarity between elements, is far from being trivial. It remains nonetheless a fundamental need. This work proposes a probabilistic data structure based on a minimal perfect hash function for indexing large sets of keys. Our structure out-compete the hash table for construction, query times and for memory usage, in the case of the indexation of a static set. To illustrate the impact of algorithms performances, we provide two applications based on similarity computation between collections of sequences, and for which this calculation is an expensive but required operation. In particular, we show a practical case in which other bioinformatics tools fail to scale up the tested data set or provide lower recall quality results.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-8.636760711669922, -12.235568046569824]}, {"key": "", "year": "", "title": "Markchit2019effective", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Effective and Efficient Indexing in Cross-Modal Hashing-Based Datasets\"\nauthors: Markchit Sarawut, Chiu Chih-Yi\nconference: Arxiv\nyear: 2019\nbibkey: markchit2019effective\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1904.13325\"}\ntags: ['ARXIV', 'Cross Modal']\n---\nTo overcome the barrier of storage and computation, the hashing technique has been widely used for nearest neighbor search in multimedia retrieval applications recently. Particularly, cross-modal retrieval that searches across different modalities becomes an active but challenging problem. Although dozens of cross-modal hashing algorithms are proposed to yield compact binary codes, the exhaustive search is impractical for the real-time purpose, and Hamming distance computation suffers inaccurate results. In this paper, we propose a novel search method that utilizes a probability-based index scheme over binary hash codes in cross-modal retrieval. The proposed hash code indexing scheme exploits a few binary bits of the hash code as the index code. We construct an inverted index table based on index codes and train a neural network to improve the indexing accuracy and efficiency. Experiments are performed on two benchmark datasets for retrieval across image and text modalities, where hash codes are generated by three cross-modal hashing methods. Results show the proposed method effectively boost the performance on these hash methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-3.2329976558685303, -4.6666460037231445]}, {"key": "", "year": "", "title": "Masci2011descriptor", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Descriptor learning for omnidirectional image matching\"\nauthors: Masci Jonathan, Migliore Davide, Bronstein Michael M., Schmidhuber J\u00fcrgen\nconference: Arxiv\nyear: 2011\nbibkey: masci2011descriptor\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1112.6291\"}\ntags: ['ARXIV']\n---\nFeature matching in omnidirectional vision systems is a challenging problem, mainly because complicated optical systems make the theoretical modelling of invariance and construction of invariant feature descriptors hard or even impossible. In this paper, we propose learning invariant descriptors using a training set of similar and dissimilar descriptor pairs. We use the similarity-preserving hashing framework, in which we are trying to map the descriptor data to the Hamming space preserving the descriptor similarity on the training set. A neural network is used to solve the underlying optimization problem. Our approach outperforms not only straightforward descriptor matching, but also state-of-the-art similarity-preserving hashing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-3.3065743446350098, 18.71622085571289]}, {"key": "", "year": "", "title": "Masci2012multimodal", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Multimodal similarity-preserving hashing\"\nauthors: Masci Jonathan, Bronstein Michael M., Bronstein Alexander A., Schmidhuber J\u00fcrgen\nconference: Arxiv\nyear: 2012\nbibkey: masci2012multimodal\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1207.1522\"}\ntags: ['ARXIV', 'Cross Modal', 'TIP']\n---\nWe introduce an efficient computational framework for hashing data belonging to multiple modalities into a single representation space where they become mutually comparable. The proposed approach is based on a novel coupled siamese neural network architecture and allows unified treatment of intra- and inter-modality similarity learning. Unlike existing cross-modality similarity learning approaches, our hashing functions are not limited to binarized linear projections and can assume arbitrarily complex forms. We show experimentally that our method significantly outperforms state-of-the-art hashing approaches on multimedia retrieval tasks.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-30.078323364257812, 1.7603510618209839]}, {"key": "", "year": "", "title": "Masci2013sparse", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Sparse similarity-preserving hashing\"\nauthors: Masci Jonathan, Bronstein Alex M., Bronstein Michael M., Sprechmann Pablo, Sapiro Guillermo\nconference: Arxiv\nyear: 2013\nbibkey: masci2013sparse\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1312.5479\"}\ntags: ['ARXIV']\n---\nIn recent years, a lot of attention has been devoted to efficient nearest neighbor search by means of similarity-preserving hashing. One of the plights of existing hashing techniques is the intrinsic trade-off between performance and computational complexity: while longer hash codes allow for lower false positive rates, it is very difficult to increase the embedding dimensionality without incurring in very high false negatives rates or prohibiting computational costs. In this paper, we propose a way to overcome this limitation by enforcing the hash codes to be sparse. Sparse high-dimensional codes enjoy from the low false positive rates typical of long hashes, while keeping the false negative rates similar to those of a shorter dense hashing scheme with equal number of degrees of freedom. We use a tailored feed-forward neural network for the hashing function. Extensive experimental evaluation involving visual and multi-modal data shows the benefits of the proposed method.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-4.165978908538818, -10.684618949890137]}, {"key": "", "year": "", "title": "Masson2024fliphash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"FlipHash: A Constant-Time Consistent Range-Hashing Algorithm\"\nauthors: Masson Charles, Lee Homin K.\nconference: Arxiv\nyear: 2024\nbibkey: masson2024fliphash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2402.17549\"}\ntags: ['ARXIV']\n---\nConsistent range-hashing is a technique used in distributed systems, either directly or as a subroutine for consistent hashing, commonly to realize an even and stable data distribution over a variable number of resources. We introduce FlipHash, a consistent range-hashing algorithm with constant time complexity and low memory requirements. Like Jump Consistent Hash, FlipHash is intended for applications where resources can be indexed sequentially. Under this condition, it ensures that keys are hashed evenly across resources and that changing the number of resources only causes keys to be remapped from a removed resource or to an added one, but never shuffled across persisted ones. FlipHash differentiates itself with its low computational cost, achieving constant-time complexity. We show that FlipHash beats Jump Consistent Hash's cost, which is logarithmic in the number of resources, both theoretically and in experiments over practical settings.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-27.393144607543945, -14.547099113464355]}, {"key": "", "year": "", "title": "Mastikhina2024an", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"An improvement of degree-based hashing (DBH) graph partition method, using a novel metric\"\nauthors: Mastikhina Anna, Senkevich Oleg, Sirotkin Dmitry, Demin Danila, Moiseev Stanislav\nconference: Arxiv\nyear: 2024\nbibkey: mastikhina2024an\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2404.07624\"}\ntags: ['ARXIV', 'Graph']\n---\nThis paper examines the graph partition problem and introduces a new metric, MSIDS (maximal sum of inner degrees squared). We establish its connection to the replication factor (RF) optimization, which has been the main focus of theoretical work in this field. Additionally, we propose a new partition algorithm, DBH-X, based on the DBH partitioner. We demonstrate that DBH-X significantly improves both the RF and MSIDS, compared to the baseline DBH algorithm. In addition, we provide test results that show the runtime acceleration of GraphX-based PageRank and Label propagation algorithms.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.036484718322754, -24.688663482666016]}, {"key": "", "year": "", "title": "Mathur2018multichannel", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Multichannel Distributed Local Pattern for Content Based Indexing and Retrieval\"\nauthors: Mathur Sonakshi, Chaudhary Mallika, Verma Hemant, Mandal Murari, Vipparthi S. K., Murala Subrahmanyam\nconference: Arxiv\nyear: 2018\nbibkey: mathur2018multichannel\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1805.02679\"}\ntags: ['ARXIV']\n---\nA novel color feature descriptor, Multichannel Distributed Local Pattern (MDLP) is proposed in this manuscript. The MDLP combines the salient features of both local binary and local mesh patterns in the neighborhood. The multi-distance information computed by the MDLP aids in robust extraction of the texture arrangement. Further, MDLP features are extracted for each color channel of an image. The retrieval performance of the MDLP is evaluated on the three benchmark datasets for CBIR, namely Corel-5000, Corel-10000 and MIT-Color Vistex respectively. The proposed technique attains substantial improvement as compared to other state-of- the-art feature descriptors in terms of various evaluation parameters such as ARP and ARR on the respective databases.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [24.820749282836914, 5.928998947143555]}, {"key": "", "year": "", "title": "Matsui2015sketch", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Sketch-based Manga Retrieval using Manga109 Dataset\"\nauthors: Matsui Yusuke, Ito Kota, Aramaki Yuji, Yamasaki Toshihiko, Aizawa Kiyoharu\nconference: Multimedia Tools and Applications, Volume\nyear: 2015\nbibkey: matsui2015sketch\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1510.04389\"}\ntags: ['Quantisation', 'Volume']\n---\nManga (Japanese comics) are popular worldwide. However, current e-manga archives offer very limited search support, including keyword-based search by title or author, or tag-based categorization. To make the manga search experience more intuitive, efficient, and enjoyable, we propose a content-based manga retrieval system. First, we propose a manga-specific image-describing framework. It consists of efficient margin labeling, edge orientation histogram feature description, and approximate nearest-neighbor search using product quantization. Second, we propose a sketch-based interface as a natural way to interact with manga content. The interface provides sketch-based querying, relevance feedback, and query retouch. For evaluation, we built a novel dataset of manga images, Manga109, which consists of 109 comic books of 21,142 pages drawn by professional manga artists. To the best of our knowledge, Manga109 is currently the biggest dataset of manga images available for research. We conducted a comparative study, a localization evaluation, and a large-scale qualitative study. From the experiments, we verified that: (1) the retrieval accuracy of the proposed method is higher than those of previous methods; (2) the proposed method can localize an object instance with reasonable runtime and accuracy; and (3) sketch querying is useful for manga search.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [25.7226505279541, -2.880927801132202]}, {"key": "", "year": "", "title": "Matsui2017pqtable", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"PQTable: Non-exhaustive Fast Search for Product-quantized Codes using Hash Tables\"\nauthors: Matsui Yusuke, Yamasaki Toshihiko, Aizawa Kiyoharu\nconference: Arxiv\nyear: 2017\nbibkey: matsui2017pqtable\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1704.06556\"}\ntags: ['ARXIV', 'Quantisation']\n---\nIn this paper, we propose a product quantization table (PQTable); a fast search method for product-quantized codes via hash-tables. An identifier of each database vector is associated with the slot of a hash table by using its PQ-code as a key. For querying, an input vector is PQ-encoded and hashed, and the items associated with that code are then retrieved. The proposed PQTable produces the same results as a linear PQ scan, and is 10^2 to 10^5 times faster. Although state-of-the-art performance can be achieved by previous inverted-indexing-based approaches, such methods require manually-designed parameter setting and significant training; our PQTable is free of these limitations, and therefore offers a practical and effective solution for real-world problems. Specifically, when the vectors are highly compressed, our PQTable achieves one of the fastest search performances on a single CPU to date with significantly efficient memory usage (0.059 ms per query over 10^9 data points with just 5.5 GB memory consumption). Finally, we show that our proposed PQTable can naturally handle the codes of an optimized product quantization (OPQTable).\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-25.339282989501953, -18.74702262878418]}, {"key": "", "year": "", "title": "Mazonka2014hasq", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hasq Hash Chains\"\nauthors: Mazonka Oleg, Popov Vlad\nconference: Arxiv\nyear: 2014\nbibkey: mazonka2014hasq\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1412.4316\"}\ntags: ['ARXIV']\n---\nThis paper describes a particular hash-based records linking chain scheme. This scheme is simple conceptually and easy to implement in software. It allows for a simple and secure way to transfer ownership of digital objects between peers.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-29.596242904663086, -14.290509223937988]}, {"key": "", "year": "", "title": "Mcauley2012image", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Image Labeling on a Network: Using Social-Network Metadata for Image Classification\"\nauthors: McAuley Julian, Leskovec Jure\nconference: Arxiv\nyear: 2012\nbibkey: mcauley2012image\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1207.3809\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nLarge-scale image retrieval benchmarks invariably consist of images from the Web. Many of these benchmarks are derived from online photo sharing networks, like Flickr, which in addition to hosting images also provide a highly interactive social community. Such communities generate rich metadata that can naturally be harnessed for image classification and retrieval. Here we study four popular benchmark datasets, extending them with social-network metadata, such as the groups to which each image belongs, the comment thread associated with the image, who uploaded it, their location, and their network of friends. Since these types of data are inherently relational, we propose a model that explicitly accounts for the interdependencies between images sharing common properties. We model the task as a binary labeling problem on a network, and use structured learning techniques to learn model parameters. We find that social-network metadata are useful in a variety of classification tasks, in many cases outperforming methods based on image content.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [17.73665428161621, -25.697538375854492]}, {"key": "", "year": "", "title": "Mccauley2018adaptive", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Adaptive MapReduce Similarity Joins\"\nauthors: McCauley Samuel, Silvestri Francesco\nconference: Arxiv\nyear: 2018\nbibkey: mccauley2018adaptive\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1804.05615\"}\ntags: ['ARXIV', 'LSH']\n---\nSimilarity joins are a fundamental database operation. Given data sets S and R, the goal of a similarity join is to find all points x in S and y in R with distance at most r. Recent research has investigated how locality-sensitive hashing (LSH) can be used for similarity join, and in particular two recent lines of work have made exciting progress on LSH-based join performance. Hu, Tao, and Yi (PODS 17) investigated joins in a massively parallel setting, showing strong results that adapt to the size of the output. Meanwhile, Ahle, Aum\\\"uller, and Pagh (SODA 17) showed a sequential algorithm that adapts to the structure of the data, matching classic bounds in the worst case but improving them significantly on more structured data. We show that this adaptive strategy can be adapted to the parallel setting, combining the advantages of these approaches. In particular, we show that a simple modification to Hu et al.'s algorithm achieves bounds that depend on the density of points in the dataset as well as the total outsize of the output. Our algorithm uses no extra parameters over other LSH approaches (in particular, its execution does not depend on the structure of the dataset), and is likely to be efficient in practice.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [0.926030695438385, -22.106704711914062]}, {"key": "", "year": "", "title": "Mccauley2019approximate", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Approximate Similarity Search Under Edit Distance Using Locality-Sensitive Hashing\"\nauthors: McCauley Samuel\nconference: Arxiv\nyear: 2019\nbibkey: mccauley2019approximate\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1907.01600\"}\ntags: ['ARXIV']\n---\nEdit distance similarity search, also called approximate pattern matching, is a fundamental problem with widespread database applications. The goal of the problem is to preprocess $n$ strings of length $d$, to quickly answer queries $q$ of the form: if there is a database string within edit distance $r$ of $q$, return a database string within edit distance $cr$ of $q$. Previous approaches to this problem either rely on very large (superconstant) approximation ratios $c$, or very small search radii $r$. Outside of a narrow parameter range, these solutions are not competitive with trivially searching through all $n$ strings. In this work give a simple and easy-to-implement hash function that can quickly answer queries for a wide range of parameters. Specifically, our strategy can answer queries in time $\\tilde\\{O\\}(d3^rn^\\{1/c\\})$. The best known practical results require $c \\gg r$ to achieve any correctness guarantee; meanwhile, the best known theoretical results are very involved and difficult to implement, and require query time at least $24^r$. Our results significantly broaden the range of parameters for which we can achieve nontrivial bounds, while retaining the practicality of a locality-sensitive hash function. We also show how to apply our ideas to the closely-related Approximate Nearest Neighbor problem for edit distance, obtaining similar time bounds.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-5.457817554473877, -21.506650924682617]}, {"key": "", "year": "", "title": "Mckeown2022hamming", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hamming Distributions of Popular Perceptual Hashing Techniques\"\nauthors: McKeown Sean, Buchanan William J\nconference: DFRWS\nyear: 2022\nbibkey: mckeown2022hamming\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2212.08035\"}\ntags: ['TOM']\n---\nContent-based file matching has been widely deployed for decades, largely for the detection of sources of copyright infringement, extremist materials, and abusive sexual media. Perceptual hashes, such as Microsoft's PhotoDNA, are one automated mechanism for facilitating detection, allowing for machines to approximately match visual features of an image or video in a robust manner. However, there does not appear to be much public evaluation of such approaches, particularly when it comes to how effective they are against content-preserving modifications to media files. In this paper, we present a million-image scale evaluation of several perceptual hashing archetypes for popular algorithms (including Facebook's PDQ, Apple's Neuralhash, and the popular pHash library) against seven image variants. The focal point is the distribution of Hamming distance scores between both unrelated images and image variants to better understand the problems faced by each approach.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-4.322353363037109, 21.4300537109375]}, {"key": "", "year": "", "title": "Meel2017on", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"On Hashing-Based Approaches to Approximate DNF-Counting\"\nauthors: Meel Kuldeep S., Shrotri Aditya A., Vardi Moshe Y.\nconference: Arxiv\nyear: 2017\nbibkey: meel2017on\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1710.05247\"}\ntags: ['ARXIV']\n---\nPropositional model counting is a fundamental problem in artificial intelligence with a wide variety of applications, such as probabilistic inference, decision making under uncertainty, and probabilistic databases. Consequently, the problem is of theoretical as well as practical interest. When the constraints are expressed as DNF formulas, Monte Carlo-based techniques have been shown to provide a fully polynomial randomized approximation scheme (FPRAS). For CNF constraints, hashing-based approximation techniques have been demonstrated to be highly successful. Furthermore, it was shown that hashing-based techniques also yield an FPRAS for DNF counting without usage of Monte Carlo sampling. Our analysis, however, shows that the proposed hashing-based approach to DNF counting provides poor time complexity compared to the Monte Carlo-based DNF counting techniques. Given the success of hashing-based techniques for CNF constraints, it is natural to ask: Can hashing-based techniques provide an efficient FPRAS for DNF counting? In this paper, we provide a positive answer to this question. To this end, we introduce two novel algorithmic techniques: \\emph{Symbolic Hashing} and \\emph{Stochastic Cell Counting}, along with a new hash family of \\emph{Row-Echelon hash functions}. These innovations allow us to design a hashing-based FPRAS for DNF counting of similar complexity (up to polylog factors) as that of prior works. Furthermore, we expect these techniques to have potential applications beyond DNF counting.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-14.049525260925293, -13.612225532531738]}, {"key": "", "year": "", "title": "Meel2020sparse", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Sparse Hashing for Scalable Approximate Model Counting: Theory and Practice\"\nauthors: Meel Kuldeep S., Akshay S.\nconference: Arxiv\nyear: 2020\nbibkey: meel2020sparse\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2004.14692\"}\ntags: ['ACL', 'ARXIV']\n---\nGiven a CNF formula F on n variables, the problem of model counting or #SAT is to compute the number of satisfying assignments of F . Model counting is a fundamental but hard problem in computer science with varied applications. Recent years have witnessed a surge of effort towards developing efficient algorithmic techniques that combine the classical 2-universal hashing with the remarkable progress in SAT solving over the past decade. These techniques augment the CNF formula F with random XOR constraints and invoke an NP oracle repeatedly on the resultant CNF-XOR formulas. In practice, calls to the NP oracle calls are replaced a SAT solver whose runtime performance is adversely affected by size of XOR constraints. The standard construction of 2-universal hash functions chooses every variable with probability p = 1/2 leading to XOR constraints of size n/2 in expectation. Consequently, the challenge is to design sparse hash functions where variables can be chosen with smaller probability and lead to smaller sized XOR constraints. In this paper, we address this challenge from theoretical and practical perspectives. First, we formalize a relaxation of universal hashing, called concentrated hashing and establish a novel and beautiful connection between concentration measures of these hash functions and isoperimetric inequalities on boolean hypercubes. This allows us to obtain (log m) tight bounds on variance and dispersion index and show that p = O( log(m)/m ) suffices for design of sparse hash functions from {0, 1}^n to {0, 1}^m. We then use sparse hash functions belonging to this concentrated hash family to develop new approximate counting algorithms. A comprehensive experimental evaluation of our algorithm on 1893 benchmarks demonstrates that usage of sparse hash functions can lead to significant speedups.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-14.278545379638672, -15.158885955810547]}, {"key": "", "year": "", "title": "Meisburger2020distributed", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Distributed Tera-Scale Similarity Search with MPI: Provably Efficient Similarity Search over billions without a Single Distance Computation\"\nauthors: Meisburger Nicholas, Shrivastava Anshumali\nconference: Arxiv\nyear: 2020\nbibkey: meisburger2020distributed\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2008.03260\"}\ntags: ['ARXIV', 'LSH']\n---\nWe present SLASH (Sketched LocAlity Sensitive Hashing), an MPI (Message Passing Interface) based distributed system for approximate similarity search over terabyte scale datasets. SLASH provides a multi-node implementation of the popular LSH (locality sensitive hashing) algorithm, which is generally implemented on a single machine. We show how we can append the LSH algorithm with heavy hitters sketches to provably solve the (high) similarity search problem without a single distance computation. Overall, we mathematically show that, under realistic data assumptions, we can identify the near-neighbor of a given query $q$ in sub-linear ($ \\ll O(n)$) number of simple sketch aggregation operations only. To make such a system practical, we offer a novel design and sketching solution to reduce the inter-machine communication overheads exponentially. In a direct comparison on comparable hardware, SLASH is more than 10000x faster than the popular LSH package in PySpark. PySpark is a widely-adopted distributed implementation of the LSH algorithm for large datasets and is deployed in commercial platforms. In the end, we show how our system scale to Tera-scale Criteo dataset with more than 4 billion samples. SLASH can index this 2.3 terabyte data over 20 nodes in under an hour, with query times in a fraction of milliseconds. To the best of our knowledge, there is no open-source system that can index and perform a similarity search on Criteo with a commodity cluster.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-4.326098442077637, -19.22256088256836]}, {"key": "", "year": "", "title": "Mendelson2018anchorhash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"AnchorHash: A Scalable Consistent Hash\"\nauthors: Mendelson Gal, Vargaftik Shay, Barabash Katherine, Lorenz Dean, Keslassy Isaac, Orda Ariel\nconference: Arxiv\nyear: 2018\nbibkey: mendelson2018anchorhash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1812.09674\"}\ntags: ['ARXIV']\n---\nConsistent hashing (CH) is a central building block in many networking applications, from datacenter load-balancing to distributed storage. Unfortunately, state-of-the-art CH solutions cannot ensure full consistency under arbitrary changes and/or cannot scale while maintaining reasonable memory footprints and update times. We present AnchorHash, a scalable and fully-consistent hashing algorithm. AnchorHash achieves high key lookup rates, a low memory footprint, and low update times. We formally establish its strong theoretical guarantees, and present advanced implementations with a memory footprint of only a few bytes per resource. Moreover, extensive evaluations indicate that it outperforms state-of-the-art algorithms, and that it can scale on a single core to 100 million resources while still achieving a key lookup rate of more than 15 million keys per second.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-27.30718231201172, -12.46096134185791]}, {"key": "", "year": "", "title": "Miao2024scenegraphloc", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"SceneGraphLoc: Cross-Modal Coarse Visual Localization on 3D Scene Graphs\"\nauthors: Miao Yang, Engelmann Francis, Vysotska Olga, Tombari Federico, Pollefeys Marc, Bar\u00e1th D\u00e1niel B\u00e9la\nconference: Arxiv\nyear: 2024\nbibkey: miao2024scenegraphloc\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2404.00469\"}\ntags: ['ARXIV', 'Cross Modal', 'Graph', 'TIP']\n---\nWe introduce a novel problem, i.e., the localization of an input image within a multi-modal reference map represented by a database of 3D scene graphs. These graphs comprise multiple modalities, including object-level point clouds, images, attributes, and relationships between objects, offering a lightweight and efficient alternative to conventional methods that rely on extensive image databases. Given the available modalities, the proposed method SceneGraphLoc learns a fixed-sized embedding for each node (i.e., representing an object instance) in the scene graph, enabling effective matching with the objects visible in the input query image. This strategy significantly outperforms other cross-modal methods, even without incorporating images into the map embeddings. When images are leveraged, SceneGraphLoc achieves performance close to that of state-of-the-art techniques depending on large image databases, while requiring three orders-of-magnitude less storage and operating orders-of-magnitude faster. The code will be made public.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.749170303344727, -29.365459442138672]}, {"key": "", "year": "", "title": "Miech2021thinking", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Thinking Fast and Slow: Efficient Text-to-Visual Retrieval with Transformers\"\nauthors: Miech Antoine, Alayrac Jean-Baptiste, Laptev Ivan, Sivic Josef, Zisserman Andrew\nconference: Arxiv\nyear: 2021\nbibkey: miech2021thinking\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2103.16553\"}\ntags: ['ARXIV']\n---\nOur objective is language-based search of large-scale image and video datasets. For this task, the approach that consists of independently mapping text and vision to a joint embedding space, a.k.a. dual encoders, is attractive as retrieval scales and is efficient for billions of images using approximate nearest neighbour search. An alternative approach of using vision-text transformers with cross-attention gives considerable improvements in accuracy over the joint embeddings, but is often inapplicable in practice for large-scale retrieval given the cost of the cross-attention mechanisms required for each sample at test time. This work combines the best of both worlds. We make the following three contributions. First, we equip transformer-based models with a new fine-grained cross-attention architecture, providing significant improvements in retrieval accuracy whilst preserving scalability. Second, we introduce a generic approach for combining a Fast dual encoder model with our Slow but accurate transformer-based model via distillation and re-ranking. Finally, we validate our approach on the Flickr30K image dataset where we show an increase in inference speed by several orders of magnitude while having results competitive to the state of the art. We also extend our method to the video domain, improving the state of the art on the VATEX dataset.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [1.478471040725708, 27.424724578857422]}, {"key": "", "year": "", "title": "Mikriukov2022an", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"An Unsupervised Cross-Modal Hashing Method Robust to Noisy Training Image-Text Correspondences in Remote Sensing\"\nauthors: Mikriukov Georgii, Ravanbakhsh Mahdyar, Demir Beg\u00fcm\nconference: Arxiv\nyear: 2022\nbibkey: mikriukov2022an\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2202.13117\"}   - {name: \"Paper\", url: \"https://git.tu-berlin.de/rsim/chnr\"}\ntags: ['ARXIV', 'Cross Modal', 'Supervised', 'Text Retrieval', 'Unsupervised']\n---\nThe development of accurate and scalable cross-modal image-text retrieval methods, where queries from one modality (e.g., text) can be matched to archive entries from another (e.g., remote sensing image) has attracted great attention in remote sensing (RS). Most of the existing methods assume that a reliable multi-modal training set with accurately matched text-image pairs is existing. However, this assumption may not always hold since the multi-modal training sets may include noisy pairs (i.e., textual descriptions/captions associated to training images can be noisy), distorting the learning process of the retrieval methods. To address this problem, we propose a novel unsupervised cross-modal hashing method robust to the noisy image-text correspondences (CHNR). CHNR consists of three modules: 1) feature extraction module, which extracts feature representations of image-text pairs; 2) noise detection module, which detects potential noisy correspondences; and 3) hashing module that generates cross-modal binary hash codes. The proposed CHNR includes two training phases: i) meta-learning phase that uses a small portion of clean (i.e., reliable) data to train the noise detection module in an adversarial fashion; and ii) the main training phase for which the trained noise detection module is used to identify noisy correspondences while the hashing module is trained on the noisy multi-modal training set. Experimental results show that the proposed CHNR outperforms state-of-the-art methods. Our code is publicly available at https://git.tu-berlin.de/rsim/chnr\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-8.256568908691406, 26.558856964111328]}, {"key": "", "year": "", "title": "Mikriukov2022deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Unsupervised Contrastive Hashing for Large-Scale Cross-Modal Text-Image Retrieval in Remote Sensing\"\nauthors: Mikriukov Georgii, Ravanbakhsh Mahdyar, Demir Beg\u00fcm\nconference: Arxiv\nyear: 2022\nbibkey: mikriukov2022deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2201.08125\"}   - {name: \"Paper\", url: \"https://git.tu-berlin.de/rsim/duch.\"}\ntags: ['ARXIV', 'Cross Modal', 'Image Retrieval', 'Supervised', 'Unsupervised']\n---\nDue to the availability of large-scale multi-modal data (e.g., satellite images acquired by different sensors, text sentences, etc) archives, the development of cross-modal retrieval systems that can search and retrieve semantically relevant data across different modalities based on a query in any modality has attracted great attention in RS. In this paper, we focus our attention on cross-modal text-image retrieval, where queries from one modality (e.g., text) can be matched to archive entries from another (e.g., image). Most of the existing cross-modal text-image retrieval systems require a high number of labeled training samples and also do not allow fast and memory-efficient retrieval due to their intrinsic characteristics. These issues limit the applicability of the existing cross-modal retrieval systems for large-scale applications in RS. To address this problem, in this paper we introduce a novel deep unsupervised cross-modal contrastive hashing (DUCH) method for RS text-image retrieval. The proposed DUCH is made up of two main modules: 1) feature extraction module (which extracts deep representations of the text-image modalities); and 2) hashing module (which learns to generate cross-modal binary hash codes from the extracted representations). Within the hashing module, we introduce a novel multi-objective loss function including: i) contrastive objectives that enable similarity preservation in both intra- and inter-modal similarities; ii) an adversarial objective that is enforced across two modalities for cross-modal representation consistency; iii) binarization objectives for generating representative hash codes. Experimental results show that the proposed DUCH outperforms state-of-the-art unsupervised cross-modal hashing methods on two multi-modal (image and text) benchmark archives in RS. Our code is publicly available at https://git.tu-berlin.de/rsim/duch.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-7.716073513031006, 26.31314468383789]}, {"key": "", "year": "", "title": "Mikriukov2022unsupervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Unsupervised Contrastive Hashing for Cross-Modal Retrieval in Remote Sensing\"\nauthors: Mikriukov Georgii, Ravanbakhsh Mahdyar, Demir Beg\u00fcm\nconference: Arxiv\nyear: 2022\nbibkey: mikriukov2022unsupervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2204.08707\"}   - {name: \"Paper\", url: \"https://git.tu-berlin.de/rsim/duch.\"}\ntags: ['ARXIV', 'Cross Modal', 'Image Retrieval', 'Supervised', 'Unsupervised']\n---\nThe development of cross-modal retrieval systems that can search and retrieve semantically relevant data across different modalities based on a query in any modality has attracted great attention in remote sensing (RS). In this paper, we focus our attention on cross-modal text-image retrieval, where queries from one modality (e.g., text) can be matched to archive entries from another (e.g., image). Most of the existing cross-modal text-image retrieval systems in RS require a high number of labeled training samples and also do not allow fast and memory-efficient retrieval. These issues limit the applicability of the existing cross-modal retrieval systems for large-scale applications in RS. To address this problem, in this paper we introduce a novel unsupervised cross-modal contrastive hashing (DUCH) method for text-image retrieval in RS. To this end, the proposed DUCH is made up of two main modules: 1) feature extraction module, which extracts deep representations of two modalities; 2) hashing module that learns to generate cross-modal binary hash codes from the extracted representations. We introduce a novel multi-objective loss function including: i) contrastive objectives that enable similarity preservation in intra- and inter-modal similarities; ii) an adversarial objective that is enforced across two modalities for cross-modal representation consistency; and iii) binarization objectives for generating hash codes. Experimental results show that the proposed DUCH outperforms state-of-the-art methods. Our code is publicly available at https://git.tu-berlin.de/rsim/duch.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-7.625970840454102, 26.258583068847656]}, {"key": "", "year": "", "title": "Ming2008the", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"The Improvement of the Bound on Hash Family\"\nauthors: Ming Xianmin, Yang Jiansheng\nconference: Arxiv\nyear: 2008\nbibkey: ming2008the\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/0806.1397\"}\ntags: ['ARXIV']\n---\nIn this paper, we study the bound on three kinds of hash family using the Singleton bound. To $\\epsilon-U(N; n, m)$ hash family, in the caes of $n&gt;m^2&gt;1$ and $1\\geq\\epsilon\\geq \\epsilon_1(n, m)$, we get that the new bound is better. To $\\epsilon-\\bigtriangleup U(N; n, m)$ hash family, in the case of $n&gt;m&gt;1$ and $1\\geq\\epsilon\\geq\\epsilon_3(n,m)$, the new bound is better. To $\\epsilon-SU(N; n, m)$ hash family, in the case of $n&gt;2^m&gt;2$ and $1\\geq\\epsilon\\geq \\epsilon_4(n, m)$, we get that the new bound is better.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-28.412195205688477, -2.698575735092163]}, {"key": "", "year": "", "title": "Miranda2022multi", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Multi hash embeddings in spaCy\"\nauthors: Miranda Lester James, K\u00e1d\u00e1r \u00c1kos, Boyd Adriane, Van Landeghem Sofie, S\u00f8gaard Anders, Honnibal Matthew\nconference: Arxiv\nyear: 2022\nbibkey: miranda2022multi\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2212.09255\"}\ntags: ['ARXIV']\n---\nThe distributed representation of symbols is one of the key technologies in machine learning systems today, playing a pivotal role in modern natural language processing. Traditional word embeddings associate a separate vector with each word. While this approach is simple and leads to good performance, it requires a lot of memory for representing a large vocabulary. To reduce the memory footprint, the default embedding layer in spaCy is a hash embeddings layer. It is a stochastic approximation of traditional embeddings that provides unique vectors for a large number of words without explicitly storing a separate vector for each of them. To be able to compute meaningful representations for both known and unknown words, hash embeddings represent each word as a summary of the normalized word form, subword information and word shape. Together, these features produce a multi-embedding of a word. In this technical report we lay out a bit of history and introduce the embedding methods in spaCy in detail. Second, we critically evaluate the hash embedding architecture with multi-embeddings on Named Entity Recognition datasets from a variety of domains and languages. The experiments validate most key design choices behind spaCy's embedders, but we also uncover a few surprising results.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-18.58328628540039, 8.418122291564941]}, {"key": "", "year": "", "title": "Mishchuk2017working", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Working hard to know your neighbor's margins: Local descriptor learning loss\"\nauthors: Mishchuk Anastasiya, Mishkin Dmytro, Radenovic Filip, Matas Jiri\nconference: Arxiv\nyear: 2017\nbibkey: mishchuk2017working\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1705.10872\"}\ntags: ['ARXIV', 'CNN']\n---\nWe introduce a novel loss for learning local feature descriptors which is inspired by the Lowe's matching criterion for SIFT. We show that the proposed loss that maximizes the distance between the closest positive and closest negative patch in the batch is better than complex regularization methods; it works well for both shallow and deep convolution network architectures. Applying the novel loss to the L2Net CNN architecture results in a compact descriptor -- it has the same dimensionality as SIFT (128) that shows state-of-art performance in wide baseline stereo, patch verification and instance retrieval benchmarks. It is fast, computing a descriptor takes about 1 millisecond on a low-end GPU.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [17.543691635131836, 21.978435516357422]}, {"key": "", "year": "", "title": "Misra2018bernoulli", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Bernoulli Embeddings for Graphs\"\nauthors: Misra Vinith, Bhatia Sumit\nconference: Arxiv\nyear: 2018\nbibkey: misra2018bernoulli\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1803.09211\"}\ntags: ['ARXIV', 'Graph', 'Quantisation']\n---\nJust as semantic hashing can accelerate information retrieval, binary valued embeddings can significantly reduce latency in the retrieval of graphical data. We introduce a simple but effective model for learning such binary vectors for nodes in a graph. By imagining the embeddings as independent coin flips of varying bias, continuous optimization techniques can be applied to the approximate expected loss. Embeddings optimized in this fashion consistently outperform the quantization of both spectral graph embeddings and various learned real-valued embeddings, on both ranking and pre-ranking tasks for a variety of datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [7.452022552490234, -30.177602767944336]}, {"key": "", "year": "", "title": "Misraa2020multi", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Multi-Modal Retrieval using Graph Neural Networks\"\nauthors: Misraa Aashish Kumar, Kale Ajinkya, Aggarwal Pranav, Aminian Ali\nconference: Arxiv\nyear: 2020\nbibkey: misraa2020multi\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2010.01666\"}\ntags: ['ARXIV', 'Graph', 'Image Retrieval']\n---\nMost real world applications of image retrieval such as Adobe Stock, which is a marketplace for stock photography and illustrations, need a way for users to find images which are both visually (i.e. aesthetically) and conceptually (i.e. containing the same salient objects) as a query image. Learning visual-semantic representations from images is a well studied problem for image retrieval. Filtering based on image concepts or attributes is traditionally achieved with index-based filtering (e.g. on textual tags) or by re-ranking after an initial visual embedding based retrieval. In this paper, we learn a joint vision and concept embedding in the same high-dimensional space. This joint model gives the user fine-grained control over the semantics of the result set, allowing them to explore the catalog of images more rapidly. We model the visual and concept relationships as a graph structure, which captures the rich information through node neighborhood. This graph structure helps us learn multi-modal node embeddings using Graph Neural Networks. We also introduce a novel inference time control, based on selective neighborhood connectivity allowing the user control over the retrieval algorithm. We evaluate these multi-modal embeddings quantitatively on the downstream relevance task of image retrieval on MS-COCO dataset and qualitatively on MS-COCO and an Adobe Stock dataset.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [13.23248291015625, -29.45945167541504]}, {"key": "", "year": "", "title": "Mithun2018webly", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Webly Supervised Joint Embedding for Cross-Modal Image-Text Retrieval\"\nauthors: Mithun Niluthpol Chowdhury, Panda Rameswar, Papalexakis Evangelos E., Roy-Chowdhury Amit K.\nconference: Arxiv\nyear: 2018\nbibkey: mithun2018webly\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1808.07793\"}\ntags: ['ARXIV', 'Cross Modal', 'Supervised', 'Text Retrieval', 'Weakly Supervised']\n---\nCross-modal retrieval between visual data and natural language description remains a long-standing challenge in multimedia. While recent image-text retrieval methods offer great promise by learning deep representations aligned across modalities, most of these methods are plagued by the issue of training with small-scale datasets covering a limited number of images with ground-truth sentences. Moreover, it is extremely expensive to create a larger dataset by annotating millions of images with sentences and may lead to a biased model. Inspired by the recent success of webly supervised learning in deep neural networks, we capitalize on readily-available web images with noisy annotations to learn robust image-text joint representation. Specifically, our main idea is to leverage web images and corresponding tags, along with fully annotated datasets, in training for learning the visual-semantic joint embedding. We propose a two-stage approach for the task that can augment a typical supervised pair-wise ranking loss based formulation with weakly-annotated web images to learn a more robust visual-semantic embedding. Experiments on two standard benchmark datasets demonstrate that our method achieves a significant performance gain in image-text retrieval compared to state-of-the-art approaches.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [1.7972379922866821, 17.458377838134766]}, {"key": "", "year": "", "title": "Mitzenmacher2012balanced", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Balanced Allocations and Double Hashing\"\nauthors: Mitzenmacher Michael\nconference: Arxiv\nyear: 2012\nbibkey: mitzenmacher2012balanced\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1209.5360\"}\ntags: ['ARXIV', 'TIP']\n---\nDouble hashing has recently found more common usage in schemes that use multiple hash functions. In double hashing, for an item $x$, one generates two hash values $f(x)$ and $g(x)$, and then uses combinations $(f(x) +k g(x)) \\bmod n$ for $k=0,1,2,...$ to generate multiple hash values from the initial two. We first perform an empirical study showing that, surprisingly, the performance difference between double hashing and fully random hashing appears negligible in the standard balanced allocation paradigm, where each item is placed in the least loaded of $d$ choices, as well as several related variants. We then provide theoretical results that explain the behavior of double hashing in this context.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-27.725004196166992, -5.049018859863281]}, {"key": "", "year": "", "title": "Mitzenmacher2014a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A New Approach to Analyzing Robin Hood Hashing\"\nauthors: Mitzenmacher Michael\nconference: Arxiv\nyear: 2014\nbibkey: mitzenmacher2014a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1401.7616\"}\ntags: ['ARXIV']\n---\nRobin Hood hashing is a variation on open addressing hashing designed to reduce the maximum search time as well as the variance in the search time for elements in the hash table. While the case of insertions only using Robin Hood hashing is well understood, the behavior with deletions has remained open. Here we show that Robin Hood hashing can be analyzed under the framework of finite-level finite-dimensional jump Markov chains. This framework allows us to re-derive some past results for the insertion-only case with some new insight, as well as provide a new analysis for a standard deletion model, where we alternate between deleting a random old key and inserting a new one. In particular, we show that a simple but apparently unstudied approach for handling deletions with Robin Hood hashing offers good performance even under high loads.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-22.375925064086914, -2.4286983013153076]}, {"key": "", "year": "", "title": "Mitzenmacher2015more", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"More Analysis of Double Hashing for Balanced Allocations\"\nauthors: Mitzenmacher Michael\nconference: Arxiv\nyear: 2015\nbibkey: mitzenmacher2015more\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1503.00658\"}\ntags: ['ARXIV', 'TIP']\n---\nWith double hashing, for a key $x$, one generates two hash values $f(x)$ and $g(x)$, and then uses combinations $(f(x) +i g(x)) \\bmod n$ for $i=0,1,2,...$ to generate multiple hash values in the range $[0,n-1]$ from the initial two. For balanced allocations, keys are hashed into a hash table where each bucket can hold multiple keys, and each key is placed in the least loaded of $d$ choices. It has been shown previously that asymptotically the performance of double hashing and fully random hashing is the same in the balanced allocation paradigm using fluid limit methods. Here we extend a coupling argument used by Lueker and Molodowitch to show that double hashing and ideal uniform hashing are asymptotically equivalent in the setting of open address hash tables to the balanced allocation setting, providing further insight into this phenomenon. We also discuss the potential for and bottlenecks limiting the use this approach for other multiple choice hashing schemes.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-27.637046813964844, -5.323746681213379]}, {"key": "", "year": "", "title": "Mitzenmacher2018robust", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Robust Set Reconciliation via Locality Sensitive Hashing\"\nauthors: Mitzenmacher Michael, Morgan Tom\nconference: Arxiv\nyear: 2018\nbibkey: mitzenmacher2018robust\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1807.09694\"}\ntags: ['ARXIV']\n---\nWe consider variations of set reconciliation problems where two parties, Alice and Bob, each hold a set of points in a metric space, and the goal is for Bob to conclude with a set of points that is close to Alice's set of points in a well-defined way. This setting has been referred to as robust set reconciliation. More specifically, in one variation we examine the goal is for Bob to end with a set of points that is close to Alice's in earth mover's distance, and in another the goal is for Bob to have a point that is close to each of Alice's. The first problem has been studied before; our results scale better with the dimension of the space. The second problem appears new. Our primary novelty is utilizing Invertible Bloom Lookup Tables in combination with locality sensitive hashing. This combination allows us to cope with the geometric setting in a communication-efficient manner.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [6.679636001586914, -2.6619367599487305]}, {"key": "", "year": "", "title": "Mohamed2012thscalable", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"TH*:Scalable Distributed Trie Hashing\"\nauthors: Mohamed Aridj, Eddine Zegour Djamel\nconference: Arxiv\nyear: 2012\nbibkey: mohamed2012thscalable\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1205.0439\"}\ntags: ['ARXIV']\n---\nIn today's world of computers, dealing with huge amounts of data is not unusual. The need to distribute this data in order to increase its availability and increase the performance of accessing it is more urgent than ever. For these reasons it is necessary to develop scalable distributed data structures. In this paper we propose a TH* distributed variant of the Trie Hashing data structure. First we propose Thsw new version of TH without node Nil in digital tree (trie), then this version will be adapted to multicomputer environment. The simulation results reveal that TH* is scalable in the sense that it grows gracefully, one bucket at a time, to a large number of servers, also TH* offers a good storage space utilization and high query efficiency special for ordering operations.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-21.620433807373047, 1.8936015367507935]}, {"key": "", "year": "", "title": "Mohammad2021compact", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Compact Binary Fingerprint for Image Copy Re-Ranking\"\nauthors: Mohammad Nazar, Baber Junaid, Bakhtyar Maheen, Chandio Bilal Ahmed, Sanjrani Anwar Ali\nconference: Arxiv\nyear: 2021\nbibkey: mohammad2021compact\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2109.07802\"}\ntags: ['ARXIV']\n---\nImage copy detection is challenging and appealing topic in computer vision and signal processing. Recent advancements in multimedia have made distribution of image across the global easy and fast: that leads to many other issues such as forgery and image copy retrieval. Local keypoint descriptors such as SIFT are used to represent the images, and based on those descriptors matching, images are matched and retrieved. Features are quantized so that searching/matching may be made feasible for large databases at the cost of accuracy loss. In this paper, we propose binary feature that is obtained by quantizing the SIFT into binary, and rank list is re-examined to remove the false positives. Experiments on challenging dataset shows the gain in accuracy and time.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [14.570985794067383, 11.566377639770508]}, {"key": "", "year": "", "title": "Mohedano2016bags", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Bags of Local Convolutional Features for Scalable Instance Search\"\nauthors: Mohedano Eva, Salvador Amaia, McGuinness Kevin, Marques Ferran, O'Connor Noel E., Giro-i-Nieto Xavier\nconference: Arxiv\nyear: 2016\nbibkey: mohedano2016bags\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1604.04653\"}\ntags: ['ARXIV', 'CNN']\n---\nThis work proposes a simple instance retrieval pipeline based on encoding the convolutional features of CNN using the bag of words aggregation scheme (BoW). Assigning each local array of activations in a convolutional layer to a visual word produces an \\textit{assignment map}, a compact representation that relates regions of an image with a visual word. We use the assignment map for fast spatial reranking, obtaining object localizations that are used for query expansion. We demonstrate the suitability of the BoW representation based on local CNN features for instance retrieval, achieving competitive performance on the Oxford and Paris buildings benchmarks. We show that our proposed system for CNN feature aggregation with BoW outperforms state-of-the-art techniques using sum pooling at a subset of the challenging TRECVid INS benchmark.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [15.037769317626953, 27.388713836669922]}, {"key": "", "year": "", "title": "Morgado2020deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Hashing with Hash-Consistent Large Margin Proxy Embeddings\"\nauthors: Morgado Pedro, Li Yunsheng, Pereira Jose Costa, Saberian Mohammad, Vasconcelos Nuno\nconference: Arxiv\nyear: 2020\nbibkey: morgado2020deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2007.13912\"}\ntags: ['ARXIV', 'CNN']\n---\nImage hash codes are produced by binarizing the embeddings of convolutional neural networks (CNN) trained for either classification or retrieval. While proxy embeddings achieve good performance on both tasks, they are non-trivial to binarize, due to a rotational ambiguity that encourages non-binary embeddings. The use of a fixed set of proxies (weights of the CNN classification layer) is proposed to eliminate this ambiguity, and a procedure to design proxy sets that are nearly optimal for both classification and hashing is introduced. The resulting hash-consistent large margin (HCLM) proxies are shown to encourage saturation of hashing units, thus guaranteeing a small binarization error, while producing highly discriminative hash-codes. A semantic extension (sHCLM), aimed to improve hashing performance in a transfer scenario, is also proposed. Extensive experiments show that sHCLM embeddings achieve significant improvements over state-of-the-art hashing procedures on several small and large datasets, both within and beyond the set of training classes.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [9.012686729431152, 29.32962989807129]}, {"key": "", "year": "", "title": "Morozov2019unsupervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Unsupervised Neural Quantization for Compressed-Domain Similarity Search\"\nauthors: Morozov Stanislav, Babenko Artem\nconference: Arxiv\nyear: 2019\nbibkey: morozov2019unsupervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1908.03883\"}\ntags: ['ARXIV', 'Deep Learning', 'Image Retrieval', 'Quantisation', 'Supervised', 'Unsupervised']\n---\nWe tackle the problem of unsupervised visual descriptors compression, which is a key ingredient of large-scale image retrieval systems. While the deep learning machinery has benefited literally all computer vision pipelines, the existing state-of-the-art compression methods employ shallow architectures, and we aim to close this gap by our paper. In more detail, we introduce a DNN architecture for the unsupervised compressed-domain retrieval, based on multi-codebook quantization. The proposed architecture is designed to incorporate both fast data encoding and efficient distances computation via lookup tables. We demonstrate the exceptional advantage of our scheme over existing quantization approaches on several datasets of visual descriptors via outperforming the previous state-of-the-art by a large margin.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.413830757141113, 21.12251853942871]}, {"key": "", "year": "", "title": "Morra2019benchmarking", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Benchmarking unsupervised near-duplicate image detection\"\nauthors: Morra Lia, Lamberti Fabrizio\nconference: Expert Systems with Applications, online first,\nyear: 2019\nbibkey: morra2019benchmarking\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1907.02821\"}\ntags: ['Deep Learning', 'Image Retrieval', 'Supervised', 'Unsupervised']\n---\nUnsupervised near-duplicate detection has many practical applications ranging from social media analysis and web-scale retrieval, to digital image forensics. It entails running a threshold-limited query on a set of descriptors extracted from the images, with the goal of identifying all possible near-duplicates, while limiting the false positives due to visually similar images. Since the rate of false alarms grows with the dataset size, a very high specificity is thus required, up to $1 - 10^\\{-9\\}$ for realistic use cases; this important requirement, however, is often overlooked in literature. In recent years, descriptors based on deep convolutional neural networks have matched or surpassed traditional feature extraction methods in content-based image retrieval tasks. To the best of our knowledge, ours is the first attempt to establish the performance range of deep learning-based descriptors for unsupervised near-duplicate detection on a range of datasets, encompassing a broad spectrum of near-duplicate definitions. We leverage both established and new benchmarks, such as the Mir-Flick Near-Duplicate (MFND) dataset, in which a known ground truth is provided for all possible pairs over a general, large scale image collection. To compare the specificity of different descriptors, we reduce the problem of unsupervised detection to that of binary classification of near-duplicate vs. not-near-duplicate images. The latter can be conveniently characterized using Receiver Operating Curve (ROC). Our findings in general favor the choice of fine-tuning deep convolutional networks, as opposed to using off-the-shelf features, but differences at high specificity settings depend on the dataset and are often small. The best performance was observed on the MFND benchmark, achieving 96\\% sensitivity at a false positive rate of $1.43 \\times 10^\\{-6\\}$.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [5.009407043457031, 13.893446922302246]}, {"key": "", "year": "", "title": "Morris2016faster", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Faster Kernels for Graphs with Continuous Attributes via Hashing\"\nauthors: Morris Christopher, Kriege Nils M., Kersting Kristian, Mutzel Petra\nconference: Arxiv\nyear: 2016\nbibkey: morris2016faster\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1610.00064\"}\ntags: ['ARXIV', 'Graph']\n---\nWhile state-of-the-art kernels for graphs with discrete labels scale well to graphs with thousands of nodes, the few existing kernels for graphs with continuous attributes, unfortunately, do not scale well. To overcome this limitation, we present hash graph kernels, a general framework to derive kernels for graphs with continuous attributes from discrete ones. The idea is to iteratively turn continuous attributes into discrete labels using randomized hash functions. We illustrate hash graph kernels for the Weisfeiler-Lehman subtree kernel and for the shortest-path kernel. The resulting novel graph kernels are shown to be, both, able to handle graphs with continuous attributes and scalable to large graphs and data sets. This is supported by our theoretical analysis and demonstrated by an extensive experimental evaluation.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [6.668173789978027, -31.34775733947754]}, {"key": "", "year": "", "title": "Morvan2017streaming", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Streaming Binary Sketching based on Subspace Tracking and Diagonal Uniformization\"\nauthors: Morvan Anne, Souloumiac Antoine, Gouy-Pailler C\u00e9dric, Atif Jamal\nconference: Arxiv\nyear: 2017\nbibkey: morvan2017streaming\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1705.07661\"}\ntags: ['ARXIV']\n---\nIn this paper, we address the problem of learning compact similarity-preserving embeddings for massive high-dimensional streams of data in order to perform efficient similarity search. We present a new online method for computing binary compressed representations -sketches- of high-dimensional real feature vectors. Given an expected code length $c$ and high-dimensional input data points, our algorithm provides a $c$-bits binary code for preserving the distance between the points from the original high-dimensional space. Our algorithm does not require neither the storage of the whole dataset nor a chunk, thus it is fully adaptable to the streaming setting. It also provides low time complexity and convergence guarantees. We demonstrate the quality of our binary sketches through experiments on real data for the nearest neighbors search task in the online setting.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.386019706726074, -9.985206604003906]}, {"key": "", "year": "", "title": "Morvan2018on", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"On the Needs for Rotations in Hypercubic Quantization Hashing\"\nauthors: Morvan Anne, Souloumiac Antoine, Choromanski Krzysztof, Gouy-Pailler C\u00e9dric, Atif Jamal\nconference: Arxiv\nyear: 2018\nbibkey: morvan2018on\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1802.03936\"}\ntags: ['ARXIV', 'Quantisation']\n---\nThe aim of this paper is to endow the well-known family of hypercubic quantization hashing methods with theoretical guarantees. In hypercubic quantization, applying a suitable (random or learned) rotation after dimensionality reduction has been experimentally shown to improve the results accuracy in the nearest neighbors search problem. We prove in this paper that the use of these rotations is optimal under some mild assumptions: getting optimal binary sketches is equivalent to applying a rotation uniformizing the diagonal of the covariance matrix between data points. Moreover, for two closed points, the probability to have dissimilar binary sketches is upper bounded by a factor of the initial distance between the data points. Relaxing these assumptions, we obtain a general concentration result for random matrices. We also provide some experiments illustrating these theoretical points and compare a set of algorithms in both the batch and online settings.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [7.454619407653809, -7.871066093444824]}, {"key": "", "year": "", "title": "Mor\u00e8re2016group", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Group Invariant Deep Representations for Image Instance Retrieval\"\nauthors: Mor\u00e8re Olivier, Veillard Antoine, Lin Jie, Petta Julie, Chandrasekhar Vijay, Poggio Tomaso\nconference: Arxiv\nyear: 2016\nbibkey: mor\u00e8re2016group\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1601.02093\"}\ntags: ['ARXIV', 'CNN', 'Quantisation', 'TIP']\n---\nMost image instance retrieval pipelines are based on comparison of vectors known as global image descriptors between a query image and the database images. Due to their success in large scale image classification, representations extracted from Convolutional Neural Networks (CNN) are quickly gaining ground on Fisher Vectors (FVs) as state-of-the-art global descriptors for image instance retrieval. While CNN-based descriptors are generally remarked for good retrieval performance at lower bitrates, they nevertheless present a number of drawbacks including the lack of robustness to common object transformations such as rotations compared with their interest point based FV counterparts. In this paper, we propose a method for computing invariant global descriptors from CNNs. Our method implements a recently proposed mathematical theory for invariance in a sensory cortex modeled as a feedforward neural network. The resulting global descriptors can be made invariant to multiple arbitrary transformation groups while retaining good discriminativeness. Based on a thorough empirical evaluation using several publicly available datasets, we show that our method is able to significantly and consistently improve retrieval results every time a new type of invariance is incorporated. We also show that our method which has few parameters is not prone to overfitting: improvements generalize well across datasets with different properties with regard to invariances. Finally, we show that our descriptors are able to compare favourably to other state-of-the-art compact descriptors in similar bitranges, exceeding the highest retrieval results reported in the literature on some datasets. A dedicated dimensionality reduction step --quantization or hashing-- may be able to further improve the competitiveness of the descriptors.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.825061798095703, 30.242403030395508]}, {"key": "", "year": "", "title": "Mor\u00e8re2016nested", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Nested Invariance Pooling and RBM Hashing for Image Instance Retrieval\"\nauthors: Mor\u00e8re Olivier, Lin Jie, Veillard Antoine, Chandrasekhar Vijay, Poggio Tomaso\nconference: Arxiv\nyear: 2016\nbibkey: mor\u00e8re2016nested\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1603.04595\"}\ntags: ['ARXIV']\n---\nThe goal of this work is the computation of very compact binary hashes for image instance retrieval. Our approach has two novel contributions. The first one is Nested Invariance Pooling (NIP), a method inspired from i-theory, a mathematical theory for computing group invariant transformations with feed-forward neural networks. NIP is able to produce compact and well-performing descriptors with visual representations extracted from convolutional neural networks. We specifically incorporate scale, translation and rotation invariances but the scheme can be extended to any arbitrary sets of transformations. We also show that using moments of increasing order throughout nesting is important. The NIP descriptors are then hashed to the target code size (32-256 bits) with a Restricted Boltzmann Machine with a novel batch-level regularization scheme specifically designed for the purpose of hashing (RBMH). A thorough empirical evaluation with state-of-the-art shows that the results obtained both with the NIP descriptors and the NIP+RBMH hashes are consistently outstanding across a wide range of datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [6.08432149887085, -1.1584142446517944]}, {"key": "", "year": "", "title": "Moulton2018maximally", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Maximally Consistent Sampling and the Jaccard Index of Probability Distributions\"\nauthors: Moulton Ryan, Jiang Yunjiang\nconference: Arxiv\nyear: 2018\nbibkey: moulton2018maximally\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1809.04052\"}\ntags: ['ARXIV']\n---\nWe introduce simple, efficient algorithms for computing a MinHash of a probability distribution, suitable for both sparse and dense data, with equivalent running times to the state of the art for both cases. The collision probability of these algorithms is a new measure of the similarity of positive vectors which we investigate in detail. We describe the sense in which this collision probability is optimal for any Locality Sensitive Hash based on sampling. We argue that this similarity measure is more useful for probability distributions than the similarity pursued by other algorithms for weighted MinHash, and is the natural generalization of the Jaccard index.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-2.6972036361694336, -10.850526809692383]}, {"key": "", "year": "", "title": "Mousavian2015deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Convolutional Features for Image Based Retrieval and Scene Categorization\"\nauthors: Mousavian Arsalan, Kosecka Jana\nconference: Arxiv\nyear: 2015\nbibkey: mousavian2015deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1509.06033\"}\ntags: ['ARXIV', 'CNN', 'Graph', 'Image Retrieval']\n---\nSeveral recent approaches showed how the representations learned by Convolutional Neural Networks can be repurposed for novel tasks. Most commonly it has been shown that the activation features of the last fully connected layers (fc7 or fc6) of the network, followed by a linear classifier outperform the state-of-the-art on several recognition challenge datasets. Instead of recognition, this paper focuses on the image retrieval problem and proposes a examines alternative pooling strategies derived for CNN features. The presented scheme uses the features maps from an earlier layer 5 of the CNN architecture, which has been shown to preserve coarse spatial information and is semantically meaningful. We examine several pooling strategies and demonstrate superior performance on the image retrieval task (INRIA Holidays) at the fraction of the computational cost, while using a relatively small memory requirements. In addition to retrieval, we see similar efficiency gains on the SUN397 scene categorization dataset, demonstrating wide applicability of this simple strategy. We also introduce and evaluate a novel GeoPlaces5K dataset from different geographical locations in the world for image retrieval that stresses more dramatic changes in appearance and viewpoint.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.862883567810059, 28.639381408691406]}, {"key": "", "year": "", "title": "Mu2016deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Hashing: A Joint Approach for Image Signature Learning\"\nauthors: Mu Yadong, Liu Zhu\nconference: Arxiv\nyear: 2016\nbibkey: mu2016deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1608.03658\"}\ntags: ['ARXIV', 'Deep Learning', 'Supervised', 'Unsupervised']\n---\nSimilarity-based image hashing represents crucial technique for visual data storage reduction and expedited image search. Conventional hashing schemes typically feed hand-crafted features into hash functions, which separates the procedures of feature extraction and hash function learning. In this paper, we propose a novel algorithm that concurrently performs feature engineering and non-linear supervised hashing function learning. Our technical contributions in this paper are two-folds: 1) deep network optimization is often achieved by gradient propagation, which critically requires a smooth objective function. The discrete nature of hash codes makes them not amenable for gradient-based optimization. To address this issue, we propose an exponentiated hashing loss function and its bilinear smooth approximation. Effective gradient calculation and propagation are thereby enabled; 2) pre-training is an important trick in supervised deep learning. The impact of pre-training on the hash code quality has never been discussed in current deep hashing literature. We propose a pre-training scheme inspired by recent advance in deep network based image classification, and experimentally demonstrate its effectiveness. Comprehensive quantitative evaluations are conducted on several widely-used image benchmarks. On all benchmarks, our proposed deep hashing algorithm outperforms all state-of-the-art competitors by significant margins. In particular, our algorithm achieves a near-perfect 0.99 in terms of Hamming ranking accuracy with only 12 bits on MNIST, and a new record of 0.74 on the CIFAR10 dataset. In comparison, the best accuracies obtained on CIFAR10 by existing hashing algorithms without or with deep networks are known to be 0.36 and 0.58 respectively.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-8.4743013381958, 5.075214385986328]}, {"key": "", "year": "", "title": "Mu2018towards", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Towards Practical Visual Search Engine within Elasticsearch\"\nauthors: Mu Cun, Zhao Jun, Yang Guang, Zhang Jing, Yan Zheng\nconference: Arxiv\nyear: 2018\nbibkey: mu2018towards\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1806.08896\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nIn this paper, we describe our end-to-end content-based image retrieval system built upon Elasticsearch, a well-known and popular textual search engine. As far as we know, this is the first time such a system has been implemented in eCommerce, and our efforts have turned out to be highly worthwhile. We end up with a novel and exciting visual search solution that is extremely easy to be deployed, distributed, scaled and monitored in a cost-friendly manner. Moreover, our platform is intrinsically flexible in supporting multimodal searches, where visual and textual information can be jointly leveraged in retrieval. The core idea is to encode image feature vectors into a collection of string tokens in a way such that closer vectors will share more string tokens in common. By doing that, we can utilize Elasticsearch to efficiently retrieve similar images based on similarities within encoded sting tokens. As part of the development, we propose a novel vector to string encoding method, which is shown to substantially outperform the previous ones in terms of both precision and latency. First-hand experiences in implementing this Elasticsearch-based platform are extensively addressed, which should be valuable to practitioners also interested in building visual search engine on top of Elasticsearch.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [3.211163282394409, 19.32879066467285]}, {"key": "", "year": "", "title": "Mu2019an", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"An Empirical Comparison of FAISS and FENSHSES for Nearest Neighbor Search in Hamming Space\"\nauthors: Mu Cun, Yang Binwei, Yan Zheng\nconference: Arxiv\nyear: 2019\nbibkey: mu2019an\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1906.10095\"}\ntags: ['ARXIV']\n---\nIn this paper, we compare the performances of FAISS and FENSHSES on nearest neighbor search in Hamming space--a fundamental task with ubiquitous applications in nowadays eCommerce. Comprehensive evaluations are made in terms of indexing speed, search latency and RAM consumption. This comparison is conducted towards a better understanding on trade-offs between nearest neighbor search systems implemented in main memory and the ones implemented in secondary memory, which is largely unaddressed in literature.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [28.69280433654785, 0.6904816031455994]}, {"key": "", "year": "", "title": "Mu2019fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast and Exact Nearest Neighbor Search in Hamming Space on Full-Text Search Engines\"\nauthors: Mu Cun, Zhao Jun, Yang Guang, Yang Binwei, Yan Zheng\nconference: Arxiv\nyear: 2019\nbibkey: mu2019fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1902.08498\"}\ntags: ['ARXIV']\n---\nA growing interest has been witnessed recently from both academia and industry in building nearest neighbor search (NNS) solutions on top of full-text search engines. Compared with other NNS systems, such solutions are capable of effectively reducing main memory consumption, coherently supporting multi-model search and being immediately ready for production deployment. In this paper, we continue the journey to explore specifically how to empower full-text search engines with fast and exact NNS in Hamming space (i.e., the set of binary codes). By revisiting three techniques (bit operation, subs-code filtering and data preprocessing with permutation) in information retrieval literature, we develop a novel engineering solution for full-text search engines to efficiently accomplish this special but important NNS task. In the experiment, we show that our proposed approach enables full-text search engines to achieve significant speed-ups over its state-of-the-art term match approach for NNS within binary codes.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [14.562980651855469, -5.934515953063965]}, {"key": "", "year": "", "title": "Mukherjee2012an", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"An Efficient Cryptographic Hash Algorithm (BSA)\"\nauthors: Mukherjee Subhabrata, Roy Bimal, Laha Anirban\nconference: In Proceedings of The\nyear: 2012\nbibkey: mukherjee2012an\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1204.2798\"}\ntags: ['Graph']\n---\nRecent cryptanalytic attacks have exposed the vulnerabilities of some widely used cryptographic hash functions like MD5 and SHA-1. Attacks in the line of differential attacks have been used to expose the weaknesses of several other hash functions like RIPEMD, HAVAL. In this paper we propose a new efficient hash algorithm that provides a near random hash output and overcomes some of the earlier weaknesses. Extensive simulations and comparisons with some existing hash functions have been done to prove the effectiveness of the BSA, which is an acronym for the name of the 3 authors.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-30.908946990966797, -3.389557123184204]}, {"key": "", "year": "", "title": "Mukundan2018understanding", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Understanding and Improving Kernel Local Descriptors\"\nauthors: Mukundan Arun, Tolias Giorgos, Bursuc Andrei, J\u00e9gou Herv\u00e9, Chum Ond\u0159ej\nconference: Arxiv\nyear: 2018\nbibkey: mukundan2018understanding\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1811.11147\"}\ntags: ['ARXIV', 'Deep Learning', 'Supervised', 'TIP', 'Unsupervised']\n---\nWe propose a multiple-kernel local-patch descriptor based on efficient match kernels from pixel gradients. It combines two parametrizations of gradient position and direction, each parametrization provides robustness to a different type of patch mis-registration: polar parametrization for noise in the patch dominant orientation detection, Cartesian for imprecise location of the feature point. Combined with whitening of the descriptor space, that is learned with or without supervision, the performance is significantly improved. We analyze the effect of the whitening on patch similarity and demonstrate its semantic meaning. Our unsupervised variant is the best performing descriptor constructed without the need of labeled data. Despite the simplicity of the proposed descriptor, it competes well with deep learning approaches on a number of different tasks.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [7.833121299743652, 3.1441447734832764]}, {"key": "", "year": "", "title": "Muramatsu2008hash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hash Property and Fixed-rate Universal Coding Theorems\"\nauthors: Muramatsu Jun, Miyake Shigeki\nconference: IEEE Transactions on Information Theory, vol.\nyear: 2008\nbibkey: muramatsu2008hash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/0804.1183\"}\ntags: []\n---\nThe aim of this paper is to prove the achievability of fixed-rate universal coding problems by using our previously introduced notion of hash property. These problems are the fixed-rate lossless universal source coding problem and the fixed-rate universal channel coding problem. Since an ensemble of sparse matrices satisfies the hash property requirement, it is proved that we can construct universal codes by using sparse matrices.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-28.1071720123291, 0.41890913248062134]}, {"key": "", "year": "", "title": "Muramatsu2012construction", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Construction of Multiple Access Channel Codes Based on Hash Property\"\nauthors: Muramatsu Jun, Miyake Shigeki\nconference: Arxiv\nyear: 2012\nbibkey: muramatsu2012construction\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1210.6719\"}\ntags: ['ARXIV', 'TIP']\n---\nThe aim of this paper is to introduce the construction of codes for a general discrete stationary memoryless multiple access channel based on the the notion of the hash property. Since an ensemble of sparse matrices has a hash property, we can use sparse matrices for code construction. Our approach has a potential advantage compared to the conventional random coding because it is expected that we can use some approximation algorithms by using the sparse structure of codes.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-28.0809383392334, 0.4440751373767853]}, {"key": "", "year": "", "title": "Musser2008a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Fast Generic Sequence Matching Algorithm\"\nauthors: Musser David R., Nishanov Gor V.\nconference: Arxiv\nyear: 2008\nbibkey: musser2008a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/0810.0264\"}\ntags: ['ARXIV']\n---\nA string matching -- and more generally, sequence matching -- algorithm is presented that has a linear worst-case computing time bound, a low worst-case bound on the number of comparisons (2n), and sublinear average-case behavior that is better than that of the fastest versions of the Boyer-Moore algorithm. The algorithm retains its efficiency advantages in a wide variety of sequence matching problems of practical interest, including traditional string matching; large-alphabet problems (as in Unicode strings); and small-alphabet, long-pattern problems (as in DNA searches). Since it is expressed as a generic algorithm for searching in sequences over an arbitrary type T, it is well suited for use in generic software libraries such as the C++ Standard Template Library. The algorithm was obtained by adding to the Knuth-Morris-Pratt algorithm one of the pattern-shifting techniques from the Boyer-Moore algorithm, with provision for use of hashing in this technique. In situations in which a hash function or random access to the sequences is not available, the algorithm falls back to an optimized version of the Knuth-Morris-Pratt algorithm.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-0.6710390448570251, -10.124253273010254]}, {"key": "", "year": "", "title": "M\u00fcller2019cross", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Cross-Modal Music Retrieval and Applications: An Overview of Key Methodologies\"\nauthors: M\u00fcller Meinard, Arzt Andreas, Balke Stefan, Dorfer Matthias, Widmer Gerhard\nconference: IEEE Signal Processing Magazine\nyear: 2019\nbibkey: m\u00fcller2019cross\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1902.04397\"}\ntags: ['Cross Modal']\n---\nThere has been a rapid growth of digitally available music data, including audio recordings, digitized images of sheet music, album covers and liner notes, and video clips. This huge amount of data calls for retrieval strategies that allow users to explore large music collections in a convenient way. More precisely, there is a need for cross-modal retrieval algorithms that, given a query in one modality (e.g., a short audio excerpt), find corresponding information and entities in other modalities (e.g., the name of the piece and the sheet music). This goes beyond exact audio identification and subsequent retrieval of metainformation as performed by commercial applications like Shazam [1].\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [31.11623191833496, -5.973339080810547]}, {"key": "", "year": "", "title": "N2013region", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Region and Location Based Indexing and Retrieval of MR-T2 Brain Tumor Images\"\nauthors: N Krishna A, Prasad B G\nconference: International Journal of Information Processing,\nyear: 2013\nbibkey: n2013region\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1312.2061\"}\ntags: []\n---\nIn this paper, region based and location based retrieval systems have been implemented for retrieval of MR-T2 axial 2-D brain images. This is done by extracting and characterizing the tumor portion of 2-D brain slices by use of a suitable threshold computed over the entire image. Indexing and retrieval is then performed by computing texture features based on gray-tone spatial-dependence matrix of segmented regions. A Hash structure is used to index all images. A combined index is adopted to point to all similar images in terms of the texture features. At query time, only those images that are in the same hash bucket as those of the queried image are compared for similarity, thus reducing the search space and time.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [28.3366756439209, 17.83313751220703]}, {"key": "", "year": "", "title": "Naidan2015permutation", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Permutation Search Methods are Efficient, Yet Faster Search is Possible\"\nauthors: Naidan Bilegsaikhan, Boytsov Leonid, Nyberg Eric\nconference: Arxiv\nyear: 2015\nbibkey: naidan2015permutation\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1506.03163\"}\ntags: ['ARXIV', 'Graph', 'LSH', 'Survey Paper']\n---\nWe survey permutation-based methods for approximate k-nearest neighbor search. In these methods, every data point is represented by a ranked list of pivots sorted by the distance to this point. Such ranked lists are called permutations. The underpinning assumption is that, for both metric and non-metric spaces, the distance between permutations is a good proxy for the distance between original points. Thus, it should be possible to efficiently retrieve most true nearest neighbors by examining only a tiny subset of data points whose permutations are similar to the permutation of a query. We further test this assumption by carrying out an extensive experimental evaluation where permutation methods are pitted against state-of-the art benchmarks (the multi-probe LSH, the VP-tree, and proximity-graph based retrieval) on a variety of realistically large data set from the image and textual domain. The focus is on the high-accuracy retrieval methods for generic spaces. Additionally, we assume that both data and indices are stored in main memory. We find permutation methods to be reasonably efficient and describe a setup where these methods are most useful. To ease reproducibility, we make our software and data sets publicly available.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [3.4097495079040527, -21.423622131347656]}, {"key": "", "year": "", "title": "Najgebauer2015fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast Dictionary Matching for Content-based Image Retrieval\"\nauthors: Najgebauer Patryk, Rygal Janusz, Nowak Tomasz, Romanowski Jakub, Rutkowski Leszek, Voloshynovskiy Sviatoslav, Scherer Rafal\nconference: Arxiv\nyear: 2015\nbibkey: najgebauer2015fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1504.06864\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nThis paper describes a method for searching for common sets of descriptors between collections of images. The presented method operates on local interest keypoints, which are generated using the SURF algorithm. The use of a dictionary of descriptors allowed achieving good performance of the content-based image retrieval. The method can be used to initially determine a set of similar pairs of keypoints between images. For this purpose, we use a certain level of tolerance between values of descriptors, as values of feature descriptors are almost never equal but similar between different images. After that, the method compares the structure of rotation and location of interest points in one image with the point structure in other images. Thus, we were able to find similar areas in images and determine the level of similarity between them, even when images contain different scenes.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [24.957395553588867, 9.49615478515625]}, {"key": "", "year": "", "title": "Najibi2015on", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"On Large-Scale Retrieval: Binary or n-ary Coding\"\nauthors: Najibi Mahyar, Rastegari Mohammad, Davis Larry S.\nconference: Arxiv\nyear: 2015\nbibkey: najibi2015on\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1509.06066\"}\ntags: ['ARXIV', 'Image Retrieval', 'Quantisation']\n---\nThe growing amount of data available in modern-day datasets makes the need to efficiently search and retrieve information. To make large-scale search feasible, Distance Estimation and Subset Indexing are the main approaches. Although binary coding has been popular for implementing both techniques, n-ary coding (known as Product Quantization) is also very effective for Distance Estimation. However, their relative performance has not been studied for Subset Indexing. We investigate whether binary or n-ary coding works better under different retrieval strategies. This leads to the design of a new n-ary coding method, \"Linear Subspace Quantization (LSQ)\" which, unlike other n-ary encoders, can be used as a similarity-preserving embedding. Experiments on image retrieval show that when Distance Estimation is used, n-ary LSQ outperforms other methods. However, when Subset Indexing is applied, interestingly, binary codings are more effective and binary LSQ achieves the best accuracy.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [13.793145179748535, 0.6862240433692932]}, {"key": "", "year": "", "title": "Nandi2014size", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Size Adaptive Region Based Huffman Compression Technique\"\nauthors: Nandi Utpal, Mandal Jyotsna Kumar\nconference: Arxiv\nyear: 2014\nbibkey: nandi2014size\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1403.0153\"}\ntags: ['ARXIV']\n---\nA loss-less compression technique is proposed which uses a variable length Region formation technique to divide the input file into a number of variable length regions. Huffman codes are obtained for entire file after formation of regions. Symbols of each region are compressed one by one. Comparisons are made among proposed technique, Region Based Huffman compression technique and classical Huffman technique. The proposed technique offers better compression ratio for some files than other two.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [18.48921775817871, -11.517518997192383]}, {"key": "", "year": "", "title": "Nara2024revisiting", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Revisiting Relevance Feedback for CLIP-based Interactive Image Retrieval\"\nauthors: Nara Ryoya, Lin Yu-Chieh, Nozawa Yuji, Ng Youyang, Itoh Goh, Torii Osamu, Matsui Yusuke\nconference: Arxiv\nyear: 2024\nbibkey: nara2024revisiting\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2404.16398\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nMany image retrieval studies use metric learning to train an image encoder. However, metric learning cannot handle differences in users' preferences, and requires data to train an image encoder. To overcome these limitations, we revisit relevance feedback, a classic technique for interactive retrieval systems, and propose an interactive CLIP-based image retrieval system with relevance feedback. Our retrieval system first executes the retrieval, collects each user's unique preferences through binary feedback, and returns images the user prefers. Even when users have various preferences, our retrieval system learns each user's preference through the feedback and adapts to the preference. Moreover, our retrieval system leverages CLIP's zero-shot transferability and achieves high accuracy without training. We empirically show that our retrieval system competes well with state-of-the-art metric learning in category-based image retrieval, despite not training image encoders specifically for each dataset. Furthermore, we set up two additional experimental settings where users have various preferences: one-label-based image retrieval and conditioned image retrieval. In both cases, our retrieval system effectively adapts to each user's preferences, resulting in improved accuracy compared to image retrieval without feedback. Overall, our work highlights the potential benefits of integrating CLIP with classic relevance feedback techniques to enhance image retrieval.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [4.250168800354004, 16.2662410736084]}, {"key": "", "year": "", "title": "Nath2022identical", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Identical Image Retrieval using Deep Learning\"\nauthors: Nath Sayan, Nayak Nikhil\nconference: Arxiv\nyear: 2022\nbibkey: nath2022identical\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2205.04883\"}\ntags: ['ARXIV', 'Deep Learning', 'Image Retrieval']\n---\nIn recent years, we know that the interaction with images has increased. Image similarity involves fetching similar-looking images abiding by a given reference image. The target is to find out whether the image searched as a query can result in similar pictures. We are using the BigTransfer Model, which is a state-of-art model itself. BigTransfer(BiT) is essentially a ResNet but pre-trained on a larger dataset like ImageNet and ImageNet-21k with additional modifications. Using the fine-tuned pre-trained Convolution Neural Network Model, we extract the key features and train on the K-Nearest Neighbor model to obtain the nearest neighbor. The application of our model is to find similar images, which are hard to achieve through text queries within a low inference time. We analyse the benchmark of our model based on this application.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [18.567890167236328, 9.683235168457031]}, {"key": "", "year": "", "title": "Navarro2020indexing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Indexing Highly Repetitive String Collections\"\nauthors: Navarro Gonzalo\nconference: Arxiv\nyear: 2020\nbibkey: navarro2020indexing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2004.02781\"}\ntags: ['ARXIV', 'Survey Paper']\n---\nTwo decades ago, a breakthrough in indexing string collections made it possible to represent them within their compressed space while at the same time offering indexed search functionalities. As this new technology permeated through applications like bioinformatics, the string collections experienced a growth that outperforms Moore's Law and challenges our ability of handling them even in compressed form. It turns out, fortunately, that many of these rapidly growing string collections are highly repetitive, so that their information content is orders of magnitude lower than their plain size. The statistical compression methods used for classical collections, however, are blind to this repetitiveness, and therefore a new set of techniques has been developed in order to properly exploit it. The resulting indexes form a new generation of data structures able to handle the huge repetitive string collections that we are facing. In this survey we cover the algorithmic developments that have led to these data structures. We describe the distinct compression paradigms that have been used to exploit repetitiveness, the fundamental algorithmic ideas that form the base of all the existing indexes, and the various structures that have been proposed, comparing them both in theoretical and practical aspects. We conclude with the current challenges in this fascinating field.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-5.700631618499756, -10.341533660888672]}, {"key": "", "year": "", "title": "Nawaz2018revisiting", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Revisiting Cross Modal Retrieval\"\nauthors: Nawaz Shah, Janjua Muhammad Kamran, Calefati Alessandro, Gallo Ignazio\nconference: Arxiv\nyear: 2018\nbibkey: nawaz2018revisiting\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1807.07364\"}\ntags: ['ARXIV', 'Cross Modal', 'TIP']\n---\nThis paper proposes a cross-modal retrieval system that leverages on image and text encoding. Most multimodal architectures employ separate networks for each modality to capture the semantic relationship between them. However, in our work image-text encoding can achieve comparable results in terms of cross-modal retrieval without having to use a separate network for each modality. We show that text encodings can capture semantic relationships between multiple modalities. In our knowledge, this work is the first of its kind in terms of employing a single network and fused image-text embedding for cross-modal retrieval. We evaluate our approach on two famous multimodal datasets: MS-COCO and Flickr30K.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [25.60187530517578, 1.3263963460922241]}, {"key": "", "year": "", "title": "Ndoundam2011collision", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Collision-resistant hash function based on composition of functions\"\nauthors: Ndoundam Rene, Sadie Juvet Karnel\nconference: ARIMA, Vol.\nyear: 2011\nbibkey: ndoundam2011collision\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1108.1478\"}\ntags: ['Graph']\n---\ncryptographic hash function is a deterministic procedure that compresses an arbitrary block of numerical data and returns a fixed-size bit string. There exist many hash functions: MD5, HAVAL, SHA, ... It was reported that these hash functions are not longer secure. Our work is focused in the construction of a new hash function based on composition of functions. The construction used the NP-completeness of Three-dimensional contingency tables and the relaxation of the constraint that a hash function should also be a compression function.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-30.710330963134766, -4.029575347900391]}, {"key": "", "year": "", "title": "Ndungu2023deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep supervised hashing for fast retrieval of radio image cubes\"\nauthors: Ndung'u Steven, Grobler Trienko, Wijnholds Stefan J., Karastoyanova Dimka, Azzopardi George\nconference: Arxiv\nyear: 2023\nbibkey: ndungu2023deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2309.00932\"}\ntags: ['ARXIV', 'Image Retrieval', 'Supervised']\n---\nThe shear number of sources that will be detected by next-generation radio surveys will be astronomical, which will result in serendipitous discoveries. Data-dependent deep hashing algorithms have been shown to be efficient at image retrieval tasks in the fields of computer vision and multimedia. However, there are limited applications of these methodologies in the field of astronomy. In this work, we utilize deep hashing to rapidly search for similar images in a large database. The experiment uses a balanced dataset of 2708 samples consisting of four classes: Compact, FRI, FRII, and Bent. The performance of the method was evaluated using the mean average precision (mAP) metric where a precision of 88.5\\% was achieved. The experimental results demonstrate the capability to search and retrieve similar radio images efficiently and at scale. The retrieval is based on the Hamming distance between the binary hash of the query image and those of the reference images in the database.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [18.21414566040039, -3.6184256076812744]}, {"key": "", "year": "", "title": "Netay2024hashing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hashing geographical point data using the space-filling H-curve\"\nauthors: Netay Igor V.\nconference: Arxiv\nyear: 2024\nbibkey: netay2024hashing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2403.16216\"}\ntags: ['ARXIV', 'Graph']\n---\nWe construct geohashing procedure based on using of space-filling H-curve. This curve provides a way to construct geohash with less computations than the construction based on usage of Hilbert curve. At the same time, H-curve has better clustering properties.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.352188110351562, -20.330224990844727]}, {"key": "", "year": "", "title": "Neyshabur2013the", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"The Power of Asymmetry in Binary Hashing\"\nauthors: Neyshabur Behnam, Yadollahpour Payman, Makarychev Yury, Salakhutdinov Ruslan, Srebro Nathan\nconference: Arxiv\nyear: 2013\nbibkey: neyshabur2013the\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1311.7662\"}\ntags: ['ARXIV']\n---\nWhen approximating binary similarity using the hamming distance between short binary hashes, we show that even if the similarity is symmetric, we can have shorter and more accurate hashes by using two distinct code maps. I.e. by approximating the similarity between $x$ and $x'$ as the hamming distance between $f(x)$ and $g(x')$, for two distinct binary codes $f,g$, rather than as the hamming distance between $f(x)$ and $f(x')$.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [4.937333583831787, -17.348384857177734]}, {"key": "", "year": "", "title": "Neyshabur2014on", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"On Symmetric and Asymmetric LSHs for Inner Product Search\"\nauthors: Neyshabur Behnam, Srebro Nathan\nconference: Arxiv\nyear: 2014\nbibkey: neyshabur2014on\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1410.5518\"}\ntags: ['ARXIV', 'LSH']\n---\nWe consider the problem of designing locality sensitive hashes (LSH) for inner product similarity, and of the power of asymmetric hashes in this context. Shrivastava and Li argue that there is no symmetric LSH for the problem and propose an asymmetric LSH based on different mappings for query and database points. However, we show there does exist a simple symmetric LSH that enjoys stronger guarantees and better empirical performance than the asymmetric LSH they suggest. We also show a variant of the settings where asymmetry is in-fact needed, but there a different asymmetric LSH is required.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [18.93148422241211, -8.627018928527832]}, {"key": "", "year": "", "title": "Ng2015exploiting", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Exploiting Local Features from Deep Networks for Image Retrieval\"\nauthors: Ng Joe Yue-Hei, Yang Fan, Davis Larry S.\nconference: Arxiv\nyear: 2015\nbibkey: ng2015exploiting\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1504.05133\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval']\n---\nDeep convolutional neural networks have been successfully applied to image classification tasks. When these same networks have been applied to image retrieval, the assumption has been made that the last layers would give the best performance, as they do in classification. We show that for instance-level image retrieval, lower layers often perform better than the last layers in convolutional neural networks. We present an approach for extracting convolutional features from different layers of the networks, and adopt VLAD encoding to encode features into a single vector for each image. We investigate the effect of different layers and scales of input images on the performance of convolutional features using the recent deep networks OxfordNet and GoogLeNet. Experiments demonstrate that intermediate layers or higher layers with finer scales produce better results for image retrieval, compared to the last layer. When using compressed 128-D VLAD descriptors, our method obtains state-of-the-art results and outperforms other VLAD and CNN based approaches on two out of three test datasets. Our work provides guidance for transferring deep networks trained on image classification to image retrieval tasks.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.007302284240723, 24.876266479492188]}, {"key": "", "year": "", "title": "Ng2023unsupervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Unsupervised Hashing with Similarity Distribution Calibration\"\nauthors: Ng Kam Woh, Zhu Xiatian, Hoe Jiun Tian, Chan Chee Seng, Zhang Tianyu, Song Yi-Zhe, Xiang Tao\nconference: Arxiv\nyear: 2023\nbibkey: ng2023unsupervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2302.07669\"}   - {name: \"Code\", url: \"https://github.com/kamwoh/sdc.\"}\ntags: ['ARXIV', 'Image Retrieval', 'Supervised', 'Unsupervised']\n---\nUnsupervised hashing methods typically aim to preserve the similarity between data points in a feature space by mapping them to binary hash codes. However, these methods often overlook the fact that the similarity between data points in the continuous feature space may not be preserved in the discrete hash code space, due to the limited similarity range of hash codes. The similarity range is bounded by the code length and can lead to a problem known as similarity collapse. That is, the positive and negative pairs of data points become less distinguishable from each other in the hash space. To alleviate this problem, in this paper a novel Similarity Distribution Calibration (SDC) method is introduced. SDC aligns the hash code similarity distribution towards a calibration distribution (e.g., beta distribution) with sufficient spread across the entire similarity range, thus alleviating the similarity collapse problem. Extensive experiments show that our SDC outperforms significantly the state-of-the-art alternatives on coarse category-level and instance-level image retrieval. Code is available at https://github.com/kamwoh/sdc.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-2.081632375717163, 1.5458245277404785]}, {"key": "", "year": "", "title": "Ng2024concepthash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"ConceptHash: Interpretable Fine-Grained Hashing via Concept Discovery\"\nauthors: Ng Kam Woh, Zhu Xiatian, Song Yi-Zhe, Xiang Tao\nconference: Arxiv\nyear: 2024\nbibkey: ng2024concepthash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2406.08457\"}   - {name: \"Code\", url: \"https://github.com/kamwoh/concepthash.\"}\ntags: ['ARXIV', 'Image Retrieval', 'TOM']\n---\nExisting fine-grained hashing methods typically lack code interpretability as they compute hash code bits holistically using both global and local features. To address this limitation, we propose ConceptHash, a novel method that achieves sub-code level interpretability. In ConceptHash, each sub-code corresponds to a human-understandable concept, such as an object part, and these concepts are automatically discovered without human annotations. Specifically, we leverage a Vision Transformer architecture and introduce concept tokens as visual prompts, along with image patch tokens as model inputs. Each concept is then mapped to a specific sub-code at the model output, providing natural sub-code interpretability. To capture subtle visual differences among highly similar sub-categories (e.g., bird species), we incorporate language guidance to ensure that the learned hash codes are distinguishable within fine-grained object classes while maintaining semantic alignment. This approach allows us to develop hash codes that exhibit similarity within families of species while remaining distinct from species in other families. Extensive experiments on four fine-grained image retrieval benchmarks demonstrate that ConceptHash outperforms previous methods by a significant margin, offering unique sub-code interpretability as an additional benefit. Code at: https://github.com/kamwoh/concepthash.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-3.1149675846099854, 0.4790206849575043]}, {"key": "", "year": "", "title": "Nguyen2013approximate", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Approximate Nearest Neighbor Search in $\\ell_p$\"\nauthors: Nguyen Huy L.\nconference: Arxiv\nyear: 2013\nbibkey: nguyen2013approximate\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1306.3601\"}\ntags: ['ARXIV', 'FOCS', 'LSH']\n---\nWe present a new locality sensitive hashing (LSH) algorithm for $c$-approximate nearest neighbor search in $\\ell_p$ with $1&lt;p&lt;2$. For a database of $n$ points in $\\ell_p$, we achieve $O(dn^\\{\\rho\\})$ query time and $O(dn+n^\\{1+\\rho\\})$ space, where $\\rho \\le O((\\ln c)^2/c^p)$. This improves upon the previous best upper bound $\\rho\\le 1/c$ by Datar et al. (SOCG 2004), and is close to the lower bound $\\rho \\ge 1/c^p$ by O'Donnell, Wu and Zhou (ITCS 2011). The proof is a simple generalization of the LSH scheme for $\\ell_2$ by Andoni and Indyk (FOCS 2006).\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-6.466333866119385, -28.505401611328125]}, {"key": "", "year": "", "title": "Nguyen2021oscar", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"OSCAR-Net: Object-centric Scene Graph Attention for Image Attribution\"\nauthors: Nguyen Eric, Bui Tu, Swaminathan Vishy, Collomosse John\nconference: Arxiv\nyear: 2021\nbibkey: nguyen2021oscar\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2108.03541\"}\ntags: ['ARXIV', 'Graph']\n---\nImages tell powerful stories but cannot always be trusted. Matching images back to trusted sources (attribution) enables users to make a more informed judgment of the images they encounter online. We propose a robust image hashing algorithm to perform such matching. Our hash is sensitive to manipulation of subtle, salient visual details that can substantially change the story told by an image. Yet the hash is invariant to benign transformations (changes in quality, codecs, sizes, shapes, etc.) experienced by images during online redistribution. Our key contribution is OSCAR-Net (Object-centric Scene Graph Attention for Image Attribution Network); a robust image hashing model inspired by recent successes of Transformers in the visual domain. OSCAR-Net constructs a scene graph representation that attends to fine-grained changes of every object's visual appearance and their spatial relationships. The network is trained via contrastive learning on a dataset of original and manipulated images yielding a state of the art image hash for content fingerprinting that scales to millions of images.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [0.325550377368927, 13.261300086975098]}, {"key": "", "year": "", "title": "Ni2016sampled", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Sampled Image Tagging and Retrieval Methods on User Generated Content\"\nauthors: Ni Karl, Zaragoza Kyle, Foster Charles, Carrano Carmen, Chen Barry, Tesfaye Yonas, Gude Alex\nconference: Arxiv\nyear: 2016\nbibkey: ni2016sampled\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1611.06962\"}\ntags: ['ARXIV', 'Deep Learning', 'TIP']\n---\nTraditional image tagging and retrieval algorithms have limited value as a result of being trained with heavily curated datasets. These limitations are most evident when arbitrary search words are used that do not intersect with training set labels. Weak labels from user generated content (UGC) found in the wild (e.g., Google Photos, FlickR, etc.) have an almost unlimited number of unique words in the metadata tags. Prior work on word embeddings successfully leveraged unstructured text with large vocabularies, and our proposed method seeks to apply similar cost functions to open source imagery. Specifically, we train a deep learning image tagging and retrieval system on large scale, user generated content (UGC) using sampling methods and joint optimization of word embeddings. By using the Yahoo! FlickR Creative Commons (YFCC100M) dataset, such an approach builds robustness to common unstructured data issues that include but are not limited to irrelevant tags, misspellings, multiple languages, polysemy, and tag imbalance. As a result, the final proposed algorithm will not only yield comparable results to state of the art in conventional image tagging, but will enable new capability to train algorithms on large, scale unstructured text in the YFCC100M dataset and outperform cited work in zero-shot capability.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [1.031837821006775, 16.483230590820312]}, {"key": "", "year": "", "title": "Niedermayer2014minimizing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Minimizing the Number of Matching Queries for Object Retrieval\"\nauthors: Niedermayer Johannes, Kr\u00f6ger Peer\nconference: Arxiv\nyear: 2014\nbibkey: niedermayer2014minimizing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1412.5808\"}\ntags: ['ARXIV']\n---\nTo increase the computational efficiency of interest-point based object retrieval, researchers have put remarkable research efforts into improving the efficiency of kNN-based feature matching, pursuing to match thousands of features against a database within fractions of a second. However, due to the high-dimensional nature of image features that reduces the effectivity of index structures (curse of dimensionality), due to the vast amount of features stored in image databases (images are often represented by up to several thousand features), this ultimate goal demanded to trade query runtimes for query precision. In this paper we address an approach complementary to indexing in order to improve the runtimes of retrieval by querying only the most promising keypoint descriptors, as this affects matching runtimes linearly and can therefore lead to increased efficiency. As this reduction of kNN queries reduces the number of tentative correspondences, a loss of query precision is minimized by an additional image-level correspondence generation stage with a computational performance independent of the underlying indexing structure. We evaluate such an adaption of the standard recognition pipeline on a variety of datasets using both SIFT and state-of-the-art binary descriptors. Our results suggest that decreasing the number of queried descriptors does not necessarily imply a reduction in the result quality as long as alternative ways of increasing query recall (by thoroughly selecting k) and MAP (using image-level correspondence generation) are considered.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [10.903908729553223, 6.350860118865967]}, {"key": "", "year": "", "title": "Nikhal2023hashreid", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"HashReID: Dynamic Network with Binary Codes for Efficient Person Re-identification\"\nauthors: Nikhal Kshitij, Ma Yujunrong, Bhattacharyya Shuvra S., Riggan Benjamin S.\nconference: Arxiv\nyear: 2023\nbibkey: nikhal2023hashreid\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2308.11900\"}\ntags: ['ARXIV', 'TIP']\n---\nBiometric applications, such as person re-identification (ReID), are often deployed on energy constrained devices. While recent ReID methods prioritize high retrieval performance, they often come with large computational costs and high search time, rendering them less practical in real-world settings. In this work, we propose an input-adaptive network with multiple exit blocks, that can terminate computation early if the retrieval is straightforward or noisy, saving a lot of computation. To assess the complexity of the input, we introduce a temporal-based classifier driven by a new training strategy. Furthermore, we adopt a binary hash code generation approach instead of relying on continuous-valued features, which significantly improves the search process by a factor of 20. To ensure similarity preservation, we utilize a new ranking regularizer that bridges the gap between continuous and binary features. Extensive analysis of our proposed method is conducted on three datasets: Market1501, MSMT17 (Multi-Scene Multi-Time), and the BGC1 (BRIAR Government Collection). Using our approach, more than 70% of the samples with compact hash codes exit early on the Market1501 dataset, saving 80% of the networks computational cost and improving over other hash-based methods by 60%. These results demonstrate a significant improvement over dynamic networks and showcase comparable accuracy performance to conventional ReID methods. Code will be made available.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-12.566145896911621, -10.022313117980957]}, {"key": "", "year": "", "title": "Ning2016scalable", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Scalable Image Retrieval by Sparse Product Quantization\"\nauthors: Ning Qingqun, Zhu Jianke, Zhong Zhiyuan, Hoi Steven C. H., Chen Chun\nconference: Arxiv\nyear: 2016\nbibkey: ning2016scalable\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1603.04614\"}\ntags: ['ARXIV', 'Image Retrieval', 'Quantisation']\n---\nFast Approximate Nearest Neighbor (ANN) search technique for high-dimensional feature indexing and retrieval is the crux of large-scale image retrieval. A recent promising technique is Product Quantization, which attempts to index high-dimensional image features by decomposing the feature space into a Cartesian product of low dimensional subspaces and quantizing each of them separately. Despite the promising results reported, their quantization approach follows the typical hard assignment of traditional quantization methods, which may result in large quantization errors and thus inferior search performance. Unlike the existing approaches, in this paper, we propose a novel approach called Sparse Product Quantization (SPQ) to encoding the high-dimensional feature vectors into sparse representation. We optimize the sparse representations of the feature vectors by minimizing their quantization errors, making the resulting representation is essentially close to the original data in practice. Experiments show that the proposed SPQ technique is not only able to compress data, but also an effective encoding technique. We obtain state-of-the-art results for ANN search on four public image datasets and the promising results of content-based image retrieval further validate the efficacy of our proposed method.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.644816398620605, 13.089130401611328]}, {"key": "", "year": "", "title": "Niu2016constructions", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Constructions and bounds for separating hash families\"\nauthors: Niu X., Cao H.\nconference: Arxiv\nyear: 2016\nbibkey: niu2016constructions\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1611.03274\"}\ntags: ['ARXIV', 'Graph']\n---\nIn this paper, we present a new construction for strong separating hash families by using hypergraphs and obtain some optimal separating hash families. We also improve some previously known bounds of separating hash families.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [5.857061862945557, -17.954219818115234]}, {"key": "", "year": "", "title": "Niwa2022a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Detection Method of Temporally Operated Videos Using Robust Hashing\"\nauthors: Niwa Shoko, Tanaka Miki, Kiya Hitoshi\nconference: Arxiv\nyear: 2022\nbibkey: niwa2022a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2208.05198\"}\ntags: ['ARXIV']\n---\nSNS providers are known to carry out the recompression and resizing of uploaded videos/images, but most conventional methods for detecting tampered videos/images are not robust enough against such operations. In addition, videos are temporally operated such as the insertion of new frames and the permutation of frames, of which operations are difficult to be detected by using conventional methods. Accordingly, in this paper, we propose a novel method with a robust hashing algorithm for detecting temporally operated videos even when applying resizing and compression to the videos.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-2.1572089195251465, 26.399797439575195]}, {"key": "", "year": "", "title": "Noh2016large", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Large-Scale Image Retrieval with Attentive Deep Local Features\"\nauthors: Noh Hyeonwoo, Araujo Andre, Sim Jack, Weyand Tobias, Han Bohyung\nconference: Arxiv\nyear: 2016\nbibkey: noh2016large\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1612.06321\"}   - {name: \"Code\", url: \"https://github.com/tensorflow/models/tree/master/research/delf\"}\ntags: ['ARXIV', 'Image Retrieval', 'TIP']\n---\nWe propose an attentive local feature descriptor suitable for large-scale image retrieval, referred to as DELF (DEep Local Feature). The new feature is based on convolutional neural networks, which are trained only with image-level annotations on a landmark image dataset. To identify semantically useful local features for image retrieval, we also propose an attention mechanism for keypoint selection, which shares most network layers with the descriptor. This framework can be used for image retrieval as a drop-in replacement for other keypoint detectors and descriptors, enabling more accurate feature matching and geometric verification. Our system produces reliable confidence scores to reject false positives---in particular, it is robust against queries that have no correct match in the database. To evaluate the proposed descriptor, we introduce a new large-scale dataset, referred to as Google-Landmarks dataset, which involves challenges in both database and query such as background clutter, partial occlusion, multiple landmarks, objects in variable scales, etc. We show that DELF outperforms the state-of-the-art global and local descriptors in the large-scale setting by significant margins. Code and dataset can be found at the project webpage: https://github.com/tensorflow/models/tree/master/research/delf .\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [9.464804649353027, 15.292073249816895]}, {"key": "", "year": "", "title": "Noma2013markov", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Markov Chain Monte Carlo for Arrangement of Hyperplanes in Locality-Sensitive Hashing\"\nauthors: Noma Yui, Konoshima Makiko\nconference: Arxiv\nyear: 2013\nbibkey: noma2013markov\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1303.4169\"}\ntags: ['ARXIV', 'Supervised']\n---\nSince Hamming distances can be calculated by bitwise computations, they can be calculated with less computational load than L2 distances. Similarity searches can therefore be performed faster in Hamming distance space. The elements of Hamming distance space are bit strings. On the other hand, the arrangement of hyperplanes induce the transformation from the feature vectors into feature bit strings. This transformation method is a type of locality-sensitive hashing that has been attracting attention as a way of performing approximate similarity searches at high speed. Supervised learning of hyperplane arrangements allows us to obtain a method that transforms them into feature bit strings reflecting the information of labels applied to higher-dimensional feature vectors. In this p aper, we propose a supervised learning method for hyperplane arrangements in feature space that uses a Markov chain Monte Carlo (MCMC) method. We consider the probability density functions used during learning, and evaluate their performance. We also consider the sampling method for learning data pairs needed in learning, and we evaluate its performance. We confirm that the accuracy of this learning method when using a suitable probability density function and sampling method is greater than the accuracy of existing learning methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [10.937603950500488, -0.5596529841423035]}, {"key": "", "year": "", "title": "Noma2014eclipse", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Eclipse Hashing: Alexandrov Compactification and Hashing with Hyperspheres for Fast Similarity Search\"\nauthors: Noma Yui, Konoshima Makiko\nconference: Arxiv\nyear: 2014\nbibkey: noma2014eclipse\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1406.3882\"}\ntags: ['ARXIV', 'Graph', 'LSH']\n---\nThe similarity searches that use high-dimensional feature vectors consisting of a vast amount of data have a wide range of application. One way of conducting a fast similarity search is to transform the feature vectors into binary vectors and perform the similarity search by using the Hamming distance. Such a transformation is a hashing method, and the choice of hashing function is important. Hashing methods using hyperplanes or hyperspheres are proposed. One study reported here is inspired by Spherical LSH, and we use hypersperes to hash the feature vectors. Our method, called Eclipse-hashing, performs a compactification of R^n by using the inverse stereographic projection, which is a kind of Alexandrov compactification. By using Eclipse-hashing, one can obtain the hypersphere-hash function without explicitly using hyperspheres. Hence, the number of nonlinear operations is reduced and the processing time of hashing becomes shorter. Furthermore, we also show that as a result of improving the approximation accuracy, Eclipse-hashing is more accurate than hyperplane-hashing.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [6.09433650970459, -20.70995330810547]}, {"key": "", "year": "", "title": "Norouzi2013fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast Exact Search in Hamming Space with Multi-Index Hashing\"\nauthors: Norouzi Mohammad, Punjani Ali, Fleet David J.\nconference: Arxiv\nyear: 2013\nbibkey: norouzi2013fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1307.2982\"}\ntags: ['ARXIV', 'TIP']\n---\nThere is growing interest in representing image data and feature descriptors using compact binary codes for fast near neighbor search. Although binary codes are motivated by their use as direct indices (addresses) into a hash table, codes longer than 32 bits are not being used as such, as it was thought to be ineffective. We introduce a rigorous way to build multiple hash tables on binary code substrings that enables exact k-nearest neighbor search in Hamming space. The approach is storage efficient and straightforward to implement. Theoretical analysis shows that the algorithm exhibits sub-linear run-time behavior for uniformly distributed codes. Empirical results show dramatic speedups over a linear scan baseline for datasets of up to one billion codes of 64, 128, or 256 bits.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-4.838894844055176, -11.9527006149292]}, {"key": "", "year": "", "title": "Nouredanesh2016gabor", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Gabor Barcodes for Medical Image Retrieval\"\nauthors: Nouredanesh Mina, Tizhoosh Hamid R., Banijamali Ershad\nconference: Arxiv\nyear: 2016\nbibkey: nouredanesh2016gabor\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1605.04478\"}\ntags: ['ARXIV', 'Image Retrieval', 'TOM']\n---\nIn recent years, advances in medical imaging have led to the emergence of massive databases, containing images from a diverse range of modalities. This has significantly heightened the need for automated annotation of the images on one side, and fast and memory-efficient content-based image retrieval systems on the other side. Binary descriptors have recently gained more attention as a potential vehicle to achieve these goals. One of the recently introduced binary descriptors for tagging of medical images are Radon barcodes (RBCs) that are driven from Radon transform via local thresholding. Gabor transform is also a powerful transform to extract texture-based information. Gabor features have exhibited robustness against rotation, scale, and also photometric disturbances, such as illumination changes and image noise in many applications. This paper introduces Gabor Barcodes (GBCs), as a novel framework for the image annotation. To find the most discriminative GBC for a given query image, the effects of employing Gabor filters with different parameters, i.e., different sets of scales and orientations, are investigated, resulting in different barcode lengths and retrieval performances. The proposed method has been evaluated on the IRMA dataset with 193 classes comprising of 12,677 x-ray images for indexing, and 1,733 x-rays images for testing. A total error score as low as $351$ ($\\approx 80\\%$ accuracy for the first hit) was achieved.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [28.091041564941406, 20.737783432006836]}, {"key": "", "year": "", "title": "Odonnell2009optimal", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Optimal lower bounds for locality sensitive hashing (except when q is tiny)\"\nauthors: O'Donnell Ryan, Wu Yi, Zhou Yuan\nconference: Arxiv\nyear: 2009\nbibkey: odonnell2009optimal\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/0912.0250\"}\ntags: ['ARXIV', 'LSH']\n---\nWe study lower bounds for Locality Sensitive Hashing (LSH) in the strongest setting: point sets in {0,1}^d under the Hamming distance. Recall that here H is said to be an (r, cr, p, q)-sensitive hash family if all pairs x, y in {0,1}^d with dist(x,y) at most r have probability at least p of collision under a randomly chosen h in H, whereas all pairs x, y in {0,1}^d with dist(x,y) at least cr have probability at most q of collision. Typically, one considers d tending to infinity, with c fixed and q bounded away from 0. For its applications to approximate nearest neighbor search in high dimensions, the quality of an LSH family H is governed by how small its \"rho parameter\" rho = ln(1/p)/ln(1/q) is as a function of the parameter c. The seminal paper of Indyk and Motwani showed that for each c, the extremely simple family H = {x -&gt; x_i : i in d} achieves rho at most 1/c. The only known lower bound, due to Motwani, Naor, and Panigrahy, is that rho must be at least .46/c (minus o_d(1)). In this paper we show an optimal lower bound: rho must be at least 1/c (minus o_d(1)). This lower bound for Hamming space yields a lower bound of 1/c^2 for Euclidean space (or the unit sphere) and 1/c for the Jaccard distance on sets; both of these match known upper bounds. Our proof is simple; the essence is that the noise stability of a boolean function at e^{-t} is a log-convex function of t.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-13.726299285888672, -20.673858642578125]}, {"key": "", "year": "", "title": "Olieman2015loclinkvis", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"LocLinkVis: A Geographic Information Retrieval-Based System for Large-Scale Exploratory Search\"\nauthors: Olieman Alex, Kamps Jaap, Claros Rosa Merino\nconference: Proc. Posters and Demos Track of\nyear: 2015\nbibkey: olieman2015loclinkvis\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1509.02010\"}\ntags: ['Graph']\n---\nIn this paper we present LocLinkVis (Locate-Link-Visualize); a system which supports exploratory information access to a document collection based on geo-referencing and visualization. It uses a gazetteer which contains representations of places ranging from countries to buildings, and that is used to recognize toponyms, disambiguate them into places, and to visualize the resulting spatial footprints.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [33.9007453918457, 4.524918556213379]}, {"key": "", "year": "", "title": "Ong2017siamese", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Siamese Network of Deep Fisher-Vector Descriptors for Image Retrieval\"\nauthors: Ong Eng-Jon, Husain Sameed, Bober Miroslaw\nconference: Arxiv\nyear: 2017\nbibkey: ong2017siamese\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1702.00338\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval']\n---\nThis paper addresses the problem of large scale image retrieval, with the aim of accurately ranking the similarity of a large number of images to a given query image. To achieve this, we propose a novel Siamese network. This network consists of two computational strands, each comprising of a CNN component followed by a Fisher vector component. The CNN component produces dense, deep convolutional descriptors that are then aggregated by the Fisher Vector method. Crucially, we propose to simultaneously learn both the CNN filter weights and Fisher Vector model parameters. This allows us to account for the evolving distribution of deep descriptors over the course of the learning process. We show that the proposed approach gives significant improvements over the state-of-the-art methods on the Oxford and Paris image retrieval datasets. Additionally, we provide a baseline performance measure for both these datasets with the inclusion of 1 million distractors.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.470535278320312, 27.27393913269043]}, {"key": "", "year": "", "title": "Ortega2022unconventional", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Unconventional application of k-means for distributed approximate similarity search\"\nauthors: Ortega Felipe, Algar Maria Jesus, de Diego Isaac Mart\u00edn, Moguerza Javier M.\nconference: Arxiv\nyear: 2022\nbibkey: ortega2022unconventional\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2208.02734\"}\ntags: ['ARXIV', 'TIP']\n---\nSimilarity search based on a distance function in metric spaces is a fundamental problem for many applications. Queries for similar objects lead to the well-known machine learning task of nearest-neighbours identification. Many data indexing strategies, collectively known as Metric Access Methods (MAM), have been proposed to speed up queries for similar elements in this context. Moreover, since exact approaches to solve similarity queries can be complex and time-consuming, alternative options have appeared to reduce query execution time, such as returning approximate results or resorting to distributed computing platforms. In this paper, we introduce MASK (Multilevel Approximate Similarity search with $k$-means), an unconventional application of the $k$-means algorithm as the foundation of a multilevel index structure for approximate similarity search, suitable for metric spaces. We show that inherent properties of $k$-means, like representing high-density data areas with fewer prototypes, can be leveraged for this purpose. An implementation of this new indexing method is evaluated, using a synthetic dataset and a real-world dataset in a high-dimensional and high-sparsity space. Results are promising and underpin the applicability of this novel indexing method in multiple domains.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [1.038906216621399, -20.11192512512207]}, {"key": "", "year": "", "title": "Ou2021integrating", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Integrating Semantics and Neighborhood Information with Graph-Driven Generative Models for Document Retrieval\"\nauthors: Ou Zijing, Su Qinliang, Yu Jianxing, Liu Bang, Wang Jingwen, Zhao Ruihui, Chen Changyou, Zheng Yefeng\nconference: ACL\nyear: 2021\nbibkey: ou2021integrating\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2105.13066\"}\ntags: ['ACL', 'Graph']\n---\nWith the need of fast retrieval speed and small memory footprint, document hashing has been playing a crucial role in large-scale information retrieval. To generate high-quality hashing code, both semantics and neighborhood information are crucial. However, most existing methods leverage only one of them or simply combine them via some intuitive criteria, lacking a theoretical principle to guide the integration process. In this paper, we encode the neighborhood information with a graph-induced Gaussian distribution, and propose to integrate the two types of information with a graph-driven generative model. To deal with the complicated correlations among documents, we further propose a tree-structured approximation method for learning. Under the approximation, we prove that the training objective can be decomposed into terms involving only singleton or pairwise documents, enabling the model to be trained as efficiently as uncorrelated ones. Extensive experimental results on three benchmark datasets show that our method achieves superior performance over state-of-the-art methods, demonstrating the effectiveness of the proposed model for simultaneously preserving semantic and neighborhood information.\\\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-16.651140213012695, 0.290611207485199]}, {"key": "", "year": "", "title": "Ou2021refining", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Refining BERT Embeddings for Document Hashing via Mutual Information Maximization\"\nauthors: Ou Zijing, Su Qinliang, Yu Jianxing, Zhao Ruihui, Zheng Yefeng, Liu Bang\nconference: Arxiv\nyear: 2021\nbibkey: ou2021refining\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2109.02867\"}\ntags: ['ARXIV', 'Supervised', 'Unsupervised']\n---\nExisting unsupervised document hashing methods are mostly established on generative models. Due to the difficulties of capturing long dependency structures, these methods rarely model the raw documents directly, but instead to model the features extracted from them (e.g. bag-of-words (BOW), TFIDF). In this paper, we propose to learn hash codes from BERT embeddings after observing their tremendous successes on downstream tasks. As a first try, we modify existing generative hashing models to accommodate the BERT embeddings. However, little improvement is observed over the codes learned from the old BOW or TFIDF features. We attribute this to the reconstruction requirement in the generative hashing, which will enforce irrelevant information that is abundant in the BERT embeddings also compressed into the codes. To remedy this issue, a new unsupervised hashing paradigm is further proposed based on the mutual information (MI) maximization principle. Specifically, the method first constructs appropriate global and local codes from the documents and then seeks to maximize their mutual information. Experimental results on three benchmark datasets demonstrate that the proposed method is able to generate hash codes that outperform existing ones learned from BOW features by a substantial margin.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-6.992757320404053, -3.693324327468872]}, {"key": "", "year": "", "title": "Ouyang2021contextual", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Contextual Similarity Aggregation with Self-attention for Visual Re-ranking\"\nauthors: Ouyang Jianbo, Wu Hui, Wang Min, Zhou Wengang, Li Houqiang\nconference: Arxiv\nyear: 2021\nbibkey: ouyang2021contextual\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2110.13430\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nIn content-based image retrieval, the first-round retrieval result by simple visual feature comparison may be unsatisfactory, which can be refined by visual re-ranking techniques. In image retrieval, it is observed that the contextual similarity among the top-ranked images is an important clue to distinguish the semantic relevance. Inspired by this observation, in this paper, we propose a visual re-ranking method by contextual similarity aggregation with self-attention. In our approach, for each image in the top-K ranking list, we represent it into an affinity feature vector by comparing it with a set of anchor images. Then, the affinity features of the top-K images are refined by aggregating the contextual information with a transformer encoder. Finally, the affinity features are used to recalculate the similarity scores between the query and the top-K images for re-ranking of the latter. To further improve the robustness of our re-ranking model and enhance the performance of our method, a new data augmentation scheme is designed. Since our re-ranking model is not directly involved with the visual feature used in the initial retrieval, it is ready to be applied to retrieval result lists obtained from various retrieval algorithms. We conduct comprehensive experiments on four benchmark datasets to demonstrate the generality and effectiveness of our proposed visual re-ranking method.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [20.964075088500977, 12.104668617248535]}, {"key": "", "year": "", "title": "Oymak2015near", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Near-Optimal Bounds for Binary Embeddings of Arbitrary Sets\"\nauthors: Oymak Samet, Recht Ben\nconference: Arxiv\nyear: 2015\nbibkey: oymak2015near\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1512.04433\"}\ntags: ['ARXIV']\n---\nWe study embedding a subset $K$ of the unit sphere to the Hamming cube $\\\\{-1,+1\\\\}^m$. We characterize the tradeoff between distortion and sample complexity $m$ in terms of the Gaussian width $\\omega(K)$ of the set. For subspaces and several structured sets we show that Gaussian maps provide the optimal tradeoff $m\\sim \\delta^\\{-2\\}\\omega^2(K)$, in particular for $\\delta$ distortion one needs $m\\approx\\delta^\\{-2\\}\\{d\\}$ where $d$ is the subspace dimension. For general sets, we provide sharp characterizations which reduces to $m\\approx\\{\\delta^\\{-4\\}\\}\\{\\omega^2(K)\\}$ after simplification. We provide improved results for local embedding of points that are in close proximity of each other which is related to locality sensitive hashing. We also discuss faster binary embedding where one takes advantage of an initial sketching procedure based on Fast Johnson-Lindenstauss Transform. Finally, we list several numerical observations and discuss open problems.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-9.586384773254395, -23.038227081298828]}, {"key": "", "year": "", "title": "Ozdemir2016scalable", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Scalable Gaussian Processes for Supervised Hashing\"\nauthors: Ozdemir Bahadir, Davis Larry S.\nconference: Arxiv\nyear: 2016\nbibkey: ozdemir2016scalable\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1604.07335\"}\ntags: ['ARXIV', 'Supervised']\n---\nWe propose a flexible procedure for large-scale image search by hash functions with kernels. Our method treats binary codes and pairwise semantic similarity as latent and observed variables, respectively, in a probabilistic model based on Gaussian processes for binary classification. We present an efficient inference algorithm with the sparse pseudo-input Gaussian process (SPGP) model and parallelization. Experiments on three large-scale image dataset demonstrate the effectiveness of the proposed hashing method, Gaussian Process Hashing (GPH), for short binary codes and the datasets without predefined classes in comparison to the state-of-the-art supervised hashing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [5.867353916168213, -0.8483400344848633]}, {"key": "", "year": "", "title": "Ozdemir2016supervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Supervised Incremental Hashing\"\nauthors: Ozdemir Bahadir, Najibi Mahyar, Davis Larry S.\nconference: Arxiv\nyear: 2016\nbibkey: ozdemir2016supervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1604.07342\"}\ntags: ['ARXIV', 'Supervised', 'Unsupervised']\n---\nWe propose an incremental strategy for learning hash functions with kernels for large-scale image search. Our method is based on a two-stage classification framework that treats binary codes as intermediate variables between the feature space and the semantic space. In the first stage of classification, binary codes are considered as class labels by a set of binary SVMs; each corresponds to one bit. In the second stage, binary codes become the input space of a multi-class SVM. Hash functions are learned by an efficient algorithm where the NP-hard problem of finding optimal binary codes is solved via cyclic coordinate descent and SVMs are trained in a parallelized incremental manner. For modifications like adding images from a previously unseen class, we describe an incremental procedure for effective and efficient updates to the previous hash functions. Experiments on three large-scale image datasets demonstrate the effectiveness of the proposed hashing method, Supervised Incremental Hashing (SIH), over the state-of-the-art supervised hashing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [5.695437908172607, -0.4917840361595154]}, {"key": "", "year": "", "title": "Ozsari2003a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Hash of Hash Functions\"\nauthors: Ozsari Turker\nconference: Arxiv\nyear: 2003\nbibkey: ozsari2003a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/cs/0310033\"}\ntags: ['ARXIV', 'Graph', 'Survey Paper']\n---\nIn this paper, we present a general review of hash functions in a cryptographic sense. We give special emphasis on some particular topics such as cipher block chaining message authentication code (CBC MAC) and its variants. This paper also broadens the information given in some well known surveys, by including more details on block-cipher based hash functions and security of different hash schemes.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-30.850339889526367, -1.3748844861984253]}, {"key": "", "year": "", "title": "Pachori2016zero", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Zero Shot Hashing\"\nauthors: Pachori Shubham, Raman Shanmuganathan\nconference: Arxiv\nyear: 2016\nbibkey: pachori2016zero\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1610.02651\"}\ntags: ['ARXIV', 'Supervised', 'Unsupervised']\n---\nThis paper provides a framework to hash images containing instances of unknown object classes. In many object recognition problems, we might have access to huge amount of data. It may so happen that even this huge data doesn't cover the objects belonging to classes that we see in our day to day life. Zero shot learning exploits auxiliary information (also called as signatures) in order to predict the labels corresponding to unknown classes. In this work, we attempt to generate the hash codes for images belonging to unseen classes, information of which is available only through the textual corpus. We formulate this as an unsupervised hashing formulation as the exact labels are not available for the instances of unseen classes. We show that the proposed solution is able to generate hash codes which can predict labels corresponding to unseen classes with appreciably good precision.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-10.487082481384277, 17.140201568603516]}, {"key": "", "year": "", "title": "Pachori2017hashing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hashing in the Zero Shot Framework with Domain Adaptation\"\nauthors: Pachori Shubham, Deshpande Ameya, Raman Shanmuganathan\nconference: Arxiv\nyear: 2017\nbibkey: pachori2017hashing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1702.01933\"}\ntags: ['ARXIV', 'Image Retrieval', 'Quantisation', 'Supervised', 'Unsupervised']\n---\nTechniques to learn hash codes which can store and retrieve large dimensional multimedia data efficiently have attracted broad research interests in the recent years. With rapid explosion of newly emerged concepts and online data, existing supervised hashing algorithms suffer from the problem of scarcity of ground truth annotations due to the high cost of obtaining manual annotations. Therefore, we propose an algorithm to learn a hash function from training images belonging to `seen' classes which can efficiently encode images of `unseen' classes to binary codes. Specifically, we project the image features from visual space and semantic features from semantic space into a common Hamming subspace. Earlier works to generate hash codes have tried to relax the discrete constraints on hash codes and solve the continuous optimization problem. However, it often leads to quantization errors. In this work, we use the max-margin classifier to learn an efficient hash function. To address the concern of domain-shift which may arise due to the introduction of new classes, we also introduce an unsupervised domain adaptation model in the proposed hashing framework. Results on the three datasets show the advantage of using domain adaptation in learning a high-quality hash function and superiority of our method for the task of image retrieval performance as compared to several state-of-the-art hashing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-6.160088539123535, 6.65595006942749]}, {"key": "", "year": "", "title": "Pacuk2016locality", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Locality-Sensitive Hashing without False Negatives for l_p\"\nauthors: Pacuk Andrzej, Sankowski Piotr, Wegrzycki Karol, Wygocki Piotr\nconference: Computing and Combinatorics -\nyear: 2016\nbibkey: pacuk2016locality\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1611.09317\"}\ntags: []\n---\nIn this paper, we show a construction of locality-sensitive hash functions without false negatives, i.e., which ensure collision for every pair of points within a given radius $R$ in $d$ dimensional space equipped with $l_p$ norm when $p \\in [1,\\infty]$. Furthermore, we show how to use these hash functions to solve the $c$-approximate nearest neighbor search problem without false negatives. Namely, if there is a point at distance $R$, we will certainly report it and points at distance greater than $cR$ will not be reported for $c=\\Omega(\\sqrt\\{d\\},d^\\{1-\\frac\\{1\\}\\{p\\}\\})$. The constructed algorithms work: - with preprocessing time $\\mathcal\\{O\\}(n \\log(n))$ and sublinear expected query time, - with preprocessing time $\\mathcal\\{O\\}(\\mathrm\\{poly\\}(n))$ and expected query time $\\mathcal\\{O\\}(\\log(n))$. Our paper reports progress on answering the open problem presented by Pagh [8] who considered the nearest neighbor search without false negatives for the Hamming distance.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-12.086433410644531, -24.089277267456055]}, {"key": "", "year": "", "title": "Pagh2006linear", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Linear Probing with Constant Independence\"\nauthors: Pagh Anna, Pagh Rasmus, Ruzic Milan\nconference: Arxiv\nyear: 2006\nbibkey: pagh2006linear\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/cs/0612055\"}\ntags: ['ARXIV', 'GAN']\n---\nHashing with linear probing dates back to the 1950s, and is among the most studied algorithms. In recent years it has become one of the most important hash table organizations since it uses the cache of modern computers very well. Unfortunately, previous analysis rely either on complicated and space consuming hash functions, or on the unrealistic assumption of free access to a truly random hash function. Already Carter and Wegman, in their seminal paper on universal hashing, raised the question of extending their analysis to linear probing. However, we show in this paper that linear probing using a pairwise independent family may have expected {\\em logarithmic} cost per operation. On the positive side, we show that 5-wise independence is enough to ensure constant expected time per operation. This resolves the question of finding a space and time efficient hash function that provably ensures good performance for linear probing.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-22.541452407836914, -9.181225776672363]}, {"key": "", "year": "", "title": "Pagh2015coveringlsh", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"CoveringLSH: Locality-sensitive Hashing without False Negatives\"\nauthors: Pagh Rasmus\nconference: Arxiv\nyear: 2015\nbibkey: pagh2015coveringlsh\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1507.03225\"}\ntags: ['ARXIV', 'LSH']\n---\nWe consider a new construction of locality-sensitive hash functions for Hamming space that is \\emph{covering} in the sense that is it guaranteed to produce a collision for every pair of vectors within a given radius $r$. The construction is \\emph{efficient} in the sense that the expected number of hash collisions between vectors at distance~$cr$, for a given $c&gt;1$, comes close to that of the best possible data independent LSH without the covering guarantee, namely, the seminal LSH construction of Indyk and Motwani (STOC '98). The efficiency of the new construction essentially \\emph{matches} their bound when the search radius is not too large --- e.g., when $cr = o(\\log(n)/\\log\\log n)$, where $n$ is the number of points in the data set, and when $cr = \\log(n)/k$ where $k$ is an integer constant. In general, it differs by at most a factor $\\ln(4)$ in the exponent of the time bounds. As a consequence, LSH-based similarity search in Hamming space can avoid the problem of false negatives at little or no cost in efficiency.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-11.345781326293945, -23.89484405517578]}, {"key": "", "year": "", "title": "Pagh2015io", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"I/O-Efficient Similarity Join\"\nauthors: Pagh Rasmus, Pham Ninh, Silvestri Francesco, St\u00f6ckel Morten\nconference: Arxiv\nyear: 2015\nbibkey: pagh2015io\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1507.00552\"}\ntags: ['ARXIV', 'LSH']\n---\nWe present an I/O-efficient algorithm for computing similarity joins based on locality-sensitive hashing (LSH). In contrast to the filtering methods commonly suggested our method has provable sub-quadratic dependency on the data size. Further, in contrast to straightforward implementations of known LSH-based algorithms on external memory, our approach is able to take significant advantage of the available internal memory: Whereas the time complexity of classical algorithms includes a factor of $N^\\rho$, where $\\rho$ is a parameter of the LSH used, the I/O complexity of our algorithm merely includes a factor $(N/M)^\\rho$, where $N$ is the data size and $M$ is the size of internal memory. Our algorithm is randomized and outputs the correct result with high probability. It is a simple, recursive, cache-oblivious procedure, and we believe that it will be useful also in other computational settings such as parallel computation.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-2.772547483444214, -15.905447006225586]}, {"key": "", "year": "", "title": "Paisitkriangkrai2014large", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Large-margin Learning of Compact Binary Image Encodings\"\nauthors: Paisitkriangkrai Sakrapee, Shen Chunhua, Hengel Anton van den\nconference: Arxiv\nyear: 2014\nbibkey: paisitkriangkrai2014large\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1402.6383\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nThe use of high-dimensional features has become a normal practice in many computer vision applications. The large dimension of these features is a limiting factor upon the number of data points which may be effectively stored and processed, however. We address this problem by developing a novel approach to learning a compact binary encoding, which exploits both pair-wise proximity and class-label information on training data set. Exploiting this extra information allows the development of encodings which, although compact, outperform the original high-dimensional features in terms of final classification or retrieval performance. The method is general, in that it is applicable to both non-parametric and parametric learning methods. This generality means that the embedded features are suitable for a wide variety of computer vision tasks, such as image classification and content-based image retrieval. Experimental results demonstrate that the new compact descriptor achieves an accuracy comparable to, and in some cases better than, the visual descriptor in the original space despite being significantly more compact. Moreover, any convex loss function and convex regularization penalty (e.g., $ \\ell_p $ norm with $ p \\ge 1 $) can be incorporated into the framework, which provides future flexibility.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [10.585460662841797, 10.230299949645996]}, {"key": "", "year": "", "title": "Palmer2023efficient", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Efficient Online String Matching through Linked Weak Factors\"\nauthors: Palmer Matthew N., Faro Simone, Scafiti Stefano\nconference: Arxiv\nyear: 2023\nbibkey: palmer2023efficient\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2310.15711\"}\ntags: ['ARXIV']\n---\nOnline string matching is a computational problem involving the search for patterns or substrings in a large text dataset, with the pattern and text being processed sequentially, without prior access to the entire text. Its relevance stems from applications in data compression, data mining, text editing, and bioinformatics, where rapid and efficient pattern matching is crucial. Various solutions have been proposed over the past few decades, employing diverse techniques. Recently, weak recognition approaches have attracted increasing attention. This paper presents Hash Chain, a new algorithm based on a robust weak factor recognition approach that connects adjacent factors through hashing. Despite its O(nm) complexity, the algorithm exhibits a sublinear behavior in practice and achieves superior performance compared to the most effective algorithms.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [0.06007428094744682, -11.582178115844727]}, {"key": "", "year": "", "title": "Pan2020tcdesc", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"TCDesc: Learning Topology Consistent Descriptors\"\nauthors: Pan Honghu, Meng Fanyang, He Zhenyu, Liang Yongsheng, Liu Wei\nconference: Arxiv\nyear: 2020\nbibkey: pan2020tcdesc\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2006.03254\"}\ntags: ['ARXIV']\n---\nTriplet loss is widely used for learning local descriptors from image patch. However, triplet loss only minimizes the Euclidean distance between matching descriptors and maximizes that between the non-matching descriptors, which neglects the topology similarity between two descriptor sets. In this paper, we propose topology measure besides Euclidean distance to learn topology consistent descriptors by considering kNN descriptors of positive sample. First we establish a novel topology vector for each descriptor followed by Locally Linear Embedding (LLE) to indicate the topological relation among the descriptor and its kNN descriptors. Then we define topology distance between descriptors as the difference of their topology vectors. Last we employ the dynamic weighting strategy to fuse Euclidean distance and topology distance of matching descriptors and take the fusion result as the positive sample distance in the triplet loss. Experimental results on several benchmarks show that our method performs better than state-of-the-arts results and effectively improves the performance of triplet loss.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [7.807195663452148, 2.875603675842285]}, {"key": "", "year": "", "title": "Pandey2022iceberght", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"IcebergHT: High Performance PMEM Hash Tables Through Stability and Low Associativity\"\nauthors: Pandey Prashant, Bender Michael A., Conway Alex, Farach-Colton Mart\u00edn, Kuszmaul William, Tagliavini Guido, Johnson Rob\nconference: Arxiv\nyear: 2022\nbibkey: pandey2022iceberght\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2210.04068\"}\ntags: ['ARXIV']\n---\nModern hash table designs strive to minimize space while maximizing speed. The most important factor in speed is the number of cache lines accessed during updates and queries. This is especially important on PMEM, which is slower than DRAM and in which writes are more expensive than reads. This paper proposes two stronger design objectives: stability and low-associativity. A stable hash table doesn't move items around, and a hash table has low associativity if there are only a few locations where an item can be stored. Low associativity ensures that queries need to examine only a few memory locations, and stability ensures that insertions write to very few cache lines. Stability also simplifies scaling and crash safety. We present IcebergHT, a fast, crash-safe, concurrent, and space-efficient hash table for PMEM based on the design principles of stability and low associativity. IcebergHT combines in-memory metadata with a new hashing technique, iceberg hashing, that is (1) space efficient, (2) stable, and (3) supports low associativity. In contrast, existing hash-tables either modify numerous cache lines during insertions (e.g. cuckoo hashing), access numerous cache lines during queries (e.g. linear probing), or waste space (e.g. chaining). Moreover, the combination of (1)-(3) yields several emergent benefits: IcebergHT scales better than other hash tables, supports crash-safety, and has excellent performance on PMEM (where writes are particularly expensive).\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-21.838212966918945, -17.618799209594727]}, {"key": "", "year": "", "title": "Panigrahy2004efficient", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Efficient Hashing with Lookups in two Memory Accesses\"\nauthors: Panigrahy Rina\nconference: Arxiv\nyear: 2004\nbibkey: panigrahy2004efficient\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/cs/0407023\"}\ntags: ['ARXIV']\n---\nThe study of hashing is closely related to the analysis of balls and bins. It is well-known that instead of using a single hash function if we randomly hash a ball into two bins and place it in the smaller of the two, then this dramatically lowers the maximum load on bins. This leads to the concept of two-way hashing where the largest bucket contains $O(\\log\\log n)$ balls with high probability. The hash look up will now search in both the buckets an item hashes to. Since an item may be placed in one of two buckets, we could potentially move an item after it has been initially placed to reduce maximum load. with a maximum load of We show that by performing moves during inserts, a maximum load of 2 can be maintained on-line, with high probability, while supporting hash update operations. In fact, with $n$ buckets, even if the space for two items are pre-allocated per bucket, as may be desirable in hardware implementations, more than $n$ items can be stored giving a high memory utilization. We also analyze the trade-off between the number of moves performed during inserts and the maximum load on a bucket. By performing at most $h$ moves, we can maintain a maximum load of $O(\\frac\\{\\log \\log n\\}\\{h \\log(\\log\\log n/h)\\})$. So, even by performing one move, we achieve a better bound than by performing no moves at all.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-17.088594436645508, -20.73797607421875]}, {"key": "", "year": "", "title": "Panigrahy2005entropy", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Entropy based Nearest Neighbor Search in High Dimensions\"\nauthors: Panigrahy Rina\nconference: Arxiv\nyear: 2005\nbibkey: panigrahy2005entropy\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/cs/0510019\"}\ntags: ['ARXIV']\n---\nIn this paper we study the problem of finding the approximate nearest neighbor of a query point in the high dimensional space, focusing on the Euclidean space. The earlier approaches use locality-preserving hash functions (that tend to map nearby points to the same value) to construct several hash tables to ensure that the query point hashes to the same bucket as its nearest neighbor in at least one table. Our approach is different -- we use one (or a few) hash table and hash several randomly chosen points in the neighborhood of the query point showing that at least one of them will hash to the bucket containing its nearest neighbor. We show that the number of randomly chosen points in the neighborhood of the query point $q$ required depends on the entropy of the hash value $h(p)$ of a random point $p$ at the same distance from $q$ at its nearest neighbor, given $q$ and the locality preserving hash function $h$ chosen randomly from the hash family. Precisely, we show that if the entropy $I(h(p)|q,h) = M$ and $g$ is a bound on the probability that two far-off points will hash to the same bucket, then we can find the approximate nearest neighbor in $O(n^\\rho)$ time and near linear $\\tilde O(n)$ space where $\\rho = M/\\log(1/g)$. Alternatively we can build a data structure of size $\\tilde O(n^\\{1/(1-\\rho)\\})$ to answer queries in $\\tilde O(d)$ time. By applying this analysis to the locality preserving hash functions in and adjusting the parameters we show that the $c$ nearest neighbor can be computed in time $\\tilde O(n^\\rho)$ and near linear space where $\\rho \\approx 2.06/c$ as $c$ becomes large.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-9.082427024841309, -25.40133285522461]}, {"key": "", "year": "", "title": "Paria2020minimizing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Minimizing FLOPs to Learn Efficient Sparse Representations\"\nauthors: Paria Biswajit, Yeh Chih-Kuan, Yen Ian E. H., Xu Ning, Ravikumar Pradeep, P\u00f3czos Barnab\u00e1s\nconference: Arxiv\nyear: 2020\nbibkey: paria2020minimizing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2004.05665\"}\ntags: ['ARXIV', 'Quantisation', 'TIP']\n---\nDeep representation learning has become one of the most widely adopted approaches for visual search, recommendation, and identification. Retrieval of such representations from a large database is however computationally challenging. Approximate methods based on learning compact representations, have been widely explored for this problem, such as locality sensitive hashing, product quantization, and PCA. In this work, in contrast to learning compact representations, we propose to learn high dimensional and sparse representations that have similar representational capacity as dense embeddings while being more efficient due to sparse matrix multiplication operations which can be much faster than dense multiplication. Following the key insight that the number of operations decreases quadratically with the sparsity of embeddings provided the non-zero entries are distributed uniformly across dimensions, we propose a novel approach to learn such distributed sparse embeddings via the use of a carefully constructed regularization function that directly minimizes a continuous relaxation of the number of floating-point operations (FLOPs) incurred during retrieval. Our experiments show that our approach is competitive to the other baselines and yields a similar or better speed-vs-accuracy tradeoff on practical datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-19.08879852294922, 5.283335208892822]}, {"key": "", "year": "", "title": "Park2016harrison", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"HARRISON: A Benchmark on HAshtag Recommendation for Real-world Images in Social Networks\"\nauthors: Park Minseok, Li Hanxiang, Kim Junmo\nconference: Arxiv\nyear: 2016\nbibkey: park2016harrison\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1605.05054\"}\ntags: ['ARXIV', 'CNN']\n---\nSimple, short, and compact hashtags cover a wide range of information on social networks. Although many works in the field of natural language processing (NLP) have demonstrated the importance of hashtag recommendation, hashtag recommendation for images has barely been studied. In this paper, we introduce the HARRISON dataset, a benchmark on hashtag recommendation for real world images in social networks. The HARRISON dataset is a realistic dataset, composed of 57,383 photos from Instagram and an average of 4.5 associated hashtags for each photo. To evaluate our dataset, we design a baseline framework consisting of visual feature extractor based on convolutional neural network (CNN) and multi-label classifier based on neural network. Based on this framework, two single feature-based models, object-based and scene-based model, and an integrated model of them are evaluated on the HARRISON dataset. Our dataset shows that hashtag recommendation task requires a wide and contextual understanding of the situation conveyed in the image. As far as we know, this work is the first vision-only attempt at hashtag recommendation for real world images in social networks. We expect this benchmark to accelerate the advancement of hashtag recommendation.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-7.426345348358154, 22.789337158203125]}, {"key": "", "year": "", "title": "Parkerholder2018compressing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Compressing Deep Neural Networks: A New Hashing Pipeline Using Kac's Random Walk Matrices\"\nauthors: Parker-Holder Jack, Gass Sam\nconference: Arxiv\nyear: 2018\nbibkey: parkerholder2018compressing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1801.02764\"}\ntags: ['ARXIV', 'Deep Learning']\n---\nThe popularity of deep learning is increasing by the day. However, despite the recent advancements in hardware, deep neural networks remain computationally intensive. Recent work has shown that by preserving the angular distance between vectors, random feature maps are able to reduce dimensionality without introducing bias to the estimator. We test a variety of established hashing pipelines as well as a new approach using Kac's random walk matrices. We demonstrate that this method achieves similar accuracy to existing pipelines.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-19.842294692993164, 13.92063045501709]}, {"key": "", "year": "", "title": "Passalis2019deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Supervised Hashing leveraging Quadratic Spherical Mutual Information for Content-based Image Retrieval\"\nauthors: Passalis Nikolaos, Tefas Anastasios\nconference: Arxiv\nyear: 2019\nbibkey: passalis2019deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1901.05135\"}\ntags: ['ARXIV', 'Image Retrieval', 'Supervised']\n---\nSeveral deep supervised hashing techniques have been proposed to allow for efficiently querying large image databases. However, deep supervised image hashing techniques are developed, to a great extent, heuristically often leading to suboptimal results. Contrary to this, we propose an efficient deep supervised hashing algorithm that optimizes the learned codes using an information-theoretic measure, the Quadratic Mutual Information (QMI). The proposed method is adapted to the needs of large-scale hashing and information retrieval leading to a novel information-theoretic measure, the Quadratic Spherical Mutual Information (QSMI). Apart from demonstrating the effectiveness of the proposed method under different scenarios and outperforming existing state-of-the-art image hashing techniques, this paper provides a structured way to model the process of information retrieval and develop novel methods adapted to the needs of each application.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-1.3699759244918823, 15.549264907836914]}, {"key": "", "year": "", "title": "Patrascu2010the", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"The Power of Simple Tabulation Hashing\"\nauthors: Patrascu Mihai, Thorup Mikkel\nconference: Arxiv\nyear: 2010\nbibkey: patrascu2010the\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1011.5200\"}\ntags: ['ARXIV']\n---\nRandomized algorithms are often enjoyed for their simplicity, but the hash functions used to yield the desired theoretical guarantees are often neither simple nor practical. Here we show that the simplest possible tabulation hashing provides unexpectedly strong guarantees. The scheme itself dates back to Carter and Wegman (STOC'77). Keys are viewed as consisting of c characters. We initialize c tables T_1, ..., T_c mapping characters to random hash codes. A key x=(x_1, ..., x_q) is hashed to T_1[x_1] xor ... xor T_c[x_c]. While this scheme is not even 4-independent, we show that it provides many of the guarantees that are normally obtained via higher independence, e.g., Chernoff-type concentration, min-wise hashing for estimating set intersection, and cuckoo hashing.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-19.975200653076172, -16.8215389251709]}, {"key": "", "year": "", "title": "Paulin2016convolutional", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Convolutional Patch Representations for Image Retrieval: an Unsupervised Approach\"\nauthors: Paulin Mattis  LEAR, Mairal Julien  LEAR, Douze Matthijs  LEAR, Harchaoui Zaid  NYU, Perronnin Florent  LEAR, Schmid Cordelia  LEAR\nconference: Arxiv\nyear: 2016\nbibkey: paulin2016convolutional\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1603.00438\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval', 'Supervised', 'Unsupervised']\n---\nConvolutional neural networks (CNNs) have recently received a lot of attention due to their ability to model local stationary structures in natural images in a multi-scale fashion, when learning all model parameters with supervision. While excellent performance was achieved for image classification when large amounts of labeled visual data are available, their success for un-supervised tasks such as image retrieval has been moderate so far. Our paper focuses on this latter setting and explores several methods for learning patch descriptors without supervision with application to matching and instance-level retrieval. To that effect, we propose a new family of convolutional descriptors for patch representation , based on the recently introduced convolutional kernel networks. We show that our descriptor, named Patch-CKN, performs better than SIFT as well as other convolutional networks learned by artificially introducing supervision and is significantly faster to train. To demonstrate its effectiveness, we perform an extensive evaluation on standard benchmarks for patch and image retrieval where we obtain state-of-the-art results. We also introduce a new dataset called RomePatches, which allows to simultaneously study descriptor performance for patch and image retrieval.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [10.2820405960083, 31.401336669921875]}, {"key": "", "year": "", "title": "Peer2023towards", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Towards Writer Retrieval for Historical Datasets\"\nauthors: Peer Marco, Kleber Florian, Sablatnig Robert\nconference: Arxiv\nyear: 2023\nbibkey: peer2023towards\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2305.05358\"}\ntags: ['ARXIV', 'Graph', 'Supervised', 'Unsupervised']\n---\nThis paper presents an unsupervised approach for writer retrieval based on clustering SIFT descriptors detected at keypoint locations resulting in pseudo-cluster labels. With those cluster labels, a residual network followed by our proposed NetRVLAD, an encoding layer with reduced complexity compared to NetVLAD, is trained on 32x32 patches at keypoint locations. Additionally, we suggest a graph-based reranking algorithm called SGR to exploit similarities of the page embeddings to boost the retrieval performance. Our approach is evaluated on two historical datasets (Historical-WI and HisIR19). We include an evaluation of different backbones and NetRVLAD. It competes with related work on historical datasets without using explicit encodings. We set a new State-of-the-art on both datasets by applying our reranking scheme and show that our approach achieves comparable performance on a modern dataset as well.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [2.778480052947998, -12.58491325378418]}, {"key": "", "year": "", "title": "Peng2018deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Reinforcement Learning for Image Hashing\"\nauthors: Peng Yuxin, Zhang Jian, Ye Zhaoda\nconference: Arxiv\nyear: 2018\nbibkey: peng2018deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1802.02904\"}\ntags: ['ARXIV']\n---\nDeep hashing methods have received much attention recently, which achieve promising results by taking advantage of the strong representation power of deep networks. However, most existing deep hashing methods learn a whole set of hashing functions independently, while ignore the correlations between different hashing functions that can promote the retrieval accuracy greatly. Inspired by the sequential decision ability of deep reinforcement learning, we propose a new Deep Reinforcement Learning approach for Image Hashing (DRLIH). Our proposed DRLIH approach models the hashing learning problem as a sequential decision process, which learns each hashing function by correcting the errors imposed by previous ones and promotes retrieval accuracy. To the best of our knowledge, this is the first work to address hashing problem from deep reinforcement learning perspective. The main contributions of our proposed DRLIH approach can be summarized as follows: (1) We propose a deep reinforcement learning hashing network. In the proposed network, we utilize recurrent neural network (RNN) as agents to model the hashing functions, which take actions of projecting images into binary codes sequentially, so that the current hashing function learning can take previous hashing functions' error into account. (2) We propose a sequential learning strategy based on proposed DRLIH. We define the state as a tuple of internal features of RNN's hidden layers and image features, which can reflect history decisions made by the agents. We also propose an action group method to enhance the correlation of hash functions in the same group. Experiments on three widely-used datasets demonstrate the effectiveness of our proposed DRLIH approach.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-12.629664421081543, 10.912424087524414]}, {"key": "", "year": "", "title": "Pham2016scalability", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Scalability and Total Recall with Fast CoveringLSH\"\nauthors: Pham Ninh, Pagh Rasmus\nconference: Arxiv\nyear: 2016\nbibkey: pham2016scalability\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1602.02620\"}\ntags: ['ARXIV', 'LSH']\n---\nLocality-sensitive hashing (LSH) has emerged as the dominant algorithmic technique for similarity search with strong performance guarantees in high-dimensional spaces. A drawback of traditional LSH schemes is that they may have \\emph{false negatives}, i.e., the recall is less than 100\\%. This limits the applicability of LSH in settings requiring precise performance guarantees. Building on the recent theoretical \"CoveringLSH\" construction that eliminates false negatives, we propose a fast and practical covering LSH scheme for Hamming space called \\emph{Fast CoveringLSH (fcLSH)}. Inheriting the design benefits of CoveringLSH our method avoids false negatives and always reports all near neighbors. Compared to CoveringLSH we achieve an asymptotic improvement to the hash function computation time from $\\mathcal\\{O\\}(dL)$ to $\\mathcal\\{O\\}(d + L\\log\\{L\\})$, where $d$ is the dimensionality of data and $L$ is the number of hash tables. Our experiments on synthetic and real-world data sets demonstrate that \\emph{fcLSH} is comparable (and often superior) to traditional hashing-based approaches for search radius up to 20 in high-dimensional Hamming space.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-5.494561195373535, -19.23912239074707]}, {"key": "", "year": "", "title": "Pham2018efficient", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Efficient texture retrieval using multiscale local extrema descriptors and covariance embedding\"\nauthors: Pham Minh-Tan\nconference: Arxiv\nyear: 2018\nbibkey: pham2018efficient\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1808.01124\"}\ntags: ['ARXIV', 'CNN']\n---\nThis paper presents an efficient method for texture retrieval using multiscale feature extraction and embedding based on the local extrema keypoints. The idea is to first represent each texture image by its local maximum and local minimum pixels. The image is then divided into regular overlapping blocks and each one is characterized by a feature vector constructed from the radiometric, geometric and structural information of its local extrema. All feature vectors are finally embedded into a covariance matrix which will be exploited for dissimilarity measurement within retrieval task. Thanks to the method's simplicity, multiscale scheme can be easily implemented to improve its scale-space representation capacity. We argue that our handcrafted features are easy to implement, fast to run but can provide very competitive performance compared to handcrafted and CNN-based learned descriptors from the literature. In particular, the proposed framework provides highly competitive retrieval rate for several texture databases including 94.95% for MIT Vistex, 79.87% for Stex, 76.15% for Outex TC-00013 and 89.74% for USPtex.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [19.708372116088867, 20.86411476135254]}, {"key": "", "year": "", "title": "Pham2022falconn", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Falconn++: A Locality-sensitive Filtering Approach for Approximate Nearest Neighbor Search\"\nauthors: Pham Ninh, Liu Tao\nconference: Arxiv\nyear: 2022\nbibkey: pham2022falconn\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2206.01382\"}\ntags: ['ARXIV', 'Graph']\n---\nWe present Falconn++, a novel locality-sensitive filtering approach for approximate nearest neighbor search on angular distance. Falconn++ can filter out potential far away points in any hash bucket \\textit{before} querying, which results in higher quality candidates compared to other hashing-based solutions. Theoretically, Falconn++ asymptotically achieves lower query time complexity than Falconn, an optimal locality-sensitive hashing scheme on angular distance. Empirically, Falconn++ achieves higher recall-speed tradeoffs than Falconn on many real-world data sets. Falconn++ is also competitive with HNSW, an efficient representative of graph-based solutions on high search recall regimes.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [8.71962833404541, -21.698259353637695]}, {"key": "", "year": "", "title": "Pibiri2021parallel", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Parallel and External-Memory Construction of Minimal Perfect Hash Functions with PTHash\"\nauthors: Pibiri Giulio Ermanno, Trani Roberto\nconference: Arxiv\nyear: 2021\nbibkey: pibiri2021parallel\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2106.02350\"}\ntags: ['ARXIV']\n---\nA function $f : U \\to \\\\{0,\\ldots,n-1\\\\}$ is a minimal perfect hash function for a set $S \\subseteq U$ of size $n$, if $f$ bijectively maps $S$ into the first $n$ natural numbers. These functions are important for many practical applications in computing, such as search engines, computer networks, and databases. Several algorithms have been proposed to build minimal perfect hash functions that: scale well to large sets, retain fast evaluation time, and take very little space, e.g., 2 - 3 bits/key. PTHash is one such algorithm, achieving very fast evaluation in compressed space, typically several times faster than other techniques. In this work, we propose a new construction algorithm for PTHash enabling: (1) multi-threading, to either build functions more quickly or more space-efficiently, and (2) external-memory processing to scale to inputs much larger than the available internal memory. Only few other algorithms in the literature share these features, despite of their big practical impact. We conduct an extensive experimental assessment on large real-world string collections and show that, with respect to other techniques, PTHash is competitive in construction time and space consumption, but retains 2 - 6$\\times$ better lookup time.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-17.17986488342285, -16.354169845581055]}, {"key": "", "year": "", "title": "Pibiri2021pthash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"PTHash: Revisiting FCH Minimal Perfect Hashing\"\nauthors: Pibiri Giulio Ermanno, Trani Roberto\nconference: SIGIR\nyear: 2021\nbibkey: pibiri2021pthash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2104.10402\"}\ntags: []\n---\nGiven a set $S$ of $n$ distinct keys, a function $f$ that bijectively maps the keys of $S$ into the range $\\\\{0,\\ldots,n-1\\\\}$ is called a minimal perfect hash function for $S$. Algorithms that find such functions when $n$ is large and retain constant evaluation time are of practical interest; for instance, search engines and databases typically use minimal perfect hash functions to quickly assign identifiers to static sets of variable-length keys such as strings. The challenge is to design an algorithm which is efficient in three different aspects: time to find $f$ (construction time), time to evaluate $f$ on a key of $S$ (lookup time), and space of representation for $f$. Several algorithms have been proposed to trade-off between these aspects. In 1992, Fox, Chen, and Heath (FCH) presented an algorithm at SIGIR providing very fast lookup evaluation. However, the approach received little attention because of its large construction time and higher space consumption compared to other subsequent techniques. Almost thirty years later we revisit their framework and present an improved algorithm that scales well to large sets and reduces space consumption altogether, without compromising the lookup time. We conduct an extensive experimental assessment and show that the algorithm finds functions that are competitive in space with state-of-the art techniques and provide $2-4\\times$ better lookup time.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-16.79734230041504, -16.49081802368164]}, {"key": "", "year": "", "title": "Pibiri2022locality", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Locality-Preserving Minimal Perfect Hashing of k-mers\"\nauthors: Pibiri Giulio Ermanno, Shibuya Yoshihiro, Limasset Antoine\nconference: Arxiv\nyear: 2022\nbibkey: pibiri2022locality\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2210.13097\"}\ntags: ['ARXIV']\n---\nMinimal perfect hashing is the problem of mapping a static set of $n$ distinct keys into the address space $\\\\{1,\\ldots,n\\\\}$ bijectively. It is well-known that $n\\log_2(e)$ bits are necessary to specify a minimal perfect hash function (MPHF) $f$, when no additional knowledge of the input keys is to be used. However, it is often the case in practice that the input keys have intrinsic relationships that we can exploit to lower the bit complexity of $f$. For example, consider a string and the set of all its distinct $k$-mers as input keys: since two consecutive $k$-mers share an overlap of $k-1$ symbols, it seems possible to beat the classic $\\log_2(e)$ bits/key barrier in this case. Moreover, we would like $f$ to map consecutive $k$-mers to consecutive addresses, as to also preserve as much as possible their relationship in the codomain. This is a useful feature in practice as it guarantees a certain degree of locality of reference for $f$, resulting in a better evaluation time when querying consecutive $k$-mers. Motivated by these premises, we initiate the study of a new type of locality-preserving MPHF designed for $k$-mers extracted consecutively from a collection of strings. We design a construction whose space usage decreases for growing $k$ and discuss experiments with a practical implementation of the method: in practice, the functions built with our method can be several times smaller and even faster to query than the most efficient MPHFs in the literature.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-15.672045707702637, -17.19327735900879]}, {"key": "", "year": "", "title": "Plummer2015flickr30k", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models\"\nauthors: Plummer Bryan A., Wang Liwei, Cervantes Chris M., Caicedo Juan C., Hockenmaier Julia, Lazebnik Svetlana\nconference: Arxiv\nyear: 2015\nbibkey: plummer2015flickr30k\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1505.04870\"}\ntags: ['ARXIV', 'TOM']\n---\nThe Flickr30k dataset has become a standard benchmark for sentence-based image description. This paper presents Flickr30k Entities, which augments the 158k captions from Flickr30k with 244k coreference chains, linking mentions of the same entities across different captions for the same image, and associating them with 276k manually annotated bounding boxes. Such annotations are essential for continued progress in automatic image description and grounded language understanding. They enable us to define a new benchmark for localization of textual entity mentions in an image. We present a strong baseline for this task that combines an image-text embedding, detectors for common objects, a color classifier, and a bias towards selecting larger objects. While our baseline rivals in accuracy more complex state-of-the-art models, we show that its gains cannot be easily parlayed into improvements on such tasks as image-sentence retrieval, thus underlining the limitations of current methods and the need for further research.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [19.426727294921875, 2.858013153076172]}, {"key": "", "year": "", "title": "Podlesnaya2016deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Learning Based Semantic Video Indexing and Retrieval\"\nauthors: Podlesnaya Anna, Podlesnyy Sergey\nconference: Arxiv\nyear: 2016\nbibkey: podlesnaya2016deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1601.07754\"}\ntags: ['ARXIV', 'Deep Learning', 'Graph', 'Video Retrieval']\n---\nWe share the implementation details and testing results for video retrieval system based exclusively on features extracted by convolutional neural networks. We show that deep learned features might serve as universal signature for semantic content of video useful in many search and retrieval tasks. We further show that graph-based storage structure for video index allows to efficiently retrieving the content with complicated spatial and temporal search queries.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [13.598251342773438, 21.214096069335938]}, {"key": "", "year": "", "title": "Porat2008an", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"An Optimal Bloom Filter Replacement Based on Matrix Solving\"\nauthors: Porat Ely\nconference: Arxiv\nyear: 2008\nbibkey: porat2008an\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/0804.1845\"}\ntags: ['ARXIV']\n---\nWe suggest a method for holding a dictionary data structure, which maps keys to values, in the spirit of Bloom Filters. The space requirements of the dictionary we suggest are much smaller than those of a hashtable. We allow storing n keys, each mapped to value which is a string of k bits. Our suggested method requires nk + o(n) bits space to store the dictionary, and O(n) time to produce the data structure, and allows answering a membership query in O(1) memory probes. The dictionary size does not depend on the size of the keys. However, reducing the space requirements of the data structure comes at a certain cost. Our dictionary has a small probability of a one sided error. When attempting to obtain the value for a key that is stored in the dictionary we always get the correct answer. However, when testing for membership of an element that is not stored in the dictionary, we may get an incorrect answer, and when requesting the value of such an element we may get a certain random value. Our method is based on solving equations in GF(2^k) and using several hash functions. Another significant advantage of our suggested method is that we do not require using sophisticated hash functions. We only require pairwise independent hash functions. We also suggest a data structure that requires only nk bits space, has O(n2) preprocessing time, and has a O(log n) query time. However, this data structures requires a uniform hash functions. In order replace a Bloom Filter of n elements with an error proability of 2^{-k}, we require nk + o(n) memory bits, O(1) query time, O(n) preprocessing time, and only pairwise independent hash function. Even the most advanced previously known Bloom Filter would require nk+O(n) space, and a uniform hash functions, so our method is significantly less space consuming especially when k is small.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-14.20156192779541, -17.041929244995117]}, {"key": "", "year": "", "title": "Porat2011a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A cuckoo hashing variant with improved memory utilization and insertion time\"\nauthors: Porat Ely, Shalem Bar\nconference: Arxiv\nyear: 2011\nbibkey: porat2011a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1104.5400\"}\ntags: ['ARXIV', 'TIP']\n---\nCuckoo hashing [4] is a multiple choice hashing scheme in which each item can be placed in multiple locations, and collisions are resolved by moving items to their alternative locations. In the classical implementation of two-way cuckoo hashing, the memory is partitioned into contiguous disjoint fixed-size buckets. Each item is hashed to two buckets, and may be stored in any of the positions within those buckets. Ref. [2] analyzed a variation in which the buckets are contiguous and overlap. However, many systems retrieve data from secondary storage in same-size blocks called pages. Fetching a page is a relatively expensive process; but once a page is fetched, its contents can be accessed orders of magnitude faster. We utilize this property of memory retrieval, presenting a variant of cuckoo hashing incorporating the following constraint: each bucket must be fully contained in a single page, but buckets are not necessarily contiguous. Empirical results show that this modification increases memory utilization and decreases the number of iterations required to insert an item. If each item is hashed to two buckets of capacity two, the page size is 8, and each bucket is fully contained in a single page, the memory utilization equals 89.71% in the classical contiguous disjoint bucket variant, 93.78% in the contiguous overlapping bucket variant, and increases to 97.46% in our new non-contiguous bucket variant. When the memory utilization is 92% and we use breadth first search to look for a vacant position, the number of iterations required to insert a new item is dramatically reduced from 545 in the contiguous overlapping buckets variant to 52 in our new non-contiguous bucket variant. In addition to the empirical results, we present a theoretical lower bound on the memory utilization of our variation as a function of the page size.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-18.618736267089844, -19.321592330932617]}, {"key": "", "year": "", "title": "Portaz2019image", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Image search using multilingual texts: a cross-modal learning approach between image and text\"\nauthors: Portaz Maxime  CEDRIC, Randrianarivo Hicham  CEDRIC, Nivaggioli Adrien  LIUM, Maudet Estelle  LIUM, Servan Christophe  LIUM, Peyronnet Sylvain  ELM\nconference: Arxiv\nyear: 2019\nbibkey: portaz2019image\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1903.11299\"}\ntags: ['ARXIV', 'Cross Modal']\n---\nMultilingual (or cross-lingual) embeddings represent several languages in a unique vector space. Using a common embedding space enables for a shared semantic between words from different languages. In this paper, we propose to embed images and texts into a unique distributional vector space, enabling to search images by using text queries expressing information needs related to the (visual) content of images, as well as using image similarity. Our framework forces the representation of an image to be similar to the representation of the text that describes it. Moreover, by using multilingual embeddings we ensure that words from two different languages have close descriptors and thus are attached to similar images. We provide experimental evidence of the efficiency of our approach by experimenting it on two datasets: Common Objects in COntext (COCO) [19] and Multi30K [7].\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [25.557113647460938, 3.193803310394287]}, {"key": "", "year": "", "title": "Portegys2015general", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"General Graph Identification By Hashing\"\nauthors: Portegys Tom\nconference: Arxiv\nyear: 2015\nbibkey: portegys2015general\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1512.07263\"}\ntags: ['ARXIV', 'Graph']\n---\nA method for identifying graphs using MD5 hashing is presented. This allows fast graph equality comparisons and can also be used to facilitate graph isomorphism testing. The graphs can be labeled or unlabeled. The method identifies vertices by hashing the graph configuration in their neighborhoods. With each vertex hashed, the entire graph can be identified by hashing the vertex hashes.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [7.990872859954834, -32.67194366455078]}, {"key": "", "year": "", "title": "Pratap2017efficient", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Efficient Compression Technique for Sparse Sets\"\nauthors: Pratap Rameshwar, Sohony Ishan, Kulkarni Raghav\nconference: Arxiv\nyear: 2017\nbibkey: pratap2017efficient\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1708.04799\"}\ntags: ['ARXIV']\n---\nRecent technological advancements have led to the generation of huge amounts of data over the web, such as text, image, audio and video. Most of this data is high dimensional and sparse, for e.g., the bag-of-words representation used for representing text. Often, an efficient search for similar data points needs to be performed in many applications like clustering, nearest neighbour search, ranking and indexing. Even though there have been significant increases in computational power, a simple brute-force similarity-search on such datasets is inefficient and at times impossible. Thus, it is desirable to get a compressed representation which preserves the similarity between data points. In this work, we consider the data points as sets and use Jaccard similarity as the similarity measure. Compression techniques are generally evaluated on the following parameters --1) Randomness required for compression, 2) Time required for compression, 3) Dimension of the data after compression, and 4) Space required to store the compressed data. Ideally, the compressed representation of the data should be such, that the similarity between each pair of data points is preserved, while keeping the time and the randomness required for compression as low as possible. We show that the compression technique suggested by Pratap and Kulkarni also works well for Jaccard similarity. We present a theoretical proof of the same and complement it with rigorous experimentations on synthetic as well as real-world datasets. We also compare our results with the state-of-the-art \"min-wise independent permutation\", and show that our compression algorithm achieves almost equal accuracy while significantly reducing the compression time and the randomness.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-10.072114944458008, -9.815010070800781]}, {"key": "", "year": "", "title": "Pratt2012a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A combinatorial analysis of the average time for open-address hash coding insertion\"\nauthors: Pratt Vaughan R.\nconference: Arxiv\nyear: 2012\nbibkey: pratt2012a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1208.5956\"}\ntags: ['ARXIV']\n---\nIn analysing a well-known hash-coding method, Knuth gave an exact expression for the average number of rejections encountered by players of a variant of musical chairs. We study a variant more closely related to musical chairs itself and deduce the same expression by a purely combinatorial approach.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-32.86799621582031, -3.742328643798828]}, {"key": "", "year": "", "title": "Prezza2023algorithms", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Algorithms for Massive Data -- Lecture Notes\"\nauthors: Prezza Nicola\nconference: Arxiv\nyear: 2023\nbibkey: prezza2023algorithms\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2301.00754\"}\ntags: ['ARXIV']\n---\nThese are the lecture notes for the course CM0622 - Algorithms for Massive Data, Ca' Foscari University of Venice. The goal of this course is to introduce algorithmic techniques for dealing with massive data: data so large that it does not fit in the computer's memory. There are two main solutions to deal with massive data: (lossless) compressed data structures and (lossy) data sketches. These notes cover both topics: compressed suffix arrays, probabilistic filters, sketching under various metrics, Locality Sensitive Hashing, nearest neighbour search, algorithms on streams (pattern matching, counting).\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [21.28037452697754, -10.18873119354248]}, {"key": "", "year": "", "title": "Prokopec2017analysis", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Analysis of Concurrent Lock-Free Hash Tries with Constant-Time Operations\"\nauthors: Prokopec Aleksandar\nconference: Arxiv\nyear: 2017\nbibkey: prokopec2017analysis\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1712.09636\"}\ntags: ['ARXIV']\n---\nCtrie is a scalable concurrent non-blocking dictionary data structure, with good cache locality, and non-blocking linearizable iterators. However, operations on most existing concurrent hash tries run in O(log n) time. In this technical report, we extend the standard concurrent hash-tries with an auxiliary data structure called a cache. The cache is essentially an array that stores pointers to a specific level of the hash trie. We analyze the performance implications of adding a cache, and prove that the running time of the basic operations becomes O(1).\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-26.76346778869629, -12.997145652770996]}, {"key": "", "year": "", "title": "Pronobis2016sharing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Sharing Hash Codes for Multiple Purposes\"\nauthors: Pronobis Wikor, Panknin Danny, Kirschnick Johannes, Srinivasan Vignesh, Samek Wojciech, Markl Volker, Kaul Manohar, Mueller Klaus-Robert, Nakajima Shinichi\nconference: Arxiv\nyear: 2016\nbibkey: pronobis2016sharing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1609.03219\"}\ntags: ['ARXIV', 'LSH', 'TIP', 'Video Retrieval']\n---\nLocality sensitive hashing (LSH) is a powerful tool for sublinear-time approximate nearest neighbor search, and a variety of hashing schemes have been proposed for different dissimilarity measures. However, hash codes significantly depend on the dissimilarity, which prohibits users from adjusting the dissimilarity at query time. In this paper, we propose {multiple purpose LSH (mp-LSH) which shares the hash codes for different dissimilarities. mp-LSH supports L2, cosine, and inner product dissimilarities, and their corresponding weighted sums, where the weights can be adjusted at query time. It also allows us to modify the importance of pre-defined groups of features. Thus, mp-LSH enables us, for example, to retrieve similar items to a query with the user preference taken into account, to find a similar material to a query with some properties (stability, utility, etc.) optimized, and to turn on or off a part of multi-modal information (brightness, color, audio, text, etc.) in image/video retrieval. We theoretically and empirically analyze the performance of three variants of mp-LSH, and demonstrate their usefulness on real-world data sets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [5.428078651428223, 4.678769111633301]}, {"key": "", "year": "", "title": "P\u00f6schko2011exploring", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Exploring Twitter Hashtags\"\nauthors: P\u00f6schko Jan\nconference: Arxiv\nyear: 2011\nbibkey: p\u00f6schko2011exploring\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1111.6553\"}\ntags: ['ARXIV']\n---\nTwitter messages often contain so-called hashtags to denote keywords related to them. Using a dataset of 29 million messages, I explore relations among these hashtags with respect to co-occurrences. Furthermore, I present an attempt to classify hashtags into five intuitive classes, using a machine-learning approach. The overall outcome is an interactive Web application to explore Twitter hashtags.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-26.750089645385742, 8.719204902648926]}, {"key": "", "year": "", "title": "Qasemizadeh2017sketching", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Sketching Word Vectors Through Hashing\"\nauthors: QasemiZadeh Behrang, Kallmeyer Laura\nconference: Arxiv\nyear: 2017\nbibkey: qasemizadeh2017sketching\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1705.04253\"}\ntags: ['ARXIV']\n---\nWe propose a new fast word embedding technique using hash functions. The method is a derandomization of a new type of random projections: By disregarding the classic constraint used in designing random projections (i.e., preserving pairwise distances in a particular normed space), our solution exploits extremely sparse non-negative random projections. Our experiments show that the proposed method can achieve competitive results, comparable to neural embedding learning techniques, however, with only a fraction of the computational complexity of these methods. While the proposed derandomization enhances the computational and space complexity of our method, the possibility of applying weighting methods such as positive pointwise mutual information (PPMI) to our models after their construction (and at a reduced dimensionality) imparts a high discriminatory power to the resulting embeddings. Obviously, this method comes with other known benefits of random projection-based techniques such as ease of update.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-6.780653476715088, -12.014866828918457]}, {"key": "", "year": "", "title": "Qi2017an", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"An efficient deep learning hashing neural network for mobile visual search\"\nauthors: Qi Heng, Liu Wu, Liu Liang\nconference: Arxiv\nyear: 2017\nbibkey: qi2017an\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1710.07750\"}\ntags: ['ARXIV', 'Deep Learning']\n---\nMobile visual search applications are emerging that enable users to sense their surroundings with smart phones. However, because of the particular challenges of mobile visual search, achieving a high recognition bitrate has becomes a consistent target of previous related works. In this paper, we propose a few-parameter, low-latency, and high-accuracy deep hashing approach for constructing binary hash codes for mobile visual search. First, we exploit the architecture of the MobileNet model, which significantly decreases the latency of deep feature extraction by reducing the number of model parameters while maintaining accuracy. Second, we add a hash-like layer into MobileNet to train the model on labeled mobile visual data. Evaluations show that the proposed system can exceed state-of-the-art accuracy performance in terms of the MAP. More importantly, the memory consumption is much less than that of other deep learning models. The proposed method requires only $13$ MB of memory for the neural network and achieves a MAP of $97.80\\%$ on the mobile location recognition dataset used for testing.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-23.493791580200195, 16.903013229370117]}, {"key": "", "year": "", "title": "Qian2015similarity", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Similarity Learning via Adaptive Regression and Its Application to Image Retrieval\"\nauthors: Qian Qi, Baytas Inci M., Jin Rong, Jain Anil, Zhu Shenghuo\nconference: Arxiv\nyear: 2015\nbibkey: qian2015similarity\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1512.01728\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nWe study the problem of similarity learning and its application to image retrieval with large-scale data. The similarity between pairs of images can be measured by the distances between their high dimensional representations, and the problem of learning the appropriate similarity is often addressed by distance metric learning. However, distance metric learning requires the learned metric to be a PSD matrix, which is computational expensive and not necessary for retrieval ranking problem. On the other hand, the bilinear model is shown to be more flexible for large-scale image retrieval task, hence, we adopt it to learn a matrix for estimating pairwise similarities under the regression framework. By adaptively updating the target matrix in regression, we can mimic the hinge loss, which is more appropriate for similarity learning problem. Although the regression problem can have the closed-form solution, the computational cost can be very expensive. The computational challenges come from two aspects: the number of images can be very large and image features have high dimensionality. We address the first challenge by compressing the data by a randomized algorithm with the theoretical guarantee. For the high dimensional issue, we address it by taking low rank assumption and applying alternating method to obtain the partial matrix, which has a global optimal solution. Empirical studies on real world image datasets (i.e., Caltech and ImageNet) demonstrate the effectiveness and efficiency of the proposed method.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.235676765441895, 6.611627578735352]}, {"key": "", "year": "", "title": "Qiao2019deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Heterogeneous Hashing for Face Video Retrieval\"\nauthors: Qiao Shishi, Wang Ruiping, Shan Shiguang, Chen Xilin\nconference: IEEE Transactions on Image Processing\nyear: 2019\nbibkey: qiao2019deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1911.01048\"}\ntags: ['Video Retrieval']\n---\nRetrieving videos of a particular person with face image as a query via hashing technique has many important applications. While face images are typically represented as vectors in Euclidean space, characterizing face videos with some robust set modeling techniques (e.g. covariance matrices as exploited in this study, which reside on Riemannian manifold), has recently shown appealing advantages. This hence results in a thorny heterogeneous spaces matching problem. Moreover, hashing with handcrafted features as done in many existing works is clearly inadequate to achieve desirable performance for this task. To address such problems, we present an end-to-end Deep Heterogeneous Hashing (DHH) method that integrates three stages including image feature learning, video modeling, and heterogeneous hashing in a single framework, to learn unified binary codes for both face images and videos. To tackle the key challenge of hashing on the manifold, a well-studied Riemannian kernel mapping is employed to project data (i.e. covariance matrices) into Euclidean space and thus enables to embed the two heterogeneous representations into a common Hamming space, where both intra-space discriminability and inter-space compatibility are considered. To perform network optimization, the gradient of the kernel mapping is innovatively derived via structured matrix backpropagation in a theoretically principled way. Experiments on three challenging datasets show that our method achieves quite competitive performance compared with existing hashing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-1.8398350477218628, 28.665660858154297]}, {"key": "", "year": "", "title": "Qiao2023talds", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"TALDS-Net: Task-Aware Adaptive Local Descriptors Selection for Few-shot Image Classification\"\nauthors: Qiao Qian, Xie Yu, Zeng Ziyin, Li Fanzhang\nconference: Arxiv\nyear: 2023\nbibkey: qiao2023talds\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2312.05449\"}\ntags: ['ARXIV']\n---\nFew-shot image classification aims to classify images from unseen novel classes with few samples. Recent works demonstrate that deep local descriptors exhibit enhanced representational capabilities compared to image-level features. However, most existing methods solely rely on either employing all local descriptors or directly utilizing partial descriptors, potentially resulting in the loss of crucial information. Moreover, these methods primarily emphasize the selection of query descriptors while overlooking support descriptors. In this paper, we propose a novel Task-Aware Adaptive Local Descriptors Selection Network (TALDS-Net), which exhibits the capacity for adaptive selection of task-aware support descriptors and query descriptors. Specifically, we compare the similarity of each local support descriptor with other local support descriptors to obtain the optimal support descriptor subset and then compare the query descriptors with the optimal support subset to obtain discriminative query descriptors. Extensive experiments demonstrate that our TALDS-Net outperforms state-of-the-art methods on both general and fine-grained datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [18.685470581054688, 17.01763916015625]}, {"key": "", "year": "", "title": "Qin2024efficient", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Efficient Graph Encoder Embedding for Large Sparse Graphs in Python\"\nauthors: Qin Xihan, Shen Cencheng\nconference: Arxiv\nyear: 2024\nbibkey: qin2024efficient\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2406.03726\"}\ntags: ['ARXIV', 'Graph']\n---\nGraph is a ubiquitous representation of data in various research fields, and graph embedding is a prevalent machine learning technique for capturing key features and generating fixed-sized attributes. However, most state-of-the-art graph embedding methods are computationally and spatially expensive. Recently, the Graph Encoder Embedding (GEE) has been shown as the fastest graph embedding technique and is suitable for a variety of network data applications. As real-world data often involves large and sparse graphs, the huge sparsity usually results in redundant computations and storage. To address this issue, we propose an improved version of GEE, sparse GEE, which optimizes the calculation and storage of zero entries in sparse matrices to enhance the running time further. Our experiments demonstrate that the sparse version achieves significant speedup compared to the original GEE with Python implementation for large sparse graphs, and sparse GEE is capable of processing millions of edges within minutes on a standard laptop.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [5.704336166381836, -30.291851043701172]}, {"key": "", "year": "", "title": "Qiu2014random", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Random Forests Can Hash\"\nauthors: Qiu Qiang, Sapiro Guillermo, Bronstein Alex\nconference: Arxiv\nyear: 2014\nbibkey: qiu2014random\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1412.5083\"}\ntags: ['ARXIV', 'Deep Learning']\n---\nHash codes are a very efficient data representation needed to be able to cope with the ever growing amounts of data. We introduce a random forest semantic hashing scheme with information-theoretic code aggregation, showing for the first time how random forest, a technique that together with deep learning have shown spectacular results in classification, can also be extended to large-scale retrieval. Traditional random forest fails to enforce the consistency of hashes generated from each tree for the same class data, i.e., to preserve the underlying similarity, and it also lacks a principled way for code aggregation across trees. We start with a simple hashing scheme, where independently trained random trees in a forest are acting as hashing functions. We the propose a subspace model as the splitting function, and show that it enforces the hash consistency in a tree for data from the same class. We also introduce an information-theoretic approach for aggregating codes of individual trees into a single hash code, producing a near-optimal unique hash for each class. Experiments on large-scale public datasets are presented, showing that the proposed approach significantly outperforms state-of-the-art hashing methods for retrieval tasks.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-11.01757526397705, -12.188825607299805]}, {"key": "", "year": "", "title": "Qiu2017foresthash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"ForestHash: Semantic Hashing With Shallow Random Forests and Tiny Convolutional Networks\"\nauthors: Qiu Qiang, Lezama Jose, Bronstein Alex, Sapiro Guillermo\nconference: Arxiv\nyear: 2017\nbibkey: qiu2017foresthash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1711.08364\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval']\n---\nHash codes are efficient data representations for coping with the ever growing amounts of data. In this paper, we introduce a random forest semantic hashing scheme that embeds tiny convolutional neural networks (CNN) into shallow random forests, with near-optimal information-theoretic code aggregation among trees. We start with a simple hashing scheme, where random trees in a forest act as hashing functions by setting `1' for the visited tree leaf, and `0' for the rest. We show that traditional random forests fail to generate hashes that preserve the underlying similarity between the trees, rendering the random forests approach to hashing challenging. To address this, we propose to first randomly group arriving classes at each tree split node into two groups, obtaining a significantly simplified two-class classification problem, which can be handled using a light-weight CNN weak learner. Such random class grouping scheme enables code uniqueness by enforcing each class to share its code with different classes in different trees. A non-conventional low-rank loss is further adopted for the CNN weak learners to encourage code consistency by minimizing intra-class variations and maximizing inter-class distance for the two random class groups. Finally, we introduce an information-theoretic approach for aggregating codes of individual trees into a single hash code, producing a near-optimal unique hash for each class. The proposed approach significantly outperforms state-of-the-art hashing methods for image retrieval tasks on large-scale public datasets, while performing at the level of other state-of-the-art image classification techniques while utilizing a more compact and efficient scalable representation. This work proposes a principled and robust procedure to train and deploy in parallel an ensemble of light-weight CNNs, instead of simply going deeper.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-11.00947093963623, -12.189695358276367]}, {"key": "", "year": "", "title": "Qiu2018deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Semantic Hashing with Generative Adversarial Networks\"\nauthors: Qiu Zhaofan, Pan Yingwei, Yao Ting, Mei Tao\nconference: Arxiv\nyear: 2018\nbibkey: qiu2018deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1804.08275\"}\ntags: ['ACL', 'ARXIV', 'CNN', 'GAN', 'Image Retrieval', 'Semi Supervised', 'Supervised']\n---\nHashing has been a widely-adopted technique for nearest neighbor search in large-scale image retrieval tasks. Recent research has shown that leveraging supervised information can lead to high quality hashing. However, the cost of annotating data is often an obstacle when applying supervised hashing to a new domain. Moreover, the results can suffer from the robustness problem as the data at training and test stage could come from similar but different distributions. This paper studies the exploration of generating synthetic data through semi-supervised generative adversarial networks (GANs), which leverages largely unlabeled and limited labeled training data to produce highly compelling data with intrinsic invariance and global coherence, for better understanding statistical structures of natural data. We demonstrate that the above two limitations can be well mitigated by applying the synthetic data for hashing. Specifically, a novel deep semantic hashing with GANs (DSH-GANs) is presented, which mainly consists of four components: a deep convolution neural networks (CNN) for learning image representations, an adversary stream to distinguish synthetic images from real ones, a hash stream for encoding image representations to hash codes and a classification stream. The whole architecture is trained end-to-end by jointly optimizing three losses, i.e., adversarial loss to correct label of synthetic or real for each sample, triplet ranking loss to preserve the relative similarity ordering in the input real-synthetic triplets and classification loss to classify each sample accurately. Extensive experiments conducted on both CIFAR-10 and NUS-WIDE image benchmarks validate the capability of exploiting synthetic images for hashing. Our framework also achieves superior results when compared to state-of-the-art deep hash models.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-8.57909107208252, 7.279230117797852]}, {"key": "", "year": "", "title": "Qiu2021unsupervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Unsupervised Hashing with Contrastive Information Bottleneck\"\nauthors: Qiu Zexuan, Su Qinliang, Ou Zijing, Yu Jianxing, Chen Changyou\nconference: Arxiv\nyear: 2021\nbibkey: qiu2021unsupervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2105.06138\"}\ntags: ['ARXIV', 'Supervised', 'Unsupervised']\n---\nMany unsupervised hashing methods are implicitly established on the idea of reconstructing the input data, which basically encourages the hashing codes to retain as much information of original data as possible. However, this requirement may force the models spending lots of their effort on reconstructing the unuseful background information, while ignoring to preserve the discriminative semantic information that is more important for the hashing task. To tackle this problem, inspired by the recent success of contrastive learning in learning continuous representations, we propose to adapt this framework to learn binary hashing codes. Specifically, we first propose to modify the objective function to meet the specific requirement of hashing and then introduce a probabilistic binary representation layer into the model to facilitate end-to-end training of the entire model. We further prove the strong connection between the proposed contrastive-learning-based hashing method and the mutual information, and show that the proposed model can be considered under the broader framework of the information bottleneck (IB). Under this perspective, a more general hashing model is naturally obtained. Extensive experimental results on three benchmark image datasets demonstrate that the proposed hashing method significantly outperforms existing baselines.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-12.496213912963867, 9.752551078796387]}, {"key": "", "year": "", "title": "Qiu2022efficient", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Efficient Document Retrieval by End-to-End Refining and Quantizing BERT Embedding with Contrastive Product Quantization\"\nauthors: Qiu Zexuan, Su Qinliang, Yu Jianxing, Si Shijing\nconference: EMNLP\nyear: 2022\nbibkey: qiu2022efficient\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2210.17170\"}\ntags: ['Quantisation']\n---\nEfficient document retrieval heavily relies on the technique of semantic hashing, which learns a binary code for every document and employs Hamming distance to evaluate document distances. However, existing semantic hashing methods are mostly established on outdated TFIDF features, which obviously do not contain lots of important semantic information about documents. Furthermore, the Hamming distance can only be equal to one of several integer values, significantly limiting its representational ability for document distances. To address these issues, in this paper, we propose to leverage BERT embeddings to perform efficient retrieval based on the product quantization technique, which will assign for every document a real-valued codeword from the codebook, instead of a binary code as in semantic hashing. Specifically, we first transform the original BERT embeddings via a learnable mapping and feed the transformed embedding into a probabilistic product quantization module to output the assigned codeword. The refining and quantizing modules can be optimized in an end-to-end manner by minimizing the probabilistic contrastive loss. A mutual information maximization based method is further proposed to improve the representativeness of codewords, so that documents can be quantized more accurately. Extensive experiments conducted on three benchmarks demonstrate that our proposed method significantly outperforms current state-of-the-art baselines.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-6.97204065322876, -3.6592342853546143]}, {"key": "", "year": "", "title": "Qiu2024hihpq", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"HiHPQ: Hierarchical Hyperbolic Product Quantization for Unsupervised Image Retrieval\"\nauthors: Qiu Zexuan, Liu Jiahong, Chen Yankai, King Irwin\nconference: Arxiv\nyear: 2024\nbibkey: qiu2024hihpq\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2401.07212\"}\ntags: ['ARXIV', 'Image Retrieval', 'Quantisation', 'Supervised', 'Unsupervised']\n---\nExisting unsupervised deep product quantization methods primarily aim for the increased similarity between different views of the identical image, whereas the delicate multi-level semantic similarities preserved between images are overlooked. Moreover, these methods predominantly focus on the Euclidean space for computational convenience, compromising their ability to map the multi-level semantic relationships between images effectively. To mitigate these shortcomings, we propose a novel unsupervised product quantization method dubbed \\textbf{Hi}erarchical \\textbf{H}yperbolic \\textbf{P}roduct \\textbf{Q}uantization (HiHPQ), which learns quantized representations by incorporating hierarchical semantic similarity within hyperbolic geometry. Specifically, we propose a hyperbolic product quantizer, where the hyperbolic codebook attention mechanism and the quantized contrastive learning on the hyperbolic product manifold are introduced to expedite quantization. Furthermore, we propose a hierarchical semantics learning module, designed to enhance the distinction between similar and non-matching images for a query by utilizing the extracted hierarchical semantics as an additional training supervision. Experiments on benchmarks show that our proposed method outperforms state-of-the-art baselines.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [4.774266242980957, 14.355128288269043]}, {"key": "", "year": "", "title": "Rabbani2023large", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Large-Scale Distributed Learning via Private On-Device Locality-Sensitive Hashing\"\nauthors: Rabbani Tahseen, Bornstein Marco, Huang Furong\nconference: Arxiv\nyear: 2023\nbibkey: rabbani2023large\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2306.02563\"}\ntags: ['ARXIV', 'LSH']\n---\nLocality-sensitive hashing (LSH) based frameworks have been used efficiently to select weight vectors in a dense hidden layer with high cosine similarity to an input, enabling dynamic pruning. While this type of scheme has been shown to improve computational training efficiency, existing algorithms require repeated randomized projection of the full layer weight, which is impractical for computational- and memory-constrained devices. In a distributed setting, deferring LSH analysis to a centralized host is (i) slow if the device cluster is large and (ii) requires access to input data which is forbidden in a federated context. Using a new family of hash functions, we develop one of the first private, personalized, and memory-efficient on-device LSH frameworks. Our framework enables privacy and personalization by allowing each device to generate hash tables, without the help of a central host, using device-specific hashing hyper-parameters (e.g. number of hash tables or hash length). Hash tables are generated with a compressed set of the full weights, and can be serially generated and discarded if the process is memory-intensive. This allows devices to avoid maintaining (i) the fully-sized model and (ii) large amounts of hash tables in local memory for LSH analysis. We prove several statistical and sensitivity properties of our hash functions, and experimentally demonstrate that our framework is competitive in training large-scale recommender networks compared to other LSH frameworks which assume unrestricted on-device capacity.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-14.908437728881836, -4.178868770599365]}, {"key": "", "year": "", "title": "Radenovi\u01072018revisiting", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Revisiting Oxford and Paris: Large-Scale Image Retrieval Benchmarking\"\nauthors: Radenovi\u0107 Filip, Iscen Ahmet, Tolias Giorgos, Avrithis Yannis, Chum Ond\u0159ej\nconference: Arxiv\nyear: 2018\nbibkey: radenovi\u01072018revisiting\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1803.11285\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval', 'TOM']\n---\nIn this paper we address issues with image retrieval benchmarking on standard and popular Oxford 5k and Paris 6k datasets. In particular, annotation errors, the size of the dataset, and the level of challenge are addressed: new annotation for both datasets is created with an extra attention to the reliability of the ground truth. Three new protocols of varying difficulty are introduced. The protocols allow fair comparison between different methods, including those using a dataset pre-processing stage. For each dataset, 15 new challenging queries are introduced. Finally, a new set of 1M hard, semi-automatically cleaned distractors is selected. An extensive comparison of the state-of-the-art methods is performed on the new benchmark. Different types of methods are evaluated, ranging from local-feature-based to modern CNN based methods. The best results are achieved by taking the best of the two worlds. Most importantly, image retrieval appears far from being solved.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [15.827342987060547, 20.447998046875]}, {"key": "", "year": "", "title": "Raff2017lempel", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Lempel-Ziv Jaccard Distance, an Effective Alternative to Ssdeep and Sdhash\"\nauthors: Raff Edward, Nicholas Charles K.\nconference: Arxiv\nyear: 2017\nbibkey: raff2017lempel\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1708.03346\"}\ntags: ['ARXIV']\n---\nRecent work has proposed the Lempel-Ziv Jaccard Distance (LZJD) as a method to measure the similarity between binary byte sequences for malware classification. We propose and test LZJD's effectiveness as a similarity digest hash for digital forensics. To do so we develop a high performance Java implementation with the same command-line arguments as sdhash, making it easy to integrate into existing workflows. Our testing shows that LZJD is effective for this task, and significantly outperforms sdhash and ssdeep in its ability to match related file fragments and files corrupted with random noise. In addition, LZJD is up to 60x faster than sdhash at comparison time.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [5.674287796020508, -4.354775905609131]}, {"key": "", "year": "", "title": "Ramabaja2020compact", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Compact Merkle Multiproofs\"\nauthors: Ramabaja Lum, Avdullahu Arber\nconference: Arxiv\nyear: 2020\nbibkey: ramabaja2020compact\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2002.07648\"}\ntags: ['ARXIV', 'TIP']\n---\nThe compact Merkle multiproof is a new and significantly more memory-efficient way to generate and verify sparse Merkle multiproofs. A standard sparse Merkle multiproof requires to store an index for every non-leaf hash in the multiproof. The compact Merkle multiproof on the other hand requires only $k$ leaf indices, where $k$ is the number of elements used for creating a multiproof. This significantly reduces the size of multirpoofs, especially for larger Merke trees.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-27.548860549926758, -9.523016929626465]}, {"key": "", "year": "", "title": "Ranjan2020a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Parallel Approach for Real-Time Face Recognition from a Large Database\"\nauthors: Ranjan Ashish, Behera Varun Nagesh Jolly, Reza Motahar\nconference: Arxiv\nyear: 2020\nbibkey: ranjan2020a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2011.00443\"}\ntags: ['ARXIV']\n---\nWe present a new facial recognition system, capable of identifying a person, provided their likeness has been previously stored in the system, in real time. The system is based on storing and comparing facial embeddings of the subject, and identifying them later within a live video feed. This system is highly accurate, and is able to tag people with their ID in real time. It is able to do so, even when using a database containing thousands of facial embeddings, by using a parallelized searching technique. This makes the system quite fast and allows it to be highly scalable.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [27.571569442749023, 12.212583541870117]}, {"key": "", "year": "", "title": "Rao2015diverse", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Diverse Yet Efficient Retrieval using Hash Functions\"\nauthors: Rao Vidyadhar, Jain Prateek, Jawahar C. V\nconference: Arxiv\nyear: 2015\nbibkey: rao2015diverse\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1509.06553\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nTypical retrieval systems have three requirements: a) Accurate retrieval i.e., the method should have high precision, b) Diverse retrieval, i.e., the obtained set of points should be diverse, c) Retrieval time should be small. However, most of the existing methods address only one or two of the above mentioned requirements. In this work, we present a method based on randomized locality sensitive hashing which tries to address all of the above requirements simultaneously. While earlier hashing approaches considered approximate retrieval to be acceptable only for the sake of efficiency, we argue that one can further exploit approximate retrieval to provide impressive trade-offs between accuracy and diversity. We extend our method to the problem of multi-label prediction, where the goal is to output a diverse and accurate set of labels for a given document in real-time. Moreover, we introduce a new notion to simultaneously evaluate a method's performance for both the precision and diversity measures. Finally, we present empirical results on several different retrieval tasks and show that our method retrieves diverse and accurate images/labels while ensuring $100x$-speed-up over the existing diverse retrieval approaches.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.344565391540527, 11.963043212890625]}, {"key": "", "year": "", "title": "Rashno2019content", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Content-based image retrieval system with most relevant features among wavelet and color features\"\nauthors: Rashno Abdolreza, Rashno Elyas\nconference: Arxiv\nyear: 2019\nbibkey: rashno2019content\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1902.02059\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nContent-based image retrieval (CBIR) has become one of the most important research directions in the domain of digital data management. In this paper, a new feature extraction schema including the norm of low frequency components in wavelet transformation and color features in RGB and HSV domains are proposed as representative feature vector for images in database followed by appropriate similarity measure for each feature type. In CBIR systems, retrieving results are so sensitive to image features. We address this problem with selection of most relevant features among complete feature set by ant colony optimization (ACO)-based feature selection which minimize the number of features as well as maximize F-measure in CBIR system. To evaluate the performance of our proposed CBIR system, it has been compared with three older proposed systems. Results show that the precision and recall of our proposed system are higher than older ones for the majority of image categories in Corel database.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [22.42347526550293, 10.481451034545898]}, {"key": "", "year": "", "title": "Rashtchian2020lsf", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"LSF-Join: Locality Sensitive Filtering for Distributed All-Pairs Set Similarity Under Skew\"\nauthors: Rashtchian Cyrus, Sharma Aneesh, Woodruff David P.\nconference: Arxiv\nyear: 2020\nbibkey: rashtchian2020lsf\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2003.02972\"}\ntags: ['ARXIV', 'Graph', 'TIP']\n---\nAll-pairs set similarity is a widely used data mining task, even for large and high-dimensional datasets. Traditionally, similarity search has focused on discovering very similar pairs, for which a variety of efficient algorithms are known. However, recent work highlights the importance of finding pairs of sets with relatively small intersection sizes. For example, in a recommender system, two users may be alike even though their interests only overlap on a small percentage of items. In such systems, some dimensions are often highly skewed because they are very popular. Together these two properties render previous approaches infeasible for large input sizes. To address this problem, we present a new distributed algorithm, LSF-Join, for approximate all-pairs set similarity. The core of our algorithm is a randomized selection procedure based on Locality Sensitive Filtering. Our method deviates from prior approximate algorithms, which are based on Locality Sensitive Hashing. Theoretically, we show that LSF-Join efficiently finds most close pairs, even for small similarity thresholds and for skewed input sets. We prove guarantees on the communication, work, and maximum load of LSF-Join, and we also experimentally demonstrate its accuracy on multiple graphs.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [3.132848024368286, -24.17643165588379]}, {"key": "", "year": "", "title": "Raviv2016coding", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Coding for Locality in Reconstructing Permutations\"\nauthors: Raviv Netanel, Yaakobi Eitan, Medard Muriel\nconference: Arxiv\nyear: 2016\nbibkey: raviv2016coding\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1601.04504\"}\ntags: ['ARXIV']\n---\nThe problem of storing permutations in a distributed manner arises in several common scenarios, such as efficient updates of a large, encrypted, or compressed data set. This problem may be addressed in either a combinatorial or a coding approach. The former approach boils down to presenting large sets of permutations with \\textit{locality}, that is, any symbol of the permutation can be computed from a small set of other symbols. In the latter approach, a permutation may be coded in order to achieve locality. This paper focuses on the combinatorial approach. We provide upper and lower bounds for the maximal size of a set of permutations with locality, and provide several simple constructions which attain the upper bound. In cases where the upper bound is not attained, we provide alternative constructions using Reed-Solomon codes, permutation polynomials, and multi-permutations.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [10.486096382141113, -7.664532661437988]}, {"key": "", "year": "", "title": "Razavian2014visual", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Visual Instance Retrieval with Deep Convolutional Networks\"\nauthors: Razavian Ali Sharif, Sullivan Josephine, Carlsson Stefan, Maki Atsuto\nconference: Arxiv\nyear: 2014\nbibkey: razavian2014visual\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1412.6574\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nThis paper provides an extensive study on the availability of image representations based on convolutional networks (ConvNets) for the task of visual instance retrieval. Besides the choice of convolutional layers, we present an efficient pipeline exploiting multi-scale schemes to extract local features, in particular, by taking geometric invariance into explicit account, i.e. positions, scales and spatial consistency. In our experiments using five standard image retrieval datasets, we demonstrate that generic ConvNet image representations can outperform other state-of-the-art methods if they are extracted appropriately.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [25.781185150146484, 9.812573432922363]}, {"key": "", "year": "", "title": "Raziperchikolaei2015optimizing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Optimizing affinity-based binary hashing using auxiliary coordinates\"\nauthors: Raziperchikolaei Ramin, Carreira-Perpi\u00f1\u00e1n Miguel \u00c1.\nconference: Arxiv\nyear: 2015\nbibkey: raziperchikolaei2015optimizing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1501.05352\"}\ntags: ['ARXIV', 'Image Retrieval', 'Supervised', 'Unsupervised']\n---\nIn supervised binary hashing, one wants to learn a function that maps a high-dimensional feature vector to a vector of binary codes, for application to fast image retrieval. This typically results in a difficult optimization problem, nonconvex and nonsmooth, because of the discrete variables involved. Much work has simply relaxed the problem during training, solving a continuous optimization, and truncating the codes a posteriori. This gives reasonable results but is quite suboptimal. Recent work has tried to optimize the objective directly over the binary codes and achieved better results, but the hash function was still learned a posteriori, which remains suboptimal. We propose a general framework for learning hash functions using affinity-based loss functions that uses auxiliary coordinates. This closes the loop and optimizes jointly over the hash functions and the binary codes so that they gradually match each other. The resulting algorithm can be seen as a corrected, iterated version of the procedure of optimizing first over the codes and then learning the hash function. Compared to this, our optimization is guaranteed to obtain better hash functions while being not much slower, as demonstrated experimentally in various supervised datasets. In addition, our framework facilitates the design of optimization algorithms for arbitrary types of loss and hash functions.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-5.378104209899902, 4.772619247436523]}, {"key": "", "year": "", "title": "Reimers2020the", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"The Curse of Dense Low-Dimensional Information Retrieval for Large Index Sizes\"\nauthors: Reimers Nils, Gurevych Iryna\nconference: Arxiv\nyear: 2020\nbibkey: reimers2020the\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2012.14210\"}\ntags: ['ARXIV', 'TIP']\n---\nInformation Retrieval using dense low-dimensional representations recently became popular and showed out-performance to traditional sparse-representations like BM25. However, no previous work investigated how dense representations perform with large index sizes. We show theoretically and empirically that the performance for dense representations decreases quicker than sparse representations for increasing index sizes. In extreme cases, this can even lead to a tipping point where at a certain index size sparse representations outperform dense representations. We show that this behavior is tightly connected to the number of dimensions of the representations: The lower the dimension, the higher the chance for false positives, i.e. returning irrelevant documents.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-23.83736228942871, 4.586596965789795]}, {"key": "", "year": "", "title": "Remil2023deeplsh", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"DeepLSH: Deep Locality-Sensitive Hash Learning for Fast and Efficient Near-Duplicate Crash Report Detection\"\nauthors: Remil Youcef, Bendimerad Anes, Mathonat Romain, Raissi Chedy, Kaytoue Mehdi\nconference: Arxiv\nyear: 2023\nbibkey: remil2023deeplsh\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2310.06703\"}\ntags: ['ARXIV', 'LSH', 'TOM']\n---\nAutomatic crash bucketing is a crucial phase in the software development process for efficiently triaging bug reports. It generally consists in grouping similar reports through clustering techniques. However, with real-time streaming bug collection, systems are needed to quickly answer the question: What are the most similar bugs to a new one?, that is, efficiently find near-duplicates. It is thus natural to consider nearest neighbors search to tackle this problem and especially the well-known locality-sensitive hashing (LSH) to deal with large datasets due to its sublinear performance and theoretical guarantees on the similarity search accuracy. Surprisingly, LSH has not been considered in the crash bucketing literature. It is indeed not trivial to derive hash functions that satisfy the so-called locality-sensitive property for the most advanced crash bucketing metrics. Consequently, we study in this paper how to leverage LSH for this task. To be able to consider the most relevant metrics used in the literature, we introduce DeepLSH, a Siamese DNN architecture with an original loss function, that perfectly approximates the locality-sensitivity property even for Jaccard and Cosine metrics for which exact LSH solutions exist. We support this claim with a series of experiments on an original dataset, which we make available.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-11.031384468078613, -2.24894642829895]}, {"key": "", "year": "", "title": "Revaud2019learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning with Average Precision: Training Image Retrieval with a Listwise Loss\"\nauthors: Revaud Jerome, Almazan Jon, de Rezende Rafael Sampaio, de Souza Cesar Roberto\nconference: Arxiv\nyear: 2019\nbibkey: revaud2019learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1906.07589\"}   - {name: \"Paper\", url: \"https://europe.naverlabs.com/Deep-Image-Retrieval/\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nImage retrieval can be formulated as a ranking problem where the goal is to order database images by decreasing similarity to the query. Recent deep models for image retrieval have outperformed traditional methods by leveraging ranking-tailored loss functions, but important theoretical and practical problems remain. First, rather than directly optimizing the global ranking, they minimize an upper-bound on the essential loss, which does not necessarily result in an optimal mean average precision (mAP). Second, these methods require significant engineering efforts to work well, e.g. special pre-training and hard-negative mining. In this paper we propose instead to directly optimize the global mAP by leveraging recent advances in listwise loss formulations. Using a histogram binning approximation, the AP can be differentiated and thus employed to end-to-end learning. Compared to existing losses, the proposed method considers thousands of images simultaneously at each iteration and eliminates the need for ad hoc tricks. It also establishes a new state of the art on many standard retrieval benchmarks. Models and evaluation scripts have been made available at https://europe.naverlabs.com/Deep-Image-Retrieval/\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [15.764856338500977, 10.292092323303223]}, {"key": "", "year": "", "title": "Rezaei2019content", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Content-based image retrieval using Mix histogram\"\nauthors: Rezaei Mohammad, Ahmadi Ali, Naderi Navid\nconference: \nyear: 2019\nbibkey: rezaei2019content\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1909.09722\"}\ntags: ['Image Retrieval']\n---\nThis paper presents a new method to extract image low-level features, namely mix histogram (MH), for content-based image retrieval. Since color and edge orientation features are important visual information which help the human visual system percept and discriminate different images, this method extracts and integrates color and edge orientation information in order to measure similarity between different images. Traditional color histograms merely focus on the global distribution of color in the image and therefore fail to extract other visual features. The MH is attempting to overcome this problem by extracting edge orientations as well as color feature. The unique characteristic of the MH is that it takes into consideration both color and edge orientation information in an effective manner. Experimental results show that it outperforms many existing methods which were originally developed for image retrieval purposes.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [21.841014862060547, 7.789262771606445]}, {"key": "", "year": "", "title": "Rossetto2019query", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Query by Semantic Sketch\"\nauthors: Rossetto Luca, Gasser Ralph, Schuldt Heiko\nconference: Arxiv\nyear: 2019\nbibkey: rossetto2019query\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1909.12526\"}\ntags: ['ARXIV', 'Video Retrieval']\n---\nSketch-based query formulation is very common in image and video retrieval as these techniques often complement textual retrieval methods that are based on either manual or machine generated annotations. In this paper, we present a retrieval approach that allows to query visual media collections by sketching concept maps, thereby merging sketch-based retrieval with the search for semantic labels. Users can draw a spatial distribution of different concept labels, such as \"sky\", \"sea\" or \"person\" and then use these sketches to find images or video scenes that exhibit a similar distribution of these concepts. Hence, this approach does not only take the semantic concepts themselves into account, but also their semantic relations as well as their spatial context. The efficient vector representation enables efficient retrieval even in large multimedia collections. We have integrated the semantic sketch query mode into our retrieval engine vitrivr and demonstrated its effectiveness.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [20.19585609436035, 7.373048305511475]}, {"key": "", "year": "", "title": "Rouhafzay2024texture", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Texture image retrieval using a classification and contourlet-based features\"\nauthors: Rouhafzay Asal, Baaziz Nadia, Allili Mohand Said\nconference: Arxiv\nyear: 2024\nbibkey: rouhafzay2024texture\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2403.06048\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nIn this paper, we propose a new framework for improving Content Based Image Retrieval (CBIR) for texture images. This is achieved by using a new image representation based on the RCT-Plus transform which is a novel variant of the Redundant Contourlet transform that extracts a richer directional information in the image. Moreover, the process of image search is improved through a learning-based approach where the images of the database are classified using an adapted similarity metric to the statistical modeling of the RCT-Plus transform. A query is then first classified to select the best texture class after which the retained class images are ranked to select top ones. By this, we have achieved significant improvements in the retrieval rates compared to previous CBIR schemes.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [24.19551658630371, 7.9040679931640625]}, {"key": "", "year": "", "title": "Roy2019metric", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Metric-Learning based Deep Hashing Network for Content Based Retrieval of Remote Sensing Images\"\nauthors: Roy Subhankar, Sangineto Enver, Demir Beg\u00fcm, Sebe Nicu\nconference: Arxiv\nyear: 2019\nbibkey: roy2019metric\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1904.01258\"}\ntags: ['ARXIV', 'TIP']\n---\nHashing methods have been recently found very effective in retrieval of remote sensing (RS) images due to their computational efficiency and fast search speed. The traditional hashing methods in RS usually exploit hand-crafted features to learn hash functions to obtain binary codes, which can be insufficient to optimally represent the information content of RS images. To overcome this problem, in this paper we introduce a metric-learning based hashing network, which learns: 1) a semantic-based metric space for effective feature representation; and 2) compact binary hash codes for fast archive search. Our network considers an interplay of multiple loss functions that allows to jointly learn a metric based semantic space facilitating similar images to be clustered together in that target space and at the same time producing compact final activations that lose negligible information when binarized. Experiments carried out on two benchmark RS archives point out that the proposed network significantly improves the retrieval performance under the same retrieval time when compared to the state-of-the-art hashing methods in RS.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-0.5424041748046875, 10.620524406433105]}, {"key": "", "year": "", "title": "Royoletelier2018disambiguating", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Disambiguating Music Artists at Scale with Audio Metric Learning\"\nauthors: Royo-Letelier Jimena, Hennequin Romain, Tran Viet-Anh, Moussallam Manuel\nconference: Arxiv\nyear: 2018\nbibkey: royoletelier2018disambiguating\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1810.01807\"}\ntags: ['ARXIV']\n---\nWe address the problem of disambiguating large scale catalogs through the definition of an unknown artist clustering task. We explore the use of metric learning techniques to learn artist embeddings directly from audio, and using a dedicated homonym artists dataset, we compare our method with a recent approach that learn similar embeddings using artist classifiers. While both systems have the ability to disambiguate unknown artists relying exclusively on audio, we show that our system is more suitable in the case when enough audio data is available for each artist in the train dataset. We also propose a new negative sampling method for metric learning that takes advantage of side information such as music genre during the learning phase and shows promising results for the artist clustering task.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [29.767784118652344, -6.925850868225098]}, {"key": "", "year": "", "title": "Ruta2021aladin", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"ALADIN: All Layer Adaptive Instance Normalization for Fine-grained Style Similarity\"\nauthors: Ruta Dan, Motiian Saeid, Faieta Baldo, Lin Zhe, Jin Hailin, Filipkowski Alex, Gilbert Andrew, Collomosse John\nconference: Arxiv\nyear: 2021\nbibkey: ruta2021aladin\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2103.09776\"}\ntags: ['ARXIV', 'Supervised', 'Weakly Supervised']\n---\nWe present ALADIN (All Layer AdaIN); a novel architecture for searching images based on the similarity of their artistic style. Representation learning is critical to visual search, where distance in the learned search embedding reflects image similarity. Learning an embedding that discriminates fine-grained variations in style is hard, due to the difficulty of defining and labelling style. ALADIN takes a weakly supervised approach to learning a representation for fine-grained style similarity of digital artworks, leveraging BAM-FG, a novel large-scale dataset of user generated content groupings gathered from the web. ALADIN sets a new state of the art accuracy for style-based visual search over both coarse labelled style data (BAM) and BAM-FG; a new 2.62 million image dataset of 310,000 fine-grained style groupings also contributed by this work.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [24.658510208129883, 4.51090145111084]}, {"key": "", "year": "", "title": "Ryali2020bio", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Bio-Inspired Hashing for Unsupervised Similarity Search\"\nauthors: Ryali Chaitanya K., Hopfield John J., Grinberg Leopold, Krotov Dmitry\nconference: Proceedings of the International Conference on Machine Learning,\nyear: 2020\nbibkey: ryali2020bio\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2001.04907\"}\ntags: ['LSH', 'Supervised', 'Unsupervised']\n---\nThe fruit fly Drosophila's olfactory circuit has inspired a new locality sensitive hashing (LSH) algorithm, FlyHash. In contrast with classical LSH algorithms that produce low dimensional hash codes, FlyHash produces sparse high-dimensional hash codes and has also been shown to have superior empirical performance compared to classical LSH algorithms in similarity search. However, FlyHash uses random projections and cannot learn from data. Building on inspiration from FlyHash and the ubiquity of sparse expansive representations in neurobiology, our work proposes a novel hashing algorithm BioHash that produces sparse high dimensional hash codes in a data-driven manner. We show that BioHash outperforms previously published benchmarks for various hashing methods. Since our learning algorithm is based on a local and biologically plausible synaptic plasticity rule, our work provides evidence for the proposal that LSH might be a computational reason for the abundance of sparse expansive motifs in a variety of biological systems. We also propose a convolutional variant BioConvHash that further improves performance. From the perspective of computer science, BioHash and BioConvHash are fast, scalable and yield compressed binary representations that are useful for similarity search.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-6.181716442108154, -8.883162498474121]}, {"key": "", "year": "", "title": "S2015low", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Low-Level Features for Image Retrieval Based on Extraction of Directional Binary Patterns and Its Oriented Gradients Histogram\"\nauthors: S. Nagaraja, J. Prabhakar C.\nconference: Arxiv\nyear: 2015\nbibkey: s2015low\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1503.03606\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nIn this paper, we present a novel approach for image retrieval based on extraction of low level features using techniques such as Directional Binary Code, Haar Wavelet transform and Histogram of Oriented Gradients. The DBC texture descriptor captures the spatial relationship between any pair of neighbourhood pixels in a local region along a given direction, while Local Binary Patterns descriptor considers the relationship between a given pixel and its surrounding neighbours. Therefore, DBC captures more spatial information than LBP and its variants, also it can extract more edge information than LBP. Hence, we employ DBC technique in order to extract grey level texture feature from each RGB channels individually and computed texture maps are further combined which represents colour texture features of an image. Then, we decomposed the extracted colour texture map and original image using Haar wavelet transform. Finally, we encode the shape and local features of wavelet transformed images using Histogram of Oriented Gradients for content based image retrieval. The performance of proposed method is compared with existing methods on two databases such as Wang's corel image and Caltech 256. The evaluation results show that our approach outperforms the existing methods for image retrieval.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [22.499069213867188, 8.126201629638672]}, {"key": "", "year": "", "title": "Sablayrolles2016how", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"How should we evaluate supervised hashing\"\nauthors: Sablayrolles Alexandre, Douze Matthijs, J\u00e9gou Herv\u00e9, Usunier Nicolas\nconference: Arxiv\nyear: 2016\nbibkey: sablayrolles2016how\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1609.06753\"}\ntags: ['ARXIV', 'Semi Supervised', 'Supervised', 'Unsupervised']\n---\nHashing produces compact representations for documents, to perform tasks like classification or retrieval based on these short codes. When hashing is supervised, the codes are trained using labels on the training data. This paper first shows that the evaluation protocols used in the literature for supervised hashing are not satisfactory: we show that a trivial solution that encodes the output of a classifier significantly outperforms existing supervised or semi-supervised methods, while using much shorter codes. We then propose two alternative protocols for supervised hashing: one based on retrieval on a disjoint set of classes, and another based on transfer learning to new classes. We provide two baseline methods for image-related tasks to assess the performance of (semi-)supervised hashing: without coding and with unsupervised codes. These baselines give a lower- and upper-bound on the performance of a supervised hashing scheme.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-9.969377517700195, 16.842241287231445]}, {"key": "", "year": "", "title": "Sackman2015perfect", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Perfect Consistent Hashing\"\nauthors: Sackman Matthew\nconference: Arxiv\nyear: 2015\nbibkey: sackman2015perfect\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1503.04988\"}\ntags: ['ARXIV']\n---\nConsistent Hashing functions are widely used for load balancing across a variety of applications. However, the original presentation and typical implementations of Consistent Hashing rely on randomised allocation of hash codes to keys which results in a flawed and approximately-uniform allocation of keys to hash codes. We analyse the desired properties and present an algorithm that perfectly achieves them without resorting to any random distributions. The algorithm is simple and adds to our understanding of what is necessary to create a consistent hash function.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-28.533510208129883, -12.561614990234375]}, {"key": "", "year": "", "title": "Saito2023pic2word", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Pic2Word: Mapping Pictures to Words for Zero-shot Composed Image Retrieval\"\nauthors: Saito Kuniaki, Sohn Kihyuk, Zhang Xiang, Li Chun-Liang, Lee Chen-Yu, Saenko Kate, Pfister Tomas\nconference: Arxiv\nyear: 2023\nbibkey: saito2023pic2word\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2302.03084\"}   - {name: \"Code\", url: \"https://github.com/google-research/composed_image_retrieval.\"}\ntags: ['ARXIV', 'Image Retrieval', 'Supervised', 'Unsupervised']\n---\nIn Composed Image Retrieval (CIR), a user combines a query image with text to describe their intended target. Existing methods rely on supervised learning of CIR models using labeled triplets consisting of the query image, text specification, and the target image. Labeling such triplets is expensive and hinders broad applicability of CIR. In this work, we propose to study an important task, Zero-Shot Composed Image Retrieval (ZS-CIR), whose goal is to build a CIR model without requiring labeled triplets for training. To this end, we propose a novel method, called Pic2Word, that requires only weakly labeled image-caption pairs and unlabeled image datasets to train. Unlike existing supervised CIR models, our model trained on weakly labeled or unlabeled datasets shows strong generalization across diverse ZS-CIR tasks, e.g., attribute editing, object composition, and domain conversion. Our approach outperforms several supervised CIR methods on the common CIR benchmark, CIRR and Fashion-IQ. Code will be made publicly available at https://github.com/google-research/composed_image_retrieval.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [6.395941257476807, 17.16805648803711]}, {"key": "", "year": "", "title": "Salvi2016bloom", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Bloom Filters and Compact Hash Codes for Efficient and Distributed Image Retrieval\"\nauthors: Salvi Andrea, Ercoli Simone, Bertini Marco, Del Bimbo Alberto\nconference: Arxiv\nyear: 2016\nbibkey: salvi2016bloom\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1605.00957\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval']\n---\nThis paper presents a novel method for efficient image retrieval, based on a simple and effective hashing of CNN features and the use of an indexing structure based on Bloom filters. These filters are used as gatekeepers for the database of image features, allowing to avoid to perform a query if the query features are not stored in the database and speeding up the query process, without affecting retrieval performance. Thanks to the limited memory requirements the system is suitable for mobile applications and distributed databases, associating each filter to a distributed portion of the database. Experimental validation has been performed on three standard image retrieval datasets, outperforming state-of-the-art hashing methods in terms of precision, while the proposed indexing method obtains a $2\\times$ speedup.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [10.684203147888184, 27.412710189819336]}, {"key": "", "year": "", "title": "Samano2019you", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"You Are Here: Geolocation by Embedding Maps and Images\"\nauthors: Samano Noe, Zhou Mengjie, Calway Andrew\nconference: Arxiv\nyear: 2019\nbibkey: samano2019you\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1911.08797\"}\ntags: ['ARXIV', 'Graph']\n---\nWe present a novel approach to geolocalising panoramic images on a 2-D cartographic map based on learning a low dimensional embedded space, which allows a comparison between an image captured at a location and local neighbourhoods of the map. The representation is not sufficiently discriminatory to allow localisation from a single image, but when concatenated along a route, localisation converges quickly, with over 90% accuracy being achieved for routes of around 200m in length when using Google Street View and Open Street Map data. The method generalises a previous fixed semantic feature based approach and achieves significantly higher localisation accuracy and faster convergence.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [9.536377906799316, -27.228845596313477]}, {"key": "", "year": "", "title": "Sanders2018hashing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hashing with Linear Probing and Referential Integrity\"\nauthors: Sanders Peter\nconference: Arxiv\nyear: 2018\nbibkey: sanders2018hashing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1808.04602\"}\ntags: ['ARXIV', 'TOM']\n---\nWe describe a variant of linear probing hash tables that never moves elements and thus supports referential integrity, i.e., pointers to elements remain valid while this element is in the hash table. This is achieved by the folklore method of marking some table entries as formerly occupied (tombstones). The innovation is that the number of tombstones is minimized. Experiments indicate that this allows an unbounded number of operations with bounded overhead compared to linear probing without tombstones (and without referential integrity).\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-32.06255340576172, -9.345726013183594]}, {"key": "", "year": "", "title": "Sangkloy2022a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Sketch Is Worth a Thousand Words: Image Retrieval with Text and Sketch\"\nauthors: Sangkloy Patsorn, Jitkrittum Wittawat, Yang Diyi, Hays James\nconference: Arxiv\nyear: 2022\nbibkey: sangkloy2022a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2208.03354\"}   - {name: \"Paper\", url: \"https://janesjanes.github.io/tsbir/.\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nWe address the problem of retrieving images with both a sketch and a text query. We present TASK-former (Text And SKetch transformer), an end-to-end trainable model for image retrieval using a text description and a sketch as input. We argue that both input modalities complement each other in a manner that cannot be achieved easily by either one alone. TASK-former follows the late-fusion dual-encoder approach, similar to CLIP, which allows efficient and scalable retrieval since the retrieval set can be indexed independently of the queries. We empirically demonstrate that using an input sketch (even a poorly drawn one) in addition to text considerably increases retrieval recall compared to traditional text-based image retrieval. To evaluate our approach, we collect 5,000 hand-drawn sketches for images in the test set of the COCO dataset. The collected sketches are available a https://janesjanes.github.io/tsbir/.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [26.8666934967041, 5.3994364738464355]}, {"key": "", "year": "", "title": "Sardey2015a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Comparative Analysis of Retrieval Techniques In Content Based Image Retrieval\"\nauthors: Sardey Mohini P., Kharate G. K.\nconference: Arxiv\nyear: 2015\nbibkey: sardey2015a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1508.06728\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nBasic group of visual techniques such as color, shape, texture are used in Content Based Image Retrievals (CBIR) to retrieve query image or subregion of image to find similar images in image database. To improve query result, relevance feedback is used many times in CBIR to help user to express their preference and improve query results.In this paper, a new approach for image retrieval is proposed which is based on the features such as Color Histogram, Eigen Values and Match Point. Images from various types of database are first identified by using edge detection techniques.Once the image is identified, then the image is searched in the particular database, then all related images are displayed. This will save the retrieval time. Further to retrieve the precise query image, any of the three techniques are used and comparison is done w.r.t. average retrieval time. Eigen value technique found to be the best as compared with other two techniques\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [22.4866886138916, 11.69648551940918]}, {"key": "", "year": "", "title": "Satuluri2011bayesian", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Bayesian Locality Sensitive Hashing for Fast Similarity Search\"\nauthors: Satuluri Venu, Parthasarathy Srinivasan\nconference: PVLDB\nyear: 2011\nbibkey: satuluri2011bayesian\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1110.1328\"}\ntags: ['LSH']\n---\nGiven a collection of objects and an associated similarity measure, the all-pairs similarity search problem asks us to find all pairs of objects with similarity greater than a certain user-specified threshold. Locality-sensitive hashing (LSH) based methods have become a very popular approach for this problem. However, most such methods only use LSH for the first phase of similarity search - i.e. efficient indexing for candidate generation. In this paper, we present BayesLSH, a principled Bayesian algorithm for the subsequent phase of similarity search - performing candidate pruning and similarity estimation using LSH. A simpler variant, BayesLSH-Lite, which calculates similarities exactly, is also presented. BayesLSH is able to quickly prune away a large majority of the false positive candidate pairs, leading to significant speedups over baseline approaches. For BayesLSH, we also provide probabilistic guarantees on the quality of the output, both in terms of accuracy and recall. Finally, the quality of BayesLSH's output can be easily tuned and does not require any manual setting of the number of hashes to use for similarity estimation, unlike standard approaches. For two state-of-the-art candidate generation algorithms, AllPairs and LSH, BayesLSH enables significant speedups, typically in the range 2x-20x for a wide variety of datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-1.240368127822876, -21.428760528564453]}, {"key": "", "year": "", "title": "Schall2019deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Metric Learning using Similarities from Nonlinear Rank Approximations\"\nauthors: Schall Konstantin, Barthel Kai Uwe, Hezel Nico, Jung Klaus\nconference: Arxiv\nyear: 2019\nbibkey: schall2019deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1909.09427\"}\ntags: ['ARXIV']\n---\nIn recent years, deep metric learning has achieved promising results in learning high dimensional semantic feature embeddings where the spatial relationships of the feature vectors match the visual similarities of the images. Similarity search for images is performed by determining the vectors with the smallest distances to a query vector. However, high retrieval quality does not depend on the actual distances of the feature vectors, but rather on the ranking order of the feature vectors from similar images. In this paper, we introduce a metric learning algorithm that focuses on identifying and modifying those feature vectors that most strongly affect the retrieval quality. We compute normalized approximated ranks and convert them to similarities by applying a nonlinear transfer function. These similarities are used in a newly proposed loss function that better contracts similar and disperses dissimilar samples. Experiments demonstrate significant improvement over existing deep feature embedding methods on the CUB-200-2011, Cars196, and Stanford Online Products data sets for all embedding sizes.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [13.53678035736084, 7.106313705444336]}, {"key": "", "year": "", "title": "Schall2021gpr1200", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"GPR1200: A Benchmark for General-Purpose Content-Based Image Retrieval\"\nauthors: Schall Konstantin, Barthel Kai Uwe, Hezel Nico, Jung Klaus\nconference: Arxiv\nyear: 2021\nbibkey: schall2021gpr1200\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2111.13122\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nEven though it has extensively been shown that retrieval specific training of deep neural networks is beneficial for nearest neighbor image search quality, most of these models are trained and tested in the domain of landmarks images. However, some applications use images from various other domains and therefore need a network with good generalization properties - a general-purpose CBIR model. To the best of our knowledge, no testing protocol has so far been introduced to benchmark models with respect to general image retrieval quality. After analyzing popular image retrieval test sets we decided to manually curate GPR1200, an easy to use and accessible but challenging benchmark dataset with a broad range of image categories. This benchmark is subsequently used to evaluate various pretrained models of different architectures on their generalization qualities. We show that large-scale pretraining significantly improves retrieval performance and present experiments on how to further increase these properties by appropriate fine-tuning. With these promising results, we hope to increase interest in the research topic of general-purpose CBIR.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [1.5253278017044067, 19.703781127929688]}, {"key": "", "year": "", "title": "Schiavo2021sketches", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Sketches image analysis: Web image search engine usingLSH index and DNN InceptionV3\"\nauthors: Schiavo Alessio, Minutella Filippo, Daole Mattia, Gomez Marsha Gomez\nconference: Arxiv\nyear: 2021\nbibkey: schiavo2021sketches\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2105.01147\"}\ntags: ['ARXIV', 'CNN', 'LSH']\n---\nThe adoption of an appropriate approximate similarity search method is an essential prereq-uisite for developing a fast and efficient CBIR system, especially when dealing with large amount ofdata. In this study we implement a web image search engine on top of a Locality Sensitive Hashing(LSH) Index to allow fast similarity search on deep features. Specifically, we exploit transfer learningfor deep features extraction from images. Firstly, we adopt InceptionV3 pretrained on ImageNet asfeatures extractor, secondly, we try out several CNNs built on top of InceptionV3 as convolutionalbase fine-tuned on our dataset. In both of the previous cases we index the features extracted within ourLSH index implementation so as to compare the retrieval performances with and without fine-tuning.In our approach we try out two different LSH implementations: the first one working with real numberfeature vectors and the second one with the binary transposed version of those vectors. Interestingly,we obtain the best performances when using the binary LSH, reaching almost the same result, in termsof mean average precision, obtained by performing sequential scan of the features, thus avoiding thebias introduced by the LSH index. Lastly, we carry out a performance analysis class by class in terms ofrecall againstmAPhighlighting, as expected, a strong positive correlation between the two.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [6.044493198394775, 15.370694160461426]}, {"key": "", "year": "", "title": "Schlegel2018adding", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Adding Cues to Binary Feature Descriptors for Visual Place Recognition\"\nauthors: Schlegel Dominik, Grisetti Giorgio\nconference: Arxiv\nyear: 2018\nbibkey: schlegel2018adding\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1809.06690\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nIn this paper we propose an approach to embed continuous and selector cues in binary feature descriptors used for visual place recognition. The embedding is achieved by extending each feature descriptor with a binary string that encodes a cue and supports the Hamming distance metric. Augmenting the descriptors in such a way has the advantage of being transparent to the procedure used to compare them. We present two concrete applications of our methodology, demonstrating the two considered types of cues. In addition to that, we conducted on these applications a broad quantitative and comparative evaluation covering five benchmark datasets and several state-of-the-art image retrieval approaches in combination with various binary descriptor types.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [24.929475784301758, 7.275047779083252]}, {"key": "", "year": "", "title": "Schlegel2018hbst", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"HBST: A Hamming Distance embedding Binary Search Tree for Visual Place Recognition\"\nauthors: Schlegel Dominik, Grisetti Giorgio\nconference: IEEE Robotics and Automation Letters\nyear: 2018\nbibkey: schlegel2018hbst\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1802.09261\"}\ntags: ['Image Retrieval']\n---\nReliable and efficient Visual Place Recognition is a major building block of modern SLAM systems. Leveraging on our prior work, in this paper we present a Hamming Distance embedding Binary Search Tree (HBST) approach for binary Descriptor Matching and Image Retrieval. HBST allows for descriptor Search and Insertion in logarithmic time by exploiting particular properties of binary Feature descriptors. We support the idea behind our search structure with a thorough analysis on the exploited descriptor properties and their effects on completeness and complexity of search and insertion. To validate our claims we conducted comparative experiments for HBST and several state-of-the-art methods on a broad range of publicly available datasets. HBST is available as a compact open-source C++ header-only library.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [21.89960289001465, -0.8437139391899109]}, {"key": "", "year": "", "title": "Schlemper2019deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Hashing using Entropy Regularised Product Quantisation Network\"\nauthors: Schlemper Jo, Caballero Jose, Aitken Andy, van Amersfoort Joost\nconference: Arxiv\nyear: 2019\nbibkey: schlemper2019deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1902.03876\"}\ntags: ['ARXIV', 'Deep Learning', 'Quantisation']\n---\nIn large scale systems, approximate nearest neighbour search is a crucial algorithm to enable efficient data retrievals. Recently, deep learning-based hashing algorithms have been proposed as a promising paradigm to enable data dependent schemes. Often their efficacy is only demonstrated on data sets with fixed, limited numbers of classes. In practical scenarios, those labels are not always available or one requires a method that can handle a higher input variability, as well as a higher granularity. To fulfil those requirements, we look at more flexible similarity measures. In this work, we present a novel, flexible, end-to-end trainable network for large-scale data hashing. Our method works by transforming the data distribution to behave as a uniform distribution on a product of spheres. The transformed data is subsequently hashed to a binary form in a way that maximises entropy of the output, (i.e. to fully utilise the available bit-rate capacity) while maintaining the correctness (i.e. close items hash to the same key in the map). We show that the method outperforms baseline approaches such as locality-sensitive hashing and product quantisation in the limited capacity regime.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-8.257105827331543, -7.511016368865967]}, {"key": "", "year": "", "title": "Schwengber2023deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Hashing via Householder Quantization\"\nauthors: Schwengber Lucas R., Resende Lucas, Orenstein Paulo, Oliveira Roberto I.\nconference: Arxiv\nyear: 2023\nbibkey: schwengber2023deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2311.04207\"}\ntags: ['ARXIV', 'Deep Learning', 'Quantisation', 'Supervised', 'Unsupervised']\n---\nHashing is at the heart of large-scale image similarity search, and recent methods have been substantially improved through deep learning techniques. Such algorithms typically learn continuous embeddings of the data. To avoid a subsequent costly binarization step, a common solution is to employ loss functions that combine a similarity learning term (to ensure similar images are grouped to nearby embeddings) and a quantization penalty term (to ensure that the embedding entries are close to binarized entries, e.g., -1 or 1). Still, the interaction between these two terms can make learning harder and the embeddings worse. We propose an alternative quantization strategy that decomposes the learning problem in two stages: first, perform similarity learning over the embedding space with no quantization; second, find an optimal orthogonal transformation of the embeddings so each coordinate of the embedding is close to its sign, and then quantize the transformed embedding through the sign function. In the second step, we parametrize orthogonal transformations using Householder matrices to efficiently leverage stochastic gradient descent. Since similarity measures are usually invariant under orthogonal transformations, this quantization strategy comes at no cost in terms of performance. The resulting algorithm is unsupervised, fast, hyperparameter-free and can be run on top of any existing deep hashing or metric learning algorithm. We provide extensive experimental results showing that this approach leads to state-of-the-art performance on widely used image datasets, and, unlike other quantization strategies, brings consistent improvements in performance to existing deep hashing algorithms.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-7.111128330230713, 8.275044441223145]}, {"key": "", "year": "", "title": "Seker2020hash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hash Cracking Benchmarking of Replacement Patterns\"\nauthors: Seker Ensar\nconference: Arxiv\nyear: 2020\nbibkey: seker2020hash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2006.08839\"}\ntags: ['ARXIV']\n---\nIn this paper, we explain our methodology to identify replacement patterns. The main purpose of this article is to show that with replacement methods on plain texts, it is possible to have more success rates when trying to recovering hashed passwords.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-26.647329330444336, -0.7543898224830627]}, {"key": "", "year": "", "title": "Shabanov2023stir", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"STIR: Siamese Transformer for Image Retrieval Postprocessing\"\nauthors: Shabanov Aleksei, Tarasov Aleksei, Nikolenko Sergey\nconference: Arxiv\nyear: 2023\nbibkey: shabanov2023stir\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2304.13393\"}   - {name: \"Code\", url: \"https://github.com/OML-Team/open-metric-learning/tree/main/pipelines/postprocessing/\"}   - {name: \"Paper\", url: \"https://dapladoc-oml-postprocessing-demo-srcappmain-pfh2g0.streamlit.app/\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nCurrent metric learning approaches for image retrieval are usually based on learning a space of informative latent representations where simple approaches such as the cosine distance will work well. Recent state of the art methods such as HypViT move to more complex embedding spaces that may yield better results but are harder to scale to production environments. In this work, we first construct a simpler model based on triplet loss with hard negatives mining that performs at the state of the art level but does not have these drawbacks. Second, we introduce a novel approach for image retrieval postprocessing called Siamese Transformer for Image Retrieval (STIR) that reranks several top outputs in a single forward pass. Unlike previously proposed Reranking Transformers, STIR does not rely on global/local feature extraction and directly compares a query image and a retrieved candidate on pixel level with the usage of attention mechanism. The resulting approach defines a new state of the art on standard image retrieval datasets: Stanford Online Products and DeepFashion In-shop. We also release the source code at https://github.com/OML-Team/open-metric-learning/tree/main/pipelines/postprocessing/ and an interactive demo of our approach at https://dapladoc-oml-postprocessing-demo-srcappmain-pfh2g0.streamlit.app/\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [7.664252281188965, 15.578060150146484]}, {"key": "", "year": "", "title": "Shand2020locality", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Locality-sensitive hashing in function spaces\"\nauthors: Shand Will, Becker Stephen\nconference: Arxiv\nyear: 2020\nbibkey: shand2020locality\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2002.03909\"}\ntags: ['ARXIV', 'LSH']\n---\nWe discuss the problem of performing similarity search over function spaces. To perform search over such spaces in a reasonable amount of time, we use {\\it locality-sensitive hashing} (LSH). We present two methods that allow LSH functions on $\\mathbb\\{R\\}^N$ to be extended to $L^p$ spaces: one using function approximation in an orthonormal basis, and another using (quasi-)Monte Carlo-style techniques. We use the presented hashing schemes to construct an LSH family for Wasserstein distance over one-dimensional, continuous probability distributions.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [13.534750938415527, -13.921367645263672]}, {"key": "", "year": "", "title": "Shanehsazzadeh2020fixed", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fixed-Length Protein Embeddings using Contextual Lenses\"\nauthors: Shanehsazzadeh Amir, Belanger David, Dohan David\nconference: Arxiv\nyear: 2020\nbibkey: shanehsazzadeh2020fixed\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2010.15065\"}\ntags: ['ARXIV', 'Deep Learning', 'Semi Supervised', 'Supervised']\n---\nThe Basic Local Alignment Search Tool (BLAST) is currently the most popular method for searching databases of biological sequences. BLAST compares sequences via similarity defined by a weighted edit distance, which results in it being computationally expensive. As opposed to working with edit distance, a vector similarity approach can be accelerated substantially using modern hardware or hashing techniques. Such an approach would require fixed-length embeddings for biological sequences. There has been recent interest in learning fixed-length protein embeddings using deep learning models under the hypothesis that the hidden layers of supervised or semi-supervised models could produce potentially useful vector embeddings. We consider transformer (BERT) protein language models that are pretrained on the TrEMBL data set and learn fixed-length embeddings on top of them with contextual lenses. The embeddings are trained to predict the family a protein belongs to for sequences in the Pfam database. We show that for nearest-neighbor family classification, pretraining offers a noticeable boost in performance and that the corresponding learned embeddings are competitive with BLAST. Furthermore, we show that the raw transformer embeddings, obtained via static pooling, do not perform well on nearest-neighbor family classification, which suggests that learning embeddings in a supervised manner via contextual lenses may be a compute-efficient alternative to fine-tuning.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [21.731388092041016, -20.832578659057617]}, {"key": "", "year": "", "title": "Shao2018h", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"H-CNN: Spatial Hashing Based CNN for 3D Shape Analysis\"\nauthors: Shao Tianjia, Yang Yin, Weng Yanlin, Hou Qiming, Zhou Kun\nconference: Arxiv\nyear: 2018\nbibkey: shao2018h\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1803.11385\"}\ntags: ['ARXIV', 'CNN']\n---\nWe present a novel spatial hashing based data structure to facilitate 3D shape analysis using convolutional neural networks (CNNs). Our method well utilizes the sparse occupancy of 3D shape boundary and builds hierarchical hash tables for an input model under different resolutions. Based on this data structure, we design two efficient GPU algorithms namely hash2col and col2hash so that the CNN operations like convolution and pooling can be efficiently parallelized. The spatial hashing is nearly minimal, and our data structure is almost of the same size as the raw input. Compared with state-of-the-art octree-based methods, our data structure significantly reduces the memory footprint during the CNN training. As the input geometry features are more compactly packed, CNN operations also run faster with our data structure. The experiment shows that, under the same network structure, our method yields comparable or better benchmarks compared to the state-of-the-art while it has only one-third memory consumption. Such superior memory performance allows the CNN to handle high-resolution shape analysis.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [10.616046905517578, 29.78277587890625]}, {"key": "", "year": "", "title": "Shao2022johnson", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Johnson-Lindenstrauss embeddings for noisy vectors -- taking advantage of the noise\"\nauthors: Shao Zhen\nconference: Arxiv\nyear: 2022\nbibkey: shao2022johnson\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2209.01006\"}\ntags: ['ARXIV']\n---\nThis paper investigates theoretical properties of subsampling and hashing as tools for approximate Euclidean norm-preserving embeddings for vectors with (unknown) additive Gaussian noises. Such embeddings are sometimes called Johnson-lindenstrauss embeddings due to their celebrated lemma. Previous work shows that as sparse embeddings, the success of subsampling and hashing closely depends on the $l_\\infty$ to $l_2$ ratios of the vector to be mapped. This paper shows that the presence of noise removes such constrain in high-dimensions, in other words, sparse embeddings such as subsampling and hashing with comparable embedding dimensions to dense embeddings have similar approximate norm-preserving dimensionality-reduction properties. The key is that the noise should be treated as an information to be exploited, not simply something to be removed. Theoretical bounds for subsampling and hashing to recover the approximate norm of a high dimension vector in the presence of noise are derived, with numerical illustrations showing better performances are achieved in the presence of noise.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [4.95716667175293, -5.873952865600586]}, {"key": "", "year": "", "title": "Sharma2015scalable", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Scalable Nonlinear Embeddings for Semantic Category-based Image Retrieval\"\nauthors: Sharma Gaurav, Schiele Bernt\nconference: Arxiv\nyear: 2015\nbibkey: sharma2015scalable\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1509.08902\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval', 'Supervised']\n---\nWe propose a novel algorithm for the task of supervised discriminative distance learning by nonlinearly embedding vectors into a low dimensional Euclidean space. We work in the challenging setting where supervision is with constraints on similar and dissimilar pairs while training. The proposed method is derived by an approximate kernelization of a linear Mahalanobis-like distance metric learning algorithm and can also be seen as a kernel neural network. The number of model parameters and test time evaluation complexity of the proposed method are O(dD) where D is the dimensionality of the input features and d is the dimension of the projection space - this is in contrast to the usual kernelization methods as, unlike them, the complexity does not scale linearly with the number of training examples. We propose a stochastic gradient based learning algorithm which makes the method scalable (w.r.t. the number of training examples), while being nonlinear. We train the method with up to half a million training pairs of 4096 dimensional CNN features. We give empirical comparisons with relevant baselines on seven challenging datasets for the task of low dimensional semantic category based image retrieval.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-11.215163230895996, 12.620018005371094]}, {"key": "", "year": "", "title": "Sharma2018improving", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Improving Similarity Search with High-dimensional Locality-sensitive Hashing\"\nauthors: Sharma Jaiyam, Navlakha Saket\nconference: Arxiv\nyear: 2018\nbibkey: sharma2018improving\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1812.01844\"}\ntags: ['ARXIV', 'LSH']\n---\nWe propose a new class of data-independent locality-sensitive hashing (LSH) algorithms based on the fruit fly olfactory circuit. The fundamental difference of this approach is that, instead of assigning hashes as dense points in a low dimensional space, hashes are assigned in a high dimensional space, which enhances their separability. We show theoretically and empirically that this new family of hash functions is locality-sensitive and preserves rank similarity for inputs in any `p space. We then analyze different variations on this strategy and show empirically that they outperform existing LSH methods for nearest-neighbors search on six benchmark datasets. Finally, we propose a multi-probe version of our algorithm that achieves higher performance for the same query time, or conversely, that maintains performance of prior approaches while taking significantly less indexing time and memory. Overall, our approach leverages the advantages of separability provided by high-dimensional spaces, while still remaining computationally efficient\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-3.790956974029541, -9.944488525390625]}, {"key": "", "year": "", "title": "Sharma2019retrieving", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Retrieving Similar E-Commerce Images Using Deep Learning\"\nauthors: Sharma Rishab, Vishvakarma Anirudha\nconference: Arxiv\nyear: 2019\nbibkey: sharma2019retrieving\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1901.03546\"}\ntags: ['ARXIV', 'CNN', 'Deep Learning', 'Image Retrieval']\n---\nIn this paper, we propose a deep convolutional neural network for learning the embeddings of images in order to capture the notion of visual similarity. We present a deep siamese architecture that when trained on positive and negative pairs of images learn an embedding that accurately approximates the ranking of images in order of visual similarity notion. We also implement a novel loss calculation method using an angular loss metrics based on the problems requirement. The final embedding of the image is combined representation of the lower and top-level embeddings. We used fractional distance matrix to calculate the distance between the learned embeddings in n-dimensional space. In the end, we compare our architecture with other existing deep architecture and go on to demonstrate the superiority of our solution in terms of image retrieval by testing the architecture on four datasets. We also show how our suggested network is better than the other traditional deep CNNs used for capturing fine-grained image similarities by learning an optimum embedding.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-1.2709670066833496, 19.044584274291992]}, {"key": "", "year": "", "title": "Shekar2023hashmem", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"HashMem: PIM-based Hashmap Accelerator\"\nauthors: Shekar Akhil, Baradaran Morteza, Tajdari Sabiha, Skadron Kevin\nconference: Arxiv\nyear: 2023\nbibkey: shekar2023hashmem\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2306.17721\"}\ntags: ['ARXIV']\n---\nHashmaps are widely utilized data structures in many applications to perform a probe on key-value pairs. However, their performance tends to degrade with the increase in the dataset size, which leads to expensive off-chip memory accesses to perform bucket traversals associated with hash collision. In this work, we propose HashMem, a processing-in-memory (PIM) architecture designed to perform bucket traversals along the row buffers at the subarray level. Due to the inherent parallelism achieved with many concurrent subarray accesses and the massive bandwidth available within DRAM, the execution time related to bucket traversals is significantly reduced. We have evaluated two versions of HashMem, performance-optimized and area-optimized, which have a speedup of 49.1x/17.1x and 9.2x/3.2x over standard C++ map and hyper-optimized hopscotch map implementations, respectively.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-19.422842025756836, -10.566530227661133]}, {"key": "", "year": "", "title": "Shen2013inductive", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Inductive Hashing on Manifolds\"\nauthors: Shen Fumin, Shen Chunhua, Shi Qinfeng, Hengel Anton van den, Tang Zhenmin\nconference: Arxiv\nyear: 2013\nbibkey: shen2013inductive\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1303.7043\"}\ntags: ['ARXIV']\n---\nLearning based hashing methods have attracted considerable attention due to their ability to greatly increase the scale at which existing algorithms may operate. Most of these methods are designed to generate binary codes that preserve the Euclidean distance in the original space. Manifold learning techniques, in contrast, are better able to model the intrinsic structure embedded in the original high-dimensional data. The complexity of these models, and the problems with out-of-sample data, have previously rendered them unsuitable for application to large-scale embedding, however. In this work, we consider how to learn compact binary embeddings on their intrinsic manifolds. In order to address the above-mentioned difficulties, we describe an efficient, inductive solution to the out-of-sample data problem, and a process by which non-parametric manifold learning may be used as the basis of a hashing method. Our proposed approach thus allows the development of a range of new hashing techniques exploiting the flexibility of the wide variety of manifold learning approaches available. We particularly show that hashing on the basis of t-SNE .\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-15.571737289428711, -1.7444934844970703]}, {"key": "", "year": "", "title": "Shen2014hashing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hashing on Nonlinear Manifolds\"\nauthors: Shen Fumin, Shen Chunhua, Shi Qinfeng, Hengel Anton van den, Tang Zhenmin, Shen Heng Tao\nconference: Arxiv\nyear: 2014\nbibkey: shen2014hashing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1412.0826\"}\ntags: ['ARXIV', 'Quantisation', 'Supervised']\n---\nLearning based hashing methods have attracted considerable attention due to their ability to greatly increase the scale at which existing algorithms may operate. Most of these methods are designed to generate binary codes preserving the Euclidean similarity in the original space. Manifold learning techniques, in contrast, are better able to model the intrinsic structure embedded in the original high-dimensional data. The complexities of these models, and the problems with out-of-sample data, have previously rendered them unsuitable for application to large-scale embedding, however. In this work, how to learn compact binary embeddings on their intrinsic manifolds is considered. In order to address the above-mentioned difficulties, an efficient, inductive solution to the out-of-sample data problem, and a process by which non-parametric manifold learning may be used as the basis of a hashing method is proposed. The proposed approach thus allows the development of a range of new hashing techniques exploiting the flexibility of the wide variety of manifold learning approaches available. It is particularly shown that hashing on the basis of t-SNE outperforms state-of-the-art hashing methods on large-scale benchmark datasets, and is very effective for image classification with very short code lengths. The proposed hashing framework is shown to be easily improved, for example, by minimizing the quantization error with learned orthogonal rotations. In addition, a supervised inductive manifold hashing framework is developed by incorporating the label information, which is shown to greatly advance the semantic retrieval performance.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-15.255805969238281, -1.917604923248291]}, {"key": "", "year": "", "title": "Shen2016learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning Binary Codes and Binary Weights for Efficient Classification\"\nauthors: Shen Fumin, Mu Yadong, Liu Wei, Yang Yang, Shen Heng Tao\nconference: Arxiv\nyear: 2016\nbibkey: shen2016learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1603.04116\"}\ntags: ['ARXIV']\n---\nThis paper proposes a generic formulation that significantly expedites the training and deployment of image classification models, particularly under the scenarios of many image categories and high feature dimensions. As a defining property, our method represents both the images and learned classifiers using binary hash codes, which are simultaneously learned from the training data. Classifying an image thereby reduces to computing the Hamming distance between the binary codes of the image and classifiers and selecting the class with minimal Hamming distance. Conventionally, compact hash codes are primarily used for accelerating image search. Our work is first of its kind to represent classifiers using binary codes. Specifically, we formulate multi-class image classification as an optimization problem over binary variables. The optimization alternatively proceeds over the binary classifiers and image hash codes. Profiting from the special property of binary codes, we show that the sub-problems can be efficiently solved through either a binary quadratic program (BQP) or linear program. In particular, for attacking the BQP problem, we propose a novel bit-flipping procedure which enjoys high efficacy and local optimality guarantee. Our formulation supports a large family of empirical loss functions and is here instantiated by exponential / hinge losses. Comprehensive evaluations are conducted on several representative image benchmarks. The experiments consistently observe reduced complexities of model training and deployment, without sacrifice of accuracies.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [5.5365986824035645, 15.88012981414795]}, {"key": "", "year": "", "title": "Shen2017deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Binaries: Encoding Semantic-Rich Cues for Efficient Textual-Visual Cross Retrieval\"\nauthors: Shen Yuming, Liu Li, Shao Ling, Song Jingkuan\nconference: Arxiv\nyear: 2017\nbibkey: shen2017deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1708.02531\"}\ntags: ['ARXIV', 'Cross Modal']\n---\nCross-modal hashing is usually regarded as an effective technique for large-scale textual-visual cross retrieval, where data from different modalities are mapped into a shared Hamming space for matching. Most of the traditional textual-visual binary encoding methods only consider holistic image representations and fail to model descriptive sentences. This renders existing methods inappropriate to handle the rich semantics of informative cross-modal data for quality textual-visual search tasks. To address the problem of hashing cross-modal data with semantic-rich cues, in this paper, a novel integrated deep architecture is developed to effectively encode the detailed semantics of informative images and long descriptive sentences, named as Textual-Visual Deep Binaries (TVDB). In particular, region-based convolutional networks with long short-term memory units are introduced to fully explore image regional details while semantic cues of sentences are modeled by a text convolutional network. Additionally, we propose a stochastic batch-wise training routine, where high-quality binary codes and deep encoding functions are efficiently optimized in an alternating manner. Experiments are conducted on three multimedia datasets, i.e. Microsoft COCO, IAPR TC-12, and INRIA Web Queries, where the proposed TVDB model significantly outperforms state-of-the-art binary coding methods in the task of cross-modal retrieval.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-1.6411906480789185, 4.816567897796631]}, {"key": "", "year": "", "title": "Shen2018nash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"NASH: Toward End-to-End Neural Architecture for Generative Semantic Hashing\"\nauthors: Shen Dinghan, Su Qinliang, Chapfuwa Paidamoyo, Wang Wenlin, Wang Guoyin, Carin Lawrence, Henao Ricardo\nconference: Arxiv\nyear: 2018\nbibkey: shen2018nash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1805.05361\"}\ntags: ['ARXIV', 'Supervised', 'Unsupervised']\n---\nSemantic hashing has become a powerful paradigm for fast similarity search in many information retrieval systems. While fairly successful, previous techniques generally require two-stage training, and the binary constraints are handled ad-hoc. In this paper, we present an end-to-end Neural Architecture for Semantic Hashing (NASH), where the binary hashing codes are treated as Bernoulli latent variables. A neural variational inference framework is proposed for training, where gradients are directly back-propagated through the discrete latent variable to optimize the hash function. We also draw connections between proposed method and rate-distortion theory, which provides a theoretical foundation for the effectiveness of the proposed framework. Experimental results on three public datasets demonstrate that our method significantly outperforms several state-of-the-art models on both unsupervised and supervised scenarios.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-20.81536102294922, 7.496367931365967]}, {"key": "", "year": "", "title": "Shen2018zero", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Zero-Shot Sketch-Image Hashing\"\nauthors: Shen Yuming, Liu Li, Shen Fumin, Shao Ling\nconference: Arxiv\nyear: 2018\nbibkey: shen2018zero\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1803.02284\"}\ntags: ['ARXIV', 'Cross Modal', 'Graph', 'Image Retrieval']\n---\nRecent studies show that large-scale sketch-based image retrieval (SBIR) can be efficiently tackled by cross-modal binary representation learning methods, where Hamming distance matching significantly speeds up the process of similarity search. Providing training and test data subjected to a fixed set of pre-defined categories, the cutting-edge SBIR and cross-modal hashing works obtain acceptable retrieval performance. However, most of the existing methods fail when the categories of query sketches have never been seen during training. In this paper, the above problem is briefed as a novel but realistic zero-shot SBIR hashing task. We elaborate the challenges of this special task and accordingly propose a zero-shot sketch-image hashing (ZSIH) model. An end-to-end three-network architecture is built, two of which are treated as the binary encoders. The third network mitigates the sketch-image heterogeneity and enhances the semantic relations among data by utilizing the Kronecker fusion layer and graph convolution, respectively. As an important part of ZSIH, we formulate a generative hashing scheme in reconstructing semantic knowledge representations for zero-shot retrieval. To the best of our knowledge, ZSIH is the first zero-shot hashing work suitable for SBIR and cross-modal search. Comprehensive experiments are conducted on two extended datasets, i.e., Sketchy and TU-Berlin with a novel zero-shot train-test split. The proposed model remarkably outperforms related works.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-8.782347679138184, 2.353152275085449]}, {"key": "", "year": "", "title": "Shen2019embarrassingly", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Embarrassingly Simple Binary Representation Learning\"\nauthors: Shen Yuming, Qin Jie, Chen Jiaxin, Liu Li, Zhu Fan\nconference: Arxiv\nyear: 2019\nbibkey: shen2019embarrassingly\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1908.09573\"}\ntags: ['ARXIV']\n---\nRecent binary representation learning models usually require sophisticated binary optimization, similarity measure or even generative models as auxiliaries. However, one may wonder whether these non-trivial components are needed to formulate practical and effective hashing models. In this paper, we answer the above question by proposing an embarrassingly simple approach to binary representation learning. With a simple classification objective, our model only incorporates two additional fully-connected layers onto the top of an arbitrary backbone network, whilst complying with the binary constraints during training. The proposed model lower-bounds the Information Bottleneck (IB) between data samples and their semantics, and can be related to many recent `learning to hash' paradigms. We show that, when properly designed, even such a simple network can generate effective binary codes, by fully exploring data semantics without any held-out alternating updating steps or auxiliary models. Experiments are conducted on conventional large-scale benchmarks, i.e., CIFAR-10, NUS-WIDE, and ImageNet, where the proposed simple model outperforms the state-of-the-art methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-14.153715133666992, 14.083961486816406]}, {"key": "", "year": "", "title": "Shen2020auto", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Auto-Encoding Twin-Bottleneck Hashing\"\nauthors: Shen Yuming, Qin Jie, Chen Jiaxin, Yu Mengyang, Liu Li, Zhu Fan, Shen Fumin, Shao Ling\nconference: Arxiv\nyear: 2020\nbibkey: shen2020auto\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2002.11930\"}   - {name: \"Code\", url: \"https://github.com/ymcidence/TBH.\"}\ntags: ['ARXIV', 'Graph', 'Supervised', 'Unsupervised']\n---\nConventional unsupervised hashing methods usually take advantage of similarity graphs, which are either pre-computed in the high-dimensional space or obtained from random anchor points. On the one hand, existing methods uncouple the procedures of hash function learning and graph construction. On the other hand, graphs empirically built upon original data could introduce biased prior knowledge of data relevance, leading to sub-optimal retrieval performance. In this paper, we tackle the above problems by proposing an efficient and adaptive code-driven graph, which is updated by decoding in the context of an auto-encoder. Specifically, we introduce into our framework twin bottlenecks (i.e., latent variables) that exchange crucial information collaboratively. One bottleneck (i.e., binary codes) conveys the high-level intrinsic data structure captured by the code-driven graph to the other (i.e., continuous variables for low-level detail information), which in turn propagates the updated network feedback for the encoder to learn more discriminative binary codes. The auto-encoding learning objective literally rewards the code-driven graph to learn an optimal encoder. Moreover, the proposed model can be simply optimized by gradient descent without violating the binary constraints. Experiments on benchmarked datasets clearly show the superiority of our framework over the state-of-the-art hashing methods. Our source code can be found at https://github.com/ymcidence/TBH.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [3.2926599979400635, -27.959871292114258]}, {"key": "", "year": "", "title": "Shen2022semicon", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"SEMICON: A Learning-to-hash Solution for Large-scale Fine-grained Image Retrieval\"\nauthors: Shen Yang, Sun Xuhao, Wei Xiu-Shen, Jiang Qing-Yuan, Yang Jian\nconference: Arxiv\nyear: 2022\nbibkey: shen2022semicon\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2209.13833\"}\ntags: ['ARXIV', 'Image Retrieval', 'TIP']\n---\nIn this paper, we propose Suppression-Enhancing Mask based attention and Interactive Channel transformatiON (SEMICON) to learn binary hash codes for dealing with large-scale fine-grained image retrieval tasks. In SEMICON, we first develop a suppression-enhancing mask (SEM) based attention to dynamically localize discriminative image regions. More importantly, different from existing attention mechanism simply erasing previous discriminative regions, our SEM is developed to restrain such regions and then discover other complementary regions by considering the relation between activated regions in a stage-by-stage fashion. In each stage, the interactive channel transformation (ICON) module is afterwards designed to exploit correlations across channels of attended activation tensors. Since channels could generally correspond to the parts of fine-grained objects, the part correlation can be also modeled accordingly, which further improves fine-grained retrieval accuracy. Moreover, to be computational economy, ICON is realized by an efficient two-step process. Finally, the hash learning of our SEMICON consists of both global- and local-level branches for better representing fine-grained objects and then generating binary hash codes explicitly corresponding to multiple levels. Experiments on five benchmark fine-grained datasets show our superiority over competing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [3.1524658203125, 9.609869003295898]}, {"key": "", "year": "", "title": "Shestakov2015scalable", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Scalable high-dimensional indexing and searching with Hadoop\"\nauthors: Shestakov Denis, Moise Diana\nconference: Arxiv\nyear: 2015\nbibkey: shestakov2015scalable\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1501.02398\"}\ntags: ['ARXIV']\n---\nWhile high-dimensional search-by-similarity techniques reached their maturity and in overall provide good performance, most of them are unable to cope with very large multimedia collections. The 'big data' challenge however has to be addressed as multimedia collections have been explosively growing and will grow even faster than ever within the next few years. Luckily, computational processing power has become more available to researchers due to easier access to distributed grid infrastructures. In this paper, we show how high-dimensional indexing and searching methods can be used on scientific grid environments and present a scalable workflow for indexing and searching over 30 billion SIFT descriptors using a cluster running Hadoop. Besides its scalability, the proposed scheme not only provides good search quality, but also achieves a stable throughput of around 210ms per image when searching a 100M image collection. Our findings could help other researchers and practitioners to cope with huge multimedia collections.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [5.362390995025635, -10.247124671936035]}, {"key": "", "year": "", "title": "Shi2016functional", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Functional Hashing for Compressing Neural Networks\"\nauthors: Shi Lei, Feng Shikun, Zhu Zhifan\nconference: Arxiv\nyear: 2016\nbibkey: shi2016functional\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1605.06560\"}\ntags: ['ARXIV', 'TIP']\n---\nAs the complexity of deep neural networks (DNNs) trend to grow to absorb the increasing sizes of data, memory and energy consumption has been receiving more and more attentions for industrial applications, especially on mobile devices. This paper presents a novel structure based on functional hashing to compress DNNs, namely FunHashNN. For each entry in a deep net, FunHashNN uses multiple low-cost hash functions to fetch values in the compression space, and then employs a small reconstruction network to recover that entry. The reconstruction network is plugged into the whole network and trained jointly. FunHashNN includes the recently proposed HashedNets as a degenerated case, and benefits from larger value capacity and less reconstruction loss. We further discuss extensions with dual space hashing and multi-hops. On several benchmark datasets, FunHashNN demonstrates high compression ratios with little loss on prediction accuracy.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-20.840919494628906, 13.190980911254883]}, {"key": "", "year": "", "title": "Shi2018a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Scalable Optimization Mechanism for Pairwise based Discrete Hashing\"\nauthors: Shi Xiaoshuang, Xing Fuyong, Zhang Zizhao, Sapkota Manish, Guo Zhenhua, Yang Lin\nconference: Arxiv\nyear: 2018\nbibkey: shi2018a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1811.10810\"}\ntags: ['ARXIV']\n---\nMaintaining the pair similarity relationship among originally high-dimensional data into a low-dimensional binary space is a popular strategy to learn binary codes. One simiple and intutive method is to utilize two identical code matrices produced by hash functions to approximate a pairwise real label matrix. However, the resulting quartic problem is difficult to directly solve due to the non-convex and non-smooth nature of the objective. In this paper, unlike previous optimization methods using various relaxation strategies, we aim to directly solve the original quartic problem using a novel alternative optimization mechanism to linearize the quartic problem by introducing a linear regression model. Additionally, we find that gradually learning each batch of binary codes in a sequential mode, i.e. batch by batch, is greatly beneficial to the convergence of binary code learning. Based on this significant discovery and the proposed strategy, we introduce a scalable symmetric discrete hashing algorithm that gradually and smoothly updates each batch of binary codes. To further improve the smoothness, we also propose a greedy symmetric discrete hashing algorithm to update each bit of batch binary codes. Moreover, we extend the proposed optimization mechanism to solve the non-convex optimization problems for binary code learning in many other pairwise based hashing algorithms. Extensive experiments on benchmark single-label and multi-label databases demonstrate the superior performance of the proposed mechanism over recent state-of-the-art methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-16.837312698364258, -1.6243624687194824]}, {"key": "", "year": "", "title": "Shi2018fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast Locality Sensitive Hashing for Beam Search on GPU\"\nauthors: Shi Xing, Xu Shizhen, Knight Kevin\nconference: Arxiv\nyear: 2018\nbibkey: shi2018fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1806.00588\"}\ntags: ['ARXIV', 'LSH']\n---\nWe present a GPU-based Locality Sensitive Hashing (LSH) algorithm to speed up beam search for sequence models. We utilize the winner-take-all (WTA) hash, which is based on relative ranking order of hidden dimensions and thus resilient to perturbations in numerical values. Our algorithm is designed by fully considering the underling architecture of CUDA-enabled GPUs (Algorithm/Architecture Co-design): 1) A parallel Cuckoo hash table is applied for LSH code lookup (guaranteed O(1) lookup time); 2) Candidate lists are shared across beams to maximize the parallelism; 3) Top frequent words are merged into candidate lists to improve performance. Experiments on 4 large-scale neural machine translation models demonstrate that our algorithm can achieve up to 4x speedup on softmax module, and 2x overall speedup without hurting BLEU on GPU.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [6.182950496673584, -15.088638305664062]}, {"key": "", "year": "", "title": "Shi2019compositional", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Compositional Embeddings Using Complementary Partitions for Memory-Efficient Recommendation Systems\"\nauthors: Shi Hao-Jun Michael, Mudigere Dheevatsa, Naumov Maxim, Yang Jiyan\nconference: Arxiv\nyear: 2019\nbibkey: shi2019compositional\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1909.02107\"}\ntags: ['ARXIV', 'Deep Learning', 'TIP']\n---\nModern deep learning-based recommendation systems exploit hundreds to thousands of different categorical features, each with millions of different categories ranging from clicks to posts. To respect the natural diversity within the categorical data, embeddings map each category to a unique dense representation within an embedded space. Since each categorical feature could take on as many as tens of millions of different possible categories, the embedding tables form the primary memory bottleneck during both training and inference. We propose a novel approach for reducing the embedding size in an end-to-end fashion by exploiting complementary partitions of the category set to produce a unique embedding vector for each category without explicit definition. By storing multiple smaller embedding tables based on each complementary partition and combining embeddings from each table, we define a unique embedding for each category at smaller memory cost. This approach may be interpreted as using a specific fixed codebook to ensure uniqueness of each category's representation. Our experimental results demonstrate the effectiveness of our approach over the hashing trick for reducing the size of the embedding tables in terms of model loss and accuracy, while retaining a similar reduction in the number of parameters.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [1.8192492723464966, -6.632104873657227]}, {"key": "", "year": "", "title": "Shi2019higher", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Higher-order Count Sketch: Dimensionality Reduction That Retains Efficient Tensor Operations\"\nauthors: Shi Yang, Anandkumar Animashree\nconference: Arxiv\nyear: 2019\nbibkey: shi2019higher\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1901.11261\"}\ntags: ['ARXIV', 'TIP']\n---\nSketching is a randomized dimensionality-reduction method that aims to preserve relevant information in large-scale datasets. Count sketch is a simple popular sketch which uses a randomized hash function to achieve compression. In this paper, we propose a novel extension known as Higher-order Count Sketch (HCS). While count sketch uses a single hash function, HCS uses multiple (smaller) hash functions for sketching. HCS reshapes the input (vector) data into a higher-order tensor and employs a tensor product of the random hash functions to compute the sketch. This results in an exponential saving (with respect to the order of the tensor) in the memory requirements of the hash functions, under certain conditions on the input data. Furthermore, when the input data itself has an underlying structure in the form of various tensor representations such as the Tucker decomposition, we obtain significant advantages. We derive efficient (approximate) computation of various tensor operations such as tensor products and tensor contractions directly on the sketched data. Thus, HCS is the first sketch to fully exploit the multi-dimensional nature of higher-order tensors. We apply HCS to tensorized neural networks where we replace fully connected layers with sketched tensor operations. We achieve nearly state of the art accuracy with significant compression on the image classification benchmark.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [2.427617311477661, 1.0708798170089722]}, {"key": "", "year": "", "title": "Shi2022deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Manifold Hashing: A Divide-and-Conquer Approach for Semi-Paired Unsupervised Cross-Modal Retrieval\"\nauthors: Shi Yufeng, You Xinge, Xu Jiamiao, Zheng Feng, Peng Qinmu, Ou Weihua\nconference: Arxiv\nyear: 2022\nbibkey: shi2022deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2209.12599\"}\ntags: ['ARXIV', 'Cross Modal', 'Supervised', 'Unsupervised']\n---\nHashing that projects data into binary codes has shown extraordinary talents in cross-modal retrieval due to its low storage usage and high query speed. Despite their empirical success on some scenarios, existing cross-modal hashing methods usually fail to cross modality gap when fully-paired data with plenty of labeled information is nonexistent. To circumvent this drawback, motivated by the Divide-and-Conquer strategy, we propose Deep Manifold Hashing (DMH), a novel method of dividing the problem of semi-paired unsupervised cross-modal retrieval into three sub-problems and building one simple yet efficiency model for each sub-problem. Specifically, the first model is constructed for obtaining modality-invariant features by complementing semi-paired data based on manifold learning, whereas the second model and the third model aim to learn hash codes and hash functions respectively. Extensive experiments on three benchmarks demonstrate the superiority of our DMH compared with the state-of-the-art fully-paired and semi-paired unsupervised cross-modal hashing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-10.622459411621094, -0.8078199028968811]}, {"key": "", "year": "", "title": "Shi2022efficient", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Efficient Cross-Modal Retrieval via Deep Binary Hashing and Quantization\"\nauthors: Shi Yang, Chung Young-joo\nconference: BMVC\nyear: 2022\nbibkey: shi2022efficient\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2202.10232\"}\ntags: ['Cross Modal', 'Deep Learning', 'Quantisation', 'Supervised', 'TIP']\n---\nCross-modal retrieval aims to search for data with similar semantic meanings across different content modalities. However, cross-modal retrieval requires huge amounts of storage and retrieval time since it needs to process data in multiple modalities. Existing works focused on learning single-source compact features such as binary hash codes that preserve similarities between different modalities. In this work, we propose a jointly learned deep hashing and quantization network (HQ) for cross-modal retrieval. We simultaneously learn binary hash codes and quantization codes to preserve semantic information in multiple modalities by an end-to-end deep learning architecture. At the retrieval step, binary hashing is used to retrieve a subset of items from the search space, then quantization is used to re-rank the retrieved items. We theoretically and empirically show that this two-stage retrieval approach provides faster retrieval results while preserving accuracy. Experimental results on the NUS-WIDE, MIR-Flickr, and Amazon datasets demonstrate that HQ achieves boosts of more than 7% in precision compared to supervised neural network-based compact coding models.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-2.4666895866394043, -2.404940366744995]}, {"key": "", "year": "", "title": "Shi2022information", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Information-Theoretic Hashing for Zero-Shot Cross-Modal Retrieval\"\nauthors: Shi Yufeng, Yu Shujian, Xu Duanquan, You Xinge\nconference: Arxiv\nyear: 2022\nbibkey: shi2022information\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2209.12491\"}\ntags: ['ARXIV', 'Cross Modal']\n---\nZero-shot cross-modal retrieval (ZS-CMR) deals with the retrieval problem among heterogenous data from unseen classes. Typically, to guarantee generalization, the pre-defined class embeddings from natural language processing (NLP) models are used to build a common space. In this paper, instead of using an extra NLP model to define a common space beforehand, we consider a totally different way to construct (or learn) a common hamming space from an information-theoretic perspective. We term our model the Information-Theoretic Hashing (ITH), which is composed of two cascading modules: an Adaptive Information Aggregation (AIA) module; and a Semantic Preserving Encoding (SPE) module. Specifically, our AIA module takes the inspiration from the Principle of Relevant Information (PRI) to construct a common space that adaptively aggregates the intrinsic semantics of different modalities of data and filters out redundant or irrelevant information. On the other hand, our SPE module further generates the hashing codes of different modalities by preserving the similarity of intrinsic semantics with the element-wise Kullback-Leibler (KL) divergence. A total correlation regularization term is also imposed to reduce the redundancy amongst different dimensions of hash codes. Sufficient experiments on three benchmark datasets demonstrate the superiority of the proposed ITH in ZS-CMR. Source code is available in the supplementary material.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-3.569894552230835, 0.3540414273738861]}, {"key": "", "year": "", "title": "Shi2022learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning Similarity Preserving Binary Codes for Recommender Systems\"\nauthors: Shi Yang, Chung Young-joo\nconference: Arxiv\nyear: 2022\nbibkey: shi2022learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2204.08569\"}\ntags: ['ARXIV', 'Cross Modal', 'Survey Paper']\n---\nHashing-based Recommender Systems (RSs) are widely studied to provide scalable services. The existing methods for the systems combine three modules to achieve efficiency: feature extraction, interaction modeling, and binarization. In this paper, we study an unexplored module combination for the hashing-based recommender systems, namely Compact Cross-Similarity Recommender (CCSR). Inspired by cross-modal retrieval, CCSR utilizes Maximum a Posteriori similarity instead of matrix factorization and rating reconstruction to model interactions between users and items. We conducted experiments on MovieLens1M, Amazon product review, Ichiba purchase dataset and confirmed CCSR outperformed the existing matrix factorization-based methods. On the Movielens1M dataset, the absolute performance improvements are up to 15.69% in NDCG and 4.29% in Recall. In addition, we extensively studied three binarization modules: $sign$, scaled tanh, and sign-scaled tanh. The result demonstrated that although differentiable scaled tanh is popular in recent discrete feature learning literature, a huge performance drop occurs when outputs of scaled $tanh$ are forced to be binary.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-0.0023798313923180103, -2.953418731689453]}, {"key": "", "year": "", "title": "Shih2014efficient", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Efficient Media Retrieval from Non-Cooperative Queries\"\nauthors: Shih Kevin, Di Wei, Jagadeesh Vignesh, Piramuthu Robinson\nconference: Arxiv\nyear: 2014\nbibkey: shih2014efficient\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1411.5307\"}\ntags: ['ARXIV']\n---\nText is ubiquitous in the artificial world and easily attainable when it comes to book title and author names. Using the images from the book cover set from the Stanford Mobile Visual Search dataset and additional book covers and metadata from openlibrary.org, we construct a large scale book cover retrieval dataset, complete with 100K distractor covers and title and author strings for each. Because our query images are poorly conditioned for clean text extraction, we propose a method for extracting a matching noisy and erroneous OCR readings and matching it against clean author and book title strings in a standard document look-up problem setup. Finally, we demonstrate how to use this text-matching as a feature in conjunction with popular retrieval features such as VLAD using a simple learning setup to achieve significant improvements in retrieval accuracy over that of either VLAD or the text alone.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [16.185468673706055, -18.022262573242188]}, {"key": "", "year": "", "title": "Shinde2010similarity", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Similarity Search and Locality Sensitive Hashing using TCAMs\"\nauthors: Shinde Rajendra, Goel Ashish, Gupta Pankaj, Dutta Debojyoti\nconference: Arxiv\nyear: 2010\nbibkey: shinde2010similarity\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1006.3514\"}\ntags: ['ARXIV', 'LSH']\n---\nSimilarity search methods are widely used as kernels in various machine learning applications. Nearest neighbor search (NNS) algorithms are often used to retrieve similar entries, given a query. While there exist efficient techniques for exact query lookup using hashing, similarity search using exact nearest neighbors is known to be a hard problem and in high dimensions, best known solutions offer little improvement over a linear scan. Fast solutions to the approximate NNS problem include Locality Sensitive Hashing (LSH) based techniques, which need storage polynomial in $n$ with exponent greater than $1$, and query time sublinear, but still polynomial in $n$, where $n$ is the size of the database. In this work we present a new technique of solving the approximate NNS problem in Euclidean space using a Ternary Content Addressable Memory (TCAM), which needs near linear space and has O(1) query time. In fact, this method also works around the best known lower bounds in the cell probe model for the query time using a data structure near linear in the size of the data base. TCAMs are high performance associative memories widely used in networking applications such as access control lists. A TCAM can query for a bit vector within a database of ternary vectors, where every bit position represents $0$, $1$ or $*$. The $*$ is a wild card representing either a $0$ or a $1$. We leverage TCAMs to design a variant of LSH, called Ternary Locality Sensitive Hashing (TLSH) wherein we hash database entries represented by vectors in the Euclidean space into $\\\\{0,1,*\\\\}$. By using the added functionality of a TLSH scheme with respect to the $*$ character, we solve an instance of the approximate nearest neighbor problem with 1 TCAM access and storage nearly linear in the size of the database. We believe that this work can open new avenues in very high speed data mining.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-5.938023567199707, -21.562408447265625]}, {"key": "", "year": "", "title": "Shoib2023content", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Content-based jewellery item retrieval using the local region-based histograms\"\nauthors: Shoib Amin Muhammad, Jabeen Summaira, Wang Changbo, Ali Tassawar\nconference: Arxiv\nyear: 2023\nbibkey: shoib2023content\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2305.07540\"}\ntags: ['ARXIV']\n---\nJewellery item retrieval is regularly used to find what people want on online marketplaces using a sample query reference image. Considering recent developments, due to the simultaneous nature of various jewelry items, various jewelry goods' occlusion in images or visual streams, as well as shape deformation, content-based jewellery item retrieval (CBJIR) still has limitations whenever it pertains to visual searching in the actual world. This article proposed a content-based jewellery item retrieval method using the local region-based histograms in HSV color space. Using five local regions, our novel jewellery classification module extracts the specific feature vectors from the query image. The jewellery classification module is also applied to the jewellery database to extract feature vectors. Finally, the similarity score is matched between the database and query features vectors to retrieve the jewellery items from the database. The proposed method performance is tested on publicly available jewellery item retrieval datasets, i.e. ringFIR and Fashion Product Images dataset. The experimental results demonstrate the dominance of the proposed method over the baseline methods for retrieving desired jewellery products.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [20.354969024658203, -7.101438999176025]}, {"key": "", "year": "", "title": "Shpilrain2024cayley", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Cayley hashing with cookies\"\nauthors: Shpilrain Vladimir, Sosnovski Bianca\nconference: Arxiv\nyear: 2024\nbibkey: shpilrain2024cayley\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2402.04943\"}\ntags: ['ARXIV', 'TIP']\n---\nCayley hash functions are based on a simple idea of using a pair of semigroup elements, A and B, to hash the 0 and 1 bit, respectively, and then to hash an arbitrary bit string in the natural way, by using multiplication of elements in the semigroup. The main advantage of Cayley hash functions compared to, say, hash functions in the SHA family is that when an already hashed document is amended, one does not have to hash the whole amended document all over again, but rather hash just the amended part and then multiply the result by the hash of the original document. Some authors argued that this may be a security hazard, specifically that this property may facilitate finding a second preimage by splitting a long bit string into shorter pieces. In this paper, we offer a way to get rid of this alleged disadvantage and keep the advantages at the same time. We call this method ``Cayley hashing with cookies\" using terminology borrowed from the theory of random walks in a random environment. For the platform semigroup, we use 2x2 matrices over F_p.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-23.526073455810547, -5.330418586730957]}, {"key": "", "year": "", "title": "Shrivastava2014asymmetric", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Asymmetric Minwise Hashing\"\nauthors: Shrivastava Anshumali, Li Ping\nconference: Arxiv\nyear: 2014\nbibkey: shrivastava2014asymmetric\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1411.3787\"}\ntags: ['ARXIV', 'LSH']\n---\nMinwise hashing (Minhash) is a widely popular indexing scheme in practice. Minhash is designed for estimating set resemblance and is known to be suboptimal in many applications where the desired measure is set overlap (i.e., inner product between binary vectors) or set containment. Minhash has inherent bias towards smaller sets, which adversely affects its performance in applications where such a penalization is not desirable. In this paper, we propose asymmetric minwise hashing (MH-ALSH), to provide a solution to this problem. The new scheme utilizes asymmetric transformations to cancel the bias of traditional minhash towards smaller sets, making the final \"collision probability\" monotonic in the inner product. Our theoretical comparisons show that for the task of retrieving with binary inner products asymmetric minhash is provably better than traditional minhash and other recently proposed hashing algorithms for general inner products. Thus, we obtain an algorithmic improvement over existing approaches in the literature. Experimental evaluations on four publicly available high-dimensional datasets validate our claims and the proposed scheme outperforms, often significantly, other hashing algorithms on the task of near neighbor retrieval with set containment. Our proposal is simple and easy to implement in practice.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-8.993196487426758, -15.100194931030273]}, {"key": "", "year": "", "title": "Shrivastava2014improved", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Improved Asymmetric Locality Sensitive Hashing (ALSH) for Maximum Inner Product Search (MIPS)\"\nauthors: Shrivastava Anshumali, Li Ping\nconference: Arxiv\nyear: 2014\nbibkey: shrivastava2014improved\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1410.5410\"}\ntags: ['ARXIV', 'LSH']\n---\nRecently it was shown that the problem of Maximum Inner Product Search (MIPS) is efficient and it admits provably sub-linear hashing algorithms. Asymmetric transformations before hashing were the key in solving MIPS which was otherwise hard. In the prior work, the authors use asymmetric transformations which convert the problem of approximate MIPS into the problem of approximate near neighbor search which can be efficiently solved using hashing. In this work, we provide a different transformation which converts the problem of approximate MIPS into the problem of approximate cosine similarity search which can be efficiently solved using signed random projections. Theoretical analysis show that the new scheme is significantly better than the original scheme for MIPS. Experimental evaluations strongly support the theoretical findings.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [1.944149136543274, -8.634515762329102]}, {"key": "", "year": "", "title": "Shrivastava2016exact", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Exact Weighted Minwise Hashing in Constant Time\"\nauthors: Shrivastava Anshumali\nconference: Arxiv\nyear: 2016\nbibkey: shrivastava2016exact\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1602.08393\"}\ntags: ['ARXIV', 'LSH', 'TIP']\n---\nWeighted minwise hashing (WMH) is one of the fundamental subroutine, required by many celebrated approximation algorithms, commonly adopted in industrial practice for large scale-search and learning. The resource bottleneck of the algorithms is the computation of multiple (typically a few hundreds to thousands) independent hashes of the data. The fastest hashing algorithm is by Ioffe \\cite{Proc:Ioffe_ICDM10}, which requires one pass over the entire data vector, $O(d)$ ($d$ is the number of non-zeros), for computing one hash. However, the requirement of multiple hashes demands hundreds or thousands passes over the data. This is very costly for modern massive dataset. In this work, we break this expensive barrier and show an expected constant amortized time algorithm which computes $k$ independent and unbiased WMH in time $O(k)$ instead of $O(dk)$ required by Ioffe's method. Moreover, our proposal only needs a few bits (5 - 9 bits) of storage per hash value compared to around $64$ bits required by the state-of-art-methodologies. Experimental evaluations, on real datasets, show that for computing 500 WMH, our proposal can be 60000x faster than the Ioffe's method without losing any accuracy. Our method is also around 100x faster than approximate heuristics capitalizing on the efficient \"densified\" one permutation hashing schemes \\cite{Proc:OneHashLSH_ICML14}. Given the simplicity of our approach and its significant advantages, we hope that it will replace existing implementations in practice.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-18.218624114990234, -14.522947311401367]}, {"key": "", "year": "", "title": "Shrivastava2017optimal", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Optimal Densification for Fast and Accurate Minwise Hashing\"\nauthors: Shrivastava Anshumali\nconference: Arxiv\nyear: 2017\nbibkey: shrivastava2017optimal\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1703.04664\"}\ntags: ['ARXIV', 'LSH']\n---\nMinwise hashing is a fundamental and one of the most successful hashing algorithm in the literature. Recent advances based on the idea of densification~\\cite{Proc:OneHashLSH_ICML14,Proc:Shrivastava_UAI14} have shown that it is possible to compute $k$ minwise hashes, of a vector with $d$ nonzeros, in mere $(d + k)$ computations, a significant improvement over the classical $O(dk)$. These advances have led to an algorithmic improvement in the query complexity of traditional indexing algorithms based on minwise hashing. Unfortunately, the variance of the current densification techniques is unnecessarily high, which leads to significantly poor accuracy compared to vanilla minwise hashing, especially when the data is sparse. In this paper, we provide a novel densification scheme which relies on carefully tailored 2-universal hashes. We show that the proposed scheme is variance-optimal, and without losing the runtime efficiency, it is significantly more accurate than existing densification techniques. As a result, we obtain a significantly efficient hashing scheme which has the same variance and collision probability as minwise hashing. Experimental evaluations on real sparse and high-dimensional datasets validate our claims. We believe that given the significant advantages, our method will replace minwise hashing implementations in practice.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-17.5095272064209, -13.743452072143555]}, {"key": "", "year": "", "title": "Sim\u00e9oni2017unsupervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Unsupervised object discovery for instance recognition\"\nauthors: Sim\u00e9oni Oriane, Iscen Ahmet, Tolias Giorgos, Avrithis Yannis, Chum Ondrej\nconference: Arxiv\nyear: 2017\nbibkey: sim\u00e9oni2017unsupervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1709.04725\"}\ntags: ['ARXIV', 'CNN', 'Graph', 'Image Retrieval', 'Supervised', 'Unsupervised']\n---\nSevere background clutter is challenging in many computer vision tasks, including large-scale image retrieval. Global descriptors, that are popular due to their memory and search efficiency, are especially prone to corruption by such a clutter. Eliminating the impact of the clutter on the image descriptor increases the chance of retrieving relevant images and prevents topic drift due to actually retrieving the clutter in the case of query expansion. In this work, we propose a novel salient region detection method. It captures, in an unsupervised manner, patterns that are both discriminative and common in the dataset. Saliency is based on a centrality measure of a nearest neighbor graph constructed from regional CNN representations of dataset images. The descriptors derived from the salient regions improve particular object retrieval, most noticeably in a large collections containing small objects.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [16.9320125579834, 19.907224655151367]}, {"key": "", "year": "", "title": "Singh2010content", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Content Base Image Retrieval Using Phong Shading\"\nauthors: Singh Uday Pratap, Jain Sanjeev, Ahmed Gulfishan Firdose\nconference: Arxiv\nyear: 2010\nbibkey: singh2010content\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1005.4267\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nThe digital image data is rapidly expanding in quantity and heterogeneity. The traditional information retrieval techniques does not meet the user's demand, so there is need to develop an efficient system for content based image retrieval. Content based image retrieval means retrieval of images from database on the basis of visual features of image like as color, texture etc. In our proposed method feature are extracted after applying Phong shading on input image. Phong shading, flattering out the dull surfaces of the image The features are extracted using color, texture &amp; edge density methods. Feature extracted values are used to find the similarity between input query image and the data base image. It can be measure by the Euclidean distance formula. The experimental result shows that the proposed approach has a better retrieval results with phong shading.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [14.420058250427246, 13.009230613708496]}, {"key": "", "year": "", "title": "Singh2014nearest", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Nearest Keyword Set Search in Multi-dimensional Datasets\"\nauthors: Singh Vishwakarma, Singh Ambuj K.\nconference: Arxiv\nyear: 2014\nbibkey: singh2014nearest\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1409.3867\"}\ntags: ['ARXIV']\n---\nKeyword-based search in text-rich multi-dimensional datasets facilitates many novel applications and tools. In this paper, we consider objects that are tagged with keywords and are embedded in a vector space. For these datasets, we study queries that ask for the tightest groups of points satisfying a given set of keywords. We propose a novel method called ProMiSH (Projection and Multi Scale Hashing) that uses random projection and hash-based index structures, and achieves high scalability and speedup. We present an exact and an approximate version of the algorithm. Our empirical studies, both on real and synthetic datasets, show that ProMiSH has a speedup of more than four orders over state-of-the-art tree-based techniques. Our scalability tests on datasets of sizes up to 10 million and dimensions up to 100 for queries having up to 9 keywords show that ProMiSH scales linearly with the dataset size, the dataset dimension, the query size, and the result size.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [6.5774078369140625, -9.834942817687988]}, {"key": "", "year": "", "title": "Singh2016efficient", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Efficient Document Indexing Using Pivot Tree\"\nauthors: Singh Gaurav, Piwowarski Benjamin\nconference: Arxiv\nyear: 2016\nbibkey: singh2016efficient\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1605.06693\"}\ntags: ['ARXIV']\n---\nWe present a novel method for efficiently searching top-k neighbors for documents represented in high dimensional space of terms based on the cosine similarity. Mostly, documents are stored as bag-of-words tf-idf representation. One of the most used ways of computing similarity between a pair of documents is cosine similarity between the vector representations, but cosine similarity is not a metric distance measure as it doesn't follow triangle inequality, therefore most metric searching methods can not be applied directly. We propose an efficient method for indexing documents using a pivot tree that leads to efficient retrieval. We also study the relation between precision and efficiency for the proposed method and compare it with a state of the art in the area of document searching based on inner product.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [15.370027542114258, -11.552791595458984]}, {"key": "", "year": "", "title": "Singh2016learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning to Hash-tag Videos with Tag2Vec\"\nauthors: Singh Aditya, Saini Saurabh, Shah Rajvi, Narayanan PJ\nconference: Arxiv\nyear: 2016\nbibkey: singh2016learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1612.04061\"}\ntags: ['ARXIV']\n---\nUser-given tags or labels are valuable resources for semantic understanding of visual media such as images and videos. Recently, a new type of labeling mechanism known as hash-tags have become increasingly popular on social media sites. In this paper, we study the problem of generating relevant and useful hash-tags for short video clips. Traditional data-driven approaches for tag enrichment and recommendation use direct visual similarity for label transfer and propagation. We attempt to learn a direct low-cost mapping from video to hash-tags using a two step training process. We first employ a natural language processing (NLP) technique, skip-gram models with neural network training to learn a low-dimensional vector representation of hash-tags (Tag2Vec) using a corpus of 10 million hash-tags. We then train an embedding function to map video features to the low-dimensional Tag2vec space. We learn this embedding for 29 categories of short video clips with hash-tags. A query video without any tag-information can then be directly mapped to the vector space of tags using the learned embedding and relevant tags can be found by performing a simple nearest-neighbor retrieval in the Tag2Vec space. We validate the relevance of the tags suggested by our system qualitatively and quantitatively with a user study.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-5.026774883270264, 16.00082015991211]}, {"key": "", "year": "", "title": "Singh2019adversarially", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Adversarially Trained Deep Neural Semantic Hashing Scheme for Subjective Search in Fashion Inventory\"\nauthors: Singh Saket, Sheet Debdoot, Dasgupta Mithun\nconference: Arxiv\nyear: 2019\nbibkey: singh2019adversarially\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1907.00382\"}\ntags: ['ARXIV', 'CNN']\n---\nThe simple approach of retrieving a closest match of a query image from one in the gallery, compares an image pair using sum of absolute difference in pixel or feature space. The process is computationally expensive, ill-posed to illumination, background composition, pose variation, as well as inefficient to be deployed on gallery sets with more than 1000 elements. Hashing is a faster alternative which involves representing images in reduced dimensional simple feature spaces. Encoding images into binary hash codes enables similarity comparison in an image-pair using the Hamming distance measure. The challenge, however, lies in encoding the images using a semantic hashing scheme that lets subjective neighbors lie within the tolerable Hamming radius. This work presents a solution employing adversarial learning of a deep neural semantic hashing network for fashion inventory retrieval. It consists of a feature extracting convolutional neural network (CNN) learned to (i) minimize error in classifying type of clothing, (ii) minimize hamming distance between semantic neighbors and maximize distance between semantically dissimilar images, (iii) maximally scramble a discriminator's ability to identify the corresponding hash code-image pair when processing a semantically similar query-gallery image pair. Experimental validation for fashion inventory search yields a mean average precision (mAP) of 90.65% in finding the closest match as compared to 53.26% obtained by the prior art of deep Cauchy hashing for hamming space retrieval.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [8.3482666015625, 12.175092697143555]}, {"key": "", "year": "", "title": "Singh2020ihashnet", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"IHashNet: Iris Hashing Network based on efficient multi-index hashing\"\nauthors: Singh Avantika, Vashist Chirag, Gaurav Pratyush, Nigam Aditya, Pratap Rameshwar\nconference: Arxiv\nyear: 2020\nbibkey: singh2020ihashnet\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2012.03881\"}\ntags: ['ARXIV']\n---\nMassive biometric deployments are pervasive in today's world. But despite the high accuracy of biometric systems, their computational efficiency degrades drastically with an increase in the database size. Thus, it is essential to index them. An ideal indexing scheme needs to generate codes that preserve the intra-subject similarity as well as inter-subject dissimilarity. Here, in this paper, we propose an iris indexing scheme using real-valued deep iris features binarized to iris bar codes (IBC) compatible with the indexing structure. Firstly, for extracting robust iris features, we have designed a network utilizing the domain knowledge of ordinal filtering and learning their nonlinear combinations. Later these real-valued features are binarized. Finally, for indexing the iris dataset, we have proposed a loss that can transform the binary feature into an improved feature compatible with the Multi-Index Hashing scheme. This loss function ensures the hamming distance equally distributed among all the contiguous disjoint sub-strings. To the best of our knowledge, this is the first work in the iris indexing domain that presents an end-to-end iris indexing structure. Experimental results on four datasets are presented to depict the efficacy of the proposed approach.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [1.2054967880249023, 5.740468978881836]}, {"key": "", "year": "", "title": "Singh2022simultaneously", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Simultaneously Learning Robust Audio Embeddings and balanced Hash codes for Query-by-Example\"\nauthors: Singh Anup, Demuynck Kris, Arora Vipul\nconference: Arxiv\nyear: 2022\nbibkey: singh2022simultaneously\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2211.11060\"}\ntags: ['ARXIV', 'Deep Learning', 'Self Supervised', 'Supervised', 'Unsupervised']\n---\nAudio fingerprinting systems must efficiently and robustly identify query snippets in an extensive database. To this end, state-of-the-art systems use deep learning to generate compact audio fingerprints. These systems deploy indexing methods, which quantize fingerprints to hash codes in an unsupervised manner to expedite the search. However, these methods generate imbalanced hash codes, leading to their suboptimal performance. Therefore, we propose a self-supervised learning framework to compute fingerprints and balanced hash codes in an end-to-end manner to achieve both fast and accurate retrieval performance. We model hash codes as a balanced clustering process, which we regard as an instance of the optimal transport problem. Experimental results indicate that the proposed approach improves retrieval efficiency while preserving high accuracy, particularly at high distortion levels, compared to the competing methods. Moreover, our system is efficient and scalable in computational load and memory storage.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-8.203461647033691, -2.1362712383270264]}, {"key": "", "year": "", "title": "Sinha2013data", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Data Hiding in Binary Image using Block Parity\"\nauthors: Sinha Sipendra, Gaikwad Amol, Kumar Deepak, Darade Snehal, Singh Rohit, Ganjewar Mr. Pramod D.\nconference: Arxiv\nyear: 2013\nbibkey: sinha2013data\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1304.1683\"}\ntags: ['ARXIV']\n---\nSecret data hiding in binary images is more difficult than other formats since binary images require only one bit representation to indicate black and white. This study proposes a new method for data hiding in binary images using optimized bit position to replace a secret bit. This method manipulates blocks, which are sub-divided. The parity bit for a specified block decides whether to change or not, to embed a secret bit. By finding the best position to insert a secret bit for each divided block, the image quality of the resulting stego-image can be improved, while maintaining low computational complexity.The experimental results show that the proposed method has an improvement with respect to a previous work.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-10.934541702270508, 17.819746017456055]}, {"key": "", "year": "", "title": "Sivertsen2017fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast Nearest Neighbor Preserving Embeddings\"\nauthors: Sivertsen Johan\nconference: Arxiv\nyear: 2017\nbibkey: sivertsen2017fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1707.06867\"}\ntags: ['ARXIV']\n---\nWe show an analog to the Fast Johnson-Lindenstrauss Transform for Nearest Neighbor Preserving Embeddings in $\\ell_2$. These are sparse, randomized embeddings that preserve the (approximate) nearest neighbors. The dimensionality of the embedding space is bounded not by the size of the embedded set n, but by its doubling dimension {\\lambda}. For most large real-world datasets this will mean a considerably lower-dimensional embedding space than possible when preserving all distances. The resulting embeddings can be used with existing approximate nearest neighbor data structures to yield speed improvements.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [10.537585258483887, -16.912511825561523]}, {"key": "", "year": "", "title": "Sivertsen2019similarity", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Similarity Problems in High Dimensions\"\nauthors: Sivertsen Johan von Tangen\nconference: Arxiv\nyear: 2019\nbibkey: sivertsen2019similarity\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1906.04842\"}\ntags: ['ARXIV']\n---\nThe main contribution of this dissertation is the introduction of new or improved approximation algorithms and data structures for several similarity search problems. We examine the furthest neighbor query, the annulus query, distance sensitive membership, nearest neighbor preserving embeddings and set similarity queries in the large-scale, high-dimensional setting.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [13.641756057739258, -14.401227951049805]}, {"key": "", "year": "", "title": "Skraparlis2000a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A method for command identification, using modified collision free hashing with addition &amp; rotation iterative hash functions (part 1)\"\nauthors: Skraparlis Dimitrios\nconference: Arxiv\nyear: 2000\nbibkey: skraparlis2000a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/cs/0005028\"}\ntags: ['ARXIV']\n---\nThis paper proposes a method for identification of a user`s fixed string set (which can be a command/instruction set for a terminal or microprocessor). This method is fast and has very small memory requirements, compared to a traditional full string storage and compare method. The user feeds characters into a microcontroller via a keyboard or another microprocessor sends commands and the microcontroller hashes the input in order to identify valid commands, ensuring no collisions between hashed valid strings, while applying further criteria to narrow collision between random and valid strings. The method proposed narrows the possibility of the latter kind of collision, achieving small code and memory-size utilization and very fast execution. Hashing is achieved using additive &amp; rotating hash functions in an iterative form, which can be very easily implemented in simple microcontrollers and microprocessors. Such hash functions are presented and compared according to their efficiency for a given string/command set, using the program found in the appendix.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-25.340513229370117, -18.655864715576172]}, {"key": "", "year": "", "title": "Slesarev2022benchmarking", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Benchmarking Hashing Algorithms for Load Balancing in a Distributed Database Environment\"\nauthors: Slesarev Alexander, Mikhailov Mikhail, Chernishev George\nconference: Arxiv\nyear: 2022\nbibkey: slesarev2022benchmarking\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2211.00741\"}\ntags: ['ARXIV', 'TIP']\n---\nModern high load applications store data using multiple database instances. Such an architecture requires data consistency, and it is important to ensure even distribution of data among nodes. Load balancing is used to achieve these goals. Hashing is the backbone of virtually all load balancing systems. Since the introduction of classic Consistent Hashing, many algorithms have been devised for this purpose. One of the purposes of the load balancer is to ensure storage cluster scalability. It is crucial for the performance of the whole system to transfer as few data records as possible during node addition or removal. The load balancer hashing algorithm has the greatest impact on this process. In this paper we experimentally evaluate several hashing algorithms used for load balancing, conducting both simulated and real system experiments. To evaluate algorithm performance, we have developed a benchmark suite based on Unidata MDM~ -- a scalable toolkit for various Master Data Management (MDM) applications. For assessment, we have employed three criteria~ -- uniformity of the produced distribution, the number of moved records, and computation speed. Following the results of our experiments, we have created a table, in which each algorithm is given an assessment according to the abovementioned criteria.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-20.155977249145508, -7.4980621337890625]}, {"key": "", "year": "", "title": "Song2017binary", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Binary Generative Adversarial Networks for Image Retrieval\"\nauthors: Song Jingkuan\nconference: Arxiv\nyear: 2017\nbibkey: song2017binary\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1708.04150\"}   - {name: \"Code\", url: \"https://github.com/htconquer/BGAN.\"}\ntags: ['ARXIV', 'GAN', 'Image Retrieval', 'Supervised', 'Unsupervised']\n---\nThe most striking successes in image retrieval using deep hashing have mostly involved discriminative models, which require labels. In this paper, we use binary generative adversarial networks (BGAN) to embed images to binary codes in an unsupervised way. By restricting the input noise variable of generative adversarial networks (GAN) to be binary and conditioned on the features of each input image, BGAN can simultaneously learn a binary representation per image, and generate an image plausibly similar to the original one. In the proposed framework, we address two main problems: 1) how to directly generate binary codes without relaxation? 2) how to equip the binary representation with the ability of accurate image retrieval? We resolve these problems by proposing new sign-activation strategy and a loss function steering the learning process, which consists of new models for adversarial loss, a content loss, and a neighborhood structure loss. Experimental results on standard datasets (CIFAR-10, NUSWIDE, and Flickr) demonstrate that our BGAN significantly outperforms existing hashing methods by up to 107\\% in terms of~mAP (See Table tab.res.map.comp) Our anonymous code is available at: https://github.com/htconquer/BGAN.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-1.8133622407913208, 6.003413200378418]}, {"key": "", "year": "", "title": "Song2017deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Discrete Hashing with Self-supervised Pairwise Labels\"\nauthors: Song Jingkuan, He Tao, Fan Hangbo, Gao Lianli\nconference: Arxiv\nyear: 2017\nbibkey: song2017deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1707.02112\"}   - {name: \"Code\", url: \"https://github.com/htconquer/ddh}.\"}\ntags: ['ARXIV', 'Image Retrieval', 'Self Supervised', 'Supervised', 'Unsupervised']\n---\nHashing methods have been widely used for applications of large-scale image retrieval and classification. Non-deep hashing methods using handcrafted features have been significantly outperformed by deep hashing methods due to their better feature representation and end-to-end learning framework. However, the most striking successes in deep hashing have mostly involved discriminative models, which require labels. In this paper, we propose a novel unsupervised deep hashing method, named Deep Discrete Hashing (DDH), for large-scale image retrieval and classification. In the proposed framework, we address two main problems: 1) how to directly learn discrete binary codes? 2) how to equip the binary representation with the ability of accurate image retrieval and classification in an unsupervised way? We resolve these problems by introducing an intermediate variable and a loss function steering the learning process, which is based on the neighborhood structure in the original space. Experimental results on standard datasets (CIFAR-10, NUS-WIDE, and Oxford-17) demonstrate that our DDH significantly outperforms existing hashing methods by large margin in terms of~mAP for image retrieval and object recognition. Code is available at \\url{https://github.com/htconquer/ddh}.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-2.0311214923858643, 5.801353454589844]}, {"key": "", "year": "", "title": "Song2018self", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Self-Supervised Video Hashing with Hierarchical Binary Auto-encoder\"\nauthors: Song Jingkuan, Zhang Hanwang, Li Xiangpeng, Gao Lianli, Wang Meng, Hong Richang\nconference: Arxiv\nyear: 2018\nbibkey: song2018self\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1802.02305\"}\ntags: ['ARXIV', 'Self Supervised', 'Supervised', 'TIP', 'Unsupervised', 'Video Retrieval']\n---\nExisting video hash functions are built on three isolated stages: frame pooling, relaxed learning, and binarization, which have not adequately explored the temporal order of video frames in a joint binary optimization model, resulting in severe information loss. In this paper, we propose a novel unsupervised video hashing framework dubbed Self-Supervised Video Hashing (SSVH), that is able to capture the temporal nature of videos in an end-to-end learning-to-hash fashion. We specifically address two central problems: 1) how to design an encoder-decoder architecture to generate binary codes for videos; and 2) how to equip the binary codes with the ability of accurate video retrieval. We design a hierarchical binary autoencoder to model the temporal dependencies in videos with multiple granularities, and embed the videos into binary codes with less computations than the stacked architecture. Then, we encourage the binary codes to simultaneously reconstruct the visual content and neighborhood structure of the videos. Experiments on two real-world datasets (FCVID and YFCC) show that our SSVH method can significantly outperform the state-of-the-art methods and achieve the currently best performance on the task of unsupervised video retrieval.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-0.3929484188556671, 26.633743286132812]}, {"key": "", "year": "", "title": "Song2019deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Hashing Learning for Visual and Semantic Retrieval of Remote Sensing Images\"\nauthors: Song Weiwei, Li Shutao, Benediktsson Jon Atli\nconference: Arxiv\nyear: 2019\nbibkey: song2019deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1909.04614\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval']\n---\nDriven by the urgent demand for managing remote sensing big data, large-scale remote sensing image retrieval (RSIR) attracts increasing attention in the remote sensing field. In general, existing retrieval methods can be regarded as visual-based retrieval approaches which search and return a set of similar images from a database to a given query image. Although retrieval methods have achieved great success, there is still a question that needs to be responded to: Can we obtain the accurate semantic labels of the returned similar images to further help analyzing and processing imagery? Inspired by the above question, in this paper, we redefine the image retrieval problem as visual and semantic retrieval of images. Specifically, we propose a novel deep hashing convolutional neural network (DHCNN) to simultaneously retrieve the similar images and classify their semantic labels in a unified framework. In more detail, a convolutional neural network (CNN) is used to extract high-dimensional deep features. Then, a hash layer is perfectly inserted into the network to transfer the deep features into compact hash codes. In addition, a fully connected layer with a softmax function is performed on hash layer to generate class distribution. Finally, a loss function is elaborately designed to simultaneously consider the label loss of each image and similarity loss of pairs of images. Experimental results on two remote sensing datasets demonstrate that the proposed method achieves the state-of-art retrieval and classification performance.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [9.149279594421387, 24.803142547607422]}, {"key": "", "year": "", "title": "Song2020deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Robust Multilevel Semantic Cross-Modal Hashing\"\nauthors: Song Ge, Zhao Jun, Tan Xiaoyang\nconference: Arxiv\nyear: 2020\nbibkey: song2020deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2002.02698\"}\ntags: ['ARXIV', 'Cross Modal', 'TIP']\n---\nHashing based cross-modal retrieval has recently made significant progress. But straightforward embedding data from different modalities into a joint Hamming space will inevitably produce false codes due to the intrinsic modality discrepancy and noises. We present a novel Robust Multilevel Semantic Hashing (RMSH) for more accurate cross-modal retrieval. It seeks to preserve fine-grained similarity among data with rich semantics, while explicitly require distances between dissimilar points to be larger than a specific value for strong robustness. For this, we give an effective bound of this value based on the information coding-theoretic analysis, and the above goals are embodied into a margin-adaptive triplet loss. Furthermore, we introduce pseudo-codes via fusing multiple hash codes to explore seldom-seen semantics, alleviating the sparsity problem of similarity information. Experiments on three benchmarks show the validity of the derived bounds, and our method achieves state-of-the-art performance.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-6.057488918304443, -4.539955139160156]}, {"key": "", "year": "", "title": "Song2022asymmetric", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Asymmetric Hash Code Learning for Remote Sensing Image Retrieval\"\nauthors: Song Weiwei, Gao Zhi, Dian Renwei, Ghamisi Pedram, Zhang Yongjun, Benediktsson J\u00f3n Atli\nconference: Arxiv\nyear: 2022\nbibkey: song2022asymmetric\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2201.05772\"}   - {name: \"Code\", url: \"https://github.com/weiweisong415/Demo\"}\ntags: ['ARXIV', 'Image Retrieval', 'Supervised']\n---\nRemote sensing image retrieval (RSIR), aiming at searching for a set of similar items to a given query image, is a very important task in remote sensing applications. Deep hashing learning as the current mainstream method has achieved satisfactory retrieval performance. On one hand, various deep neural networks are used to extract semantic features of remote sensing images. On the other hand, the hashing techniques are subsequently adopted to map the high-dimensional deep features to the low-dimensional binary codes. This kind of methods attempts to learn one hash function for both the query and database samples in a symmetric way. However, with the number of database samples increasing, it is typically time-consuming to generate the hash codes of large-scale database images. In this paper, we propose a novel deep hashing method, named asymmetric hash code learning (AHCL), for RSIR. The proposed AHCL generates the hash codes of query and database images in an asymmetric way. In more detail, the hash codes of query images are obtained by binarizing the output of the network, while the hash codes of database images are directly learned by solving the designed objective function. In addition, we combine the semantic information of each image and the similarity information of pairs of images as supervised information to train a deep hashing network, which improves the representation ability of deep features and hash codes. The experimental results on three public datasets demonstrate that the proposed method outperforms symmetric methods in terms of retrieval accuracy and efficiency. The source code is available at https://github.com/weiweisong415/Demo AHCL for TGRS2022.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-11.461909294128418, 3.670835494995117]}, {"key": "", "year": "", "title": "Song2023learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning More Discriminative Local Descriptors for Few-shot Learning\"\nauthors: Song Qijun, Zhou Siyun, Xu Liwei\nconference: Arxiv\nyear: 2023\nbibkey: song2023learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2305.08721\"}\ntags: ['ARXIV']\n---\nFew-shot learning for image classification comes up as a hot topic in computer vision, which aims at fast learning from a limited number of labeled images and generalize over the new tasks. In this paper, motivated by the idea of Fisher Score, we propose a Discriminative Local Descriptors Attention (DLDA) model that adaptively selects the representative local descriptors and does not introduce any additional parameters, while most of the existing local descriptors based methods utilize the neural networks that inevitably involve the tedious parameter tuning. Moreover, we modify the traditional $k$-NN classification model by adjusting the weights of the $k$ nearest neighbors according to their distances from the query point. Experiments on four benchmark datasets show that our method not only achieves higher accuracy compared with the state-of-art approaches for few-shot learning, but also possesses lower sensitivity to the choices of $k$.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [8.789679527282715, 20.676259994506836]}, {"key": "", "year": "", "title": "Sosnovski2023cryptanalysis", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Cryptanalysis of a Cayley Hash Function Based on Affine Maps in one Variable over a Finite Field\"\nauthors: Sosnovski Bianca\nconference: Arxiv\nyear: 2023\nbibkey: sosnovski2023cryptanalysis\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2308.15765\"}\ntags: ['ARXIV', 'Graph']\n---\nCayley hash functions are cryptographic hashes constructed from Cayley graphs of groups. The hash function proposed by Shpilrain and Sosnovski (2016), based on linear functions over a finite field, was proven insecure. This paper shows that the proposal by Ghaffari and Mostaghim (2018) that uses the Shpilrain and Sosnovski's hash in its construction is also insecure. We demonstrate its security vulnerability by constructing collisions.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-31.174209594726562, -3.611154317855835]}, {"key": "", "year": "", "title": "Spector2021bounding", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Bounding the Last Mile: Efficient Learned String Indexing\"\nauthors: Spector Benjamin, Kipf Andreas, Vaidya Kapil, Wang Chi, Minhas Umar Farooq, Kraska Tim\nconference: Arxiv\nyear: 2021\nbibkey: spector2021bounding\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2111.14905\"}\ntags: ['ARXIV']\n---\nWe introduce the RadixStringSpline (RSS) learned index structure for efficiently indexing strings. RSS is a tree of radix splines each indexing a fixed number of bytes. RSS approaches or exceeds the performance of traditional string indexes while using 7-70$\\times$ less memory. RSS achieves this by using the minimal string prefix to sufficiently distinguish the data unlike most learned approaches which index the entire string. Additionally, the bounded-error nature of RSS accelerates the last mile search and also enables a memory-efficient hash-table lookup accelerator. We benchmark RSS on several real-world string datasets against ART and HOT. Our experiments suggest this line of research may be promising for future memory-intensive database applications.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-23.8142032623291, -9.364059448242188]}, {"key": "", "year": "", "title": "Sridhar2010comparison", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Comparison Of Modified Dual Ternary Indexing And Multi-Key Hashing Algorithms For Music Information Retrieval\"\nauthors: Sridhar Rajeswari  Anna   University-Chennai, India, Amudha A.  Anna   University-Chennai, India, Karthiga S.  Anna   University-Chennai, India, T Geetha V Anna   University-Chennai, India\nconference: International Journal of Artificial Intelligence &amp; Applications\nyear: 2010\nbibkey: sridhar2010comparison\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1007.5137\"}\ntags: []\n---\nIn this work we have compared two indexing algorithms that have been used to index and retrieve Carnatic music songs. We have compared a modified algorithm of the Dual ternary indexing algorithm for music indexing and retrieval with the multi-key hashing indexing algorithm proposed by us. The modification in the dual ternary algorithm was essential to handle variable length query phrase and to accommodate features specific to Carnatic music. The dual ternary indexing algorithm is adapted for Carnatic music by segmenting using the segmentation technique for Carnatic music. The dual ternary algorithm is compared with the multi-key hashing algorithm designed by us for indexing and retrieval in which features like MFCC, spectral flux, melody string and spectral centroid are used as features for indexing data into a hash table. The way in which collision resolution was handled by this hash table is different than the normal hash table approaches. It was observed that multi-key hashing based retrieval had a lesser time complexity than dual-ternary based indexing The algorithms were also compared for their precision and recall in which multi-key hashing had a better recall than modified dual ternary indexing for the sample data considered.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [30.28821563720703, -7.94548225402832]}, {"key": "", "year": "", "title": "Srivastava20173d", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"3D Binary Signatures\"\nauthors: Srivastava Siddharth, Lall Brejesh\nconference: Arxiv\nyear: 2017\nbibkey: srivastava20173d\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1708.07937\"}\ntags: ['ARXIV']\n---\nIn this paper, we propose a novel binary descriptor for 3D point clouds. The proposed descriptor termed as 3D Binary Signature (3DBS) is motivated from the matching efficiency of the binary descriptors for 2D images. 3DBS describes keypoints from point clouds with a binary vector resulting in extremely fast matching. The method uses keypoints from standard keypoint detectors. The descriptor is built by constructing a Local Reference Frame and aligning a local surface patch accordingly. The local surface patch constitutes of identifying nearest neighbours based upon an angular constraint among them. The points are ordered with respect to the distance from the keypoints. The normals of the ordered pairs of these keypoints are projected on the axes and the relative magnitude is used to assign a binary digit. The vector thus constituted is used as a signature for representing the keypoints. The matching is done by using hamming distance. We show that 3DBS outperforms state of the art descriptors on various evaluation metrics.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [8.717061996459961, 0.45020627975463867]}, {"key": "", "year": "", "title": "Staszewski2020a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A new approach to descriptors generation for image retrieval by analyzing activations of deep neural network layers\"\nauthors: Staszewski Pawe\u0142, Jaworski Maciej, Cao Jinde, Rutkowski Leszek\nconference: Arxiv\nyear: 2020\nbibkey: staszewski2020a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2007.06624\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nIn this paper, we consider the problem of descriptors construction for the task of content-based image retrieval using deep neural networks. The idea of neural codes, based on fully connected layers activations, is extended by incorporating the information contained in convolutional layers. It is known that the total number of neurons in the convolutional part of the network is large and the majority of them have little influence on the final classification decision. Therefore, in the paper we propose a novel algorithm that allows us to extract the most significant neuron activations and utilize this information to construct effective descriptors. The descriptors consisting of values taken from both the fully connected and convolutional layers perfectly represent the whole image content. The images retrieved using these descriptors match semantically very well to the query image, and also they are similar in other secondary image characteristics, like background, textures or color distribution. These features of the proposed descriptors are verified experimentally based on the IMAGENET1M dataset using the VGG16 neural network.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.523168563842773, 21.275012969970703]}, {"key": "", "year": "", "title": "Steinruecken2014compressing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Compressing Sets and Multisets of Sequences\"\nauthors: Steinruecken Christian\nconference: Arxiv\nyear: 2014\nbibkey: steinruecken2014compressing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1401.6410\"}\ntags: ['ARXIV', 'Graph', 'TIP']\n---\nThis article describes lossless compression algorithms for multisets of sequences, taking advantage of the multiset's unordered structure. Multisets are a generalisation of sets where members are allowed to occur multiple times. A multiset can be encoded na\\\"ively by simply storing its elements in some sequential order, but then information is wasted on the ordering. We propose a technique that transforms the multiset into an order-invariant tree representation, and derive an arithmetic code that optimally compresses the tree. Our method achieves compression even if the sequences in the multiset are individually incompressible (such as cryptographic hash sums). The algorithm is demonstrated practically by compressing collections of SHA-1 hash sums, and multisets of arbitrary, individually encodable objects.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-29.870967864990234, -7.714158058166504]}, {"key": "", "year": "", "title": "Stojmirovic2003indexing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Indexing Schemes for Similarity Search In Datasets of Short Protein Fragments\"\nauthors: Stojmirovic Aleksandar, Pestov Vladimir\nconference: Information Systems\nyear: 2003\nbibkey: stojmirovic2003indexing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/cs/0309005\"}\ntags: []\n---\nWe propose a family of very efficient hierarchical indexing schemes for ungapped, score matrix-based similarity search in large datasets of short (4-12 amino acid) protein fragments. This type of similarity search has importance in both providing a building block to more complex algorithms and for possible use in direct biological investigations where datasets are of the order of 60 million objects. Our scheme is based on the internal geometry of the amino acid alphabet and performs exceptionally well, for example outputting 100 nearest neighbours to any possible fragment of length 10 after scanning on average less than one per cent of the entire dataset.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [21.337949752807617, -17.90593910217285]}, {"key": "", "year": "", "title": "Struppek2021learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning to Break Deep Perceptual Hashing: The Use Case NeuralHash\"\nauthors: Struppek Lukas, Hintersdorf Dominik, Neider Daniel, Kersting Kristian\nconference: Arxiv\nyear: 2021\nbibkey: struppek2021learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2111.06628\"}\ntags: ['ARXIV']\n---\nApple recently revealed its deep perceptual hashing system NeuralHash to detect child sexual abuse material (CSAM) on user devices before files are uploaded to its iCloud service. Public criticism quickly arose regarding the protection of user privacy and the system's reliability. In this paper, we present the first comprehensive empirical analysis of deep perceptual hashing based on NeuralHash. Specifically, we show that current deep perceptual hashing may not be robust. An adversary can manipulate the hash values by applying slight changes in images, either induced by gradient-based approaches or simply by performing standard image transformations, forcing or preventing hash collisions. Such attacks permit malicious actors easily to exploit the detection system: from hiding abusive material to framing innocent users, everything is possible. Moreover, using the hash values, inferences can still be made about the data stored on user devices. In our view, based on our results, deep perceptual hashing in its current form is generally not ready for robust client-side scanning and should not be used from a privacy perspective.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-30.59845542907715, 5.9674530029296875]}, {"key": "", "year": "", "title": "Stylianou2019visualizing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Visualizing Deep Similarity Networks\"\nauthors: Stylianou Abby, Souvenir Richard, Pless Robert\nconference: Arxiv\nyear: 2019\nbibkey: stylianou2019visualizing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1901.00536\"}\ntags: ['ARXIV']\n---\nFor convolutional neural network models that optimize an image embedding, we propose a method to highlight the regions of images that contribute most to pairwise similarity. This work is a corollary to the visualization tools developed for classification networks, but applicable to the problem domains better suited to similarity learning. The visualization shows how similarity networks that are fine-tuned learn to focus on different features. We also generalize our approach to embedding networks that use different pooling strategies and provide a simple mechanism to support image similarity searches on objects or sub-regions in the query image.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [17.86112403869629, 6.2522196769714355]}, {"key": "", "year": "", "title": "Su2014a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A New Non-MDS Hash Function Resisting Birthday Attack and Meet-in-the-middle Attack\"\nauthors: Su Shenghui, Xie Tao, Lu Shuwang\nconference: Theoretical Computer Science, v\nyear: 2014\nbibkey: su2014a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1408.5999\"}\ntags: []\n---\nTo examine the integrity and authenticity of an IP address efficiently and economically, this paper proposes a new non-Merkle-Damgard structural (non-MDS) hash function called JUNA that is based on a multivariate permutation problem and an anomalous subset product problem to which no subexponential time solutions are found so far. JUNA includes an initialization algorithm and a compression algorithm, and converts a short message of n bits which is regarded as only one block into a digest of m bits, where 80 &lt;= m &lt;= 232 and 80 &lt;= m &lt;= n &lt;= 4096. The analysis and proof show that the new hash is one-way, weakly collision-free, and strongly collision-free, and its security against existent attacks such as birthday attack and meet-in-the- middle attack is to O(2 ^ m). Moreover, a detailed proof that the new hash function is resistant to the birthday attack is given. Compared with the Chaum-Heijst-Pfitzmann hash based on a discrete logarithm problem, the new hash is lightweight, and thus it opens a door to convenience for utilization of lightweight digital signing schemes.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-22.840471267700195, -14.232810020446777]}, {"key": "", "year": "", "title": "Su2021hard", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hard Example Guided Hashing for Image Retrieval\"\nauthors: Su Hai, Han Meiyin, Liang Junle, Liang Jun, Yu Songsen\nconference: Arxiv\nyear: 2021\nbibkey: su2021hard\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2112.13565\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nCompared with the traditional hashing methods, deep hashing methods generate hash codes with rich semantic information and greatly improves the performances in the image retrieval field. However, it is unsatisfied for current deep hashing methods to predict the similarity of hard examples. It exists two main factors affecting the ability of learning hard examples, which are weak key features extraction and the shortage of hard examples. In this paper, we give a novel end-to-end model to extract the key feature from hard examples and obtain hash code with the accurate semantic information. In addition, we redesign a hard pair-wise loss function to assess the hard degree and update penalty weights of examples. It effectively alleviates the shortage problem in hard examples. Experimental results on CIFAR-10 and NUS-WIDE demonstrate that our model outperformances the mainstream hashing-based image retrieval methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-2.7490274906158447, 11.444839477539062]}, {"key": "", "year": "", "title": "Suma2024ames", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"AMES: Asymmetric and Memory-Efficient Similarity Estimation for Instance-level Retrieval\"\nauthors: Suma Pavel, Kordopatis-Zilos Giorgos, Iscen Ahmet, Tolias Giorgos\nconference: Arxiv\nyear: 2024\nbibkey: suma2024ames\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2408.03282\"}   - {name: \"Code\", url: \"https://github.com/pavelsuma/ames\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nThis work investigates the problem of instance-level image retrieval re-ranking with the constraint of memory efficiency, ultimately aiming to limit memory usage to 1KB per image. Departing from the prevalent focus on performance enhancements, this work prioritizes the crucial trade-off between performance and memory requirements. The proposed model uses a transformer-based architecture designed to estimate image-to-image similarity by capturing interactions within and across images based on their local descriptors. A distinctive property of the model is the capability for asymmetric similarity estimation. Database images are represented with a smaller number of descriptors compared to query images, enabling performance improvements without increasing memory consumption. To ensure adaptability across different applications, a universal model is introduced that adjusts to a varying number of local descriptors during the testing phase. Results on standard benchmarks demonstrate the superiority of our approach over both hand-crafted and learned models. In particular, compared with current state-of-the-art methods that overlook their memory footprint, our approach not only attains superior performance but does so with a significantly reduced memory footprint. The code and pretrained models are publicly available at: https://github.com/pavelsuma/ames\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-0.11434715241193771, 21.170207977294922]}, {"key": "", "year": "", "title": "Sumbul2020deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Learning for Image Search and Retrieval in Large Remote Sensing Archives\"\nauthors: Sumbul Gencer, Kang Jian, Demir Beg\u00fcm\nconference: Arxiv\nyear: 2020\nbibkey: sumbul2020deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2004.01613\"}\ntags: ['ARXIV', 'Deep Learning']\n---\nThis chapter presents recent advances in content based image search and retrieval (CBIR) systems in remote sensing (RS) for fast and accurate information discovery from massive data archives. Initially, we analyze the limitations of the traditional CBIR systems that rely on the hand-crafted RS image descriptors. Then, we focus our attention on the advances in RS CBIR systems for which deep learning (DL) models are at the forefront. In particular, we present the theoretical properties of the most recent DL based CBIR systems for the characterization of the complex semantic content of RS images. After discussing their strengths and limitations, we present the deep hashing based CBIR systems that have high time-efficient search capability within huge data archives. Finally, the most promising research directions in RS CBIR are discussed.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [8.562173843383789, 23.85202407836914]}, {"key": "", "year": "", "title": "Sumbul2022a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Novel Framework to Jointly Compress and Index Remote Sensing Images for Efficient Content-Based Retrieval\"\nauthors: Sumbul Gencer, Xiang Jun, Madam Nimisha Thekke, Demir Beg\u00fcm\nconference: Arxiv\nyear: 2022\nbibkey: sumbul2022a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2201.06459\"}   - {name: \"Paper\", url: \"https://git.tu-berlin.de/rsim/RS-JCIF.\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nRemote sensing (RS) images are usually stored in compressed format to reduce the storage size of the archives. Thus, existing content-based image retrieval (CBIR) systems in RS require decoding images before applying CBIR (which is computationally demanding in the case of large-scale CBIR problems). To address this problem, in this paper, we present a joint framework that simultaneously learns RS image compression and indexing. Thus, it eliminates the need for decoding RS images before applying CBIR. The proposed framework is made up of two modules. The first module compresses RS images based on an auto-encoder architecture. The second module produces hash codes with a high discrimination capability by employing soft pairwise, bit-balancing and classification loss functions. We also introduce a two stage learning strategy with gradient manipulation techniques to obtain image representations that are compatible with both RS image indexing and compression. Experimental results show the efficacy of the proposed framework when compared to widely used approaches in RS. The code of the proposed framework is available at https://git.tu-berlin.de/rsim/RS-JCIF.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-7.088401794433594, 25.940811157226562]}, {"key": "", "year": "", "title": "Sun20213rd", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"3rd Place: A Global and Local Dual Retrieval Solution to Facebook AI Image Similarity Challenge\"\nauthors: Sun Xinlong, Qin Yangyang, Xu Xuyuan, Gong Guoping, Fang Yang, Wang Yexin\nconference: Arxiv\nyear: 2021\nbibkey: sun20213rd\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2112.02373\"}\ntags: ['ARXIV', 'GAN', 'Self Supervised', 'Supervised']\n---\nAs a basic task of computer vision, image similarity retrieval is facing the challenge of large-scale data and image copy attacks. This paper presents our 3rd place solution to the matching track of Image Similarity Challenge (ISC) 2021 organized by Facebook AI. We propose a multi-branch retrieval method of combining global descriptors and local descriptors to cover all attack cases. Specifically, we attempt many strategies to optimize global descriptors, including abundant data augmentations, self-supervised learning with a single Transformer model, overlay detection preprocessing. Moreover, we introduce the robust SIFT feature and GPU Faiss for local retrieval which makes up for the shortcomings of the global retrieval. Finally, KNN-matching algorithm is used to judge the match and merge scores. We show some ablation experiments of our method, which reveals the complementary advantages of global and local features.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [2.315330982208252, -1.4284775257110596]}, {"key": "", "year": "", "title": "Sun2024soar", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"SOAR: Improved Indexing for Approximate Nearest Neighbor Search\"\nauthors: Sun Philip, Simcha David, Dopson Dave, Guo Ruiqi, Kumar Sanjiv\nconference: Advances in Neural Information Processing Systems\nyear: 2024\nbibkey: sun2024soar\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2404.00774\"}\ntags: ['TIP']\n---\nThis paper introduces SOAR: Spilling with Orthogonality-Amplified Residuals, a novel data indexing technique for approximate nearest neighbor (ANN) search. SOAR extends upon previous approaches to ANN search, such as spill trees, that utilize multiple redundant representations while partitioning the data to reduce the probability of missing a nearest neighbor during search. Rather than training and computing these redundant representations independently, however, SOAR uses an orthogonality-amplified residual loss, which optimizes each representation to compensate for cases where other representations perform poorly. This drastically improves the overall index quality, resulting in state-of-the-art ANN benchmark performance while maintaining fast indexing times and low memory consumption.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.232670783996582, -15.30013370513916]}, {"key": "", "year": "", "title": "Sunarso2013scalable", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Scalable Protein Sequence Similarity Search using Locality-Sensitive Hashing and MapReduce\"\nauthors: Sunarso Freddie, Venugopal Srikumar, Lauro Federico\nconference: Arxiv\nyear: 2013\nbibkey: sunarso2013scalable\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1310.0883\"}\ntags: ['ARXIV', 'LSH']\n---\nMetagenomics is the study of environments through genetic sampling of their microbiota. Metagenomic studies produce large datasets that are estimated to grow at a faster rate than the available computational capacity. A key step in the study of metagenome data is sequence similarity searching which is computationally intensive over large datasets. Tools such as BLAST require large dedicated computing infrastructure to perform such analysis and may not be available to every researcher. In this paper, we propose a novel approach called ScalLoPS that performs searching on protein sequence datasets using LSH (Locality-Sensitive Hashing) that is implemented using the MapReduce distributed framework. ScalLoPS is designed to scale across computing resources sourced from cloud computing providers. We present the design and implementation of ScalLoPS followed by evaluation with datasets derived from both traditional as well as metagenomic studies. Our experiments show that with this method approximates the quality of BLAST results while improving the scalability of protein sequence search.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [21.47083282470703, -19.876741409301758]}, {"key": "", "year": "", "title": "Suprem2018approximate", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Approximate Query Matching for Image Retrieval\"\nauthors: Suprem Abhijit, Chau Polo\nconference: Arxiv\nyear: 2018\nbibkey: suprem2018approximate\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1803.05401\"}\ntags: ['ARXIV', 'Graph', 'Image Retrieval']\n---\nTraditional image recognition involves identifying the key object in a portrait-type image with a single object focus (ILSVRC, AlexNet, and VGG). More recent approaches consider dense image recognition - segmenting an image with appropriate bounding boxes and performing image recognition within these bounding boxes (Semantic segmentation). The Visual Genome dataset [5] is an attempt to bridge these various approaches to a cohesive dataset for each subtask - bounding box generation, image recognition, captioning, and a new operation: scene graph generation. Our focus is on using such scene graphs to perform graph search on image databases to holistically retrieve images based on a search criteria. We develop a method to store scene graphs and metadata in graph databases (using Neo4J) and to perform fast approximate retrieval of images based on a graph search query. We process more complex queries than single object search, e.g. \"girl eating cake\" retrieves images that contain the specified relation as well as variations.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [14.793869018554688, -28.511484146118164]}, {"key": "", "year": "", "title": "Svenstrup2017hash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hash Embeddings for Efficient Word Representations\"\nauthors: Svenstrup Dan, Hansen Jonas Meinertz, Winther Ole\nconference: Arxiv\nyear: 2017\nbibkey: svenstrup2017hash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1709.03933\"}\ntags: ['ARXIV']\n---\nWe present hash embeddings, an efficient method for representing words in a continuous vector form. A hash embedding may be seen as an interpolation between a standard word embedding and a word embedding created using a random hash function (the hashing trick). In hash embeddings each token is represented by $k$ $d$-dimensional embeddings vectors and one $k$ dimensional weight vector. The final $d$ dimensional representation of the token is the product of the two. Rather than fitting the embedding vectors for each token these are selected by the hashing trick from a shared pool of $B$ embedding vectors. Our experiments show that hash embeddings can easily deal with huge vocabularies consisting of millions of tokens. When using a hash embedding there is no need to create a dictionary before training nor to perform any kind of vocabulary pruning after training. We show that models trained using hash embeddings exhibit at least the same level of performance as models trained using regular embeddings across a wide range of tasks. Furthermore, the number of parameters needed by such an embedding is only a fraction of what is required by a regular embedding. Since standard embeddings and embeddings constructed using the hashing trick are actually just special cases of a hash embedding, hash embeddings can be considered an extension and improvement over the existing regular embedding types.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-22.250072479248047, -5.190042018890381]}, {"key": "", "year": "", "title": "Szeto2016binary", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Binary Codes for Tagging X-Ray Images via Deep De-Noising Autoencoders\"\nauthors: Sze-To Antonio, Tizhoosh Hamid R., Wong Andrew K. C.\nconference: Arxiv\nyear: 2016\nbibkey: szeto2016binary\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1604.07060\"}\ntags: ['ARXIV', 'Image Retrieval', 'Supervised', 'TOM', 'Unsupervised']\n---\nA Content-Based Image Retrieval (CBIR) system which identifies similar medical images based on a query image can assist clinicians for more accurate diagnosis. The recent CBIR research trend favors the construction and use of binary codes to represent images. Deep architectures could learn the non-linear relationship among image pixels adaptively, allowing the automatic learning of high-level features from raw pixels. However, most of them require class labels, which are expensive to obtain, particularly for medical images. The methods which do not need class labels utilize a deep autoencoder for binary hashing, but the code construction involves a specific training algorithm and an ad-hoc regularization technique. In this study, we explored using a deep de-noising autoencoder (DDA), with a new unsupervised training scheme using only backpropagation and dropout, to hash images into binary codes. We conducted experiments on more than 14,000 x-ray images. By using class labels only for evaluating the retrieval results, we constructed a 16-bit DDA and a 512-bit DDA independently. Comparing to other unsupervised methods, we succeeded to obtain the lowest total error by using the 512-bit codes for retrieval via exhaustive search, and speed up 9.27 times with the use of the 16-bit codes while keeping a comparable total error. We found that our new training scheme could reduce the total retrieval error significantly by 21.9%. To further boost the image retrieval performance, we developed Radon Autoencoder Barcode (RABC) which are learned from the Radon projections of images using a de-noising autoencoder. Experimental results demonstrated its superior performance in retrieval when it was combined with DDA binary codes.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [26.450828552246094, 22.166465759277344]}, {"key": "", "year": "", "title": "Tabei2016scalable", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Scalable Similarity Search for Molecular Descriptors\"\nauthors: Tabei Yasuo, Puglisi Simon J.\nconference: Arxiv\nyear: 2016\nbibkey: tabei2016scalable\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1611.10045\"}\ntags: ['ARXIV']\n---\nSimilarity search over chemical compound databases is a fundamental task in the discovery and design of novel drug-like molecules. Such databases often encode molecules as non-negative integer vectors, called molecular descriptors, which represent rich information on various molecular properties. While there exist efficient indexing structures for searching databases of binary vectors, solutions for more general integer vectors are in their infancy. In this paper we present a time- and space- efficient index for the problem that we call the succinct intervals-splitting tree algorithm for molecular descriptors (SITAd). Our approach extends efficient methods for binary-vector databases, and uses ideas from succinct data structures. Our experiments, on a large database of over 40 million compounds, show SITAd significantly outperforms alternative approaches in practice.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [20.716602325439453, -18.376060485839844]}, {"key": "", "year": "", "title": "Taherkhani2020error", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Error-Corrected Margin-Based Deep Cross-Modal Hashing for Facial Image Retrieval\"\nauthors: Taherkhani Fariborz, Talreja Veeru, Valenti Matthew C., Nasrabadi Nasser M.\nconference: Arxiv\nyear: 2020\nbibkey: taherkhani2020error\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2004.03378\"}\ntags: ['ARXIV', 'Cross Modal', 'Image Retrieval']\n---\nCross-modal hashing facilitates mapping of heterogeneous multimedia data into a common Hamming space, which can beutilized for fast and flexible retrieval across different modalities. In this paper, we propose a novel cross-modal hashingarchitecture-deep neural decoder cross-modal hashing (DNDCMH), which uses a binary vector specifying the presence of certainfacial attributes as an input query to retrieve relevant face images from a database. The DNDCMH network consists of two separatecomponents: an attribute-based deep cross-modal hashing (ADCMH) module, which uses a margin (m)-based loss function toefficiently learn compact binary codes to preserve similarity between modalities in the Hamming space, and a neural error correctingdecoder (NECD), which is an error correcting decoder implemented with a neural network. The goal of NECD network in DNDCMH isto error correct the hash codes generated by ADCMH to improve the retrieval efficiency. The NECD network is trained such that it hasan error correcting capability greater than or equal to the margin (m) of the margin-based loss function. This results in NECD cancorrect the corrupted hash codes generated by ADCMH up to the Hamming distance of m. We have evaluated and comparedDNDCMH with state-of-the-art cross-modal hashing methods on standard datasets to demonstrate the superiority of our method.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [4.7047834396362305, 9.226064682006836]}, {"key": "", "year": "", "title": "Taileb2013content", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Content Based Image Retrieval System Using NOHIS-tree\"\nauthors: Taileb Mounira\nconference: Arxiv\nyear: 2013\nbibkey: taileb2013content\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1302.7039\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nContent-based image retrieval (CBIR) has been one of the most important research areas in computer vision. It is a widely used method for searching images in huge databases. In this paper we present a CBIR system called NOHIS-Search. The system is based on the indexing technique NOHIS-tree. The two phases of the system are described and the performance of the system is illustrated with the image database ImagEval. NOHIS-Search system was compared to other two CBIR systems; the first that using PDDP indexing algorithm and the second system is that using the sequential search. Results show that NOHIS-Search system outperforms the two other systems.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [25.418548583984375, 13.549468994140625]}, {"key": "", "year": "", "title": "Taisho2015leveraging", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Leveraging Image based Prior for Visual Place Recognition\"\nauthors: Taisho Tsukamoto, Kanji Tanaka\nconference: Arxiv\nyear: 2015\nbibkey: taisho2015leveraging\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1505.03205\"}\ntags: ['ARXIV']\n---\nIn this study, we propose a novel scene descriptor for visual place recognition. Unlike popular bag-of-words scene descriptors which rely on a library of vector quantized visual features, our proposed descriptor is based on a library of raw image data, such as publicly available photo collections from Google StreetView and Flickr. The library images need not to be associated with spatial information regarding the viewpoint and orientation of the scene. As a result, these images are cheaper than the database images; in addition, they are readily available. Our proposed descriptor directly mines the image library to discover landmarks (i.e., image patches) that suitably match an input query/database image. The discovered landmarks are then compactly described by their pose and shape (i.e., library image ID, bounding boxes) and used as a compact discriminative scene descriptor for the input image. We evaluate the effectiveness of our scene description framework by comparing its performance to that of previous approaches.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [21.284372329711914, 16.219745635986328]}, {"key": "", "year": "", "title": "Talreja2019using", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Using Deep Cross Modal Hashing and Error Correcting Codes for Improving the Efficiency of Attribute Guided Facial Image Retrieval\"\nauthors: Talreja Veeru, Taherkhani Fariborz, Valenti Matthew C., Nasrabadi Nasser M.\nconference: Arxiv\nyear: 2019\nbibkey: talreja2019using\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1902.04139\"}\ntags: ['ARXIV', 'Cross Modal', 'Deep Learning', 'Image Retrieval']\n---\nWith benefits of fast query speed and low storage cost, hashing-based image retrieval approaches have garnered considerable attention from the research community. In this paper, we propose a novel Error-Corrected Deep Cross Modal Hashing (CMH-ECC) method which uses a bitmap specifying the presence of certain facial attributes as an input query to retrieve relevant face images from the database. In this architecture, we generate compact hash codes using an end-to-end deep learning module, which effectively captures the inherent relationships between the face and attribute modality. We also integrate our deep learning module with forward error correction codes to further reduce the distance between different modalities of the same subject. Specifically, the properties of deep hashing and forward error correction codes are exploited to design a cross modal hashing framework with high retrieval performance. Experimental results using two standard datasets with facial attributes-image modalities indicate that our CMH-ECC face image retrieval model outperforms most of the current attribute-based face image retrieval approaches.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [5.207099914550781, 9.215553283691406]}, {"key": "", "year": "", "title": "Tan2017supervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Supervised Hashing with End-to-End Binary Deep Neural Network\"\nauthors: Tan Dang-Khoa Le, Do Thanh-Toan, Cheung Ngai-Man\nconference: Arxiv\nyear: 2017\nbibkey: tan2017supervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1711.08901\"}\ntags: ['ARXIV', 'Image Retrieval', 'Supervised', 'Unsupervised']\n---\nImage hashing is a popular technique applied to large scale content-based visual retrieval due to its compact and efficient binary codes. Our work proposes a new end-to-end deep network architecture for supervised hashing which directly learns binary codes from input images and maintains good properties over binary codes such as similarity preservation, independence, and balancing. Furthermore, we also propose a new learning scheme that can cope with the binary constrained loss function. The proposed algorithm not only is scalable for learning over large-scale datasets but also outperforms state-of-the-art supervised hashing methods, which are illustrated throughout extensive experiments from various image retrieval benchmarks.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-7.92681884765625, 15.059431076049805]}, {"key": "", "year": "", "title": "Tan2020learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning to Hash with Graph Neural Networks for Recommender Systems\"\nauthors: Tan Qiaoyu, Liu Ninghao, Zhao Xing, Yang Hongxia, Zhou Jingren, Hu Xia\nconference: Arxiv\nyear: 2020\nbibkey: tan2020learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2003.01917\"}\ntags: ['ARXIV', 'Graph', 'TIP']\n---\nGraph representation learning has attracted much attention in supporting high quality candidate search at scale. Despite its effectiveness in learning embedding vectors for objects in the user-item interaction network, the computational costs to infer users' preferences in continuous embedding space are tremendous. In this work, we investigate the problem of hashing with graph neural networks (GNNs) for high quality retrieval, and propose a simple yet effective discrete representation learning framework to jointly learn continuous and discrete codes. Specifically, a deep hashing with GNNs (HashGNN) is presented, which consists of two components, a GNN encoder for learning node representations, and a hash layer for encoding representations to hash codes. The whole architecture is trained end-to-end by jointly optimizing two losses, i.e., reconstruction loss from reconstructing observed links, and ranking loss from preserving the relative ordering of hash codes. A novel discrete optimization strategy based on straight through estimator (STE) with guidance is proposed. The principal idea is to avoid gradient magnification in back-propagation of STE with continuous embedding guidance, in which we begin from learning an easier network that mimic the continuous embedding and let it evolve during the training until it finally goes back to STE. Comprehensive experiments over three publicly available and one real-world Alibaba company datasets demonstrate that our model not only can achieve comparable performance compared with its continuous counterpart but also runs multiple times faster during inference.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [2.673032522201538, -31.23891258239746]}, {"key": "", "year": "", "title": "Tan2021bcd", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"BCD: A Cross-Architecture Binary Comparison Database Experiment Using Locality Sensitive Hashing Algorithms\"\nauthors: Tan Haoxi\nconference: Arxiv\nyear: 2021\nbibkey: tan2021bcd\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2112.05492\"}   - {name: \"Code\", url: \"https://github.com/h4sh5/bcddb\"}\ntags: ['ARXIV', 'LSH']\n---\nGiven a binary executable without source code, it is difficult to determine what each function in the binary does by reverse engineering it, and even harder without prior experience and context. In this paper, we performed a comparison of different hashing functions' effectiveness at detecting similar lifted snippets of LLVM IR code, and present the design and implementation of a framework for cross-architecture binary code similarity search database using MinHash as the chosen hashing algorithm, over SimHash, SSDEEP and TLSH. The motivation is to help reverse engineers to quickly gain context of functions in an unknown binary by comparing it against a database of known functions. The code for this project is open source and can be found at https://github.com/h4sh5/bcddb\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-12.737916946411133, 15.925515174865723]}, {"key": "", "year": "", "title": "Tan2021instance", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Instance-level Image Retrieval using Reranking Transformers\"\nauthors: Tan Fuwen, Yuan Jiangbo, Ordonez Vicente\nconference: Arxiv\nyear: 2021\nbibkey: tan2021instance\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2103.12236\"}   - {name: \"Code\", url: \"https://github.com/uvavision/RerankingTransformer.\"}\ntags: ['ARXIV', 'Image Retrieval', 'Supervised']\n---\nInstance-level image retrieval is the task of searching in a large database for images that match an object in a query image. To address this task, systems usually rely on a retrieval step that uses global image descriptors, and a subsequent step that performs domain-specific refinements or reranking by leveraging operations such as geometric verification based on local features. In this work, we propose Reranking Transformers (RRTs) as a general model to incorporate both local and global features to rerank the matching images in a supervised fashion and thus replace the relatively expensive process of geometric verification. RRTs are lightweight and can be easily parallelized so that reranking a set of top matching results can be performed in a single forward-pass. We perform extensive experiments on the Revisited Oxford and Paris datasets, and the Google Landmarks v2 dataset, showing that RRTs outperform previous reranking approaches while using much fewer local descriptors. Moreover, we demonstrate that, unlike existing approaches, RRTs can be optimized jointly with the feature extractor, which can lead to feature representations tailored to downstream tasks and further accuracy improvements. The code and trained models are publicly available at https://github.com/uvavision/RerankingTransformer.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [7.930150985717773, 15.52581787109375]}, {"key": "", "year": "", "title": "Tan2023fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast Locality Sensitive Hashing with Theoretical Guarantee\"\nauthors: Tan Zongyuan, Wang Hongya, Xu Bo, Luo Minjie, Du Ming\nconference: Arxiv\nyear: 2023\nbibkey: tan2023fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2309.15479\"}\ntags: ['ARXIV', 'LSH']\n---\nLocality-sensitive hashing (LSH) is an effective randomized technique widely used in many machine learning tasks. The cost of hashing is proportional to data dimensions, and thus often the performance bottleneck when dimensionality is high and the number of hash functions involved is large. Surprisingly, however, little work has been done to improve the efficiency of LSH computation. In this paper, we design a simple yet efficient LSH scheme, named FastLSH, under l2 norm. By combining random sampling and random projection, FastLSH reduces the time complexity from O(n) to O(m) (m&lt;n), where n is the data dimensionality and m is the number of sampled dimensions. Moreover, FastLSH has provable LSH property, which distinguishes it from the non-LSH fast sketches. We conduct comprehensive experiments over a collection of real and synthetic datasets for the nearest neighbor search task. Experimental results demonstrate that FastLSH is on par with the state-of-the-arts in terms of answer quality, space occupation and query efficiency, while enjoying up to 80x speedup in hash function evaluation. We believe that FastLSH is a promising alternative to the classic LSH scheme.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-17.472503662109375, -11.012566566467285]}, {"key": "", "year": "", "title": "Tan2023unfolded", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Unfolded Self-Reconstruction LSH: Towards Machine Unlearning in Approximate Nearest Neighbour Search\"\nauthors: Tan Kim Yong, Lyu Yueming, Ong Yew Soon, Tsang Ivor W.\nconference: Arxiv\nyear: 2023\nbibkey: tan2023unfolded\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2304.02350\"}\ntags: ['ARXIV', 'LSH']\n---\nApproximate nearest neighbour (ANN) search is an essential component of search engines, recommendation systems, etc. Many recent works focus on learning-based data-distribution-dependent hashing and achieve good retrieval performance. However, due to increasing demand for users' privacy and security, we often need to remove users' data information from Machine Learning (ML) models to satisfy specific privacy and security requirements. This need requires the ANN search algorithm to support fast online data deletion and insertion. Current learning-based hashing methods need retraining the hash function, which is prohibitable due to the vast time-cost of large-scale data. To address this problem, we propose a novel data-dependent hashing method named unfolded self-reconstruction locality-sensitive hashing (USR-LSH). Our USR-LSH unfolded the optimization update for instance-wise data reconstruction, which is better for preserving data information than data-independent LSH. Moreover, our USR-LSH supports fast online data deletion and insertion without retraining. To the best of our knowledge, we are the first to address the machine unlearning of retrieval problems. Empirically, we demonstrate that USR-LSH outperforms the state-of-the-art data-distribution-independent LSH in ANN tasks in terms of precision and recall. We also show that USR-LSH has significantly faster data deletion and insertion time than learning-based data-dependent hashing.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-15.64808464050293, -7.508762359619141]}, {"key": "", "year": "", "title": "Tanaka2021fake", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fake-image detection with Robust Hashing\"\nauthors: Tanaka Miki, Kiya Hitoshi\nconference: Arxiv\nyear: 2021\nbibkey: tanaka2021fake\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2102.01313\"}\ntags: ['ARXIV', 'GAN', 'TIP']\n---\nIn this paper, we investigate whether robust hashing has a possibility to robustly detect fake-images even when multiple manipulation techniques such as JPEG compression are applied to images for the first time. In an experiment, the proposed fake detection with robust hashing is demonstrated to outperform state-of-the-art one under the use of various datasets including fake images generated with GANs.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-4.042069911956787, 23.589815139770508]}, {"key": "", "year": "", "title": "Tang2021when", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"When Similarity Digest Meets Vector Management System: A Survey on Similarity Hash Function\"\nauthors: Tang Zhushou, Tang Lingyi, Tang Keying, Tang Ruoying\nconference: Arxiv\nyear: 2021\nbibkey: tang2021when\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2109.08789\"}\ntags: ['ARXIV', 'Survey Paper']\n---\nThe booming vector manage system calls for feasible similarity hash function as a front-end to perform similarity analysis. In this paper, we make a systematical survey on the existent well-known similarity hash functions to tease out the satisfied ones. We conclude that the similarity hash function MinHash and Nilsimsa can be directly marshaled into the pipeline of similarity analysis using vector manage system. After that, we make a brief and empirical discussion on the performance, drawbacks of the these functions and highlight MinHash, the variant of SimHash and feature hashing are the best for vector management system for large-scale similarity analysis.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [15.106471061706543, -14.051351547241211]}, {"key": "", "year": "", "title": "Tanioka2019a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Fast Content-Based Image Retrieval Method Using Deep Visual Features\"\nauthors: Tanioka Hiroki\nconference: \nyear: 2019\nbibkey: tanioka2019a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1908.01505\"}\ntags: ['CNN', 'Image Retrieval']\n---\nFast and scalable Content-Based Image Retrieval using visual features is required for document analysis, Medical image analysis, etc. in the present age. Convolutional Neural Network (CNN) activations as features achieved their outstanding performance in this area. Deep Convolutional representations using the softmax function in the output layer are also ones among visual features. However, almost all the image retrieval systems hold their index of visual features on main memory in order to high responsiveness, limiting their applicability for big data applications. In this paper, we propose a fast calculation method of cosine similarity with L2 norm indexed in advance on Elasticsearch. We evaluate our approach with ImageNet Dataset and VGG-16 pre-trained model. The evaluation results show the effectiveness and efficiency of our proposed method.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.739276885986328, 26.139442443847656]}, {"key": "", "year": "", "title": "Taquet2010invariant", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Invariant Spectral Hashing of Image Saliency Graph\"\nauthors: Taquet Maxime, Jacques Laurent, De Vleeschouwer Christophe, Macq Benoit\nconference: Arxiv\nyear: 2010\nbibkey: taquet2010invariant\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1009.3029\"}\ntags: ['ARXIV', 'Graph']\n---\nImage hashing is the process of associating a short vector of bits to an image. The resulting summaries are useful in many applications including image indexing, image authentication and pattern recognition. These hashes need to be invariant under transformations of the image that result in similar visual content, but should drastically differ for conceptually distinct contents. This paper proposes an image hashing method that is invariant under rotation, scaling and translation of the image. The gist of our approach relies on the geometric characterization of salient point distribution in the image. This is achieved by the definition of a \"saliency graph\" connecting these points jointly with an image intensity function on the graph nodes. An invariant hash is then obtained by considering the spectrum of this function in the eigenvector basis of the Laplacian graph, that is, its graph Fourier transform. Interestingly, this spectrum is invariant under any relabeling of the graph nodes. The graph reveals geometric information of the image, making the hash robust to image transformation, yet distinct for different visual content. The efficiency of the proposed method is assessed on a set of MRI 2-D slices and on a database of faces.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [8.09591293334961, -30.12498664855957]}, {"key": "", "year": "", "title": "Tatsuno2024aisaq", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"AiSAQ: All-in-Storage ANNS with Product Quantization for DRAM-free Information Retrieval\"\nauthors: Tatsuno Kento, Miyashita Daisuke, Ikeda Taiga, Ishiyama Kiyoshi, Sumiyoshi Kazunari, Deguchi Jun\nconference: Arxiv\nyear: 2024\nbibkey: tatsuno2024aisaq\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2404.06004\"}\ntags: ['ARXIV', 'Graph', 'Quantisation', 'TIP']\n---\nIn approximate nearest neighbor search (ANNS) methods based on approximate proximity graphs, DiskANN achieves good recall-speed balance for large-scale datasets using both of RAM and storage. Despite it claims to save memory usage by loading compressed vectors by product quantization (PQ), its memory usage increases in proportion to the scale of datasets. In this paper, we propose All-in-Storage ANNS with Product Quantization (AiSAQ), which offloads the compressed vectors to storage. Our method achieves $\\sim$10 MB memory usage in query search even with billion-scale datasets with minor performance degradation. AiSAQ also reduces the index load time before query search, which enables the index switch between muitiple billion-scale datasets and significantly enhances the flexibility of retrieval-augmented generation (RAG). This method is applicable to all graph-based ANNS algorithms and can be combined with higher-spec ANNS methods in the future.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [4.348214626312256, -13.778034210205078]}, {"key": "", "year": "", "title": "Tavenard2010balancing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Balancing clusters to reduce response time variability in large scale image search\"\nauthors: Tavenard Romain  INRIA - IRISA, Amsaleg Laurent  INRIA - IRISA, J\u00e9gou Herv\u00e9  INRIA - IRISA\nconference: Arxiv\nyear: 2010\nbibkey: tavenard2010balancing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1009.4739\"}\ntags: ['ARXIV']\n---\nMany algorithms for approximate nearest neighbor search in high-dimensional spaces partition the data into clusters. At query time, in order to avoid exhaustive search, an index selects the few (or a single) clusters nearest to the query point. Clusters are often produced by the well-known $k$-means approach since it has several desirable properties. On the downside, it tends to produce clusters having quite different cardinalities. Imbalanced clusters negatively impact both the variance and the expectation of query response times. This paper proposes to modify $k$-means centroids to produce clusters with more comparable sizes without sacrificing the desirable properties. Experiments with a large scale collection of image descriptors show that our algorithm significantly reduces the variance of response times without seriously impacting the search quality.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [6.048293590545654, -23.146991729736328]}, {"key": "", "year": "", "title": "Tchayekondi2020a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A new hashing based nearest neighbors selection technique for big datasets\"\nauthors: Tchaye-Kondi Jude, Zhai Yanlong, Zhu Liehuang\nconference: Arxiv\nyear: 2020\nbibkey: tchayekondi2020a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2004.02290\"}\ntags: ['ARXIV', 'Supervised']\n---\nKNN has the reputation to be the word simplest but efficient supervised learning algorithm used for either classification or regression. KNN prediction efficiency highly depends on the size of its training data but when this training data grows KNN suffers from slowness in making decisions since it needs to search nearest neighbors within the entire dataset at each decision making. This paper proposes a new technique that enables the selection of nearest neighbors directly in the neighborhood of a given observation. The proposed approach consists of dividing the data space into subcells of a virtual grid built on top of data space. The mapping between the data points and subcells is performed using hashing. When it comes to select the nearest neighbors of a given observation, we firstly identify the cell the observation belongs by using hashing, and then we look for nearest neighbors from that central cell and cells around it layer by layer. From our experiment performance analysis on publicly available datasets, our algorithm outperforms the original KNN in time efficiency with a prediction quality as good as that of KNN it also offers competitive performance with solutions like KDtree\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-8.644244194030762, -8.43568229675293]}, {"key": "", "year": "", "title": "Teichmann2018detect", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Detect-to-Retrieve: Efficient Regional Aggregation for Image Search\"\nauthors: Teichmann Marvin, Araujo Andre, Zhu Menglong, Sim Jack\nconference: Arxiv\nyear: 2018\nbibkey: teichmann2018detect\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1812.01584\"}   - {name: \"Code\", url: \"https://github.com/tensorflow/models/tree/master/research/delf.\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nRetrieving object instances among cluttered scenes efficiently requires compact yet comprehensive regional image representations. Intuitively, object semantics can help build the index that focuses on the most relevant regions. However, due to the lack of bounding-box datasets for objects of interest among retrieval benchmarks, most recent work on regional representations has focused on either uniform or class-agnostic region selection. In this paper, we first fill the void by providing a new dataset of landmark bounding boxes, based on the Google Landmarks dataset, that includes $86k$ images with manually curated boxes from $15k$ unique landmarks. Then, we demonstrate how a trained landmark detector, using our new dataset, can be leveraged to index image regions and improve retrieval accuracy while being much more efficient than existing regional methods. In addition, we introduce a novel regional aggregated selective match kernel (R-ASMK) to effectively combine information from detected regions into an improved holistic image representation. R-ASMK boosts image retrieval accuracy substantially with no dimensionality increase, while even outperforming systems that index image regions independently. Our complete image retrieval system improves upon the previous state-of-the-art by significant margins on the Revisited Oxford and Paris datasets. Code and data available at the project webpage: https://github.com/tensorflow/models/tree/master/research/delf.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [9.616454124450684, 15.665241241455078]}, {"key": "", "year": "", "title": "Teixeira2013scalable", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Scalable Locality-Sensitive Hashing for Similarity Search in High-Dimensional, Large-Scale Multimedia Datasets\"\nauthors: Teixeira Thiago S. F. X., Teodoro George, Valle Eduardo, Saltz Joel H.\nconference: Arxiv\nyear: 2013\nbibkey: teixeira2013scalable\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1310.4136\"}\ntags: ['ARXIV', 'LSH']\n---\nSimilarity search is critical for many database applications, including the increasingly popular online services for Content-Based Multimedia Retrieval (CBMR). These services, which include image search engines, must handle an overwhelming volume of data, while keeping low response times. Thus, scalability is imperative for similarity search in Web-scale applications, but most existing methods are sequential and target shared-memory machines. Here we address these issues with a distributed, efficient, and scalable index based on Locality-Sensitive Hashing (LSH). LSH is one of the most efficient and popular techniques for similarity search, but its poor referential locality properties has made its implementation a challenging problem. Our solution is based on a widely asynchronous dataflow parallelization with a number of optimizations that include a hierarchical parallelization to decouple indexing and data storage, locality-aware data partition strategies to reduce message passing, and multi-probing to limit memory usage. The proposed parallelization attained an efficiency of 90% in a distributed system with about 800 CPU cores. In particular, the original locality-aware data partition reduced the number of messages exchanged in 30%. Our parallel LSH was evaluated using the largest public dataset for similarity search (to the best of our knowledge) with $10^9$ 128-d SIFT descriptors extracted from Web images. This is two orders of magnitude larger than datasets that previous LSH parallelizations could handle.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-3.0402705669403076, -18.506330490112305]}, {"key": "", "year": "", "title": "Temburwar2021deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Learning Based Image Retrieval in the JPEG Compressed Domain\"\nauthors: Temburwar Shrikant, Rajesh Bulla, Javed Mohammed\nconference: Arxiv\nyear: 2021\nbibkey: temburwar2021deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2107.03648\"}\ntags: ['ARXIV', 'Deep Learning', 'Image Retrieval']\n---\nContent-based image retrieval (CBIR) systems on pixel domain use low-level features, such as colour, texture and shape, to retrieve images. In this context, two types of image representations i.e. local and global image features have been studied in the literature. Extracting these features from pixel images and comparing them with images from the database is very time-consuming. Therefore, in recent years, there has been some effort to accomplish image analysis directly in the compressed domain with lesser computations. Furthermore, most of the images in our daily transactions are stored in the JPEG compressed format. Therefore, it would be ideal if we could retrieve features directly from the partially decoded or compressed data and use them for retrieval. Here, we propose a unified model for image retrieval which takes DCT coefficients as input and efficiently extracts global and local features directly in the JPEG compressed domain for accurate image retrieval. The experimental findings indicate that our proposed model performed similarly to the current DELG model which takes RGB features as an input with reference to mean average precision while having a faster training and retrieval speed.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [15.185334205627441, 15.137076377868652]}, {"key": "", "year": "", "title": "Teofili2019lucene", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Lucene for Approximate Nearest-Neighbors Search on Arbitrary Dense Vectors\"\nauthors: Teofili Tommaso, Lin Jimmy\nconference: Arxiv\nyear: 2019\nbibkey: teofili2019lucene\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1910.10208\"}\ntags: ['ARXIV', 'Deep Learning', 'LSH']\n---\nWe demonstrate three approaches for adapting the open-source Lucene search library to perform approximate nearest-neighbor search on arbitrary dense vectors, using similarity search on word embeddings as a case study. At its core, Lucene is built around inverted indexes of a document collection's (sparse) term-document matrix, which is incompatible with the lower-dimensional dense vectors that are common in deep learning applications. We evaluate three techniques to overcome these challenges that can all be natively integrated into Lucene: the creation of documents populated with fake words, LSH applied to lexical realizations of dense vectors, and k-d trees coupled with dimensionality reduction. Experiments show that the \"fake words\" approach represents the best balance between effectiveness and efficiency. These techniques are integrated into the Anserini open-source toolkit and made available to the community.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [13.696568489074707, -10.35604190826416]}, {"key": "", "year": "", "title": "Tepper2020procrustean", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Procrustean Orthogonal Sparse Hashing\"\nauthors: Tepper Mariano, Sengupta Dipanjan, Willke Ted\nconference: Arxiv\nyear: 2020\nbibkey: tepper2020procrustean\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2006.04847\"}\ntags: ['ARXIV']\n---\nHashing is one of the most popular methods for similarity search because of its speed and efficiency. Dense binary hashing is prevalent in the literature. Recently, insect olfaction was shown to be structurally and functionally analogous to sparse hashing [6]. Here, we prove that this biological mechanism is the solution to a well-posed optimization problem. Furthermore, we show that orthogonality increases the accuracy of sparse hashing. Next, we present a novel method, Procrustean Orthogonal Sparse Hashing (POSH), that unifies these findings, learning an orthogonal transform from training data compatible with the sparse hashing mechanism. We provide theoretical evidence of the shortcomings of Optimal Sparse Lifting (OSL) [22] and BioHash [30], two related olfaction-inspired methods, and propose two new methods, Binary OSL and SphericalHash, to address these deficiencies. We compare POSH, Binary OSL, and SphericalHash to several state-of-the-art hashing methods and provide empirical results for the superiority of the proposed methods across a wide range of standard benchmarks and parameter settings.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-6.312636852264404, -8.840083122253418]}, {"key": "", "year": "", "title": "Thakur2019conv", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Conv-codes: Audio Hashing For Bird Species Classification\"\nauthors: Thakur Anshul, Sharma Pulkit, Abrol Vinayak, Rajan Padmanabhan\nconference: Arxiv\nyear: 2019\nbibkey: thakur2019conv\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1902.02498\"}\ntags: ['ARXIV', 'Graph', 'Supervised']\n---\nIn this work, we propose a supervised, convex representation based audio hashing framework for bird species classification. The proposed framework utilizes archetypal analysis, a matrix factorization technique, to obtain convex-sparse representations of a bird vocalization. These convex representations are hashed using Bloom filters with non-cryptographic hash functions to obtain compact binary codes, designated as conv-codes. The conv-codes extracted from the training examples are clustered using class-specific k-medoids clustering with Jaccard coefficient as the similarity metric. A hash table is populated using the cluster centers as keys while hash values/slots are pointers to the species identification information. During testing, the hash table is searched to find the species information corresponding to a cluster center that exhibits maximum similarity with the test conv-code. Hence, the proposed framework classifies a bird vocalization in the conv-code space and requires no explicit classifier or reconstruction error calculations. Apart from that, based on min-hash and direct addressing, we also propose a variant of the proposed framework that provides faster and effective classification. The performances of both these frameworks are compared with existing bird species classification frameworks on the audio recordings of 50 different bird species.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [32.579139709472656, 12.527998924255371]}, {"key": "", "year": "", "title": "Thomas2020preserving", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Preserving Semantic Neighborhoods for Robust Cross-modal Retrieval\"\nauthors: Thomas Christopher, Kovashka Adriana\nconference: ECCV\nyear: 2020\nbibkey: thomas2020preserving\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2007.08617\"}\ntags: ['Cross Modal']\n---\nThe abundance of multimodal data (e.g. social media posts) has inspired interest in cross-modal retrieval methods. Popular approaches rely on a variety of metric learning losses, which prescribe what the proximity of image and text should be, in the learned space. However, most prior methods have focused on the case where image and text convey redundant information; in contrast, real-world image-text pairs convey complementary information with little overlap. Further, images in news articles and media portray topics in a visually diverse fashion; thus, we need to take special care to ensure a meaningful image representation. We propose novel within-modality losses which encourage semantic coherency in both the text and image subspaces, which does not necessarily align with visual coherency. Our method ensures that not only are paired images and texts close, but the expected image-image and text-text relationships are also observed. Our approach improves the results of cross-modal retrieval on four datasets compared to five baselines.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [17.700885772705078, 2.23099946975708]}, {"key": "", "year": "", "title": "Thorup2013bottom", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Bottom-k and Priority Sampling, Set Similarity and Subset Sums with Minimal Independence\"\nauthors: Thorup Mikkel\nconference: Arxiv\nyear: 2013\nbibkey: thorup2013bottom\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1303.5479\"}\ntags: ['ARXIV', 'TOM']\n---\nWe consider bottom-k sampling for a set X, picking a sample S_k(X) consisting of the k elements that are smallest according to a given hash function h. With this sample we can estimate the relative size f=|Y|/|X| of any subset Y as |S_k(X) intersect Y|/k. A standard application is the estimation of the Jaccard similarity f=|A intersect B|/|A union B| between sets A and B. Given the bottom-k samples from A and B, we construct the bottom-k sample of their union as S_k(A union B)=S_k(S_k(A) union S_k(B)), and then the similarity is estimated as |S_k(A union B) intersect S_k(A) intersect S_k(B)|/k. We show here that even if the hash function is only 2-independent, the expected relative error is O(1/sqrt(fk)). For fk=Omega(1) this is within a constant factor of the expected relative error with truly random hashing. For comparison, consider the classic approach of kxmin-wise where we use k hash independent functions h_1,...,h_k, storing the smallest element with each hash function. For kxmin-wise there is an at least constant bias with constant independence, and it is not reduced with larger k. Recently Feigenblat et al. showed that bottom-k circumvents the bias if the hash function is 8-independent and k is sufficiently large. We get down to 2-independence for any k. Our result is based on a simply union bound, transferring generic concentration bounds for the hashing scheme to the bottom-k sample, e.g., getting stronger probability error bounds with higher independence. For weighted sets, we consider priority sampling which adapts efficiently to the concrete input weights, e.g., benefiting strongly from heavy-tailed input. This time, the analysis is much more involved, but again we show that generic concentration bounds can be applied.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-14.527044296264648, -20.472158432006836]}, {"key": "", "year": "", "title": "Thorup2015fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast and Powerful Hashing using Tabulation\"\nauthors: Thorup Mikkel\nconference: Arxiv\nyear: 2015\nbibkey: thorup2015fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1505.01523\"}\ntags: ['ARXIV', 'Survey Paper']\n---\nRandomized algorithms are often enjoyed for their simplicity, but the hash functions employed to yield the desired probabilistic guarantees are often too complicated to be practical. Here we survey recent results on how simple hashing schemes based on tabulation provide unexpectedly strong guarantees. Simple tabulation hashing dates back to Zobrist [1970]. Keys are viewed as consisting of $c$ characters and we have precomputed character tables $h_1,...,h_c$ mapping characters to random hash values. A key $x=(x_1,...,x_c)$ is hashed to $h_1[x_1] \\oplus h_2[x_2].....\\oplus h_c[x_c]$. This schemes is very fast with character tables in cache. While simple tabulation is not even 4-independent, it does provide many of the guarantees that are normally obtained via higher independence, e.g., linear probing and Cuckoo hashing. Next we consider twisted tabulation where one input character is \"twisted\" in a simple way. The resulting hash function has powerful distributional properties: Chernoff-Hoeffding type tail bounds and a very small bias for min-wise hashing. This also yields an extremely fast pseudo-random number generator that is provably good for many classic randomized algorithms and data-structures. Finally, we consider double tabulation where we compose two simple tabulation functions, applying one to the output of the other, and show that this yields very high independence in the classic framework of Carter and Wegman [1977]. In fact, w.h.p., for a given set of size proportional to that of the space consumed, double tabulation gives fully-random hashing. We also mention some more elaborate tabulation schemes getting near-optimal independence for given time and space. While these tabulation schemes are all easy to implement and use, their analysis is not.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-20.029539108276367, -16.631975173950195]}, {"key": "", "year": "", "title": "Thorup2015high", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"High Speed Hashing for Integers and Strings\"\nauthors: Thorup Mikkel\nconference: Arxiv\nyear: 2015\nbibkey: thorup2015high\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1504.06804\"}\ntags: ['ARXIV']\n---\nThese notes describe the most efficient hash functions currently known for hashing integers and strings. These modern hash functions are often an order of magnitude faster than those presented in standard text books. They are also simpler to implement, and hence a clear win in practice, but their analysis is harder. Some of the most practical hash functions have only appeared in theory papers, and some of them requires combining results from different theory papers. The goal here is to combine the information in lecture-style notes that can be used by theoreticians and practitioners alike, thus making these practical fruits of theory more widely accessible.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-21.57058334350586, -12.136502265930176]}, {"key": "", "year": "", "title": "Thorup2015linear", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Linear Probing with 5-Independent Hashing\"\nauthors: Thorup Mikkel\nconference: Arxiv\nyear: 2015\nbibkey: thorup2015linear\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1509.04549\"}\ntags: ['ARXIV']\n---\nThese lecture notes show that linear probing takes expected constant time if the hash function is 5-independent. This result was first proved by Pagh et al. [STOC'07,SICOMP'09]. The simple proof here is essentially taken from [Patrascu and Thorup ICALP'10]. We will also consider a smaller space version of linear probing that may have false positives like Bloom filters. These lecture notes illustrate the use of higher moments in data structures, and could be used in a course on randomized algorithms.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-33.73053741455078, -8.597989082336426]}, {"key": "", "year": "", "title": "Tian2017semi", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Semi-supervised Multimodal Hashing\"\nauthors: Tian Dayong, Gong Maoguo, Zhou Deyun, Shi Jiao, Lei Yu\nconference: Arxiv\nyear: 2017\nbibkey: tian2017semi\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1712.03404\"}\ntags: ['ARXIV', 'Semi Supervised', 'Supervised', 'TIP', 'Unsupervised']\n---\nRetrieving nearest neighbors across correlated data in multiple modalities, such as image-text pairs on Facebook and video-tag pairs on YouTube, has become a challenging task due to the huge amount of data. Multimodal hashing methods that embed data into binary codes can boost the retrieving speed and reduce storage requirement. As unsupervised multimodal hashing methods are usually inferior to supervised ones, while the supervised ones requires too much manually labeled data, the proposed method in this paper utilizes a part of labels to design a semi-supervised multimodal hashing method. It first computes the transformation matrices for data matrices and label matrix. Then, with these transformation matrices, fuzzy logic is introduced to estimate a label matrix for unlabeled data. Finally, it uses the estimated label matrix to learn hashing functions for data in each modality to generate a unified binary code matrix. Experiments show that the proposed semi-supervised method with 50% labels can get a medium performance among the compared supervised ones and achieve an approximate performance to the best supervised method with 90% labels. With only 10% labels, the proposed method can still compete with the worst compared supervised one.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-6.750687122344971, 0.006799205206334591]}, {"key": "", "year": "", "title": "Tian2018learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning Decorrelated Hashing Codes for Multimodal Retrieval\"\nauthors: Tian Dayong\nconference: Arxiv\nyear: 2018\nbibkey: tian2018learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1803.00682\"}\ntags: ['ARXIV', 'TIP']\n---\nIn social networks, heterogeneous multimedia data correlate to each other, such as videos and their corresponding tags in YouTube and image-text pairs in Facebook. Nearest neighbor retrieval across multiple modalities on large data sets becomes a hot yet challenging problem. Hashing is expected to be an efficient solution, since it represents data as binary codes. As the bit-wise XOR operations can be fast handled, the retrieval time is greatly reduced. Few existing multimodal hashing methods consider the correlation among hashing bits. The correlation has negative impact on hashing codes. When the hashing code length becomes longer, the retrieval performance improvement becomes slower. In this paper, we propose a minimum correlation regularization (MCR) for multimodal hashing. First, the sigmoid function is used to embed the data matrices. Then, the MCR is applied on the output of sigmoid function. As the output of sigmoid function approximates a binary code matrix, the proposed MCR can efficiently decorrelate the hashing codes. Experiments show the superiority of the proposed method becomes greater as the code length increases.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-3.0942981243133545, -4.615518093109131]}, {"key": "", "year": "", "title": "Tian2019global", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Global Hashing System for Fast Image Search\"\nauthors: Tian Dayong, Tao Dacheng\nconference: Arxiv\nyear: 2019\nbibkey: tian2019global\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1904.08685\"}\ntags: ['ARXIV']\n---\nHashing methods have been widely investigated for fast approximate nearest neighbor searching in large data sets. Most existing methods use binary vectors in lower dimensional spaces to represent data points that are usually real vectors of higher dimensionality. We divide the hashing process into two steps. Data points are first embedded in a low-dimensional space, and the global positioning system method is subsequently introduced but modified for binary embedding. We devise dataindependent and data-dependent methods to distribute the satellites at appropriate locations. Our methods are based on finding the tradeoff between the information losses in these two steps. Experiments show that our data-dependent method outperforms other methods in different-sized data sets from 100k to 10M. By incorporating the orthogonality of the code matrix, both our data-independent and data-dependent methods are particularly impressive in experiments on longer bits.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [17.305349349975586, -3.7034780979156494]}, {"key": "", "year": "", "title": "Tissier2018near", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Near-lossless Binarization of Word Embeddings\"\nauthors: Tissier Julien, Gravier Christophe, Habrard Amaury\nconference: Arxiv\nyear: 2018\nbibkey: tissier2018near\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1803.09065\"}\ntags: ['ARXIV']\n---\nWord embeddings are commonly used as a starting point in many NLP models to achieve state-of-the-art performances. However, with a large vocabulary and many dimensions, these floating-point representations are expensive both in terms of memory and calculations which makes them unsuitable for use on low-resource devices. The method proposed in this paper transforms real-valued embeddings into binary embeddings while preserving semantic information, requiring only 128 or 256 bits for each vector. This leads to a small memory footprint and fast vector operations. The model is based on an autoencoder architecture, which also allows to reconstruct original vectors from the binary ones. Experimental results on semantic similarity, text classification and sentiment analysis tasks show that the binarization of word embeddings only leads to a loss of ~2% in accuracy while vector size is reduced by 97%. Furthermore, a top-k benchmark demonstrates that using these binary vectors is 30 times faster than using real-valued vectors.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [4.376656532287598, -8.320463180541992]}, {"key": "", "year": "", "title": "Tizhoosh2015barcode", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Barcode Annotations for Medical Image Retrieval: A Preliminary Investigation\"\nauthors: Tizhoosh Hamid R.\nconference: Arxiv\nyear: 2015\nbibkey: tizhoosh2015barcode\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1505.05212\"}\ntags: ['ARXIV', 'GAN', 'Image Retrieval']\n---\nThis paper proposes to generate and to use barcodes to annotate medical images and/or their regions of interest such as organs, tumors and tissue types. A multitude of efficient feature-based image retrieval methods already exist that can assign a query image to a certain image class. Visual annotations may help to increase the retrieval accuracy if combined with existing feature-based classification paradigms. Whereas with annotations we usually mean textual descriptions, in this paper barcode annotations are proposed. In particular, Radon barcodes (RBC) are introduced. As well, local binary patterns (LBP) and local Radon binary patterns (LRBP) are implemented as barcodes. The IRMA x-ray dataset with 12,677 training images and 1,733 test images is used to verify how barcodes could facilitate image retrieval.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [28.25558853149414, 20.14796257019043]}, {"key": "", "year": "", "title": "Tizhoosh2016minmax", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"MinMax Radon Barcodes for Medical Image Retrieval\"\nauthors: Tizhoosh H. R., Zhu Shujin, Lo Hanson, Chaudhari Varun, Mehdi Tahmid\nconference: Arxiv\nyear: 2016\nbibkey: tizhoosh2016minmax\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1610.00318\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nContent-based medical image retrieval can support diagnostic decisions by clinical experts. Examining similar images may provide clues to the expert to remove uncertainties in his/her final diagnosis. Beyond conventional feature descriptors, binary features in different ways have been recently proposed to encode the image content. A recent proposal is \"Radon barcodes\" that employ binarized Radon projections to tag/annotate medical images with content-based binary vectors, called barcodes. In this paper, MinMax Radon barcodes are introduced which are superior to \"local thresholding\" scheme suggested in the literature. Using IRMA dataset with 14,410 x-ray images from 193 different classes, the advantage of using MinMax Radon barcodes over \\emph{thresholded} Radon barcodes are demonstrated. The retrieval error for direct search drops by more than 15\\%. As well, SURF, as a well-established non-binary approach, and BRISK, as a recent binary method are examined to compare their results with MinMax Radon barcodes when retrieving images from IRMA dataset. The results demonstrate that MinMax Radon barcodes are faster and more accurate when applied on IRMA images.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [27.93185806274414, 20.86618995666504]}, {"key": "", "year": "", "title": "Toker2024a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Dataset for Metaphor Detection in Early Medieval Hebrew Poetry\"\nauthors: Toker Michael, Mishali Oren, M\u00fcnz-Manor Ophir, Kimelfeld Benny, Belinkov Yonatan\nconference: Arxiv\nyear: 2024\nbibkey: toker2024a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2402.17371\"}\ntags: ['ARXIV']\n---\nThere is a large volume of late antique and medieval Hebrew texts. They represent a crucial linguistic and cultural bridge between Biblical and modern Hebrew. Poetry is prominent in these texts and one of its main haracteristics is the frequent use of metaphor. Distinguishing figurative and literal language use is a major task for scholars of the Humanities, especially in the fields of literature, linguistics, and hermeneutics. This paper presents a new, challenging dataset of late antique and medieval Hebrew poetry with expert annotations of metaphor, as well as some baseline results, which we hope will facilitate further research in this area.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [28.187496185302734, -3.5691354274749756]}, {"key": "", "year": "", "title": "Tolias2014orientation", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Orientation covariant aggregation of local descriptors with embeddings\"\nauthors: Tolias Giorgos  INRIA, Furon Teddy  INRIA, J\u00e9gou Herv\u00e9  INRIA\nconference: Arxiv\nyear: 2014\nbibkey: tolias2014orientation\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1407.2170\"}\ntags: ['ARXIV']\n---\nImage search systems based on local descriptors typically achieve orientation invariance by aligning the patches on their dominant orientations. Albeit successful, this choice introduces too much invariance because it does not guarantee that the patches are rotated consistently. This paper introduces an aggregation strategy of local descriptors that achieves this covariance property by jointly encoding the angle in the aggregation stage in a continuous manner. It is combined with an efficient monomial embedding to provide a codebook-free method to aggregate local descriptors into a single vector representation. Our strategy is also compatible and employed with several popular encoding methods, in particular bag-of-words, VLAD and the Fisher vector. Our geometric-aware aggregation strategy is effective for image search, as shown by experiments performed on standard benchmarks for image and particular object retrieval, namely Holidays and Oxford buildings.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [18.915042877197266, 19.693042755126953]}, {"key": "", "year": "", "title": "Tolias2015particular", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Particular object retrieval with integral max-pooling of CNN activations\"\nauthors: Tolias Giorgos, Sicre Ronan, J\u00e9gou Herv\u00e9\nconference: Arxiv\nyear: 2015\nbibkey: tolias2015particular\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1511.05879\"}\ntags: ['ARXIV', 'CNN', 'TIP']\n---\nRecently, image representation built upon Convolutional Neural Network (CNN) has been shown to provide effective descriptors for image search, outperforming pre-CNN features as short-vector representations. Yet such models are not compatible with geometry-aware re-ranking methods and still outperformed, on some particular object retrieval benchmarks, by traditional image search systems relying on precise descriptor matching, geometric re-ranking, or query expansion. This work revisits both retrieval stages, namely initial search and re-ranking, by employing the same primitive information derived from the CNN. We build compact feature vectors that encode several image regions without the need to feed multiple inputs to the network. Furthermore, we extend integral images to handle max-pooling on convolutional layer activations, allowing us to efficiently localize matching objects. The resulting bounding box is finally used for image re-ranking. As a result, this paper significantly improves existing CNN-based recognition pipeline: We report for the first time results competing with traditional methods on the challenging Oxford5k and Paris6k datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.811232566833496, 28.57229232788086]}, {"key": "", "year": "", "title": "Tolias2017asymmetric", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Asymmetric Feature Maps with Application to Sketch Based Retrieval\"\nauthors: Tolias Giorgos, Chum Ond\u0159ej\nconference: Arxiv\nyear: 2017\nbibkey: tolias2017asymmetric\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1704.03946\"}\ntags: ['ARXIV', 'Image Retrieval', 'TIP']\n---\nWe propose a novel concept of asymmetric feature maps (AFM), which allows to evaluate multiple kernels between a query and database entries without increasing the memory requirements. To demonstrate the advantages of the AFM method, we derive a short vector image representation that, due to asymmetric feature maps, supports efficient scale and translation invariant sketch-based image retrieval. Unlike most of the short-code based retrieval systems, the proposed method provides the query localization in the retrieved image. The efficiency of the search is boosted by approximating a 2D translation search via trigonometric polynomial of scores by 1D projections. The projections are a special case of AFM. An order of magnitude speed-up is achieved compared to traditional trigonometric polynomials. The results are boosted by an image-based average query expansion, exceeding significantly the state of the art on standard benchmarks.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [19.01556396484375, 0.39562880992889404]}, {"key": "", "year": "", "title": "Torres2021compact", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Compact and Effective Representations for Sketch-based Image Retrieval\"\nauthors: Torres Pablo, Saavedra Jose M.\nconference: Arxiv\nyear: 2021\nbibkey: torres2021compact\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2104.10278\"}\ntags: ['ARXIV', 'Image Retrieval', 'Supervised', 'Unsupervised']\n---\nSketch-based image retrieval (SBIR) has undergone an increasing interest in the community of computer vision bringing high impact in real applications. For instance, SBIR brings an increased benefit to eCommerce search engines because it allows users to formulate a query just by drawing what they need to buy. However, current methods showing high precision in retrieval work in a high dimensional space, which negatively affects aspects like memory consumption and time processing. Although some authors have also proposed compact representations, these drastically degrade the performance in a low dimension. Therefore in this work, we present different results of evaluating methods for producing compact embeddings in the context of sketch-based image retrieval. Our main interest is in strategies aiming to keep the local structure of the original space. The recent unsupervised local-topology preserving dimension reduction method UMAP fits our requirements and shows outstanding performance, improving even the precision achieved by SOTA methods. We evaluate six methods in two different datasets. We use Flickr15K and eCommerce datasets; the latter is another contribution of this work. We show that UMAP allows us to have feature vectors of 16 bytes improving precision by more than 35%.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [9.972980499267578, 14.369024276733398]}, {"key": "", "year": "", "title": "Tran2017hedera", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hedera: Scalable Indexing and Exploring Entities in Wikipedia Revision History\"\nauthors: Tran Tuan, Nguyen Tu Ngoc\nconference: Arxiv\nyear: 2017\nbibkey: tran2017hedera\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1701.03937\"}\ntags: ['ARXIV']\n---\nMuch of work in semantic web relying on Wikipedia as the main source of knowledge often work on static snapshots of the dataset. The full history of Wikipedia revisions, while contains much more useful information, is still difficult to access due to its exceptional volume. To enable further research on this collection, we developed a tool, named Hedera, that efficiently extracts semantic information from Wikipedia revision history datasets. Hedera exploits Map-Reduce paradigm to achieve rapid extraction, it is able to handle one entire Wikipedia articles revision history within a day in a medium-scale cluster, and supports flexible data structures for various kinds of semantic web study.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [17.281131744384766, -24.08641815185547]}, {"key": "", "year": "", "title": "Trzcinski2018scone", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"SConE: Siamese Constellation Embedding Descriptor for Image Matching\"\nauthors: Trzcinski Tomasz, Komorowski Jacek, Dabala Lukasz, Czarnota Konrad, Kurzejamski Grzegorz, Lynen Simon\nconference: Arxiv\nyear: 2018\nbibkey: trzcinski2018scone\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1809.11054\"}\ntags: ['ARXIV']\n---\nNumerous computer vision applications rely on local feature descriptors, such as SIFT, SURF or FREAK, for image matching. Although their local character makes image matching processes more robust to occlusions, it often leads to geometrically inconsistent keypoint matches that need to be filtered out, e.g. using RANSAC. In this paper we propose a novel, more discriminative, descriptor that includes not only local feature representation, but also information about the geometric layout of neighbouring keypoints. To that end, we use a Siamese architecture that learns a low-dimensional feature embedding of keypoint constellation by maximizing the distances between non-corresponding pairs of matched image patches, while minimizing it for correct matches. The 48-dimensional oating point descriptor that we train is built on top of the state-of-the-art FREAK descriptor achieves significant performance improvement over the competitors on a challenging TUM dataset.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [18.478790283203125, 19.34261131286621]}, {"key": "", "year": "", "title": "Tsai2022learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning Weakly-Supervised Contrastive Representations\"\nauthors: Tsai Yao-Hung Hubert, Li Tianqin, Liu Weixin, Liao Peiyuan, Salakhutdinov Ruslan, Morency Louis-Philippe\nconference: Arxiv\nyear: 2022\nbibkey: tsai2022learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2202.06670\"}\ntags: ['ARXIV', 'Self Supervised', 'Supervised', 'Unsupervised', 'Weakly Supervised']\n---\nWe argue that a form of the valuable information provided by the auxiliary information is its implied data clustering information. For instance, considering hashtags as auxiliary information, we can hypothesize that an Instagram image will be semantically more similar with the same hashtags. With this intuition, we present a two-stage weakly-supervised contrastive learning approach. The first stage is to cluster data according to its auxiliary information. The second stage is to learn similar representations within the same cluster and dissimilar representations for data from different clusters. Our empirical experiments suggest the following three contributions. First, compared to conventional self-supervised representations, the auxiliary-information-infused representations bring the performance closer to the supervised representations, which use direct downstream labels as supervision signals. Second, our approach performs the best in most cases, when comparing our approach with other baseline representation learning methods that also leverage auxiliary data information. Third, we show that our approach also works well with unsupervised constructed clusters (e.g., no auxiliary information), resulting in a strong unsupervised representation learning approach.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-14.622833251953125, 18.134254455566406]}, {"key": "", "year": "", "title": "Tsang2022clustering", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Clustering the Sketch: A Novel Approach to Embedding Table Compression\"\nauthors: Tsang Henry Ling-Hei, Ahle Thomas Dybdahl\nconference: Arxiv\nyear: 2022\nbibkey: tsang2022clustering\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2210.05974\"}\ntags: ['ARXIV', 'Quantisation']\n---\nEmbedding tables are used by machine learning systems to work with categorical features. In modern Recommendation Systems, these tables can be very large, necessitating the development of new methods for fitting them in memory, even during training. We suggest Clustered Compositional Embeddings (CCE) which combines clustering-based compression like quantization to codebooks with dynamic methods like The Hashing Trick and Compositional Embeddings (Shi et al., 2020). Experimentally CCE achieves the best of both worlds: The high compression rate of codebook-based quantization, but *dynamically* like hashing-based methods, so it can be used during training. Theoretically, we prove that CCE is guaranteed to converge to the optimal codebook and give a tight bound for the number of iterations required.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-19.665428161621094, 5.357240200042725]}, {"key": "", "year": "", "title": "Tu2018object", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Object Detection based Deep Unsupervised Hashing\"\nauthors: Tu Rong-Cheng, Mao Xian-Ling, Feng Bo-Si, Bian Bing-Bing, Ying Yu-shu\nconference: Arxiv\nyear: 2018\nbibkey: tu2018object\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1811.09822\"}\ntags: ['ARXIV', 'Image Retrieval', 'Supervised', 'Unsupervised']\n---\nRecently, similarity-preserving hashing methods have been extensively studied for large-scale image retrieval. Compared with unsupervised hashing, supervised hashing methods for labeled data have usually better performance by utilizing semantic label information. Intuitively, for unlabeled data, it will improve the performance of unsupervised hashing methods if we can first mine some supervised semantic 'label information' from unlabeled data and then incorporate the 'label information' into the training process. Thus, in this paper, we propose a novel Object Detection based Deep Unsupervised Hashing method (ODDUH). Specifically, a pre-trained object detection model is utilized to mining supervised 'label information', which is used to guide the learning process to generate high-quality hash codes.Extensive experiments on two public datasets demonstrate that the proposed method outperforms the state-of-the-art unsupervised hashing methods in the image retrieval task.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-4.518383979797363, 14.45460319519043]}, {"key": "", "year": "", "title": "Tu2019deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Cross-Modal Hashing with Hashing Functions and Unified Hash Codes Jointly Learning\"\nauthors: Tu Rong-Cheng, Mao Xian-Ling, Ma Bing, Hu Yong, Yan Tan, Wei Wei, Huang Heyan\nconference: Arxiv\nyear: 2019\nbibkey: tu2019deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1907.12490\"}\ntags: ['ARXIV', 'Cross Modal']\n---\nDue to their high retrieval efficiency and low storage cost, cross-modal hashing methods have attracted considerable attention. Generally, compared with shallow cross-modal hashing methods, deep cross-modal hashing methods can achieve a more satisfactory performance by integrating feature learning and hash codes optimizing into a same framework. However, most existing deep cross-modal hashing methods either cannot learn a unified hash code for the two correlated data-points of different modalities in a database instance or cannot guide the learning of unified hash codes by the feedback of hashing function learning procedure, to enhance the retrieval accuracy. To address the issues above, in this paper, we propose a novel end-to-end Deep Cross-Modal Hashing with Hashing Functions and Unified Hash Codes Jointly Learning (DCHUC). Specifically, by an iterative optimization algorithm, DCHUC jointly learns unified hash codes for image-text pairs in a database and a pair of hash functions for unseen query image-text pairs. With the iterative optimization algorithm, the learned unified hash codes can be used to guide the hashing function learning procedure; Meanwhile, the learned hashing functions can feedback to guide the unified hash codes optimizing procedure. Extensive experiments on three public datasets demonstrate that the proposed method outperforms the state-of-the-art cross-modal hashing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-9.674145698547363, 0.3841833472251892]}, {"key": "", "year": "", "title": "Tu2020deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Cross-modal Hashing via Margin-dynamic-softmax Loss\"\nauthors: Tu Rong-Cheng, Mao Xian-Ling, Tu Rongxin, Bian Binbin, Wei Wei, Huang Heyan\nconference: Arxiv\nyear: 2020\nbibkey: tu2020deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2011.03451\"}\ntags: ['ARXIV', 'Cross Modal', 'Supervised']\n---\nDue to their high retrieval efficiency and low storage cost for cross-modal search task, cross-modal hashing methods have attracted considerable attention. For the supervised cross-modal hashing methods, how to make the learned hash codes preserve semantic information sufficiently contained in the label of datapoints is the key to further enhance the retrieval performance. Hence, almost all supervised cross-modal hashing methods usually depends on defining a similarity between datapoints with the label information to guide the hashing model learning fully or partly. However, the defined similarity between datapoints can only capture the label information of datapoints partially and misses abundant semantic information, then hinders the further improvement of retrieval performance. Thus, in this paper, different from previous works, we propose a novel cross-modal hashing method without defining the similarity between datapoints, called Deep Cross-modal Hashing via \\textit{Margin-dynamic-softmax Loss} (DCHML). Specifically, DCHML first trains a proxy hashing network to transform each category information of a dataset into a semantic discriminative hash code, called proxy hash code. Each proxy hash code can preserve the semantic information of its corresponding category well. Next, without defining the similarity between datapoints to supervise the training process of the modality-specific hashing networks , we propose a novel \\textit{margin-dynamic-softmax loss} to directly utilize the proxy hashing codes as supervised information. Finally, by minimizing the novel \\textit{margin-dynamic-softmax loss}, the modality-specific hashing networks can be trained to generate hash codes which can simultaneously preserve the cross-modal similarity and abundant semantic information well.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-9.716238021850586, -0.8922504186630249]}, {"key": "", "year": "", "title": "Tu2022unsupervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Unsupervised Hashing with Semantic Concept Mining\"\nauthors: Tu Rong-Cheng, Mao Xian-Ling, Lin Kevin Qinghong, Cai Chengfei, Qin Weize, Wang Hongfa, Wei Wei, Huang Heyan\nconference: Arxiv\nyear: 2022\nbibkey: tu2022unsupervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2209.11475\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval', 'Supervised', 'Unsupervised']\n---\nRecently, to improve the unsupervised image retrieval performance, plenty of unsupervised hashing methods have been proposed by designing a semantic similarity matrix, which is based on the similarities between image features extracted by a pre-trained CNN model. However, most of these methods tend to ignore high-level abstract semantic concepts contained in images. Intuitively, concepts play an important role in calculating the similarity among images. In real-world scenarios, each image is associated with some concepts, and the similarity between two images will be larger if they share more identical concepts. Inspired by the above intuition, in this work, we propose a novel Unsupervised Hashing with Semantic Concept Mining, called UHSCM, which leverages a VLP model to construct a high-quality similarity matrix. Specifically, a set of randomly chosen concepts is first collected. Then, by employing a vision-language pretraining (VLP) model with the prompt engineering which has shown strong power in visual representation learning, the set of concepts is denoised according to the training images. Next, the proposed method UHSCM applies the VLP model with prompting again to mine the concept distribution of each image and construct a high-quality semantic similarity matrix based on the mined concept distributions. Finally, with the semantic similarity matrix as guiding information, a novel hashing loss with a modified contrastive loss based regularization item is proposed to optimize the hashing network. Extensive experiments on three benchmark datasets show that the proposed method outperforms the state-of-the-art baselines in the image retrieval task.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-2.7113232612609863, 13.043988227844238]}, {"key": "", "year": "", "title": "Turati2023locality", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Locality-Sensitive Hashing Does Not Guarantee Privacy! Attacks on Google's FLoC and the MinHash Hierarchy System\"\nauthors: Turati Florian  ETH Zurich, Cotrini Carlos  ETH Zurich, Kubicek Karel  ETH Zurich, Basin David  ETH Zurich\nconference: Arxiv\nyear: 2023\nbibkey: turati2023locality\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2302.13635\"}\ntags: ['ARXIV', 'Graph']\n---\nRecently proposed systems aim at achieving privacy using locality-sensitive hashing. We show how these approaches fail by presenting attacks against two such systems: Google's FLoC proposal for privacy-preserving targeted advertising and the MinHash Hierarchy, a system for processing mobile users' traffic behavior in a privacy-preserving way. Our attacks refute the pre-image resistance, anonymity, and privacy guarantees claimed for these systems. In the case of FLoC, we show how to deanonymize users using Sybil attacks and to reconstruct 10% or more of the browsing history for 30% of its users using Generative Adversarial Networks. We achieve this only analyzing the hashes used by FLoC. For MinHash, we precisely identify the movement of a subset of individuals and, on average, we can limit users' movement to just 10% of the possible geographic area, again using just the hashes. In addition, we refute their differential privacy claims.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-31.235612869262695, 6.114139080047607]}, {"key": "", "year": "", "title": "Uchida2016adaptive", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Adaptive Substring Extraction and Modified Local NBNN Scoring for Binary Feature-based Local Mobile Visual Search without False Positives\"\nauthors: Uchida Yusuke, Sakazawa Shigeyuki, Satoh Shin'ichi\nconference: Arxiv\nyear: 2016\nbibkey: uchida2016adaptive\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1610.06266\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nIn this paper, we propose a stand-alone mobile visual search system based on binary features and the bag-of-visual words framework. The contribution of this study is three-fold: (1) We propose an adaptive substring extraction method that adaptively extracts informative bits from the original binary vector and stores them in the inverted index. These substrings are used to refine visual word-based matching. (2) A modified local NBNN scoring method is proposed in the context of image retrieval, which considers the density of binary features in scoring each feature matching. (3) In order to suppress false positives, we introduce a convexity check step that imposes a convexity constraint on the configuration of a transformed reference image. The proposed system improves retrieval accuracy by 11% compared with a conventional method without increasing the database size. Furthermore, our system with the convexity check does not lead to false positive results.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [22.195384979248047, 6.548537731170654]}, {"key": "", "year": "", "title": "Uchida2016image", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Image Retrieval with Fisher Vectors of Binary Features\"\nauthors: Uchida Yusuke, Sakazawa Shigeyuki, Satoh Shin'ichi\nconference: Arxiv\nyear: 2016\nbibkey: uchida2016image\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1609.08291\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nRecently, the Fisher vector representation of local features has attracted much attention because of its effectiveness in both image classification and image retrieval. Another trend in the area of image retrieval is the use of binary features such as ORB, FREAK, and BRISK. Considering the significant performance improvement for accuracy in both image classification and retrieval by the Fisher vector of continuous feature descriptors, if the Fisher vector were also to be applied to binary features, we would receive similar benefits in binary feature based image retrieval and classification. In this paper, we derive the closed-form approximation of the Fisher vector of binary features modeled by the Bernoulli mixture model. We also propose accelerating the Fisher vector by using the approximate value of posterior probability. Experiments show that the Fisher vector representation significantly improves the accuracy of image retrieval compared with a bag of binary words approach.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [23.563140869140625, 16.979042053222656]}, {"key": "", "year": "", "title": "Uchida2016local", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Local Feature Detectors, Descriptors, and Image Representations: A Survey\"\nauthors: Uchida Yusuke\nconference: Arxiv\nyear: 2016\nbibkey: uchida2016local\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1607.08368\"}\ntags: ['ARXIV', 'Deep Learning', 'Image Retrieval', 'Survey Paper']\n---\nWith the advances in both stable interest region detectors and robust and distinctive descriptors, local feature-based image or object retrieval has become a popular research topic. %All of the local feature-based image retrieval system involves two important processes: local feature extraction and image representation. The other key technology for image retrieval systems is image representation such as the bag-of-visual words (BoVW), Fisher vector, or Vector of Locally Aggregated Descriptors (VLAD) framework. In this paper, we review local features and image representations for image retrieval. Because many and many methods are proposed in this area, these methods are grouped into several classes and summarized. In addition, recent deep learning-based approaches for image retrieval are briefly reviewed.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [22.938512802124023, 16.328371047973633]}, {"key": "", "year": "", "title": "Ufer2021object", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Object Retrieval and Localization in Large Art Collections using Deep Multi-Style Feature Fusion and Iterative Voting\"\nauthors: Ufer Nikolai, Lang Sabine, Ommer Bj\u00f6rn\nconference: Arxiv\nyear: 2021\nbibkey: ufer2021object\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2107.06935\"}\ntags: ['ARXIV', 'Graph']\n---\nThe search for specific objects or motifs is essential to art history as both assist in decoding the meaning of artworks. Digitization has produced large art collections, but manual methods prove to be insufficient to analyze them. In the following, we introduce an algorithm that allows users to search for image regions containing specific motifs or objects and find similar regions in an extensive dataset, helping art historians to analyze large digitized art collections. Computer vision has presented efficient methods for visual instance retrieval across photographs. However, applied to art collections, they reveal severe deficiencies because of diverse motifs and massive domain shifts induced by differences in techniques, materials, and styles. In this paper, we present a multi-style feature fusion approach that successfully reduces the domain gap and improves retrieval results without labelled data or curated image collections. Our region-based voting with GPU-accelerated approximate nearest-neighbour search allows us to find and localize even small motifs within an extensive dataset in a few seconds. We obtain state-of-the-art results on the Brueghel dataset and demonstrate its generalization to inhomogeneous collections with a large number of distractors.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [26.411291122436523, -5.407119274139404]}, {"key": "", "year": "", "title": "Ustinova2016learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning Deep Embeddings with Histogram Loss\"\nauthors: Ustinova Evgeniya, Lempitsky Victor\nconference: Arxiv\nyear: 2016\nbibkey: ustinova2016learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1611.00822\"}\ntags: ['ARXIV']\n---\nWe suggest a loss for learning deep embeddings. The new loss does not introduce parameters that need to be tuned and results in very good embeddings across a range of datasets and problems. The loss is computed by estimating two distribution of similarities for positive (matching) and negative (non-matching) sample pairs, and then computing the probability of a positive pair to have a lower similarity score than a negative pair based on the estimated similarity distributions. We show that such operations can be performed in a simple and piecewise-differentiable manner using 1D histograms with soft assignment operations. This makes the proposed loss suitable for learning deep embeddings using stochastic optimization. In the experiments, the new loss performs favourably compared to recently proposed alternatives.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [0.8563147783279419, 0.031214868649840355]}, {"key": "", "year": "", "title": "Vaiwsri2021accurate", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Accurate and Efficient Suffix Tree Based Privacy-Preserving String Matching\"\nauthors: Vaiwsri Sirintra, Ranbaduge Thilina, Christen Peter, Ng Kee Siong\nconference: Arxiv\nyear: 2021\nbibkey: vaiwsri2021accurate\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2104.03018\"}\ntags: ['ARXIV', 'GAN']\n---\nThe task of calculating similarities between strings held by different organizations without revealing these strings is an increasingly important problem in areas such as health informatics, national censuses, genomics, and fraud detection. Most existing privacy-preserving string comparison functions are either based on comparing sets of encoded character q-grams, allow only exact matching of encrypted strings, or they are aimed at long genomic sequences that have a small alphabet. The set-based privacy-preserving similarity functions commonly used to compare name and address strings in the context of privacy-preserving record linkage do not take the positions of sub-strings into account. As a result, two very different strings can potentially be considered as an exact match leading to wrongly linked records. Existing set-based techniques also cannot identify the length of the longest common sub-string across two strings. In this paper we propose a novel approach for accurate and efficient privacy-preserving string matching based on suffix trees that are encoded using chained hashing. We incorporate a hashing based encoding technique upon the encoded suffixes to improve privacy against frequency attacks such as those exploiting Benford's law. Our approach allows various operations to be performed without the strings to be compared being revealed: the length of the longest common sub-string, do two strings have the same beginning, middle or end, and the longest common sub-string similarity between two strings. These functions allow a more accurate comparison of, for example, bank account, credit card, or telephone numbers, which cannot be compared appropriately with existing privacy-preserving string matching techniques. Our evaluation on several data sets with different types of strings validates the privacy and accuracy of our proposed approach.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-6.525328636169434, -5.466647148132324]}, {"key": "", "year": "", "title": "Valdenegrotoro2019implementing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Implementing Noise with Hash functions for Graphics Processing Units\"\nauthors: Valdenegro-Toro Matias, Pincheira Hector\nconference: Arxiv\nyear: 2019\nbibkey: valdenegrotoro2019implementing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1903.12270\"}\ntags: ['ARXIV', 'Graph']\n---\nWe propose a modification to Perlin noise which use computable hash functions instead of textures as lookup tables. We implemented the FNV1, Jenkins and Murmur hashes on Shader Model 4.0 Graphics Processing Units for noise generation. Modified versions of the FNV1 and Jenkins hashes provide very close performance compared to a texture based Perlin noise implementation. Our noise modification enables noise function evaluation without any texture fetches, trading computational power for memory bandwidth.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [23.368389129638672, -8.41430950164795]}, {"key": "", "year": "", "title": "Valle2018visual", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Visual Display and Retrieval of Music Information\"\nauthors: Valle Rafael\nconference: Arxiv\nyear: 2018\nbibkey: valle2018visual\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1807.10204\"}\ntags: ['ARXIV']\n---\nThis paper describes computational methods for the visual display and analysis of music information. We provide a concise description of software, music descriptors and data visualization techniques commonly used in music information retrieval. Finally, we provide use cases where the described software, descriptors and visualizations are showcased.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [31.254114151000977, -2.9060750007629395]}, {"key": "", "year": "", "title": "Valsesia2019analysis", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Analysis of SparseHash: an efficient embedding of set-similarity via sparse projections\"\nauthors: Valsesia Diego, Fosson Sophie Marie, Ravazzi Chiara, Bianchi Tiziano, Magli Enrico\nconference: Arxiv\nyear: 2019\nbibkey: valsesia2019analysis\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1909.01802\"}\ntags: ['ARXIV']\n---\nEmbeddings provide compact representations of signals in order to perform efficient inference in a wide variety of tasks. In particular, random projections are common tools to construct Euclidean distance-preserving embeddings, while hashing techniques are extensively used to embed set-similarity metrics, such as the Jaccard coefficient. In this letter, we theoretically prove that a class of random projections based on sparse matrices, called SparseHash, can preserve the Jaccard coefficient between the supports of sparse signals, which can be used to estimate set similarities. Moreover, besides the analysis, we provide an efficient implementation and we test the performance in several numerical experiments, both on synthetic and real datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.326045036315918, -11.037186622619629]}, {"key": "", "year": "", "title": "Van2015color", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Color Image Retrieval Using Fuzzy Measure Hamming and S-Tree\"\nauthors: Van Thanh The, Le Thanh Manh\nconference: Arxiv\nyear: 2015\nbibkey: van2015color\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1506.01166\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nThis chapter approaches the image retrieval system on the base of the colors of image. It creates fuzzy signature to describe the color of image on color space HSV and builds fuzzy Hamming distance (FHD) to evaluate the similarity between the images. In order to reduce the storage space and speed up the search of similar images, it aims to create S-tree to store fuzzy signature relies on FHD and builds image retrieval algorithm on S-tree. Then, it provides the content-based image retrieval (CBIR) and an image retrieval method on FHD and S-tree. Last but not least, based on this theory, it also presents an application and experimental assessment of the process of querying similar image on the database system over 10,000 images.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [29.68303871154785, 9.098451614379883]}, {"key": "", "year": "", "title": "Van2015image", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Image Retrieval Based on Binary Signature ang S-kGraph\"\nauthors: Van Thanh The, Le Thanh Manh\nconference: Annales Univ. Sci. Budapest, Sect. Comp.,\nyear: 2015\nbibkey: van2015image\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1506.00761\"}\ntags: ['Graph', 'Image Retrieval', 'TIP']\n---\nIn this paper, we introduce an optimum approach for querying similar images on large digital-image databases. Our work is based on RBIR (region-based image retrieval) method which uses multiple regions as the key to retrieval images. This method significantly improves the accuracy of queries. However, this also increases the cost of computing. To reduce this expensive computational cost, we implement binary signature encoder which maps an image to its identification in binary. In order to fasten the lookup, binary signatures of images are classified by the help of S-kGraph. Finally, our work is evaluated on COREL's images.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [28.206523895263672, 9.65988826751709]}, {"key": "", "year": "", "title": "Van2015rbir", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"RBIR Based on Signature Graph\"\nauthors: Van Thanh The, Le Thanh Manh\nconference: Arxiv\nyear: 2015\nbibkey: van2015rbir\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1507.04816\"}\ntags: ['ARXIV', 'Graph', 'Image Retrieval']\n---\nThis paper approaches the image retrieval system on the base of visual features local region RBIR (region-based image retrieval). First of all, the paper presents a method for extracting the interest points based on Harris-Laplace to create the feature region of the image. Next, in order to reduce the storage space and speed up query image, the paper builds the binary signature structure to describe the visual content of image. Based on the image's binary signature, the paper builds the SG (signature graph) to classify and store image's binary signatures. Since then, the paper builds the image retrieval algorithm on SG through the similar measure EMD (earth mover's distance) between the image's binary signatures. Last but not least, the paper gives an image retrieval model RBIR, experiments and assesses the image retrieval method on Corel image database over 10,000 images.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [28.985511779785156, 9.349116325378418]}, {"key": "", "year": "", "title": "Vanblokland2020an", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"An Indexing Scheme and Descriptor for 3D Object Retrieval Based on Local Shape Querying\"\nauthors: van Blokland Bart Iver, Theoharis Theoharis\nconference: Computers &amp; Graphics Volume\nyear: 2020\nbibkey: vanblokland2020an\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2008.02916\"}\ntags: []\n---\nA binary descriptor indexing scheme based on Hamming distance called the Hamming tree for local shape queries is presented. A new binary clutter resistant descriptor named Quick Intersection Count Change Image (QUICCI) is also introduced. This local shape descriptor is extremely small and fast to compare. Additionally, a novel distance function called Weighted Hamming applicable to QUICCI images is proposed for retrieval applications. The effectiveness of the indexing scheme and QUICCI is demonstrated on 828 million QUICCI images derived from the SHREC2017 dataset, while the clutter resistance of QUICCI is shown using the clutterbox experiment.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [22.62442398071289, 0.4276657700538635]}, {"key": "", "year": "", "title": "Vanblokland2021partial", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Partial 3D Object Retrieval using Local Binary QUICCI Descriptors and Dissimilarity Tree Indexing\"\nauthors: van Blokland Bart Iver, Theoharis Theoharis\nconference: Arxiv\nyear: 2021\nbibkey: vanblokland2021partial\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2107.03368\"}\ntags: ['ARXIV']\n---\nA complete pipeline is presented for accurate and efficient partial 3D object retrieval based on Quick Intersection Count Change Image (QUICCI) binary local descriptors and a novel indexing tree. It is shown how a modification to the QUICCI query descriptor makes it ideal for partial retrieval. An indexing structure called Dissimilarity Tree is proposed which can significantly accelerate searching the large space of local descriptors; this is applicable to QUICCI and other binary descriptors. The index exploits the distribution of bits within descriptors for efficient retrieval. The retrieval pipeline is tested on the artificial part of SHREC'16 dataset with near-ideal retrieval results.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [22.313005447387695, 0.4100082218647003]}, {"key": "", "year": "", "title": "Veit2017separating", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Separating Self-Expression and Visual Content in Hashtag Supervision\"\nauthors: Veit Andreas, Nickel Maximilian, Belongie Serge, van der Maaten Laurens\nconference: Arxiv\nyear: 2017\nbibkey: veit2017separating\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1711.09825\"}\ntags: ['ARXIV']\n---\nThe variety, abundance, and structured nature of hashtags make them an interesting data source for training vision models. For instance, hashtags have the potential to significantly reduce the problem of manual supervision and annotation when learning vision models for a large number of concepts. However, a key challenge when learning from hashtags is that they are inherently subjective because they are provided by users as a form of self-expression. As a consequence, hashtags may have synonyms (different hashtags referring to the same visual content) and may be ambiguous (the same hashtag referring to different visual content). These challenges limit the effectiveness of approaches that simply treat hashtags as image-label pairs. This paper presents an approach that extends upon modeling simple image-label pairs by modeling the joint distribution of images, hashtags, and users. We demonstrate the efficacy of such approaches in image tagging and retrieval experiments, and show how the joint model can be used to perform user-conditional retrieval and tagging.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-4.630090236663818, 15.33519458770752]}, {"key": "", "year": "", "title": "Veit2020improving", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Improving Calibration in Deep Metric Learning With Cross-Example Softmax\"\nauthors: Veit Andreas, Wilber Kimberly\nconference: Arxiv\nyear: 2020\nbibkey: veit2020improving\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2011.08824\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nModern image retrieval systems increasingly rely on the use of deep neural networks to learn embedding spaces in which distance encodes the relevance between a given query and image. In this setting, existing approaches tend to emphasize one of two properties. Triplet-based methods capture top-$k$ relevancy, where all top-$k$ scoring documents are assumed to be relevant to a given query Pairwise contrastive models capture threshold relevancy, where all documents scoring higher than some threshold are assumed to be relevant. In this paper, we propose Cross-Example Softmax which combines the properties of top-$k$ and threshold relevancy. In each iteration, the proposed loss encourages all queries to be closer to their matching images than all queries are to all non-matching images. This leads to a globally more calibrated similarity metric and makes distance more interpretable as an absolute measure of relevance. We further introduce Cross-Example Negative Mining, in which each pair is compared to the hardest negative comparisons across the entire batch. Empirically, we show in a series of experiments on Conceptual Captions and Flickr30k, that the proposed method effectively improves global calibration and also retrieval performance.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [15.523322105407715, 9.23987865447998]}, {"key": "", "year": "", "title": "Venkataramanan2023integrating", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Integrating Visual and Semantic Similarity Using Hierarchies for Image Retrieval\"\nauthors: Venkataramanan Aishwarya, Laviale Martin, Pradalier C\u00e9dric\nconference: Arxiv\nyear: 2023\nbibkey: venkataramanan2023integrating\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2308.08431\"}\ntags: ['ARXIV', 'Image Retrieval', 'TOM']\n---\nMost of the research in content-based image retrieval (CBIR) focus on developing robust feature representations that can effectively retrieve instances from a database of images that are visually similar to a query. However, the retrieved images sometimes contain results that are not semantically related to the query. To address this, we propose a method for CBIR that captures both visual and semantic similarity using a visual hierarchy. The hierarchy is constructed by merging classes with overlapping features in the latent space of a deep neural network trained for classification, assuming that overlapping classes share high visual and semantic similarities. Finally, the constructed hierarchy is integrated into the distance calculation metric for similarity search. Experiments on standard datasets: CUB-200-2011 and CIFAR100, and a real-life use case using diatom microscopy images show that our method achieves superior performance compared to the existing methods on image retrieval.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [22.406898498535156, 10.428478240966797]}, {"key": "", "year": "", "title": "Venkateswara2017deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Hashing Network for Unsupervised Domain Adaptation\"\nauthors: Venkateswara Hemanth, Eusebio Jose, Chakraborty Shayok, Panchanathan Sethuraman\nconference: Arxiv\nyear: 2017\nbibkey: venkateswara2017deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1706.07522\"}\ntags: ['ARXIV', 'Deep Learning', 'Supervised', 'TIP', 'Unsupervised']\n---\nIn recent years, deep neural networks have emerged as a dominant machine learning tool for a wide variety of application domains. However, training a deep neural network requires a large amount of labeled data, which is an expensive process in terms of time, labor and human expertise. Domain adaptation or transfer learning algorithms address this challenge by leveraging labeled data in a different, but related source domain, to develop a model for the target domain. Further, the explosive growth of digital data has posed a fundamental challenge concerning its storage and retrieval. Due to its storage and retrieval efficiency, recent years have witnessed a wide application of hashing in a variety of computer vision applications. In this paper, we first introduce a new dataset, Office-Home, to evaluate domain adaptation algorithms. The dataset contains images of a variety of everyday objects from multiple domains. We then propose a novel deep learning framework that can exploit labeled source data and unlabeled target data to learn informative hash codes, to accurately classify unseen target data. To the best of our knowledge, this is the first research effort to exploit the feature learning capabilities of deep neural networks to learn representative hash codes to address the domain adaptation problem. Our extensive empirical studies on multiple transfer tasks corroborate the usefulness of the framework in learning efficient hash codes which outperform existing competitive baselines for unsupervised domain adaptation.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-17.988815307617188, 10.85721492767334]}, {"key": "", "year": "", "title": "Verdoliva2015a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A reliable order-statistics-based approximate nearest neighbor search algorithm\"\nauthors: Verdoliva Luisa, Cozzolino Davide, Poggi Giovanni\nconference: Arxiv\nyear: 2015\nbibkey: verdoliva2015a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1509.03453\"}\ntags: ['ARXIV']\n---\nWe propose a new algorithm for fast approximate nearest neighbor search based on the properties of ordered vectors. Data vectors are classified based on the index and sign of their largest components, thereby partitioning the space in a number of cones centered in the origin. The query is itself classified, and the search starts from the selected cone and proceeds to neighboring ones. Overall, the proposed algorithm corresponds to locality sensitive hashing in the space of directions, with hashing based on the order of components. Thanks to the statistical features emerging through ordering, it deals very well with the challenging case of unstructured data, and is a valuable building block for more complex techniques dealing with structured data. Experiments on both simulated and real-world data prove the proposed algorithm to provide a state-of-the-art performance.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [8.178694725036621, -11.623169898986816]}, {"key": "", "year": "", "title": "Verma2014image", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Image Retrieval And Classification Using Local Feature Vectors\"\nauthors: Verma Vikas\nconference: Arxiv\nyear: 2014\nbibkey: verma2014image\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1409.0749\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nContent Based Image Retrieval(CBIR) is one of the important subfield in the field of Information Retrieval. The goal of a CBIR algorithm is to retrieve semantically similar images in response to a query image submitted by the end user. CBIR is a hard problem because of the phenomenon known as $\\textit \\{semantic gap\\}$. In this thesis, we aim at analyzing the performance of a CBIR system build using local feature vectors and Intermediate Matching Kernel. We also propose a Two-Step Matching process for reducing the response time of the CBIR systems. Further, we develop a Meta-Learning framework for improving the retrieval performance of these systems. Our results show that the Two-Step Matching process significantly reduces response time and the Meta-Learning Framework improves the retrieval performance by more than two fold. We also analyze the performance of various image classification systems that use different image representations constructed from the local feature vectors.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [21.938831329345703, 13.173101425170898]}, {"key": "", "year": "", "title": "Vimina2013a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Sub-block Based Image Retrieval Using Modified Integrated Region Matching\"\nauthors: Vimina E. R., Jacob K. Poulose\nconference: International Journal of Computer Science Issues, Vol.\nyear: 2013\nbibkey: vimina2013a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1307.1561\"}\ntags: ['Image Retrieval']\n---\nThis paper proposes a content based image retrieval (CBIR) system using the local colour and texture features of selected image sub-blocks and global colour and shape features of the image. The image sub-blocks are roughly identified by segmenting the image into partitions of different configuration, finding the edge density in each partition using edge thresholding followed by morphological dilation. The colour and texture features of the identified regions are computed from the histograms of the quantized HSV colour space and Gray Level Co- occurrence Matrix (GLCM) respectively. The colour and texture feature vectors is computed for each region. The shape features are computed from the Edge Histogram Descriptor (EHD). A modified Integrated Region Matching (IRM) algorithm is used for finding the minimum distance between the sub-blocks of the query and target image. Experimental results show that the proposed method provides better retrieving result than retrieval using some of the existing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [23.18168830871582, 8.364856719970703]}, {"key": "", "year": "", "title": "Vitanyi2011compression", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Compression-based Similarity\"\nauthors: Vitanyi Paul M. B.  CWI, Amsterdam, The Netherlands\nconference: Arxiv\nyear: 2011\nbibkey: vitanyi2011compression\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1110.4544\"}\ntags: ['ARXIV']\n---\nFirst we consider pair-wise distances for literal objects consisting of finite binary files. These files are taken to contain all of their meaning, like genomes or books. The distances are based on compression of the objects concerned, normalized, and can be viewed as similarity distances. Second, we consider pair-wise distances between names of objects, like \"red\" or \"christianity.\" In this case the distances are based on searches of the Internet. Such a search can be performed by any search engine that returns aggregate page counts. We can extract a code length from the numbers returned, use the same formula as before, and derive a similarity or relative semantics between names for objects. The theory is based on Kolmogorov complexity. We test both similarities extensively experimentally.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [16.827117919921875, -11.55987548828125]}, {"key": "", "year": "", "title": "Vo2018generalization", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Generalization in Metric Learning: Should the Embedding Layer be the Embedding Layer\"\nauthors: Vo Nam, Hays James\nconference: Arxiv\nyear: 2018\nbibkey: vo2018generalization\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1803.03310\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nThis work studies deep metric learning under small to medium scale data as we believe that better generalization could be a contributing factor to the improvement of previous fine-grained image retrieval methods; it should be considered when designing future techniques. In particular, we investigate using other layers in a deep metric learning system (besides the embedding layer) for feature extraction and analyze how well they perform on training data and generalize to testing data. From this study, we suggest a new regularization practice where one can add or choose a more optimal layer for feature extraction. State-of-the-art performance is demonstrated on 3 fine-grained image retrieval benchmarks: Cars-196, CUB-200-2011, and Stanford Online Product.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [17.470672607421875, 8.422343254089355]}, {"key": "", "year": "", "title": "Wan2015hdidx", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"HDIdx: High-Dimensional Indexing for Efficient Approximate Nearest Neighbor Search\"\nauthors: Wan Ji, Tang Sheng, Zhang Yongdong, Li Jintao, Wu Pengcheng, Hoi Steven C. H.\nconference: Arxiv\nyear: 2015\nbibkey: wan2015hdidx\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1510.01991\"}\ntags: ['ARXIV']\n---\nFast Nearest Neighbor (NN) search is a fundamental challenge in large-scale data processing and analytics, particularly for analyzing multimedia contents which are often of high dimensionality. Instead of using exact NN search, extensive research efforts have been focusing on approximate NN search algorithms. In this work, we present \"HDIdx\", an efficient high-dimensional indexing library for fast approximate NN search, which is open-source and written in Python. It offers a family of state-of-the-art algorithms that convert input high-dimensional vectors into compact binary codes, making them very efficient and scalable for NN search with very low space complexity.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [6.621766090393066, -10.179685592651367]}, {"key": "", "year": "", "title": "Wang2014geometric", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Geometric VLAD for Large Scale Image Search\"\nauthors: Wang Zixuan, Di Wei, Bhardwaj Anurag, Jagadeesh Vignesh, Piramuthu Robinson\nconference: Arxiv\nyear: 2014\nbibkey: wang2014geometric\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1403.3829\"}\ntags: ['ARXIV']\n---\nWe present a novel compact image descriptor for large scale image search. Our proposed descriptor - Geometric VLAD (gVLAD) is an extension of VLAD (Vector of Locally Aggregated Descriptors) that incorporates weak geometry information into the VLAD framework. The proposed geometry cues are derived as a membership function over keypoint angles which contain evident and informative information but yet often discarded. A principled technique for learning the membership function by clustering angles is also presented. Further, to address the overhead of iterative codebook training over real-time datasets, a novel codebook adaptation strategy is outlined. Finally, we demonstrate the efficacy of proposed gVLAD based retrieval framework where we achieve more than 15% improvement in mAP over existing benchmarks.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [14.963114738464355, -21.539079666137695]}, {"key": "", "year": "", "title": "Wang2014hashing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hashing for Similarity Search: A Survey\"\nauthors: Wang Jingdong, Shen Heng Tao, Song Jingkuan, Ji Jianqiu\nconference: Arxiv\nyear: 2014\nbibkey: wang2014hashing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1408.2927\"}\ntags: ['ARXIV', 'Survey Paper']\n---\nSimilarity search (nearest neighbor search) is a problem of pursuing the data items whose distances to a query item are the smallest from a large database. Various methods have been developed to address this problem, and recently a lot of efforts have been devoted to approximate search. In this paper, we present a survey on one of the main solutions, hashing, which has been widely studied since the pioneering work locality sensitive hashing. We divide the hashing algorithms two main categories: locality sensitive hashing, which designs hash functions without exploring the data distribution and learning to hash, which learns hash functions according the data distribution, and review them from various aspects, including hash function design and distance measure and search scheme in the hash coding space.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [7.98006010055542, -19.60011100769043]}, {"key": "", "year": "", "title": "Wang2014scalable", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Scalable Similarity Learning using Large Margin Neighborhood Embedding\"\nauthors: Wang Zhaowen, Yang Jianchao, Lin Zhe, Brandt Jonathan, Chang Shiyu, Huang Thomas\nconference: Arxiv\nyear: 2014\nbibkey: wang2014scalable\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1404.6272\"}\ntags: ['ARXIV', 'TOM']\n---\nClassifying large-scale image data into object categories is an important problem that has received increasing research attention. Given the huge amount of data, non-parametric approaches such as nearest neighbor classifiers have shown promising results, especially when they are underpinned by a learned distance or similarity measurement. Although metric learning has been well studied in the past decades, most existing algorithms are impractical to handle large-scale data sets. In this paper, we present an image similarity learning method that can scale well in both the number of images and the dimensionality of image descriptors. To this end, similarity comparison is restricted to each sample's local neighbors and a discriminative similarity measure is induced from large margin neighborhood embedding. We also exploit the ensemble of projections so that high-dimensional features can be processed in a set of lower-dimensional subspaces in parallel without much performance compromise. The similarity function is learned online using a stochastic gradient descent algorithm in which the triplet sampling strategy is customized for quick convergence of classification performance. The effectiveness of our proposed model is validated on several data sets with scales varying from tens of thousands to one million images. Recognition accuracies competitive with the state-of-the-art performance are achieved with much higher efficiency and scalability.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.198470115661621, 7.835127353668213]}, {"key": "", "year": "", "title": "Wang2015learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning Deep Structure-Preserving Image-Text Embeddings\"\nauthors: Wang Liwei, Li Yin, Lazebnik Svetlana\nconference: Arxiv\nyear: 2015\nbibkey: wang2015learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1511.06078\"}\ntags: ['ARXIV', 'Image Retrieval', 'TIP']\n---\nThis paper proposes a method for learning joint embeddings of images and text using a two-branch neural network with multiple layers of linear projections followed by nonlinearities. The network is trained using a large margin objective that combines cross-view ranking constraints with within-view neighborhood structure preservation constraints inspired by metric learning literature. Extensive experiments show that our approach gains significant improvements in accuracy for image-to-text and text-to-image retrieval. Our method achieves new state-of-the-art results on the Flickr30K and MSCOCO image-sentence datasets and shows promise on the new task of phrase localization on the Flickr30K Entities dataset.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [18.379100799560547, 8.28060531616211]}, {"key": "", "year": "", "title": "Wang2016a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Survey on Learning to Hash\"\nauthors: Wang Jingdong, Zhang Ting, Song Jingkuan, Sebe Nicu, Shen Heng Tao\nconference: Arxiv\nyear: 2016\nbibkey: wang2016a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1606.00185\"}\ntags: ['ARXIV', 'Quantisation', 'Survey Paper']\n---\nNearest neighbor search is a problem of finding the data points from the database such that the distances from them to the query point are the smallest. Learning to hash is one of the major solutions to this problem and has been widely studied recently. In this paper, we present a comprehensive survey of the learning to hash algorithms, categorize them according to the manners of preserving the similarities into: pairwise similarity preserving, multiwise similarity preserving, implicit similarity preserving, as well as quantization, and discuss their relations. We separate quantization from pairwise similarity preserving as the objective function is very different though quantization, as we show, can be derived from preserving the pairwise similarities. In addition, we present the evaluation protocols, and the general performance analysis, and point out that the quantization algorithms perform superiorly in terms of search accuracy, search time cost, and space cost. Finally, we introduce a few emerging topics.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-20.36248016357422, -1.960649013519287]}, {"key": "", "year": "", "title": "Wang2016deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Supervised Hashing with Triplet Labels\"\nauthors: Wang Xiaofang, Shi Yi, Kitani Kris M.\nconference: Arxiv\nyear: 2016\nbibkey: wang2016deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1612.03900\"}\ntags: ['ARXIV', 'Image Retrieval', 'Supervised', 'Unsupervised']\n---\nHashing is one of the most popular and powerful approximate nearest neighbor search techniques for large-scale image retrieval. Most traditional hashing methods first represent images as off-the-shelf visual features and then produce hashing codes in a separate stage. However, off-the-shelf visual features may not be optimally compatible with the hash code learning procedure, which may result in sub-optimal hash codes. Recently, deep hashing methods have been proposed to simultaneously learn image features and hash codes using deep neural networks and have shown superior performance over traditional hashing methods. Most deep hashing methods are given supervised information in the form of pairwise labels or triplet labels. The current state-of-the-art deep hashing method DPSH~\\cite{li2015feature}, which is based on pairwise labels, performs image feature learning and hash code learning simultaneously by maximizing the likelihood of pairwise similarities. Inspired by DPSH~\\cite{li2015feature}, we propose a triplet label based deep hashing method which aims to maximize the likelihood of the given triplet labels. Experimental results show that our method outperforms all the baselines on CIFAR-10 and NUS-WIDE datasets, including the state-of-the-art method DPSH~\\cite{li2015feature} and all the previous triplet label based deep hashing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-2.5057554244995117, 8.728699684143066]}, {"key": "", "year": "", "title": "Wang2016unsupervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Unsupervised Cross-Media Hashing with Structure Preservation\"\nauthors: Wang Xiangyu, Chia Alex Yong-Sang\nconference: Arxiv\nyear: 2016\nbibkey: wang2016unsupervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1603.05782\"}\ntags: ['ARXIV', 'Supervised', 'Unsupervised']\n---\nRecent years have seen the exponential growth of heterogeneous multimedia data. The need for effective and accurate data retrieval from heterogeneous data sources has attracted much research interest in cross-media retrieval. Here, given a query of any media type, cross-media retrieval seeks to find relevant results of different media types from heterogeneous data sources. To facilitate large-scale cross-media retrieval, we propose a novel unsupervised cross-media hashing method. Our method incorporates local affinity and distance repulsion constraints into a matrix factorization framework. Correspondingly, the proposed method learns hash functions that generates unified hash codes from different media types, while ensuring intrinsic geometric structure of the data distribution is preserved. These hash codes empower the similarity between data of different media types to be evaluated directly. Experimental results on two large-scale multimedia datasets demonstrate the effectiveness of the proposed method, where we outperform the state-of-the-art methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-2.1993067264556885, -4.794652462005615]}, {"key": "", "year": "", "title": "Wang2017composite", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Composite Quantization\"\nauthors: Wang Jingdong, Zhang Ting\nconference: Arxiv\nyear: 2017\nbibkey: wang2017composite\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1712.00955\"}\ntags: ['ARXIV', 'Quantisation']\n---\nThis paper studies the compact coding approach to approximate nearest neighbor search. We introduce a composite quantization framework. It uses the composition of several ($M$) elements, each of which is selected from a different dictionary, to accurately approximate a $D$-dimensional vector, thus yielding accurate search, and represents the data vector by a short code composed of the indices of the selected elements in the corresponding dictionaries. Our key contribution lies in introducing a near-orthogonality constraint, which makes the search efficiency is guaranteed as the cost of the distance computation is reduced to $O(M)$ from $O(D)$ through a distance table lookup scheme. The resulting approach is called near-orthogonal composite quantization. We theoretically justify the equivalence between near-orthogonal composite quantization and minimizing an upper bound of a function formed by jointly considering the quantization error and the search cost according to a generalized triangle inequality. We empirically show the efficacy of the proposed approach over several benchmark datasets. In addition, we demonstrate the superior performances in other three applications: combination with inverted multi-index, quantizing the query for mobile search, and inner-product similarity search.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [10.325362205505371, -13.899883270263672]}, {"key": "", "year": "", "title": "Wang2017supervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Supervised Deep Hashing for Hierarchical Labeled Data\"\nauthors: Wang Dan, Huang Heyan, Lu Chi, Feng Bo-Si, Nie Liqiang, Wen Guihua, Mao Xian-Ling\nconference: Arxiv\nyear: 2017\nbibkey: wang2017supervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1704.02088\"}\ntags: ['ARXIV', 'Image Retrieval', 'Supervised', 'Unsupervised']\n---\nRecently, hashing methods have been widely used in large-scale image retrieval. However, most existing hashing methods did not consider the hierarchical relation of labels, which means that they ignored the rich information stored in the hierarchy. Moreover, most of previous works treat each bit in a hash code equally, which does not meet the scenario of hierarchical labeled data. In this paper, we propose a novel deep hashing method, called supervised hierarchical deep hashing (SHDH), to perform hash code learning for hierarchical labeled data. Specifically, we define a novel similarity formula for hierarchical labeled data by weighting each layer, and design a deep convolutional neural network to obtain a hash code for each data point. Extensive experiments on several real-world public datasets show that the proposed method outperforms the state-of-the-art baselines in the image retrieval task.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-2.3085741996765137, 16.10423469543457]}, {"key": "", "year": "", "title": "Wang2019cluster", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Cluster-wise Unsupervised Hashing for Cross-Modal Similarity Search\"\nauthors: Wang Lu, Yang Jie\nconference: Arxiv\nyear: 2019\nbibkey: wang2019cluster\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1911.07923\"}\ntags: ['ARXIV', 'Cross Modal', 'Supervised', 'Unsupervised']\n---\nLarge-scale cross-modal hashing similarity retrieval has attracted more and more attention in modern search applications such as search engines and autopilot, showing great superiority in computation and storage. However, current unsupervised cross-modal hashing methods still have some limitations: (1)many methods relax the discrete constraints to solve the optimization objective which may significantly degrade the retrieval performance;(2)most existing hashing model project heterogenous data into a common latent space, which may always lose sight of diversity in heterogenous data;(3)transforming real-valued data point to binary codes always results in abundant loss of information, producing the suboptimal continuous latent space. To overcome above problems, in this paper, a novel Cluster-wise Unsupervised Hashing (CUH) method is proposed. Specifically, CUH jointly performs the multi-view clustering that projects the original data points from different modalities into its own low-dimensional latent semantic space and finds the cluster centroid points and the common clustering indicators in its own low-dimensional space, and learns the compact hash codes and the corresponding linear hash functions. An discrete optimization framework is developed to learn the unified binary codes across modalities under the guidance cluster-wise code-prototypes. The reasonableness and effectiveness of CUH is well demonstrated by comprehensive experiments on diverse benchmark datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-11.029053688049316, -2.8946051597595215]}, {"key": "", "year": "", "title": "Wang2019deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Collaborative Discrete Hashing with Semantic-Invariant Structure\"\nauthors: Wang Zijian, Zhang Zheng, Luo Yadan, Huang Zi\nconference: SIGIR\nyear: 2019\nbibkey: wang2019deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1911.01565\"}\ntags: []\n---\nExisting deep hashing approaches fail to fully explore semantic correlations and neglect the effect of linguistic context on visual attention learning, leading to inferior performance. This paper proposes a dual-stream learning framework, dubbed Deep Collaborative Discrete Hashing (DCDH), which constructs a discriminative common discrete space by collaboratively incorporating the shared and individual semantics deduced from visual features and semantic labels. Specifically, the context-aware representations are generated by employing the outer product of visual embeddings and semantic encodings. Moreover, we reconstruct the labels and introduce the focal loss to take advantage of frequent and rare concepts. The common binary code space is built on the joint learning of the visual representations attended by language, the semantic-invariant structure construction and the label distribution correction. Extensive experiments demonstrate the superiority of our method.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-6.044536590576172, 13.544615745544434]}, {"key": "", "year": "", "title": "Wang2019fusion", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fusion-supervised Deep Cross-modal Hashing\"\nauthors: Wang Li, Zhu Lei, Yu En, Sun Jiande, Zhang Huaxiang\nconference: Arxiv\nyear: 2019\nbibkey: wang2019fusion\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1904.11171\"}\ntags: ['ARXIV', 'Cross Modal', 'Supervised', 'Unsupervised']\n---\nDeep hashing has recently received attention in cross-modal retrieval for its impressive advantages. However, existing hashing methods for cross-modal retrieval cannot fully capture the heterogeneous multi-modal correlation and exploit the semantic information. In this paper, we propose a novel \\emph{Fusion-supervised Deep Cross-modal Hashing} (FDCH) approach. Firstly, FDCH learns unified binary codes through a fusion hash network with paired samples as input, which effectively enhances the modeling of the correlation of heterogeneous multi-modal data. Then, these high-quality unified hash codes further supervise the training of the modality-specific hash networks for encoding out-of-sample queries. Meanwhile, both pair-wise similarity information and classification information are embedded in the hash networks under one stream framework, which simultaneously preserves cross-modal similarity and keeps semantic consistency. Experimental results on two benchmark datasets demonstrate the state-of-the-art performance of FDCH.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-5.639607906341553, -3.309481620788574]}, {"key": "", "year": "", "title": "Wang2019supervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Supervised Quantization for Similarity Search\"\nauthors: Wang Xiaojuan, Zhang Ting, Q Guo-Jun, Tang Jinhui, Wang Jingdong\nconference: Arxiv\nyear: 2019\nbibkey: wang2019supervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1902.00617\"}\ntags: ['ARXIV', 'Quantisation', 'Supervised', 'Unsupervised']\n---\nIn this paper, we address the problem of searching for semantically similar images from a large database. We present a compact coding approach, supervised quantization. Our approach simultaneously learns feature selection that linearly transforms the database points into a low-dimensional discriminative subspace, and quantizes the data points in the transformed space. The optimization criterion is that the quantized points not only approximate the transformed points accurately, but also are semantically separable: the points belonging to a class lie in a cluster that is not overlapped with other clusters corresponding to other classes, which is formulated as a classification problem. The experiments on several standard datasets show the superiority of our approach over the state-of-the art supervised hashing and unsupervised quantization algorithms.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [7.472527503967285, -6.3221025466918945]}, {"key": "", "year": "", "title": "Wang2020asymmetric", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Asymmetric Correlation Quantization Hashing for Cross-modal Retrieval\"\nauthors: Wang Lu, Yang Jie\nconference: Arxiv\nyear: 2020\nbibkey: wang2020asymmetric\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2001.04625\"}\ntags: ['ARXIV', 'Cross Modal', 'Quantisation', 'TIP']\n---\nDue to the superiority in similarity computation and database storage for large-scale multiple modalities data, cross-modal hashing methods have attracted extensive attention in similarity retrieval across the heterogeneous modalities. However, there are still some limitations to be further taken into account: (1) most current CMH methods transform real-valued data points into discrete compact binary codes under the binary constraints, limiting the capability of representation for original data on account of abundant loss of information and producing suboptimal hash codes; (2) the discrete binary constraint learning model is hard to solve, where the retrieval performance may greatly reduce by relaxing the binary constraints for large quantization error; (3) handling the learning problem of CMH in a symmetric framework, leading to difficult and complex optimization objective. To address above challenges, in this paper, a novel Asymmetric Correlation Quantization Hashing (ACQH) method is proposed. Specifically, ACQH learns the projection matrixs of heterogeneous modalities data points for transforming query into a low-dimensional real-valued vector in latent semantic space and constructs the stacked compositional quantization embedding in a coarse-to-fine manner for indicating database points by a series of learnt real-valued codeword in the codebook with the help of pointwise label information regression simultaneously. Besides, the unified hash codes across modalities can be directly obtained by the discrete iterative optimization framework devised in the paper. Comprehensive experiments on diverse three benchmark datasets have shown the effectiveness and rationality of ACQH.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-9.630147933959961, -3.95070743560791]}, {"key": "", "year": "", "title": "Wang2020deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Reinforcement Learning with Label Embedding Reward for Supervised Image Hashing\"\nauthors: Wang Zhenzhen, Hong Weixiang, Yuan Junsong\nconference: Arxiv\nyear: 2020\nbibkey: wang2020deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2008.03973\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval', 'Supervised']\n---\nDeep hashing has shown promising results in image retrieval and recognition. Despite its success, most existing deep hashing approaches are rather similar: either multi-layer perceptron or CNN is applied to extract image feature, followed by different binarization activation functions such as sigmoid, tanh or autoencoder to generate binary code. In this work, we introduce a novel decision-making approach for deep supervised hashing. We formulate the hashing problem as travelling across the vertices in the binary code space, and learn a deep Q-network with a novel label embedding reward defined by Bose-Chaudhuri-Hocquenghem (BCH) codes to explore the best path. Extensive experiments and analysis on the CIFAR-10 and NUS-WIDE dataset show that our approach outperforms state-of-the-art supervised hashing methods under various code lengths.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-7.5164875984191895, 13.90610122680664]}, {"key": "", "year": "", "title": "Wang2021a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Semantic Indexing Structure for Image Retrieval\"\nauthors: Wang Ying, Liu Tingzhen, Bu Zepeng, Huang Yuhui, Gao Lizhong, Wang Qiao\nconference: Arxiv\nyear: 2021\nbibkey: wang2021a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2109.06583\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nIn large-scale image retrieval, many indexing methods have been proposed to narrow down the searching scope of retrieval. The features extracted from images usually are of high dimensions or unfixed sizes due to the existence of key points. Most of existing index structures suffer from the dimension curse, the unfixed feature size and/or the loss of semantic similarity. In this paper a new classification-based indexing structure, called Semantic Indexing Structure (SIS), is proposed, in which we utilize the semantic categories rather than clustering centers to create database partitions, such that the proposed index SIS can be combined with feature extractors without the restriction of dimensions. Besides, it is observed that the size of each semantic partition is positively correlated with the semantic distribution of database. Along this way, we found that when the partition number is normalized to five, the proposed algorithm performed very well in all the tests. Compared with state-of-the-art models, SIS achieves outstanding performance.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [8.617666244506836, 6.227530479431152]}, {"key": "", "year": "", "title": "Wang2021contrastive", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Contrastive Quantization with Code Memory for Unsupervised Image Retrieval\"\nauthors: Wang Jinpeng, Zeng Ziyun, Chen Bin, Dai Tao, Xia Shu-Tao\nconference: Arxiv\nyear: 2021\nbibkey: wang2021contrastive\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2109.05205\"}   - {name: \"Code\", url: \"https://github.com/gimpong/AAAI22-MeCoQ.\"}\ntags: ['ARXIV', 'Image Retrieval', 'Quantisation', 'Supervised', 'Unsupervised']\n---\nThe high efficiency in computation and storage makes hashing (including binary hashing and quantization) a common strategy in large-scale retrieval systems. To alleviate the reliance on expensive annotations, unsupervised deep hashing becomes an important research problem. This paper provides a novel solution to unsupervised deep quantization, namely Contrastive Quantization with Code Memory (MeCoQ). Different from existing reconstruction-based strategies, we learn unsupervised binary descriptors by contrastive learning, which can better capture discriminative visual semantics. Besides, we uncover that codeword diversity regularization is critical to prevent contrastive learning-based quantization from model degeneration. Moreover, we introduce a novel quantization code memory module that boosts contrastive learning with lower feature drift than conventional feature memories. Extensive experiments on benchmark datasets show that MeCoQ outperforms state-of-the-art methods. Code and configurations are publicly available at https://github.com/gimpong/AAAI22-MeCoQ.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-7.249763488769531, 3.2535738945007324]}, {"key": "", "year": "", "title": "Wang2021cross", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Cross-modal Zero-shot Hashing by Label Attributes Embedding\"\nauthors: Wang Runmin, Yu Guoxian, Liu Lei, Cui Lizhen, Domeniconi Carlotta, Zhang Xiangliang\nconference: Arxiv\nyear: 2021\nbibkey: wang2021cross\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2111.04080\"}\ntags: ['ARXIV', 'Cross Modal']\n---\nCross-modal hashing (CMH) is one of the most promising methods in cross-modal approximate nearest neighbor search. Most CMH solutions ideally assume the labels of training and testing set are identical. However, the assumption is often violated, causing a zero-shot CMH problem. Recent efforts to address this issue focus on transferring knowledge from the seen classes to the unseen ones using label attributes. However, the attributes are isolated from the features of multi-modal data. To reduce the information gap, we introduce an approach called LAEH (Label Attributes Embedding for zero-shot cross-modal Hashing). LAEH first gets the initial semantic attribute vectors of labels by word2vec model and then uses a transformation network to transform them into a common subspace. Next, it leverages the hash vectors and the feature similarity matrix to guide the feature extraction network of different modalities. At the same time, LAEH uses the attribute similarity as the supplement of label similarity to rectify the label embedding and common subspace. Experiments show that LAEH outperforms related representative zero-shot and cross-modal hashing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-4.232019901275635, -0.8083642721176147]}, {"key": "", "year": "", "title": "Wang2021mathematical", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Mathematical Models for Local Sensing Hashes\"\nauthors: Wang Li, Wangner Lilon\nconference: Arxiv\nyear: 2021\nbibkey: wang2021mathematical\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2111.08344\"}\ntags: ['ARXIV']\n---\nAs data volumes continue to grow, searches in data are becoming increasingly time-consuming. Classical index structures for neighbor search are no longer sustainable due to the \"curse of dimensionality\". Instead, approximated index structures offer a good opportunity to significantly accelerate the neighbor search for clustering and outlier detection and to have the lowest possible error rate in the results of the algorithms. Local sensing hashes is one of those. We indicate directions to mathematically model the properties of it.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [2.1249570846557617, -17.2806339263916]}, {"key": "", "year": "", "title": "Wang2021meta", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Meta Cross-Modal Hashing on Long-Tailed Data\"\nauthors: Wang Runmin, Yu Guoxian, Domeniconi Carlotta, Zhang Xiangliang\nconference: Arxiv\nyear: 2021\nbibkey: wang2021meta\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2111.04086\"}\ntags: ['ARXIV', 'Cross Modal']\n---\nDue to the advantage of reducing storage while speeding up query time on big heterogeneous data, cross-modal hashing has been extensively studied for approximate nearest neighbor search of multi-modal data. Most hashing methods assume that training data is class-balanced.However, in practice, real world data often have a long-tailed distribution. In this paper, we introduce a meta-learning based cross-modal hashing method (MetaCMH) to handle long-tailed data. Due to the lack of training samples in the tail classes, MetaCMH first learns direct features from data in different modalities, and then introduces an associative memory module to learn the memory features of samples of the tail classes. It then combines the direct and memory features to obtain meta features for each sample. For samples of the head classes of the long tail distribution, the weight of the direct features is larger, because there are enough training data to learn them well; while for rare classes, the weight of the memory features is larger. Finally, MetaCMH uses a likelihood loss function to preserve the similarity in different modalities and learns hash functions in an end-to-end fashion. Experiments on long-tailed datasets show that MetaCMH performs significantly better than state-of-the-art methods, especially on the tail classes.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-15.630561828613281, -5.61271858215332]}, {"key": "", "year": "", "title": "Wang2021prototype", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Prototype-supervised Adversarial Network for Targeted Attack of Deep Hashing\"\nauthors: Wang Xunguang, Zhang Zheng, Wu Baoyuan, Shen Fumin, Lu Guangming\nconference: Arxiv\nyear: 2021\nbibkey: wang2021prototype\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2105.07553\"}   - {name: \"Code\", url: \"https://github.com/xunguangwang/ProS-GAN\"}\ntags: ['ARXIV', 'GAN', 'Image Retrieval', 'Supervised']\n---\nDue to its powerful capability of representation learning and high-efficiency computation, deep hashing has made significant progress in large-scale image retrieval. However, deep hashing networks are vulnerable to adversarial examples, which is a practical secure problem but seldom studied in hashing-based retrieval field. In this paper, we propose a novel prototype-supervised adversarial network (ProS-GAN), which formulates a flexible generative architecture for efficient and effective targeted hashing attack. To the best of our knowledge, this is the first generation-based method to attack deep hashing networks. Generally, our proposed framework consists of three parts, i.e., a PrototypeNet, a generator, and a discriminator. Specifically, the designed PrototypeNet embeds the target label into the semantic representation and learns the prototype code as the category-level representative of the target label. Moreover, the semantic representation and the original image are jointly fed into the generator for a flexible targeted attack. Particularly, the prototype code is adopted to supervise the generator to construct the targeted adversarial example by minimizing the Hamming distance between the hash code of the adversarial example and the prototype code. Furthermore, the generator is against the discriminator to simultaneously encourage the adversarial examples visually realistic and the semantic representation informative. Extensive experiments verify that the proposed framework can efficiently produce adversarial examples with better targeted attack performance and transferability over state-of-the-art targeted attack methods of deep hashing. The related codes could be available at https://github.com/xunguangwang/ProS-GAN .\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-11.070076942443848, 8.075424194335938]}, {"key": "", "year": "", "title": "Wang2022a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Survey on Efficient Processing of Similarity Queries over Neural Embeddings\"\nauthors: Wang Yifan\nconference: Arxiv\nyear: 2022\nbibkey: wang2022a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2204.07922\"}\ntags: ['ARXIV', 'Survey Paper']\n---\nSimilarity query is the family of queries based on some similarity metrics. Unlike the traditional database queries which are mostly based on value equality, similarity queries aim to find targets \"similar enough to\" the given data objects, depending on some similarity metric, e.g., Euclidean distance, cosine similarity and so on. To measure the similarity between data objects, traditional methods normally work on low level or syntax features(e.g., basic visual features on images or bag-of-word features of text), which makes them weak to compute the semantic similarities between objects. So for measuring data similarities semantically, neural embedding is applied. Embedding techniques work by representing the raw data objects as vectors (so called \"embeddings\" or \"neural embeddings\" since they are mostly generated by neural network models) that expose the hidden semantics of the raw data, based on which embeddings do show outstanding effectiveness on capturing data similarities, making it one of the most widely used and studied techniques in the state-of-the-art similarity query processing research. But there are still many open challenges on the efficiency of embedding based similarity query processing, which are not so well-studied as the effectiveness. In this survey, we first provide an overview of the \"similarity query\" and \"similarity query processing\" problems. Then we talk about recent approaches on designing the indexes and operators for highly efficient similarity query processing on top of embeddings (or more generally, high dimensional data). Finally, we investigate the specific solutions with and without using embeddings in selected application domains of similarity queries, including entity resolution and information retrieval. By comparing the solutions, we show how neural embeddings benefit those applications.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [0.4268215596675873, -19.725881576538086]}, {"key": "", "year": "", "title": "Wang2022anchor", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Anchor Graph Structure Fusion Hashing for Cross-Modal Similarity Search\"\nauthors: Wang Lu, Yang Jie, Zareapoor Masoumeh, Zheng Zhonglong\nconference: Arxiv\nyear: 2022\nbibkey: wang2022anchor\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2202.04327\"}\ntags: ['ARXIV', 'Cross Modal', 'Graph', 'TIP']\n---\nCross-modal hashing still has some challenges needed to address: (1) most existing CMH methods take graphs as input to model data distribution. These methods omit to consider the correlation of graph structure among multiple modalities; (2) most existing CMH methods ignores considering the fusion affinity among multi-modalities data; (3) most existing CMH methods relax the discrete constraints to solve the optimization objective, significantly degrading the retrieval performance. To solve the above limitations, we propose a novel Anchor Graph Structure Fusion Hashing (AGSFH). AGSFH constructs the anchor graph structure fusion matrix from different anchor graphs of multiple modalities with the Hadamard product, which can fully exploit the geometric property of underlying data structure. Based on the anchor graph structure fusion matrix, AGSFH attempts to directly learn an intrinsic anchor graph, where the structure of the intrinsic anchor graph is adaptively tuned so that the number of components of the intrinsic graph is exactly equal to the number of clusters. Besides, AGSFH preserves the anchor fusion affinity into the common binary Hamming space. Furthermore, a discrete optimization framework is designed to learn the unified binary codes. Extensive experimental results on three public social datasets demonstrate the superiority of AGSFH.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [4.628576278686523, -28.823667526245117]}, {"key": "", "year": "", "title": "Wang2022binary", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Binary Representation via Jointly Personalized Sparse Hashing\"\nauthors: Wang Xiaoqin, Chen Chen, Lan Rushi, Liu Licheng, Liu Zhenbing, Zhou Huiyu, Luo Xiaonan\nconference: Arxiv\nyear: 2022\nbibkey: wang2022binary\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2208.14883\"}\ntags: ['ARXIV', 'Supervised', 'Unsupervised']\n---\nUnsupervised hashing has attracted much attention for binary representation learning due to the requirement of economical storage and efficiency of binary codes. It aims to encode high-dimensional features in the Hamming space with similarity preservation between instances. However, most existing methods learn hash functions in manifold-based approaches. Those methods capture the local geometric structures (i.e., pairwise relationships) of data, and lack satisfactory performance in dealing with real-world scenarios that produce similar features (e.g. color and shape) with different semantic information. To address this challenge, in this work, we propose an effective unsupervised method, namely Jointly Personalized Sparse Hashing (JPSH), for binary representation learning. To be specific, firstly, we propose a novel personalized hashing module, i.e., Personalized Sparse Hashing (PSH). Different personalized subspaces are constructed to reflect category-specific attributes for different clusters, adaptively mapping instances within the same cluster to the same Hamming space. In addition, we deploy sparse constraints for different personalized subspaces to select important features. We also collect the strengths of the other clusters to build the PSH module with avoiding over-fitting. Then, to simultaneously preserve semantic and pairwise similarities in our JPSH, we incorporate the PSH and manifold-based hash learning into the seamless formulation. As such, JPSH not only distinguishes the instances from different clusters, but also preserves local neighborhood structures within the cluster. Finally, an alternating optimization algorithm is adopted to iteratively capture analytical solutions of the JPSH model. Extensive experiments on four benchmark datasets verify that the JPSH outperforms several hashing algorithms on the similarity search task.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-11.1419677734375, -4.940609455108643]}, {"key": "", "year": "", "title": "Wang2022hcfrec", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"HCFRec: Hash Collaborative Filtering via Normalized Flow with Structural Consensus for Efficient Recommendation\"\nauthors: Wang Fan, Liu Weiming, Chen Chaochao, Zhu Mengying, Zheng Xiaolin\nconference: Arxiv\nyear: 2022\nbibkey: wang2022hcfrec\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2205.12042\"}\ntags: ['ARXIV']\n---\nThe ever-increasing data scale of user-item interactions makes it challenging for an effective and efficient recommender system. Recently, hash-based collaborative filtering (Hash-CF) approaches employ efficient Hamming distance of learned binary representations of users and items to accelerate recommendations. However, Hash-CF often faces two challenging problems, i.e., optimization on discrete representations and preserving semantic information in learned representations. To address the above two challenges, we propose HCFRec, a novel Hash-CF approach for effective and efficient recommendations. Specifically, HCFRec not only innovatively introduces normalized flow to learn the optimal hash code by efficiently fit a proposed approximate mixture multivariate normal distribution, a continuous but approximately discrete distribution, but also deploys a cluster consistency preserving mechanism to preserve the semantic structure in representations for more accurate recommendations. Extensive experiments conducted on six real-world datasets demonstrate the superiority of our HCFRec compared to the state-of-art methods in terms of effectiveness and efficiency.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-1.0896291732788086, -3.7142019271850586]}, {"key": "", "year": "", "title": "Wang2022inverted", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Inverted Semantic-Index for Image Retrieval\"\nauthors: Wang Ying\nconference: Arxiv\nyear: 2022\nbibkey: wang2022inverted\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2206.12623\"}\ntags: ['ARXIV', 'Image Retrieval', 'Quantisation', 'Supervised', 'Unsupervised']\n---\nThis paper addresses the construction of inverted index for large-scale image retrieval. The inverted index proposed by J. Sivic brings a significant acceleration by reducing distance computations with only a small fraction of the database. The state-of-the-art inverted indices aim to build finer partitions that produce a concise and accurate candidate list. However, partitioning in these frameworks is generally achieved by unsupervised clustering methods which ignore the semantic information of images. In this paper, we replace the clustering method with image classification, during the construction of codebook. We then propose a merging and splitting method to solve the problem that the number of partitions is unchangeable in the inverted semantic-index. Next, we combine our semantic-index with the product quantization (PQ) so as to alleviate the accuracy loss caused by PQ compression. Finally, we evaluate our model on large-scale image retrieval benchmarks. Experiment results demonstrate that our model can significantly improve the retrieval accuracy by generating high-quality candidate lists.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [8.673766136169434, 6.067992210388184]}, {"key": "", "year": "", "title": "Wang2023graph", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Graph-Collaborated Auto-Encoder Hashing for Multi-view Binary Clustering\"\nauthors: Wang Huibing, Yao Mingze, Jiang Guangqi, Mi Zetian, Fu Xianping\nconference: Arxiv\nyear: 2023\nbibkey: wang2023graph\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2301.02484\"}\ntags: ['ARXIV', 'Graph', 'Quantisation', 'Supervised', 'TIP', 'Unsupervised']\n---\nUnsupervised hashing methods have attracted widespread attention with the explosive growth of large-scale data, which can greatly reduce storage and computation by learning compact binary codes. Existing unsupervised hashing methods attempt to exploit the valuable information from samples, which fails to take the local geometric structure of unlabeled samples into consideration. Moreover, hashing based on auto-encoders aims to minimize the reconstruction loss between the input data and binary codes, which ignores the potential consistency and complementarity of multiple sources data. To address the above issues, we propose a hashing algorithm based on auto-encoders for multi-view binary clustering, which dynamically learns affinity graphs with low-rank constraints and adopts collaboratively learning between auto-encoders and affinity graphs to learn a unified binary code, called Graph-Collaborated Auto-Encoder Hashing for Multi-view Binary Clustering (GCAE). Specifically, we propose a multi-view affinity graphs learning model with low-rank constraint, which can mine the underlying geometric information from multi-view data. Then, we design an encoder-decoder paradigm to collaborate the multiple affinity graphs, which can learn a unified binary code effectively. Notably, we impose the decorrelation and code balance constraints on binary codes to reduce the quantization errors. Finally, we utilize an alternating iterative optimization scheme to obtain the multi-view clustering results. Extensive experimental results on $5$ public datasets are provided to reveal the effectiveness of the algorithm and its superior performance over other state-of-the-art alternatives.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [3.826946496963501, -28.381057739257812]}, {"key": "", "year": "", "title": "Wang2023learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning Efficient Representations for Image-Based Patent Retrieval\"\nauthors: Wang Hongsong, Zhang Yuqi\nconference: Arxiv\nyear: 2023\nbibkey: wang2023learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2308.13749\"}\ntags: ['ARXIV', 'Image Retrieval', 'Text Retrieval']\n---\nPatent retrieval has been attracting tremendous interest from researchers in intellectual property and information retrieval communities in the past decades. However, most existing approaches rely on textual and metadata information of the patent, and content-based image-based patent retrieval is rarely investigated. Based on traits of patent drawing images, we present a simple and lightweight model for this task. Without bells and whistles, this approach significantly outperforms other counterparts on a large-scale benchmark and noticeably improves the state-of-the-art by 33.5% with the mean average precision (mAP) score. Further experiments reveal that this model can be elaborately scaled up to achieve a surprisingly high mAP of 93.5%. Our method ranks first in the ECCV 2022 Patent Diagram Image Retrieval Challenge.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [21.94986915588379, -4.645324230194092]}, {"key": "", "year": "", "title": "Wang2023masked", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Masked Space-Time Hash Encoding for Efficient Dynamic Scene Reconstruction\"\nauthors: Wang Feng, Chen Zilong, Wang Guokang, Song Yafei, Liu Huaping\nconference: Arxiv\nyear: 2023\nbibkey: wang2023masked\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2310.17527\"}   - {name: \"Code\", url: \"https://github.com/masked-spacetime-hashing/msth\"}\ntags: ['ARXIV']\n---\nIn this paper, we propose the Masked Space-Time Hash encoding (MSTH), a novel method for efficiently reconstructing dynamic 3D scenes from multi-view or monocular videos. Based on the observation that dynamic scenes often contain substantial static areas that result in redundancy in storage and computations, MSTH represents a dynamic scene as a weighted combination of a 3D hash encoding and a 4D hash encoding. The weights for the two components are represented by a learnable mask which is guided by an uncertainty-based objective to reflect the spatial and temporal importance of each 3D position. With this design, our method can reduce the hash collision rate by avoiding redundant queries and modifications on static areas, making it feasible to represent a large number of space-time voxels by hash tables with small size.Besides, without the requirements to fit the large numbers of temporally redundant features independently, our method is easier to optimize and converge rapidly with only twenty minutes of training for a 300-frame dynamic scene.As a result, MSTH obtains consistently better results than previous methods with only 20 minutes of training time and 130 MB of memory storage. Code is available at https://github.com/masked-spacetime-hashing/msth\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [0.01919558085501194, 6.250161647796631]}, {"key": "", "year": "", "title": "Wang2023reliable", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Reliable and Efficient Evaluation of Adversarial Robustness for Deep Hashing-Based Retrieval\"\nauthors: Wang Xunguang, Bai Jiawang, Xu Xinyue, Li Xiaomeng\nconference: Arxiv\nyear: 2023\nbibkey: wang2023reliable\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2303.12658\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nDeep hashing has been extensively applied to massive image retrieval due to its efficiency and effectiveness. Recently, several adversarial attacks have been presented to reveal the vulnerability of deep hashing models against adversarial examples. However, existing attack methods suffer from degraded performance or inefficiency because they underutilize the semantic relations between original samples or spend a lot of time learning these relations with a deep neural network. In this paper, we propose a novel Pharos-guided Attack, dubbed PgA, to evaluate the adversarial robustness of deep hashing networks reliably and efficiently. Specifically, we design pharos code to represent the semantics of the benign image, which preserves the similarity to semantically relevant samples and dissimilarity to irrelevant ones. It is proven that we can quickly calculate the pharos code via a simple math formula. Accordingly, PgA can directly conduct a reliable and efficient attack on deep hashing-based retrieval by maximizing the similarity between the hash code of the adversarial example and the pharos code. Extensive experiments on the benchmark datasets verify that the proposed algorithm outperforms the prior state-of-the-arts in both attack strength and speed.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-7.0448899269104, 4.504345417022705]}, {"key": "", "year": "", "title": "Wang2023scene", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Scene Graph Based Fusion Network For Image-Text Retrieval\"\nauthors: Wang Guoliang, Shang Yanlei, Chen Yong\nconference: Arxiv\nyear: 2023\nbibkey: wang2023scene\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2303.11090\"}\ntags: ['ARXIV', 'Cross Modal', 'Graph', 'Text Retrieval']\n---\nA critical challenge to image-text retrieval is how to learn accurate correspondences between images and texts. Most existing methods mainly focus on coarse-grained correspondences based on co-occurrences of semantic objects, while failing to distinguish the fine-grained local correspondences. In this paper, we propose a novel Scene Graph based Fusion Network (dubbed SGFN), which enhances the images'/texts' features through intra- and cross-modal fusion for image-text retrieval. To be specific, we design an intra-modal hierarchical attention fusion to incorporate semantic contexts, such as objects, attributes, and relationships, into images'/texts' feature vectors via scene graphs, and a cross-modal attention fusion to combine the contextual semantics and local fusion via contextual vectors. Extensive experiments on public datasets Flickr30K and MSCOCO show that our SGFN performs better than quite a few SOTA image-text retrieval methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [15.053428649902344, -25.89124870300293]}, {"key": "", "year": "", "title": "Wang2024enhancing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Enhancing Image-Text Matching with Adaptive Feature Aggregation\"\nauthors: Wang Zuhui, Yin Yunting, Ramakrishnan I. V.\nconference: Arxiv\nyear: 2024\nbibkey: wang2024enhancing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2401.09725\"}\ntags: ['ARXIV', 'Cross Modal', 'Text Retrieval']\n---\nImage-text matching aims to find matched cross-modal pairs accurately. While current methods often rely on projecting cross-modal features into a common embedding space, they frequently suffer from imbalanced feature representations across different modalities, leading to unreliable retrieval results. To address these limitations, we introduce a novel Feature Enhancement Module that adaptively aggregates single-modal features for more balanced and robust image-text retrieval. Additionally, we propose a new loss function that overcomes the shortcomings of original triplet ranking loss, thereby significantly improving retrieval performance. The proposed model has been evaluated on two public datasets and achieves competitive retrieval performance when compared with several state-of-the-art models. Implementation codes can be found here.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [18.42121124267578, 3.381639003753662]}, {"key": "", "year": "", "title": "Wang2024neural", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Neural Locality Sensitive Hashing for Entity Blocking\"\nauthors: Wang Runhui, Kong Luyang, Tao Yefan, Borthwick Andrew, Golac Davor, Johnson Henrik, Hijazi Shadie, Deng Dong, Zhang Yongfeng\nconference: Arxiv\nyear: 2024\nbibkey: wang2024neural\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2401.18064\"}\ntags: ['ARXIV', 'LSH', 'Semi Supervised', 'Supervised', 'TOM']\n---\nLocality-sensitive hashing (LSH) is a fundamental algorithmic technique widely employed in large-scale data processing applications, such as nearest-neighbor search, entity resolution, and clustering. However, its applicability in some real-world scenarios is limited due to the need for careful design of hashing functions that align with specific metrics. Existing LSH-based Entity Blocking solutions primarily rely on generic similarity metrics such as Jaccard similarity, whereas practical use cases often demand complex and customized similarity rules surpassing the capabilities of generic similarity metrics. Consequently, designing LSH functions for these customized similarity rules presents considerable challenges. In this research, we propose a neuralization approach to enhance locality-sensitive hashing by training deep neural networks to serve as hashing functions for complex metrics. We assess the effectiveness of this approach within the context of the entity resolution problem, which frequently involves the use of task-specific metrics in real-world applications. Specifically, we introduce NLSHBlock (Neural-LSH Block), a novel blocking methodology that leverages pre-trained language models, fine-tuned with a novel LSH-based loss function. Through extensive evaluations conducted on a diverse range of real-world datasets, we demonstrate the superiority of NLSHBlock over existing methods, exhibiting significant performance improvements. Furthermore, we showcase the efficacy of NLSHBlock in enhancing the performance of the entity matching phase, particularly within the semi-supervised setting.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-10.261550903320312, 6.427513599395752]}, {"key": "", "year": "", "title": "Wang2024rreh", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"RREH: Reconstruction Relations Embedded Hashing for Semi-Paired Cross-Modal Retrieval\"\nauthors: Wang Jianzong, Shi Haoxiang, Luo Kaiyi, Zhang Xulong, Cheng Ning, Xiao Jing\nconference: Arxiv\nyear: 2024\nbibkey: wang2024rreh\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2405.17777\"}\ntags: ['ARXIV', 'Cross Modal', 'Supervised', 'Unsupervised']\n---\nKnown for efficient computation and easy storage, hashing has been extensively explored in cross-modal retrieval. The majority of current hashing models are predicated on the premise of a direct one-to-one mapping between data points. However, in real practice, data correspondence across modalities may be partially provided. In this research, we introduce an innovative unsupervised hashing technique designed for semi-paired cross-modal retrieval tasks, named Reconstruction Relations Embedded Hashing (RREH). RREH assumes that multi-modal data share a common subspace. For paired data, RREH explores the latent consistent information of heterogeneous modalities by seeking a shared representation. For unpaired data, to effectively capture the latent discriminative features, the high-order relationships between unpaired data and anchors are embedded into the latent subspace, which are computed by efficient linear reconstruction. The anchors are sampled from paired data, which improves the efficiency of hash learning. The RREH trains the underlying features and the binary encodings in a unified framework with high-order reconstruction relations preserved. With the well devised objective function and discrete optimization algorithm, RREH is designed to be scalable, making it suitable for large-scale datasets and facilitating efficient cross-modal retrieval. In the evaluation process, the proposed is tested with partially paired data to establish its superiority over several existing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-7.033288478851318, -2.3503189086914062]}, {"key": "", "year": "", "title": "Wang2024weakly", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Weakly Supervised Deep Hyperspherical Quantization for Image Retrieval\"\nauthors: Wang Jinpeng, Chen Bin, Zhang Qiang, Meng Zaiqiao, Liang Shangsong, Xia Shu-Tao\nconference: Arxiv\nyear: 2024\nbibkey: wang2024weakly\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2404.04998\"}   - {name: \"Code\", url: \"https://github.com/gimpong/AAAI21-WSDHQ.\"}\ntags: ['ARXIV', 'Graph', 'Image Retrieval', 'Quantisation', 'Supervised', 'Weakly Supervised']\n---\nDeep quantization methods have shown high efficiency on large-scale image retrieval. However, current models heavily rely on ground-truth information, hindering the application of quantization in label-hungry scenarios. A more realistic demand is to learn from inexhaustible uploaded images that are associated with informal tags provided by amateur users. Though such sketchy tags do not obviously reveal the labels, they actually contain useful semantic information for supervising deep quantization. To this end, we propose Weakly-Supervised Deep Hyperspherical Quantization (WSDHQ), which is the first work to learn deep quantization from weakly tagged images. Specifically, 1) we use word embeddings to represent the tags and enhance their semantic information based on a tag correlation graph. 2) To better preserve semantic information in quantization codes and reduce quantization error, we jointly learn semantics-preserving embeddings and supervised quantizer on hypersphere by employing a well-designed fusion layer and tailor-made loss functions. Extensive experiments show that WSDHQ can achieve state-of-art performance on weakly-supervised compact coding. Code is available at https://github.com/gimpong/AAAI21-WSDHQ.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-1.3857158422470093, 12.740352630615234]}, {"key": "", "year": "", "title": "Weaver2019constructing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Constructing Minimal Perfect Hash Functions Using SAT Technology\"\nauthors: Weaver Sean, Heule Marijn\nconference: Arxiv\nyear: 2019\nbibkey: weaver2019constructing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1911.10099\"}\ntags: ['ARXIV']\n---\nMinimal perfect hash functions (MPHFs) are used to provide efficient access to values of large dictionaries (sets of key-value pairs). Discovering new algorithms for building MPHFs is an area of active research, especially from the perspective of storage efficiency. The information-theoretic limit for MPHFs is 1/(ln 2) or roughly 1.44 bits per key. The current best practical algorithms range between 2 and 4 bits per key. In this article, we propose two SAT-based constructions of MPHFs. Our first construction yields MPHFs near the information-theoretic limit. For this construction, current state-of-the-art SAT solvers can handle instances where the dictionaries contain up to 40 elements, thereby outperforming the existing (brute-force) methods. Our second construction uses XOR-SAT filters to realize a practical approach with long-term storage of approximately 1.83 bits per key.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-16.404081344604492, -3.833487033843994]}, {"key": "", "year": "", "title": "Wei2022accurate", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Accurate Instance-Level CAD Model Retrieval in a Large-Scale Database\"\nauthors: Wei Jiaxin, Hu Lan, Wang Chenyu, Kneip Laurent\nconference: Arxiv\nyear: 2022\nbibkey: wei2022accurate\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2207.01339\"}\ntags: ['ARXIV']\n---\nWe present a new solution to the fine-grained retrieval of clean CAD models from a large-scale database in order to recover detailed object shape geometries for RGBD scans. Unlike previous work simply indexing into a moderately small database using an object shape descriptor and accepting the top retrieval result, we argue that in the case of a large-scale database a more accurate model may be found within a neighborhood of the descriptor. More importantly, we propose that the distinctiveness deficiency of shape descriptors at the instance level can be compensated by a geometry-based re-ranking of its neighborhood. Our approach first leverages the discriminative power of learned representations to distinguish between different categories of models and then uses a novel robust point set distance metric to re-rank the CAD neighborhood, enabling fine-grained retrieval in a large shape database. Evaluation on a real-world dataset shows that our geometry-based re-ranking is a conceptually simple but highly effective method that can lead to a significant improvement in retrieval accuracy compared to the state-of-the-art.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [19.902027130126953, -0.19688363373279572]}, {"key": "", "year": "", "title": "Wei2022hyperbolic", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hyperbolic Hierarchical Contrastive Hashing\"\nauthors: Wei Rukai, Liu Yu, Song Jingkuan, Xie Yanzhao, Zhou Ke\nconference: Transaction on Image Processing\nyear: 2022\nbibkey: wei2022hyperbolic\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2212.08904\"}\ntags: ['Supervised', 'Unsupervised']\n---\nHierarchical semantic structures, naturally existing in real-world datasets, can assist in capturing the latent distribution of data to learn robust hash codes for retrieval systems. Although hierarchical semantic structures can be simply expressed by integrating semantically relevant data into a high-level taxon with coarser-grained semantics, the construction, embedding, and exploitation of the structures remain tricky for unsupervised hash learning. To tackle these problems, we propose a novel unsupervised hashing method named Hyperbolic Hierarchical Contrastive Hashing (HHCH). We propose to embed continuous hash codes into hyperbolic space for accurate semantic expression since embedding hierarchies in hyperbolic space generates less distortion than in hyper-sphere space and Euclidean space. In addition, we extend the K-Means algorithm to hyperbolic space and perform the proposed hierarchical hyperbolic K-Means algorithm to construct hierarchical semantic structures adaptively. To exploit the hierarchical semantic structures in hyperbolic space, we designed the hierarchical contrastive learning algorithm, including hierarchical instance-wise and hierarchical prototype-wise contrastive learning. Extensive experiments on four benchmark datasets demonstrate that the proposed method outperforms the state-of-the-art unsupervised hashing methods. Codes will be released.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-6.493743419647217, 11.422295570373535]}, {"key": "", "year": "", "title": "Wei2023attribute", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Attribute-Aware Deep Hashing with Self-Consistency for Large-Scale Fine-Grained Image Retrieval\"\nauthors: Wei Xiu-Shen, Shen Yang, Sun Xuhao, Wang Peng, Peng Yuxin\nconference: Arxiv\nyear: 2023\nbibkey: wei2023attribute\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2311.12894\"}\ntags: ['ARXIV', 'Image Retrieval', 'Supervised', 'Unsupervised']\n---\nOur work focuses on tackling large-scale fine-grained image retrieval as ranking the images depicting the concept of interests (i.e., the same sub-category labels) highest based on the fine-grained details in the query. It is desirable to alleviate the challenges of both fine-grained nature of small inter-class variations with large intra-class variations and explosive growth of fine-grained data for such a practical task. In this paper, we propose attribute-aware hashing networks with self-consistency for generating attribute-aware hash codes to not only make the retrieval process efficient, but also establish explicit correspondences between hash codes and visual attributes. Specifically, based on the captured visual representations by attention, we develop an encoder-decoder structure network of a reconstruction task to unsupervisedly distill high-level attribute-specific vectors from the appearance-specific visual representations without attribute annotations. Our models are also equipped with a feature decorrelation constraint upon these attribute vectors to strengthen their representative abilities. Then, driven by preserving original entities' similarity, the required hash codes can be generated from these attribute-specific vectors and thus become attribute-aware. Furthermore, to combat simplicity bias in deep hashing, we consider the model design from the perspective of the self-consistency principle and propose to further enhance models' self-consistency by equipping an additional image reconstruction path. Comprehensive quantitative experiments under diverse empirical settings on six fine-grained retrieval datasets and two generic retrieval datasets show the superiority of our models over competing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [3.0448217391967773, 9.455574035644531]}, {"key": "", "year": "", "title": "Wei2023chain", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"CHAIN: Exploring Global-Local Spatio-Temporal Information for Improved Self-Supervised Video Hashing\"\nauthors: Wei Rukai, Liu Yu, Song Jingkuan, Cui Heng, Xie Yanzhao, Zhou Ke\nconference: Arxiv\nyear: 2023\nbibkey: wei2023chain\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2310.18926\"}\ntags: ['ARXIV', 'Self Supervised', 'Supervised', 'Video Retrieval']\n---\nCompressing videos into binary codes can improve retrieval speed and reduce storage overhead. However, learning accurate hash codes for video retrieval can be challenging due to high local redundancy and complex global dependencies between video frames, especially in the absence of labels. Existing self-supervised video hashing methods have been effective in designing expressive temporal encoders, but have not fully utilized the temporal dynamics and spatial appearance of videos due to less challenging and unreliable learning tasks. To address these challenges, we begin by utilizing the contrastive learning task to capture global spatio-temporal information of videos for hashing. With the aid of our designed augmentation strategies, which focus on spatial and temporal variations to create positive pairs, the learning framework can generate hash codes that are invariant to motion, scale, and viewpoint. Furthermore, we incorporate two collaborative learning tasks, i.e., frame order verification and scene change regularization, to capture local spatio-temporal details within video frames, thereby enhancing the perception of temporal structure and the modeling of spatio-temporal relationships. Our proposed Contrastive Hashing with Global-Local Spatio-temporal Information (CHAIN) outperforms state-of-the-art self-supervised video hashing methods on four video benchmark datasets. Our codes will be released.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-0.36256131529808044, 26.5335693359375]}, {"key": "", "year": "", "title": "Wei2023uniir", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"UniIR: Training and Benchmarking Universal Multimodal Information Retrievers\"\nauthors: Wei Cong, Chen Yang, Chen Haonan, Hu Hexiang, Zhang Ge, Fu Jie, Ritter Alan, Chen Wenhu\nconference: Arxiv\nyear: 2023\nbibkey: wei2023uniir\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2311.17136\"}\ntags: ['ARXIV', 'Cross Modal']\n---\nExisting information retrieval (IR) models often assume a homogeneous format, limiting their applicability to diverse user needs, such as searching for images with text descriptions, searching for a news article with a headline image, or finding a similar photo with a query image. To approach such different information-seeking demands, we introduce UniIR, a unified instruction-guided multimodal retriever capable of handling eight distinct retrieval tasks across modalities. UniIR, a single retrieval system jointly trained on ten diverse multimodal-IR datasets, interprets user instructions to execute various retrieval tasks, demonstrating robust performance across existing datasets and zero-shot generalization to new tasks. Our experiments highlight that multi-task training and instruction tuning are keys to UniIR's generalization ability. Additionally, we construct the M-BEIR, a multimodal retrieval benchmark with comprehensive results, to standardize the evaluation of universal multimodal information retrieval.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [20.646636962890625, 4.04620361328125]}, {"key": "", "year": "", "title": "Wei2024contrastive", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Contrastive masked auto-encoders based self-supervised hashing for 2D image and 3D point cloud cross-modal retrieval\"\nauthors: Wei Rukai, Cui Heng, Liu Yu, Hou Yufeng, Xie Yanzhao, Zhou Ke\nconference: Arxiv\nyear: 2024\nbibkey: wei2024contrastive\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2408.05711\"}\ntags: ['ARXIV', 'Cross Modal', 'Self Supervised', 'Supervised']\n---\nImplementing cross-modal hashing between 2D images and 3D point-cloud data is a growing concern in real-world retrieval systems. Simply applying existing cross-modal approaches to this new task fails to adequately capture latent multi-modal semantics and effectively bridge the modality gap between 2D and 3D. To address these issues without relying on hand-crafted labels, we propose contrastive masked autoencoders based self-supervised hashing (CMAH) for retrieval between images and point-cloud data. We start by contrasting 2D-3D pairs and explicitly constraining them into a joint Hamming space. This contrastive learning process ensures robust discriminability for the generated hash codes and effectively reduces the modality gap. Moreover, we utilize multi-modal auto-encoders to enhance the model's understanding of multi-modal semantics. By completing the masked image/point-cloud data modeling task, the model is encouraged to capture more localized clues. In addition, the proposed multi-modal fusion block facilitates fine-grained interactions among different modalities. Extensive experiments on three public datasets demonstrate that the proposed CMAH significantly outperforms all baseline methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-2.7538506984710693, 4.148930549621582]}, {"key": "", "year": "", "title": "Weiland2018understanding", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Understanding the Gist of Images - Ranking of Concepts for Multimedia Indexing\"\nauthors: Weiland Lydia, Ponzetto Simone Paolo, Effelsberg Wolfgang, Dietz Laura\nconference: Arxiv\nyear: 2018\nbibkey: weiland2018understanding\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1809.08593\"}\ntags: ['ARXIV']\n---\nNowadays, where multimedia data is continuously generated, stored, and distributed, multimedia indexing, with its purpose of group- ing similar data, becomes more important than ever. Understanding the gist (=message) of multimedia instances is framed in related work as a ranking of concepts from a knowledge base, i.e., Wikipedia. We cast the task of multimedia indexing as a gist understanding problem. Our pipeline benefits from external knowledge and two subsequent learning- to-rank (l2r) settings. The first l2r produces a ranking of concepts rep- resenting the respective multimedia instance. The second l2r produces a mapping between the concept representation of an instance and the targeted class topic(s) for the multimedia indexing task. The evaluation on an established big size corpus (MIRFlickr25k, with 25,000 images), shows that multimedia indexing benefits from understanding the gist. Finally, with a MAP of 61.42, it can be shown that the multimedia in- dexing task benefits from understanding the gist. Thus, the presented end-to-end setting outperforms DBM and competes with Hashing-based methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [20.84113883972168, 5.345873832702637]}, {"key": "", "year": "", "title": "Weinberger2009feature", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Feature Hashing for Large Scale Multitask Learning\"\nauthors: Weinberger Kilian, Dasgupta Anirban, Attenberg Josh, Langford John, Smola Alex\nconference: Arxiv\nyear: 2009\nbibkey: weinberger2009feature\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/0902.2206\"}\ntags: ['ARXIV']\n---\nEmpirical evidence suggests that hashing is an effective strategy for dimensionality reduction and practical nonparametric estimation. In this paper we provide exponential tail bounds for feature hashing and show that the interaction between random subspaces is negligible with high probability. We demonstrate the feasibility of this approach with experimental results for a new use case -- multitask learning with hundreds of thousands of tasks.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-25.495447158813477, 1.0225286483764648]}, {"key": "", "year": "", "title": "Weng2019efficient", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Efficient Querying from Weighted Binary Codes\"\nauthors: Weng Zhenyu, Zhu Yuesheng\nconference: Arxiv\nyear: 2019\nbibkey: weng2019efficient\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1912.05006\"}\ntags: ['ARXIV']\n---\nBinary codes are widely used to represent the data due to their small storage and efficient computation. However, there exists an ambiguity problem that lots of binary codes share the same Hamming distance to a query. To alleviate the ambiguity problem, weighted binary codes assign different weights to each bit of binary codes and compare the binary codes by the weighted Hamming distance. Till now, performing the querying from the weighted binary codes efficiently is still an open issue. In this paper, we propose a new method to rank the weighted binary codes and return the nearest weighted binary codes of the query efficiently. In our method, based on the multi-index hash tables, two algorithms, the table bucket finding algorithm and the table merging algorithm, are proposed to select the nearest weighted binary codes of the query in a non-exhaustive and accurate way. The proposed algorithms are justified by proving their theoretic properties. The experiments on three large-scale datasets validate both the search efficiency and the search accuracy of our method. Especially for the number of weighted binary codes up to one billion, our method shows a great improvement of more than 1000 times faster than the linear scan.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-7.717162132263184, -15.45859432220459]}, {"key": "", "year": "", "title": "Weng2019online", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Online Hashing with Efficient Updating of Binary Codes\"\nauthors: Weng Zhenyu, Zhu Yuesheng\nconference: Arxiv\nyear: 2019\nbibkey: weng2019online\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1911.12125\"}\ntags: ['ARXIV', 'Image Retrieval', 'Streaming Data']\n---\nOnline hashing methods are efficient in learning the hash functions from the streaming data. However, when the hash functions change, the binary codes for the database have to be recomputed to guarantee the retrieval accuracy. Recomputing the binary codes by accumulating the whole database brings a timeliness challenge to the online retrieval process. In this paper, we propose a novel online hashing framework to update the binary codes efficiently without accumulating the whole database. In our framework, the hash functions are fixed and the projection functions are introduced to learn online from the streaming data. Therefore, inefficient updating of the binary codes by accumulating the whole database can be transformed to efficient updating of the binary codes by projecting the binary codes into another binary space. The queries and the binary code database are projected asymmetrically to further improve the retrieval accuracy. The experiments on two multi-label image databases demonstrate the effectiveness and the efficiency of our method for multi-label image retrieval.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-6.597902774810791, 19.920480728149414]}, {"key": "", "year": "", "title": "Weng2020fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast Search on Binary Codes by Weighted Hamming Distance\"\nauthors: Weng Zhenyu, Zhu Yuesheng, Liu Ruixin\nconference: Arxiv\nyear: 2020\nbibkey: weng2020fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2009.08591\"}\ntags: ['ARXIV', 'TIP']\n---\nWeighted Hamming distance, as a similarity measure between binary codes and binary queries, provides superior accuracy in search tasks than Hamming distance. However, how to efficiently and accurately find $K$ binary codes that have the smallest weighted Hamming distance to the query remains an open issue. In this paper, a fast search algorithm is proposed to perform the non-exhaustive search for $K$ nearest binary codes by weighted Hamming distance. By using binary codes as direct bucket indices in a hash table, the search algorithm generates a sequence to probe the buckets based on the independence characteristic of the weights for each bit. Furthermore, a fast search framework based on the proposed search algorithm is designed to solve the problem of long binary codes. Specifically, long binary codes are split into substrings and multiple hash tables are built on them. Then, the search algorithm probes the buckets to obtain candidates according to the generated substring indices, and a merging algorithm is proposed to find the nearest binary codes by merging the candidates. Theoretical analysis and experimental results demonstrate that the search algorithm improves the search accuracy compared to other non-exhaustive algorithms and provides orders-of-magnitude faster search than the linear scan baseline.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-7.252745151519775, -16.47924041748047]}, {"key": "", "year": "", "title": "Weng2020random", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Random VLAD based Deep Hashing for Efficient Image Retrieval\"\nauthors: Weng Li, Ye Lingzhi, Tian Jiangmin, Cao Jiuwen, Wang Jianzhong\nconference: Arxiv\nyear: 2020\nbibkey: weng2020random\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2002.02333\"}\ntags: ['ARXIV', 'Image Retrieval', 'Quantisation']\n---\nImage hash algorithms generate compact binary representations that can be quickly matched by Hamming distance, thus become an efficient solution for large-scale image retrieval. This paper proposes RV-SSDH, a deep image hash algorithm that incorporates the classical VLAD (vector of locally aggregated descriptors) architecture into neural networks. Specifically, a novel neural network component is formed by coupling a random VLAD layer with a latent hash layer through a transform layer. This component can be combined with convolutional layers to realize a hash algorithm. We implement RV-SSDH as a point-wise algorithm that can be efficiently trained by minimizing classification error and quantization loss. Comprehensive experiments show this new architecture significantly outperforms baselines such as NetVLAD and SSDH, and offers a cost-effective trade-off in the state-of-the-art. In addition, the proposed random VLAD layer leads to satisfactory accuracy with low complexity, thus shows promising potentials as an alternative to NetVLAD.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [0.6247332692146301, 11.290188789367676]}, {"key": "", "year": "", "title": "Weng2021online", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Online Hashing with Similarity Learning\"\nauthors: Weng Zhenyu, Zhu Yuesheng\nconference: Arxiv\nyear: 2021\nbibkey: weng2021online\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2108.02560\"}\ntags: ['ARXIV', 'Image Retrieval', 'Streaming Data']\n---\nOnline hashing methods usually learn the hash functions online, aiming to efficiently adapt to the data variations in the streaming environment. However, when the hash functions are updated, the binary codes for the whole database have to be updated to be consistent with the hash functions, resulting in the inefficiency in the online image retrieval process. In this paper, we propose a novel online hashing framework without updating binary codes. In the proposed framework, the hash functions are fixed and a parametric similarity function for the binary codes is learnt online to adapt to the streaming data. Specifically, a parametric similarity function that has a bilinear form is adopted and a metric learning algorithm is proposed to learn the similarity function online based on the characteristics of the hashing methods. The experiments on two multi-label image datasets show that our method is competitive or outperforms the state-of-the-art online hashing methods in terms of both accuracy and efficiency for multi-label image retrieval.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-6.663636207580566, 19.98029136657715]}, {"key": "", "year": "", "title": "Weng2023constant", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Constant Sequence Extension for Fast Search Using Weighted Hamming Distance\"\nauthors: Weng Zhenyu, Zhuang Huiping, Li Haizhou, Lin Zhiping\nconference: Arxiv\nyear: 2023\nbibkey: weng2023constant\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2306.03612\"}\ntags: ['ARXIV']\n---\nRepresenting visual data using compact binary codes is attracting increasing attention as binary codes are used as direct indices into hash table(s) for fast non-exhaustive search. Recent methods show that ranking binary codes using weighted Hamming distance (WHD) rather than Hamming distance (HD) by generating query-adaptive weights for each bit can better retrieve query-related items. However, search using WHD is slower than that using HD. One main challenge is that the complexity of extending a monotone increasing sequence using WHD to probe buckets in hash table(s) for existing methods is at least proportional to the square of the sequence length, while that using HD is proportional to the sequence length. To overcome this challenge, we propose a novel fast non-exhaustive search method using WHD. The key idea is to design a constant sequence extension algorithm to perform each sequence extension in constant computational complexity and the total complexity is proportional to the sequence length, which is justified by theoretical analysis. Experimental results show that our method is faster than other WHD-based search methods. Also, compared with the HD-based non-exhaustive search method, our method has comparable efficiency but retrieves more query-related items for the dataset of up to one billion items.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-6.221930027008057, -15.800844192504883]}, {"key": "", "year": "", "title": "Weston2011large", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Large-Scale Music Annotation and Retrieval: Learning to Rank in Joint Semantic Spaces\"\nauthors: Weston Jason, Bengio Samy, Hamel Philippe\nconference: Arxiv\nyear: 2011\nbibkey: weston2011large\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1105.5196\"}\ntags: ['ARXIV']\n---\nMusic prediction tasks range from predicting tags given a song or clip of audio, predicting the name of the artist, or predicting related songs given a song, clip, artist name or tag. That is, we are interested in every semantic relationship between the different musical concepts in our database. In realistically sized databases, the number of songs is measured in the hundreds of thousands or more, and the number of artists in the tens of thousands or more, providing a considerable challenge to standard machine learning techniques. In this work, we propose a method that scales to such datasets which attempts to capture the semantic similarities between the database items by modeling audio, artist names, and tags in a single low-dimensional semantic space. This choice of space is learnt by optimizing the set of prediction tasks of interest jointly using multi-task learning. Our method both outperforms baseline methods and, in comparison to them, is faster and consumes less memory. We then demonstrate how our method learns an interpretable model, where the semantic space captures well the similarities of interest.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [30.25396156311035, -7.337425231933594]}, {"key": "", "year": "", "title": "Wieschollek2017efficient", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Efficient Large-scale Approximate Nearest Neighbor Search on the GPU\"\nauthors: Wieschollek Patrick, Wang Oliver, Sorkine-Hornung Alexander, Lensch Hendrik P. A.\nconference: The IEEE Conference on Computer Vision and Pattern Recognition\nyear: 2017\nbibkey: wieschollek2017efficient\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1702.05911\"}\ntags: ['Quantisation']\n---\nWe present a new approach for efficient approximate nearest neighbor (ANN) search in high dimensional spaces, extending the idea of Product Quantization. We propose a two-level product and vector quantization tree that reduces the number of vector comparisons required during tree traversal. Our approach also includes a novel highly parallelizable re-ranking method for candidate vectors by efficiently reusing already computed intermediate values. Due to its small memory footprint during traversal, the method lends itself to an efficient, parallel GPU implementation. This Product Quantization Tree (PQT) approach significantly outperforms recent state of the art methods for high dimensional nearest neighbor queries on standard reference datasets. Ours is the first work that demonstrates GPU performance superior to CPU performance on high dimensional, large scale ANN problems in time-critical real-world applications, like loop-closing in videos.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [5.543776512145996, -13.490142822265625]}, {"key": "", "year": "", "title": "Won2020multimodal", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Multimodal Metric Learning for Tag-based Music Retrieval\"\nauthors: Won Minz, Oramas Sergio, Nieto Oriol, Gouyon Fabien, Serra Xavier\nconference: Arxiv\nyear: 2020\nbibkey: won2020multimodal\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2010.16030\"}\ntags: ['ARXIV', 'Cross Modal', 'TOM']\n---\nTag-based music retrieval is crucial to browse large-scale music libraries efficiently. Hence, automatic music tagging has been actively explored, mostly as a classification task, which has an inherent limitation: a fixed vocabulary. On the other hand, metric learning enables flexible vocabularies by using pretrained word embeddings as side information. Also, metric learning has already proven its suitability for cross-modal retrieval tasks in other domains (e.g., text-to-image) by jointly learning a multimodal embedding space. In this paper, we investigate three ideas to successfully introduce multimodal metric learning for tag-based music retrieval: elaborate triplet sampling, acoustic and cultural music information, and domain-specific word embeddings. Our experimental results show that the proposed ideas enhance the retrieval system quantitatively, and qualitatively. Furthermore, we release the MSD500, a subset of the Million Song Dataset (MSD) containing 500 cleaned tags, 7 manually annotated tag categories, and user taste profiles.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [30.5992488861084, -6.733826160430908]}, {"key": "", "year": "", "title": "Wu2016robust", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Robust Hashing for Multi-View Data: Jointly Learning Low-Rank Kernelized Similarity Consensus and Hash Functions\"\nauthors: Wu Lin, Wang Yang\nconference: Arxiv\nyear: 2016\nbibkey: wu2016robust\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1611.05521\"}\ntags: ['ARXIV', 'Graph', 'TIP', 'TOM']\n---\nLearning hash functions/codes for similarity search over multi-view data is attracting increasing attention, where similar hash codes are assigned to the data objects characterizing consistently neighborhood relationship across views. Traditional methods in this category inherently suffer three limitations: 1) they commonly adopt a two-stage scheme where similarity matrix is first constructed, followed by a subsequent hash function learning; 2) these methods are commonly developed on the assumption that data samples with multiple representations are noise-free,which is not practical in real-life applications; 3) they often incur cumbersome training model caused by the neighborhood graph construction using all $N$ points in the database ($O(N)$). In this paper, we motivate the problem of jointly and efficiently training the robust hash functions over data objects with multi-feature representations which may be noise corrupted. To achieve both the robustness and training efficiency, we propose an approach to effectively and efficiently learning low-rank kernelized \\footnote{We use kernelized similarity rather than kernel, as it is not a squared symmetric matrix for data-landmark affinity matrix.} hash functions shared across views. Specifically, we utilize landmark graphs to construct tractable similarity matrices in multi-views to automatically discover neighborhood structure in the data. To learn robust hash functions, a latent low-rank kernel function is used to construct hash functions in order to accommodate linearly inseparable data. In particular, a latent kernelized similarity matrix is recovered by rank minimization on multiple kernel-based similarity matrices. Extensive experiments on real-world multi-view datasets validate the efficacy of our method in the presence of error corruptions.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-10.555447578430176, -6.150580406188965]}, {"key": "", "year": "", "title": "Wu2017improved", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Improved Consistent Weighted Sampling Revisited\"\nauthors: Wu Wei, Li Bin, Chen Ling, Zhang Chengqi, Yu Philip S.\nconference: Arxiv\nyear: 2017\nbibkey: wu2017improved\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1706.01172\"}\ntags: ['ARXIV']\n---\nMin-Hash is a popular technique for efficiently estimating the Jaccard similarity of binary sets. Consistent Weighted Sampling (CWS) generalizes the Min-Hash scheme to sketch weighted sets and has drawn increasing interest from the community. Due to its constant-time complexity independent of the values of the weights, Improved CWS (ICWS) is considered as the state-of-the-art CWS algorithm. In this paper, we revisit ICWS and analyze its underlying mechanism to show that there actually exists dependence between the two components of the hash-code produced by ICWS, which violates the condition of independence. To remedy the problem, we propose an Improved ICWS (I$^2$CWS) algorithm which not only shares the same theoretical computational complexity as ICWS but also abides by the required conditions of the CWS scheme. The experimental results on a number of synthetic data sets and real-world text data sets demonstrate that our I$^2$CWS algorithm can estimate the Jaccard similarity more accurately, and also compete with or outperform the compared methods, including ICWS, in classification and top-$K$ retrieval, after relieving the underlying dependence.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-3.2104451656341553, -9.124868392944336]}, {"key": "", "year": "", "title": "Wu2017structured", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Structured Deep Hashing with Convolutional Neural Networks for Fast Person Re-identification\"\nauthors: Wu Lin, Wang Yang\nconference: Arxiv\nyear: 2017\nbibkey: wu2017structured\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1702.04179\"}\ntags: ['ARXIV', 'CNN', 'Deep Learning']\n---\nGiven a pedestrian image as a query, the purpose of person re-identification is to identify the correct match from a large collection of gallery images depicting the same person captured by disjoint camera views. The critical challenge is how to construct a robust yet discriminative feature representation to capture the compounded variations in pedestrian appearance. To this end, deep learning methods have been proposed to extract hierarchical features against extreme variability of appearance. However, existing methods in this category generally neglect the efficiency in the matching stage whereas the searching speed of a re-identification system is crucial in real-world applications. In this paper, we present a novel deep hashing framework with Convolutional Neural Networks (CNNs) for fast person re-identification. Technically, we simultaneously learn both CNN features and hash functions/codes to get robust yet discriminative features and similarity-preserving hash codes. Thereby, person re-identification can be resolved by efficiently computing and ranking the Hamming distances between images. A structured loss function defined over positive pairs and hard negatives is proposed to formulate a novel optimization problem so that fast convergence and more stable optimized solution can be obtained. Extensive experiments on two benchmarks CUHK03 \\cite{FPNN} and Market-1501 \\cite{Market1501} show that the proposed deep architecture is efficacy over state-of-the-arts.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.463688850402832, 1.9939825534820557]}, {"key": "", "year": "", "title": "Wu2018a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Review for Weighted MinHash Algorithms\"\nauthors: Wu Wei, Li Bin, Chen Ling, Gao Junbin, Zhang Chengqi\nconference: Arxiv\nyear: 2018\nbibkey: wu2018a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1811.04633\"}\ntags: ['ARXIV', 'Quantisation', 'Survey Paper']\n---\nData similarity (or distance) computation is a fundamental research topic which underpins many high-level applications based on similarity measures in machine learning and data mining. However, in large-scale real-world scenarios, the exact similarity computation has become daunting due to \"3V\" nature (volume, velocity and variety) of big data. In such cases, the hashing techniques have been verified to efficiently conduct similarity estimation in terms of both theory and practice. Currently, MinHash is a popular technique for efficiently estimating the Jaccard similarity of binary sets and furthermore, weighted MinHash is generalized to estimate the generalized Jaccard similarity of weighted sets. This review focuses on categorizing and discussing the existing works of weighted MinHash algorithms. In this review, we mainly categorize the Weighted MinHash algorithms into quantization-based approaches, \"active index\"-based ones and others, and show the evolution and inherent connection of the weighted MinHash algorithms, from the integer weighted MinHash algorithms to real-valued weighted MinHash ones (particularly the Consistent Weighted Sampling scheme). Also, we have developed a python toolbox for the algorithms, and released it in our github. Based on the toolbox, we experimentally conduct a comprehensive comparative study of the standard MinHash algorithm and the weighted MinHash ones.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-0.4664888381958008, -23.68011474609375]}, {"key": "", "year": "", "title": "Wu2018cycle", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Cycle-Consistent Deep Generative Hashing for Cross-Modal Retrieval\"\nauthors: Wu Lin, Wang Yang, Shao Ling\nconference: Arxiv\nyear: 2018\nbibkey: wu2018cycle\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1804.11013\"}\ntags: ['ARXIV', 'Cross Modal']\n---\nIn this paper, we propose a novel deep generative approach to cross-modal retrieval to learn hash functions in the absence of paired training samples through the cycle consistency loss. Our proposed approach employs adversarial training scheme to lean a couple of hash functions enabling translation between modalities while assuming the underlying semantic relationship. To induce the hash codes with semantics to the input-output pair, cycle consistency loss is further proposed upon the adversarial training to strengthen the correlations between inputs and corresponding outputs. Our approach is generative to learn hash functions such that the learned hash codes can maximally correlate each input-output correspondence, meanwhile can also regenerate the inputs so as to minimize the information loss. The learning to hash embedding is thus performed to jointly optimize the parameters of the hash functions across modalities as well as the associated generative models. Extensive experiments on a variety of large-scale cross-modal data sets demonstrate that our proposed method achieves better retrieval results than the state-of-the-arts.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-13.165834426879883, 3.610353708267212]}, {"key": "", "year": "", "title": "Wu2018learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning Effective Binary Visual Representations with Deep Networks\"\nauthors: Wu Jianxin, Luo Jian-Hao\nconference: Arxiv\nyear: 2018\nbibkey: wu2018learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1803.03004\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nAlthough traditionally binary visual representations are mainly designed to reduce computational and storage costs in the image retrieval research, this paper argues that binary visual representations can be applied to large scale recognition and detection problems in addition to hashing in retrieval. Furthermore, the binary nature may make it generalize better than its real-valued counterparts. Existing binary hashing methods are either two-stage or hinging on loss term regularization or saturated functions, hence converge slowly and only emit soft binary values. This paper proposes Approximately Binary Clamping (ABC), which is non-saturating, end-to-end trainable, with fast convergence and can output true binary visual representations. ABC achieves comparable accuracy in ImageNet classification as its real-valued counterpart, and even generalizes better in object detection. On benchmark image retrieval datasets, ABC also outperforms existing hashing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [2.5741770267486572, 2.7799224853515625]}, {"key": "", "year": "", "title": "Wu2021hashing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hashing-Accelerated Graph Neural Networks for Link Prediction\"\nauthors: Wu Wei, Li Bin, Luo Chuan, Nejdl Wolfgang\nconference: The Web Conference\nyear: 2021\nbibkey: wu2021hashing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2105.14280\"}\ntags: ['Graph']\n---\nNetworks are ubiquitous in the real world. Link prediction, as one of the key problems for network-structured data, aims to predict whether there exists a link between two nodes. The traditional approaches are based on the explicit similarity computation between the compact node representation by embedding each node into a low-dimensional space. In order to efficiently handle the intensive similarity computation in link prediction, the hashing technique has been successfully used to produce the node representation in the Hamming space. However, the hashing-based link prediction algorithms face accuracy loss from the randomized hashing techniques or inefficiency from the learning to hash techniques in the embedding process. Currently, the Graph Neural Network (GNN) framework has been widely applied to the graph-related tasks in an end-to-end manner, but it commonly requires substantial computational resources and memory costs due to massive parameter learning, which makes the GNN-based algorithms impractical without the help of a powerful workhorse. In this paper, we propose a simple and effective model called #GNN, which balances the trade-off between accuracy and efficiency. #GNN is able to efficiently acquire node representation in the Hamming space for link prediction by exploiting the randomized hashing technique to implement message passing and capture high-order proximity in the GNN framework. Furthermore, we characterize the discriminative power of #GNN in probability. The extensive experimental results demonstrate that the proposed #GNN algorithm achieves accuracy comparable to the learning-based algorithms and outperforms the randomized algorithm, while running significantly faster than the learning-based algorithms. Also, the proposed algorithm shows excellent scalability on a large-scale network with the limited resources.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [3.443936347961426, -31.510862350463867]}, {"key": "", "year": "", "title": "Wu2021online", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Online Enhanced Semantic Hashing: Towards Effective and Efficient Retrieval for Streaming Multi-Modal Data\"\nauthors: Wu Xiao-Ming, Luo Xin, Zhan Yu-Wei, Ding Chen-Lu, Chen Zhen-Duo, Xu Xin-Shun\nconference: Arxiv\nyear: 2021\nbibkey: wu2021online\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2109.04260\"}\ntags: ['ARXIV', 'Streaming Data']\n---\nWith the vigorous development of multimedia equipment and applications, efficient retrieval of large-scale multi-modal data has become a trendy research topic. Thereinto, hashing has become a prevalent choice due to its retrieval efficiency and low storage cost. Although multi-modal hashing has drawn lots of attention in recent years, there still remain some problems. The first point is that existing methods are mainly designed in batch mode and not able to efficiently handle streaming multi-modal data. The second point is that all existing online multi-modal hashing methods fail to effectively handle unseen new classes which come continuously with streaming data chunks. In this paper, we propose a new model, termed Online enhAnced SemantIc haShing (OASIS). We design novel semantic-enhanced representation for data, which could help handle the new coming classes, and thereby construct the enhanced semantic objective function. An efficient and effective discrete online optimization algorithm is further proposed for OASIS. Extensive experiments show that our method can exceed the state-of-the-art models. For good reproducibility and benefiting the community, our code and data are already available in supplementary material and will be made publicly available.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-16.35941505432129, 4.248480319976807]}, {"key": "", "year": "", "title": "Wu2022hierarchical", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hierarchical Locality Sensitive Hashing for Structured Data: A Survey\"\nauthors: Wu Wei, Li Bin\nconference: Arxiv\nyear: 2022\nbibkey: wu2022hierarchical\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2204.11209\"}\ntags: ['ARXIV', 'Graph', 'LSH', 'Survey Paper', 'TIP']\n---\nData similarity (or distance) computation is a fundamental research topic which fosters a variety of similarity-based machine learning and data mining applications. In big data analytics, it is impractical to compute the exact similarity of data instances due to high computational cost. To this end, the Locality Sensitive Hashing (LSH) technique has been proposed to provide accurate estimators for various similarity measures between sets or vectors in an efficient manner without the learning process. Structured data (e.g., sequences, trees and graphs), which are composed of elements and relations between the elements, are commonly seen in the real world, but the traditional LSH algorithms cannot preserve the structure information represented as relations between elements. In order to conquer the issue, researchers have been devoted to the family of the hierarchical LSH algorithms. In this paper, we explore the present progress of the research into hierarchical LSH from the following perspectives: 1) Data structures, where we review various hierarchical LSH algorithms for three typical data structures and uncover their inherent connections; 2) Applications, where we review the hierarchical LSH algorithms in multiple application scenarios; 3) Challenges, where we discuss some potential challenges as future directions.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-0.4407772123813629, -23.93244743347168]}, {"key": "", "year": "", "title": "Wu2022hqann", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"HQANN: Efficient and Robust Similarity Search for Hybrid Queries with Structured and Unstructured Constraints\"\nauthors: Wu Wei, He Junlin, Qiao Yu, Fu Guoheng, Liu Li, Yu Jin\nconference: Arxiv\nyear: 2022\nbibkey: wu2022hqann\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2207.07940\"}\ntags: ['ARXIV', 'Graph']\n---\nThe in-memory approximate nearest neighbor search (ANNS) algorithms have achieved great success for fast high-recall query processing, but are extremely inefficient when handling hybrid queries with unstructured (i.e., feature vectors) and structured (i.e., related attributes) constraints. In this paper, we present HQANN, a simple yet highly efficient hybrid query processing framework which can be easily embedded into existing proximity graph-based ANNS algorithms. We guarantee both low latency and high recall by leveraging navigation sense among attributes and fusing vector similarity search with attribute filtering. Experimental results on both public and in-house datasets demonstrate that HQANN is 10x faster than the state-of-the-art hybrid ANNS solutions to reach the same recall quality and its performance is hardly affected by the complexity of attributes. It can reach 99\\% recall@10 in just around 50 microseconds On GLOVE-1.2M with thousands of attribute constraints.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-3.5190768241882324, -17.85702133178711]}, {"key": "", "year": "", "title": "Wu2022retrievalguard", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"RetrievalGuard: Provably Robust 1-Nearest Neighbor Image Retrieval\"\nauthors: Wu Yihan, Zhang Hongyang, Huang Heng\nconference: Arxiv\nyear: 2022\nbibkey: wu2022retrievalguard\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2206.11225\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nRecent research works have shown that image retrieval models are vulnerable to adversarial attacks, where slightly modified test inputs could lead to problematic retrieval results. In this paper, we aim to design a provably robust image retrieval model which keeps the most important evaluation metric Recall@1 invariant to adversarial perturbation. We propose the first 1-nearest neighbor (NN) image retrieval algorithm, RetrievalGuard, which is provably robust against adversarial perturbations within an $\\ell_2$ ball of calculable radius. The challenge is to design a provably robust algorithm that takes into consideration the 1-NN search and the high-dimensional nature of the embedding space. Algorithmically, given a base retrieval model and a query sample, we build a smoothed retrieval model by carefully analyzing the 1-NN search procedure in the high-dimensional embedding space. We show that the smoothed retrieval model has bounded Lipschitz constant and thus the retrieval score is invariant to $\\ell_2$ adversarial perturbations. Experiments on image retrieval tasks validate the robustness of our RetrievalGuard method.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.81587028503418, 15.048344612121582]}, {"key": "", "year": "", "title": "Wu2022self", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Self-Supervised Consistent Quantization for Fully Unsupervised Image Retrieval\"\nauthors: Wu Guile, Zhang Chao, Liwicki Stephan\nconference: Arxiv\nyear: 2022\nbibkey: wu2022self\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2206.09806\"}\ntags: ['ARXIV', 'Image Retrieval', 'Quantisation', 'Self Supervised', 'Supervised', 'Unsupervised']\n---\nUnsupervised image retrieval aims to learn an efficient retrieval system without expensive data annotations, but most existing methods rely heavily on handcrafted feature descriptors or pre-trained feature extractors. To minimize human supervision, recent advance proposes deep fully unsupervised image retrieval aiming at training a deep model from scratch to jointly optimize visual features and quantization codes. However, existing approach mainly focuses on instance contrastive learning without considering underlying semantic structure information, resulting in sub-optimal performance. In this work, we propose a novel self-supervised consistent quantization approach to deep fully unsupervised image retrieval, which consists of part consistent quantization and global consistent quantization. In part consistent quantization, we devise part neighbor semantic consistency learning with codeword diversity regularization. This allows to discover underlying neighbor structure information of sub-quantized representations as self-supervision. In global consistent quantization, we employ contrastive learning for both embedding and quantized representations and fuses these representations for consistent contrastive regularization between instances. This can make up for the loss of useful representation information during quantization and regularize consistency between instances. With a unified learning objective of part and global consistent quantization, our approach exploits richer self-supervision cues to facilitate model learning. Extensive experiments on three benchmark datasets show the superiority of our approach over the state-of-the-art methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [3.5948221683502197, 15.387980461120605]}, {"key": "", "year": "", "title": "Wu2024sign", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Sign-Guided Bipartite Graph Hashing for Hamming Space Search\"\nauthors: Wu Xueyi\nconference: Arxiv\nyear: 2024\nbibkey: wu2024sign\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2405.02716\"}\ntags: ['ARXIV', 'Graph']\n---\nBipartite graph hashing (BGH) is extensively used for Top-K search in Hamming space at low storage and inference costs. Recent research adopts graph convolutional hashing for BGH and has achieved the state-of-the-art performance. However, the contributions of its various influencing factors to hashing performance have not been explored in-depth, including the same/different sign count between two binary embeddings during Hamming space search (sign property), the contribution of sub-embeddings at each layer (model property), the contribution of different node types in the bipartite graph (node property), and the combination of augmentation methods. In this work, we build a lightweight graph convolutional hashing model named LightGCH by mainly removing the augmentation methods of the state-of-the-art model BGCH. By analyzing the contributions of each layer and node type to performance, as well as analyzing the Hamming similarity statistics at each layer, we find that the actual neighbors in the bipartite graph tend to have low Hamming similarity at the shallow layer, and all nodes tend to have high Hamming similarity at the deep layers in LightGCH. To tackle these problems, we propose a novel sign-guided framework SGBGH to make improvement, which uses sign-guided negative sampling to improve the Hamming similarity of neighbors, and uses sign-aware contrastive learning to help nodes learn more uniform representations. Experimental results show that SGBGH outperforms BGCH and LightGCH significantly in embedding quality.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [2.4811179637908936, -27.333942413330078]}, {"key": "", "year": "", "title": "Wurzer2016randomised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Randomised Relevance Model\"\nauthors: Wurzer Dominik, Osborne Miles, Lavrenko Victor\nconference: Arxiv\nyear: 2016\nbibkey: wurzer2016randomised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1607.02641\"}\ntags: ['ARXIV', 'LSH']\n---\nRelevance Models are well-known retrieval models and capable of producing competitive results. However, because they use query expansion they can be very slow. We address this slowness by incorporating two variants of locality sensitive hashing (LSH) into the query expansion process. Results on two document collections suggest that we can obtain large reductions in the amount of work, with a small reduction in effectiveness. Our approach is shown to be additive when pruning query terms.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [1.7294235229492188, -14.936031341552734]}, {"key": "", "year": "", "title": "Wurzer2022parameterizing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Parameterizing Kterm Hashing\"\nauthors: Wurzer Dominik, Qin Yumeng\nconference: SIGIR\nyear: 2022\nbibkey: wurzer2022parameterizing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2208.01340\"}\ntags: []\n---\nKterm Hashing provides an innovative approach to novelty detection on massive data streams. Previous research focused on maximizing the efficiency of Kterm Hashing and succeeded in scaling First Story Detection to Twitter-size data stream without sacrificing detection accuracy. In this paper, we focus on improving the effectiveness of Kterm Hashing. Traditionally, all kterms are considered as equally important when calculating a document's degree of novelty with respect to the past. We believe that certain kterms are more important than others and hypothesize that uniform kterm weights are sub-optimal for determining novelty in data streams. To validate our hypothesis, we parameterize Kterm Hashing by assigning weights to kterms based on their characteristics. Our experiments apply Kterm Hashing in a First Story Detection setting and reveal that parameterized Kterm Hashing can surpass state-of-the-art detection accuracy and significantly outperform the uniformly weighted approach.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-17.83672332763672, -13.129981994628906]}, {"key": "", "year": "", "title": "Wygocki2017on", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"On fast bounded locality sensitive hashing\"\nauthors: Wygocki Piotr\nconference: Arxiv\nyear: 2017\nbibkey: wygocki2017on\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1704.05902\"}\ntags: ['ARXIV']\n---\nIn this paper, we examine the hash functions expressed as scalar products, i.e., $f(x)=&lt;v,x&gt;$, for some bounded random vector $v$. Such hash functions have numerous applications, but often there is a need to optimize the choice of the distribution of $v$. In the present work, we focus on so-called anti-concentration bounds, i.e. the upper bounds of $\\mathbb\\{P\\}\\left[|&lt;v,x&gt;| &lt; \\alpha \\right]$. In many applications, $v$ is a vector of independent random variables with standard normal distribution. In such case, the distribution of $&lt;v,x&gt;$ is also normal and it is easy to approximate $\\mathbb\\{P\\}\\left[|&lt;v,x&gt;| &lt; \\alpha \\right]$. Here, we consider two bounded distributions in the context of the anti-concentration bounds. Particularly, we analyze $v$ being a random vector from the unit ball in $l_\\{\\infty\\}$ and $v$ being a random vector from the unit sphere in $l_\\{2\\}$. We show optimal up to a constant anti-concentration measures for functions $f(x)=&lt;v,x&gt;$. As a consequence of our research, we obtain new best results for \\newline \\textit{$c$-approximate nearest neighbors without false negatives} for $l_p$ in high dimensional space for all $p\\in[1,\\infty]$, for $c=\\Omega(\\max\\\\{\\sqrt\\{d\\},d^\\{1/p\\}\\\\})$. These results improve over those presented in [16]. Finally, our paper reports progress on answering the open problem by Pagh~[17], who considered the nearest neighbor search without false negatives for the Hamming distance.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-13.260063171386719, -24.086000442504883]}, {"key": "", "year": "", "title": "W\u00f6hnert2023a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A study on the use of perceptual hashing to detect manipulation of embedded messages in images\"\nauthors: W\u00f6hnert Sven-Jannik, W\u00f6hnert Kai Hendrik, Almamedov Eldar, Frank Carsten, Skwarek Volker\nconference: Arxiv\nyear: 2023\nbibkey: w\u00f6hnert2023a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2303.00092\"}\ntags: ['ARXIV']\n---\nTypically, metadata of images are stored in a specific data segment of the image file. However, to securely detect changes, data can also be embedded within images. This follows the goal to invisibly and robustly embed as much information as possible to, ideally, even survive compression. This work searches for embedding principles which allow to distinguish between unintended changes by lossy image compression and malicious manipulation of the embedded message based on the change of its perceptual or robust hash. Different embedding and compression algorithms are compared. The study shows that embedding a message via integer wavelet transform and compression with Karhunen-Loeve-transform yields the best results. However, it was not possible to distinguish between manipulation and compression in all cases.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [19.021812438964844, 13.518248558044434]}, {"key": "", "year": "", "title": "Xia2016unsupervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Unsupervised Deep Hashing for Large-scale Visual Search\"\nauthors: Xia Zhaoqiang, Feng Xiaoyi, Peng Jinye, Hadid Abdenour\nconference: \nyear: 2016\nbibkey: xia2016unsupervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1602.00206\"}\ntags: ['Deep Learning', 'Supervised', 'Unsupervised']\n---\nLearning based hashing plays a pivotal role in large-scale visual search. However, most existing hashing algorithms tend to learn shallow models that do not seek representative binary codes. In this paper, we propose a novel hashing approach based on unsupervised deep learning to hierarchically transform features into hash codes. Within the heterogeneous deep hashing framework, the autoencoder layers with specific constraints are considered to model the nonlinear mapping between features and binary codes. Then, a Restricted Boltzmann Machine (RBM) layer with constraints is utilized to reduce the dimension in the hamming space. Extensive experiments on the problem of visual search demonstrate the competitiveness of our proposed approach compared to state-of-the-art.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-10.784331321716309, 14.823141098022461]}, {"key": "", "year": "", "title": "Xiao2023unsupervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Unsupervised Multi-Criteria Adversarial Detection in Deep Image Retrieval\"\nauthors: Xiao Yanru, Wang Cong, Gao Xing\nconference: Arxiv\nyear: 2023\nbibkey: xiao2023unsupervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2304.04228\"}\ntags: ['ARXIV', 'Deep Learning', 'Image Retrieval', 'Quantisation', 'Supervised', 'Unsupervised']\n---\nThe vulnerability in the algorithm supply chain of deep learning has imposed new challenges to image retrieval systems in the downstream. Among a variety of techniques, deep hashing is gaining popularity. As it inherits the algorithmic backend from deep learning, a handful of attacks are recently proposed to disrupt normal image retrieval. Unfortunately, the defense strategies in softmax classification are not readily available to be applied in the image retrieval domain. In this paper, we propose an efficient and unsupervised scheme to identify unique adversarial behaviors in the hamming space. In particular, we design three criteria from the perspectives of hamming distance, quantization loss and denoising to defend against both untargeted and targeted attacks, which collectively limit the adversarial space. The extensive experiments on four datasets demonstrate 2-23% improvements of detection rates with minimum computational overhead for real-time image queries.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [4.580313682556152, 24.981962203979492]}, {"key": "", "year": "", "title": "Xie2013kernelized", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Kernelized Locality-Sensitive Hashing for Semi-Supervised Agglomerative Clustering\"\nauthors: Xie Boyi, Zheng Shuheng\nconference: Arxiv\nyear: 2013\nbibkey: xie2013kernelized\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1301.3575\"}\ntags: ['ARXIV', 'LSH', 'Semi Supervised', 'Supervised']\n---\nLarge scale agglomerative clustering is hindered by computational burdens. We propose a novel scheme where exact inter-instance distance calculation is replaced by the Hamming distance between Kernelized Locality-Sensitive Hashing (KLSH) hashed values. This results in a method that drastically decreases computation time. Additionally, we take advantage of certain labeled data points via distance metric learning to achieve a competitive precision and recall comparing to K-Means but in much less computation time.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [1.7894469499588013, -13.876143455505371]}, {"key": "", "year": "", "title": "Xiong2020approximate", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval\"\nauthors: Xiong Lee, Xiong Chenyan, Li Ye, Tang Kwok-Fung, Liu Jialin, Bennett Paul, Ahmed Junaid, Overwijk Arnold\nconference: Arxiv\nyear: 2020\nbibkey: xiong2020approximate\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2007.00808\"}\ntags: ['ARXIV', 'Text Retrieval']\n---\nConducting text retrieval in a dense learned representation space has many intriguing advantages over sparse retrieval. Yet the effectiveness of dense retrieval (DR) often requires combination with sparse retrieval. In this paper, we identify that the main bottleneck is in the training mechanisms, where the negative instances used in training are not representative of the irrelevant documents in testing. This paper presents Approximate nearest neighbor Negative Contrastive Estimation (ANCE), a training mechanism that constructs negatives from an Approximate Nearest Neighbor (ANN) index of the corpus, which is parallelly updated with the learning process to select more realistic negative training instances. This fundamentally resolves the discrepancy between the data distribution used in the training and testing of DR. In our experiments, ANCE boosts the BERT-Siamese DR model to outperform all competitive dense and sparse retrieval baselines. It nearly matches the accuracy of sparse-retrieval-and-BERT-reranking using dot-product in the ANCE-learned representation space and provides almost 100x speed-up.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-9.856667518615723, 20.670408248901367]}, {"key": "", "year": "", "title": "Xu2015short", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Short Text Hashing Improved by Integrating Multi-Granularity Topics and Tags\"\nauthors: Xu Jiaming, Xu Bo, Tian Guanhua, Zhao Jun, Wang Fangyuan, Hao Hongwei\nconference: Arxiv\nyear: 2015\nbibkey: xu2015short\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1503.02801\"}\ntags: ['ARXIV']\n---\nDue to computational and storage efficiencies of compact binary codes, hashing has been widely used for large-scale similarity search. Unfortunately, many existing hashing methods based on observed keyword features are not effective for short texts due to the sparseness and shortness. Recently, some researchers try to utilize latent topics of certain granularity to preserve semantic similarity in hash codes beyond keyword matching. However, topics of certain granularity are not adequate to represent the intrinsic semantic information. In this paper, we present a novel unified approach for short text Hashing using Multi-granularity Topics and Tags, dubbed HMTT. In particular, we propose a selection method to choose the optimal multi-granularity topics depending on the type of dataset, and design two distinct hashing strategies to incorporate multi-granularity topics. We also propose a simple and effective method to exploit tags to enhance the similarity of related texts. We carry out extensive experiments on one short text dataset as well as on one normal text dataset. The results demonstrate that our approach is effective and significantly outperforms baselines on several evaluation metrics.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-5.588136672973633, -6.195271015167236]}, {"key": "", "year": "", "title": "Xu2016binary", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Binary Subspace Coding for Query-by-Image Video Retrieval\"\nauthors: Xu Ruicong, Yang Yang, Luo Yadan, Shen Fumin, Huang Zi, Shen Heng Tao\nconference: Arxiv\nyear: 2016\nbibkey: xu2016binary\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1612.01657\"}\ntags: ['ARXIV', 'Video Retrieval']\n---\nThe query-by-image video retrieval (QBIVR) task has been attracting considerable research attention recently. However, most existing methods represent a video by either aggregating or projecting all its frames into a single datum point, which may easily cause severe information loss. In this paper, we propose an efficient QBIVR framework to enable an effective and efficient video search with image query. We first define a similarity-preserving distance metric between an image and its orthogonal projection in the subspace of the video, which can be equivalently transformed to a Maximum Inner Product Search (MIPS) problem. Besides, to boost the efficiency of solving the MIPS problem, we propose two asymmetric hashing schemes, which bridge the domain gap of images and videos. The first approach, termed Inner-product Binary Coding (IBC), preserves the inner relationships of images and videos in a common Hamming space. To further improve the retrieval efficiency, we devise a Bilinear Binary Coding (BBC) approach, which employs compact bilinear projections instead of a single large projection matrix. Extensive experiments have been conducted on four real-world video datasets to verify the effectiveness of our proposed approaches as compared to the state-of-the-arts.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [0.48987677693367004, 28.032819747924805]}, {"key": "", "year": "", "title": "Xu2017cross", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Cross-modal Subspace Learning for Fine-grained Sketch-based Image Retrieval\"\nauthors: Xu Peng, Yin Qiyue, Huang Yongye, Song Yi-Zhe, Ma Zhanyu, Wang Liang, Xiang Tao, Kleijn W. Bastiaan, Guo Jun\nconference: Arxiv\nyear: 2017\nbibkey: xu2017cross\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1705.09888\"}\ntags: ['ARXIV', 'Cross Modal', 'Image Retrieval']\n---\nSketch-based image retrieval (SBIR) is challenging due to the inherent domain-gap between sketch and photo. Compared with pixel-perfect depictions of photos, sketches are iconic renderings of the real world with highly abstract. Therefore, matching sketch and photo directly using low-level visual clues are unsufficient, since a common low-level subspace that traverses semantically across the two modalities is non-trivial to establish. Most existing SBIR studies do not directly tackle this cross-modal problem. This naturally motivates us to explore the effectiveness of cross-modal retrieval methods in SBIR, which have been applied in the image-text matching successfully. In this paper, we introduce and compare a series of state-of-the-art cross-modal subspace learning methods and benchmark them on two recently released fine-grained SBIR datasets. Through thorough examination of the experimental results, we have demonstrated that the subspace learning can effectively model the sketch-photo domain-gap. In addition we draw a few key insights to drive future research.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [6.880982875823975, 18.03889274597168]}, {"key": "", "year": "", "title": "Xu2018error", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Error Correction Maximization for Deep Image Hashing\"\nauthors: Xu Xiang, Wang Xiaofang, Kitani Kris M.\nconference: Arxiv\nyear: 2018\nbibkey: xu2018error\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1808.01942\"}\ntags: ['ARXIV', 'Deep Learning']\n---\nWe propose to use the concept of the Hamming bound to derive the optimal criteria for learning hash codes with a deep network. In particular, when the number of binary hash codes (typically the number of image categories) and code length are known, it is possible to derive an upper bound on the minimum Hamming distance between the hash codes. This upper bound can then be used to define the loss function for learning hash codes. By encouraging the margin (minimum Hamming distance) between the hash codes of different image categories to match the upper bound, we are able to learn theoretically optimal hash codes. Our experiments show that our method significantly outperforms competing deep learning-based approaches and obtains top performance on benchmark datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-6.854292392730713, 15.916959762573242]}, {"key": "", "year": "", "title": "Xu2018gpu", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"GPU Accelerated Cascade Hashing Image Matching for Large Scale 3D Reconstruction\"\nauthors: Xu Tao, Sun Kun, Tao Wenbing\nconference: Arxiv\nyear: 2018\nbibkey: xu2018gpu\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1805.08995\"}\ntags: ['ARXIV', 'Graph']\n---\nImage feature point matching is a key step in Structure from Motion(SFM). However, it is becoming more and more time consuming because the number of images is getting larger and larger. In this paper, we proposed a GPU accelerated image matching method with improved Cascade Hashing. Firstly, we propose a Disk-Memory-GPU data exchange strategy and optimize the load order of data, so that the proposed method can deal with big data. Next, we parallelize the Cascade Hashing method on GPU. An improved parallel reduction and an improved parallel hashing ranking are proposed to fulfill this task. Finally, extensive experiments show that our image matching is about 20 times faster than SiftGPU on the same graphics card, nearly 100 times faster than the CPU CasHash method and hundreds of times faster than the CPU Kd-Tree based matching method. Further more, we introduce the epipolar constraint to the proposed method, and use the epipolar geometry to guide the feature matching procedure, which further reduces the matching cost.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.060735702514648, 4.154788494110107]}, {"key": "", "year": "", "title": "Xu2018sketchmate", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"SketchMate: Deep Hashing for Million-Scale Human Sketch Retrieval\"\nauthors: Xu Peng, Huang Yongye, Yuan Tongtong, Pang Kaiyue, Song Yi-Zhe, Xiang Tao, Hospedales Timothy M., Ma Zhanyu, Guo Jun\nconference: Arxiv\nyear: 2018\nbibkey: xu2018sketchmate\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1804.01401\"}\ntags: ['ARXIV', 'CNN']\n---\nWe propose a deep hashing framework for sketch retrieval that, for the first time, works on a multi-million scale human sketch dataset. Leveraging on this large dataset, we explore a few sketch-specific traits that were otherwise under-studied in prior literature. Instead of following the conventional sketch recognition task, we introduce the novel problem of sketch hashing retrieval which is not only more challenging, but also offers a better testbed for large-scale sketch analysis, since: (i) more fine-grained sketch feature learning is required to accommodate the large variations in style and abstraction, and (ii) a compact binary code needs to be learned at the same time to enable efficient retrieval. Key to our network design is the embedding of unique characteristics of human sketch, where (i) a two-branch CNN-RNN architecture is adapted to explore the temporal ordering of strokes, and (ii) a novel hashing loss is specifically designed to accommodate both the temporal and abstract traits of sketches. By working with a 3.8M sketch dataset, we show that state-of-the-art hashing models specifically engineered for static images fail to perform well on temporal sketch data. Our network on the other hand not only offers the best retrieval performance on various code sizes, but also yields the best generalization performance under a zero-shot setting and when re-purposed for sketch recognition. Such superior performances effectively demonstrate the benefit of our sketch-specific design.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-11.75467300415039, 24.041893005371094]}, {"key": "", "year": "", "title": "Xu2020multi", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Multi-Feature Discrete Collaborative Filtering for Fast Cold-start Recommendation\"\nauthors: Xu Yang, Zhu Lei, Cheng Zhiyong, Li Jingjing, Sun Jiande\nconference: Arxiv\nyear: 2020\nbibkey: xu2020multi\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2003.10719\"}\ntags: ['ARXIV', 'Quantisation', 'TIP']\n---\nHashing is an effective technique to address the large-scale recommendation problem, due to its high computation and storage efficiency on calculating the user preferences on items. However, existing hashing-based recommendation methods still suffer from two important problems: 1) Their recommendation process mainly relies on the user-item interactions and single specific content feature. When the interaction history or the content feature is unavailable (the cold-start problem), their performance will be seriously deteriorated. 2) Existing methods learn the hash codes with relaxed optimization or adopt discrete coordinate descent to directly solve binary hash codes, which results in significant quantization loss or consumes considerable computation time. In this paper, we propose a fast cold-start recommendation method, called Multi-Feature Discrete Collaborative Filtering (MFDCF), to solve these problems. Specifically, a low-rank self-weighted multi-feature fusion module is designed to adaptively project the multiple content features into binary yet informative hash codes by fully exploiting their complementarity. Additionally, we develop a fast discrete optimization algorithm to directly compute the binary hash codes with simple operations. Experiments on two public recommendation datasets demonstrate that MFDCF outperforms the state-of-the-arts on various aspects.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [0.07855517417192459, -4.2380051612854]}, {"key": "", "year": "", "title": "Xu2020on", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"On Learning Semantic Representations for Million-Scale Free-Hand Sketches\"\nauthors: Xu Peng, Huang Yongye, Yuan Tongtong, Xiang Tao, Hospedales Timothy M., Song Yi-Zhe, Wang Liang\nconference: Arxiv\nyear: 2020\nbibkey: xu2020on\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2007.04101\"}\ntags: ['ARXIV', 'CNN']\n---\nIn this paper, we study learning semantic representations for million-scale free-hand sketches. This is highly challenging due to the domain-unique traits of sketches, e.g., diverse, sparse, abstract, noisy. We propose a dual-branch CNNRNN network architecture to represent sketches, which simultaneously encodes both the static and temporal patterns of sketch strokes. Based on this architecture, we further explore learning the sketch-oriented semantic representations in two challenging yet practical settings, i.e., hashing retrieval and zero-shot recognition on million-scale sketches. Specifically, we use our dual-branch architecture as a universal representation framework to design two sketch-specific deep models: (i) We propose a deep hashing model for sketch retrieval, where a novel hashing loss is specifically designed to accommodate both the abstract and messy traits of sketches. (ii) We propose a deep embedding model for sketch zero-shot recognition, via collecting a large-scale edge-map dataset and proposing to extract a set of semantic vectors from edge-maps as the semantic knowledge for sketch zero-shot domain alignment. Both deep models are evaluated by comprehensive experiments on million-scale sketches and outperform the state-of-the-art competitors.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-11.748077392578125, 24.04850196838379]}, {"key": "", "year": "", "title": "Xu2021hhf", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"HHF: Hashing-guided Hinge Function for Deep Hashing Retrieval\"\nauthors: Xu Chengyin, Chai Zenghao, Xu Zhengzhuo, Li Hongjia, Zuo Qiruyi, Yang Lingyu, Yuan Chun\nconference: Arxiv\nyear: 2021\nbibkey: xu2021hhf\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2112.02225\"}   - {name: \"Code\", url: \"https://github.com/JerryXu0129/HHF.\"}\ntags: ['ARXIV', 'Image Retrieval', 'Quantisation']\n---\nDeep hashing has shown promising performance in large-scale image retrieval. However, latent codes extracted by Deep Neural Networks (DNNs) will inevitably lose semantic information during the binarization process, which damages the retrieval accuracy and makes it challenging. Although many existing approaches perform regularization to alleviate quantization errors, we figure out an incompatible conflict between metric learning and quantization learning. The metric loss penalizes the inter-class distances to push different classes unconstrained far away. Worse still, it tends to map the latent code deviate from ideal binarization point and generate severe ambiguity in the binarization process. Based on the minimum distance of the binary linear code, we creatively propose Hashing-guided Hinge Function (HHF) to avoid such conflict. In detail, the carefully-designed inflection point, which relies on the hash bit length and category numbers, is explicitly adopted to balance the metric term and quantization term. Such a modification prevents the network from falling into local metric optimal minima in deep hashing. Extensive experiments in CIFAR-10, CIFAR-100, ImageNet, and MS-COCO show that HHF consistently outperforms existing techniques, and is robust and flexible to transplant into other methods. Code is available at https://github.com/JerryXu0129/HHF.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-5.523457050323486, 1.1247460842132568]}, {"key": "", "year": "", "title": "Xu2022hyp2", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"HyP$^2$ Loss: Beyond Hypersphere Metric Space for Multi-label Image Retrieval\"\nauthors: Xu Chengyin, Chai Zenghao, Xu Zhengzhuo, Yuan Chun, Fan Yanbo, Wang Jue\nconference: Arxiv\nyear: 2022\nbibkey: xu2022hyp2\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2208.06866\"}   - {name: \"Code\", url: \"https://github.com/JerryXu0129/HyP2-Loss.\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nImage retrieval has become an increasingly appealing technique with broad multimedia application prospects, where deep hashing serves as the dominant branch towards low storage and efficient retrieval. In this paper, we carried out in-depth investigations on metric learning in deep hashing for establishing a powerful metric space in multi-label scenarios, where the pair loss suffers high computational overhead and converge difficulty, while the proxy loss is theoretically incapable of expressing the profound label dependencies and exhibits conflicts in the constructed hypersphere space. To address the problems, we propose a novel metric learning framework with Hybrid Proxy-Pair Loss (HyP$^2$ Loss) that constructs an expressive metric space with efficient training complexity w.r.t. the whole dataset. The proposed HyP$^2$ Loss focuses on optimizing the hypersphere space by learnable proxies and excavating data-to-data correlations of irrelevant pairs, which integrates sufficient data correspondence of pair-based methods and high-efficiency of proxy-based methods. Extensive experiments on four standard multi-label benchmarks justify the proposed method outperforms the state-of-the-art, is robust among different hash bits and achieves significant performance gains with a faster, more stable convergence speed. Our code is available at https://github.com/JerryXu0129/HyP2-Loss.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-7.49124002456665, 3.146681070327759]}, {"key": "", "year": "", "title": "Xu2023deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Lifelong Cross-modal Hashing\"\nauthors: Xu Liming, Li Hanqi, Zheng Bochuan, Li Weisheng, Lv Jiancheng\nconference: Arxiv\nyear: 2023\nbibkey: xu2023deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2304.13357\"}\ntags: ['ARXIV', 'Cross Modal', 'Deep Learning', 'ICIP', 'Supervised']\n---\nHashing methods have made significant progress in cross-modal retrieval tasks with fast query speed and low storage cost. Among them, deep learning-based hashing achieves better performance on large-scale data due to its excellent extraction and representation ability for nonlinear heterogeneous features. However, there are still two main challenges in catastrophic forgetting when data with new categories arrive continuously, and time-consuming for non-continuous hashing retrieval to retrain for updating. To this end, we, in this paper, propose a novel deep lifelong cross-modal hashing to achieve lifelong hashing retrieval instead of re-training hash function repeatedly when new data arrive. Specifically, we design lifelong learning strategy to update hash functions by directly training the incremental data instead of retraining new hash functions using all the accumulated data, which significantly reduce training time. Then, we propose lifelong hashing loss to enable original hash codes participate in lifelong learning but remain invariant, and further preserve the similarity and dis-similarity among original and incremental hash codes to maintain performance. Additionally, considering distribution heterogeneity when new data arriving continuously, we introduce multi-label semantic similarity to supervise hash learning, and it has been proven that the similarity improves performance with detailed analysis. Experimental results on benchmark datasets show that the proposed methods achieves comparative performance comparing with recent state-of-the-art cross-modal hashing methods, and it yields substantial average increments over 20\\% in retrieval accuracy and almost reduces over 80\\% training time when new data arrives continuously.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-14.279251098632812, -6.561676979064941]}, {"key": "", "year": "", "title": "Xu2023suvr", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"SUVR: A Search-based Approach to Unsupervised Visual Representation Learning\"\nauthors: Xu Yi-Zhan, Chen Chih-Yao, Li Cheng-Te\nconference: Arxiv\nyear: 2023\nbibkey: xu2023suvr\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2305.14754\"}\ntags: ['ARXIV', 'Graph', 'Supervised', 'Unsupervised']\n---\nUnsupervised learning has grown in popularity because of the difficulty of collecting annotated data and the development of modern frameworks that allow us to learn from unlabeled data. Existing studies, however, either disregard variations at different levels of similarity or only consider negative samples from one batch. We argue that image pairs should have varying degrees of similarity, and the negative samples should be allowed to be drawn from the entire dataset. In this work, we propose Search-based Unsupervised Visual Representation Learning (SUVR) to learn better image representations in an unsupervised manner. We first construct a graph from the image dataset by the similarity between images, and adopt the concept of graph traversal to explore positive samples. In the meantime, we make sure that negative samples can be drawn from the full dataset. Quantitative experiments on five benchmark image classification datasets demonstrate that SUVR can significantly outperform strong competing methods on unsupervised embedding learning. Qualitative experiments also show that SUVR can produce better representations in which similar images are clustered closer together than unrelated images in the latent space.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [10.175061225891113, -30.06998062133789]}, {"key": "", "year": "", "title": "Xuan2018deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Randomized Ensembles for Metric Learning\"\nauthors: Xuan Hong, Souvenir Richard, Pless Robert\nconference: Arxiv\nyear: 2018\nbibkey: xuan2018deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1808.04469\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nLearning embedding functions, which map semantically related inputs to nearby locations in a feature space supports a variety of classification and information retrieval tasks. In this work, we propose a novel, generalizable and fast method to define a family of embedding functions that can be used as an ensemble to give improved results. Each embedding function is learned by randomly bagging the training labels into small subsets. We show experimentally that these embedding ensembles create effective embedding functions. The ensemble output defines a metric space that improves state of the art performance for image retrieval on CUB-200-2011, Cars-196, In-Shop Clothes Retrieval and VehicleID.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [17.775224685668945, 8.357449531555176]}, {"key": "", "year": "", "title": "Xuan2019improved", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Improved Embeddings with Easy Positive Triplet Mining\"\nauthors: Xuan Hong, Stylianou Abby, Pless Robert\nconference: Arxiv\nyear: 2019\nbibkey: xuan2019improved\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1904.04370\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nDeep metric learning seeks to define an embedding where semantically similar images are embedded to nearby locations, and semantically dissimilar images are embedded to distant locations. Substantial work has focused on loss functions and strategies to learn these embeddings by pushing images from the same class as close together in the embedding space as possible. In this paper, we propose an alternative, loosened embedding strategy that requires the embedding function only map each training image to the most similar examples from the same class, an approach we call \"Easy Positive\" mining. We provide a collection of experiments and visualizations that highlight that this Easy Positive mining leads to embeddings that are more flexible and generalize better to new unseen data. This simple mining strategy yields recall performance that exceeds state of the art approaches (including those with complicated loss functions and ensemble methods) on image retrieval datasets including CUB, Stanford Online Products, In-Shop Clothes and Hotels-50K.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [15.491835594177246, 8.860109329223633]}, {"key": "", "year": "", "title": "Xue2022cross", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Cross-Scale Context Extracted Hashing for Fine-Grained Image Binary Encoding\"\nauthors: Xue Xuetong, Shi Jiaying, He Xinxue, Xu Shenghui, Pan Zhaoming\nconference: Arxiv\nyear: 2022\nbibkey: xue2022cross\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2210.07572\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nDeep hashing has been widely applied to large-scale image retrieval tasks owing to efficient computation and low storage cost by encoding high-dimensional image data into binary codes. Since binary codes do not contain as much information as float features, the essence of binary encoding is preserving the main context to guarantee retrieval quality. However, the existing hashing methods have great limitations on suppressing redundant background information and accurately encoding from Euclidean space to Hamming space by a simple sign function. In order to solve these problems, a Cross-Scale Context Extracted Hashing Network (CSCE-Net) is proposed in this paper. Firstly, we design a two-branch framework to capture fine-grained local information while maintaining high-level global semantic information. Besides, Attention guided Information Extraction module (AIE) is introduced between two branches, which suppresses areas of low context information cooperated with global sliding windows. Unlike previous methods, our CSCE-Net learns a content-related Dynamic Sign Function (DSF) to replace the original simple sign function. Therefore, the proposed CSCE-Net is context-sensitive and able to perform well on accurate image binary encoding. We further demonstrate that our CSCE-Net is superior to the existing hashing methods, which improves retrieval performance on standard benchmarks.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [1.4224863052368164, 8.870877265930176]}, {"key": "", "year": "", "title": "Xue2022hashformers", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"HashFormers: Towards Vocabulary-independent Pre-trained Transformers\"\nauthors: Xue Huiyin, Aletras Nikolaos\nconference: Arxiv\nyear: 2022\nbibkey: xue2022hashformers\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2210.07904\"}\ntags: ['ARXIV', 'TIP']\n---\nTransformer-based pre-trained language models are vocabulary-dependent, mapping by default each token to its corresponding embedding. This one-to-one mapping results into embedding matrices that occupy a lot of memory (i.e. millions of parameters) and grow linearly with the size of the vocabulary. Previous work on on-device transformers dynamically generate token embeddings on-the-fly without embedding matrices using locality-sensitive hashing over morphological information. These embeddings are subsequently fed into transformer layers for text classification. However, these methods are not pre-trained. Inspired by this line of work, we propose HashFormers, a new family of vocabulary-independent pre-trained transformers that support an unlimited vocabulary (i.e. all possible tokens in a corpus) given a substantially smaller fixed-sized embedding matrix. We achieve this by first introducing computationally cheap hashing functions that bucket together individual tokens to embeddings. We also propose three variants that do not require an embedding matrix at all, further reducing the memory requirements. We empirically demonstrate that HashFormers are more memory efficient compared to standard pre-trained transformers while achieving comparable predictive performance when fine-tuned on multiple text classification tasks. For example, our most efficient HashFormer variant has a negligible performance degradation (0.4\\% on GLUE) using only 99.1K parameters for representing the embeddings compared to 12.3-38M parameters of state-of-the-art models.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-21.769351959228516, -5.2767767906188965]}, {"key": "", "year": "", "title": "Yadav2023efficient", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Efficient k-NN Search with Cross-Encoders using Adaptive Multi-Round CUR Decomposition\"\nauthors: Yadav Nishant, Monath Nicholas, Zaheer Manzil, McCallum Andrew\nconference: Arxiv\nyear: 2023\nbibkey: yadav2023efficient\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2305.02996\"}\ntags: ['ARXIV', 'Image Retrieval', 'TIP']\n---\nCross-encoder models, which jointly encode and score a query-item pair, are prohibitively expensive for direct k-nearest neighbor (k-NN) search. Consequently, k-NN search typically employs a fast approximate retrieval (e.g. using BM25 or dual-encoder vectors), followed by reranking with a cross-encoder; however, the retrieval approximation often has detrimental recall regret. This problem is tackled by ANNCUR (Yadav et al., 2022), a recent work that employs a cross-encoder only, making search efficient using a relatively small number of anchor items, and a CUR matrix factorization. While ANNCUR's one-time selection of anchors tends to approximate the cross-encoder distances on average, doing so forfeits the capacity to accurately estimate distances to items near the query, leading to regret in the crucial end-task: recall of top-k items. In this paper, we propose ADACUR, a method that adaptively, iteratively, and efficiently minimizes the approximation error for the practically important top-k neighbors. It does so by iteratively performing k-NN search using the anchors available so far, then adding these retrieved nearest neighbors to the anchor set for the next round. Empirically, on multiple datasets, in comparison to previous traditional and state-of-the-art methods such as ANNCUR and dual-encoder-based retrieve-and-rerank, our proposed approach ADACUR consistently reduces recall error-by up to 70% on the important k = 1 setting-while using no more compute than its competitors.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-7.985287189483643, -19.2481689453125]}, {"key": "", "year": "", "title": "Yadav2024adaptive", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Adaptive Retrieval and Scalable Indexing for k-NN Search with Cross-Encoders\"\nauthors: Yadav Nishant, Monath Nicholas, Zaheer Manzil, Fergus Rob, McCallum Andrew\nconference: Arxiv\nyear: 2024\nbibkey: yadav2024adaptive\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2405.03651\"}\ntags: ['ARXIV']\n---\nCross-encoder (CE) models which compute similarity by jointly encoding a query-item pair perform better than embedding-based models (dual-encoders) at estimating query-item relevance. Existing approaches perform k-NN search with CE by approximating the CE similarity with a vector embedding space fit either with dual-encoders (DE) or CUR matrix factorization. DE-based retrieve-and-rerank approaches suffer from poor recall on new domains and the retrieval with DE is decoupled from the CE. While CUR-based approaches can be more accurate than the DE-based approach, they require a prohibitively large number of CE calls to compute item embeddings, thus making it impractical for deployment at scale. In this paper, we address these shortcomings with our proposed sparse-matrix factorization based method that efficiently computes latent query and item embeddings to approximate CE scores and performs k-NN search with the approximate CE similarity. We compute item embeddings offline by factorizing a sparse matrix containing query-item CE scores for a set of train queries. Our method produces a high-quality approximation while requiring only a fraction of CE calls as compared to CUR-based methods, and allows for leveraging DE to initialize the embedding space while avoiding compute- and resource-intensive finetuning of DE via distillation. At test time, the item embeddings remain fixed and retrieval occurs over rounds, alternating between a) estimating the test query embedding by minimizing error in approximating CE scores of items retrieved thus far, and b) using the updated test query embedding for retrieving more items. Our k-NN search method improves recall by up to 5% (k=1) and 54% (k=100) over DE-based approaches. Additionally, our indexing approach achieves a speedup of up to 100x over CUR-based and 5x over DE distillation methods, while matching or improving k-NN search recall over baselines.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [3.474139451980591, -3.569715976715088]}, {"key": "", "year": "", "title": "Yamada2021efficient", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Efficient Passage Retrieval with Hashing for Open-domain Question Answering\"\nauthors: Yamada Ikuya, Asai Akari, Hajishirzi Hannaneh\nconference: Arxiv\nyear: 2021\nbibkey: yamada2021efficient\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2106.00882\"}   - {name: \"Code\", url: \"https://github.com/studio-ousia/bpr.\"}\ntags: ['ARXIV']\n---\nMost state-of-the-art open-domain question answering systems use a neural retrieval model to encode passages into continuous vectors and extract them from a knowledge source. However, such retrieval models often require large memory to run because of the massive size of their passage index. In this paper, we introduce Binary Passage Retriever (BPR), a memory-efficient neural retrieval model that integrates a learning-to-hash technique into the state-of-the-art Dense Passage Retriever (DPR) to represent the passage index using compact binary codes rather than continuous vectors. BPR is trained with a multi-task objective over two tasks: efficient candidate generation based on binary codes and accurate reranking based on continuous vectors. Compared with DPR, BPR substantially reduces the memory cost from 65GB to 2GB without a loss of accuracy on two standard open-domain question answering benchmarks: Natural Questions and TriviaQA. Our code and trained models are available at https://github.com/studio-ousia/bpr.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.03075885772705, -3.3997883796691895]}, {"key": "", "year": "", "title": "Yamamoto2022compressive", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Compressive Self-localization Using Relative Attribute Embedding\"\nauthors: Yamamoto Ryogo, Tanaka Kanji\nconference: Arxiv\nyear: 2022\nbibkey: yamamoto2022compressive\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2208.08863\"}\ntags: ['ARXIV']\n---\nThe use of relative attribute (e.g., beautiful, safe, convenient) -based image embeddings in visual place recognition, as a domain-adaptive compact image descriptor that is orthogonal to the typical approach of absolute attribute (e.g., color, shape, texture) -based image embeddings, is explored in this paper.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [26.221891403198242, 7.529176235198975]}, {"key": "", "year": "", "title": "Yan2018norm", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Norm-Range Partition: A Universal Catalyst for LSH based Maximum Inner Product Search (MIPS)\"\nauthors: Yan Xiao, Dai Xinyan, Liu Jie, Zhou Kaiwen, Cheng James\nconference: Arxiv\nyear: 2018\nbibkey: yan2018norm\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1810.09104\"}\ntags: ['ARXIV', 'LSH']\n---\nRecently, locality sensitive hashing (LSH) was shown to be effective for MIPS and several algorithms including $L_2$-ALSH, Sign-ALSH and Simple-LSH have been proposed. In this paper, we introduce the norm-range partition technique, which partitions the original dataset into sub-datasets containing items with similar 2-norms and builds hash index independently for each sub-dataset. We prove that norm-range partition reduces the query processing complexity for all existing LSH based MIPS algorithms under mild conditions. The key to performance improvement is that norm-range partition allows to use smaller normalization factor most sub-datasets. For efficient query processing, we also formulate a unified framework to rank the buckets from the hash indexes of different sub-datasets. Experiments on real datasets show that norm-range partition significantly reduces the number of probed for LSH based MIPS algorithms when achieving the same recall.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [2.308274745941162, -7.512088298797607]}, {"key": "", "year": "", "title": "Yan2020deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Multi-View Enhancement Hashing for Image Retrieval\"\nauthors: Yan Chenggang, Gong Biao, Wei Yuxuan, Gao Yue\nconference: Arxiv\nyear: 2020\nbibkey: yan2020deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2002.00169\"}\ntags: ['ARXIV', 'Deep Learning', 'ICIP', 'Image Retrieval', 'Supervised']\n---\nHashing is an efficient method for nearest neighbor search in large-scale data space by embedding high-dimensional feature descriptors into a similarity preserving Hamming space with a low dimension. However, large-scale high-speed retrieval through binary code has a certain degree of reduction in retrieval accuracy compared to traditional retrieval methods. We have noticed that multi-view methods can well preserve the diverse characteristics of data. Therefore, we try to introduce the multi-view deep neural network into the hash learning field, and design an efficient and innovative retrieval model, which has achieved a significant improvement in retrieval performance. In this paper, we propose a supervised multi-view hash model which can enhance the multi-view information through neural networks. This is a completely new hash learning method that combines multi-view and deep learning methods. The proposed method utilizes an effective view stability evaluation method to actively explore the relationship among views, which will affect the optimization direction of the entire network. We have also designed a variety of multi-data fusion methods in the Hamming space to preserve the advantages of both convolution and multi-view. In order to avoid excessive computing resources on the enhancement procedure during retrieval, we set up a separate structure called memory network which participates in training together. The proposed method is systematically evaluated on the CIFAR-10, NUS-WIDE and MS-COCO datasets, and the results show that our method significantly outperforms the state-of-the-art single-view and multi-view hashing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-8.422670364379883, 8.348454475402832]}, {"key": "", "year": "", "title": "Yan2020image", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Image Retrieval for Structure-from-Motion via Graph Convolutional Network\"\nauthors: Yan Shen, Pen Yang, Lai Shiming, Liu Yu, Zhang Maojun\nconference: Arxiv\nyear: 2020\nbibkey: yan2020image\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2009.08049\"}\ntags: ['ARXIV', 'Graph', 'Image Retrieval']\n---\nConventional image retrieval techniques for Structure-from-Motion (SfM) suffer from the limit of effectively recognizing repetitive patterns and cannot guarantee to create just enough match pairs with high precision and high recall. In this paper, we present a novel retrieval method based on Graph Convolutional Network (GCN) to generate accurate pairwise matches without costly redundancy. We formulate image retrieval task as a node binary classification problem in graph data: a node is marked as positive if it shares the scene overlaps with the query image. The key idea is that we find that the local context in feature space around a query image contains rich information about the matchable relation between this image and its neighbors. By constructing a subgraph surrounding the query image as input data, we adopt a learnable GCN to exploit whether nodes in the subgraph have overlapping regions with the query photograph. Experiments demonstrate that our method performs remarkably well on the challenging dataset of highly ambiguous and duplicated scenes. Besides, compared with state-of-the-art matchable retrieval methods, the proposed approach significantly reduces useless attempted matches without sacrificing the accuracy and completeness of reconstruction.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.07330322265625, -29.473264694213867]}, {"key": "", "year": "", "title": "Yan2021binary", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Binary Code based Hash Embedding for Web-scale Applications\"\nauthors: Yan Bencheng, Wang Pengjie, Liu Jinquan, Lin Wei, Lee Kuang-Chih, Xu Jian, Zheng Bo\nconference: Arxiv\nyear: 2021\nbibkey: yan2021binary\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2109.02471\"}\ntags: ['ARXIV', 'Deep Learning']\n---\nNowadays, deep learning models are widely adopted in web-scale applications such as recommender systems, and online advertising. In these applications, embedding learning of categorical features is crucial to the success of deep learning models. In these models, a standard method is that each categorical feature value is assigned a unique embedding vector which can be learned and optimized. Although this method can well capture the characteristics of the categorical features and promise good performance, it can incur a huge memory cost to store the embedding table, especially for those web-scale applications. Such a huge memory cost significantly holds back the effectiveness and usability of EDRMs. In this paper, we propose a binary code based hash embedding method which allows the size of the embedding table to be reduced in arbitrary scale without compromising too much performance. Experimental evaluation results show that one can still achieve 99\\% performance even if the embedding table size is reduced 1000$\\times$ smaller than the original one with our proposed method.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-17.180274963378906, 6.105036735534668]}, {"key": "", "year": "", "title": "Yang2015supervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Supervised Learning of Semantics-Preserving Hash via Deep Convolutional Neural Networks\"\nauthors: Yang Huei-Fang, Lin Kevin, Chen Chu-Song\nconference: Arxiv\nyear: 2015\nbibkey: yang2015supervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1507.00101\"}\ntags: ['ARXIV', 'Supervised', 'Unsupervised']\n---\nThis paper presents a simple yet effective supervised deep hash approach that constructs binary hash codes from labeled data for large-scale image search. We assume that the semantic labels are governed by several latent attributes with each attribute on or off, and classification relies on these attributes. Based on this assumption, our approach, dubbed supervised semantics-preserving deep hashing (SSDH), constructs hash functions as a latent layer in a deep network and the binary codes are learned by minimizing an objective function defined over classification error and other desirable hash codes properties. With this design, SSDH has a nice characteristic that classification and retrieval are unified in a single learning model. Moreover, SSDH performs joint learning of image representations, hash codes, and classification in a point-wised manner, and thus is scalable to large-scale datasets. SSDH is simple and can be realized by a slight enhancement of an existing deep architecture for classification; yet it is effective and outperforms other hashing approaches on several benchmarks and large datasets. Compared with state-of-the-art approaches, SSDH achieves higher retrieval accuracy, while the classification performance is not sacrificed.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-6.371525287628174, 11.295709609985352]}, {"key": "", "year": "", "title": "Yang2016zero", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Zero-Shot Hashing via Transferring Supervised Knowledge\"\nauthors: Yang Yang, Chen Weilun, Luo Yadan, Shen Fumin, Shao Jie, Shen Heng Tao\nconference: Arxiv\nyear: 2016\nbibkey: yang2016zero\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1606.05032\"}\ntags: ['ARXIV', 'Image Retrieval', 'Supervised', 'Unsupervised']\n---\nHashing has shown its efficiency and effectiveness in facilitating large-scale multimedia applications. Supervised knowledge e.g. semantic labels or pair-wise relationship) associated to data is capable of significantly improving the quality of hash codes and hash functions. However, confronted with the rapid growth of newly-emerging concepts and multimedia data on the Web, existing supervised hashing approaches may easily suffer from the scarcity and validity of supervised information due to the expensive cost of manual labelling. In this paper, we propose a novel hashing scheme, termed \\emph{zero-shot hashing} (ZSH), which compresses images of \"unseen\" categories to binary codes with hash functions learned from limited training data of \"seen\" categories. Specifically, we project independent data labels i.e. 0/1-form label vectors) into semantic embedding space, where semantic relationships among all the labels can be precisely characterized and thus seen supervised knowledge can be transferred to unseen classes. Moreover, in order to cope with the semantic shift problem, we rotate the embedded space to more suitably align the embedded semantics with the low-level visual feature space, thereby alleviating the influence of semantic gap. In the meantime, to exert positive effects on learning high-quality hash functions, we further propose to preserve local structural property and discrete nature in binary codes. Besides, we develop an efficient alternating algorithm to solve the ZSH model. Extensive experiments conducted on various real-life datasets show the superior zero-shot image retrieval performance of ZSH as compared to several state-of-the-art hashing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-12.224943161010742, -0.5235410928726196]}, {"key": "", "year": "", "title": "Yang2018deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Attention-guided Hashing\"\nauthors: Yang Zhan, Raymond Osolo Ian, Sun Wuqing, Long Jun\nconference: Arxiv\nyear: 2018\nbibkey: yang2018deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1812.01404\"}\ntags: ['ARXIV', 'Deep Learning', 'Supervised']\n---\nWith the rapid growth of multimedia data (e.g., image, audio and video etc.) on the web, learning-based hashing techniques such as Deep Supervised Hashing (DSH) have proven to be very efficient for large-scale multimedia search. The recent successes seen in Learning-based hashing methods are largely due to the success of deep learning-based hashing methods. However, there are some limitations to previous learning-based hashing methods (e.g., the learned hash codes containing repetitive and highly correlated information). In this paper, we propose a novel learning-based hashing method, named Deep Attention-guided Hashing (DAgH). DAgH is implemented using two stream frameworks. The core idea is to use guided hash codes which are generated by the hashing network of the first stream framework (called first hashing network) to guide the training of the hashing network of the second stream framework (called second hashing network). Specifically, in the first network, it leverages an attention network and hashing network to generate the attention-guided hash codes from the original images. The loss function we propose contains two components: the semantic loss and the attention loss. The attention loss is used to punish the attention network to obtain the salient region from pairs of images; in the second network, these attention-guided hash codes are used to guide the training of the second hashing network (i.e., these codes are treated as supervised labels to train the second network). By doing this, DAgH can make full use of the most critical information contained in images to guide the second hashing network in order to learn efficient hash codes in a true end-to-end fashion. Results from our experiments demonstrate that DAgH can generate high quality hash codes and it outperforms current state-of-the-art methods on three benchmark datasets, CIFAR-10, NUS-WIDE, and ImageNet.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-14.3001708984375, 9.593606948852539]}, {"key": "", "year": "", "title": "Yang2018efficient", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Efficient Image Retrieval via Decoupling Diffusion into Online and Offline Processing\"\nauthors: Yang Fan, Hinami Ryota, Matsui Yusuke, Ly Steven, Satoh Shin'ichi\nconference: Arxiv\nyear: 2018\nbibkey: yang2018efficient\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1811.10907\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nDiffusion is commonly used as a ranking or re-ranking method in retrieval tasks to achieve higher retrieval performance, and has attracted lots of attention in recent years. A downside to diffusion is that it performs slowly in comparison to the naive k-NN search, which causes a non-trivial online computational cost on large datasets. To overcome this weakness, we propose a novel diffusion technique in this paper. In our work, instead of applying diffusion to the query, we pre-compute the diffusion results of each element in the database, making the online search a simple linear combination on top of the k-NN search process. Our proposed method becomes 10~ times faster in terms of online search speed. Moreover, we propose to use late truncation instead of early truncation in previous works to achieve better retrieval performance.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [14.855875015258789, 12.76237964630127]}, {"key": "", "year": "", "title": "Yang20192", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"2-bit Model Compression of Deep Convolutional Neural Network on ASIC Engine for Image Retrieval\"\nauthors: Yang Bin, Yang Lin, Li Xiaochun, Zhang Wenhan, Zhou Hua, Zhang Yequn, Ren Yongxiong, Shi Yinbo\nconference: Arxiv\nyear: 2019\nbibkey: yang20192\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1905.03362\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval', 'Quantisation']\n---\nImage retrieval utilizes image descriptors to retrieve the most similar images to a given query image. Convolutional neural network (CNN) is becoming the dominant approach to extract image descriptors for image retrieval. For low-power hardware implementation of image retrieval, the drawback of CNN-based feature descriptor is that it requires hundreds of megabytes of storage. To address this problem, this paper applies deep model quantization and compression to CNN in ASIC chip for image retrieval. It is demonstrated that the CNN-based features descriptor can be extracted using as few as 2-bit weights quantization to deliver a similar performance as floating-point model for image retrieval. In addition, to implement CNN in ASIC, especially for large scale images, the limited buffer size of chips should be considered. To retrieve large scale images, we propose an improved pooling strategy, region nested invariance pooling (RNIP), which uses cropped sub-images for CNN. Testing results on chip show that integrating RNIP with the proposed 2-bit CNN model compression approach is capable of retrieving large scale images.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [10.926827430725098, 29.063743591308594]}, {"key": "", "year": "", "title": "Yang2019asymmetric", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Asymmetric Deep Semantic Quantization for Image Retrieval\"\nauthors: Yang Zhan, Raymond Osolo Ian, Sun WuQing, Long Jun\nconference: Arxiv\nyear: 2019\nbibkey: yang2019asymmetric\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1903.12493\"}\ntags: ['ARXIV', 'Deep Learning', 'Image Retrieval', 'Quantisation']\n---\nDue to its fast retrieval and storage efficiency capabilities, hashing has been widely used in nearest neighbor retrieval tasks. By using deep learning based techniques, hashing can outperform non-learning based hashing technique in many applications. However, we argue that the current deep learning based hashing methods ignore some critical problems (e.g., the learned hash codes are not discriminative due to the hashing methods being unable to discover rich semantic information and the training strategy having difficulty optimizing the discrete binary codes). In this paper, we propose a novel image hashing method, termed as \\textbf{\\underline{A}}symmetric \\textbf{\\underline{D}}eep \\textbf{\\underline{S}}emantic \\textbf{\\underline{Q}}uantization (\\textbf{ADSQ}). \\textbf{ADSQ} is implemented using three stream frameworks, which consist of one \\emph{LabelNet} and two \\emph{ImgNets}. The \\emph{LabelNet} leverages the power of three fully-connected layers, which are used to capture rich semantic information between image pairs. For the two \\emph{ImgNets}, they each adopt the same convolutional neural network structure, but with different weights (i.e., asymmetric convolutional neural networks). The two \\emph{ImgNets} are used to generate discriminative compact hash codes. Specifically, the function of the \\emph{LabelNet} is to capture rich semantic information that is used to guide the two \\emph{ImgNets} in minimizing the gap between the real-continuous features and the discrete binary codes. Furthermore, \\textbf{ADSQ} can utilize the most critical semantic information to guide the feature learning process and consider the consistency of the common semantic space and Hamming space. Experimental results on three benchmarks (i.e., CIFAR-10, NUS-WIDE, and ImageNet) demonstrate that the proposed \\textbf{ADSQ} can outperforms current state-of-the-art methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-3.802157402038574, 8.291242599487305]}, {"key": "", "year": "", "title": "Yang2019distillhash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"DistillHash: Unsupervised Deep Hashing by Distilling Data Pairs\"\nauthors: Yang Erkun, Liu Tongliang, Deng Cheng, Liu Wei, Tao Dacheng\nconference: Arxiv\nyear: 2019\nbibkey: yang2019distillhash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1905.03465\"}\ntags: ['ARXIV', 'Supervised', 'TOM', 'Unsupervised']\n---\nDue to the high storage and search efficiency, hashing has become prevalent for large-scale similarity search. Particularly, deep hashing methods have greatly improved the search performance under supervised scenarios. In contrast, unsupervised deep hashing models can hardly achieve satisfactory performance due to the lack of reliable supervisory similarity signals. To address this issue, we propose a novel deep unsupervised hashing model, dubbed DistillHash, which can learn a distilled data set consisted of data pairs, which have confidence similarity signals. Specifically, we investigate the relationship between the initial noisy similarity signals learned from local structures and the semantic similarity labels assigned by a Bayes optimal classifier. We show that under a mild assumption, some data pairs, of which labels are consistent with those assigned by the Bayes optimal classifier, can be potentially distilled. Inspired by this fact, we design a simple yet effective strategy to distill data pairs automatically and further adopt a Bayesian learning framework to learn hash functions from the distilled data set. Extensive experimental results on three widely used benchmark datasets show that the proposed DistillHash consistently accomplishes the state-of-the-art search performance.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-8.060802459716797, -2.8437118530273438]}, {"key": "", "year": "", "title": "Yang2019feature", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Feature Pyramid Hashing\"\nauthors: Yang Yifan, Geng Libing, Lai Hanjiang, Pan Yan, Yin Jian\nconference: Arxiv\nyear: 2019\nbibkey: yang2019feature\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1904.02325\"}\ntags: ['ARXIV', 'Image Retrieval', 'TIP']\n---\nIn recent years, deep-networks-based hashing has become a leading approach for large-scale image retrieval. Most deep hashing approaches use the high layer to extract the powerful semantic representations. However, these methods have limited ability for fine-grained image retrieval because the semantic features extracted from the high layer are difficult in capturing the subtle differences. To this end, we propose a novel two-pyramid hashing architecture to learn both the semantic information and the subtle appearance details for fine-grained image search. Inspired by the feature pyramids of convolutional neural network, a vertical pyramid is proposed to capture the high-layer features and a horizontal pyramid combines multiple low-layer features with structural information to capture the subtle differences. To fuse the low-level features, a novel combination strategy, called consensus fusion, is proposed to capture all subtle information from several low-layers for finer retrieval. Extensive evaluation on two fine-grained datasets CUB-200-2011 and Stanford Dogs demonstrate that the proposed method achieves significant performance compared with the state-of-art baselines.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-1.7485419511795044, 14.533926010131836]}, {"key": "", "year": "", "title": "Yang2019shared", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Shared Predictive Cross-Modal Deep Quantization\"\nauthors: Yang Erkun, Deng Cheng, Li Chao, Liu Wei, Li Jie, Tao Dacheng\nconference: Arxiv\nyear: 2019\nbibkey: yang2019shared\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1904.07488\"}\ntags: ['ARXIV', 'Cross Modal', 'Quantisation', 'Supervised']\n---\nWith explosive growth of data volume and ever-increasing diversity of data modalities, cross-modal similarity search, which conducts nearest neighbor search across different modalities, has been attracting increasing interest. This paper presents a deep compact code learning solution for efficient cross-modal similarity search. Many recent studies have proven that quantization-based approaches perform generally better than hashing-based approaches on single-modal similarity search. In this paper, we propose a deep quantization approach, which is among the early attempts of leveraging deep neural networks into quantization-based cross-modal similarity search. Our approach, dubbed shared predictive deep quantization (SPDQ), explicitly formulates a shared subspace across different modalities and two private subspaces for individual modalities, and representations in the shared subspace and the private subspaces are learned simultaneously by embedding them to a reproducing kernel Hilbert space, where the mean embedding of different modality distributions can be explicitly compared. In addition, in the shared subspace, a quantizer is learned to produce the semantics preserving compact codes with the help of label alignment. Thanks to this novel network architecture in cooperation with supervised quantization training, SPDQ can preserve intramodal and intermodal similarities as much as possible and greatly reduce quantization error. Experiments on two popular benchmarks corroborate that our approach outperforms state-of-the-art methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-13.468338966369629, 7.197784423828125]}, {"key": "", "year": "", "title": "Yang2020camera", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Camera-Based Piano Sheet Music Identification\"\nauthors: Yang Daniel, Tsai TJ\nconference: Arxiv\nyear: 2020\nbibkey: yang2020camera\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2007.14579\"}\ntags: ['ARXIV']\n---\nThis paper presents a method for large-scale retrieval of piano sheet music images. Our work differs from previous studies on sheet music retrieval in two ways. First, we investigate the problem at a much larger scale than previous studies, using all solo piano sheet music images in the entire IMSLP dataset as a searchable database. Second, we use cell phone images of sheet music as our input queries, which lends itself to a practical, user-facing application. We show that a previously proposed fingerprinting method for sheet music retrieval is far too slow for a real-time application, and we diagnose its shortcomings. We propose a novel hashing scheme called dynamic n-gram fingerprinting that significantly reduces runtime while simultaneously boosting retrieval accuracy. In experiments on IMSLP data, our proposed method achieves a mean reciprocal rank of 0.85 and an average runtime of 0.98 seconds per query.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [31.846681594848633, -8.213772773742676]}, {"key": "", "year": "", "title": "Yang2021dolg", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"DOLG: Single-Stage Image Retrieval with Deep Orthogonal Fusion of Local and Global Features\"\nauthors: Yang Min, He Dongliang, Fan Miao, Shi Baorong, Xue Xuetong, Li Fu, Ding Errui, Huang Jizhou\nconference: Arxiv\nyear: 2021\nbibkey: yang2021dolg\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2108.02927\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nImage Retrieval is a fundamental task of obtaining images similar to the query one from a database. A common image retrieval practice is to firstly retrieve candidate images via similarity search using global image features and then re-rank the candidates by leveraging their local features. Previous learning-based studies mainly focus on either global or local image representation learning to tackle the retrieval task. In this paper, we abandon the two-stage paradigm and seek to design an effective single-stage solution by integrating local and global information inside images into compact image representations. Specifically, we propose a Deep Orthogonal Local and Global (DOLG) information fusion framework for end-to-end image retrieval. It attentively extracts representative local information with multi-atrous convolutions and self-attention at first. Components orthogonal to the global image representation are then extracted from the local information. At last, the orthogonal components are concatenated with the global representation as a complementary, and then aggregation is performed to generate the final representation. The whole framework is end-to-end differentiable and can be trained with image-level labels. Extensive experimental results validate the effectiveness of our solution and show that our model achieves state-of-the-art image retrieval performances on Revisited Oxford and Paris datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [16.437896728515625, 15.098286628723145]}, {"key": "", "year": "", "title": "Yang2022fedhap", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"FedHAP: Federated Hashing with Global Prototypes for Cross-silo Retrieval\"\nauthors: Yang Meilin, Xu Jian, Liu Yang, Ding Wenbo\nconference: Arxiv\nyear: 2022\nbibkey: yang2022fedhap\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2207.05525\"}\ntags: ['ARXIV', 'ICIP']\n---\nDeep hashing has been widely applied in large-scale data retrieval due to its superior retrieval efficiency and low storage cost. However, data are often scattered in data silos with privacy concerns, so performing centralized data storage and retrieval is not always possible. Leveraging the concept of federated learning (FL) to perform deep hashing is a recent research trend. However, existing frameworks mostly rely on the aggregation of the local deep hashing models, which are trained by performing similarity learning with local skewed data only. Therefore, they cannot work well for non-IID clients in a real federated environment. To overcome these challenges, we propose a novel federated hashing framework that enables participating clients to jointly train the shared deep hashing model by leveraging the prototypical hash codes for each class. Globally, the transmission of global prototypes with only one prototypical hash code per class will minimize the impact of communication cost and privacy risk. Locally, the use of global prototypes are maximized by jointly training a discriminator network and the local hashing network. Extensive experiments on benchmark datasets are conducted to demonstrate that our method can significantly improve the performance of the deep hashing model in the federated environments with non-IID data distributions.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-14.202383041381836, -3.2361719608306885]}, {"key": "", "year": "", "title": "Yang2024trisampler", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"TriSampler: A Better Negative Sampling Principle for Dense Retrieval\"\nauthors: Yang Zhen, Shao Zhou, Dong Yuxiao, Tang Jie\nconference: Arxiv\nyear: 2024\nbibkey: yang2024trisampler\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2402.11855\"}\ntags: ['ARXIV']\n---\nNegative sampling stands as a pivotal technique in dense retrieval, essential for training effective retrieval models and significantly impacting retrieval performance. While existing negative sampling methods have made commendable progress by leveraging hard negatives, a comprehensive guiding principle for constructing negative candidates and designing negative sampling distributions is still lacking. To bridge this gap, we embark on a theoretical analysis of negative sampling in dense retrieval. This exploration culminates in the unveiling of the quasi-triangular principle, a novel framework that elucidates the triangular-like interplay between query, positive document, and negative document. Fueled by this guiding principle, we introduce TriSampler, a straightforward yet highly effective negative sampling method. The keypoint of TriSampler lies in its ability to selectively sample more informative negatives within a prescribed constrained region. Experimental evaluation show that TriSampler consistently attains superior retrieval performance across a diverse of representative retrieval models.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.105360984802246, 18.003620147705078]}, {"key": "", "year": "", "title": "Yao2017one", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"One-Shot Fine-Grained Instance Retrieval\"\nauthors: Yao Hantao, Zhang Shiliang, Zhang Yongdong, Li Jintao, Tian Qi\nconference: Arxiv\nyear: 2017\nbibkey: yao2017one\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1707.00811\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nFine-Grained Visual Categorization (FGVC) has achieved significant progress recently. However, the number of fine-grained species could be huge and dynamically increasing in real scenarios, making it difficult to recognize unseen objects under the current FGVC framework. This raises an open issue to perform large-scale fine-grained identification without a complete training set. Aiming to conquer this issue, we propose a retrieval task named One-Shot Fine-Grained Instance Retrieval (OSFGIR). \"One-Shot\" denotes the ability of identifying unseen objects through a fine-grained retrieval task assisted with an incomplete auxiliary training set. This paper first presents the detailed description to OSFGIR task and our collected OSFGIR-378K dataset. Next, we propose the Convolutional and Normalization Networks (CN-Nets) learned on the auxiliary dataset to generate a concise and discriminative representation. Finally, we present a coarse-to-fine retrieval framework consisting of three components, i.e., coarse retrieval, fine-grained retrieval, and query expansion, respectively. The framework progressively retrieves images with similar semantics, and performs fine-grained identification. Experiments show our OSFGIR framework achieves significantly better accuracy and efficiency than existing FGVC and image retrieval methods, thus could be a better solution for large-scale fine-grained object identification.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.552678108215332, 13.637674331665039]}, {"key": "", "year": "", "title": "Yao2019efficient", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Efficient Discrete Supervised Hashing for Large-scale Cross-modal Retrieval\"\nauthors: Yao Tao, Kong Xiangwei, Yan Lianshan, Tang Wenjing, Tian Qi\nconference: Arxiv\nyear: 2019\nbibkey: yao2019efficient\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1905.01304\"}\ntags: ['ARXIV', 'Cross Modal', 'Quantisation', 'Supervised', 'Unsupervised']\n---\nSupervised cross-modal hashing has gained increasing research interest on large-scale retrieval task owning to its satisfactory performance and efficiency. However, it still has some challenging issues to be further studied: 1) most of them fail to well preserve the semantic correlations in hash codes because of the large heterogenous gap; 2) most of them relax the discrete constraint on hash codes, leading to large quantization error and consequent low performance; 3) most of them suffer from relatively high memory cost and computational complexity during training procedure, which makes them unscalable. In this paper, to address above issues, we propose a supervised cross-modal hashing method based on matrix factorization dubbed Efficient Discrete Supervised Hashing (EDSH). Specifically, collective matrix factorization on heterogenous features and semantic embedding with class labels are seamlessly integrated to learn hash codes. Therefore, the feature based similarities and semantic correlations can be both preserved in hash codes, which makes the learned hash codes more discriminative. Then an efficient discrete optimal algorithm is proposed to handle the scalable issue. Instead of learning hash codes bit-by-bit, hash codes matrix can be obtained directly which is more efficient. Extensive experimental results on three public real-world datasets demonstrate that EDSH produces a superior performance in both accuracy and scalability over some existing cross-modal hashing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-12.08221435546875, -2.816103219985962]}, {"key": "", "year": "", "title": "Yasunaga2021improved", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Improved Bounds for Codes Correcting Insertions and Deletions\"\nauthors: Yasunaga Kenji\nconference: Arxiv\nyear: 2021\nbibkey: yasunaga2021improved\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2107.01785\"}\ntags: ['ARXIV']\n---\nThis paper studies the cardinality of codes correcting insertions and deletions. We give improved upper and lower bounds on code size. Our upper bound is obtained by utilizing the asymmetric property of list decoding for insertions and deletions and can be seen as analogous to the Elias bound in the Hamming metric. Our non-asymptotic bound is better than the existing bounds when the minimum Levenshtein distance is relatively large. The asymptotic bound exceeds the Elias and the MRRW bounds adapted from the Hamming-metric bounds for the binary and the quaternary cases. Our lower bound improves on the bound by Levenshtein, but its effect is limited and vanishes asymptotically.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [10.426238059997559, -6.104382514953613]}, {"key": "", "year": "", "title": "Ye2015first", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"First-Take-All: Temporal Order-Preserving Hashing for 3D Action Videos\"\nauthors: Ye Jun, Hu Hao, Li Kai, Qi Guo-Jun, Hua Kien A.\nconference: Arxiv\nyear: 2015\nbibkey: ye2015first\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1506.02184\"}\ntags: ['ARXIV']\n---\nWith the prevalence of the commodity depth cameras, the new paradigm of user interfaces based on 3D motion capturing and recognition have dramatically changed the way of interactions between human and computers. Human action recognition, as one of the key components in these devices, plays an important role to guarantee the quality of user experience. Although the model-driven methods have achieved huge success, they cannot provide a scalable solution for efficiently storing, retrieving and recognizing actions in the large-scale applications. These models are also vulnerable to the temporal translation and warping, as well as the variations in motion scales and execution rates. To address these challenges, we propose to treat the 3D human action recognition as a video-level hashing problem and propose a novel First-Take-All (FTA) Hashing algorithm capable of hashing the entire video into hash codes of fixed length. We demonstrate that this FTA algorithm produces a compact representation of the video invariant to the above mentioned variations, through which action recognition can be solved by an efficient nearest neighbor search by the Hamming distance between the FTA hash codes. Experiments on the public 3D human action datasets shows that the FTA algorithm can reach a recognition accuracy higher than 80%, with about 15 bits per frame considering there are 65 frames per video over the datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-2.3165123462677, 29.59539031982422]}, {"key": "", "year": "", "title": "Yeo2023cuckoo", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Cuckoo Hashing in Cryptography: Optimal Parameters, Robustness and Applications\"\nauthors: Yeo Kevin\nconference: Arxiv\nyear: 2023\nbibkey: yeo2023cuckoo\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2306.11220\"}\ntags: ['ARXIV', 'Graph']\n---\nCuckoo hashing is a powerful primitive that enables storing items using small space with efficient querying. At a high level, cuckoo hashing maps $n$ items into $b$ entries storing at most $\\ell$ items such that each item is placed into one of $k$ randomly chosen entries. Additionally, there is an overflow stash that can store at most $s$ items. Many cryptographic primitives rely upon cuckoo hashing to privately embed and query data where it is integral to ensure small failure probability when constructing cuckoo hashing tables as it directly relates to the privacy guarantees. As our main result, we present a more query-efficient cuckoo hashing construction using more hash functions. For construction failure probability $\\epsilon$, the query overhead of our scheme is $O(1 + \\sqrt\\{\\log(1/\\epsilon)/\\log n\\})$. Our scheme has quadratically smaller query overhead than prior works for any target failure probability $\\epsilon$. We also prove lower bounds matching our construction. Our improvements come from a new understanding of the locality of cuckoo hashing failures for small sets of items. We also initiate the study of robust cuckoo hashing where the input set may be chosen with knowledge of the hash functions. We present a cuckoo hashing scheme using more hash functions with query overhead $\\tilde\\{O\\}(\\log \\lambda)$ that is robust against poly$(\\lambda)$ adversaries. Furthermore, we present lower bounds showing that this construction is tight and that extending previous approaches of large stashes or entries cannot obtain robustness except with $\\Omega(n)$ query overhead. As applications of our results, we obtain improved constructions for batch codes and PIR. In particular, we present the most efficient explicit batch code and blackbox reduction from single-query PIR to batch PIR.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-18.8708438873291, -18.651491165161133]}, {"key": "", "year": "", "title": "Yesiler2020less", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Less is more: Faster and better music version identification with embedding distillation\"\nauthors: Yesiler Furkan, Serr\u00e0 Joan, G\u00f3mez Emilia\nconference: Arxiv\nyear: 2020\nbibkey: yesiler2020less\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2010.03284\"}\ntags: ['ARXIV']\n---\nVersion identification systems aim to detect different renditions of the same underlying musical composition (loosely called cover songs). By learning to encode entire recordings into plain vector embeddings, recent systems have made significant progress in bridging the gap between accuracy and scalability, which has been a key challenge for nearly two decades. In this work, we propose to further narrow this gap by employing a set of data distillation techniques that reduce the embedding dimensionality of a pre-trained state-of-the-art model. We compare a wide range of techniques and propose new ones, from classical dimensionality reduction to more sophisticated distillation schemes. With those, we obtain 99% smaller embeddings that, moreover, yield up to a 3% accuracy increase. Such small embeddings can have an important impact in retrieval time, up to the point of making a real-world system practical on a standalone laptop.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [31.404691696166992, -7.316640377044678]}, {"key": "", "year": "", "title": "Yokoo2020two", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Two-stage Discriminative Re-ranking for Large-scale Landmark Retrieval\"\nauthors: Yokoo Shuhei, Ozaki Kohei, Simo-Serra Edgar, Iizuka Satoshi\nconference: Arxiv\nyear: 2020\nbibkey: yokoo2020two\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2003.11211\"}   - {name: \"Code\", url: \"https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution}\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nWe propose an efficient pipeline for large-scale landmark image retrieval that addresses the diversity of the dataset through two-stage discriminative re-ranking. Our approach is based on embedding the images in a feature-space using a convolutional neural network trained with a cosine softmax loss. Due to the variance of the images, which include extreme viewpoint changes such as having to retrieve images of the exterior of a landmark from images of the interior, this is very challenging for approaches based exclusively on visual similarity. Our proposed re-ranking approach improves the results in two steps: in the sort-step, $k$-nearest neighbor search with soft-voting to sort the retrieved results based on their label similarity to the query images, and in the insert-step, we add additional samples from the dataset that were not retrieved by image-similarity. This approach allows overcoming the low visual diversity in retrieved images. In-depth experimental results show that the proposed approach significantly outperforms existing approaches on the challenging Google Landmarks Datasets. Using our methods, we achieved 1st place in the Google Landmark Retrieval 2019 challenge and 3rd place in the Google Landmark Recognition 2019 challenge on Kaggle. Our code is publicly available here: \\url{https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution}\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [9.341522216796875, 11.931568145751953]}, {"key": "", "year": "", "title": "Yokoo2021contrastive", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Contrastive Learning with Large Memory Bank and Negative Embedding Subtraction for Accurate Copy Detection\"\nauthors: Yokoo Shuhei\nconference: Arxiv\nyear: 2021\nbibkey: yokoo2021contrastive\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2112.04323\"}   - {name: \"Code\", url: \"https://github.com/lyakaap/ISC21-Descriptor-Track-1st}\"}\ntags: ['ARXIV', 'CNN']\n---\nCopy detection, which is a task to determine whether an image is a modified copy of any image in a database, is an unsolved problem. Thus, we addressed copy detection by training convolutional neural networks (CNNs) with contrastive learning. Training with a large memory-bank and hard data augmentation enables the CNNs to obtain more discriminative representation. Our proposed negative embedding subtraction further boosts the copy detection accuracy. Using our methods, we achieved 1st place in the Facebook AI Image Similarity Challenge: Descriptor Track. Our code is publicly available here: \\url{https://github.com/lyakaap/ISC21-Descriptor-Track-1st}\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [2.3552980422973633, 23.38292121887207]}, {"key": "", "year": "", "title": "Yoon2020image", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Image-to-Image Retrieval by Learning Similarity between Scene Graphs\"\nauthors: Yoon Sangwoong, Kang Woo Young, Jeon Sungwook, Lee SeongEun, Han Changjin, Park Jonghun, Kim Eun-Sol\nconference: Arxiv\nyear: 2020\nbibkey: yoon2020image\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2012.14700\"}\ntags: ['ARXIV', 'Graph', 'Image Retrieval']\n---\nAs a scene graph compactly summarizes the high-level content of an image in a structured and symbolic manner, the similarity between scene graphs of two images reflects the relevance of their contents. Based on this idea, we propose a novel approach for image-to-image retrieval using scene graph similarity measured by graph neural networks. In our approach, graph neural networks are trained to predict the proxy image relevance measure, computed from human-annotated captions using a pre-trained sentence similarity model. We collect and publish the dataset for image relevance measured by human annotators to evaluate retrieval algorithms. The collected dataset shows that our method agrees well with the human perception of image similarity than other competitive baselines.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.759391784667969, -28.580556869506836]}, {"key": "", "year": "", "title": "Yu2016variable", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Variable-Length Hashing\"\nauthors: Yu Honghai, Moulin Pierre, Ng Hong Wei, Li Xiaoli\nconference: Arxiv\nyear: 2016\nbibkey: yu2016variable\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1603.05414\"}\ntags: ['ARXIV', 'TIP']\n---\nHashing has emerged as a popular technique for large-scale similarity search. Most learning-based hashing methods generate compact yet correlated hash codes. However, this redundancy is storage-inefficient. Hence we propose a lossless variable-length hashing (VLH) method that is both storage- and search-efficient. Storage efficiency is achieved by converting the fixed-length hash code into a variable-length code. Search efficiency is obtained by using a multiple hash table structure. With VLH, we are able to deliberately add redundancy into hash codes to improve retrieval performance with little sacrifice in storage efficiency or search complexity. In particular, we propose a block K-means hashing (B-KMH) method to obtain significantly improved retrieval performance with no increase in storage and marginal increase in computational cost.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-8.792573928833008, -5.0282721519470215]}, {"key": "", "year": "", "title": "Yu2017hyperminhash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"HyperMinHash: MinHash in LogLog space\"\nauthors: Yu Yun William, Weber Griffin M.\nconference: Arxiv\nyear: 2017\nbibkey: yu2017hyperminhash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1710.08436\"}\ntags: ['ACL', 'ARXIV', 'TIP']\n---\nIn this extended abstract, we describe and analyze a lossy compression of MinHash from buckets of size $O(\\log n)$ to buckets of size $O(\\log\\log n)$ by encoding using floating-point notation. This new compressed sketch, which we call HyperMinHash, as we build off a HyperLogLog scaffold, can be used as a drop-in replacement of MinHash. Unlike comparable Jaccard index fingerprinting algorithms in sub-logarithmic space (such as b-bit MinHash), HyperMinHash retains MinHash's features of streaming updates, unions, and cardinality estimation. For a multiplicative approximation error $1+ \\epsilon$ on a Jaccard index $ t $, given a random oracle, HyperMinHash needs $O\\left(\\epsilon^\\{-2\\} \\left( \\log\\log n + \\log \\frac\\{1\\}\\{ t \\epsilon\\} \\right)\\right)$ space. HyperMinHash allows estimating Jaccard indices of 0.01 for set cardinalities on the order of $10^\\{19\\}$ with relative error of around 10\\% using 64KiB of memory; MinHash can only estimate Jaccard indices for cardinalities of $10^\\{10\\}$ with the same memory consumption.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-10.724801063537598, -19.63406753540039]}, {"key": "", "year": "", "title": "Yu2018discriminative", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Discriminative Supervised Hashing for Cross-Modal similarity Search\"\nauthors: Yu Jun, Wu Xiao-Jun, Kittler Josef\nconference: Arxiv\nyear: 2018\nbibkey: yu2018discriminative\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1812.07660\"}\ntags: ['ARXIV', 'Cross Modal', 'Supervised', 'TIP']\n---\nWith the advantage of low storage cost and high retrieval efficiency, hashing techniques have recently been an emerging topic in cross-modal similarity search. As multiple modal data reflect similar semantic content, many researches aim at learning unified binary codes. However, discriminative hashing features learned by these methods are not adequate. This results in lower accuracy and robustness. We propose a novel hashing learning framework which jointly performs classifier learning, subspace learning and matrix factorization to preserve class-specific semantic content, termed Discriminative Supervised Hashing (DSH), to learn the discrimative unified binary codes for multi-modal data. Besides, reducing the loss of information and preserving the non-linear structure of data, DSH non-linearly projects different modalities into the common space in which the similarity among heterogeneous data points can be measured. Extensive experiments conducted on the three publicly available datasets demonstrate that the framework proposed in this paper outperforms several state-of -the-art methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-5.105963230133057, -4.391601085662842]}, {"key": "", "year": "", "title": "Yu2018learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning Discriminative Hashing Codes for Cross-Modal Retrieval based on Multi-view Features\"\nauthors: Yu Jun, Wu Xiao-Jun, Kittler Josef\nconference: Arxiv\nyear: 2018\nbibkey: yu2018learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1808.04152\"}\ntags: ['ARXIV', 'Cross Modal', 'Quantisation', 'TIP']\n---\nHashing techniques have been applied broadly in retrieval tasks due to their low storage requirements and high speed of processing. Many hashing methods based on a single view have been extensively studied for information retrieval. However, the representation capacity of a single view is insufficient and some discriminative information is not captured, which results in limited improvement. In this paper, we employ multiple views to represent images and texts for enriching the feature information. Our framework exploits the complementary information among multiple views to better learn the discriminative compact hash codes. A discrete hashing learning framework that jointly performs classifier learning and subspace learning is proposed to complete multiple search tasks simultaneously. Our framework includes two stages, namely a kernelization process and a quantization process. Kernelization aims to find a common subspace where multi-view features can be fused. The quantization stage is designed to learn discriminative unified hashing codes. Extensive experiments are performed on single-label datasets (WiKi and MMED) and multi-label datasets (MIRFlickr and NUS-WIDE) and the experimental results indicate the superiority of our method compared with the state-of-the-art methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-10.750625610351562, -0.32576116919517517]}, {"key": "", "year": "", "title": "Yu2018semi", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Semi-supervised Hashing for Semi-Paired Cross-View Retrieval\"\nauthors: Yu Jun, Wu Xiao-Jun, Kittler Josef\nconference: Arxiv\nyear: 2018\nbibkey: yu2018semi\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1806.07155\"}\ntags: ['ARXIV', 'Semi Supervised', 'Supervised']\n---\nRecently, hashing techniques have gained importance in large-scale retrieval tasks because of their retrieval speed. Most of the existing cross-view frameworks assume that data are well paired. However, the fully-paired multiview situation is not universal in real applications. The aim of the method proposed in this paper is to learn the hashing function for semi-paired cross-view retrieval tasks. To utilize the label information of partial data, we propose a semi-supervised hashing learning framework which jointly performs feature extraction and classifier learning. The experimental results on two datasets show that our method outperforms several state-of-the-art methods in terms of retrieval accuracy.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-18.27324104309082, 0.49150756001472473]}, {"key": "", "year": "", "title": "Yu2019unsupervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Unsupervised Multi-modal Hashing for Cross-modal retrieval\"\nauthors: Yu Jun, Wu Xiao-Jun\nconference: Arxiv\nyear: 2019\nbibkey: yu2019unsupervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1904.00726\"}\ntags: ['ARXIV', 'Cross Modal', 'Supervised', 'Unsupervised']\n---\nWith the advantage of low storage cost and high efficiency, hashing learning has received much attention in the domain of Big Data. In this paper, we propose a novel unsupervised hashing learning method to cope with this open problem to directly preserve the manifold structure by hashing. To address this problem, both the semantic correlation in textual space and the locally geometric structure in the visual space are explored simultaneously in our framework. Besides, the `2;1-norm constraint is imposed on the projection matrices to learn the discriminative hash function for each modality. Extensive experiments are performed to evaluate the proposed method on the three publicly available datasets and the experimental results show that our method can achieve superior performance over the state-of-the-art methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-16.61163330078125, 0.9701041579246521]}, {"key": "", "year": "", "title": "Yu2020comprehensive", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Comprehensive Graph-conditional Similarity Preserving Network for Unsupervised Cross-modal Hashing\"\nauthors: Yu Jun, Zhou Hao, Zhan Yibing, Tao Dacheng\nconference: Arxiv\nyear: 2020\nbibkey: yu2020comprehensive\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2012.13538\"}   - {name: \"Code\", url: \"https://github.com/Atmegal/DGCPN.\"}\ntags: ['ARXIV', 'Cross Modal', 'Graph', 'Quantisation', 'Supervised', 'Unsupervised']\n---\nUnsupervised cross-modal hashing (UCMH) has become a hot topic recently. Current UCMH focuses on exploring data similarities. However, current UCMH methods calculate the similarity between two data, mainly relying on the two data's cross-modal features. These methods suffer from inaccurate similarity problems that result in a suboptimal retrieval Hamming space, because the cross-modal features between the data are not sufficient to describe the complex data relationships, such as situations where two data have different feature representations but share the inherent concepts. In this paper, we devise a deep graph-neighbor coherence preserving network (DGCPN). Specifically, DGCPN stems from graph models and explores graph-neighbor coherence by consolidating the information between data and their neighbors. DGCPN regulates comprehensive similarity preserving losses by exploiting three types of data similarities (i.e., the graph-neighbor coherence, the coexistent similarity, and the intra- and inter-modality consistency) and designs a half-real and half-binary optimization strategy to reduce the quantization errors during hashing. Essentially, DGCPN addresses the inaccurate similarity problem by exploring and exploiting the data's intrinsic relationships in a graph. We conduct extensive experiments on three public UCMH datasets. The experimental results demonstrate the superiority of DGCPN, e.g., by improving the mean average precision from 0.722 to 0.751 on MIRFlickr-25K using 64-bit hashing codes to retrieve texts from images. We will release the source code package and the trained model on https://github.com/Atmegal/DGCPN.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [2.9439642429351807, -26.56720542907715]}, {"key": "", "year": "", "title": "Yu2020encode", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Encode the Unseen: Predictive Video Hashing for Scalable Mid-Stream Retrieval\"\nauthors: Yu Tong, Padoy Nicolas\nconference: Arxiv\nyear: 2020\nbibkey: yu2020encode\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2009.14661\"}\ntags: ['ARXIV', 'Video Retrieval']\n---\nThis paper tackles a new problem in computer vision: mid-stream video-to-video retrieval. This task, which consists in searching a database for content similar to a video right as it is playing, e.g. from a live stream, exhibits challenging characteristics. Only the beginning part of the video is available as query and new frames are constantly added as the video plays out. To perform retrieval in this demanding situation, we propose an approach based on a binary encoder that is both predictive and incremental in order to (1) account for the missing video content at query time and (2) keep up with repeated, continuously evolving queries throughout the streaming. In particular, we present the first hashing framework that infers the unseen future content of a currently playing video. Experiments on FCVID and ActivityNet demonstrate the feasibility of this task. Our approach also yields a significant mAP@20 performance increase compared to a baseline adapted from the literature for this task, for instance 7.4% (2.6%) increase at 20% (50%) of elapsed runtime on FCVID using bitcodes of size 192 bits.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-0.56107097864151, 28.4243106842041]}, {"key": "", "year": "", "title": "Yu2020self", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Self-supervised asymmetric deep hashing with margin-scalable constraint\"\nauthors: Yu Zhengyang, Wu Song, Dou Zhihao, Bakker Erwin M.\nconference: Arxiv\nyear: 2020\nbibkey: yu2020self\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2012.03820\"}\ntags: ['ARXIV', 'Self Supervised', 'Supervised', 'TIP']\n---\nDue to its effectivity and efficiency, deep hashing approaches are widely used for large-scale visual search. However, it is still challenging to produce compact and discriminative hash codes for images associated with multiple semantics for two main reasons, 1) similarity constraints designed in most of the existing methods are based upon an oversimplified similarity assignment(i.e., 0 for instance pairs sharing no label, 1 for instance pairs sharing at least 1 label), 2) the exploration in multi-semantic relevance are insufficient or even neglected in many of the existing methods. These problems significantly limit the discrimination of generated hash codes. In this paper, we propose a novel self-supervised asymmetric deep hashing method with a margin-scalable constraint(SADH) approach to cope with these problems. SADH implements a self-supervised network to sufficiently preserve semantic information in a semantic feature dictionary and a semantic code dictionary for the semantics of the given dataset, which efficiently and precisely guides a feature learning network to preserve multilabel semantic information using an asymmetric learning strategy. By further exploiting semantic dictionaries, a new margin-scalable constraint is employed for both precise similarity searching and robust hash code generation. Extensive empirical research on four popular benchmarks validates the proposed method and shows it outperforms several state-of-the-art approaches.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-4.443605422973633, 8.362765312194824]}, {"key": "", "year": "", "title": "Yu2021improving", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Improving Query Representations for Dense Retrieval with Pseudo Relevance Feedback\"\nauthors: Yu HongChien, Xiong Chenyan, Callan Jamie\nconference: Arxiv\nyear: 2021\nbibkey: yu2021improving\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2108.13454\"}\ntags: ['ARXIV']\n---\nDense retrieval systems conduct first-stage retrieval using embedded representations and simple similarity metrics to match a query to documents. Its effectiveness depends on encoded embeddings to capture the semantics of queries and documents, a challenging task due to the shortness and ambiguity of search queries. This paper proposes ANCE-PRF, a new query encoder that uses pseudo relevance feedback (PRF) to improve query representations for dense retrieval. ANCE-PRF uses a BERT encoder that consumes the query and the top retrieved documents from a dense retrieval model, ANCE, and it learns to produce better query embeddings directly from relevance labels. It also keeps the document index unchanged to reduce overhead. ANCE-PRF significantly outperforms ANCE and other recent dense retrieval systems on several datasets. Analysis shows that the PRF encoder effectively captures the relevant and complementary information from PRF documents, while ignoring the noise with its learned attention mechanism.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [16.416440963745117, -5.929357051849365]}, {"key": "", "year": "", "title": "Yu2022learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning to Hash Naturally Sorts\"\nauthors: Yu Jiaguo, Shen Yuming, Wang Menghan, Zhang Haofeng, Torr Philip H. S.\nconference: Arxiv\nyear: 2022\nbibkey: yu2022learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2201.13322\"}\ntags: ['ARXIV', 'Self Supervised', 'Supervised', 'Unsupervised']\n---\nLearning to hash pictures a list-wise sorting problem. Its testing metrics, e.g., mean-average precision, count on a sorted candidate list ordered by pair-wise code similarity. However, scarcely does one train a deep hashing model with the sorted results end-to-end because of the non-differentiable nature of the sorting operation. This inconsistency in the objectives of training and test may lead to sub-optimal performance since the training loss often fails to reflect the actual retrieval metric. In this paper, we tackle this problem by introducing Naturally-Sorted Hashing (NSH). We sort the Hamming distances of samples' hash codes and accordingly gather their latent representations for self-supervised training. Thanks to the recent advances in differentiable sorting approximations, the hash head receives gradients from the sorter so that the hash encoder can be optimized along with the training procedure. Additionally, we describe a novel Sorted Noise-Contrastive Estimation (SortedNCE) loss that selectively picks positive and negative samples for contrastive learning, which allows NSH to mine data semantic relations during training in an unsupervised manner. Our extensive experiments show the proposed NSH model significantly outperforms the existing unsupervised hashing methods on three benchmarked datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-11.297769546508789, 1.471375584602356]}, {"key": "", "year": "", "title": "Yu2022weighted", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Weighted Contrastive Hashing\"\nauthors: Yu Jiaguo, Qiu Huming, Chen Dubing, Zhang Haofeng\nconference: Arxiv\nyear: 2022\nbibkey: yu2022weighted\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2209.14099\"}\ntags: ['ARXIV', 'Supervised', 'TIP', 'Unsupervised']\n---\nThe development of unsupervised hashing is advanced by the recent popular contrastive learning paradigm. However, previous contrastive learning-based works have been hampered by (1) insufficient data similarity mining based on global-only image representations, and (2) the hash code semantic loss caused by the data augmentation. In this paper, we propose a novel method, namely Weighted Contrative Hashing (WCH), to take a step towards solving these two problems. We introduce a novel mutual attention module to alleviate the problem of information asymmetry in network features caused by the missing image structure during contrative augmentation. Furthermore, we explore the fine-grained semantic relations between images, i.e., we divide the images into multiple patches and calculate similarities between patches. The aggregated weighted similarities, which reflect the deep image relations, are distilled to facilitate the hash codes learning with a distillation loss, so as to obtain better retrieval performance. Extensive experiments show that the proposed WCH significantly outperforms existing unsupervised hashing methods on three benchmark datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-4.812320709228516, 12.629542350769043]}, {"key": "", "year": "", "title": "Yuan2019central", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Central Similarity Quantization for Efficient Image and Video Retrieval\"\nauthors: Yuan Li, Wang Tao, Zhang Xiaopeng, Tay Francis EH, Jie Zequn, Liu Wei, Feng Jiashi\nconference: Arxiv\nyear: 2019\nbibkey: yuan2019central\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1908.00347\"}   - {name: \"Code\", url: \"https://github.com/yuanli2333/Hadamard-Matrix-for-hashing}\"}\ntags: ['ARXIV', 'Quantisation', 'Video Retrieval']\n---\nExisting data-dependent hashing methods usually learn hash functions from pairwise or triplet data relationships, which only capture the data similarity locally, and often suffer from low learning efficiency and low collision rate. In this work, we propose a new \\emph{global} similarity metric, termed as \\emph{central similarity}, with which the hash codes of similar data pairs are encouraged to approach a common center and those for dissimilar pairs to converge to different centers, to improve hash learning efficiency and retrieval accuracy. We principally formulate the computation of the proposed central similarity metric by introducing a new concept, i.e., \\emph{hash center} that refers to a set of data points scattered in the Hamming space with a sufficient mutual distance between each other. We then provide an efficient method to construct well separated hash centers by leveraging the Hadamard matrix and Bernoulli distributions. Finally, we propose the Central Similarity Quantization (CSQ) that optimizes the central similarity between data points w.r.t.\\ their hash centers instead of optimizing the local similarity. CSQ is generic and applicable to both image and video hashing scenarios. Extensive experiments on large-scale image and video retrieval tasks demonstrate that CSQ can generate cohesive hash codes for similar data pairs and dispersed hash codes for dissimilar pairs, achieving a noticeable boost in retrieval performance, i.e. 3\\%-20\\% in mAP over the previous state-of-the-arts. The code is at: \\url{https://github.com/yuanli2333/Hadamard-Matrix-for-hashing}\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-2.5243561267852783, 2.5152809619903564]}, {"key": "", "year": "", "title": "Yuan2019signal", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Signal-to-Noise Ratio: A Robust Distance Metric for Deep Metric Learning\"\nauthors: Yuan Tongtong, Deng Weihong, Tang Jian, Tang Yinan, Chen Binghui\nconference: Arxiv\nyear: 2019\nbibkey: yuan2019signal\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1904.02616\"}\ntags: ['ARXIV']\n---\nDeep metric learning, which learns discriminative features to process image clustering and retrieval tasks, has attracted extensive attention in recent years. A number of deep metric learning methods, which ensure that similar examples are mapped close to each other and dissimilar examples are mapped farther apart, have been proposed to construct effective structures for loss functions and have shown promising results. In this paper, different from the approaches on learning the loss structures, we propose a robust SNR distance metric based on Signal-to-Noise Ratio (SNR) for measuring the similarity of image pairs for deep metric learning. By exploring the properties of our SNR distance metric from the view of geometry space and statistical theory, we analyze the properties of our metric and show that it can preserve the semantic similarity between image pairs, which well justify its suitability for deep metric learning. Compared with Euclidean distance metric, our SNR distance metric can further jointly reduce the intra-class distances and enlarge the inter-class distances for learned features. Leveraging our SNR distance metric, we propose Deep SNR-based Metric Learning (DSML) to generate discriminative feature embeddings. By extensive experiments on three widely adopted benchmarks, including CARS196, CUB200-2011 and CIFAR10, our DSML has shown its superiority over other state-of-the-art methods. Additionally, we extend our SNR distance metric to deep hashing learning, and conduct experiments on two benchmarks, including CIFAR10 and NUS-WIDE, to demonstrate the effectiveness and generality of our SNR distance metric.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [13.322400093078613, 7.698155879974365]}, {"key": "", "year": "", "title": "Yuan2023semantic", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Semantic-Aware Adversarial Training for Reliable Deep Hashing Retrieval\"\nauthors: Yuan Xu, Zhang Zheng, Wang Xunguang, Wu Lin\nconference: in IEEE Transactions on Information Forensics and Security, vol.\nyear: 2023\nbibkey: yuan2023semantic\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2310.14637\"}   - {name: \"Code\", url: \"https://github.com/xandery-geek/SAAT.\"}\ntags: ['Image Retrieval']\n---\nDeep hashing has been intensively studied and successfully applied in large-scale image retrieval systems due to its efficiency and effectiveness. Recent studies have recognized that the existence of adversarial examples poses a security threat to deep hashing models, that is, adversarial vulnerability. Notably, it is challenging to efficiently distill reliable semantic representatives for deep hashing to guide adversarial learning, and thereby it hinders the enhancement of adversarial robustness of deep hashing-based retrieval models. Moreover, current researches on adversarial training for deep hashing are hard to be formalized into a unified minimax structure. In this paper, we explore Semantic-Aware Adversarial Training (SAAT) for improving the adversarial robustness of deep hashing models. Specifically, we conceive a discriminative mainstay features learning (DMFL) scheme to construct semantic representatives for guiding adversarial learning in deep hashing. Particularly, our DMFL with the strict theoretical guarantee is adaptively optimized in a discriminative learning manner, where both discriminative and semantic properties are jointly considered. Moreover, adversarial examples are fabricated by maximizing the Hamming distance between the hash codes of adversarial samples and mainstay features, the efficacy of which is validated in the adversarial attack trials. Further, we, for the first time, formulate the formalized adversarial training of deep hashing into a unified minimax optimization under the guidance of the generated mainstay codes. Extensive experiments on benchmark datasets show superb attack performance against the state-of-the-art algorithms, meanwhile, the proposed adversarial training can effectively eliminate adversarial perturbations for trustworthy deep hashing-based retrieval. Our code is available at https://github.com/xandery-geek/SAAT.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-11.142930030822754, 8.090279579162598]}, {"key": "", "year": "", "title": "Yun2024neurohash", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"NeuroHash: A Hyperdimensional Neuro-Symbolic Framework for Spatially-Aware Image Hashing and Retrieval\"\nauthors: Yun Sanggeon, Masukawa Ryozo, Jeong SungHeon, Imani Mohsen\nconference: Arxiv\nyear: 2024\nbibkey: yun2024neurohash\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2404.11025\"}\ntags: ['ARXIV', 'Deep Learning', 'Image Retrieval', 'Self Supervised', 'Supervised', 'TOM']\n---\nCustomizable image retrieval from large datasets remains a critical challenge, particularly when preserving spatial relationships within images. Traditional hashing methods, primarily based on deep learning, often fail to capture spatial information adequately and lack transparency. In this paper, we introduce NeuroHash, a novel neuro-symbolic framework leveraging Hyperdimensional Computing (HDC) to enable highly customizable, spatially-aware image retrieval. NeuroHash combines pre-trained deep neural network models with HDC-based symbolic models, allowing for flexible manipulation of hash values to support conditional image retrieval. Our method includes a self-supervised context-aware HDC encoder and novel loss terms for optimizing lower-dimensional bipolar hashing using multilinear hyperplanes. We evaluate NeuroHash on two benchmark datasets, demonstrating superior performance compared to state-of-the-art hashing methods, as measured by mAP@5K scores and our newly introduced metric, mAP@5Kr, which assesses spatial alignment. The results highlight NeuroHash's ability to achieve competitive performance while offering significant advantages in flexibility and customization, paving the way for more advanced and versatile image retrieval systems.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [8.762859344482422, 10.775399208068848]}, {"key": "", "year": "", "title": "Zadeh2012dimension", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Dimension Independent Similarity Computation\"\nauthors: Zadeh Reza Bosagh, Goel Ashish\nconference: Arxiv\nyear: 2012\nbibkey: zadeh2012dimension\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1206.2082\"}\ntags: ['ARXIV']\n---\nWe present a suite of algorithms for Dimension Independent Similarity Computation (DISCO) to compute all pairwise similarities between very high dimensional sparse vectors. All of our results are provably independent of dimension, meaning apart from the initial cost of trivially reading in the data, all subsequent operations are independent of the dimension, thus the dimension can be very large. We study Cosine, Dice, Overlap, and the Jaccard similarity measures. For Jaccard similiarity we include an improved version of MinHash. Our results are geared toward the MapReduce framework. We empirically validate our theorems at large scale using data from the social networking site Twitter. At time of writing, our algorithms are live in production at twitter.com.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-9.685129165649414, -16.01270866394043]}, {"key": "", "year": "", "title": "Zamani2023multivariate", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Multivariate Representation Learning for Information Retrieval\"\nauthors: Zamani Hamed, Bendersky Michael\nconference: Arxiv\nyear: 2023\nbibkey: zamani2023multivariate\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2304.14522\"}\ntags: ['ARXIV']\n---\nDense retrieval models use bi-encoder network architectures for learning query and document representations. These representations are often in the form of a vector representation and their similarities are often computed using the dot product function. In this paper, we propose a new representation learning framework for dense retrieval. Instead of learning a vector for each query and document, our framework learns a multivariate distribution and uses negative multivariate KL divergence to compute the similarity between distributions. For simplicity and efficiency reasons, we assume that the distributions are multivariate normals and then train large language models to produce mean and variance vectors for these distributions. We provide a theoretical foundation for the proposed framework and show that it can be seamlessly integrated into the existing approximate nearest neighbor algorithms to perform retrieval efficiently. We conduct an extensive suite of experiments on a wide range of datasets, and demonstrate significant improvements compared to competitive dense retrieval models.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [14.043488502502441, -10.141098976135254]}, {"key": "", "year": "", "title": "Zeng2019modal", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Modal-aware Features for Multimodal Hashing\"\nauthors: Zeng Haien, Lai Hanjiang, Chu Hanlu, Tang Yong, Yin Jian\nconference: Arxiv\nyear: 2019\nbibkey: zeng2019modal\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1911.08479\"}\ntags: ['ARXIV', 'TIP']\n---\nMany retrieval applications can benefit from multiple modalities, e.g., text that contains images on Wikipedia, for which how to represent multimodal data is the critical component. Most deep multimodal learning methods typically involve two steps to construct the joint representations: 1) learning of multiple intermediate features, with each intermediate feature corresponding to a modality, using separate and independent deep models; 2) merging the intermediate features into a joint representation using a fusion strategy. However, in the first step, these intermediate features do not have previous knowledge of each other and cannot fully exploit the information contained in the other modalities. In this paper, we present a modal-aware operation as a generic building block to capture the non-linear dependences among the heterogeneous intermediate features that can learn the underlying correlation structures in other multimodal data as soon as possible. The modal-aware operation consists of a kernel network and an attention network. The kernel network is utilized to learn the non-linear relationships with other modalities. Then, to learn better representations for binary hash codes, we present an attention network that finds the informative regions of these modal-aware features that are favorable for retrieval. Experiments conducted on three public benchmark datasets demonstrate significant improvements in the performance of our method relative to state-of-the-art methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-1.1185919046401978, -0.5994231104850769]}, {"key": "", "year": "", "title": "Zeng2019simultaneous", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Simultaneous Region Localization and Hash Coding for Fine-grained Image Retrieval\"\nauthors: Zeng Haien, Lai Hanjiang, Yin Jian\nconference: Arxiv\nyear: 2019\nbibkey: zeng2019simultaneous\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1911.08028\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nFine-grained image hashing is a challenging problem due to the difficulties of discriminative region localization and hash code generation. Most existing deep hashing approaches solve the two tasks independently. While these two tasks are correlated and can reinforce each other. In this paper, we propose a deep fine-grained hashing to simultaneously localize the discriminative regions and generate the efficient binary codes. The proposed approach consists of a region localization module and a hash coding module. The region localization module aims to provide informative regions to the hash coding module. The hash coding module aims to generate effective binary codes and give feedback for learning better localizer. Moreover, to better capture subtle differences, multi-scale regions at different layers are learned without the need of bounding-box/part annotations. Extensive experiments are conducted on two public benchmark fine-grained datasets. The results demonstrate significant improvements in the performance of our method relative to other fine-grained hashing algorithms.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-1.5882776975631714, 9.95937728881836]}, {"key": "", "year": "", "title": "Zeng2021phpq", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"PHPQ: Pyramid Hybrid Pooling Quantization for Efficient Fine-Grained Image Retrieval\"\nauthors: Zeng Ziyun, Wang Jinpeng, Chen Bin, Dai Tao, Xia Shu-Tao, Wang Zhi\nconference: Pattern Recognition Letters, Volume\nyear: 2021\nbibkey: zeng2021phpq\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2109.05206\"}\ntags: ['CNN', 'Image Retrieval', 'Quantisation', 'Volume']\n---\nDeep hashing approaches, including deep quantization and deep binary hashing, have become a common solution to large-scale image retrieval due to their high computation and storage efficiency. Most existing hashing methods cannot produce satisfactory results for fine-grained retrieval, because they usually adopt the outputs of the last CNN layer to generate binary codes. Since deeper layers tend to summarize visual clues, e.g., texture, into abstract semantics, e.g., dogs and cats, the feature produced by the last CNN layer is less effective in capturing subtle but discriminative visual details that mostly exist in shallow layers. To improve fine-grained image hashing, we propose Pyramid Hybrid Pooling Quantization (PHPQ). Specifically, we propose a Pyramid Hybrid Pooling (PHP) module to capture and preserve fine-grained semantic information from multi-level features, which emphasizes the subtle discrimination of different sub-categories. Besides, we propose a learnable quantization module with a partial codebook attention mechanism, which helps to optimize the most relevant codewords and improves the quantization. Comprehensive experiments on two widely-used public benchmarks, i.e., CUB-200-2011 and Stanford Dogs, demonstrate that PHPQ outperforms state-of-the-art methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-3.981231451034546, 6.104986667633057]}, {"key": "", "year": "", "title": "Zeng2023cascading", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Cascading Hierarchical Networks with Multi-task Balanced Loss for Fine-grained hashing\"\nauthors: Zeng Xianxian, Zheng Yanjun\nconference: Arxiv\nyear: 2023\nbibkey: zeng2023cascading\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2303.11274\"}   - {name: \"Code\", url: \"https://github.com/kaiba007/FG-CNET.\"}\ntags: ['ARXIV']\n---\nWith the explosive growth in the number of fine-grained images in the Internet era, it has become a challenging problem to perform fast and efficient retrieval from large-scale fine-grained images. Among the many retrieval methods, hashing methods are widely used due to their high efficiency and small storage space occupation. Fine-grained hashing is more challenging than traditional hashing problems due to the difficulties such as low inter-class variances and high intra-class variances caused by the characteristics of fine-grained images. To improve the retrieval accuracy of fine-grained hashing, we propose a cascaded network to learn compact and highly semantic hash codes, and introduce an attention-guided data augmentation method. We refer to this network as a cascaded hierarchical data augmentation network. We also propose a novel approach to coordinately balance the loss of multi-task learning. We do extensive experiments on some common fine-grained visual classification datasets. The experimental results demonstrate that our proposed method outperforms several state-of-art hashing methods and can effectively improve the accuracy of fine-grained retrieval. The source code is publicly available: https://github.com/kaiba007/FG-CNET.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-15.533223152160645, 2.3347370624542236]}, {"key": "", "year": "", "title": "Zhan2020repbert", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"RepBERT: Contextualized Text Embeddings for First-Stage Retrieval\"\nauthors: Zhan Jingtao, Mao Jiaxin, Liu Yiqun, Zhang Min, Ma Shaoping\nconference: Arxiv\nyear: 2020\nbibkey: zhan2020repbert\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2006.15498\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nAlthough exact term match between queries and documents is the dominant method to perform first-stage retrieval, we propose a different approach, called RepBERT, to represent documents and queries with fixed-length contextualized embeddings. The inner products of query and document embeddings are regarded as relevance scores. On MS MARCO Passage Ranking task, RepBERT achieves state-of-the-art results among all initial retrieval techniques. And its efficiency is comparable to bag-of-words methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [26.427400588989258, 1.5275200605392456]}, {"key": "", "year": "", "title": "Zhan2020weakly", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Weakly-Supervised Online Hashing\"\nauthors: Zhan Yu-Wei, Luo Xin, Sun Yu, Wang Yongxin, Chen Zhen-Duo, Xu Xin-Shun\nconference: Arxiv\nyear: 2020\nbibkey: zhan2020weakly\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2009.07436\"}\ntags: ['ARXIV', 'Image Retrieval', 'Supervised', 'Unsupervised', 'Weakly Supervised']\n---\nWith the rapid development of social websites, recent years have witnessed an explosive growth of social images with user-provided tags which continuously arrive in a streaming fashion. Due to the fast query speed and low storage cost, hashing-based methods for image search have attracted increasing attention. However, existing hashing methods for social image retrieval are based on batch mode which violates the nature of social images, i.e., social images are usually generated periodically or collected in a stream fashion. Although there exist many online image hashing methods, they either adopt unsupervised learning which ignore the relevant tags, or are designed in the supervised manner which needs high-quality labels. In this paper, to overcome the above limitations, we propose a new method named Weakly-supervised Online Hashing (WOH). In order to learn high-quality hash codes, WOH exploits the weak supervision by considering the semantics of tags and removing the noise. Besides, We develop a discrete online optimization algorithm for WOH, which is efficient and scalable. Extensive experiments conducted on two real-world datasets demonstrate the superiority of WOH compared with several state-of-the-art hashing baselines.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-5.785088539123535, 9.364455223083496]}, {"key": "", "year": "", "title": "Zhan2021learning", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Learning Discrete Representations via Constrained Clustering for Effective and Efficient Dense Retrieval\"\nauthors: Zhan Jingtao, Mao Jiaxin, Liu Yiqun, Guo Jiafeng, Zhang Min, Ma Shaoping\nconference: Arxiv\nyear: 2021\nbibkey: zhan2021learning\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2110.05789\"}\ntags: ['ARXIV', 'Quantisation']\n---\nDense Retrieval (DR) has achieved state-of-the-art first-stage ranking effectiveness. However, the efficiency of most existing DR models is limited by the large memory cost of storing dense vectors and the time-consuming nearest neighbor search (NNS) in vector space. Therefore, we present RepCONC, a novel retrieval model that learns discrete Representations via CONstrained Clustering. RepCONC jointly trains dual-encoders and the Product Quantization (PQ) method to learn discrete document representations and enables fast approximate NNS with compact indexes. It models quantization as a constrained clustering process, which requires the document embeddings to be uniformly clustered around the quantization centroids and supports end-to-end optimization of the quantization method and dual-encoders. We theoretically demonstrate the importance of the uniform clustering constraint in RepCONC and derive an efficient approximate solution for constrained clustering by reducing it to an instance of the optimal transport problem. Besides constrained clustering, RepCONC further adopts a vector-based inverted file system (IVF) to support highly efficient vector search on CPUs. Extensive experiments on two popular ad-hoc retrieval benchmarks show that RepCONC achieves better ranking effectiveness than competitive vector quantization baselines under different compression ratio settings. It also substantially outperforms a wide range of existing retrieval models in terms of retrieval effectiveness, memory efficiency, and time efficiency.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-12.948175430297852, -6.2260847091674805]}, {"key": "", "year": "", "title": "Zhang2010self", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Self-Taught Hashing for Fast Similarity Search\"\nauthors: Zhang Dell, Wang Jun, Cai Deng, Lu Jinsong\nconference: Arxiv\nyear: 2010\nbibkey: zhang2010self\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1004.5370\"}\ntags: ['ARXIV', 'Supervised', 'Unsupervised']\n---\nThe ability of fast similarity search at large scale is of great importance to many Information Retrieval (IR) applications. A promising way to accelerate similarity search is semantic hashing which designs compact binary codes for a large number of documents so that semantically similar documents are mapped to similar codes (within a short Hamming distance). Although some recently proposed techniques are able to generate high-quality codes for documents known in advance, obtaining the codes for previously unseen documents remains to be a very challenging problem. In this paper, we emphasise this issue and propose a novel Self-Taught Hashing (STH) approach to semantic hashing: we first find the optimal $l$-bit binary codes for all documents in the given corpus via unsupervised learning, and then train $l$ classifiers via supervised learning to predict the $l$-bit code for any query document unseen before. Our experiments on three real-world text datasets show that the proposed approach using binarised Laplacian Eigenmap (LapEig) and linear Support Vector Machine (SVM) outperforms state-of-the-art techniques significantly.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-4.911765098571777, -5.232259273529053]}, {"key": "", "year": "", "title": "Zhang2015bit", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Bit-Scalable Deep Hashing with Regularized Similarity Learning for Image Retrieval and Person Re-identification\"\nauthors: Zhang Ruimao, Lin Liang, Zhang Rui, Zuo Wangmeng, Zhang Lei\nconference: Arxiv\nyear: 2015\nbibkey: zhang2015bit\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1508.04535\"}\ntags: ['ARXIV', 'GAN', 'Image Retrieval', 'Supervised']\n---\nExtracting informative image features and learning effective approximate hashing functions are two crucial steps in image retrieval . Conventional methods often study these two steps separately, e.g., learning hash functions from a predefined hand-crafted feature space. Meanwhile, the bit lengths of output hashing codes are preset in most previous methods, neglecting the significance level of different bits and restricting their practical flexibility. To address these issues, we propose a supervised learning framework to generate compact and bit-scalable hashing codes directly from raw images. We pose hashing learning as a problem of regularized similarity learning. Specifically, we organize the training images into a batch of triplet samples, each sample containing two images with the same label and one with a different label. With these triplet samples, we maximize the margin between matched pairs and mismatched pairs in the Hamming space. In addition, a regularization term is introduced to enforce the adjacency consistency, i.e., images of similar appearances should have similar codes. The deep convolutional neural network is utilized to train the model in an end-to-end fashion, where discriminative image features and hash functions are simultaneously optimized. Furthermore, each bit of our hashing codes is unequally weighted so that we can manipulate the code lengths by truncating the insignificant bits. Our framework outperforms state-of-the-arts on public benchmarks of similar image search and also achieves promising results in the application of person re-identification in surveillance. It is also shown that the generated bit-scalable hashing codes well preserve the discriminative powers with shorter code lengths.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-7.804492950439453, 7.416083812713623]}, {"key": "", "year": "", "title": "Zhang2015efficient", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Efficient Training of Very Deep Neural Networks for Supervised Hashing\"\nauthors: Zhang Ziming, Chen Yuting, Saligrama Venkatesh\nconference: Arxiv\nyear: 2015\nbibkey: zhang2015efficient\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1511.04524\"}\ntags: ['ARXIV', 'Supervised', 'TIP']\n---\nIn this paper, we propose training very deep neural networks (DNNs) for supervised learning of hash codes. Existing methods in this context train relatively \"shallow\" networks limited by the issues arising in back propagation (e.e. vanishing gradients) as well as computational efficiency. We propose a novel and efficient training algorithm inspired by alternating direction method of multipliers (ADMM) that overcomes some of these limitations. Our method decomposes the training process into independent layer-wise local updates through auxiliary variables. Empirically we observe that our training algorithm always converges and its computational complexity is linearly proportional to the number of edges in the networks. Empirically we manage to train DNNs with 64 hidden layers and 1024 nodes per layer for supervised hashing in about 3 hours using a single GPU. Our proposed very deep supervised hashing (VDSH) method significantly outperforms the state-of-the-art on several benchmark datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-18.649194717407227, 12.524879455566406]}, {"key": "", "year": "", "title": "Zhang2015reflectance", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Reflectance Hashing for Material Recognition\"\nauthors: Zhang Hang, Dana Kristin, Nishino Ko\nconference: Arxiv\nyear: 2015\nbibkey: zhang2015reflectance\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1502.02092\"}\ntags: ['ARXIV']\n---\nWe introduce a novel method for using reflectance to identify materials. Reflectance offers a unique signature of the material but is challenging to measure and use for recognizing materials due to its high-dimensionality. In this work, one-shot reflectance is captured using a unique optical camera measuring {\\it reflectance disks} where the pixel coordinates correspond to surface viewing angles. The reflectance has class-specific stucture and angular gradients computed in this reflectance space reveal the material class. These reflectance disks encode discriminative information for efficient and accurate material recognition. We introduce a framework called reflectance hashing that models the reflectance disks with dictionary learning and binary hashing. We demonstrate the effectiveness of reflectance hashing for material recognition with a number of real-world materials.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [20.719636917114258, 1.5792193412780762]}, {"key": "", "year": "", "title": "Zhang2016improving", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Improving Raw Image Storage Efficiency by Exploiting Similarity\"\nauthors: Zhang Binqi, Wang Chen, Zhou Bing Bing, Zomaya Albert Y.\nconference: Arxiv\nyear: 2016\nbibkey: zhang2016improving\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1604.05442\"}\ntags: ['ARXIV']\n---\nTo improve the temporal and spatial storage efficiency, researchers have intensively studied various techniques, including compression and deduplication. Through our evaluation, we find that methods such as photo tags or local features help to identify the content-based similar- ity between raw images. The images can then be com- pressed more efficiently to get better storage space sav- ings. Furthermore, storing similar raw images together enables rapid data sorting, searching and retrieval if the images are stored in a distributed and large-scale envi- ronment by reducing fragmentation. In this paper, we evaluated the compressibility by designing experiments and observing the results. We found that on a statistical basis the higher similarity photos have, the better com- pression results are. This research helps provide a clue for future large-scale storage system design.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [16.39859962463379, 5.426716327667236]}, {"key": "", "year": "", "title": "Zhang2016query", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Query-adaptive Image Retrieval by Deep Weighted Hashing\"\nauthors: Zhang Jian, Peng Yuxin\nconference: Arxiv\nyear: 2016\nbibkey: zhang2016query\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1612.02541\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nHashing methods have attracted much attention for large scale image retrieval. Some deep hashing methods have achieved promising results by taking advantage of the strong representation power of deep networks recently. However, existing deep hashing methods treat all hash bits equally. On one hand, a large number of images share the same distance to a query image due to the discrete Hamming distance, which raises a critical issue of image retrieval where fine-grained rankings are very important. On the other hand, different hash bits actually contribute to the image retrieval differently, and treating them equally greatly affects the retrieval accuracy of image. To address the above two problems, we propose the query-adaptive deep weighted hashing (QaDWH) approach, which can perform fine-grained ranking for different queries by weighted Hamming distance. First, a novel deep hashing network is proposed to learn the hash codes and corresponding class-wise weights jointly, so that the learned weights can reflect the importance of different hash bits for different image classes. Second, a query-adaptive image retrieval method is proposed, which rapidly generates hash bit weights for different query images by fusing its semantic probability and the learned class-wise weights. Fine-grained image retrieval is then performed by the weighted Hamming distance, which can provide more accurate ranking than the traditional Hamming distance. Experiments on four widely used datasets show that the proposed approach outperforms eight state-of-the-art hashing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-2.3318562507629395, 8.64645767211914]}, {"key": "", "year": "", "title": "Zhang2016scalable", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Scalable Discrete Supervised Hash Learning with Asymmetric Matrix Factorization\"\nauthors: Zhang Shifeng, Li Jianmin, Guo Jinma, Zhang Bo\nconference: Arxiv\nyear: 2016\nbibkey: zhang2016scalable\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1609.08740\"}\ntags: ['ARXIV', 'Supervised']\n---\nHashing method maps similar data to binary hashcodes with smaller hamming distance, and it has received a broad attention due to its low storage cost and fast retrieval speed. However, the existing limitations make the present algorithms difficult to deal with large-scale datasets: (1) discrete constraints are involved in the learning of the hash function; (2) pairwise or triplet similarity is adopted to generate efficient hashcodes, resulting both time and space complexity are greater than O(n^2). To address these issues, we propose a novel discrete supervised hash learning framework which can be scalable to large-scale datasets. First, the discrete learning procedure is decomposed into a binary classifier learning scheme and binary codes learning scheme, which makes the learning procedure more efficient. Second, we adopt the Asymmetric Low-rank Matrix Factorization and propose the Fast Clustering-based Batch Coordinate Descent method, such that the time and space complexity is reduced to O(n). The proposed framework also provides a flexible paradigm to incorporate with arbitrary hash function, including deep neural networks and kernel methods. Experiments on large-scale datasets demonstrate that the proposed method is superior or comparable with state-of-the-art hashing algorithms.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-13.79776382446289, -4.330104351043701]}, {"key": "", "year": "", "title": "Zhang2016ssdh", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"SSDH: Semi-supervised Deep Hashing for Large Scale Image Retrieval\"\nauthors: Zhang Jian, Peng Yuxin\nconference: Arxiv\nyear: 2016\nbibkey: zhang2016ssdh\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1607.08477\"}\ntags: ['ARXIV', 'Graph', 'Image Retrieval', 'Semi Supervised', 'Supervised']\n---\nHashing methods have been widely used for efficient similarity retrieval on large scale image database. Traditional hashing methods learn hash functions to generate binary codes from hand-crafted features, which achieve limited accuracy since the hand-crafted features cannot optimally represent the image content and preserve the semantic similarity. Recently, several deep hashing methods have shown better performance because the deep architectures generate more discriminative feature representations. However, these deep hashing methods are mainly designed for supervised scenarios, which only exploit the semantic similarity information, but ignore the underlying data structures. In this paper, we propose the semi-supervised deep hashing (SSDH) approach, to perform more effective hash function learning by simultaneously preserving semantic similarity and underlying data structures. The main contributions are as follows: (1) We propose a semi-supervised loss to jointly minimize the empirical error on labeled data, as well as the embedding error on both labeled and unlabeled data, which can preserve the semantic similarity and capture the meaningful neighbors on the underlying data structures for effective hashing. (2) A semi-supervised deep hashing network is designed to extensively exploit both labeled and unlabeled data, in which we propose an online graph construction method to benefit from the evolving deep features during training to better capture semantic neighbors. To the best of our knowledge, the proposed deep network is the first deep hashing method that can perform hash code learning and feature learning simultaneously in a semi-supervised fashion. Experimental results on 5 widely-used datasets show that our proposed approach outperforms the state-of-the-art hashing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-9.549591064453125, 3.060983419418335]}, {"key": "", "year": "", "title": "Zhang2017effective", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Effective Image Retrieval via Multilinear Multi-index Fusion\"\nauthors: Zhang Zhizhong, Xie Yuan, Zhang Wensheng, Tian Qi\nconference: Arxiv\nyear: 2017\nbibkey: zhang2017effective\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1709.09304\"}\ntags: ['ARXIV', 'Image Retrieval', 'TIP']\n---\nMulti-index fusion has demonstrated impressive performances in retrieval task by integrating different visual representations in a unified framework. However, previous works mainly consider propagating similarities via neighbor structure, ignoring the high order information among different visual representations. In this paper, we propose a new multi-index fusion scheme for image retrieval. By formulating this procedure as a multilinear based optimization problem, the complementary information hidden in different indexes can be explored more thoroughly. Specially, we first build our multiple indexes from various visual representations. Then a so-called index-specific functional matrix, which aims to propagate similarities, is introduced for updating the original index. The functional matrices are then optimized in a unified tensor space to achieve a refinement, such that the relevant images can be pushed more closer. The optimization problem can be efficiently solved by the augmented Lagrangian method with theoretical convergence guarantee. Unlike the traditional multi-index fusion scheme, our approach embeds the multi-index subspace structure into the new indexes with sparse constraint, thus it has little additional memory consumption in online query stage. Experimental evaluation on three benchmark datasets reveals that the proposed approach achieves the state-of-the-art performance, i.e., N-score 3.94 on UKBench, mAP 94.1\\% on Holiday and 62.39\\% on Market-1501.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [10.340088844299316, 12.89029598236084]}, {"key": "", "year": "", "title": "Zhang2017hashganattention", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"HashGAN:Attention-aware Deep Adversarial Hashing for Cross Modal Retrieval\"\nauthors: Zhang Xi, Zhou Siyu, Feng Jiashi, Lai Hanjiang, Li Bo, Pan Yan, Yin Jian, Yan Shuicheng\nconference: Arxiv\nyear: 2017\nbibkey: zhang2017hashganattention\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1711.09347\"}\ntags: ['ARXIV', 'Cross Modal', 'GAN']\n---\nAs the rapid growth of multi-modal data, hashing methods for cross-modal retrieval have received considerable attention. Deep-networks-based cross-modal hashing methods are appealing as they can integrate feature learning and hash coding into end-to-end trainable frameworks. However, it is still challenging to find content similarities between different modalities of data due to the heterogeneity gap. To further address this problem, we propose an adversarial hashing network with attention mechanism to enhance the measurement of content similarities by selectively focusing on informative parts of multi-modal data. The proposed new adversarial network, HashGAN, consists of three building blocks: 1) the feature learning module to obtain feature representations, 2) the generative attention module to generate an attention mask, which is used to obtain the attended (foreground) and the unattended (background) feature representations, 3) the discriminative hash coding module to learn hash functions that preserve the similarities between different modalities. In our framework, the generative module and the discriminative module are trained in an adversarial way: the generator is learned to make the discriminator cannot preserve the similarities of multi-modal data w.r.t. the background feature representations, while the discriminator aims to preserve the similarities of multi-modal data w.r.t. both the foreground and the background feature representations. Extensive evaluations on several benchmark datasets demonstrate that the proposed HashGAN brings substantial improvements over other state-of-the-art cross-modal hashing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-11.533345222473145, 6.773382186889648]}, {"key": "", "year": "", "title": "Zhang2017unsupervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Unsupervised Generative Adversarial Cross-modal Hashing\"\nauthors: Zhang Jian, Peng Yuxin, Yuan Mingkuan\nconference: Arxiv\nyear: 2017\nbibkey: zhang2017unsupervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1712.00358\"}\ntags: ['ARXIV', 'Cross Modal', 'GAN', 'Graph', 'Supervised', 'Unsupervised']\n---\nCross-modal hashing aims to map heterogeneous multimedia data into a common Hamming space, which can realize fast and flexible retrieval across different modalities. Unsupervised cross-modal hashing is more flexible and applicable than supervised methods, since no intensive labeling work is involved. However, existing unsupervised methods learn hashing functions by preserving inter and intra correlations, while ignoring the underlying manifold structure across different modalities, which is extremely helpful to capture meaningful nearest neighbors of different modalities for cross-modal retrieval. To address the above problem, in this paper we propose an Unsupervised Generative Adversarial Cross-modal Hashing approach (UGACH), which makes full use of GAN's ability for unsupervised representation learning to exploit the underlying manifold structure of cross-modal data. The main contributions can be summarized as follows: (1) We propose a generative adversarial network to model cross-modal hashing in an unsupervised fashion. In the proposed UGACH, given a data of one modality, the generative model tries to fit the distribution over the manifold structure, and select informative data of another modality to challenge the discriminative model. The discriminative model learns to distinguish the generated data and the true positive data sampled from correlation graph to achieve better retrieval accuracy. These two models are trained in an adversarial way to improve each other and promote hashing function learning. (2) We propose a correlation graph based approach to capture the underlying manifold structure across different modalities, so that data of different modalities but within the same manifold can have smaller Hamming distance and promote retrieval accuracy. Extensive experiments compared with 6 state-of-the-art methods verify the effectiveness of our proposed approach.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-12.170551300048828, 6.202939033508301]}, {"key": "", "year": "", "title": "Zhang2018improved", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Improved Deep Hashing with Soft Pairwise Similarity for Multi-label Image Retrieval\"\nauthors: Zhang Zheng, Zou Qin, Lin Yuewei, Chen Long, Wang Song\nconference: Arxiv\nyear: 2018\nbibkey: zhang2018improved\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1803.02987\"}\ntags: ['ARXIV', 'Image Retrieval', 'TIP']\n---\nHash coding has been widely used in the approximate nearest neighbor search for large-scale image retrieval. Recently, many deep hashing methods have been proposed and shown largely improved performance over traditional feature-learning-based methods. Most of these methods examine the pairwise similarity on the semantic-level labels, where the pairwise similarity is generally defined in a hard-assignment way. That is, the pairwise similarity is '1' if they share no less than one class label and '0' if they do not share any. However, such similarity definition cannot reflect the similarity ranking for pairwise images that hold multiple labels. In this paper, a new deep hashing method is proposed for multi-label image retrieval by re-defining the pairwise similarity into an instance similarity, where the instance similarity is quantified into a percentage based on the normalized semantic labels. Based on the instance similarity, a weighted cross-entropy loss and a minimum mean square error loss are tailored for loss-function construction, and are efficiently used for simultaneous feature learning and hash coding. Experiments on three popular datasets demonstrate that, the proposed method outperforms the competing methods and achieves the state-of-the-art performance in multi-label image retrieval.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [3.24006986618042, 5.82944393157959]}, {"key": "", "year": "", "title": "Zhang2018minjoin", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"MinJoin: Efficient Edit Similarity Joins via Local Hash Minima\"\nauthors: Zhang Haoyu, Zhang Qin\nconference: Arxiv\nyear: 2018\nbibkey: zhang2018minjoin\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1810.08833\"}\ntags: ['ARXIV']\n---\nWe study the problem of computing similarity joins under edit distance on a set of strings. Edit similarity joins is a fundamental problem in databases, data mining and bioinformatics. It finds important applications in data cleaning and integration, collaborative filtering, genome sequence assembly, etc. This problem has attracted significant attention in the past two decades. However, all previous algorithms either cannot scale well to long strings and large similarity thresholds, or suffer from imperfect accuracy. In this paper we propose a new algorithm for edit similarity joins using a novel string partition based approach. We show mathematically that with high probability our algorithm achieves a perfect accuracy, and runs in linear time plus a data-dependent verification step. Experiments on real world datasets show that our algorithm significantly outperforms the state-of-the-art algorithms for edit similarity joins, and achieves perfect accuracy on all the datasets that we have tested.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [0.6771448850631714, -21.70118522644043]}, {"key": "", "year": "", "title": "Zhang2018sch", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"SCH-GAN: Semi-supervised Cross-modal Hashing by Generative Adversarial Network\"\nauthors: Zhang Jian, Peng Yuxin, Yuan Mingkuan\nconference: Arxiv\nyear: 2018\nbibkey: zhang2018sch\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1802.02488\"}\ntags: ['ARXIV', 'Cross Modal', 'GAN', 'Semi Supervised', 'Supervised']\n---\nCross-modal hashing aims to map heterogeneous multimedia data into a common Hamming space, which can realize fast and flexible retrieval across different modalities. Supervised cross-modal hashing methods have achieved considerable progress by incorporating semantic side information. However, they mainly have two limitations: (1) Heavily rely on large-scale labeled cross-modal training data which are labor intensive and hard to obtain. (2) Ignore the rich information contained in the large amount of unlabeled data across different modalities, especially the margin examples that are easily to be incorrectly retrieved, which can help to model the correlations. To address these problems, in this paper we propose a novel Semi-supervised Cross-Modal Hashing approach by Generative Adversarial Network (SCH-GAN). We aim to take advantage of GAN's ability for modeling data distributions to promote cross-modal hashing learning in an adversarial way. The main contributions can be summarized as follows: (1) We propose a novel generative adversarial network for cross-modal hashing. In our proposed SCH-GAN, the generative model tries to select margin examples of one modality from unlabeled data when giving a query of another modality. While the discriminative model tries to distinguish the selected examples and true positive examples of the query. These two models play a minimax game so that the generative model can promote the hashing performance of discriminative model. (2) We propose a reinforcement learning based algorithm to drive the training of proposed SCH-GAN. The generative model takes the correlation score predicted by discriminative model as a reward, and tries to select the examples close to the margin to promote discriminative model by maximizing the margin between positive and negative data. Experiments on 3 widely-used datasets verify the effectiveness of our proposed approach.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-12.241366386413574, 6.276913642883301]}, {"key": "", "year": "", "title": "Zhang2018semantic", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Semantic Cluster Unary Loss for Efficient Deep Hashing\"\nauthors: Zhang Shifeng, Li Jianmin, Zhang Bo\nconference: IEEE Transactions on Image Processing,\nyear: 2018\nbibkey: zhang2018semantic\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1805.08705\"}\ntags: ['Deep Learning', 'Semi Supervised', 'Supervised']\n---\nHashing method maps similar data to binary hashcodes with smaller hamming distance, which has received a broad attention due to its low storage cost and fast retrieval speed. With the rapid development of deep learning, deep hashing methods have achieved promising results in efficient information retrieval. Most of the existing deep hashing methods adopt pairwise or triplet losses to deal with similarities underlying the data, but the training is difficult and less efficient because $O(n^2)$ data pairs and $O(n^3)$ triplets are involved. To address these issues, we propose a novel deep hashing algorithm with unary loss which can be trained very efficiently. We first of all introduce a Unary Upper Bound of the traditional triplet loss, thus reducing the complexity to $O(n)$ and bridging the classification-based unary loss and the triplet loss. Second, we propose a novel Semantic Cluster Deep Hashing (SCDH) algorithm by introducing a modified Unary Upper Bound loss, named Semantic Cluster Unary Loss (SCUL). The resultant hashcodes form several compact clusters, which means hashcodes in the same cluster have similar semantic information. We also demonstrate that the proposed SCDH is easy to be extended to semi-supervised settings by incorporating the state-of-the-art semi-supervised learning algorithms. Experiments on large-scale datasets show that the proposed method is superior to state-of-the-art hashing algorithms.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-13.637221336364746, -4.337104797363281]}, {"key": "", "year": "", "title": "Zhang2019collaborative", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Collaborative Quantization for Cross-Modal Similarity Search\"\nauthors: Zhang Ting, Wang Jingdong\nconference: Arxiv\nyear: 2019\nbibkey: zhang2019collaborative\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1902.00623\"}\ntags: ['ARXIV', 'Cross Modal', 'Quantisation']\n---\nCross-modal similarity search is a problem about designing a search system supporting querying across content modalities, e.g., using an image to search for texts or using a text to search for images. This paper presents a compact coding solution for efficient search, with a focus on the quantization approach which has already shown the superior performance over the hashing solutions in the single-modal similarity search. We propose a cross-modal quantization approach, which is among the early attempts to introduce quantization into cross-modal search. The major contribution lies in jointly learning the quantizers for both modalities through aligning the quantized representations for each pair of image and text belonging to a document. In addition, our approach simultaneously learns the common space for both modalities in which quantization is conducted to enable efficient and effective search using the Euclidean distance computed in the common space with fast distance table lookup. Experimental results compared with several competitive algorithms over three benchmark datasets demonstrate that the proposed approach achieves the state-of-the-art performance.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [15.480664253234863, -9.57435131072998]}, {"key": "", "year": "", "title": "Zhang2019joint", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Joint Cluster Unary Loss for Efficient Cross-Modal Hashing\"\nauthors: Zhang Shifeng, Li Jianmin, Zhang Bo\nconference: Arxiv\nyear: 2019\nbibkey: zhang2019joint\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1902.00644\"}\ntags: ['ARXIV', 'Cross Modal', 'Supervised']\n---\nWith the rapid growth of various types of multimodal data, cross-modal deep hashing has received broad attention for solving cross-modal retrieval problems efficiently. Most cross-modal hashing methods follow the traditional supervised hashing framework in which the $O(n^2)$ data pairs and $O(n^3)$ data triplets are generated for training, but the training procedure is less efficient because the complexity is high for large-scale dataset. To address these issues, we propose a novel and efficient cross-modal hashing algorithm in which the unary loss is introduced. First of all, We introduce the Cross-Modal Unary Loss (CMUL) with $O(n)$ complexity to bridge the traditional triplet loss and classification-based unary loss. A more accurate bound of the triplet loss for structured multilabel data is also proposed in CMUL. Second, we propose the novel Joint Cluster Cross-Modal Hashing (JCCH) algorithm for efficient hash learning, in which the CMUL is involved. The resultant hashcodes form several clusters in which the hashcodes in the same cluster share similar semantic information, and the heterogeneity gap on different modalities is diminished by sharing the clusters. The proposed algorithm is able to be applied to various types of data, and experiments on large-scale datasets show that the proposed method is superior over or comparable with state-of-the-art cross-modal hashing methods, and training with the proposed method is more efficient than others.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-14.144254684448242, -5.285114765167236]}, {"key": "", "year": "", "title": "Zhang2019language", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Language in Our Time: An Empirical Analysis of Hashtags\"\nauthors: Zhang Yang\nconference: Arxiv\nyear: 2019\nbibkey: zhang2019language\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1905.04590\"}\ntags: ['ARXIV', 'Graph']\n---\nHashtags in online social networks have gained tremendous popularity during the past five years. The resulting large quantity of data has provided a new lens into modern society. Previously, researchers mainly rely on data collected from Twitter to study either a certain type of hashtags or a certain property of hashtags. In this paper, we perform the first large-scale empirical analysis of hashtags shared on Instagram, the major platform for hashtag-sharing. We study hashtags from three different dimensions including the temporal-spatial dimension, the semantic dimension, and the social dimension. Extensive experiments performed on three large-scale datasets with more than 7 million hashtags in total provide a series of interesting observations. First, we show that the temporal patterns of hashtags can be categorized into four different clusters, and people tend to share fewer hashtags at certain places and more hashtags at others. Second, we observe that a non-negligible proportion of hashtags exhibit large semantic displacement. We demonstrate hashtags that are more uniformly shared among users, as quantified by the proposed hashtag entropy, are less prone to semantic displacement. In the end, we propose a bipartite graph embedding model to summarize users' hashtag profiles, and rely on these profiles to perform friendship prediction. Evaluation results show that our approach achieves an effective prediction with AUC (area under the ROC curve) above 0.8 which demonstrates the strong social signals possessed in hashtags.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-25.654775619506836, 10.660970687866211]}, {"key": "", "year": "", "title": "Zhang2019pairwise", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Pairwise Teacher-Student Network for Semi-Supervised Hashing\"\nauthors: Zhang Shifeng, Li Jianmin, Zhang Bo\nconference: Arxiv\nyear: 2019\nbibkey: zhang2019pairwise\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1902.00643\"}\ntags: ['ARXIV', 'Graph', 'Semi Supervised', 'Supervised']\n---\nHashing method maps similar high-dimensional data to binary hashcodes with smaller hamming distance, and it has received broad attention due to its low storage cost and fast retrieval speed. Pairwise similarity is easily obtained and widely used for retrieval, and most supervised hashing algorithms are carefully designed for the pairwise supervisions. As labeling all data pairs is difficult, semi-supervised hashing is proposed which aims at learning efficient codes with limited labeled pairs and abundant unlabeled ones. Existing methods build graphs to capture the structure of dataset, but they are not working well for complex data as the graph is built based on the data representations and determining the representations of complex data is difficult. In this paper, we propose a novel teacher-student semi-supervised hashing framework in which the student is trained with the pairwise information produced by the teacher network. The network follows the smoothness assumption, which achieves consistent distances for similar data pairs so that the retrieval results are similar for neighborhood queries. Experiments on large-scale datasets show that the proposed method reaches impressive gain over the supervised baselines and is superior to state-of-the-art semi-supervised hashing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-15.760184288024902, 7.634372234344482]}, {"key": "", "year": "", "title": "Zhang2019sadih", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"SADIH: Semantic-Aware DIscrete Hashing\"\nauthors: Zhang Zheng, Xie Guo-sen, Li Yang, Li Sheng, Huang Zi\nconference: Arxiv\nyear: 2019\nbibkey: zhang2019sadih\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1904.01739\"}\ntags: ['ARXIV', 'Supervised', 'TIP']\n---\nDue to its low storage cost and fast query speed, hashing has been recognized to accomplish similarity search in large-scale multimedia retrieval applications. Particularly supervised hashing has recently received considerable research attention by leveraging the label information to preserve the pairwise similarities of data points in the Hamming space. However, there still remain two crucial bottlenecks: 1) the learning process of the full pairwise similarity preservation is computationally unaffordable and unscalable to deal with big data; 2) the available category information of data are not well-explored to learn discriminative hash functions. To overcome these challenges, we propose a unified Semantic-Aware DIscrete Hashing (SADIH) framework, which aims to directly embed the transformed semantic information into the asymmetric similarity approximation and discriminative hashing function learning. Specifically, a semantic-aware latent embedding is introduced to asymmetrically preserve the full pairwise similarities while skillfully handle the cumbersome n times n pairwise similarity matrix. Meanwhile, a semantic-aware autoencoder is developed to jointly preserve the data structures in the discriminative latent semantic space and perform data reconstruction. Moreover, an efficient alternating optimization algorithm is proposed to solve the resulting discrete optimization problem. Extensive experimental results on multiple large-scale datasets demonstrate that our SADIH can clearly outperform the state-of-the-art baselines with the additional benefit of lower computational costs.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-11.672554016113281, -3.9624905586242676]}, {"key": "", "year": "", "title": "Zhang2019semantic", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Semantic Hierarchy Preserving Deep Hashing for Large-scale Image Retrieval\"\nauthors: Zhang Ming, Zhe Xuefei, Ou-Yang Le, Chen Shifeng, Yan Hong\nconference: Arxiv\nyear: 2019\nbibkey: zhang2019semantic\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1901.11259\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nDeep hashing models have been proposed as an efficient method for large-scale similarity search. However, most existing deep hashing methods only utilize fine-level labels for training while ignoring the natural semantic hierarchy structure. This paper presents an effective method that preserves the classwise similarity of full-level semantic hierarchy for large-scale image retrieval. Experiments on two benchmark datasets show that our method helps improve the fine-level retrieval performance. Moreover, with the help of the semantic hierarchy, it can produce significantly better binary codes for hierarchical retrieval, which indicates its potential of providing more user-desired retrieval results.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-2.5050625801086426, 14.566207885742188]}, {"key": "", "year": "", "title": "Zhang2020a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A survey on deep hashing for image retrieval\"\nauthors: Zhang Xiaopeng\nconference: Arxiv\nyear: 2020\nbibkey: zhang2020a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2006.05627\"}\ntags: ['ARXIV', 'CNN', 'Image Retrieval', 'Supervised', 'Survey Paper']\n---\nHashing has been widely used in approximate nearest search for large-scale database retrieval for its computation and storage efficiency. Deep hashing, which devises convolutional neural network architecture to exploit and extract the semantic information or feature of images, has received increasing attention recently. In this survey, several deep supervised hashing methods for image retrieval are evaluated and I conclude three main different directions for deep supervised hashing methods. Several comments are made at the end. Moreover, to break through the bottleneck of the existing hashing methods, I propose a Shadow Recurrent Hashing(SRH) method as a try. Specifically, I devise a CNN architecture to extract the semantic features of images and design a loss function to encourage similar images projected close. To this end, I propose a concept: shadow of the CNN output. During optimization process, the CNN output and its shadow are guiding each other so as to achieve the optimal solution as much as possible. Several experiments on dataset CIFAR-10 show the satisfying performance of SRH.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [9.400898933410645, 26.69241714477539]}, {"key": "", "year": "", "title": "Zhang2020collaborative", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Collaborative Generative Hashing for Marketing and Fast Cold-start Recommendation\"\nauthors: Zhang Yan, Tsang Ivor W., Duan Lixin\nconference: Arxiv\nyear: 2020\nbibkey: zhang2020collaborative\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2011.00953\"}\ntags: ['ARXIV']\n---\nCold-start has being a critical issue in recommender systems with the explosion of data in e-commerce. Most existing studies proposed to alleviate the cold-start problem are also known as hybrid recommender systems that learn representations of users and items by combining user-item interactive and user/item content information. However, previous hybrid methods regularly suffered poor efficiency bottlenecking in online recommendations with large-scale items, because they were designed to project users and items into continuous latent space where the online recommendation is expensive. To this end, we propose a collaborative generated hashing (CGH) framework to improve the efficiency by denoting users and items as binary codes, then fast hashing search techniques can be used to speed up the online recommendation. In addition, the proposed CGH can generate potential users or items for marketing application where the generative network is designed with the principle of Minimum Description Length (MDL), which is used to learn compact and informative binary codes. Extensive experiments on two public datasets show the advantages for recommendations in various settings over competing baselines and analyze its feasibility in marketing application.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [1.0580174922943115, -4.28498649597168]}, {"key": "", "year": "", "title": "Zhang2020deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Pairwise Hashing for Cold-start Recommendation\"\nauthors: Zhang Yan, Tsang Ivor W., Yin Hongzhi, Yang Guowu, Lian Defu, Li Jingjing\nconference: \nyear: 2020\nbibkey: zhang2020deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2011.00944\"}\ntags: ['Deep Learning']\n---\nRecommendation efficiency and data sparsity problems have been regarded as two challenges of improving performance for online recommendation. Most of the previous related work focus on improving recommendation accuracy instead of efficiency. In this paper, we propose a Deep Pairwise Hashing (DPH) to map users and items to binary vectors in Hamming space, where a user's preference for an item can be efficiently calculated by Hamming distance, which significantly improves the efficiency of online recommendation. To alleviate data sparsity and cold-start problems, the user-item interactive information and item content information are unified to learn effective representations of items and users. Specifically, we first pre-train robust item representation from item content data by a Denoising Auto-encoder instead of other deterministic deep learning frameworks; then we finetune the entire framework by adding a pairwise loss objective with discrete constraints; moreover, DPH aims to minimize a pairwise ranking loss that is consistent with the ultimate goal of recommendation. Finally, we adopt the alternating optimization method to optimize the proposed model with discrete constraints. Extensive experiments on three different datasets show that DPH can significantly advance the state-of-the-art frameworks regarding data sparsity and item cold-start recommendation.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [0.40866929292678833, -4.415670871734619]}, {"key": "", "year": "", "title": "Zhang2020model", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Model Size Reduction Using Frequency Based Double Hashing for Recommender Systems\"\nauthors: Zhang Caojin, Liu Yicun, Xie Yuanpu, Ktena Sofia Ira, Tejani Alykhan, Gupta Akshay, Myana Pranay Kumar, Dilipkumar Deepak, Paul Suvadip, Ihara Ikuhiro, Upadhyaya Prasang, Huszar Ferenc, Shi Wenzhe\nconference: Arxiv\nyear: 2020\nbibkey: zhang2020model\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2007.14523\"}\ntags: ['ARXIV']\n---\nDeep Neural Networks (DNNs) with sparse input features have been widely used in recommender systems in industry. These models have large memory requirements and need a huge amount of training data. The large model size usually entails a cost, in the range of millions of dollars, for storage and communication with the inference services. In this paper, we propose a hybrid hashing method to combine frequency hashing and double hashing techniques for model size reduction, without compromising performance. We evaluate the proposed models on two product surfaces. In both cases, experiment results demonstrated that we can reduce the model size by around 90 % while keeping the performance on par with the original baselines.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-21.81524658203125, 5.705792427062988]}, {"key": "", "year": "", "title": "Zhang2021bytesteady", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"byteSteady: Fast Classification Using Byte-Level n-Gram Embeddings\"\nauthors: Zhang Xiang, Drouin Alexandre, Li Raymond\nconference: Arxiv\nyear: 2021\nbibkey: zhang2021bytesteady\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2106.13302\"}\ntags: ['ARXIV']\n---\nThis article introduces byteSteady -- a fast model for classification using byte-level n-gram embeddings. byteSteady assumes that each input comes as a sequence of bytes. A representation vector is produced using the averaged embedding vectors of byte-level n-grams, with a pre-defined set of n. The hashing trick is used to reduce the number of embedding vectors. This input representation vector is then fed into a linear classifier. A straightforward application of byteSteady is text classification. We also apply byteSteady to one type of non-language data -- DNA sequences for gene classification. For both problems we achieved competitive classification results against strong baselines, suggesting that byteSteady can be applied to both language and non-language data. Furthermore, we find that simple compression using Huffman coding does not significantly impact the results, which offers an accuracy-speed trade-off previously unexplored in machine learning.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.064888954162598, -5.786676406860352]}, {"key": "", "year": "", "title": "Zhang2021improved", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Improved Deep Classwise Hashing With Centers Similarity Learning for Image Retrieval\"\nauthors: Zhang Ming, Yan Hong\nconference: Arxiv\nyear: 2021\nbibkey: zhang2021improved\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2103.09442\"}\ntags: ['ARXIV', 'Image Retrieval', 'Supervised']\n---\nDeep supervised hashing for image retrieval has attracted researchers' attention due to its high efficiency and superior retrieval performance. Most existing deep supervised hashing works, which are based on pairwise/triplet labels, suffer from the expensive computational cost and insufficient utilization of the semantics information. Recently, deep classwise hashing introduced a classwise loss supervised by class labels information alternatively; however, we find it still has its drawback. In this paper, we propose an improved deep classwise hashing, which enables hashing learning and class centers learning simultaneously. Specifically, we design a two-step strategy on center similarity learning. It interacts with the classwise loss to attract the class center to concentrate on the intra-class samples while pushing other class centers as far as possible. The centers similarity learning contributes to generating more compact and discriminative hashing codes. We conduct experiments on three benchmark datasets. It shows that the proposed method effectively surpasses the original method and outperforms state-of-the-art baselines under various commonly-used evaluation metrics for image retrieval.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-4.0541791915893555, 10.528806686401367]}, {"key": "", "year": "", "title": "Zhang2021instance", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Instance-weighted Central Similarity for Multi-label Image Retrieval\"\nauthors: Zhang Zhiwei, Peng Hanyu\nconference: Arxiv\nyear: 2021\nbibkey: zhang2021instance\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2108.05274\"}\ntags: ['ARXIV', 'Image Retrieval', 'TIP', 'TOM']\n---\nDeep hashing has been widely applied to large-scale image retrieval by encoding high-dimensional data points into binary codes for efficient retrieval. Compared with pairwise/triplet similarity based hash learning, central similarity based hashing can more efficiently capture the global data distribution. For multi-label image retrieval, however, previous methods only use multiple hash centers with equal weights to generate one centroid as the learning target, which ignores the relationship between the weights of hash centers and the proportion of instance regions in the image. To address the above issue, we propose a two-step alternative optimization approach, Instance-weighted Central Similarity (ICS), to automatically learn the center weight corresponding to a hash code. Firstly, we apply the maximum entropy regularizer to prevent one hash center from dominating the loss function, and compute the center weights via projection gradient descent. Secondly, we update neural network parameters by standard back-propagation with fixed center weights. More importantly, the learned center weights can well reflect the proportion of foreground instances in the image. Our method achieves the state-of-the-art performance on the image retrieval benchmarks, and especially improves the mAP by 1.6%-6.4% on the MS COCO dataset.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [2.9240376949310303, 4.569751262664795]}, {"key": "", "year": "", "title": "Zhang2021joint", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Joint Learning of Deep Retrieval Model and Product Quantization based Embedding Index\"\nauthors: Zhang Han, Shen Hongwei, Qiu Yiming, Jiang Yunjiang, Wang Songlin, Xu Sulong, Xiao Yun, Long Bo, Yang Wen-Yun\nconference: Arxiv\nyear: 2021\nbibkey: zhang2021joint\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2105.03933\"}\ntags: ['ARXIV', 'Quantisation']\n---\nEmbedding index that enables fast approximate nearest neighbor(ANN) search, serves as an indispensable component for state-of-the-art deep retrieval systems. Traditional approaches, often separating the two steps of embedding learning and index building, incur additional indexing time and decayed retrieval accuracy. In this paper, we propose a novel method called Poeem, which stands for product quantization based embedding index jointly trained with deep retrieval model, to unify the two separate steps within an end-to-end training, by utilizing a few techniques including the gradient straight-through estimator, warm start strategy, optimal space decomposition and Givens rotation. Extensive experimental results show that the proposed method not only improves retrieval accuracy significantly but also reduces the indexing time to almost none. We have open sourced our approach for the sake of comparison and reproducibility.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [14.84650707244873, -6.845201015472412]}, {"key": "", "year": "", "title": "Zhang2021moon", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"MOON: Multi-Hash Codes Joint Learning for Cross-Media Retrieval\"\nauthors: Zhang Donglin, Wu Xiao-Jun, Yin He-Feng, Kittler Josef\nconference: Arxiv\nyear: 2021\nbibkey: zhang2021moon\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2109.00883\"}\ntags: ['ARXIV', 'Cross Modal', 'TIP']\n---\nIn recent years, cross-media hashing technique has attracted increasing attention for its high computation efficiency and low storage cost. However, the existing approaches still have some limitations, which need to be explored. 1) A fixed hash length (e.g., 16bits or 32bits) is predefined before learning the binary codes. Therefore, these models need to be retrained when the hash length changes, that consumes additional computation power, reducing the scalability in practical applications. 2) Existing cross-modal approaches only explore the information in the original multimedia data to perform the hash learning, without exploiting the semantic information contained in the learned hash codes. To this end, we develop a novel Multiple hash cOdes jOint learNing method (MOON) for cross-media retrieval. Specifically, the developed MOON synchronously learns the hash codes with multiple lengths in a unified framework. Besides, to enhance the underlying discrimination, we combine the clues from the multimodal data, semantic labels and learned hash codes for hash learning. As far as we know, the proposed MOON is the first work to simultaneously learn different length hash codes without retraining in cross-media retrieval. Experiments on several databases show that our MOON can achieve promising performance, outperforming some recent competitive shallow and deep methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-14.183915138244629, -9.406330108642578]}, {"key": "", "year": "", "title": "Zhang2022hashing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Hashing Learning with Hyper-Class Representation\"\nauthors: Zhang Shichao, Li Jiaye\nconference: Arxiv\nyear: 2022\nbibkey: zhang2022hashing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2206.02334\"}\ntags: ['ARXIV', 'Supervised', 'Unsupervised']\n---\nExisting unsupervised hash learning is a kind of attribute-centered calculation. It may not accurately preserve the similarity between data. This leads to low down the performance of hash function learning. In this paper, a hash algorithm is proposed with a hyper-class representation. It is a two-steps approach. The first step finds potential decision features and establish hyper-class. The second step constructs hash learning based on the hyper-class information in the first step, so that the hash codes of the data within the hyper-class are as similar as possible, as well as the hash codes of the data between the hyper-classes are as different as possible. To evaluate the efficiency, a series of experiments are conducted on four public datasets. The experimental results show that the proposed hash algorithm is more efficient than the compared algorithms, in terms of mean average precision (MAP), average precision (AP) and Hamming radius 2 (HAM2)\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-20.385934829711914, -0.7028651833534241]}, {"key": "", "year": "", "title": "Zhang2022supervised", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Supervised Deep Hashing for High-dimensional and Heterogeneous Case-based Reasoning\"\nauthors: Zhang Qi, Hu Liang, Shi Chongyang, Liu Ke, Cao Longbing\nconference: Arxiv\nyear: 2022\nbibkey: zhang2022supervised\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2206.14523\"}\ntags: ['ARXIV', 'Quantisation', 'Supervised', 'Unsupervised']\n---\nCase-based Reasoning (CBR) on high-dimensional and heterogeneous data is a trending yet challenging and computationally expensive task in the real world. A promising approach is to obtain low-dimensional hash codes representing cases and perform a similarity retrieval of cases in Hamming space. However, previous methods based on data-independent hashing rely on random projections or manual construction, inapplicable to address specific data issues (e.g., high-dimensionality and heterogeneity) due to their insensitivity to data characteristics. To address these issues, this work introduces a novel deep hashing network to learn similarity-preserving compact hash codes for efficient case retrieval and proposes a deep-hashing-enabled CBR model HeCBR. Specifically, we introduce position embedding to represent heterogeneous features and utilize a multilinear interaction layer to obtain case embeddings, which effectively filtrates zero-valued features to tackle high-dimensionality and sparsity and captures inter-feature couplings. Then, we feed the case embeddings into fully-connected layers, and subsequently a hash layer generates hash codes with a quantization regularizer to control the quantization loss during relaxation. To cater to incremental learning of CBR, we further propose an adaptive learning strategy to update the hash function. Extensive experiments on public datasets show that HeCBR greatly reduces storage and significantly accelerates case retrieval. HeCBR achieves desirable performance compared with the state-of-the-art CBR methods and performs significantly better than hashing-based CBR methods in classification.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-12.009011268615723, -5.43310546875]}, {"key": "", "year": "", "title": "Zhang2023cafe", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"CAFE: Towards Compact, Adaptive, and Fast Embedding for Large-scale Recommendation Models\"\nauthors: Zhang Hailin, Liu Zirui, Chen Boxuan, Zhao Yikai, Zhao Tong, Yang Tong, Cui Bin\nconference: Arxiv\nyear: 2023\nbibkey: zhang2023cafe\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2312.03256\"}\ntags: ['ARXIV', 'Deep Learning', 'TIP']\n---\nRecently, the growing memory demands of embedding tables in Deep Learning Recommendation Models (DLRMs) pose great challenges for model training and deployment. Existing embedding compression solutions cannot simultaneously meet three key design requirements: memory efficiency, low latency, and adaptability to dynamic data distribution. This paper presents CAFE, a Compact, Adaptive, and Fast Embedding compression framework that addresses the above requirements. The design philosophy of CAFE is to dynamically allocate more memory resources to important features (called hot features), and allocate less memory to unimportant ones. In CAFE, we propose a fast and lightweight sketch data structure, named HotSketch, to capture feature importance and report hot features in real time. For each reported hot feature, we assign it a unique embedding. For the non-hot features, we allow multiple features to share one embedding by using hash embedding technique. Guided by our design philosophy, we further propose a multi-level hash embedding framework to optimize the embedding tables of non-hot features. We theoretically analyze the accuracy of HotSketch, and analyze the model convergence against deviation. Extensive experiments show that CAFE significantly outperforms existing embedding compression methods, yielding 3.92% and 3.68% superior testing AUC on Criteo Kaggle dataset and CriteoTB dataset at a compression ratio of 10000x. The source codes of CAFE are available at GitHub.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-2.140105724334717, -27.351123809814453]}, {"key": "", "year": "", "title": "Zhang2023image", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Image-text Retrieval via Preserving Main Semantics of Vision\"\nauthors: Zhang Xu, Niu Xinzheng, Fournier-Viger Philippe, Dai Xudong\nconference: Arxiv\nyear: 2023\nbibkey: zhang2023image\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2304.10254\"}   - {name: \"Code\", url: \"https://github.com/ZhangXu0963/VSL.\"}\ntags: ['ARXIV', 'Cross Modal', 'Text Retrieval']\n---\nImage-text retrieval is one of the major tasks of cross-modal retrieval. Several approaches for this task map images and texts into a common space to create correspondences between the two modalities. However, due to the content (semantics) richness of an image, redundant secondary information in an image may cause false matches. To address this issue, this paper presents a semantic optimization approach, implemented as a Visual Semantic Loss (VSL), to assist the model in focusing on an image's main content. This approach is inspired by how people typically annotate the content of an image by describing its main content. Thus, we leverage the annotated texts corresponding to an image to assist the model in capturing the main content of the image, reducing the negative impact of secondary content. Extensive experiments on two benchmark datasets (MSCOCO and Flickr30K) demonstrate the superior performance of our method. The code is available at: https://github.com/ZhangXu0963/VSL.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [21.848237991333008, 4.280638694763184]}, {"key": "", "year": "", "title": "Zhang2024demo", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"DEMO: A Statistical Perspective for Efficient Image-Text Matching\"\nauthors: Zhang Fan, Hua Xian-Sheng, Chen Chong, Luo Xiao\nconference: Arxiv\nyear: 2024\nbibkey: zhang2024demo\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2405.11496\"}\ntags: ['ARXIV', 'Self Supervised', 'Supervised', 'TIP', 'Unsupervised']\n---\nImage-text matching has been a long-standing problem, which seeks to connect vision and language through semantic understanding. Due to the capability to manage large-scale raw data, unsupervised hashing-based approaches have gained prominence recently. They typically construct a semantic similarity structure using the natural distance, which subsequently provides guidance to the model optimization process. However, the similarity structure could be biased at the boundaries of semantic distributions, causing error accumulation during sequential optimization. To tackle this, we introduce a novel hashing approach termed Distribution-based Structure Mining with Consistency Learning (DEMO) for efficient image-text matching. From a statistical view, DEMO characterizes each image using multiple augmented views, which are considered as samples drawn from its intrinsic semantic distribution. Then, we employ a non-parametric distribution divergence to ensure a robust and precise similarity structure. In addition, we introduce collaborative consistency learning which not only preserves the similarity structure in the Hamming space but also encourages consistency between retrieval distribution from different directions in a self-supervised manner. Through extensive experiments on three benchmark image-text matching datasets, we demonstrate that DEMO achieves superior performance compared with many state-of-the-art methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [4.075473785400391, 11.08778190612793]}, {"key": "", "year": "", "title": "Zhang2024magiclens", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"MagicLens: Self-Supervised Image Retrieval with Open-Ended Instructions\"\nauthors: Zhang Kai, Luan Yi, Hu Hexiang, Lee Kenton, Qiao Siyuan, Chen Wenhu, Su Yu, Chang Ming-Wei\nconference: Arxiv\nyear: 2024\nbibkey: zhang2024magiclens\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2403.19651\"}   - {name: \"Paper\", url: \"https://open-vision-language.github.io/MagicLens/.\"}\ntags: ['ARXIV', 'Image Retrieval', 'Self Supervised', 'Supervised']\n---\nImage retrieval, i.e., finding desired images given a reference image, inherently encompasses rich, multi-faceted search intents that are difficult to capture solely using image-based measures. Recent works leverage text instructions to allow users to more freely express their search intents. However, they primarily focus on image pairs that are visually similar and/or can be characterized by a small set of pre-defined relations. The core thesis of this paper is that text instructions can enable retrieving images with richer relations beyond visual similarity. To show this, we introduce MagicLens, a series of self-supervised image retrieval models that support open-ended instructions. MagicLens is built on a key novel insight: image pairs that naturally occur on the same web pages contain a wide range of implicit relations (e.g., inside view of), and we can bring those implicit relations explicit by synthesizing instructions via foundation models. Trained on 36.7M (query image, instruction, target image) triplets with rich semantic relations mined from the web, MagicLens achieves results comparable with or better than prior best on eight benchmarks of various image retrieval tasks, while maintaining high parameter efficiency with a significantly smaller model size. Additional human analyses on a 1.4M-image unseen corpus further demonstrate the diversity of search intents supported by MagicLens. Code and models are publicly available at https://open-vision-language.github.io/MagicLens/.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [1.3557318449020386, 17.93979835510254]}, {"key": "", "year": "", "title": "Zhao2015deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Semantic Ranking Based Hashing for Multi-Label Image Retrieval\"\nauthors: Zhao Fang, Huang Yongzhen, Wang Liang, Tan Tieniu\nconference: Arxiv\nyear: 2015\nbibkey: zhao2015deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1501.06272\"}\ntags: ['ARXIV', 'Image Retrieval', 'TIP']\n---\nWith the rapid growth of web images, hashing has received increasing interests in large scale image retrieval. Research efforts have been devoted to learning compact binary codes that preserve semantic similarity based on labels. However, most of these hashing methods are designed to handle simple binary similarity. The complex multilevel semantic structure of images associated with multiple labels have not yet been well explored. Here we propose a deep semantic ranking based method for learning hash functions that preserve multilevel semantic similarity between multi-label images. In our approach, deep convolutional neural network is incorporated into hash functions to jointly learn feature representations and mappings from them to hash codes, which avoids the limitation of semantic representation power of hand-crafted features. Meanwhile, a ranking list that encodes the multilevel similarity information is employed to guide the learning of such deep hash functions. An effective scheme based on surrogate loss is used to solve the intractable optimization problem of nonsmooth and multivariate ranking measures involved in the learning procedure. Experimental results show the superiority of our proposed approach over several state-of-the-art hashing methods in term of ranking evaluation metrics when tested on multi-label image datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-4.223665237426758, 9.474982261657715]}, {"key": "", "year": "", "title": "Zhao2017scalable", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Scalable Nearest Neighbor Search based on kNN Graph\"\nauthors: Zhao Wan-Lei, Yang Jie, Deng Cheng-Hao\nconference: Arxiv\nyear: 2017\nbibkey: zhao2017scalable\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1701.08475\"}\ntags: ['ARXIV', 'Graph', 'Quantisation']\n---\nNearest neighbor search is known as a challenging issue that has been studied for several decades. Recently, this issue becomes more and more imminent in viewing that the big data problem arises from various fields. In this paper, a scalable solution based on hill-climbing strategy with the support of k-nearest neighbor graph (kNN) is presented. Two major issues have been considered in the paper. Firstly, an efficient kNN graph construction method based on two means tree is presented. For the nearest neighbor search, an enhanced hill-climbing procedure is proposed, which sees considerable performance boost over original procedure. Furthermore, with the support of inverted indexing derived from residue vector quantization, our method achieves close to 100% recall with high speed efficiency in two state-of-the-art evaluation benchmarks. In addition, a comparative study on both the compressional and traditional nearest neighbor search methods is presented. We show that our method achieves the best trade-off between search quality, efficiency and memory complexity.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [6.501142501831055, -25.648637771606445]}, {"key": "", "year": "", "title": "Zhao2018approximate", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Approximate k-NN Graph Construction: a Generic Online Approach\"\nauthors: Zhao Wan-Lei, Wang Hui, Ngo Chong-Wah\nconference: Arxiv\nyear: 2018\nbibkey: zhao2018approximate\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1804.03032\"}\ntags: ['ARXIV', 'Graph']\n---\nNearest neighbor search and k-nearest neighbor graph construction are two fundamental issues arise from many disciplines such as multimedia information retrieval, data-mining and machine learning. They become more and more imminent given the big data emerge in various fields in recent years. In this paper, a simple but effective solution both for approximate k-nearest neighbor search and approximate k-nearest neighbor graph construction is presented. These two issues are addressed jointly in our solution. On the one hand, the approximate k-nearest neighbor graph construction is treated as a search task. Each sample along with its k-nearest neighbors are joined into the k-nearest neighbor graph by performing the nearest neighbor search sequentially on the graph under construction. On the other hand, the built k-nearest neighbor graph is used to support k-nearest neighbor search. Since the graph is built online, the dynamic update on the graph, which is not possible from most of the existing solutions, is supported. This solution is feasible for various distance measures. Its effectiveness both as k-nearest neighbor construction and k-nearest neighbor search approaches is verified across different types of data in different scales, various dimensions and under different metrics.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [6.473058700561523, -25.837223052978516]}, {"key": "", "year": "", "title": "Zhao2021a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Feature Consistency Driven Attention Erasing Network for Fine-Grained Image Retrieval\"\nauthors: Zhao Qi, Wang Xu, Lyu Shuchang, Liu Binghao, Yang Yifan\nconference: Arxiv\nyear: 2021\nbibkey: zhao2021a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2110.04479\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nLarge-scale fine-grained image retrieval has two main problems. First, low dimensional feature embedding can fasten the retrieval process but bring accuracy reduce due to overlooking the feature of significant attention regions of images in fine-grained datasets. Second, fine-grained images lead to the same category query hash codes mapping into the different cluster in database hash latent space. To handle these two issues, we propose a feature consistency driven attention erasing network (FCAENet) for fine-grained image retrieval. For the first issue, we propose an adaptive augmentation module in FCAENet, which is selective region erasing module (SREM). SREM makes the network more robust on subtle differences of fine-grained task by adaptively covering some regions of raw images. The feature extractor and hash layer can learn more representative hash code for fine-grained images by SREM. With regard to the second issue, we fully exploit the pair-wise similarity information and add the enhancing space relation loss (ESRL) in FCAENet to make the vulnerable relation stabler between the query hash code and database hash code. We conduct extensive experiments on five fine-grained benchmark datasets (CUB2011, Aircraft, NABirds, VegFru, Food101) for 12bits, 24bits, 32bits, 48bits hash code. The results show that FCAENet achieves the state-of-the-art (SOTA) fine-grained retrieval performance compared with other methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [2.5676825046539307, 8.49215030670166]}, {"key": "", "year": "", "title": "Zhao2021rescuing", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Rescuing Deep Hashing from Dead Bits Problem\"\nauthors: Zhao Shu, Wu Dayan, Zhou Yucan, Li Bo, Wang Weiping\nconference: Arxiv\nyear: 2021\nbibkey: zhao2021rescuing\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2102.00648\"}\ntags: ['ARXIV', 'Image Retrieval', 'Quantisation']\n---\nDeep hashing methods have shown great retrieval accuracy and efficiency in large-scale image retrieval. How to optimize discrete hash bits is always the focus in deep hashing methods. A common strategy in these methods is to adopt an activation function, e.g. $\\operatorname\\{sigmoid\\}(\\cdot)$ or $\\operatorname\\{tanh\\}(\\cdot)$, and minimize a quantization loss to approximate discrete values. However, this paradigm may make more and more hash bits stuck into the wrong saturated area of the activation functions and never escaped. We call this problem \"Dead Bits Problem~(DBP)\". Besides, the existing quantization loss will aggravate DBP as well. In this paper, we propose a simple but effective gradient amplifier which acts before activation functions to alleviate DBP. Moreover, we devise an error-aware quantization loss to further alleviate DBP. It avoids the negative effect of quantization loss based on the similarity between two images. The proposed gradient amplifier and error-aware quantization loss are compatible with a variety of deep hashing methods. Experimental results on three datasets demonstrate the efficiency of the proposed gradient amplifier and the error-aware quantization loss.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-4.492207050323486, 4.626173973083496]}, {"key": "", "year": "", "title": "Zhdanov2023catching", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Catching Image Retrieval Generalization\"\nauthors: Zhdanov Maksim, Karpukhin Ivan\nconference: Arxiv\nyear: 2023\nbibkey: zhdanov2023catching\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2306.13357\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nThe concepts of overfitting and generalization are vital for evaluating machine learning models. In this work, we show that the popular Recall@K metric depends on the number of classes in the dataset, which limits its ability to estimate generalization. To fix this issue, we propose a new metric, which measures retrieval performance, and, unlike Recall@K, estimates generalization. We apply the proposed metric to popular image retrieval methods and provide new insights about deep metric learning generalization.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [17.54096031188965, 10.042228698730469]}, {"key": "", "year": "", "title": "Zhe2018deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Class-Wise Hashing: Semantics-Preserving Hashing via Class-wise Loss\"\nauthors: Zhe Xuefei, Chen Shifeng, Yan Hong\nconference: Arxiv\nyear: 2018\nbibkey: zhe2018deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1803.04137\"}\ntags: ['ARXIV', 'Deep Learning', 'Image Retrieval', 'Supervised']\n---\nDeep supervised hashing has emerged as an influential solution to large-scale semantic image retrieval problems in computer vision. In the light of recent progress, convolutional neural network based hashing methods typically seek pair-wise or triplet labels to conduct the similarity preserving learning. However, complex semantic concepts of visual contents are hard to capture by similar/dissimilar labels, which limits the retrieval performance. Generally, pair-wise or triplet losses not only suffer from expensive training costs but also lack in extracting sufficient semantic information. In this regard, we propose a novel deep supervised hashing model to learn more compact class-level similarity preserving binary codes. Our deep learning based model is motivated by deep metric learning that directly takes semantic labels as supervised information in training and generates corresponding discriminant hashing code. Specifically, a novel cubic constraint loss function based on Gaussian distribution is proposed, which preserves semantic variations while penalizes the overlap part of different classes in the embedding space. To address the discrete optimization problem introduced by binary codes, a two-step optimization strategy is proposed to provide efficient training and avoid the problem of gradient vanishing. Extensive experiments on four large-scale benchmark databases show that our model can achieve the state-of-the-art retrieval performance. Moreover, when training samples are limited, our method surpasses other supervised deep hashing methods with non-negligible margins.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-12.765019416809082, 8.175141334533691]}, {"key": "", "year": "", "title": "Zheng2016sift", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"SIFT Meets CNN: A Decade Survey of Instance Retrieval\"\nauthors: Zheng Liang, Yang Yi, Tian Qi\nconference: Arxiv\nyear: 2016\nbibkey: zheng2016sift\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1608.01807\"}\ntags: ['ARXIV', 'CNN', 'GAN', 'Image Retrieval', 'Survey Paper']\n---\nIn the early days, content-based image retrieval (CBIR) was studied with global features. Since 2003, image retrieval based on local descriptors (de facto SIFT) has been extensively studied for over a decade due to the advantage of SIFT in dealing with image transformations. Recently, image representations based on the convolutional neural network (CNN) have attracted increasing interest in the community and demonstrated impressive performance. Given this time of rapid evolution, this article provides a comprehensive survey of instance retrieval over the last decade. Two broad categories, SIFT-based and CNN-based methods, are presented. For the former, according to the codebook size, we organize the literature into using large/medium-sized/small codebooks. For the latter, we discuss three lines of methods, i.e., using pre-trained or fine-tuned CNN models, and hybrid methods. The first two perform a single-pass of an image to the network, while the last category employs a patch-based feature extraction scheme. This survey presents milestones in modern instance retrieval, reviews a broad selection of previous works in different categories, and provides insights on the connection between SIFT and CNN-based methods. After analyzing and comparing retrieval performance of different categories on several datasets, we discuss promising directions towards generic and specialized instance retrieval.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.313882827758789, 27.685428619384766]}, {"key": "", "year": "", "title": "Zheng2020generative", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Generative Semantic Hashing Enhanced via Boltzmann Machines\"\nauthors: Zheng Lin, Su Qinliang, Shen Dinghan, Chen Changyou\nconference: Arxiv\nyear: 2020\nbibkey: zheng2020generative\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2006.08858\"}\ntags: ['ARXIV']\n---\nGenerative semantic hashing is a promising technique for large-scale information retrieval thanks to its fast retrieval speed and small memory footprint. For the tractability of training, existing generative-hashing methods mostly assume a factorized form for the posterior distribution, enforcing independence among the bits of hash codes. From the perspectives of both model representation and code space size, independence is always not the best assumption. In this paper, to introduce correlations among the bits of hash codes, we propose to employ the distribution of Boltzmann machine as the variational posterior. To address the intractability issue of training, we first develop an approximate method to reparameterize the distribution of a Boltzmann machine by augmenting it as a hierarchical concatenation of a Gaussian-like distribution and a Bernoulli distribution. Based on that, an asymptotically-exact lower bound is further derived for the evidence lower bound (ELBO). With these novel techniques, the entire model can be optimized efficiently. Extensive experimental results demonstrate that by effectively modeling correlations among different bits within a hash code, our model can achieve significant performance gains.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-15.451421737670898, -3.2908565998077393]}, {"key": "", "year": "", "title": "Zheng2023building", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Building K-Anonymous User Cohorts with\\\\ Consecutive Consistent Weighted Sampling (CCWS)\"\nauthors: Zheng Xinyi, Zhao Weijie, Li Xiaoyun, Li Ping\nconference: Arxiv\nyear: 2023\nbibkey: zheng2023building\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2304.13677\"}\ntags: ['ARXIV']\n---\nTo retrieve personalized campaigns and creatives while protecting user privacy, digital advertising is shifting from member-based identity to cohort-based identity. Under such identity regime, an accurate and efficient cohort building algorithm is desired to group users with similar characteristics. In this paper, we propose a scalable $K$-anonymous cohort building algorithm called {\\em consecutive consistent weighted sampling} (CCWS). The proposed method combines the spirit of the ($p$-powered) consistent weighted sampling and hierarchical clustering, so that the $K$-anonymity is ensured by enforcing a lower bound on the size of cohorts. Evaluations on a LinkedIn dataset consisting of $&gt;70$M users and ads campaigns demonstrate that CCWS achieves substantial improvements over several hashing-based methods including sign random projections (SignRP), minwise hashing (MinHash), as well as the vanilla CWS.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [2.0770373344421387, -2.478419542312622]}, {"key": "", "year": "", "title": "Zhong2015a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Deep Hashing Learning Network\"\nauthors: Zhong Guoqiang, Yang Pan, Wang Sijiang, Dong Junyu\nconference: Arxiv\nyear: 2015\nbibkey: zhong2015a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1507.04437\"}\ntags: ['ARXIV', 'Quantisation', 'Supervised']\n---\nHashing-based methods seek compact and efficient binary codes that preserve the neighborhood structure in the original data space. For most existing hashing methods, an image is first encoded as a vector of hand-crafted visual feature, followed by a hash projection and quantization step to get the compact binary vector. Most of the hand-crafted features just encode the low-level information of the input, the feature may not preserve the semantic similarities of images pairs. Meanwhile, the hashing function learning process is independent with the feature representation, so the feature may not be optimal for the hashing projection. In this paper, we propose a supervised hashing method based on a well designed deep convolutional neural network, which tries to learn hashing code and compact representations of data simultaneously. The proposed model learn the binary codes by adding a compact sigmoid layer before the loss layer. Experiments on several image data sets show that the proposed model outperforms other state-of-the-art methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [4.357062816619873, 3.600363254547119]}, {"key": "", "year": "", "title": "Zhong2015efficient", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Efficient Similarity Indexing and Searching in High Dimensions\"\nauthors: Zhong Yu\nconference: Arxiv\nyear: 2015\nbibkey: zhong2015efficient\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1505.03090\"}\ntags: ['ARXIV']\n---\nEfficient indexing and searching of high dimensional data has been an area of active research due to the growing exploitation of high dimensional data and the vulnerability of traditional search methods to the curse of dimensionality. This paper presents a new approach for fast and effective searching and indexing of high dimensional features using random partitions of the feature space. Experiments on both handwritten digits and 3-D shape descriptors have shown the proposed algorithm to be highly effective and efficient in indexing and searching real data sets of several hundred dimensions. We also compare its performance to that of the state-of-the-art locality sensitive hashing algorithm.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [6.501530647277832, -10.172253608703613]}, {"key": "", "year": "", "title": "Zhong2020compact", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Compact Deep Aggregation for Set Retrieval\"\nauthors: Zhong Yujie, Arandjelovi\u0107 Relja, Zisserman Andrew\nconference: Arxiv\nyear: 2020\nbibkey: zhong2020compact\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2003.11794\"}\ntags: ['ARXIV', 'CNN', 'TIP', 'Text Retrieval']\n---\nThe objective of this work is to learn a compact embedding of a set of descriptors that is suitable for efficient retrieval and ranking, whilst maintaining discriminability of the individual descriptors. We focus on a specific example of this general problem -- that of retrieving images containing multiple faces from a large scale dataset of images. Here the set consists of the face descriptors in each image, and given a query for multiple identities, the goal is then to retrieve, in order, images which contain all the identities, all but one, \\etc To this end, we make the following contributions: first, we propose a CNN architecture -- {\\em SetNet} -- to achieve the objective: it learns face descriptors and their aggregation over a set to produce a compact fixed length descriptor designed for set retrieval, and the score of an image is a count of the number of identities that match the query; second, we show that this compact descriptor has minimal loss of discriminability up to two faces per image, and degrades slowly after that -- far exceeding a number of baselines; third, we explore the speed vs.\\ retrieval quality trade-off for set retrieval using this compact descriptor; and, finally, we collect and annotate a large dataset of images containing various number of celebrities, which we use for evaluation and is publicly released.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [12.591778755187988, 16.482364654541016]}, {"key": "", "year": "", "title": "Zhornyak2022hashencoding", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"HashEncoding: Autoencoding with Multiscale Coordinate Hashing\"\nauthors: Zhornyak Lukas, Xu Zhengjie, Tang Haoran, Shi Jianbo\nconference: Arxiv\nyear: 2022\nbibkey: zhornyak2022hashencoding\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2211.15894\"}\ntags: ['ARXIV']\n---\nWe present HashEncoding, a novel autoencoding architecture that leverages a non-parametric multiscale coordinate hash function to facilitate a per-pixel decoder without convolutions. By leveraging the space-folding behaviour of hashing functions, HashEncoding allows for an inherently multiscale embedding space that remains much smaller than the original image. As a result, the decoder requires very few parameters compared with decoders in traditional autoencoders, approaching a non-parametric reconstruction of the original image and allowing for greater generalizability. Finally, by allowing backpropagation directly to the coordinate space, we show that HashEncoding can be exploited for geometric tasks such as optical flow.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-29.282018661499023, -9.692161560058594]}, {"key": "", "year": "", "title": "Zhou2016transfer", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Transfer Hashing with Privileged Information\"\nauthors: Zhou Joey Tianyi, Xu Xinxing, Pan Sinno Jialin, Tsang Ivor W., Qin Zheng, Goh Rick Siow Mong\nconference: Arxiv\nyear: 2016\nbibkey: zhou2016transfer\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1605.04034\"}\ntags: ['ARXIV', 'Quantisation']\n---\nMost existing learning to hash methods assume that there are sufficient data, either labeled or unlabeled, on the domain of interest (i.e., the target domain) for training. However, this assumption cannot be satisfied in some real-world applications. To address this data sparsity issue in hashing, inspired by transfer learning, we propose a new framework named Transfer Hashing with Privileged Information (THPI). Specifically, we extend the standard learning to hash method, Iterative Quantization (ITQ), in a transfer learning manner, namely ITQ+. In ITQ+, a new slack function is learned from auxiliary data to approximate the quantization error in ITQ. We developed an alternating optimization approach to solve the resultant optimization problem for ITQ+. We further extend ITQ+ to LapITQ+ by utilizing the geometry structure among the auxiliary data for learning more precise binary codes in the target domain. Extensive experiments on several benchmark datasets verify the effectiveness of our proposed approaches through comparisons with several state-of-the-art baselines.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-12.871332168579102, 12.568506240844727]}, {"key": "", "year": "", "title": "Zhou2017deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Hashing with Triplet Quantization Loss\"\nauthors: Zhou Yuefu, Huang Shanshan, Zhang Ya, Wang Yanfeng\nconference: Arxiv\nyear: 2017\nbibkey: zhou2017deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1710.11445\"}\ntags: ['ARXIV', 'Image Retrieval', 'Quantisation']\n---\nWith the explosive growth of image databases, deep hashing, which learns compact binary descriptors for images, has become critical for fast image retrieval. Many existing deep hashing methods leverage quantization loss, defined as distance between the features before and after quantization, to reduce the error from binarizing features. While minimizing the quantization loss guarantees that quantization has minimal effect on retrieval accuracy, it unfortunately significantly reduces the expressiveness of features even before the quantization. In this paper, we show that the above definition of quantization loss is too restricted and in fact not necessary for maintaining high retrieval accuracy. We therefore propose a new form of quantization loss measured in triplets. The core idea of the triplet quantization loss is to learn discriminative real-valued descriptors which lead to minimal loss on retrieval accuracy after quantization. Extensive experiments on two widely used benchmark data sets of different scales, CIFAR-10 and In-shop, demonstrate that the proposed method outperforms the state-of-the-art deep hashing methods. Moreover, we show that the compact binary descriptors obtained with triplet quantization loss lead to very small performance drop after quantization.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-0.35186898708343506, 8.267475128173828]}, {"key": "", "year": "", "title": "Zhou2023marvel", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"MARVEL: Unlocking the Multi-Modal Capability of Dense Retrieval via Visual Module Plugin\"\nauthors: Zhou Tianshuo, Mei Sen, Li Xinze, Liu Zhenghao, Xiong Chenyan, Liu Zhiyuan, Gu Yu, Yu Ge\nconference: Arxiv\nyear: 2023\nbibkey: zhou2023marvel\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2310.14037\"}   - {name: \"Code\", url: \"https://github.com/OpenMatch/MARVEL.\"}\ntags: ['ARXIV', 'Text Retrieval']\n---\nThis paper proposes Multi-modAl Retrieval model via Visual modulE pLugin (MARVEL), which learns an embedding space for queries and multi-modal documents to conduct retrieval. MARVEL encodes queries and multi-modal documents with a unified encoder model, which helps to alleviate the modality gap between images and texts. Specifically, we enable the image understanding ability of the well-trained dense retriever, T5-ANCE, by incorporating the visual module's encoded image features as its inputs. To facilitate the multi-modal retrieval tasks, we build the ClueWeb22-MM dataset based on the ClueWeb22 dataset, which regards anchor texts as queries, and extracts the related text and image documents from anchor-linked web pages. Our experiments show that MARVEL significantly outperforms the state-of-the-art methods on the multi-modal retrieval dataset WebQA and ClueWeb22-MM. MARVEL provides an opportunity to broaden the advantages of text retrieval to the multi-modal scenario. Besides, we also illustrate that the language model has the ability to extract image semantics and partly map the image features to the input word embedding space. All codes are available at https://github.com/OpenMatch/MARVEL.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [0.8295145034790039, 18.087915420532227]}, {"key": "", "year": "", "title": "Zhou2024semi", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Semi-Parametric Retrieval via Binary Token Index\"\nauthors: Zhou Jiawei, Dong Li, Wei Furu, Chen Lei\nconference: Arxiv\nyear: 2024\nbibkey: zhou2024semi\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2405.01924\"}\ntags: ['ARXIV']\n---\nThe landscape of information retrieval has broadened from search services to a critical component in various advanced applications, where indexing efficiency, cost-effectiveness, and freshness are increasingly important yet remain less explored. To address these demands, we introduce Semi-parametric Vocabulary Disentangled Retrieval (SVDR). SVDR is a novel semi-parametric retrieval framework that supports two types of indexes: an embedding-based index for high effectiveness, akin to existing neural retrieval methods; and a binary token index that allows for quick and cost-effective setup, resembling traditional term-based retrieval. In our evaluation on three open-domain question answering benchmarks with the entire Wikipedia as the retrieval corpus, SVDR consistently demonstrates superiority. It achieves a 3% higher top-1 retrieval accuracy compared to the dense retriever DPR when using an embedding-based index and an 9% higher top-1 accuracy compared to BM25 when using a binary token index. Specifically, the adoption of a binary token index reduces index preparation time from 30 GPU hours to just 2 CPU hours and storage size from 31 GB to 2 GB, achieving a 90% reduction compared to an embedding-based index.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [3.4130730628967285, -7.945956230163574]}, {"key": "", "year": "", "title": "Zhu2016radon", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Radon Features and Barcodes for Medical Image Retrieval via SVM\"\nauthors: Zhu Shujin, Tizhoosh H. R.\nconference: Arxiv\nyear: 2016\nbibkey: zhu2016radon\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1604.04675\"}\ntags: ['ARXIV', 'Image Retrieval']\n---\nFor more than two decades, research has been performed on content-based image retrieval (CBIR). By combining Radon projections and the support vector machines (SVM), a content-based medical image retrieval method is presented in this work. The proposed approach employs the normalized Radon projections with corresponding image category labels to build an SVM classifier, and the Radon barcode database which encodes every image in a binary format is also generated simultaneously to tag all images. To retrieve similar images when a query image is given, Radon projections and the barcode of the query image are generated. Subsequently, the k-nearest neighbor search method is applied to find the images with minimum Hamming distance of the Radon barcode within the same class predicted by the trained SVM classifier that uses Radon features. The performance of the proposed method is validated by using the IRMA 2009 dataset with 14,410 x-ray images in 57 categories. The results demonstrate that our method has the capacity to retrieve similar responses for the correctly identified query image and even for those mistakenly classified by SVM. The approach further is very fast and has low memory requirement.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [28.25865936279297, 21.182945251464844]}, {"key": "", "year": "", "title": "Zhu2017discrete", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Discrete Multi-modal Hashing with Canonical Views for Robust Mobile Landmark Search\"\nauthors: Zhu Lei, Huang Zi, Liu Xiaobai, He Xiangnan, Song Jingkuan, Zhou Xiaofang\nconference: Arxiv\nyear: 2017\nbibkey: zhu2017discrete\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1707.04047\"}\ntags: ['ARXIV', 'TIP']\n---\nMobile landmark search (MLS) recently receives increasing attention for its great practical values. However, it still remains unsolved due to two important challenges. One is high bandwidth consumption of query transmission, and the other is the huge visual variations of query images sent from mobile devices. In this paper, we propose a novel hashing scheme, named as canonical view based discrete multi-modal hashing (CV-DMH), to handle these problems via a novel three-stage learning procedure. First, a submodular function is designed to measure visual representativeness and redundancy of a view set. With it, canonical views, which capture key visual appearances of landmark with limited redundancy, are efficiently discovered with an iterative mining strategy. Second, multi-modal sparse coding is applied to transform visual features from multiple modalities into an intermediate representation. It can robustly and adaptively characterize visual contents of varied landmark images with certain canonical views. Finally, compact binary codes are learned on intermediate representation within a tailored discrete binary embedding model which preserves visual relations of images measured with canonical views and removes the involved noises. In this part, we develop a new augmented Lagrangian multiplier (ALM) based optimization method to directly solve the discrete binary codes. We can not only explicitly deal with the discrete constraint, but also consider the bit-uncorrelated constraint and balance constraint together. Experiments on real world landmark datasets demonstrate the superior performance of CV-DMH over several state-of-the-art methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-4.9893879890441895, 7.3535475730896]}, {"key": "", "year": "", "title": "Zhu2017part", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Part-based Deep Hashing for Large-scale Person Re-identification\"\nauthors: Zhu Fuqing, Kong Xiangwei, Zheng Liang, Fu Haiyan, Tian Qi\nconference: Arxiv\nyear: 2017\nbibkey: zhu2017part\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1705.02145\"}\ntags: ['ARXIV', 'Deep Learning']\n---\nLarge-scale is a trend in person re-identification (re-id). It is important that real-time search be performed in a large gallery. While previous methods mostly focus on discriminative learning, this paper makes the attempt in integrating deep learning and hashing into one framework to evaluate the efficiency and accuracy for large-scale person re-id. We integrate spatial information for discriminative visual representation by partitioning the pedestrian image into horizontal parts. Specifically, Part-based Deep Hashing (PDH) is proposed, in which batches of triplet samples are employed as the input of the deep hashing architecture. Each triplet sample contains two pedestrian images (or parts) with the same identity and one pedestrian image (or part) of the different identity. A triplet loss function is employed with a constraint that the Hamming distance of pedestrian images (or parts) with the same identity is smaller than ones with the different identity. In the experiment, we show that the proposed Part-based Deep Hashing method yields very competitive re-id accuracy on the large-scale Market-1501 and Market-1501+500K datasets.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [11.488909721374512, 1.9871219396591187]}, {"key": "", "year": "", "title": "Zhu2019exploring", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Exploring Auxiliary Context: Discrete Semantic Transfer Hashing for Scalable Image Retrieval\"\nauthors: Zhu Lei, Huang Zi, Li Zhihui, Xie Liang, Shen Heng Tao\nconference: Arxiv\nyear: 2019\nbibkey: zhu2019exploring\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1904.11207\"}\ntags: ['ARXIV', 'Image Retrieval', 'Supervised', 'TIP', 'Unsupervised']\n---\nUnsupervised hashing can desirably support scalable content-based image retrieval (SCBIR) for its appealing advantages of semantic label independence, memory and search efficiency. However, the learned hash codes are embedded with limited discriminative semantics due to the intrinsic limitation of image representation. To address the problem, in this paper, we propose a novel hashing approach, dubbed as \\emph{Discrete Semantic Transfer Hashing} (DSTH). The key idea is to \\emph{directly} augment the semantics of discrete image hash codes by exploring auxiliary contextual modalities. To this end, a unified hashing framework is formulated to simultaneously preserve visual similarities of images and perform semantic transfer from contextual modalities. Further, to guarantee direct semantic transfer and avoid information loss, we explicitly impose the discrete constraint, bit--uncorrelation constraint and bit-balance constraint on hash codes. A novel and effective discrete optimization method based on augmented Lagrangian multiplier is developed to iteratively solve the optimization problem. The whole learning process has linear computation complexity and desirable scalability. Experiments on three benchmark datasets demonstrate the superiority of DSTH compared with several state-of-the-art approaches.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-4.079963207244873, 7.760610580444336]}, {"key": "", "year": "", "title": "Zhu2020dual", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Dual-level Semantic Transfer Deep Hashing for Efficient Social Image Retrieval\"\nauthors: Zhu Lei, Cui Hui, Cheng Zhiyong, Li Jingjing, Zhang Zheng\nconference: Arxiv\nyear: 2020\nbibkey: zhu2020dual\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2006.05586\"}   - {name: \"Code\", url: \"https://github.com/research2020-1/DSTDH\"}\ntags: ['ARXIV', 'Graph', 'Image Retrieval', 'Supervised', 'Unsupervised']\n---\nSocial network stores and disseminates a tremendous amount of user shared images. Deep hashing is an efficient indexing technique to support large-scale social image retrieval, due to its deep representation capability, fast retrieval speed and low storage cost. Particularly, unsupervised deep hashing has well scalability as it does not require any manually labelled data for training. However, owing to the lacking of label guidance, existing methods suffer from severe semantic shortage when optimizing a large amount of deep neural network parameters. Differently, in this paper, we propose a Dual-level Semantic Transfer Deep Hashing (DSTDH) method to alleviate this problem with a unified deep hash learning framework. Our model targets at learning the semantically enhanced deep hash codes by specially exploiting the user-generated tags associated with the social images. Specifically, we design a complementary dual-level semantic transfer mechanism to efficiently discover the potential semantics of tags and seamlessly transfer them into binary hash codes. On the one hand, instance-level semantics are directly preserved into hash codes from the associated tags with adverse noise removing. Besides, an image-concept hypergraph is constructed for indirectly transferring the latent high-order semantic correlations of images and tags into hash codes. Moreover, the hash codes are obtained simultaneously with the deep representation learning by the discrete hash optimization strategy. Extensive experiments on two public social image retrieval datasets validate the superior performance of our method compared with state-of-the-art hashing methods. The source codes of our method can be obtained at https://github.com/research2020-1/DSTDH\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-5.507120132446289, 9.144691467285156]}, {"key": "", "year": "", "title": "Zhu2022a", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"A Lower Bound of Hash Codes' Performance\"\nauthors: Zhu Xiaosu, Song Jingkuan, Lei Yu, Gao Lianli, Shen Heng Tao\nconference: Arxiv\nyear: 2022\nbibkey: zhu2022a\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2210.05899\"}   - {name: \"Code\", url: \"https://github.com/VL-Group/LBHash.\"}\ntags: ['ARXIV']\n---\nAs a crucial approach for compact representation learning, hashing has achieved great success in effectiveness and efficiency. Numerous heuristic Hamming space metric learning objectives are designed to obtain high-quality hash codes. Nevertheless, a theoretical analysis of criteria for learning good hash codes remains largely unexploited. In this paper, we prove that inter-class distinctiveness and intra-class compactness among hash codes determine the lower bound of hash codes' performance. Promoting these two characteristics could lift the bound and improve hash learning. We then propose a surrogate model to fully exploit the above objective by estimating the posterior of hash codes and controlling it, which results in a low-bias optimization. Extensive experiments reveal the effectiveness of the proposed method. By testing on a series of hash-models, we obtain performance improvements among all of them, with an up to $26.5\\%$ increase in mean Average Precision and an up to $20.5\\%$ increase in accuracy. Our code is publicly available at https://github.com/VL-Group/LBHash.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-16.691410064697266, 2.047964572906494]}, {"key": "", "year": "", "title": "Zhu2023central", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Central Similarity Multi-View Hashing for Multimedia Retrieval\"\nauthors: Zhu Jian, Cheng Wen, Cui Yu, Tang Chang, Dai Yuyang, Li Yong, Zeng Lingfang\nconference: Arxiv\nyear: 2023\nbibkey: zhu2023central\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2308.13774\"}\ntags: ['ARXIV']\n---\nHash representation learning of multi-view heterogeneous data is the key to improving the accuracy of multimedia retrieval. However, existing methods utilize local similarity and fall short of deeply fusing the multi-view features, resulting in poor retrieval accuracy. Current methods only use local similarity to train their model. These methods ignore global similarity. Furthermore, most recent works fuse the multi-view features via a weighted sum or concatenation. We contend that these fusion methods are insufficient for capturing the interaction between various views. We present a novel Central Similarity Multi-View Hashing (CSMVH) method to address the mentioned problems. Central similarity learning is used for solving the local similarity problem, which can utilize the global similarity between the hash center and samples. We present copious empirical data demonstrating the superiority of gate-based fusion over conventional approaches. On the MS COCO and NUS-WIDE, the proposed CSMVH performs better than the state-of-the-art methods by a large margin (up to 11.41% mean Average Precision (mAP) improvement).\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-13.139721870422363, 1.2329987287521362]}, {"key": "", "year": "", "title": "Zhu2023clip", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"CLIP Multi-modal Hashing: A new baseline CLIPMH\"\nauthors: Zhu Jian, Sheng Mingkai, Ke Mingda, Huang Zhangmin, Chang Jingfei\nconference: Arxiv\nyear: 2023\nbibkey: zhu2023clip\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2308.11797\"}\ntags: ['ARXIV', 'Supervised', 'Unsupervised']\n---\nThe multi-modal hashing method is widely used in multimedia retrieval. It can fuse multi-source data to generate binary hash code. However, the current multi-modal methods have the problem of low retrieval accuracy. The reason is that the individual backbone networks have limited feature expression capabilities and are not jointly pre-trained on large-scale unsupervised multi-modal data. To solve this problem, we propose a new baseline CLIP Multi-modal Hashing (CLIPMH) method. It uses CLIP model to extract text and image features, and then fuse to generate hash code. CLIP improves the expressiveness of each modal feature. In this way, it can greatly improve the retrieval performance of multi-modal hashing methods. In comparison to state-of-the-art unsupervised and supervised multi-modal hashing methods, experiments reveal that the proposed CLIPMH can significantly enhance performance (Maximum increase of 8.38%). CLIP also has great advantages over the text and visual backbone networks commonly used before.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-13.219719886779785, 1.9408921003341675]}, {"key": "", "year": "", "title": "Zhu2023deep", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Deep Metric Multi-View Hashing for Multimedia Retrieval\"\nauthors: Zhu Jian, Huang Zhangmin, Ruan Xiaohu, Cui Yu, Cheng Yongli, Zeng Lingfang\nconference: Arxiv\nyear: 2023\nbibkey: zhu2023deep\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2304.06358\"}\ntags: ['ARXIV']\n---\nLearning the hash representation of multi-view heterogeneous data is an important task in multimedia retrieval. However, existing methods fail to effectively fuse the multi-view features and utilize the metric information provided by the dissimilar samples, leading to limited retrieval precision. Current methods utilize weighted sum or concatenation to fuse the multi-view features. We argue that these fusion methods cannot capture the interaction among different views. Furthermore, these methods ignored the information provided by the dissimilar samples. We propose a novel deep metric multi-view hashing (DMMVH) method to address the mentioned problems. Extensive empirical evidence is presented to show that gate-based fusion is better than typical methods. We introduce deep metric learning to the multi-view hashing problems, which can utilize metric information of dissimilar samples. On the MIR-Flickr25K, MS COCO, and NUS-WIDE, our method outperforms the current state-of-the-art methods by a large margin (up to 15.28 mean Average Precision (mAP) improvement).\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-13.233588218688965, 1.3935601711273193]}, {"key": "", "year": "", "title": "Zhu2024fast", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Fast Exact Retrieval for Nearest-neighbor Lookup (FERN)\"\nauthors: Zhu Richard\nconference: Arxiv\nyear: 2024\nbibkey: zhu2024fast\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2405.04435\"}   - {name: \"Code\", url: \"https://github.com/RichardZhu123/ferns}\"}\ntags: ['ARXIV', 'GAN']\n---\nExact nearest neighbor search is a computationally intensive process, and even its simpler sibling -- vector retrieval -- can be computationally complex. This is exacerbated when retrieving vectors which have high-dimension $d$ relative to the number of vectors, $N$, in the database. Exact nearest neighbor retrieval has been generally acknowledged to be a $O(Nd)$ problem with no sub-linear solutions. Attention has instead shifted towards Approximate Nearest-Neighbor (ANN) retrieval techniques, many of which have sub-linear or even logarithmic time complexities. However, if our intuition from binary search problems (e.g. $d=1$ vector retrieval) carries, there ought to be a way to retrieve an organized representation of vectors without brute-forcing our way to a solution. For low dimension (e.g. $d=2$ or $d=3$ cases), \\texttt{kd-trees} provide a $O(d\\log N)$ algorithm for retrieval. Unfortunately the algorithm deteriorates rapidly to a $O(dN)$ solution at high dimensions (e.g. $k=128$), in practice. We propose a novel algorithm for logarithmic Fast Exact Retrieval for Nearest-neighbor lookup (FERN), inspired by \\texttt{kd-trees}. The algorithm achieves $O(d\\log N)$ look-up with 100\\% recall on 10 million $d=128$ uniformly randomly generated vectors.\\footnote{Code available at https://github.com/RichardZhu123/ferns}\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-6.814272880554199, -20.50877571105957]}, {"key": "", "year": "", "title": "Zhuang2023towards", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Towards Fast and Accurate Image-Text Retrieval with Self-Supervised Fine-Grained Alignment\"\nauthors: Zhuang Jiamin, Yu Jing, Ding Yang, Qu Xiangyan, Hu Yue\nconference: IEEE Transactions on Multimedia\nyear: 2023\nbibkey: zhuang2023towards\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2308.14009\"}   - {name: \"Code\", url: \"https://github.com/Zjamie813/SelfAlign.\"}\ntags: ['Cross Modal', 'Self Supervised', 'Supervised', 'Text Retrieval']\n---\nImage-text retrieval requires the system to bridge the heterogenous gap between vision and language for accurate retrieval while keeping the network lightweight-enough for efficient retrieval. Existing trade-off solutions mainly study from the view of incorporating cross-modal interactions with the independent-embedding framework or leveraging stronger pretrained encoders, which still demand time-consuming similarity measurement or heavyweight model structure in the retrieval stage. In this work, we propose an image-text alignment module SelfAlign on top of the independent-embedding framework, which improves the retrieval accuracy while maintains the retrieval efficiency without extra supervision. SelfAlign contains two collaborative sub-modules that force image-text alignment at both concept level and context level by self-supervised contrastive learning. It does not require cross-modal embedding interactions during training while maintaining independent image and text encoders during retrieval. With comparable time cost, SelfAlign consistently boosts the accuracy of state-of-the-art non-pretraining independent-embedding models respectively by 9.1%, 4.2% and 6.6% in terms of R@sum score on Flickr30K, MSCOCO 1K and MS-COCO 5K datasets. The retrieval accuracy also outperforms most existing interactive-embedding models with orders of magnitude decrease in retrieval time. The source code is available at: https://github.com/Zjamie813/SelfAlign.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [3.018974542617798, 15.123056411743164]}, {"key": "", "year": "", "title": "Zieba2018bingan", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"BinGAN: Learning Compact Binary Descriptors with a Regularized GAN\"\nauthors: Zieba Maciej, Semberecki Piotr, El-Gaaly Tarek, Trzcinski Tomasz\nconference: Arxiv\nyear: 2018\nbibkey: zieba2018bingan\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1806.06778\"}\ntags: ['ARXIV', 'GAN']\n---\nIn this paper, we propose a novel regularization method for Generative Adversarial Networks, which allows the model to learn discriminative yet compact binary representations of image patches (image descriptors). We employ the dimensionality reduction that takes place in the intermediate layers of the discriminator network and train binarized low-dimensional representation of the penultimate layer to mimic the distribution of the higher-dimensional preceding layers. To achieve this, we introduce two loss terms that aim at: (i) reducing the correlation between the dimensions of the binarized low-dimensional representation of the penultimate layer i. e. maximizing joint entropy) and (ii) propagating the relations between the dimensions in the high-dimensional space to the low-dimensional space. We evaluate the resulting binary image descriptors on two challenging applications, image matching and retrieval, and achieve state-of-the-art results.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [8.878480911254883, 2.3313794136047363]}, {"key": "", "year": "", "title": "Zou2019transductive", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Transductive Zero-Shot Hashing for Multilabel Image Retrieval\"\nauthors: Zou Qin, Zhang Zheng, Cao Ling, Chen Long, Wang Song\nconference: IEEE Transactions on Neural Networks and Learning Systems,\nyear: 2019\nbibkey: zou2019transductive\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/1911.07192\"}\ntags: ['Image Retrieval', 'Quantisation']\n---\nHash coding has been widely used in approximate nearest neighbor search for large-scale image retrieval. Given semantic annotations such as class labels and pairwise similarities of the training data, hashing methods can learn and generate effective and compact binary codes. While some newly introduced images may contain undefined semantic labels, which we call unseen images, zeor-shot hashing techniques have been studied. However, existing zeor-shot hashing methods focus on the retrieval of single-label images, and cannot handle multi-label images. In this paper, for the first time, a novel transductive zero-shot hashing method is proposed for multi-label unseen image retrieval. In order to predict the labels of the unseen/target data, a visual-semantic bridge is built via instance-concept coherence ranking on the seen/source data. Then, pairwise similarity loss and focal quantization loss are constructed for training a hashing model using both the seen/source and unseen/target data. Extensive evaluations on three popular multi-label datasets demonstrate that, the proposed hashing method achieves significantly better results than the competing methods.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-4.139157772064209, 13.718363761901855]}, {"key": "", "year": "", "title": "Zubarev2008wet", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Wet Paper Coding for Watermarking of Binary Images\"\nauthors: Zubarev Michail, Korzhik Valery, Morales-Luna Guillermo\nconference: Arxiv\nyear: 2008\nbibkey: zubarev2008wet\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/0808.2486\"}\ntags: ['ARXIV']\n---\nWe propose a new method to embed data in binary images, including scanned text, figures, and signatures. Our method relies on the concept of wet paper codes. The shuffling before embedding is used in order to equalize irregular embedding capacity from diverse areas in the image. The hidden data can be extracted without the original binary image. We illustrate some examples of watermarked binary images after wet paper coding.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [24.357351303100586, 0.11319812387228012]}, {"key": "", "year": "", "title": "\u00d1anculef2020self", "abstract": "<hr />\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>layout: publication\ntitle: \"Self-Supervised Bernoulli Autoencoders for Semi-Supervised Hashing\"\nauthors: \u00d1anculef Ricardo, Mena Francisco, Macaluso Antonio, Lodi Stefano, Sartori Claudio\nconference: Arxiv\nyear: 2020\nbibkey: \u00f1anculef2020self\nadditional_links:\n  - {name: \"Paper\", url: \"https://arxiv.org/abs/2007.08799\"}   - {name: \"Code\", url: \"https://github.com/amacaluso/SSB-VAE.\"}\ntags: ['ARXIV', 'Self Supervised', 'Semi Supervised', 'Supervised', 'Unsupervised']\n---\nSemantic hashing is an emerging technique for large-scale similarity search based on representing high-dimensional data using similarity-preserving binary codes used for efficient indexing and search. It has recently been shown that variational autoencoders, with Bernoulli latent representations parametrized by neural nets, can be successfully trained to learn such codes in supervised and unsupervised scenarios, improving on more traditional methods thanks to their ability to handle the binary constraints architecturally. However, the scenario where labels are scarce has not been studied yet. This paper investigates the robustness of hashing methods based on variational autoencoders to the lack of supervision, focusing on two semi-supervised approaches currently in use. The first augments the variational autoencoder's training objective to jointly model the distribution over the data and the class labels. The second approach exploits the annotations to define an additional pairwise loss that enforces consistency between the similarity in the code (Hamming) space and the similarity in the label space. Our experiments show that both methods can significantly increase the hash codes' quality. The pairwise approach can exhibit an advantage when the number of labelled points is large. However, we found that this method degrades quickly and loses its advantage when labelled samples decrease. To circumvent this problem, we propose a novel supervision method in which the model uses its label distribution predictions to implement the pairwise objective. Compared to the best baseline, this procedure yields similar performance in fully supervised settings but improves the results significantly when labelled data is scarce. Our code is made publicly available at https://github.com/amacaluso/SSB-VAE.\n</code></pre></div></div>\n", "tags": [], "tsne_embedding": [-7.638601303100586, 0.5035723447799683]}]