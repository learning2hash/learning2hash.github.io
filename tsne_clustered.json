[{"key": "2025scratch", "year": "2025", "citations": "110", "title": "SCRATCH: A Scalable Discrete Matrix Factorization Hashing For Cross-modal Retrieval", "abstract": "<p>In recent years, many hashing methods have been proposed for the cross-modal retrieval task. However, there are still some issues that need to be further explored. For example, some of them relax the binary constraints to generate the hash codes, which may generate large quantization error. Although some discrete schemes have been proposed, most of them are time-consuming. In addition, most of the existing supervised hashing methods use an n x n similarity matrix during the optimization, making them unscalable. To address these issues, in this paper, we present a novel supervised cross-modal hashing method\u2014Scalable disCRete mATrix faCtorization Hashing, SCRATCH for short. It leverages the collective matrix factorization on the kernelized features and the semantic embedding with labels to find a latent semantic space to preserve the intra- and inter-modality similarities. In addition, it incorporates the label matrix instead of the similarity matrix into the loss function. Based on the proposed loss function and the iterative optimization algorithm, it can learn the hash functions and binary codes simultaneously. Moreover, the binary codes can be generated discretely, reducing the quantization error generated by the relaxation scheme. Its time complexity is linear to the size of the dataset, making it scalable to large-scale datasets. Extensive experiments on three benchmark datasets, namely, Wiki, MIRFlickr-25K, and NUS-WIDE, have verified that our proposed SCRATCH model outperforms several state-of-the-art unsupervised and supervised hashing methods for cross-modal retrieval.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Compact Codes", "Alt", "Multimodal Retrieval", "Quantization", "Evaluation"], "tsne_embedding": [-6.205993175506592, -6.202737808227539], "cluster": 9}, {"key": "aalto2019metric", "year": "2019", "citations": "30", "title": "Metric Learning On Manifolds", "abstract": "<p>Recent literature has shown that symbolic data, such as text and graphs, is\noften better represented by points on a curved manifold, rather than in\nEuclidean space. However, geometrical operations on manifolds are generally\nmore complicated than in Euclidean space, and thus many techniques for\nprocessing and analysis taken for granted in Euclidean space are difficult on\nmanifolds. A priori, it is not obvious how we may generalize such methods to\nmanifolds. We consider specifically the problem of distance metric learning,\nand present a framework that solves it on a large class of manifolds, such that\nsimilar data are located in closer proximity with respect to the manifold\ndistance function. In particular, we extend the existing metric learning\nalgorithms, and derive the corresponding sample complexity rates for the case\nof manifolds. Additionally, we demonstrate an improvement of performance in\n\\(k\\)-means clustering and \\(k\\)-nearest neighbor classification on real-world\ncomplex networks using our methods.</p>\n", "tags": ["Tools & Libraries", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [6.880805015563965, 15.346193313598633], "cluster": 0}, {"key": "aamand2020no", "year": "2020", "citations": "22", "title": "No Repetition: Fast Streaming With Highly Concentrated Hashing", "abstract": "<p>To get estimators that work within a certain error bound with high\nprobability, a common strategy is to design one that works with constant\nprobability, and then boost the probability using independent repetitions.\nImportant examples of this approach are small space algorithms for estimating\nthe number of distinct elements in a stream, or estimating the set similarity\nbetween large sets. Using standard strongly universal hashing to process each\nelement, we get a sketch based estimator where the probability of a too large\nerror is, say, 1/4. By performing \\(r\\) independent repetitions and taking the\nmedian of the estimators, the error probability falls exponentially in \\(r\\).\nHowever, running \\(r\\) independent experiments increases the processing time by a\nfactor \\(r\\).\n  Here we make the point that if we have a hash function with strong\nconcentration bounds, then we get the same high probability bounds without any\nneed for repetitions. Instead of \\(r\\) independent sketches, we have a single\nsketch that is \\(r\\) times bigger, so the total space is the same. However, we\nonly apply a single hash function, so we save a factor \\(r\\) in time, and the\noverall algorithms just get simpler.\n  Fast practical hash functions with strong concentration bounds were recently\nproposed by Aamand em et al. (to appear in STOC 2020). Using their hashing\nschemes, the algorithms thus become very fast and practical, suitable for\nonline processing of high volume data streams.</p>\n", "tags": ["Hashing Methods"], "tsne_embedding": [-5.933004379272461, -24.46651268005371], "cluster": 5}, {"key": "aamand2024hashing", "year": "2024", "citations": "116", "title": "Hashing For Sampling-based Estimation", "abstract": "<p>Hash-based sampling and estimation are common themes in computing. Using\nhashing for sampling gives us the coordination needed to compare samples from\ndifferent sets. Hashing is also used when we want to count distinct elements.\nThe quality of the estimator for, say, the Jaccard similarity between two sets,\ndepends on the concentration of the number of sampled elements from their\nintersection. Often we want to compare one query set against many stored sets\nto find one of the most similar sets, so we need strong concentration and low\nerror-probability. In this paper, we provide strong explicit concentration\nbounds for Tornado Tabulation hashing [Bercea, Beretta, Klausen, Houen, and\nThorup, FOCS\u201923] which is a realistic constant time hashing scheme. Previous\nconcentration bounds for fast hashing were off by orders of magnitude, in the\nsample size needed to guarantee the same concentration. The true power of our\nresult appears when applied in the local uniformity framework by [Dahlgaard,\nKnudsen, Rotenberg, and Thorup, STOC\u201915].</p>\n", "tags": ["AAAI", "Tools & Libraries", "Hashing Methods"], "tsne_embedding": [13.852865219116211, -0.8175846338272095], "cluster": 4}, {"key": "abeywickrama2016k", "year": "2016", "citations": "25", "title": "K-nearest Neighbors On Road Networks: A Journey In Experimentation And In-memory Implementation", "abstract": "<p>A k nearest neighbor (kNN) query on road networks retrieves the k closest\npoints of interest (POIs) by their network distances from a given location.\nToday, in the era of ubiquitous mobile computing, this is a highly pertinent\nquery. While Euclidean distance has been used as a heuristic to search for the\nclosest POIs by their road network distance, its efficacy has not been\nthoroughly investigated. The most recent methods have shown significant\nimprovement in query performance. Earlier studies, which proposed disk-based\nindexes, were compared to the current state-of-the-art in main memory. However,\nrecent studies have shown that main memory comparisons can be challenging and\nrequire careful adaptation. This paper presents an extensive experimental\ninvestigation in main memory to settle these and several other issues. We use\nefficient and fair memory-resident implementations of each method to reproduce\npast experiments and conduct additional comparisons for several overlooked\nevaluations. Notably we revisit a previously discarded technique (IER) showing\nthat, through a simple improvement, it is often the best performing technique.</p>\n", "tags": ["Evaluation", "Distance Metric Learning"], "tsne_embedding": [14.930121421813965, -7.379689693450928], "cluster": 2}, {"key": "abulibdeh2020learned", "year": "2020", "citations": "8", "title": "Learned Indexes For A Google-scale Disk-based Database", "abstract": "<p>There is great excitement about learned index structures, but understandable\nskepticism about the practicality of a new method uprooting decades of research\non B-Trees. In this paper, we work to remove some of that uncertainty by\ndemonstrating how a learned index can be integrated in a distributed,\ndisk-based database system: Google\u2019s Bigtable. We detail several design\ndecisions we made to integrate learned indexes in Bigtable. Our results show\nthat integrating learned index significantly improves the end-to-end read\nlatency and throughput for Bigtable.</p>\n", "tags": ["Vector Indexing", "Efficiency And Optimization"], "tsne_embedding": [8.043931007385254, -9.67282485961914], "cluster": 2}, {"key": "adir2022privacy", "year": "2022", "citations": "5", "title": "Privacy-preserving Record Linkage Using Local Sensitive Hash And Private Set Intersection", "abstract": "<p>The amount of data stored in data repositories increases every year. This\nmakes it challenging to link records between different datasets across\ncompanies and even internally, while adhering to privacy regulations. Address\nor name changes, and even different spelling used for entity data, can prevent\ncompanies from using private deduplication or record-linking solutions such as\nprivate set intersection (PSI). To this end, we propose a new and efficient\nprivacy-preserving record linkage (PPRL) protocol that combines PSI and local\nsensitive hash (LSH) functions, and runs in linear time. We explain the privacy\nguarantees that our protocol provides and demonstrate its practicality by\nexecuting the protocol over two datasets with \\(2^{20}\\) records each, in \\(11-45\\)\nminutes, depending on network settings.</p>\n", "tags": ["Locality Sensitive Hashing", "DATASETS"], "tsne_embedding": [1.812232494354248, -24.517990112304688], "cluster": 5}, {"key": "agarwal2021dynamic", "year": "2021", "citations": "10", "title": "Dynamic Enumeration Of Similarity Joins", "abstract": "<p>This paper considers enumerating answers to similarity-join queries under\ndynamic updates: Given two sets of \\(n\\) points \\(A,B\\) in \\(\\mathbb{R}^d\\), a metric\n\\(\\phi(\\cdot)\\), and a distance threshold \\(r &gt; 0\\), report all pairs of points\n\\((a, b) \\in A \\times B\\) with \\(\\phi(a,b) \\le r\\). Our goal is to store \\(A,B\\) into\na dynamic data structure that, whenever asked, can enumerate all result pairs\nwith worst-case delay guarantee, i.e., the time between enumerating two\nconsecutive pairs is bounded. Furthermore, the data structure can be\nefficiently updated when a point is inserted into or deleted from \\(A\\) or \\(B\\).\n  We propose several efficient data structures for answering similarity-join\nqueries in low dimension. For exact enumeration of similarity join, we present\nnear-linear-size data structures for \\(\\ell_1, \\ell_\\infty\\) metrics with\n\\(log^{O(1)} n\\) update time and delay. We show that such a data structure is\nnot feasible for the \\(\u2113\u2082\\) metric for \\(d \\ge 4\\). For approximate enumeration\nof similarity join, where the distance threshold is a soft constraint, we\nobtain a unified linear-size data structure for \\(\\ell_p\\) metric, with\n\\(log^{O(1)} n\\) delay and update time. In high dimensions, we present an\nefficient data structure with worst-case delay-guarantee using locality\nsensitive hashing (LSH).</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Graph Based ANN"], "tsne_embedding": [31.186260223388672, 1.940872073173523], "cluster": 7}, {"key": "aghamolaei2023massively", "year": "2023", "citations": "33", "title": "Massively-parallel Heat Map Sorting And Applications To Explainable Clustering", "abstract": "<p>Given a set of points labeled with \\(k\\) labels, we introduce the heat map\nsorting problem as reordering and merging the points and dimensions while\npreserving the clusters (labels). A cluster is preserved if it remains\nconnected, i.e., if it is not split into several clusters and no two clusters\nare merged.\n  We prove the problem is NP-hard and we give a fixed-parameter algorithm with\na constant number of rounds in the massively parallel computation model, where\neach machine has a sublinear memory and the total memory of the machines is\nlinear. We give an approximation algorithm for a NP-hard special case of the\nproblem. We empirically compare our algorithm with k-means and density-based\nclustering (DBSCAN) using a dimensionality reduction via locality-sensitive\nhashing on several directed and undirected graphs of email and computer\nnetworks.</p>\n", "tags": ["Hashing Methods", "Evaluation"], "tsne_embedding": [23.010889053344727, -14.245540618896484], "cluster": 2}, {"key": "aghazadeh2020distributed", "year": "2020", "citations": "24", "title": "A Distributed Approximate Nearest Neighbor Method For Real-time Face Recognition", "abstract": "<p>Nowadays, face recognition and more generally image recognition have many\napplications in the modern world and are widely used in our daily tasks. This\npaper aims to propose a distributed approximate nearest neighbor (ANN) method\nfor real-time face recognition using a big dataset that involves a lot of\nclasses. The proposed approach is based on using a clustering method to\nseparate the dataset into different clusters and on specifying the importance\nof each cluster by defining cluster weights. To this end, reference instances\nare selected from each cluster based on the cluster weights using a maximum\nlikelihood approach. This process leads to a more informed selection of\ninstances, so it enhances the performance of the algorithm. Experimental\nresults confirm the efficiency of the proposed method and its out-performance\nin terms of accuracy and the processing time.</p>\n", "tags": ["CVPR", "DATASETS", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [9.342864990234375, 8.92326545715332], "cluster": 4}, {"key": "aguerrebere2023similarity", "year": "2023", "citations": "15", "title": "Similarity Search In The Blink Of An Eye With Compressed Indices", "abstract": "<p>Nowadays, data is represented by vectors. Retrieving those vectors, among\nmillions and billions, that are similar to a given query is a ubiquitous\nproblem, known as similarity search, of relevance for a wide range of\napplications. Graph-based indices are currently the best performing techniques\nfor billion-scale similarity search. However, their random-access memory\npattern presents challenges to realize their full potential. In this work, we\npresent new techniques and systems for creating faster and smaller graph-based\nindices. To this end, we introduce a novel vector compression method,\nLocally-adaptive Vector Quantization (LVQ), that uses per-vector scaling and\nscalar quantization to improve search performance with fast similarity\ncomputations and a reduced effective bandwidth, while decreasing memory\nfootprint and barely impacting accuracy. LVQ, when combined with a new\nhigh-performance computing system for graph-based similarity search,\nestablishes the new state of the art in terms of performance and memory\nfootprint. For billions of vectors, LVQ outcompetes the second-best\nalternatives: (1) in the low-memory regime, by up to 20.7x in throughput with\nup to a 3x memory footprint reduction, and (2) in the high-throughput regime by\n5.8x with 1.4x less memory.</p>\n", "tags": ["Graph Based ANN", "Efficiency And Optimization", "Large Scale Search", "Alt", "Similarity Search", "Quantization", "Evaluation"], "tsne_embedding": [19.503089904785156, 11.510761260986328], "cluster": 0}, {"key": "ahle2016parameter", "year": "2016", "citations": "19", "title": "Parameter-free Locality Sensitive Hashing For Spherical Range Reporting", "abstract": "<p>We present a data structure for <em>spherical range reporting</em> on a point set\n\\(S\\), i.e., reporting all points in \\(S\\) that lie within radius \\(r\\) of a given\nquery point \\(q\\). Our solution builds upon the Locality-Sensitive Hashing (LSH)\nframework of Indyk and Motwani, which represents the asymptotically best\nsolutions to near neighbor problems in high dimensions. While traditional LSH\ndata structures have several parameters whose optimal values depend on the\ndistance distribution from \\(q\\) to the points of \\(S\\), our data structure is\nparameter-free, except for the space usage, which is configurable by the user.\nNevertheless, its expected query time basically matches that of an LSH data\nstructure whose parameters have been <em>optimally chosen for the data and query</em>\nin question under the given space constraints. In particular, our data\nstructure provides a smooth trade-off between hard queries (typically addressed\nby standard LSH) and easy queries such as those where the number of points to\nreport is a constant fraction of \\(S\\), or where almost all points in \\(S\\) are far\naway from the query point. In contrast, known data structures fix LSH\nparameters based on certain parameters of the input alone.\n  The algorithm has expected query time bounded by \\(O(t (n/t)^\\rho)\\), where \\(t\\)\nis the number of points to report and \\(\\rho\\in (0,1)\\) depends on the data\ndistribution and the strength of the LSH family used. We further present a\nparameter-free way of using multi-probing, for LSH families that support it,\nand show that for many such families this approach allows us to get expected\nquery time close to \\(O(n^\\rho+t)\\), which is the best we can hope to achieve\nusing LSH. The previously best running time in high dimensions was \\(\u03a9(t\nn^\\rho)\\). For many data distributions where the intrinsic dimensionality of the\npoint set close to \\(q\\) is low, we can give improved upper bounds on the\nexpected query time.</p>\n", "tags": ["Locality Sensitive Hashing", "Tools & Libraries", "Hashing Methods", "Efficiency And Optimization"], "tsne_embedding": [31.315855026245117, 0.7549490928649902], "cluster": 7}, {"key": "ahle2017optimal", "year": "2017", "citations": "13", "title": "Optimal Las Vegas Locality Sensitive Data Structures", "abstract": "<p>We show that approximate similarity (near neighbour) search can be solved in\nhigh dimensions with performance matching state of the art (data independent)\nLocality Sensitive Hashing, but with a guarantee of no false negatives.\n  Specifically, we give two data structures for common problems.\n  For \\(c\\)-approximate near neighbour in Hamming space we get query time\n\\(dn^{1/c+o(1)}\\) and space \\(dn^{1+1/c+o(1)}\\) matching that of\n\\cite{indyk1998approximate} and answering a long standing open question\nfrom~\\cite{indyk2000dimensionality} and~\\cite{pagh2016locality} in the\naffirmative.\n  By means of a new deterministic reduction from \\(\\ell_1\\) to Hamming we also\nsolve \\(\\ell_1\\) and \\(\u2113\u2082\\) with query time \\(d^2n^{1/c+o(1)}\\) and space \\(d^2\nn^{1+1/c+o(1)}\\).\n  For \\((s_1,s_2)\\)-approximate Jaccard similarity we get query time\n\\(dn^{\\rho+o(1)}\\) and space \\(dn^{1+\\rho+o(1)}\\),\n\\(\\rho=log\\frac{1+s_1}{2s_1}\\big/log\\frac{1+s_2}{2s_2}\\), when sets have equal\nsize, matching the performance of~\\cite{tobias2016}.\n  The algorithms are based on space partitions, as with classic LSH, but we\nconstruct these using a combination of brute force, tensoring, perfect hashing\nand splitter functions `a la~\\cite{naor1995splitters}. We also show a new\ndimensionality reduction lemma with 1-sided error.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Graph Based ANN", "Efficiency And Optimization", "Evaluation"], "tsne_embedding": [30.689733505249023, -0.38905069231987], "cluster": 7}, {"key": "ahle2019subsets", "year": "2019", "citations": "5", "title": "Subsets And Supermajorities: Optimal Hashing-based Set Similarity Search", "abstract": "<p>We formulate and optimally solve a new generalized Set Similarity Search\nproblem, which assumes the size of the database and query sets are known in\nadvance. By creating polylog copies of our data-structure, we optimally solve\nany symmetric Approximate Set Similarity Search problem, including approximate\nversions of Subset Search, Maximum Inner Product Search (MIPS), Jaccard\nSimilarity Search and Partial Match.\n  Our algorithm can be seen as a natural generalization of previous work on Set\nas well as Euclidean Similarity Search, but conceptually it differs by\noptimally exploiting the information present in the sets as well as their\ncomplements, and doing so asymmetrically between queries and stored sets. Doing\nso we improve upon the best previous work: MinHash [J. Discrete Algorithms\n1998], SimHash [STOC 2002], Spherical LSF [SODA 2016, 2017] and Chosen Path\n[STOC 2017] by as much as a factor \\(n^{0.14}\\) in both time and space; or in the\nnear-constant time regime, in space, by an arbitrarily large polynomial factor.\n  Turning the geometric concept, based on Boolean supermajority functions, into\na practical algorithm requires ideas from branching random walks on \\(\\mathbb\nZ^2\\), for which we give the first non-asymptotic near tight analysis.\n  Our lower bounds follow from new hypercontractive arguments, which can be\nseen as characterizing the exact family of similarity search problems for which\nsupermajorities are optimal. The optimality holds for among all hashing based\ndata structures in the random setting, and by reductions, for 1 cell and 2 cell\nprobe data structures. As a side effect, we obtain new hypercontractive bounds\non the directed noise operator \\(T^{p_1 \\to p_2}_\\rho\\).</p>\n", "tags": ["Locality Sensitive Hashing", "Similarity Search", "Hashing Methods"], "tsne_embedding": [28.766565322875977, 0.21207986772060394], "cluster": 7}, {"key": "aksoy2022satellite", "year": "2022", "citations": "8", "title": "Satellite Image Search In Agoraeo", "abstract": "<p>The growing operational capability of global Earth Observation (EO) creates\nnew opportunities for data-driven approaches to understand and protect our\nplanet. However, the current use of EO archives is very restricted due to the\nhuge archive sizes and the limited exploration capabilities provided by EO\nplatforms. To address this limitation, we have recently proposed MiLaN, a\ncontent-based image retrieval approach for fast similarity search in satellite\nimage archives. MiLaN is a deep hashing network based on metric learning that\nencodes high-dimensional image features into compact binary hash codes. We use\nthese codes as keys in a hash table to enable real-time nearest neighbor search\nand highly accurate retrieval. In this demonstration, we showcase the\nefficiency of MiLaN by integrating it with EarthQube, a browser and search\nengine within AgoraEO. EarthQube supports interactive visual exploration and\nQuery-by-Example over satellite image repositories. Demo visitors will interact\nwith EarthQube playing the role of different users that search images in a\nlarge-scale remote sensing archive by their semantic content and apply other\nfilters.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Efficiency And Optimization", "Distance Metric Learning", "Neural Hashing", "Similarity Search"], "tsne_embedding": [1.819919228553772, 17.466838836669922], "cluster": 6}, {"key": "albrecht2015genoogle", "year": "2015", "citations": "9", "title": "Genoogle: An Indexed And Parallelized Search Engine For Similar DNA Sequences", "abstract": "<p>The search for similar genetic sequences is one of the main bioinformatics\ntasks. The genetic sequences data banks are growing exponentially and the\nsearching techniques that use linear time are not capable to do the search in\nthe required time anymore. Another problem is that the clock speed of the\nmodern processors are not growing as it did before, instead, the processing\ncapacity is growing with the addiction of more processing cores and the\ntechniques which does not use parallel computing does not have benefits from\nthese extra cores. This work aims to use data indexing techniques to reduce the\nsearching process computation cost united with the parallelization of the\nsearching techniques to use the computational capacity of the multi core\nprocessors. To verify the viability of using these two techniques\nsimultaneously, a software which uses parallelization techniques with inverted\nindexes was developed.\n  Experiments were executed to analyze the performance gain when parallelism is\nutilized, the search time gain, and also the quality of the results when it\ncompared with others searching tools. The results of these experiments were\npromising, the parallelism gain overcame the expected speedup, the searching\ntime was 20 times faster than the parallelized NCBI BLAST, and the searching\nresults showed a good quality when compared with this tool.\n  The software source code is available at\nhttps://github.com/felipealbrecht/Genoogle .</p>\n", "tags": ["Evaluation", "Efficiency And Optimization"], "tsne_embedding": [8.822945594787598, -18.959482192993164], "cluster": 2}, {"key": "alemu2018multi", "year": "2018", "citations": "23", "title": "Multi-feature Fusion For Image Retrieval Using Constrained Dominant Sets", "abstract": "<p>Aggregating different image features for image retrieval has recently shown\nits effectiveness. While highly effective, though, the question of how to\nuplift the impact of the best features for a specific query image persists as\nan open computer vision problem. In this paper, we propose a computationally\nefficient approach to fuse several hand-crafted and deep features, based on the\nprobabilistic distribution of a given membership score of a constrained cluster\nin an unsupervised manner. First, we introduce an incremental nearest neighbor\n(NN) selection method, whereby we dynamically select k-NN to the query. We then\nbuild several graphs from the obtained NN sets and employ constrained dominant\nsets (CDS) on each graph G to assign edge weights which consider the intrinsic\nmanifold structure of the graph, and detect false matches to the query.\nFinally, we elaborate the computation of feature positive-impact weight (PIW)\nbased on the dispersive degree of the characteristics vector. To this end, we\nexploit the entropy of a cluster membership-score distribution. In addition,\nthe final NN set bypasses a heuristic voting scheme. Experiments on several\nretrieval benchmark datasets show that our method can improve the\nstate-of-the-art result.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Evaluation"], "tsne_embedding": [14.957544326782227, 10.710346221923828], "cluster": 0}, {"key": "ali2020cross", "year": "2020", "citations": "10", "title": "Cross Hashing: Anonymizing Encounters In Decentralised Contact Tracing Protocols", "abstract": "<p>During the COVID-19 (SARS-CoV-2) epidemic, Contact Tracing emerged as an\nessential tool for managing the epidemic. App-based solutions have emerged for\nContact Tracing, including a protocol designed by Apple and Google (influenced\nby an open-source protocol known as DP3T). This protocol contains two\nwell-documented de-anonymisation attacks. Firstly that when someone is marked\nas having tested positive and their keys are made public, they can be tracked\nover a large geographic area for 24 hours at a time. Secondly, whilst the app\nrequires a minimum exposure duration to register a contact, there is no\ncryptographic guarantee for this property. This means an adversary can scan\nBluetooth networks and retrospectively find who is infected. We propose a novel\n\u201ccross hashing\u201d approach to cryptographically guarantee minimum exposure\ndurations. We further mitigate the 24-hour data exposure of infected\nindividuals and reduce computational time for identifying if a user has been\nexposed using \\(k\\)-Anonymous buckets of hashes and Private Set Intersection. We\nempirically demonstrate that this modified protocol can offer like-for-like\nefficacy to the existing protocol.</p>\n", "tags": ["Hashing Methods"], "tsne_embedding": [3.58131742477417, -25.12234878540039], "cluster": 5}, {"key": "alparslan2020towards", "year": "2020", "citations": "15", "title": "Towards Evaluating Gaussian Blurring In Perceptual Hashing As A Facial Image Filter", "abstract": "<p>With the growth in social media, there is a huge amount of images of faces\navailable on the internet. Often, people use other people\u2019s pictures on their\nown profile. Perceptual hashing is often used to detect whether two images are\nidentical. Therefore, it can be used to detect whether people are misusing\nothers\u2019 pictures. In perceptual hashing, a hash is calculated for a given\nimage, and a new test image is mapped to one of the existing hashes if\nduplicate features are present. Therefore, it can be used as an image filter to\nflag banned image content or adversarial attacks \u2013which are modifications that\nare made on purpose to deceive the filter\u2013 even though the content might be\nchanged to deceive the filters. For this reason, it is critical for perceptual\nhashing to be robust enough to take transformations such as resizing, cropping,\nand slight pixel modifications into account. In this paper, we would like to\npropose to experiment with effect of gaussian blurring in perceptual hashing\nfor detecting misuse of personal images specifically for face images. We\nhypothesize that use of gaussian blurring on the image before calculating its\nhash will increase the accuracy of our filter that detects adversarial attacks\nwhich consist of image cropping, adding text annotation, and image rotation.</p>\n", "tags": ["Hashing Methods", "Evaluation", "Robustness"], "tsne_embedding": [-14.646110534667969, 16.050451278686523], "cluster": 3}, {"key": "amato2016aggregating", "year": "2016", "citations": "11", "title": "Aggregating Binary Local Descriptors For Image Retrieval", "abstract": "<p>Content-Based Image Retrieval based on local features is computationally\nexpensive because of the complexity of both extraction and matching of local\nfeature. On one hand, the cost for extracting, representing, and comparing\nlocal visual descriptors has been dramatically reduced by recently proposed\nbinary local features. On the other hand, aggregation techniques provide a\nmeaningful summarization of all the extracted feature of an image into a single\ndescriptor, allowing us to speed up and scale up the image search. Only a few\nworks have recently mixed together these two research directions, defining\naggregation methods for binary local features, in order to leverage on the\nadvantage of both approaches. In this paper, we report an extensive comparison\namong state-of-the-art aggregation methods applied to binary features. Then, we\nmathematically formalize the application of Fisher Kernels to Bernoulli Mixture\nModels. Finally, we investigate the combination of the aggregated binary\nfeatures with the emerging Convolutional Neural Network (CNN) features. Our\nresults show that aggregation methods on binary features are effective and\nrepresent a worthwhile alternative to the direct matching. Moreover, the\ncombination of the CNN with the Fisher Vector (FV) built upon binary features\nallowed us to obtain a relative improvement over the CNN results that is in\nline with that recently obtained using the combination of the CNN with the FV\nbuilt upon SIFTs. The advantage of using the FV built upon binary features is\nthat the extraction process of binary features is about two order of magnitude\nfaster than SIFTs.</p>\n", "tags": ["Image Retrieval", "Alt", "Evaluation"], "tsne_embedding": [-14.797019958496094, 21.500856399536133], "cluster": 6}, {"key": "amato2016reducing", "year": "2016", "citations": "9", "title": "On Reducing The Number Of Visual Words In The Bag-of-features Representation", "abstract": "<p>A new class of applications based on visual search engines are emerging,\nespecially on smart-phones that have evolved into powerful tools for processing\nimages and videos. The state-of-the-art algorithms for large visual content\nrecognition and content based similarity search today use the \u201cBag of Features\u201d\n(BoF) or \u201cBag of Words\u201d (BoW) approach. The idea, borrowed from text retrieval,\nenables the use of inverted files. A very well known issue with this approach\nis that the query images, as well as the stored data, are described with\nthousands of words. This poses obvious efficiency problems when using inverted\nfiles to perform efficient image matching. In this paper, we propose and\ncompare various techniques to reduce the number of words describing an image to\nimprove efficiency and we study the effects of this reduction on effectiveness\nin landmark recognition and retrieval scenarios. We show that very relevant\nimprovement in performance are achievable still preserving the advantages of\nthe BoF base approach.</p>\n", "tags": ["Image Retrieval", "Efficiency And Optimization", "Text Retrieval", "ICCV", "Similarity Search", "Vector Indexing", "Evaluation"], "tsne_embedding": [1.9030410051345825, 8.544696807861328], "cluster": 4}, {"key": "amrouche2021hashing", "year": "2021", "citations": "5", "title": "Hashing And Metric Learning For Charged Particle Tracking", "abstract": "<p>We propose a novel approach to charged particle tracking at high intensity\nparticle colliders based on Approximate Nearest Neighbors search. With hundreds\nof thousands of measurements per collision to be reconstructed e.g. at the High\nLuminosity Large Hadron Collider, the currently employed combinatorial track\nfinding approaches become inadequate. Here, we use hashing techniques to\nseparate measurements into buckets of 20-50 hits and increase their purity\nusing metric learning. Two different approaches are studied to further resolve\ntracks inside buckets: Local Fisher Discriminant Analysis and Neural Networks\nfor triplet similarity learning. We demonstrate the proposed approach on\nsimulated collisions and show significant speed improvement with bucket\ntracking efficiency of 96% and a fake rate of 8% on unseen particle events.</p>\n", "tags": ["Distance Metric Learning", "Hashing Methods", "Efficiency And Optimization"], "tsne_embedding": [9.31618595123291, -3.744649648666382], "cluster": 4}, {"key": "amsaleg2022intrinsic", "year": "2022", "citations": "30", "title": "Intrinsic Dimensionality Estimation Within Tight Localities: A Theoretical And Experimental Analysis", "abstract": "<p>Accurate estimation of Intrinsic Dimensionality (ID) is of crucial importance\nin many data mining and machine learning tasks, including dimensionality\nreduction, outlier detection, similarity search and subspace clustering.\nHowever, since their convergence generally requires sample sizes (that is,\nneighborhood sizes) on the order of hundreds of points, existing ID estimation\nmethods may have only limited usefulness for applications in which the data\nconsists of many natural groups of small size. In this paper, we propose a\nlocal ID estimation strategy stable even for `tight\u2019 localities consisting of\nas few as 20 sample points. The estimator applies MLE techniques over all\navailable pairwise distances among the members of the sample, based on a recent\nextreme-value-theoretic model of intrinsic dimensionality, the Local Intrinsic\nDimension (LID). Our experimental results show that our proposed estimation\ntechnique can achieve notably smaller variance, while maintaining comparable\nlevels of bias, at much smaller sample sizes than state-of-the-art estimators.</p>\n", "tags": ["Similarity Search"], "tsne_embedding": [17.34839630126953, -1.2729289531707764], "cluster": 7}, {"key": "an2020fast", "year": "2020", "citations": "44", "title": "Fast And Incremental Loop Closure Detection With Deep Features And Proximity Graphs", "abstract": "<p>In recent years, the robotics community has extensively examined methods\nconcerning the place recognition task within the scope of simultaneous\nlocalization and mapping applications.This article proposes an appearance-based\nloop closure detection pipeline named ``FILD++\u201d (Fast and Incremental Loop\nclosure Detection).First, the system is fed by consecutive images and, via\npassing them twice through a single convolutional neural network, global and\nlocal deep features are extracted.Subsequently, a hierarchical navigable\nsmall-world graph incrementally constructs a visual database representing the\nrobot\u2019s traversed path based on the computed global features.Finally, a query\nimage, grabbed each time step, is set to retrieve similar locations on the\ntraversed route.An image-to-image pairing follows, which exploits local\nfeatures to evaluate the spatial information. Thus, in the proposed article, we\npropose a single network for global and local feature extraction in contrast to\nour previous work (FILD), while an exhaustive search for the verification\nprocess is adopted over the generated deep local features avoiding the\nutilization of hash codes. Exhaustive experiments on eleven publicly available\ndatasets exhibit the system\u2019s high performance (achieving the highest recall\nscore on eight of them) and low execution times (22.05 ms on average in New\nCollege, which is the largest one containing 52480 images) compared to other\nstate-of-the-art approaches.</p>\n", "tags": ["Graph Based ANN", "DATASETS", "Hashing Methods", "Evaluation"], "tsne_embedding": [0.6775205135345459, 19.565948486328125], "cluster": 6}, {"key": "andoni2016approximate", "year": "2016", "citations": "24", "title": "Approximate Near Neighbors For General Symmetric Norms", "abstract": "<p>We show that every symmetric normed space admits an efficient nearest\nneighbor search data structure with doubly-logarithmic approximation.\nSpecifically, for every \\(n\\), \\(d = n^{o(1)}\\), and every \\(d\\)-dimensional\nsymmetric norm \\(|\\cdot|\\), there exists a data structure for\n\\(\\mathrm{poly}(log log n)\\)-approximate nearest neighbor search over\n\\(|\\cdot|\\) for \\(n\\)-point datasets achieving \\(n^{o(1)}\\) query time and\n\\(n^{1+o(1)}\\) space. The main technical ingredient of the algorithm is a\nlow-distortion embedding of a symmetric norm into a low-dimensional iterated\nproduct of top-\\(k\\) norms.\n  We also show that our techniques cannot be extended to general norms.</p>\n", "tags": ["DATASETS", "Efficiency And Optimization"], "tsne_embedding": [28.01350975036621, -3.3608644008636475], "cluster": 7}, {"key": "andoni2016lower", "year": "2016", "citations": "30", "title": "Lower Bounds On Time-space Trade-offs For Approximate Near Neighbors", "abstract": "<p>We show tight lower bounds for the entire trade-off between space and query\ntime for the Approximate Near Neighbor search problem. Our lower bounds hold in\na restricted model of computation, which captures all hashing-based approaches.\nIn articular, our lower bound matches the upper bound recently shown in\n[Laarhoven 2015] for the random instance on a Euclidean sphere (which we show\nin fact extends to the entire space \\(\\mathbb{R}^d\\) using the techniques from\n[Andoni, Razenshteyn 2015]).\n  We also show tight, unconditional cell-probe lower bounds for one and two\nprobes, improving upon the best known bounds from [Panigrahy, Talwar, Wieder\n2010]. In particular, this is the first space lower bound (for any static data\nstructure) for two probes which is not polynomially smaller than for one probe.\nTo show the result for two probes, we establish and exploit a connection to\nlocally-decodable codes.</p>\n", "tags": ["Hashing Methods"], "tsne_embedding": [25.898202896118164, -3.130526304244995], "cluster": 7}, {"key": "andoni2016optimal", "year": "2016", "citations": "66", "title": "Optimal Hashing-based Time-space Trade-offs For Approximate Near Neighbors", "abstract": "<p>[See the paper for the full abstract.]\n  We show tight upper and lower bounds for time-space trade-offs for the\n\\(c\\)-Approximate Near Neighbor Search problem. For the \\(d\\)-dimensional Euclidean\nspace and \\(n\\)-point datasets, we develop a data structure with space \\(n^{1 +\n\\rho_u + o(1)} + O(dn)\\) and query time \\(n^{\\rho_q + o(1)} + d n^{o(1)}\\) for\nevery \\(\\rho_u, \\rho_q \\geq 0\\) such that: \\begin{equation} c^2 \\sqrt{\\rho_q} +\n(c^2 - 1) \\sqrt{\\rho_u} = \\sqrt{2c^2 - 1}. \\end{equation}\n  This is the first data structure that achieves sublinear query time and\nnear-linear space for every approximation factor \\(c &gt; 1\\), improving upon\n[Kapralov, PODS 2015]. The data structure is a culmination of a long line of\nwork on the problem for all space regimes; it builds on Spherical\nLocality-Sensitive Filtering [Becker, Ducas, Gama, Laarhoven, SODA 2016] and\ndata-dependent hashing [Andoni, Indyk, Nguyen, Razenshteyn, SODA 2014] [Andoni,\nRazenshteyn, STOC 2015].\n  Our matching lower bounds are of two types: conditional and unconditional.\nFirst, we prove tightness of the whole above trade-off in a restricted model of\ncomputation, which captures all known hashing-based approaches. We then show\nunconditional cell-probe lower bounds for one and two probes that match the\nabove trade-off for \\(\\rho_q = 0\\), improving upon the best known lower bounds\nfrom [Panigrahy, Talwar, Wieder, FOCS 2010]. In particular, this is the first\nspace lower bound (for any static data structure) for two probes which is not\npolynomially smaller than the one-probe bound. To show the result for two\nprobes, we establish and exploit a connection to locally-decodable codes.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization"], "tsne_embedding": [30.646812438964844, -1.0229833126068115], "cluster": 7}, {"key": "andoni2018approximate", "year": "2018", "citations": "108", "title": "Approximate Nearest Neighbor Search In High Dimensions", "abstract": "<p>The nearest neighbor problem is defined as follows: Given a set \\(P\\) of \\(n\\)\npoints in some metric space \\((X,D)\\), build a data structure that, given any\npoint \\(q\\), returns a point in \\(P\\) that is closest to \\(q\\) (its \u201cnearest\nneighbor\u201d in \\(P\\)). The data structure stores additional information about the\nset \\(P\\), which is then used to find the nearest neighbor without computing all\ndistances between \\(q\\) and \\(P\\). The problem has a wide range of applications in\nmachine learning, computer vision, databases and other fields.\n  To reduce the time needed to find nearest neighbors and the amount of memory\nused by the data structure, one can formulate the {\\em approximate} nearest\nneighbor problem, where the the goal is to return any point \\(p\u2019 \\in P\\) such\nthat the distance from \\(q\\) to \\(p\u2019\\) is at most \\(c \\cdot \\min_{p \\in P} D(q,p)\\),\nfor some \\(c \\geq 1\\). Over the last two decades, many efficient solutions to\nthis problem were developed. In this article we survey these developments, as\nwell as their connections to questions in geometric functional analysis and\ncombinatorial geometry.</p>\n", "tags": ["Survey Paper", "CVPR"], "tsne_embedding": [26.938270568847656, 1.5748250484466553], "cluster": 7}, {"key": "andoni2021average", "year": "2021", "citations": "6", "title": "From Average Embeddings To Nearest Neighbor Search", "abstract": "<p>In this note, we show that one can use average embeddings, introduced\nrecently in [Naor\u201920, arXiv:1905.01280], to obtain efficient algorithms for\napproximate nearest neighbor search. In particular, a metric \\(X\\) embeds into\n\\(\u2113\u2082\\) on average, with distortion \\(D\\), if, for any distribution \\(\\mu\\) on\n\\(X\\), the embedding is \\(D\\) Lipschitz and the (square of) distance does not\ndecrease on average (wrt \\(\\mu\\)). In particular existence of such an embedding\n(assuming it is efficient) implies a \\(O(D^3)\\) approximate nearest neighbor\nsearch under \\(X\\). This can be seen as a strengthening of the classic\n(bi-Lipschitz) embedding approach to nearest neighbor search, and is another\napplication of data-dependent hashing paradigm.</p>\n", "tags": ["Hashing Methods"], "tsne_embedding": [22.108461380004883, -1.7586872577667236], "cluster": 7}, {"key": "andoni2025near", "year": "2025", "citations": "1420", "title": "Near-optimal Hashing Algorithms For Approximate Nearest Neighbor In High Dimensions", "abstract": "<p>We present an algorithm for the c-approximate nearest neighbor problem in a d-dimensional Euclidean space, achieving query time of O(dn 1c2/+o(1)) and space O(dn + n1+1c2/+o(1)). This almost matches the lower bound for hashing-based algorithm recently obtained in (R. Motwani et al., 2006). We also obtain a space-efficient version of the algorithm, which uses dn+n logO(1) n space, with a query time of dnO(1/c2). Finally, we discuss practical variants of the algorithms that utilize fast bounded-distance decoders for the Leech lattice</p>\n", "tags": ["Hashing Methods", "Efficiency And Optimization"], "tsne_embedding": [25.8555850982666, -3.1050891876220703], "cluster": 7}, {"key": "andoni2025practical", "year": "2025", "citations": "238", "title": "Practical And Optimal LSH For Angular Distance", "abstract": "<p>We show the existence of a Locality-Sensitive Hashing (LSH) family for the angular\ndistance that yields an approximate Near Neighbor Search algorithm with the\nasymptotically optimal running time exponent. Unlike earlier algorithms with this\nproperty (e.g., Spherical LSH [1, 2]), our algorithm is also practical, improving\nupon the well-studied hyperplane LSH [3] in practice. We also introduce a multiprobe\nversion of this algorithm and conduct an experimental evaluation on real\nand synthetic data sets.\nWe complement the above positive results with a fine-grained lower bound for the\nquality of any LSH family for angular distance. Our lower bound implies that the\nabove LSH family exhibits a trade-off between evaluation time and quality that is\nclose to optimal for a natural class of LSH functions.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Evaluation"], "tsne_embedding": [22.0335693359375, -0.4514721930027008], "cluster": 7}, {"key": "andrecut2021additive", "year": "2021", "citations": "17", "title": "Additive Feature Hashing", "abstract": "<p>The hashing trick is a machine learning technique used to encode categorical\nfeatures into a numerical vector representation of pre-defined fixed length. It\nworks by using the categorical hash values as vector indices, and updating the\nvector values at those indices. Here we discuss a different approach based on\nadditive-hashing and the \u201calmost orthogonal\u201d property of high-dimensional\nrandom vectors. That is, we show that additive feature hashing can be performed\ndirectly by adding the hash values and converting them into high-dimensional\nnumerical vectors. We show that the performance of additive feature hashing is\nsimilar to the hashing trick, and we illustrate the results numerically using\nsynthetic, language recognition, and SMS spam detection data.</p>\n", "tags": ["Hashing Methods", "Evaluation"], "tsne_embedding": [1.8281623125076294, -11.97442626953125], "cluster": 9}, {"key": "andr\u00e92017accelerated", "year": "2017", "citations": "14", "title": "Accelerated Nearest Neighbor Search With Quick ADC", "abstract": "<p>Efficient Nearest Neighbor (NN) search in high-dimensional spaces is a\nfoundation of many multimedia retrieval systems. Because it offers low\nresponses times, Product Quantization (PQ) is a popular solution. PQ compresses\nhigh-dimensional vectors into short codes using several sub-quantizers, which\nenables in-RAM storage of large databases. This allows fast answers to NN\nqueries, without accessing the SSD or HDD. The key feature of PQ is that it can\ncompute distances between short codes and high-dimensional vectors using\ncache-resident lookup tables. The efficiency of this technique, named\nAsymmetric Distance Computation (ADC), remains limited because it performs many\ncache accesses.\n  In this paper, we introduce Quick ADC, a novel technique that achieves a 3 to\n6 times speedup over ADC by exploiting Single Instruction Multiple Data (SIMD)\nunits available in current CPUs. Efficiently exploiting SIMD requires\nalgorithmic changes to the ADC procedure. Namely, Quick ADC relies on two key\nmodifications of ADC: (i) the use 4-bit sub-quantizers instead of the standard\n8-bit sub-quantizers and (ii) the quantization of floating-point distances.\nThis allows Quick ADC to exceed the performance of state-of-the-art systems,\ne.g., it achieves a Recall@100 of 0.94 in 3.4 ms on 1 billion SIFT descriptors\n(128-bit codes).</p>\n", "tags": ["Evaluation", "Quantization", "Efficiency And Optimization", "Graph Based ANN", "Compact Codes", "Multimodal Retrieval"], "tsne_embedding": [-8.865534782409668, -21.47760581970215], "cluster": 5}, {"key": "andr\u00e92019derived", "year": "2019", "citations": "28", "title": "Derived Codebooks For High-accuracy Nearest Neighbor Search", "abstract": "<p>High-dimensional Nearest Neighbor (NN) search is central in multimedia search\nsystems. Product Quantization (PQ) is a widespread NN search technique which\nhas a high performance and good scalability. PQ compresses high-dimensional\nvectors into compact codes thanks to a combination of quantizers. Large\ndatabases can, therefore, be stored entirely in RAM, enabling fast responses to\nNN queries. In almost all cases, PQ uses 8-bit quantizers as they offer low\nresponse times. In this paper, we advocate the use of 16-bit quantizers.\nCompared to 8-bit quantizers, 16-bit quantizers boost accuracy but they\nincrease response time by a factor of 3 to 10. We propose a novel approach that\nallows 16-bit quantizers to offer the same response time as 8-bit quantizers,\nwhile still providing a boost of accuracy. Our approach builds on two key\nideas: (i) the construction of derived codebooks that allow a fast and\napproximate distance evaluation, and (ii) a two-pass NN search procedure which\nbuilds a candidate set using the derived codebooks, and then refines it using\n16-bit quantizers. On 1 billion SIFT vectors, with an inverted index, our\napproach offers a Recall@100 of 0.85 in 5.2 ms. By contrast, 16-bit quantizers\nalone offer a Recall@100 of 0.85 in 39 ms, and 8-bit quantizers a Recall@100 of\n0.82 in 3.8 ms.</p>\n", "tags": ["Compact Codes", "Quantization", "Hashing Methods", "Evaluation"], "tsne_embedding": [-9.14739990234375, -21.633007049560547], "cluster": 5}, {"key": "araujo2016large", "year": "2016", "citations": "14", "title": "Large-scale Query-by-image Video Retrieval Using Bloom Filters", "abstract": "<p>We consider the problem of using image queries to retrieve videos from a\ndatabase. Our focus is on large-scale applications, where it is infeasible to\nindex each database video frame independently. Our main contribution is a\nframework based on Bloom filters, which can be used to index long video\nsegments, enabling efficient image-to-video comparisons. Using this framework,\nwe investigate several retrieval architectures, by considering different types\nof aggregation and different functions to encode visual information \u2013 these\nplay a crucial role in achieving high performance. Extensive experiments show\nthat the proposed technique improves mean average precision by 24% on a public\ndataset, while being 4X faster, compared to the previous state-of-the-art.</p>\n", "tags": ["DATASETS", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-7.206635475158691, 22.129518508911133], "cluster": 6}, {"key": "argerich2017generic", "year": "2017", "citations": "11", "title": "Generic LSH Families For The Angular Distance Based On Johnson-lindenstrauss Projections And Feature Hashing LSH", "abstract": "<p>In this paper we propose the creation of generic LSH families for the angular\ndistance based on Johnson-Lindenstrauss projections. We show that feature\nhashing is a valid J-L projection and propose two new LSH families based on\nfeature hashing. These new LSH families are tested on both synthetic and real\ndatasets with very good results and a considerable performance improvement over\nother LSH families. While the theoretical analysis is done for the angular\ndistance, these families can also be used in practice for the euclidean\ndistance with excellent results [2]. Our tests using real datasets show that\nthe proposed LSH functions work well for the euclidean distance.</p>\n", "tags": ["Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Distance Metric Learning", "Evaluation"], "tsne_embedding": [22.38857650756836, -0.06533358991146088], "cluster": 7}, {"key": "arponen2019shrewd", "year": "2019", "citations": "27", "title": "SHREWD: Semantic Hierarchy-based Relational Embeddings For Weakly-supervised Deep Hashing", "abstract": "<p>Using class labels to represent class similarity is a typical approach to\ntraining deep hashing systems for retrieval; samples from the same or different\nclasses take binary 1 or 0 similarity values. This similarity does not model\nthe full rich knowledge of semantic relations that may be present between data\npoints. In this work we build upon the idea of using semantic hierarchies to\nform distance metrics between all available sample labels; for example cat to\ndog has a smaller distance than cat to guitar. We combine this type of semantic\ndistance into a loss function to promote similar distances between the deep\nneural network embeddings. We also introduce an empirical Kullback-Leibler\ndivergence loss term to promote binarization and uniformity of the embeddings.\nWe test the resulting SHREWD method and demonstrate improvements in\nhierarchical retrieval scores using compact, binary hash codes instead of real\nvalued ones, and show that in a weakly supervised hashing setting we are able\nto learn competitively without explicitly relying on class labels, but instead\non similarities between labels.</p>\n", "tags": ["CVPR", "Distance Metric Learning", "Neural Hashing", "Hashing Methods"], "tsne_embedding": [-0.22423560917377472, -2.9515299797058105], "cluster": 9}, {"key": "artetxe2018massively", "year": "2018", "citations": "747", "title": "Massively Multilingual Sentence Embeddings For Zero-shot Cross-lingual Transfer And Beyond", "abstract": "<p>We introduce an architecture to learn joint multilingual sentence\nrepresentations for 93 languages, belonging to more than 30 different families\nand written in 28 different scripts. Our system uses a single BiLSTM encoder\nwith a shared BPE vocabulary for all languages, which is coupled with an\nauxiliary decoder and trained on publicly available parallel corpora. This\nenables us to learn a classifier on top of the resulting embeddings using\nEnglish annotated data only, and transfer it to any of the 93 languages without\nany modification. Our experiments in cross-lingual natural language inference\n(XNLI dataset), cross-lingual document classification (MLDoc dataset) and\nparallel corpus mining (BUCC dataset) show the effectiveness of our approach.\nWe also introduce a new test set of aligned sentences in 112 languages, and\nshow that our sentence embeddings obtain strong results in multilingual\nsimilarity search even for low-resource languages. Our implementation, the\npre-trained encoder and the multilingual test set are available at\nhttps://github.com/facebookresearch/LASER</p>\n", "tags": ["DATASETS", "TACL", "ACL", "Similarity Search"], "tsne_embedding": [12.369017601013184, -13.9686861038208], "cluster": 2}, {"key": "atighehchi2019cryptanalysis", "year": "2019", "citations": "56", "title": "A Cryptanalysis Of Two Cancelable Biometric Schemes Based On Index-of-max Hashing", "abstract": "<p>Cancelable biometric schemes generate secure biometric templates by combining\nuser specific tokens and biometric data. The main objective is to create\nirreversible, unlinkable, and revocable templates, with high accuracy in\nmatching. In this paper, we cryptanalyze two recent cancelable biometric\nschemes based on a particular locality sensitive hashing function, index-of-max\n(IoM): Gaussian Random Projection-IoM (GRP-IoM) and Uniformly Random\nPermutation-IoM (URP-IoM). As originally proposed, these schemes were claimed\nto be resistant against reversibility, authentication, and linkability attacks\nunder the stolen token scenario. We propose several attacks against GRP-IoM and\nURP-IoM, and argue that both schemes are severely vulnerable against\nauthentication and linkability attacks. We also propose better, but not yet\npractical, reversibility attacks against GRP-IoM. The correctness and practical\nimpact of our attacks are verified over the same dataset provided by the\nauthors of these two schemes.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "DATASETS"], "tsne_embedding": [5.309823036193848, -26.279146194458008], "cluster": 5}, {"key": "aum\u00fcller2017distance", "year": "2017", "citations": "18", "title": "Distance-sensitive Hashing", "abstract": "<p>Locality-sensitive hashing (LSH) is an important tool for managing\nhigh-dimensional noisy or uncertain data, for example in connection with data\ncleaning (similarity join) and noise-robust search (similarity search).\nHowever, for a number of problems the LSH framework is not known to yield good\nsolutions, and instead ad hoc solutions have been designed for particular\nsimilarity and distance measures. For example, this is true for\noutput-sensitive similarity search/join, and for indexes supporting annulus\nqueries that aim to report a point close to a certain given distance from the\nquery point.\n  In this paper we initiate the study of distance-sensitive hashing (DSH), a\ngeneralization of LSH that seeks a family of hash functions such that the\nprobability of two points having the same hash value is a given function of the\ndistance between them. More precisely, given a distance space \\((X,\n\\text{dist})\\) and a \u201ccollision probability function\u201d (CPF) \\(f\\colon\n\\mathbb{R}\\rightarrow [0,1]\\) we seek a distribution over pairs of functions\n\\((h,g)\\) such that for every pair of points \\(x, y \\in X\\) the collision\nprobability is \\(\\Pr[h(x)=g(y)] = f(\\text{dist}(x,y))\\). Locality-sensitive\nhashing is the study of how fast a CPF can decrease as the distance grows. For\nmany spaces, \\(f\\) can be made exponentially decreasing even if we restrict\nattention to the symmetric case where \\(g=h\\). We show that the asymmetry\nachieved by having a pair of functions makes it possible to achieve CPFs that\nare, for example, increasing or unimodal, and show how this leads to principled\nsolutions to problems not addressed by the LSH framework. This includes a novel\napplication to privacy-preserving distance estimation. We believe that the DSH\nframework will find further applications in high-dimensional data management.</p>\n", "tags": ["Similarity Search", "Locality Sensitive Hashing", "Tools & Libraries", "Hashing Methods"], "tsne_embedding": [31.27701187133789, 1.9233403205871582], "cluster": 7}, {"key": "aum\u00fcller2018ann", "year": "2018", "citations": "189", "title": "Ann-benchmarks: A Benchmarking Tool For Approximate Nearest Neighbor Algorithms", "abstract": "<p>This paper describes ANN-Benchmarks, a tool for evaluating the performance of\nin-memory approximate nearest neighbor algorithms. It provides a standard\ninterface for measuring the performance and quality achieved by nearest\nneighbor algorithms on different standard data sets. It supports several\ndifferent ways of integrating \\(k\\)-NN algorithms, and its configuration system\nautomatically tests a range of parameter settings for each algorithm.\nAlgorithms are compared with respect to many different (approximate) quality\nmeasures, and adding more is easy and fast; the included plotting front-ends\ncan visualise these as images, \\(\\LaTeX\\) plots, and websites with interactive\nplots. ANN-Benchmarks aims to provide a constantly updated overview of the\ncurrent state of the art of \\(k\\)-NN algorithms. In the short term, this overview\nallows users to choose the correct \\(k\\)-NN algorithm and parameters for their\nsimilarity search task; in the longer term, algorithm designers will be able to\nuse this overview to test and refine automatic parameter tuning. The paper\ngives an overview of the system, evaluates the results of the benchmark, and\npoints out directions for future work. Interestingly, very different approaches\nto \\(k\\)-NN search yield comparable quality-performance trade-offs. The system is\navailable at http://ann-benchmarks.com .</p>\n", "tags": ["Survey Paper", "Similarity Search", "Evaluation"], "tsne_embedding": [9.061927795410156, 8.595882415771484], "cluster": 4}, {"key": "aum\u00fcller2019fair", "year": "2019", "citations": "16", "title": "Fair Near Neighbor Search: Independent Range Sampling In High Dimensions", "abstract": "<p>Similarity search is a fundamental algorithmic primitive, widely used in many\ncomputer science disciplines. There are several variants of the similarity\nsearch problem, and one of the most relevant is the \\(r\\)-near neighbor (\\(r\\)-NN)\nproblem: given a radius \\(r&gt;0\\) and a set of points \\(S\\), construct a data\nstructure that, for any given query point \\(q\\), returns a point \\(p\\) within\ndistance at most \\(r\\) from \\(q\\). In this paper, we study the \\(r\\)-NN problem in\nthe light of fairness. We consider fairness in the sense of equal opportunity:\nall points that are within distance \\(r\\) from the query should have the same\nprobability to be returned. In the low-dimensional case, this problem was first\nstudied by Hu, Qiao, and Tao (PODS 2014). Locality sensitive hashing (LSH), the\ntheoretically strongest approach to similarity search in high dimensions, does\nnot provide such a fairness guarantee. To address this, we propose efficient\ndata structures for \\(r\\)-NN where all points in \\(S\\) that are near \\(q\\) have the\nsame probability to be selected and returned by the query. Specifically, we\nfirst propose a black-box approach that, given any LSH scheme, constructs a\ndata structure for uniformly sampling points in the neighborhood of a query.\nThen, we develop a data structure for fair similarity search under inner\nproduct that requires nearly-linear space and exploits locality sensitive\nfilters. The paper concludes with an experimental evaluation that highlights\n(un)fairness in a recommendation setting on real-world datasets and discusses\nthe inherent unfairness introduced by solving other variants of the problem.</p>\n", "tags": ["Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Recommender Systems", "Similarity Search", "Evaluation"], "tsne_embedding": [28.122407913208008, 2.8010220527648926], "cluster": 7}, {"key": "aum\u00fcller2019puffinn", "year": "2019", "citations": "7", "title": "PUFFINN: Parameterless And Universally Fast Finding Of Nearest Neighbors", "abstract": "<p>We present PUFFINN, a parameterless LSH-based index for solving the\n\\(k\\)-nearest neighbor problem with probabilistic guarantees. By parameterless we\nmean that the user is only required to specify the amount of memory the index\nis supposed to use and the result quality that should be achieved. The index\ncombines several heuristic ideas known in the literature. By small adaptions to\nthe query algorithm, we make heuristics rigorous. We perform experiments on\nreal-world and synthetic inputs to evaluate implementation choices and show\nthat the implementation satisfies the quality guarantees while being\ncompetitive with other state-of-the-art approaches to nearest neighbor search.\n  We describe a novel synthetic data set that is difficult to solve for almost\nall existing nearest neighbor search approaches, and for which PUFFINN\nsignificantly outperform previous methods.</p>\n", "tags": ["Locality Sensitive Hashing"], "tsne_embedding": [14.776643753051758, -6.687636375427246], "cluster": 2}, {"key": "aum\u00fcller2019role", "year": "2019", "citations": "8", "title": "The Role Of Local Intrinsic Dimensionality In Benchmarking Nearest Neighbor Search", "abstract": "<p>This paper reconsiders common benchmarking approaches to nearest neighbor\nsearch. It is shown that the concept of local intrinsic dimensionality (LID)\nallows to choose query sets of a wide range of difficulty for real-world\ndatasets. Moreover, the effect of different LID distributions on the running\ntime performance of implementations is empirically studied. To this end,\ndifferent visualization concepts are introduced that allow to get a more\nfine-grained overview of the inner workings of nearest neighbor search\nprinciples. The paper closes with remarks about the diversity of datasets\ncommonly used for nearest neighbor search benchmarking. It is shown that such\nreal-world datasets are not diverse: results on a single dataset predict\nresults on all other datasets well.</p>\n", "tags": ["Survey Paper", "DATASETS", "Evaluation"], "tsne_embedding": [17.56273078918457, 0.8892495036125183], "cluster": 7}, {"key": "aum\u00fcller2020differentially", "year": "2020", "citations": "5", "title": "Differentially Private Sketches For Jaccard Similarity Estimation", "abstract": "<p>This paper describes two locally-differential private algorithms for\nreleasing user vectors such that the Jaccard similarity between these vectors\ncan be efficiently estimated. The basic building block is the well known\nMinHash method. To achieve a privacy-utility trade-off, MinHash is extended in\ntwo ways using variants of Generalized Randomized Response and the Laplace\nMechanism. A theoretical analysis provides bounds on the absolute error and\nexperiments show the utility-privacy trade-off on synthetic and real-world\ndata. The paper ends with a critical discussion of related work.</p>\n", "tags": ["Locality Sensitive Hashing"], "tsne_embedding": [13.257859230041504, -20.33085060119629], "cluster": 2}, {"key": "awad2021better", "year": "2021", "citations": "5", "title": "Better GPU Hash Tables", "abstract": "<p>We revisit the problem of building static hash tables on the GPU and design\nand build three bucketed hash tables that use different probing schemes. Our\nimplementations are lock-free and offer efficient memory access patterns; thus,\nonly the probing scheme is the factor affecting the performance of the hash\ntable\u2019s different operations. Our results show that a bucketed cuckoo hash\ntable that uses three hash functions (BCHT) outperforms alternative methods\nthat use power-of-two choices, iceberg hashing, and a cuckoo hash table that\nuses a bucket size one. At high load factors as high as 0.99, BCHT enjoys an\naverage probe count of 1.43 during insertion. Using three hash functions only,\npositive and negative queries require at most 1.39 and 2.8 average probes per\nkey, respectively.</p>\n", "tags": ["Alt", "Hashing Methods", "Evaluation"], "tsne_embedding": [-0.024895325303077698, -13.990532875061035], "cluster": 9}, {"key": "azarafrooz2018fuzzy", "year": "2018", "citations": "13", "title": "Fuzzy Hashing As Perturbation-consistent Adversarial Kernel Embedding", "abstract": "<p>Measuring the similarity of two files is an important task in malware\nanalysis, with fuzzy hash functions being a popular approach. Traditional fuzzy\nhash functions are data agnostic: they do not learn from a particular dataset\nhow to determine similarity; their behavior is fixed across all datasets. In\nthis paper, we demonstrate that fuzzy hash functions can be learned in a novel\nminimax training framework and that these learned fuzzy hash functions\noutperform traditional fuzzy hash functions at the file similarity task for\nPortable Executable files. In our approach, hash digests can be extracted from\nthe kernel embeddings of two kernel networks, trained in a minimax framework,\nwhere the roles of players during training (i.e adversary versus generator)\nalternate along with the input data. We refer to this new minimax architecture\nas perturbation-consistent. The similarity score for a pair of files is the\nutility of the minimax game in equilibrium. Our experiments show that learned\nfuzzy hash functions generalize well, capable of determining that two files are\nsimilar even when one of those files was generated using insertion and deletion\noperations.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Alt", "Tools & Libraries", "Robustness"], "tsne_embedding": [1.4503790140151978, -17.664777755737305], "cluster": 5}, {"key": "bach2025hierarchical", "year": "2025", "citations": "16", "title": "Hierarchical Patch Compression For Colpali: Efficient Multi-vector Document Retrieval With Dynamic Pruning And Quantization", "abstract": "<p>Multi-vector document retrieval systems, such as ColPali, excel in fine-grained matching for complex queries but incur significant storage and computational costs due to their reliance on high-dimensional patch embeddings and late-interaction scoring. To address these challenges, we propose HPC-ColPali, a Hierarchical Patch Compression framework that enhances the efficiency of ColPali while preserving its retrieval accuracy. Our approach integrates three innovative techniques: (1) K-Means quantization, which compresses patch embeddings into 1-byte centroid indices, achieving up to 32\\(\\times\\) storage reduction; (2) attention-guided dynamic pruning, utilizing Vision-Language Model attention weights to retain only the top-\\(p%\\) most salient patches, reducing late-interaction computation by up to 60% with less than 2% nDCG@10 loss; and (3) optional binary encoding of centroid indices into \\(b\\)-bit strings (\\(b=\\lceillog_2 K\\rceil\\)), enabling rapid Hamming distance-based similarity search for resource-constrained environments. Evaluated on the ViDoRe and SEC-Filings datasets, HPC-ColPali achieves 30\u201350% lower query latency under HNSW indexing while maintaining high retrieval precision. When integrated into a Retrieval-Augmented Generation pipeline for legal summarization, it reduces hallucination rates by 30% and halves end-to-end latency. These advancements establish HPC-ColPali as a scalable and efficient solution for multi-vector document retrieval across diverse applications. Code is available at https://github.com/DngBack/HPC-ColPali.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Graph Based ANN", "Efficiency And Optimization", "Text Retrieval", "SIGIR", "Similarity Search", "Quantization", "Tools & Libraries", "Evaluation"], "tsne_embedding": [3.6867895126342773, 1.1350762844085693], "cluster": 4}, {"key": "backurs2019scalable", "year": "2019", "citations": "12", "title": "Scalable Nearest Neighbor Search For Optimal Transport", "abstract": "<p>The Optimal Transport (a.k.a. Wasserstein) distance is an increasingly\npopular similarity measure for rich data domains, such as images or text\ndocuments. This raises the necessity for fast nearest neighbor search\nalgorithms according to this distance, which poses a substantial computational\nbottleneck on massive datasets. In this work we introduce Flowtree, a fast and\naccurate approximation algorithm for the Wasserstein-\\(1\\) distance. We formally\nanalyze its approximation factor and running time. We perform extensive\nexperimental evaluation of nearest neighbor search algorithms in the \\(W_1\\)\ndistance on real-world dataset. Our results show that compared to previous\nstate of the art, Flowtree achieves up to \\(7.4\\) times faster running time.</p>\n", "tags": ["DATASETS", "Evaluation"], "tsne_embedding": [8.602951049804688, 17.074857711791992], "cluster": 0}, {"key": "backurs2024efficiently", "year": "2024", "citations": "23", "title": "Efficiently Computing Similarities To Private Datasets", "abstract": "<p>Many methods in differentially private model training rely on computing the\nsimilarity between a query point (such as public or synthetic data) and private\ndata. We abstract out this common subroutine and study the following\nfundamental algorithmic problem: Given a similarity function \\(f\\) and a large\nhigh-dimensional private dataset \\(X \\subset \\mathbb{R}^d\\), output a\ndifferentially private (DP) data structure which approximates \\(\\sum_{x \\in X}\nf(x,y)\\) for any query \\(y\\). We consider the cases where \\(f\\) is a kernel\nfunction, such as \\(f(x,y) = e^{-|x-y|_2^2/\\sigma^2}\\) (also known as DP kernel\ndensity estimation), or a distance function such as \\(f(x,y) = |x-y|_2\\), among\nothers.\n  Our theoretical results improve upon prior work and give better\nprivacy-utility trade-offs as well as faster query times for a wide range of\nkernels and distance functions. The unifying approach behind our results is\nleveraging `low-dimensional structures\u2019 present in the specific functions \\(f\\)\nthat we study, using tools such as provable dimensionality reduction,\napproximation theory, and one-dimensional decomposition of the functions. Our\nalgorithms empirically exhibit improved query times and accuracy over prior\nstate of the art. We also present an application to DP classification. Our\nexperiments demonstrate that the simple methodology of classifying based on\naverage similarity is orders of magnitude faster than prior DP-SGD based\napproaches for comparable accuracy.</p>\n", "tags": ["DATASETS", "ICASSP", "Efficiency And Optimization"], "tsne_embedding": [28.55210304260254, 1.800620198249817], "cluster": 7}, {"key": "bahi2017hash", "year": "2017", "citations": "54", "title": "Hash Functions Using Chaotic Iterations", "abstract": "<p>In this paper, a novel formulation of discrete chaotic iterations in the\nfield of dynamical systems is given. Their topological properties are studied:\nit is mathematically proved that, under some conditions, these iterations have\na chaotic behavior in the meaning of Devaney. This chaotic behavior allows us\nto propose a way to generate new hash functions. An illustration example is\ndetailed in order to show how to use our theoretical study in practice.</p>\n", "tags": ["Hashing Methods"], "tsne_embedding": [-4.761992454528809, -17.8995361328125], "cluster": 5}, {"key": "bai2018learning", "year": "2018", "citations": "62", "title": "Learning-based Efficient Graph Similarity Computation Via Multi-scale Convolutional Set Matching", "abstract": "<p>Graph similarity computation is one of the core operations in many\ngraph-based applications, such as graph similarity search, graph database\nanalysis, graph clustering, etc. Since computing the exact distance/similarity\nbetween two graphs is typically NP-hard, a series of approximate methods have\nbeen proposed with a trade-off between accuracy and speed. Recently, several\ndata-driven approaches based on neural networks have been proposed, most of\nwhich model the graph-graph similarity as the inner product of their\ngraph-level representations, with different techniques proposed for generating\none embedding per graph. However, using one fixed-dimensional embedding per\ngraph may fail to fully capture graphs in varying sizes and link structures, a\nlimitation that is especially problematic for the task of graph similarity\ncomputation, where the goal is to find the fine-grained difference between two\ngraphs. In this paper, we address the problem of graph similarity computation\nfrom another perspective, by directly matching two sets of node embeddings\nwithout the need to use fixed-dimensional vectors to represent whole graphs for\ntheir similarity computation. The model, GraphSim, achieves the\nstate-of-the-art performance on four real-world graph datasets under six out of\neight settings (here we count a specific dataset and metric combination as one\nsetting), compared to existing popular methods for approximate Graph Edit\nDistance (GED) and Maximum Common Subgraph (MCS) computation.</p>\n", "tags": ["AAAI", "DATASETS", "Graph Based ANN", "Similarity Search", "Evaluation"], "tsne_embedding": [21.724807739257812, 12.425826072692871], "cluster": 0}, {"key": "bai2020targeted", "year": "2020", "citations": "67", "title": "Targeted Attack For Deep Hashing Based Retrieval", "abstract": "<p>The deep hashing based retrieval method is widely adopted in large-scale\nimage and video retrieval. However, there is little investigation on its\nsecurity. In this paper, we propose a novel method, dubbed deep hashing\ntargeted attack (DHTA), to study the targeted attack on such retrieval.\nSpecifically, we first formulate the targeted attack as a point-to-set\noptimization, which minimizes the average distance between the hash code of an\nadversarial example and those of a set of objects with the target label. Then\nwe design a novel component-voting scheme to obtain an anchor code as the\nrepresentative of the set of hash codes of objects with the target label, whose\noptimality guarantee is also theoretically derived. To balance the performance\nand perceptibility, we propose to minimize the Hamming distance between the\nhash code of the adversarial example and the anchor code under the\n\\(\\ell^\\infty\\) restriction on the perturbation. Extensive experiments verify\nthat DHTA is effective in attacking both deep hashing based image retrieval and\nvideo retrieval.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Neural Hashing", "Evaluation", "Robustness"], "tsne_embedding": [-5.969071865081787, 10.708703994750977], "cluster": 6}, {"key": "banerjee2020simpatch", "year": "2020", "citations": "7", "title": "Simpatch: A Nearest Neighbor Similarity Match Between Image Patches", "abstract": "<p>Measuring the similarity between patches in images is a fundamental building\nblock in various tasks. Naturally, the patch-size has a major impact on the\nmatching quality, and on the consequent application performance. We try to use\nlarge patches instead of relatively small patches so that each patch contains\nmore information. We use different feature extraction mechanisms to extract the\nfeatures of each individual image patches which forms a feature matrix and find\nout the nearest neighbor patches in the image. The nearest patches are\ncalculated using two different nearest neighbor algorithms in this paper for a\nquery patch for a given image and the results have been demonstrated in this\npaper.</p>\n", "tags": ["Evaluation"], "tsne_embedding": [11.562359809875488, 7.994739532470703], "cluster": 0}, {"key": "baranchuk2018revisiting", "year": "2018", "citations": "67", "title": "Revisiting The Inverted Indices For Billion-scale Approximate Nearest Neighbors", "abstract": "<p>This work addresses the problem of billion-scale nearest neighbor search. The\nstate-of-the-art retrieval systems for billion-scale databases are currently\nbased on the inverted multi-index, the recently proposed generalization of the\ninverted index structure. The multi-index provides a very fine-grained\npartition of the feature space that allows extracting concise and accurate\nshort-lists of candidates for the search queries. In this paper, we argue that\nthe potential of the simple inverted index was not fully exploited in previous\nworks and advocate its usage both for the highly-entangled deep descriptors and\nrelatively disentangled SIFT descriptors. We introduce a new retrieval system\nthat is based on the inverted index and outperforms the multi-index by a large\nmargin for the same memory consumption and construction complexity. For\nexample, our system achieves the state-of-the-art recall rates several times\nfaster on the dataset of one billion deep descriptors compared to the efficient\nimplementation of the inverted multi-index from the FAISS library.</p>\n", "tags": ["DATASETS", "Large Scale Search", "Vector Indexing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [3.2655892372131348, 9.441505432128906], "cluster": 4}, {"key": "baranchuk2019learning", "year": "2019", "citations": "8", "title": "Learning To Route In Similarity Graphs", "abstract": "<p>Recently similarity graphs became the leading paradigm for efficient nearest\nneighbor search, outperforming traditional tree-based and LSH-based methods.\nSimilarity graphs perform the search via greedy routing: a query traverses the\ngraph and in each vertex moves to the adjacent vertex that is the closest to\nthis query. In practice, similarity graphs are often susceptible to local\nminima, when queries do not reach its nearest neighbors, getting stuck in\nsuboptimal vertices. In this paper we propose to learn the routing function\nthat overcomes local minima via incorporating information about the graph\nglobal structure. In particular, we augment the vertices of a given graph with\nadditional representations that are learned to provide the optimal routing from\nthe start vertex to the query nearest neighbor. By thorough experiments, we\ndemonstrate that the proposed learnable routing successfully diminishes the\nlocal minima problem and significantly improves the overall search performance.</p>\n", "tags": ["Tree Based ANN", "Locality Sensitive Hashing", "Evaluation"], "tsne_embedding": [20.758914947509766, 13.040164947509766], "cluster": 0}, {"key": "bateni2024efficient", "year": "2024", "citations": "33", "title": "Efficient Centroid-linkage Clustering", "abstract": "<p>We give an efficient algorithm for Centroid-Linkage Hierarchical\nAgglomerative Clustering (HAC), which computes a \\(c\\)-approximate clustering in\nroughly \\(n^{1+O(1/c^2)}\\) time. We obtain our result by combining a new\nCentroid-Linkage HAC algorithm with a novel fully dynamic data structure for\nnearest neighbor search which works under adaptive updates.\n  We also evaluate our algorithm empirically. By leveraging a state-of-the-art\nnearest-neighbor search library, we obtain a fast and accurate Centroid-Linkage\nHAC algorithm. Compared to an existing state-of-the-art exact baseline, our\nimplementation maintains the clustering quality while delivering up to a\n\\(36\\times\\) speedup due to performing fewer distance comparisons.</p>\n", "tags": ["Tools & Libraries", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [18.333711624145508, 4.922810077667236], "cluster": 0}, {"key": "bawa2025lsh", "year": "2025", "citations": "5", "title": "LSH Forest: Self-tuning Indexes For Similarity Search", "abstract": "<p>We consider the problem of indexing high-dimensional data for answering (approximate) similarity-search queries. Similarity indexes prove to be important in a wide variety of settings: Web search\nengines desire fast, parallel, main-memory-based indexes for similarity search on text data; database systems desire disk-based similarity indexes for high-dimensional data, including text and images;\npeer-to-peer systems desire distributed similarity indexes with low\ncommunication cost. We propose an indexing scheme called LSH\nForest which is applicable in all the above contexts. Our index uses the well-known technique of locality-sensitive hashing (LSH),\nbut improves upon previous designs by (a) eliminating the different data-dependent parameters for which LSH must be constantly hand-tuned, and (b) improving on LSH\u2019s performance guarantees for skewed data distributions while retaining the same storage\nand query overhead. We show how to construct this index in main\nmemory, on disk, in parallel systems, and in peer-to-peer systems.\nWe evaluate the design with experiments on multiple text corpora\nand demonstrate both the self-tuning nature and the superior performance of LSH Forest.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Graph Based ANN", "Similarity Search", "Evaluation"], "tsne_embedding": [10.795221328735352, -0.40496328473091125], "cluster": 4}, {"key": "beck2019distributed", "year": "2019", "citations": "29", "title": "A Distributed And Approximated Nearest Neighbors Algorithm For An Efficient Large Scale Mean Shift Clustering", "abstract": "<p>In this paper we target the class of modal clustering methods where clusters\nare defined in terms of the local modes of the probability density function\nwhich generates the data. The most well-known modal clustering method is the\nk-means clustering. Mean Shift clustering is a generalization of the k-means\nclustering which computes arbitrarily shaped clusters as defined as the basins\nof attraction to the local modes created by the density gradient ascent paths.\nDespite its potential, the Mean Shift approach is a computationally expensive\nmethod for unsupervised learning. Thus, we introduce two contributions aiming\nto provide clustering algorithms with a linear time complexity, as opposed to\nthe quadratic time complexity for the exact Mean Shift clustering. Firstly we\npropose a scalable procedure to approximate the density gradient ascent.\nSecond, our proposed scalable cluster labeling technique is presented. Both\npropositions are based on Locality Sensitive Hashing (LSH) to approximate\nnearest neighbors. These two techniques may be used for moderate sized\ndatasets. Furthermore, we show that using our proposed approximations of the\ndensity gradient ascent as a pre-processing step in other clustering methods\ncan also improve dedicated classification metrics. For the latter, a\ndistributed implementation, written for the Spark/Scala ecosystem is proposed.\nFor all these considered clustering methods, we present experimental results\nillustrating their labeling accuracy and their potential to solve concrete\nproblems.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "DATASETS"], "tsne_embedding": [15.890778541564941, 7.490764141082764], "cluster": 0}, {"key": "beierle2018do", "year": "2018", "citations": "8", "title": "Do You Like What I Like? Similarity Estimation In Proximity-based Mobile Social Networks", "abstract": "<p>While existing social networking services tend to connect people who know\neach other, people show a desire to also connect to yet unknown people in\nphysical proximity. Existing research shows that people tend to connect to\nsimilar people. Utilizing technology in order to stimulate human interaction\nbetween strangers, we consider the scenario of two strangers meeting. On the\nexample of similarity in musical taste, we develop a solution for the problem\nof similarity estimation in proximity-based mobile social networks. We show\nthat a single exchange of a probabilistic data structure between two devices\ncan closely estimate the similarity of two users - without the need to contact\na third-party server.We introduce metrics for fast and space-efficient\napproximation of the Dice coefficient of two multisets - based on the\ncomparison of two Counting Bloom Filters or two Count-Min Sketches. Our\nanalysis shows that utilizing a single hash function minimizes the error when\ncomparing these probabilistic data structures. The size that should be chosen\nfor the data structure depends on the expected average number of unique input\nelements. Using real user data, we show that a Counting Bloom Filter with a\nsingle hash function and a length of 128 is sufficient to accurately estimate\nthe similarity between two multisets representing the musical tastes of two\nusers. Our approach is generalizable for any other similarity estimation of\nfrequencies represented as multisets.</p>\n", "tags": ["Hashing Methods", "Evaluation"], "tsne_embedding": [13.005547523498535, 4.120556354522705], "cluster": 4}, {"key": "beling2025phast", "year": "2025", "citations": "93", "title": "Phast -- Perfect Hashing With Fast Evaluation", "abstract": "<p>Perfect hash functions give unique \u201cnames\u201d to arbitrary keys requiring only a few bits per key. This is an essential building block in applications like static hash tables, databases, or bioinformatics. This paper introduces the PHast approach that has the currently fastest query time with competitive construction time and space consumption. PHast improves bucket-placement which first hashes each key k to a bucket, and then looks for the bucket seed s such that a secondary hash function maps pairs (s,k) in a collision-free way. PHast can use small-range primary hash functions with linear mapping, fixed-width encoding of seeds, and parallel construction. This is achieved using small overlapping slices of allowed values and bumping to handle unsuccessful seed assignment.</p>\n", "tags": ["Hashing Methods", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [-0.4227008819580078, -13.68625259399414], "cluster": 9}, {"key": "belyy2018memoir", "year": "2018", "citations": "13", "title": "MEMOIR: Multi-class Extreme Classification With Inexact Margin", "abstract": "<p>Multi-class classification with a very large number of classes, or extreme\nclassification, is a challenging problem from both statistical and\ncomputational perspectives. Most of the classical approaches to multi-class\nclassification, including one-vs-rest or multi-class support vector machines,\nrequire the exact estimation of the classifier\u2019s margin, at both the training\nand the prediction steps making them intractable in extreme classification\nscenarios. In this paper, we study the impact of computing an approximate\nmargin using nearest neighbor (ANN) search structures combined with\nlocality-sensitive hashing (LSH). This approximation allows to dramatically\nreduce both the training and the prediction time without a significant loss in\nperformance. We theoretically prove that this approximation does not lead to a\nsignificant loss of the risk of the model and provide empirical evidence over\nfive publicly available large scale datasets, showing that the proposed\napproach is highly competitive with respect to state-of-the-art approaches on\ntime, memory and performance measures.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Evaluation", "DATASETS"], "tsne_embedding": [16.013057708740234, 3.018954038619995], "cluster": 4}, {"key": "bender2021iceberg", "year": "2021", "citations": "10", "title": "Iceberg Hashing: Optimizing Many Hash-table Criteria At Once", "abstract": "<p>Despite being one of the oldest data structures in computer science, hash\ntables continue to be the focus of a great deal of both theoretical and\nempirical research. A central reason for this is that many of the fundamental\nproperties that one desires from a hash table are difficult to achieve\nsimultaneously; thus many variants offering different trade-offs have been\nproposed.\n  This paper introduces Iceberg hashing, a hash table that simultaneously\noffers the strongest known guarantees on a large number of core properties.\nIceberg hashing supports constant-time operations while improving on the state\nof the art for space efficiency, cache efficiency, and low failure probability.\nIceberg hashing is also the first hash table to support a load factor of up to\n\\(1 - o(1)\\) while being stable, meaning that the position where an element is\nstored only ever changes when resizes occur. In fact, in the setting where keys\nare \\(\\Theta(log n)\\) bits, the space guarantees that Iceberg hashing offers,\nnamely that it uses at most \\(log \\binom{|U|}{n} + O(n log log n)\\) bits to\nstore \\(n\\) items from a universe \\(U\\), matches a lower bound by Demaine et al.\nthat applies to any stable hash table.\n  Iceberg hashing introduces new general-purpose techniques for some of the\nmost basic aspects of hash-table design. Notably, our indirection-free\ntechnique for dynamic resizing, which we call waterfall addressing, and our\ntechniques for achieving stability and very-high probability guarantees, can be\napplied to any hash table that makes use of the front-yard/backyard paradigm\nfor hash table design.</p>\n", "tags": ["Hashing Methods", "Efficiency And Optimization"], "tsne_embedding": [-5.312596321105957, -28.09334373474121], "cluster": 5}, {"key": "bender2021optimal", "year": "2021", "citations": "16", "title": "On The Optimal Time/space Tradeoff For Hash Tables", "abstract": "<p>For nearly six decades, the central open question in the study of hash tables\nhas been to determine the optimal achievable tradeoff curve between time and\nspace. State-of-the-art hash tables offer the following guarantee: If\nkeys/values are Theta(log n) bits each, then it is possible to achieve\nconstant-time insertions/deletions/queries while wasting only O(loglog n) bits\nof space per key when compared to the information-theoretic optimum. Even prior\nto this bound being achieved, the target of O(loglog n) wasted bits per key was\nknown to be a natural end goal, and was proven to be optimal for a number of\nclosely related problems (e.g., stable hashing, dynamic retrieval, and\ndynamically-resized filters).\n  This paper shows that O(loglog n) wasted bits per key is not the end of the\nline for hashing. In fact, for any k \\in [log* n], it is possible to achieve\nO(k)-time insertions/deletions, O(1)-time queries, and O(log^{(k)} n) wasted\nbits per key (all with high probability in n). This means that, each time we\nincrease insertion/deletion time by an <em>additive constant</em>, we reduce the\nwasted bits per key <em>exponentially</em>. We further show that this tradeoff\ncurve is the best achievable by any of a large class of hash tables, including\nany hash table designed using the current framework for making constant-time\nhash tables succinct.</p>\n", "tags": ["Tools & Libraries", "Hashing Methods"], "tsne_embedding": [-4.91329288482666, -27.340213775634766], "cluster": 5}, {"key": "bera2021dimensionality", "year": "2021", "citations": "6", "title": "Dimensionality Reduction For Categorical Data", "abstract": "<p>Categorical attributes are those that can take a discrete set of values,\ne.g., colours. This work is about compressing vectors over categorical\nattributes to low-dimension discrete vectors. The current hash-based methods\ncompressing vectors over categorical attributes to low-dimension discrete\nvectors do not provide any guarantee on the Hamming distances between the\ncompressed representations. Here we present FSketch to create sketches for\nsparse categorical data and an estimator to estimate the pairwise Hamming\ndistances among the uncompressed data only from their sketches. We claim that\nthese sketches can be used in the usual data mining tasks in place of the\noriginal data without compromising the quality of the task. For that, we ensure\nthat the sketches also are categorical, sparse, and the Hamming distance\nestimates are reasonably precise. Both the sketch construction and the Hamming\ndistance estimation algorithms require just a single-pass; furthermore, changes\nto a data point can be incorporated into its sketch in an efficient manner. The\ncompressibility depends upon how sparse the data is and is independent of the\noriginal dimension \u2013 making our algorithm attractive for many real-life\nscenarios. Our claims are backed by rigorous theoretical analysis of the\nproperties of FSketch and supplemented by extensive comparative evaluations\nwith related algorithms on some real-world datasets. We show that FSketch is\nsignificantly faster, and the accuracy obtained by using its sketches are among\nthe top for the standard unsupervised tasks of RMSE, clustering and similarity\nsearch.</p>\n", "tags": ["Compact Codes", "DATASETS", "Evaluation"], "tsne_embedding": [7.924106597900391, 7.526237487792969], "cluster": 4}, {"key": "bera2021quint", "year": "2021", "citations": "5", "title": "QUINT: Node Embedding Using Network Hashing", "abstract": "<p>Representation learning using network embedding has received tremendous\nattention due to its efficacy to solve downstream tasks. Popular embedding\nmethods (such as deepwalk, node2vec, LINE) are based on a neural architecture,\nthus unable to scale on large networks both in terms of time and space usage.\nRecently, we proposed BinSketch, a sketching technique for compressing binary\nvectors to binary vectors. In this paper, we show how to extend BinSketch and\nuse it for network hashing. Our proposal named QUINT is built upon BinSketch,\nand it embeds nodes of a sparse network onto a low-dimensional space using\nsimple bi-wise operations. QUINT is the first of its kind that provides\ntremendous gain in terms of speed and space usage without compromising much on\nthe accuracy of the downstream tasks. Extensive experiments are conducted to\ncompare QUINT with seven state-of-the-art network embedding methods for two end\ntasks - link prediction and node classification. We observe huge performance\ngain for QUINT in terms of speedup (up to 7000x) and space saving (up to 80x)\ndue to its bit-wise nature to obtain node embedding. Moreover, QUINT is a\nconsistent top-performer for both the tasks among the baselines across all the\ndatasets. Our empirical observations are backed by rigorous theoretical\nanalysis to justify the effectiveness of QUINT. In particular, we prove that\nQUINT retains enough structural information which can be used further to\napproximate many topological properties of networks with high confidence.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [-2.045065402984619, -16.945371627807617], "cluster": 5}, {"key": "bhatnagar2024piecewise", "year": "2024", "citations": "7", "title": "Piecewise-linear Manifolds For Deep Metric Learning", "abstract": "<p>Unsupervised deep metric learning (UDML) focuses on learning a semantic\nrepresentation space using only unlabeled data. This challenging problem\nrequires accurately estimating the similarity between data points, which is\nused to supervise a deep network. For this purpose, we propose to model the\nhigh-dimensional data manifold using a piecewise-linear approximation, with\neach low-dimensional linear piece approximating the data manifold in a small\nneighborhood of a point. These neighborhoods are used to estimate similarity\nbetween data points. We empirically show that this similarity estimate\ncorrelates better with the ground truth than the similarity estimates of\ncurrent state-of-the-art techniques. We also show that proxies, commonly used\nin supervised metric learning, can be used to model the piecewise-linear\nmanifold in an unsupervised setting, helping improve performance. Our method\noutperforms existing unsupervised metric learning approaches on standard\nzero-shot image retrieval benchmarks.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [-17.42603302001953, 5.063017845153809], "cluster": 3}, {"key": "bhunia2018texture", "year": "2018", "citations": "17", "title": "Texture Synthesis Guided Deep Hashing For Texture Image Retrieval", "abstract": "<p>With the large-scale explosion of images and videos over the internet,\nefficient hashing methods have been developed to facilitate memory and time\nefficient retrieval of similar images. However, none of the existing works uses\nhashing to address texture image retrieval mostly because of the lack of\nsufficiently large texture image databases. Our work addresses this problem by\ndeveloping a novel deep learning architecture that generates binary hash codes\nfor input texture images. For this, we first pre-train a Texture Synthesis\nNetwork (TSN) which takes a texture patch as input and outputs an enlarged view\nof the texture by injecting newer texture content. Thus it signifies that the\nTSN encodes the learnt texture specific information in its intermediate layers.\nIn the next stage, a second network gathers the multi-scale feature\nrepresentations from the TSN\u2019s intermediate layers using channel-wise\nattention, combines them in a progressive manner to a dense continuous\nrepresentation which is finally converted into a binary hash code with the help\nof individual and pairwise label information. The new enlarged texture patches\nalso help in data augmentation to alleviate the problem of insufficient texture\ndata and are used to train the second stage of the network. Experiments on\nthree public texture image retrieval datasets indicate the superiority of our\ntexture synthesis guided hashing approach over current state-of-the-art\nmethods.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Neural Hashing", "Similarity Search"], "tsne_embedding": [-11.993817329406738, -6.418936729431152], "cluster": 1}, {"key": "bibak2020mmh", "year": "2020", "citations": "10", "title": "MMH* With Arbitrary Modulus Is Always Almost-universal", "abstract": "<p>Universal hash functions, discovered by Carter and Wegman in 1979, are of\ngreat importance in computer science with many applications. MMH\\(^<em>\\) is a\nwell-known \\(\\triangle\\)-universal hash function family, based on the evaluation\nof a dot product modulo a prime. In this paper, we introduce a generalization\nof MMH\\(^</em>\\), that we call GMMH\\(^<em>\\), using the same construction as MMH\\(^</em>\\) but\nwith an arbitrary integer modulus \\(n&gt;1\\), and show that GMMH\\(^*\\) is\n\\(\\frac{1}{p}\\)-almost-\\(\\triangle\\)-universal, where \\(p\\) is the smallest prime\ndivisor of \\(n\\). This bound is tight.</p>\n", "tags": ["Hashing Methods", "Evaluation"], "tsne_embedding": [29.40458106994629, -3.7641749382019043], "cluster": 7}, {"key": "bingmann2019cobs", "year": "2019", "citations": "67", "title": "COBS: A Compact Bit-sliced Signature Index", "abstract": "<p>We present COBS, a COmpact Bit-sliced Signature index, which is a cross-over\nbetween an inverted index and Bloom filters. Our target application is to index\n\\(k\\)-mers of DNA samples or \\(q\\)-grams from text documents and process\napproximate pattern matching queries on the corpus with a user-chosen coverage\nthreshold. Query results may contain a number of false positives which\ndecreases exponentially with the query length. We compare COBS to seven other\nindex software packages on 100000 microbial DNA samples. COBS\u2019 compact but\nsimple data structure outperforms the other indexes in construction time and\nquery performance with Mantis by Pandey et al. in second place. However, unlike\nMantis and other previous work, COBS does not need the complete index in RAM\nand is thus designed to scale to larger document sets.</p>\n", "tags": ["Evaluation"], "tsne_embedding": [7.523890495300293, -19.11713409423828], "cluster": 5}, {"key": "biswas2020perceptual", "year": "2020", "citations": "26", "title": "Perceptual Hashing Applied To Tor Domains Recognition", "abstract": "<p>The Tor darknet hosts different types of illegal content, which are monitored\nby cybersecurity agencies. However, manually classifying Tor content can be\nslow and error-prone. To support this task, we introduce Frequency-Dominant\nNeighborhood Structure (F-DNS), a new perceptual hashing method for\nautomatically classifying domains by their screenshots. First, we evaluated\nF-DNS using images subject to various content preserving operations. We\ncompared them with their original images, achieving better correlation\ncoefficients than other state-of-the-art methods, especially in the case of\nrotation. Then, we applied F-DNS to categorize Tor domains using the Darknet\nUsage Service Images-2K (DUSI-2K), a dataset with screenshots of active Tor\nservice domains. Finally, we measured the performance of F-DNS against an image\nclassification approach and a state-of-the-art hashing method. Our proposal\nobtained 98.75% accuracy in Tor images, surpassing all other methods compared.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Evaluation"], "tsne_embedding": [-14.115800857543945, 13.2967529296875], "cluster": 3}, {"key": "black2021compositional", "year": "2021", "citations": "75", "title": "Compositional Sketch Search", "abstract": "<p>We present an algorithm for searching image collections using free-hand\nsketches that describe the appearance and relative positions of multiple\nobjects. Sketch based image retrieval (SBIR) methods predominantly match\nqueries containing a single, dominant object invariant to its position within\nan image. Our work exploits drawings as a concise and intuitive representation\nfor specifying entire scene compositions. We train a convolutional neural\nnetwork (CNN) to encode masked visual features from sketched objects, pooling\nthese into a spatial descriptor encoding the spatial relationships and\nappearances of objects in the composition. Training the CNN backbone as a\nSiamese network under triplet loss yields a metric search embedding for\nmeasuring compositional similarity which may be efficiently leveraged for\nvisual search by applying product quantization.</p>\n", "tags": ["Image Retrieval", "Quantization", "Distance Metric Learning"], "tsne_embedding": [-0.8584293723106384, 17.167926788330078], "cluster": 6}, {"key": "blundo2011espresso", "year": "2011", "citations": "44", "title": "Espresso: Efficient Privacy-preserving Evaluation Of Sample Set Similarity", "abstract": "<p>Electronic information is increasingly often shared among entities without\ncomplete mutual trust. To address related security and privacy issues, a few\ncryptographic techniques have emerged that support privacy-preserving\ninformation sharing and retrieval. One interesting open problem in this context\ninvolves two parties that need to assess the similarity of their datasets, but\nare reluctant to disclose their actual content. This paper presents an\nefficient and provably-secure construction supporting the privacy-preserving\nevaluation of sample set similarity, where similarity is measured as the\nJaccard index. We present two protocols: the first securely computes the\n(Jaccard) similarity of two sets, and the second approximates it, using MinHash\ntechniques, with lower complexities. We show that our novel protocols are\nattractive in many compelling applications, including document/multimedia\nsimilarity, biometric authentication, and genetic tests. In the process, we\ndemonstrate that our constructions are appreciably more efficient than prior\nwork.</p>\n", "tags": ["Locality Sensitive Hashing", "Evaluation", "DATASETS"], "tsne_embedding": [9.282756805419922, -21.83885383605957], "cluster": 5}, {"key": "brodu2006spherical", "year": "2006", "citations": "5", "title": "Spherical Indexing For Neighborhood Queries", "abstract": "<p>This is an algorithm for finding neighbors when the objects can freely move\nand have no predefined position. The query consists in finding neighbors for a\ncenter location and a given radius. Space is discretized in cubic cells. This\nalgorithm introduces a direct spherical indexing that gives the list of all\ncells making up the query sphere, for any radius and any center location. It\ncan additionally take in account both cyclic and non-cyclic regions of\ninterest. Finding only the K nearest neighbors naturally benefits from the\nspherical indexing by minimally running through the sphere from center to edge,\nand reducing the maximum distance when K neighbors have been found.</p>\n", "tags": [], "tsne_embedding": [19.03804588317871, -4.324582099914551], "cluster": 7}, {"key": "brooks2017multi", "year": "2017", "citations": "10", "title": "Multi-level Spherical Locality Sensitive Hashing For Approximate Near Neighbors", "abstract": "<p>This paper introduces \u201cMulti-Level Spherical LSH\u201d: parameter-free, a\nmulti-level, data-dependant Locality Sensitive Hashing data structure for\nsolving the Approximate Near Neighbors Problem (ANN). This data structure uses\na modified version of a multi-probe adaptive querying algorithm, with the\npotential of achieving a \\(O(n^p + t)\\) query run time, for all inputs n where \\(t\n&lt;= n\\).</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods"], "tsne_embedding": [24.957456588745117, -3.734285831451416], "cluster": 7}, {"key": "bruch2023approximate", "year": "2023", "citations": "6", "title": "An Approximate Algorithm For Maximum Inner Product Search Over Streaming Sparse Vectors", "abstract": "<p>Maximum Inner Product Search or top-k retrieval on sparse vectors is\nwell-understood in information retrieval, with a number of mature algorithms\nthat solve it exactly. However, all existing algorithms are tailored to text\nand frequency-based similarity measures. To achieve optimal memory footprint\nand query latency, they rely on the near stationarity of documents and on laws\ngoverning natural languages. We consider, instead, a setup in which collections\nare streaming \u2013 necessitating dynamic indexing \u2013 and where indexing and\nretrieval must work with arbitrarily distributed real-valued vectors. As we\nshow, existing algorithms are no longer competitive in this setup, even against\nnaive solutions. We investigate this gap and present a novel approximate\nsolution, called Sinnamon, that can efficiently retrieve the top-k results for\nsparse real valued vectors drawn from arbitrary distributions. Notably,\nSinnamon offers levers to trade-off memory consumption, latency, and accuracy,\nmaking the algorithm suitable for constrained applications and systems. We give\ntheoretical results on the error introduced by the approximate nature of the\nalgorithm, and present an empirical evaluation of its performance on two\nhardware platforms and synthetic and real-valued datasets. We conclude by\nlaying out concrete directions for future research on this general top-k\nretrieval problem over sparse vectors.</p>\n", "tags": ["DATASETS", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [13.887812614440918, -5.796230792999268], "cluster": 2}, {"key": "bruch2024efficient", "year": "2024", "citations": "6", "title": "Efficient Inverted Indexes For Approximate Retrieval Over Learned Sparse Representations", "abstract": "<p>Learned sparse representations form an attractive class of contextual\nembeddings for text retrieval. That is so because they are effective models of\nrelevance and are interpretable by design. Despite their apparent compatibility\nwith inverted indexes, however, retrieval over sparse embeddings remains\nchallenging. That is due to the distributional differences between learned\nembeddings and term frequency-based lexical models of relevance such as BM25.\nRecognizing this challenge, a great deal of research has gone into, among other\nthings, designing retrieval algorithms tailored to the properties of learned\nsparse representations, including approximate retrieval systems. In fact, this\ntask featured prominently in the latest BigANN Challenge at NeurIPS 2023, where\napproximate algorithms were evaluated on a large benchmark dataset by\nthroughput and recall. In this work, we propose a novel organization of the\ninverted index that enables fast yet effective approximate retrieval over\nlearned sparse embeddings. Our approach organizes inverted lists into\ngeometrically-cohesive blocks, each equipped with a summary vector. During\nquery processing, we quickly determine if a block must be evaluated using the\nsummaries. As we show experimentally, single-threaded query processing using\nour method, Seismic, reaches sub-millisecond per-query latency on various\nsparse embeddings of the MS MARCO dataset while maintaining high recall. Our\nresults indicate that Seismic is one to two orders of magnitude faster than\nstate-of-the-art inverted index-based solutions and further outperforms the\nwinning (graph-based) submissions to the BigANN Challenge by a significant\nmargin.</p>\n", "tags": ["DATASETS", "Graph Based ANN", "Efficiency And Optimization", "Text Retrieval", "SIGIR", "Evaluation"], "tsne_embedding": [-16.36505889892578, -10.315499305725098], "cluster": 1}, {"key": "bruch2024optimistic", "year": "2024", "citations": "6", "title": "Optimistic Query Routing In Clustering-based Approximate Maximum Inner Product Search", "abstract": "<p>Clustering-based nearest neighbor search is an effective method in which\npoints are partitioned into geometric shards to form an index, with only a few\nshards searched during query processing to find a set of top-\\(k\\) vectors. Even\nthough the search efficacy is heavily influenced by the algorithm that\nidentifies the shards to probe, it has received little attention in the\nliterature. This work bridges that gap by studying routing in clustering-based\nmaximum inner product search. We unpack existing routers and notice the\nsurprising contribution of optimism. We then take a page from the sequential\ndecision making literature and formalize that insight following the principle\nof ``optimism in the face of uncertainty.\u2019\u2019 In particular, we present a\nframework that incorporates the moments of the distribution of inner products\nwithin each shard to estimate the maximum inner product. We then present an\ninstance of our algorithm that uses only the first two moments to reach the\nsame accuracy as state-of-the-art routers such as ScaNN by probing up to \\(50%\\)\nfewer points on benchmark datasets. Our algorithm is also space-efficient: we\ndesign a sketch of the second moment whose size is independent of the number of\npoints and requires \\(\\mathcal{O}(1)\\) vectors per shard.</p>\n", "tags": ["AAAI", "DATASETS", "Tools & Libraries", "Evaluation"], "tsne_embedding": [18.17715835571289, 5.01303243637085], "cluster": 0}, {"key": "bury2016efficient", "year": "2016", "citations": "8", "title": "Efficient Similarity Search In Dynamic Data Streams", "abstract": "<p>The Jaccard index is an important similarity measure for item sets and\nBoolean data. On large datasets, an exact similarity computation is often\ninfeasible for all item pairs both due to time and space constraints, giving\nrise to faster approximate methods. The algorithm of choice used to quickly\ncompute the Jaccard index \\(\\frac{\\vert A \\cap B \\vert}{\\vert A\\cup B\\vert}\\) of\ntwo item sets \\(A\\) and \\(B\\) is usually a form of min-hashing. Most min-hashing\nschemes are maintainable in data streams processing only additions, but none\nare known to work when facing item-wise deletions. In this paper, we\ninvestigate scalable approximation algorithms for rational set similarities, a\nbroad class of similarity measures including Jaccard. Motivated by a result of\nChierichetti and Kumar [J. ACM 2015] who showed any rational set similarity \\(S\\)\nadmits a locality sensitive hashing (LSH) scheme if and only if the\ncorresponding distance \\(1-S\\) is a metric, we can show that there exists a space\nefficient summary maintaining a \\((1\\pm \\epsilon)\\) multiplicative\napproximation to \\(1-S\\) in dynamic data streams. This in turn also yields a\n\\(\\epsilon\\) additive approximation of the similarity. The existence of these\napproximations hints at, but does not directly imply a LSH scheme in dynamic\ndata streams. Our second and main contribution now lies in the design of such a\nLSH scheme maintainable in dynamic data streams. The scheme is space efficient,\neasy to implement and to the best of our knowledge the first of its kind able\nto process deletions.</p>\n", "tags": ["Locality Sensitive Hashing", "Similarity Search", "Hashing Methods", "DATASETS"], "tsne_embedding": [13.59498119354248, 2.1234145164489746], "cluster": 4}, {"key": "cai2016revisit", "year": "2016", "citations": "29", "title": "A Revisit Of Hashing Algorithms For Approximate Nearest Neighbor Search", "abstract": "<p>Approximate Nearest Neighbor Search (ANNS) is a fundamental problem in many\nareas of machine learning and data mining. During the past decade, numerous\nhashing algorithms are proposed to solve this problem. Every proposed algorithm\nclaims outperform other state-of-the-art hashing methods. However, the\nevaluation of these hashing papers was not thorough enough, and those claims\nshould be re-examined. The ultimate goal of an ANNS method is returning the\nmost accurate answers (nearest neighbors) in the shortest time. If implemented\ncorrectly, almost all the hashing methods will have their performance improved\nas the code length increases. However, many existing hashing papers only report\nthe performance with the code length shorter than 128. In this paper, we\ncarefully revisit the problem of search with a hash index, and analyze the pros\nand cons of two popular hash index search procedures. Then we proposed a very\nsimple but effective two level index structures and make a thorough comparison\nof eleven popular hashing algorithms. Surprisingly, the random-projection-based\nLocality Sensitive Hashing (LSH) is the best performed algorithm, which is in\ncontradiction to the claims in all the other ten hashing papers. Despite the\nextreme simplicity of random-projection-based LSH, our results show that the\ncapability of this algorithm has been far underestimated. For the sake of\nreproducibility, all the codes used in the paper are released on GitHub, which\ncan be used as a testing platform for a fair comparison between various hashing\nalgorithms.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Graph Based ANN", "Vector Indexing", "Evaluation"], "tsne_embedding": [-2.22957444190979, -24.096296310424805], "cluster": 5}, {"key": "cai2017revisit", "year": "2017", "citations": "13", "title": "A Revisit On Deep Hashings For Large-scale Content Based Image Retrieval", "abstract": "<p>There is a growing trend in studying deep hashing methods for content-based\nimage retrieval (CBIR), where hash functions and binary codes are learnt using\ndeep convolutional neural networks and then the binary codes can be used to do\napproximate nearest neighbor (ANN) search. All the existing deep hashing papers\nreport their methods\u2019 superior performance over the traditional hashing methods\naccording to their experimental results. However, there are serious flaws in\nthe evaluations of existing deep hashing papers: (1) The datasets they used are\ntoo small and simple to simulate the real CBIR situation. (2) They did not\ncorrectly include the search time in their evaluation criteria, while the\nsearch time is crucial in real CBIR systems. (3) The performance of some\nunsupervised hashing algorithms (e.g., LSH) can easily be boosted if one uses\nmultiple hash tables, which is an important factor should be considered in the\nevaluation while most of the deep hashing papers failed to do so.\n  We re-evaluate several state-of-the-art deep hashing methods with a carefully\ndesigned experimental setting. Empirical results reveal that the performance of\nthese deep hashing methods are inferior to multi-table IsoH, a very simple\nunsupervised hashing method. Thus, the conclusions in all the deep hashing\npapers should be carefully re-examined.</p>\n", "tags": ["Image Retrieval", "Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Compact Codes", "Neural Hashing", "Evaluation"], "tsne_embedding": [-6.368277549743652, -4.435543537139893], "cluster": 9}, {"key": "cakaloglu2018text", "year": "2018", "citations": "6", "title": "Text Embeddings For Retrieval From A Large Knowledge Base", "abstract": "<p>Text embedding representing natural language documents in a semantic vector\nspace can be used for document retrieval using nearest neighbor lookup. In\norder to study the feasibility of neural models specialized for retrieval in a\nsemantically meaningful way, we suggest the use of the Stanford Question\nAnswering Dataset (SQuAD) in an open-domain question answering context, where\nthe first task is to find paragraphs useful for answering a given question.\nFirst, we compare the quality of various text-embedding methods on the\nperformance of retrieval and give an extensive empirical comparison on the\nperformance of various non-augmented base embedding with, and without IDF\nweighting. Our main results are that by training deep residual neural models,\nspecifically for retrieval purposes, can yield significant gains when it is\nused to augment existing embeddings. We also establish that deeper models are\nsuperior to this task. The best base baseline embeddings augmented by our\nlearned neural approach improves the top-1 paragraph recall of the system by\n14%.</p>\n", "tags": ["Graph Based ANN", "Text Retrieval", "Evaluation", "DATASETS"], "tsne_embedding": [-16.34113311767578, -1.4549484252929688], "cluster": 1}, {"key": "cakir2017mihash", "year": "2017", "citations": "99", "title": "Mihash: Online Hashing With Mutual Information", "abstract": "<p>Learning-based hashing methods are widely used for nearest neighbor\nretrieval, and recently, online hashing methods have demonstrated good\nperformance-complexity trade-offs by learning hash functions from streaming\ndata. In this paper, we first address a key challenge for online hashing: the\nbinary codes for indexed data must be recomputed to keep pace with updates to\nthe hash functions. We propose an efficient quality measure for hash functions,\nbased on an information-theoretic quantity, mutual information, and use it\nsuccessfully as a criterion to eliminate unnecessary hash table updates. Next,\nwe also show how to optimize the mutual information objective using stochastic\ngradient descent. We thus develop a novel hashing method, MIHash, that can be\nused in both online and batch settings. Experiments on image retrieval\nbenchmarks (including a 2.5M image dataset) confirm the effectiveness of our\nformulation, both in reducing hash table recomputations and in learning\nhigh-quality hash functions.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Compact Codes", "ICCV", "Evaluation"], "tsne_embedding": [4.631951332092285, -7.982411861419678], "cluster": 2}, {"key": "cakir2018hashing", "year": "2018", "citations": "31", "title": "Hashing With Binary Matrix Pursuit", "abstract": "<p>We propose theoretical and empirical improvements for two-stage hashing\nmethods. We first provide a theoretical analysis on the quality of the binary\ncodes and show that, under mild assumptions, a residual learning scheme can\nconstruct binary codes that fit any neighborhood structure with arbitrary\naccuracy. Secondly, we show that with high-capacity hash functions such as\nCNNs, binary code inference can be greatly simplified for many standard\nneighborhood definitions, yielding smaller optimization problems and more\nrobust codes. Incorporating our findings, we propose a novel two-stage hashing\nmethod that significantly outperforms previous hashing studies on widely used\nimage retrieval benchmarks.</p>\n", "tags": ["Compact Codes", "Image Retrieval", "Hashing Methods", "Evaluation"], "tsne_embedding": [4.080868244171143, 12.04151725769043], "cluster": 4}, {"key": "cakir2025adaptive", "year": "2025", "citations": "88", "title": "Adaptive Hashing For Fast Similarity Search", "abstract": "<p>With the staggering growth in image and video datasets,\nalgorithms that provide fast similarity search and compact\nstorage are crucial. Hashing methods that map the\ndata into Hamming space have shown promise; however,\nmany of these methods employ a batch-learning strategy\nin which the computational cost and memory requirements\nmay become intractable and infeasible with larger and\nlarger datasets. To overcome these challenges, we propose\nan online learning algorithm based on stochastic gradient\ndescent in which the hash functions are updated iteratively\nwith streaming data. In experiments with three image retrieval\nbenchmarks, our online algorithm attains retrieval\naccuracy that is comparable to competing state-of-the-art\nbatch-learning solutions, while our formulation is orders\nof magnitude faster and being online it is adaptable to the\nvariations of the data. Moreover, our formulation yields improved\nretrieval performance over a recently reported online\nhashing technique, Online Kernel Hashing.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "ICCV", "Similarity Search", "Evaluation"], "tsne_embedding": [-5.111440181732178, 21.070375442504883], "cluster": 6}, {"key": "cao2016correlation", "year": "2016", "citations": "62", "title": "Correlation Hashing Network For Efficient Cross-modal Retrieval", "abstract": "<p>Hashing is widely applied to approximate nearest neighbor search for\nlarge-scale multimodal retrieval with storage and computation efficiency.\nCross-modal hashing improves the quality of hash coding by exploiting semantic\ncorrelations across different modalities. Existing cross-modal hashing methods\nfirst transform data into low-dimensional feature vectors, and then generate\nbinary codes by another separate quantization step. However, suboptimal hash\ncodes may be generated since the quantization error is not explicitly minimized\nand the feature representation is not jointly optimized with the binary codes.\nThis paper presents a Correlation Hashing Network (CHN) approach to cross-modal\nhashing, which jointly learns good data representation tailored to hash coding\nand formally controls the quantization error. The proposed CHN is a hybrid deep\narchitecture that constitutes a convolutional neural network for learning good\nimage representations, a multilayer perception for learning good text\nrepresentations, two hashing layers for generating compact binary codes, and a\nstructured max-margin loss that integrates all things together to enable\nlearning similarity-preserving and high-quality hash codes. Extensive empirical\nstudy shows that CHN yields state of the art cross-modal retrieval performance\non standard benchmarks.</p>\n", "tags": ["Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Multimodal Retrieval", "Quantization", "Evaluation"], "tsne_embedding": [-9.437725067138672, 2.9381115436553955], "cluster": 8}, {"key": "cao2016transitive", "year": "2016", "citations": "25", "title": "Transitive Hashing Network For Heterogeneous Multimedia Retrieval", "abstract": "<p>Hashing has been widely applied to large-scale multimedia retrieval due to\nthe storage and retrieval efficiency. Cross-modal hashing enables efficient\nretrieval from database of one modality in response to a query of another\nmodality. Existing work on cross-modal hashing assumes heterogeneous\nrelationship across modalities for hash function learning. In this paper, we\nrelax the strong assumption by only requiring such heterogeneous relationship\nin an auxiliary dataset different from the query/database domain. We craft a\nhybrid deep architecture to simultaneously learn the cross-modal correlation\nfrom the auxiliary dataset, and align the dataset distributions between the\nauxiliary dataset and the query/database domain, which generates transitive\nhash codes for heterogeneous multimedia retrieval. Extensive experiments\nexhibit that the proposed approach yields state of the art multimedia retrieval\nperformance on public datasets, i.e. NUS-WIDE, ImageNet-YahooQA.</p>\n", "tags": ["AAAI", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Evaluation"], "tsne_embedding": [-3.2925567626953125, 15.989389419555664], "cluster": 6}, {"key": "cao2017hashnet", "year": "2017", "citations": "632", "title": "Hashnet: Deep Learning To Hash By Continuation", "abstract": "<p>Learning to hash has been widely applied to approximate nearest neighbor\nsearch for large-scale multimedia retrieval, due to its computation efficiency\nand retrieval quality. Deep learning to hash, which improves retrieval quality\nby end-to-end representation learning and hash encoding, has received\nincreasing attention recently. Subject to the ill-posed gradient difficulty in\nthe optimization with sign activations, existing deep learning to hash methods\nneed to first learn continuous representations and then generate binary hash\ncodes in a separated binarization step, which suffer from substantial loss of\nretrieval quality. This work presents HashNet, a novel deep architecture for\ndeep learning to hash by continuation method with convergence guarantees, which\nlearns exactly binary hash codes from imbalanced similarity data. The key idea\nis to attack the ill-posed gradient problem in optimizing deep networks with\nnon-smooth binary activations by continuation method, in which we begin from\nlearning an easier network with smoothed activation function and let it evolve\nduring the training, until it eventually goes back to being the original,\ndifficult to optimize, deep network with the sign activation function.\nComprehensive empirical evidence shows that HashNet can generate exactly binary\nhash codes and yield state-of-the-art multimedia retrieval performance on\nstandard benchmarks.</p>\n", "tags": ["Hashing Methods", "Efficiency And Optimization", "Neural Hashing", "ICCV", "Evaluation"], "tsne_embedding": [-7.378027439117432, -8.844365119934082], "cluster": 9}, {"key": "cao2017transfer", "year": "2017", "citations": "15", "title": "Transfer Adversarial Hashing For Hamming Space Retrieval", "abstract": "<p>Hashing is widely applied to large-scale image retrieval due to the storage\nand retrieval efficiency. Existing work on deep hashing assumes that the\ndatabase in the target domain is identically distributed with the training set\nin the source domain. This paper relaxes this assumption to a transfer\nretrieval setting, which allows the database and the training set to come from\ndifferent but relevant domains. However, the transfer retrieval setting will\nintroduce two technical difficulties: first, the hash model trained on the\nsource domain cannot work well on the target domain due to the large\ndistribution gap; second, the domain gap makes it difficult to concentrate the\ndatabase points to be within a small Hamming ball. As a consequence, transfer\nretrieval performance within Hamming Radius 2 degrades significantly in\nexisting hashing methods. This paper presents Transfer Adversarial Hashing\n(TAH), a new hybrid deep architecture that incorporates a pairwise\n\\(t\\)-distribution cross-entropy loss to learn concentrated hash codes and an\nadversarial network to align the data distributions between the source and\ntarget domains. TAH can generate compact transfer hash codes for efficient\nimage retrieval on both source and target domains. Comprehensive experiments\nvalidate that TAH yields state of the art Hamming space retrieval performance\non standard datasets.</p>\n", "tags": ["Image Retrieval", "AAAI", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Neural Hashing", "Evaluation", "Robustness"], "tsne_embedding": [-7.779284954071045, 10.172746658325195], "cluster": 8}, {"key": "cao2018deep", "year": "2018", "citations": "33", "title": "Deep Priority Hashing", "abstract": "<p>Deep hashing enables image retrieval by end-to-end learning of deep\nrepresentations and hash codes from training data with pairwise similarity\ninformation. Subject to the distribution skewness underlying the similarity\ninformation, most existing deep hashing methods may underperform for imbalanced\ndata due to misspecified loss functions. This paper presents Deep Priority\nHashing (DPH), an end-to-end architecture that generates compact and balanced\nhash codes in a Bayesian learning framework. The main idea is to reshape the\nstandard cross-entropy loss for similarity-preserving learning such that it\ndown-weighs the loss associated to highly-confident pairs. This idea leads to a\nnovel priority cross-entropy loss, which prioritizes the training on uncertain\npairs over confident pairs. Also, we propose another priority quantization\nloss, which prioritizes hard-to-quantize examples for generation of nearly\nlossless hash codes. Extensive experiments demonstrate that DPH can generate\nhigh-quality hash codes and yield state-of-the-art image retrieval results on\nthree datasets, ImageNet, NUS-WIDE, and MS-COCO.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Neural Hashing", "Quantization", "Tools & Libraries"], "tsne_embedding": [-11.05466079711914, 4.665195941925049], "cluster": 8}, {"key": "cao2018end", "year": "2018", "citations": "65", "title": "End-to-end Latent Fingerprint Search", "abstract": "<p>Latent fingerprints are one of the most important and widely used sources of\nevidence in law enforcement and forensic agencies. Yet the performance of the\nstate-of-the-art latent recognition systems is far from satisfactory, and they\noften require manual markups to boost the latent search performance. Further,\nthe COTS systems are proprietary and do not output the true comparison scores\nbetween a latent and reference prints to conduct quantitative evidential\nanalysis. We present an end-to-end latent fingerprint search system, including\nautomated region of interest (ROI) cropping, latent image preprocessing,\nfeature extraction, feature comparison , and outputs a candidate list. Two\nseparate minutiae extraction models provide complementary minutiae templates.\nTo compensate for the small number of minutiae in small area and poor quality\nlatents, a virtual minutiae set is generated to construct a texture template. A\n96-dimensional descriptor is extracted for each minutia from its neighborhood.\nFor computational efficiency, the descriptor length for virtual minutiae is\nfurther reduced to 16 using product quantization. Our end-to-end system is\nevaluated on three latent databases: NIST SD27 (258 latents); MSP (1,200\nlatents), WVU (449 latents) and N2N (10,000 latents) against a background set\nof 100K rolled prints, which includes the true rolled mates of the latents with\nrank-1 retrieval rates of 65.7%, 69.4%, 65.5%, and 7.6% respectively. A\nmulti-core solution implemented on 24 cores obtains 1ms per latent to rolled\ncomparison.</p>\n", "tags": ["Quantization", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [-9.200613021850586, 0.6420379281044006], "cluster": 8}, {"key": "cao2019enhancing", "year": "2019", "citations": "94", "title": "Enhancing Remote Sensing Image Retrieval With Triplet Deep Metric Learning Network", "abstract": "<p>With the rapid growing of remotely sensed imagery data, there is a high\ndemand for effective and efficient image retrieval tools to manage and exploit\nsuch data. In this letter, we present a novel content-based remote sensing\nimage retrieval method based on Triplet deep metric learning convolutional\nneural network (CNN). By constructing a Triplet network with metric learning\nobjective function, we extract the representative features of the images in a\nsemantic space in which images from the same class are close to each other\nwhile those from different classes are far apart. In such a semantic space,\nsimple metric measures such as Euclidean distance can be used directly to\ncompare the similarity of images and effectively retrieve images of the same\nclass. We also investigate a supervised and an unsupervised learning methods\nfor reducing the dimensionality of the learned semantic features. We present\ncomprehensive experimental results on two publicly available remote sensing\nimage retrieval datasets and show that our method significantly outperforms\nstate-of-the-art.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Tools & Libraries", "Distance Metric Learning"], "tsne_embedding": [-11.99049186706543, 20.438512802124023], "cluster": 6}, {"key": "cao2019unsupervised", "year": "2019", "citations": "12", "title": "Unsupervised Deep Metric Learning Via Auxiliary Rotation Loss", "abstract": "<p>Deep metric learning is an important area due to its applicability to many\ndomains such as image retrieval and person re-identification. The main drawback\nof such models is the necessity for labeled data. In this work, we propose to\ngenerate pseudo-labels for deep metric learning directly from clustering\nassignment and we introduce unsupervised deep metric learning (UDML)\nregularized by a self-supervision (SS) task. In particular, we propose to\nregularize the training process by predicting image rotations. Our method\n(UDML-SS) jointly learns discriminative embeddings, unsupervised clustering\nassignments of the embeddings, as well as a self-supervised pretext task.\nUDML-SS iteratively cluster embeddings using traditional clustering algorithm\n(e.g., k-means), and sampling training pairs based on the cluster assignment\nfor metric learning, while optimizing self-supervised pretext task in a\nmulti-task fashion. The role of self-supervision is to stabilize the training\nprocess and encourages the model to learn meaningful feature representations\nthat are not distorted due to unreliable clustering assignments. The proposed\nmethod performs well on standard benchmarks for metric learning, where it\noutperforms current state-of-the-art approaches by a large margin and it also\nshows competitive performance with various metric learning loss functions.</p>\n", "tags": ["Image Retrieval", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [-22.282102584838867, 1.5299803018569946], "cluster": 3}, {"key": "cao2022context", "year": "2022", "citations": "14", "title": "Context Recovery And Knowledge Retrieval: A Novel Two-stream Framework For Video Anomaly Detection", "abstract": "<p>Video anomaly detection aims to find the events in a video that do not\nconform to the expected behavior. The prevalent methods mainly detect anomalies\nby snippet reconstruction or future frame prediction error. However, the error\nis highly dependent on the local context of the current snippet and lacks the\nunderstanding of normality. To address this issue, we propose to detect\nanomalous events not only by the local context, but also according to the\nconsistency between the testing event and the knowledge about normality from\nthe training data. Concretely, we propose a novel two-stream framework based on\ncontext recovery and knowledge retrieval, where the two streams can complement\neach other. For the context recovery stream, we propose a spatiotemporal U-Net\nwhich can fully utilize the motion information to predict the future frame.\nFurthermore, we propose a maximum local error mechanism to alleviate the\nproblem of large recovery errors caused by complex foreground objects. For the\nknowledge retrieval stream, we propose an improved learnable locality-sensitive\nhashing, which optimizes hash functions via a Siamese network and a mutual\ndifference loss. The knowledge about normality is encoded and stored in hash\ntables, and the distance between the testing event and the knowledge\nrepresentation is used to reveal the probability of anomaly. Finally, we fuse\nthe anomaly scores from the two streams to detect anomalies. Extensive\nexperiments demonstrate the effectiveness and complementarity of the two\nstreams, whereby the proposed two-stream framework achieves state-of-the-art\nperformance on four datasets.</p>\n", "tags": ["DATASETS", "Tools & Libraries", "Hashing Methods", "Evaluation"], "tsne_embedding": [-7.454960346221924, 15.177262306213379], "cluster": 6}, {"key": "cao2025collective", "year": "2025", "citations": "97", "title": "Collective Deep Quantization For Efficient Cross-modal Retrieval", "abstract": "<p>Cross-modal similarity retrieval is a problem about designing a retrieval system that supports querying across\ncontent modalities, e.g., using an image to retrieve for\ntexts. This paper presents a compact coding solution for\nefficient cross-modal retrieval, with a focus on the quantization approach which has already shown the superior\nperformance over the hashing solutions in single-modal\nsimilarity retrieval. We propose a collective deep quantization (CDQ) approach, which is the first attempt to\nintroduce quantization in end-to-end deep architecture\nfor cross-modal retrieval. The major contribution lies in\njointly learning deep representations and the quantizers\nfor both modalities using carefully-crafted hybrid networks and well-specified loss functions. In addition, our\napproach simultaneously learns the common quantizer\ncodebook for both modalities through which the crossmodal correlation can be substantially enhanced. CDQ\nenables efficient and effective cross-modal retrieval using inner product distance computed based on the common codebook with fast distance table lookup. Extensive experiments show that CDQ yields state of the art\ncross-modal retrieval results on standard benchmarks.</p>\n", "tags": ["AAAI", "Hashing Methods", "Multimodal Retrieval", "Similarity Search", "Quantization", "Evaluation"], "tsne_embedding": [1.1335864067077637, 3.1173770427703857], "cluster": 4}, {"key": "cao2025correlation", "year": "2025", "citations": "98", "title": "Correlation Autoencoder Hashing For Supervised Cross-modal Search", "abstract": "<p>Due to its storage and query efficiency, hashing has been widely\napplied to approximate nearest neighbor search from large-scale\ndatasets. While there is increasing interest in cross-modal hashing\nwhich facilitates cross-media retrieval by embedding data from different modalities into a common Hamming space, how to distill the\ncross-modal correlation structure effectively remains a challenging\nproblem. In this paper, we propose a novel supervised cross-modal\nhashing method, Correlation Autoencoder Hashing (CAH), to learn\ndiscriminative and compact binary codes based on deep autoencoders. Specifically, CAH jointly maximizes the feature correlation\nrevealed by bimodal data and the semantic correlation conveyed in\nsimilarity labels, while embeds them into hash codes by nonlinear\ndeep autoencoders. Extensive experiments clearly show the superior effectiveness and efficiency of CAH against the state-of-the-art\nhashing methods on standard cross-modal retrieval benchmarks.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Multimodal Retrieval", "Evaluation"], "tsne_embedding": [-0.8559114933013916, -1.1578434705734253], "cluster": 4}, {"key": "cao2025deep", "year": "2025", "citations": "358", "title": "Deep Cauchy Hashing For Hamming Space Retrieval", "abstract": "<p>Due to its computation efficiency and retrieval quality,\nhashing has been widely applied to approximate nearest\nneighbor search for large-scale image retrieval, while deep\nhashing further improves the retrieval quality by end-toend representation learning and hash coding. With compact\nhash codes, Hamming space retrieval enables the most efficient constant-time search that returns data points within a\ngiven Hamming radius to each query, by hash table lookups\ninstead of linear scan. However, subject to the weak capability of concentrating relevant images to be within a small\nHamming ball due to mis-specified loss functions, existing deep hashing methods may underperform for Hamming\nspace retrieval.  This work presents Deep Cauchy Hashing\n(DCH), a novel deep hashing model that generates compact\nand concentrated binary hash codes to enable efficient and\neffective Hamming space retrieval. The main idea is to design a pairwise cross-entropy loss based on Cauchy distribution, which penalizes significantly on similar image pairs\nwith Hamming distance larger than the given Hamming radius threshold. Comprehensive experiments demonstrate\nthat DCH can generate highly concentrated hash codes and\nyield state-of-the-art Hamming space retrieval performance\non three datasets, NUS-WIDE, CIFAR-10, and MS-COCO.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "CVPR", "Neural Hashing", "Evaluation"], "tsne_embedding": [-6.699739456176758, 10.693472862243652], "cluster": 6}, {"key": "cao2025hashgan", "year": "2025", "citations": "117", "title": "Hashgan: Deep Learning To Hash With Pair Conditional Wasserstein GAN", "abstract": "<p>Deep learning to hash improves image retrieval performance by end-to-end representation learning and hash coding from training data with pairwise similarity information.\nSubject to the scarcity of similarity information that is often\nexpensive to collect for many application domains, existing\ndeep learning to hash methods may overfit the training data\nand result in substantial loss of retrieval quality. This paper\npresents HashGAN, a novel architecture for deep learning\nto hash, which learns compact binary hash codes from both\nreal images and diverse images synthesized by generative\nmodels. The main idea is to augment the training data with\nnearly real images synthesized from a new Pair Conditional\nWasserstein GAN (PC-WGAN) conditioned on the pairwise\nsimilarity information. Extensive experiments demonstrate\nthat HashGAN can generate high-quality binary hash codes\nand yield state-of-the-art image retrieval performance on\nthree benchmarks, NUS-WIDE, CIFAR-10, and MS-COCO.</p>\n", "tags": ["CVPR", "Image Retrieval", "Hashing Methods", "Evaluation"], "tsne_embedding": [-11.335476875305176, 4.584208965301514], "cluster": 8}, {"key": "carreiraperpinan2025hashing", "year": "2025", "citations": "142", "title": "Hashing With Binary Autoencoders", "abstract": "<p>An attractive approach for fast search in image\ndatabases is binary hashing, where each high-dimensional,\nreal-valued image is mapped onto a low-dimensional, binary\nvector and the search is done in this binary space.\nFinding the optimal hash function is difficult because it involves\nbinary constraints, and most approaches approximate\nthe optimization by relaxing the constraints and then\nbinarizing the result. Here, we focus on the binary autoencoder\nmodel, which seeks to reconstruct an image from the\nbinary code produced by the hash function. We show that\nthe optimization can be simplified with the method of auxiliary\ncoordinates. This reformulates the optimization as\nalternating two easier steps: one that learns the encoder\nand decoder separately, and one that optimizes the code for\neach image. Image retrieval experiments show the resulting\nhash function outperforms or is competitive with state-ofthe-art\nmethods for binary hashing.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "CVPR", "Compact Codes", "Alt", "Evaluation"], "tsne_embedding": [-4.520187854766846, 8.38827896118164], "cluster": 8}, {"key": "carreiraperpi\u00f1\u00e1n2016ensemble", "year": "2016", "citations": "8", "title": "An Ensemble Diversity Approach To Supervised Binary Hashing", "abstract": "<p>Binary hashing is a well-known approach for fast approximate nearest-neighbor\nsearch in information retrieval. Much work has focused on affinity-based\nobjective functions involving the hash functions or binary codes. These\nobjective functions encode neighborhood information between data points and are\noften inspired by manifold learning algorithms. They ensure that the hash\nfunctions differ from each other through constraints or penalty terms that\nencourage codes to be orthogonal or dissimilar across bits, but this couples\nthe binary variables and complicates the already difficult optimization. We\npropose a much simpler approach: we train each hash function (or bit)\nindependently from each other, but introduce diversity among them using\ntechniques from classifier ensembles. Surprisingly, we find that not only is\nthis faster and trivially parallelizable, but it also improves over the more\ncomplex, coupled objective function, and achieves state-of-the-art precision\nand recall in experiments with image retrieval.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Compact Codes", "Alt", "Evaluation"], "tsne_embedding": [-3.4577088356018066, 8.101495742797852], "cluster": 8}, {"key": "castellano2020visual", "year": "2020", "citations": "40", "title": "Visual Link Retrieval And Knowledge Discovery In Painting Datasets", "abstract": "<p>Visual arts are of inestimable importance for the cultural, historic and\neconomic growth of our society. One of the building blocks of most analysis in\nvisual arts is to find similarity relationships among paintings of different\nartists and painting schools. To help art historians better understand visual\narts, this paper presents a framework for visual link retrieval and knowledge\ndiscovery in digital painting datasets. Visual link retrieval is accomplished\nby using a deep convolutional neural network to perform feature extraction and\na fully unsupervised nearest neighbor mechanism to retrieve links among\ndigitized paintings. Historical knowledge discovery is achieved by performing a\ngraph analysis that makes it possible to study influences among artists. An\nexperimental evaluation on a database collecting paintings by very popular\nartists shows the effectiveness of the method. The unsupervised strategy makes\nthe method interesting especially in cases where metadata are scarce,\nunavailable or difficult to collect.</p>\n", "tags": ["DATASETS", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-26.614450454711914, 10.016018867492676], "cluster": 3}, {"key": "centurion2023geometric", "year": "2023", "citations": "14", "title": "Geometric Algorithms For \\(k\\)-nn Poisoning", "abstract": "<p>We propose a label poisoning attack on geometric data sets against\n\\(k\\)-nearest neighbor classification. We provide an algorithm that can compute\nan \\(\\epsilon n\\)-additive approximation of the optimal poisoning in \\(n\\cdot\n2^{2^{O(d+k/\\epsilon)}}\\) time for a given data set \\(X \\in \\mathbb{R}^d\\),\nwhere \\(|X| = n\\). Our algorithm achieves its objectives through the application\nof multi-scale random partitions.</p>\n", "tags": [], "tsne_embedding": [22.88554573059082, -3.102109670639038], "cluster": 7}, {"key": "cerda2019encoding", "year": "2019", "citations": "24", "title": "Encoding High-cardinality String Categorical Variables", "abstract": "<p>Statistical models usually require vector representations of categorical\nvariables, using for instance one-hot encoding. This strategy breaks down when\nthe number of categories grows, as it creates high-dimensional feature vectors.\nAdditionally, for string entries, one-hot encoding does not capture information\nin their representation.Here, we seek low-dimensional encoding of\nhigh-cardinality string categorical variables. Ideally, these should be:\nscalable to many categories; interpretable to end users; and facilitate\nstatistical analysis. We introduce two encoding approaches for string\ncategories: a Gamma-Poisson matrix factorization on substring counts, and the\nmin-hash encoder, for fast approximation of string similarities. We show that\nmin-hash turns set inclusions into inequality relations that are easier to\nlearn. Both approaches are scalable and streamable. Experiments on real and\nsimulated data show that these methods improve supervised learning with\nhigh-cardinality categorical variables. We recommend the following: if\nscalability is central, the min-hash encoder is the best option as it does not\nrequire any data fit; if interpretability is important, the Gamma-Poisson\nfactorization is the best alternative, as it can be interpreted as one-hot\nencoding on inferred categories with informative feature names. Both models\nenable autoML on the original string entries as they remove the need for\nfeature engineering or data cleaning.</p>\n", "tags": ["Alt"], "tsne_embedding": [-2.927868366241455, -6.798320293426514], "cluster": 9}, {"key": "chadha2016voronoi", "year": "2016", "citations": "29", "title": "Voronoi-based Compact Image Descriptors: Efficient Region-of-interest Retrieval With VLAD And Deep-learning-based Descriptors", "abstract": "<p>We investigate the problem of image retrieval based on visual queries when\nthe latter comprise arbitrary regions-of-interest (ROI) rather than entire\nimages. Our proposal is a compact image descriptor that combines the\nstate-of-the-art in content-based descriptor extraction with a multi-level,\nVoronoi-based spatial partitioning of each dataset image. The proposed\nmulti-level Voronoi-based encoding uses a spatial hierarchical K-means over\ninterest-point locations, and computes a content-based descriptor over each\ncell. In order to reduce the matching complexity with minimal or no sacrifice\nin retrieval performance: (i) we utilize the tree structure of the spatial\nhierarchical K-means to perform a top-to-bottom pruning for local similarity\nmaxima; (ii) we propose a new image similarity score that combines relevant\ninformation from all partition levels into a single measure for similarity;\n(iii) we combine our proposal with a novel and efficient approach for optimal\nbit allocation within quantized descriptor representations. By deriving both a\nVoronoi-based VLAD descriptor (termed as Fast-VVLAD) and a Voronoi-based deep\nconvolutional neural network (CNN) descriptor (termed as Fast-VDCNN), we\ndemonstrate that our Voronoi-based framework is agnostic to the descriptor\nbasis, and can easily be slotted into existing frameworks. Via a range of ROI\nqueries in two standard datasets, it is shown that the Voronoi-based\ndescriptors achieve comparable or higher mean Average Precision against\nconventional grid-based spatial search, while offering more than two-fold\nreduction in complexity. Finally, beyond ROI queries, we show that Voronoi\npartitioning improves the geometric invariance of compact CNN descriptors,\nthereby resulting in competitive performance to the current state-of-the-art on\nwhole image retrieval.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Tools & Libraries", "Evaluation"], "tsne_embedding": [7.220221042633057, 11.415873527526855], "cluster": 0}, {"key": "chaidaroon2017variational", "year": "2017", "citations": "71", "title": "Variational Deep Semantic Hashing For Text Documents", "abstract": "<p>As the amount of textual data has been rapidly increasing over the past\ndecade, efficient similarity search methods have become a crucial component of\nlarge-scale information retrieval systems. A popular strategy is to represent\noriginal data samples by compact binary codes through hashing. A spectrum of\nmachine learning methods have been utilized, but they often lack expressiveness\nand flexibility in modeling to learn effective representations. The recent\nadvances of deep learning in a wide range of applications has demonstrated its\ncapability to learn robust and powerful feature representations for complex\ndata. Especially, deep generative models naturally combine the expressiveness\nof probabilistic generative models with the high capacity of deep neural\nnetworks, which is very suitable for text modeling. However, little work has\nleveraged the recent progress in deep learning for text hashing.\n  In this paper, we propose a series of novel deep document generative models\nfor text hashing. The first proposed model is unsupervised while the second one\nis supervised by utilizing document labels/tags for hashing. The third model\nfurther considers document-specific factors that affect the generation of\nwords. The probabilistic generative formulation of the proposed models provides\na principled framework for model extension, uncertainty estimation, simulation,\nand interpretability. Based on variational inference and reparameterization,\nthe proposed models can be interpreted as encoder-decoder deep neural networks\nand thus they are capable of learning complex nonlinear distributed\nrepresentations of the original documents. We conduct a comprehensive set of\nexperiments on four public testbeds. The experimental results have demonstrated\nthe effectiveness of the proposed supervised learning models for text hashing.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Compact Codes", "Text Retrieval", "SIGIR", "Similarity Search", "Tools & Libraries"], "tsne_embedding": [-13.99593448638916, -9.102130889892578], "cluster": 1}, {"key": "chaidaroon2025deep", "year": "2025", "citations": "29", "title": "Deep Semantic Text Hashing With Weak Supervision", "abstract": "<p>With an ever increasing amount of data available on the web, fast similarity search has become the critical component for large-scale information retrieval systems. One solution is semantic hashing which designs binary codes to accelerate similarity search. Recently, deep learning has been successfully applied to the semantic hashing problem and produces high-quality compact binary codes compared to traditional methods. However, most state-of-the-art semantic hashing approaches require large amounts of hand-labeled training data which are often expensive and time consuming to collect. The cost of getting labeled data is the key bottleneck in deploying these hashing methods. Motivated by the recent success in machine learning that makes use of weak supervision, we employ unsupervised ranking methods such as BM25 to extract weak signals from training data. We further introduce two deep generative semantic hashing models to leverage weak signals for text hashing. The experimental results on four public datasets show that our models can generate high-quality binary codes without using hand-labeled training data and significantly outperform the competitive unsupervised semantic hashing baselines.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Compact Codes", "Text Retrieval", "SIGIR", "Similarity Search"], "tsne_embedding": [-5.613973617553711, -9.59669017791748], "cluster": 9}, {"key": "chakraborty2019conlsh", "year": "2019", "citations": "13", "title": "Conlsh: Context Based Locality Sensitive Hashing For Mapping Of Noisy SMRT Reads", "abstract": "<p>Single Molecule Real-Time (SMRT) sequencing is a recent advancement of Next\nGen technology developed by Pacific Bio (PacBio). It comes with an explosion of\nlong and noisy reads demanding cutting edge research to get most out of it. To\ndeal with the high error probability of SMRT data, a novel contextual Locality\nSensitive Hashing (conLSH) based algorithm is proposed in this article, which\ncan effectively align the noisy SMRT reads to the reference genome. Here,\nsequences are hashed together based not only on their closeness, but also on\nsimilarity of context. The algorithm has \\(\\mathcal{O}(n^{\\rho+1})\\) space\nrequirement, where \\(n\\) is the number of sequences in the corpus and \\(\\rho\\) is a\nconstant. The indexing time and querying time are bounded by \\(\\mathcal{O}(\n\\frac{n^{\\rho+1} \\cdot \\ln n}{\\ln \\frac{1}{P_2}})\\) and \\(\\mathcal{O}(n^\\rho)\\)\nrespectively, where \\(P_2 &gt; 0\\), is a probability value. This algorithm is\nparticularly useful for retrieving similar sequences, a widely used task in\nbiology. The proposed conLSH based aligner is compared with rHAT, popularly\nused for aligning SMRT reads, and is found to comprehensively beat it in speed\nas well as in memory requirements. In particular, it takes approximately\n\\(24.2%\\) less processing time, while saving about \\(70.3%\\) in peak memory\nrequirement for H.sapiens PacBio dataset.</p>\n", "tags": ["Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-15.900396347045898, -22.539541244506836], "cluster": 1}, {"key": "chandrasekaran2017lattice", "year": "2017", "citations": "40", "title": "Lattice-based Locality Sensitive Hashing Is Optimal", "abstract": "<p>Locality sensitive hashing (LSH) was introduced by Indyk and Motwani (STOC\n<code class=\"language-plaintext highlighter-rouge\">98) to give the first sublinear time algorithm for the c-approximate nearest\nneighbor (ANN) problem using only polynomial space. At a high level, an LSH\nfamily hashes \"nearby\" points to the same bucket and \"far away\" points to\ndifferent buckets. The quality of measure of an LSH family is its LSH exponent,\nwhich helps determine both query time and space usage.\n  In a seminal work, Andoni and Indyk (FOCS </code>06) constructed an LSH family\nbased on random ball partitioning of space that achieves an LSH exponent of\n1/c^2 for the l_2 norm, which was later shown to be optimal by Motwani, Naor\nand Panigrahy (SIDMA <code class=\"language-plaintext highlighter-rouge\">07) and O'Donnell, Wu and Zhou (TOCT </code>14). Although\noptimal in the LSH exponent, the ball partitioning approach is computationally\nexpensive. So, in the same work, Andoni and Indyk proposed a simpler and more\npractical hashing scheme based on Euclidean lattices and provided computational\nresults using the 24-dimensional Leech lattice. However, no theoretical\nanalysis of the scheme was given, thus leaving open the question of finding the\nexponent of lattice based LSH.\n  In this work, we resolve this question by showing the existence of lattices\nachieving the optimal LSH exponent of 1/c^2 using techniques from the geometry\nof numbers. At a more conceptual level, our results show that optimal LSH space\npartitions can have periodic structure. Understanding the extent to which\nadditional structure can be imposed on these partitions, e.g. to yield low\nspace and query complexity, remains an important open problem.</p>\n", "tags": ["Alt", "Locality Sensitive Hashing", "Hashing Methods", "Efficiency And Optimization"], "tsne_embedding": [29.686912536621094, -1.7026418447494507], "cluster": 7}, {"key": "chandrasekhar2017compression", "year": "2017", "citations": "21", "title": "Compression Of Deep Neural Networks For Image Instance Retrieval", "abstract": "<p>Image instance retrieval is the problem of retrieving images from a database\nwhich contain the same object. Convolutional Neural Network (CNN) based\ndescriptors are becoming the dominant approach for generating {\\it global image\ndescriptors} for the instance retrieval problem. One major drawback of\nCNN-based {\\it global descriptors} is that uncompressed deep neural network\nmodels require hundreds of megabytes of storage making them inconvenient to\ndeploy in mobile applications or in custom hardware. In this work, we study the\nproblem of neural network model compression focusing on the image instance\nretrieval task. We study quantization, coding, pruning and weight sharing\ntechniques for reducing model size for the instance retrieval problem. We\nprovide extensive experimental results on the trade-off between retrieval\nperformance and model size for different types of networks on several data sets\nproviding the most comprehensive study on this topic. We compress models to the\norder of a few MBs: two orders of magnitude smaller than the uncompressed\nmodels while achieving negligible loss in retrieval performance.</p>\n", "tags": ["Quantization", "Evaluation"], "tsne_embedding": [-13.231239318847656, 21.695499420166016], "cluster": 6}, {"key": "charikar2018hashing", "year": "2018", "citations": "51", "title": "Hashing-based-estimators For Kernel Density In High Dimensions", "abstract": "<p>Given a set of points \\(P\\subset \\mathbb{R}^{d}\\) and a kernel \\(k\\), the Kernel\nDensity Estimate at a point \\(x\\in\\mathbb{R}^{d}\\) is defined as\n\\(\\mathrm{KDE}<em>{P}(x)=\\frac{1}{|P|}\\sum</em>{y\\in P} k(x,y)\\). We study the problem\nof designing a data structure that given a data set \\(P\\) and a kernel function,\nreturns <em>approximations to the kernel density</em> of a query point in <em>sublinear\ntime</em>. We introduce a class of unbiased estimators for kernel density\nimplemented through locality-sensitive hashing, and give general theorems\nbounding the variance of such estimators. These estimators give rise to\nefficient data structures for estimating the kernel density in high dimensions\nfor a variety of commonly used kernels. Our work is the first to provide\ndata-structures with theoretical guarantees that improve upon simple random\nsampling in high dimensions.</p>\n", "tags": ["Hashing Methods"], "tsne_embedding": [27.769275665283203, 0.31249353289604187], "cluster": 7}, {"key": "charikar2018multi", "year": "2018", "citations": "5", "title": "Multi-resolution Hashing For Fast Pairwise Summations", "abstract": "<p>A basic computational primitive in the analysis of massive datasets is\nsumming simple functions over a large number of objects. Modern applications\npose an additional challenge in that such functions often depend on a parameter\nvector \\(y\\) (query) that is unknown a priori. Given a set of points \\(X\\subset\n\\mathbb{R}^{d}\\) and a pairwise function \\(w:\\mathbb{R}^{d}\\times\n\\mathbb{R}^{d}\\to [0,1]\\), we study the problem of designing a data-structure\nthat enables sublinear-time approximation of the summation\n\\(Z_{w}(y)=\\frac{1}{|X|}\\sum_{x\\in X}w(x,y)\\) for any query \\(y\\in\n\\mathbb{R}^{d}\\). By combining ideas from Harmonic Analysis (partitions of unity\nand approximation theory) with Hashing-Based-Estimators [Charikar, Siminelakis\nFOCS\u201917], we provide a general framework for designing such data structures\nthrough hashing that reaches far beyond what previous techniques allowed.\n  A key design principle is a collection of \\(T\\geq 1\\) hashing schemes with\ncollision probabilities \\(p_{1},\\ldots, p_{T}\\) such that \\(\\sup_{t\\in\n[T]}\\{p_{t}(x,y)\\} = \\Theta(\\sqrt{w(x,y)})\\). This leads to a data-structure\nthat approximates \\(Z_{w}(y)\\) using a sub-linear number of samples from each\nhash family. Using this new framework along with Distance Sensitive Hashing\n[Aumuller, Christiani, Pagh, Silvestri PODS\u201918], we show that such a collection\ncan be constructed and evaluated efficiently for any log-convex function\n\\(w(x,y)=e^{\\phi(\\langle x,y\\rangle)}\\) of the inner product on the unit sphere\n\\(x,y\\in \\mathcal{S}^{d-1}\\).\n  Our method leads to data structures with sub-linear query time that\nsignificantly improve upon random sampling and can be used for Kernel Density\nor Partition Function Estimation. We provide extensions of our result from the\nsphere to \\(\\mathbb{R}^{d}\\) and from scalar functions to vector functions.</p>\n", "tags": ["DATASETS", "Tools & Libraries", "Hashing Methods", "Efficiency And Optimization"], "tsne_embedding": [30.452646255493164, -0.026527898386120796], "cluster": 7}, {"key": "charikar2020kernel", "year": "2020", "citations": "6", "title": "Kernel Density Estimation Through Density Constrained Near Neighbor Search", "abstract": "<p>In this paper we revisit the kernel density estimation problem: given a\nkernel \\(K(x, y)\\) and a dataset of \\(n\\) points in high dimensional Euclidean\nspace, prepare a data structure that can quickly output, given a query \\(q\\), a\n\\((1+\\epsilon)\\)-approximation to \\(\\mu:=\\frac1{|P|}\\sum_{p\\in P} K(p, q)\\). First,\nwe give a single data structure based on classical near neighbor search\ntechniques that improves upon or essentially matches the query time and space\ncomplexity for all radial kernels considered in the literature so far. We then\nshow how to improve both the query complexity and runtime by using recent\nadvances in data-dependent near neighbor search.\n  We achieve our results by giving a new implementation of the natural\nimportance sampling scheme. Unlike previous approaches, our algorithm first\nsamples the dataset uniformly (considering a geometric sequence of sampling\nrates), and then uses existing approximate near neighbor search techniques on\nthe resulting smaller dataset to retrieve the sampled points that lie at an\nappropriate distance from the query. We show that the resulting sampled dataset\nhas strong geometric structure, making approximate near neighbor search return\nthe required samples much more efficiently than for worst case datasets of the\nsame size. As an example application, we show that this approach yields a data\nstructure that achieves query time \\(\\mu^{-(1+o(1))/4}\\) and space complexity\n\\(\\mu^{-(1+o(1))}\\) for the Gaussian kernel. Our data dependent approach achieves\nquery time \\(\\mu^{-0.173-o(1)}\\) and space \\(\\mu^{-(1+o(1))}\\) for the Gaussian\nkernel. The data dependent analysis relies on new techniques for tracking the\ngeometric structure of the input datasets in a recursive hashing process that\nwe hope will be of interest in other applications in near neighbor search.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization"], "tsne_embedding": [29.10942268371582, 0.5163121223449707], "cluster": 7}, {"key": "chatzigeorgakidis2023accelerating", "year": "2023", "citations": "5", "title": "Accelerating Spatio-textual Queries With Learned Indices", "abstract": "<p>Efficiently computing spatio-textual queries has become increasingly\nimportant in various applications that need to quickly retrieve geolocated\nentities associated with textual information, such as in location-based\nservices and social networks. To accelerate such queries, several works have\nproposed combining spatial and textual indices into hybrid index structures.\nRecently, the novel idea of replacing traditional indices with ML models has\nattracted a lot of attention. This includes works on learned spatial indices,\nwhere the main challenge is to address the lack of a total ordering among\nobjects in a multidimensional space. In this work, we investigate how to extend\nthis novel type of index design to the case of spatio-textual data. We study\ndifferent design choices, based on either loose or tight coupling between the\nspatial and textual part, as well as a hybrid index that combines a traditional\nand a learned component. We also perform an experimental evaluation using\nseveral real-world datasets to assess the potential benefits of using a learned\nindex for evaluating spatio-textual queries.</p>\n", "tags": ["Vector Indexing", "Evaluation", "DATASETS"], "tsne_embedding": [4.81358003616333, 6.136826038360596], "cluster": 4}, {"key": "chaudhuri2021crossatnet", "year": "2021", "citations": "28", "title": "Crossatnet - A Novel Cross-attention Based Framework For Sketch-based Image Retrieval", "abstract": "<p>We propose a novel framework for cross-modal zero-shot learning (ZSL) in the\ncontext of sketch-based image retrieval (SBIR). Conventionally, the SBIR schema\nmainly considers simultaneous mappings among the two image views and the\nsemantic side information. Therefore, it is desirable to consider fine-grained\nclasses mainly in the sketch domain using highly discriminative and\nsemantically rich feature space. However, the existing deep generative\nmodeling-based SBIR approaches majorly focus on bridging the gaps between the\nseen and unseen classes by generating pseudo-unseen-class samples. Besides,\nviolating the ZSL protocol by not utilizing any unseen-class information during\ntraining, such techniques do not pay explicit attention to modeling the\ndiscriminative nature of the shared space. Also, we note that learning a\nunified feature space for both the multi-view visual data is a tedious task\nconsidering the significant domain difference between sketches and color\nimages. In this respect, as a remedy, we introduce a novel framework for\nzero-shot SBIR. While we define a cross-modal triplet loss to ensure the\ndiscriminative nature of the shared space, an innovative cross-modal attention\nlearning strategy is also proposed to guide feature extraction from the image\ndomain exploiting information from the respective sketch counterpart. In order\nto preserve the semantic consistency of the shared space, we consider a graph\nCNN-based module that propagates the semantic class topology to the shared\nspace. To ensure an improved response time during inference, we further explore\nthe possibility of representing the shared space in terms of hash codes.\nExperimental results obtained on the benchmark TU-Berlin and the Sketchy\ndatasets confirm the superiority of CrossATNet in yielding state-of-the-art\nresults.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Distance Metric Learning", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-6.861324310302734, 0.01970537006855011], "cluster": 8}, {"key": "chehreghani2019unsupervised", "year": "2019", "citations": "14", "title": "Unsupervised Representation Learning With Minimax Distance Measures", "abstract": "<p>We investigate the use of Minimax distances to extract in a nonparametric way\nthe features that capture the unknown underlying patterns and structures in the\ndata. We develop a general-purpose and computationally efficient framework to\nemploy Minimax distances with many machine learning methods that perform on\nnumerical data. We study both computing the pairwise Minimax distances for all\npairs of objects and as well as computing the Minimax distances of all the\nobjects to/from a fixed (test) object. We first efficiently compute the\npairwise Minimax distances between the objects, using the equivalence of\nMinimax distances over a graph and over a minimum spanning tree constructed on\nthat. Then, we perform an embedding of the pairwise Minimax distances into a\nnew vector space, such that their squared Euclidean distances in the new space\nequal to the pairwise Minimax distances in the original space. We also study\nthe case of having multiple pairwise Minimax matrices, instead of a single one.\nThereby, we propose an embedding via first summing up the centered matrices and\nthen performing an eigenvalue decomposition to obtain the relevant features. In\nthe following, we study computing Minimax distances from a fixed (test) object\nwhich can be used for instance in K-nearest neighbor search. Similar to the\ncase of all-pair pairwise Minimax distances, we develop an efficient and\ngeneral-purpose algorithm that is applicable with any arbitrary base distance\nmeasure. Moreover, we investigate in detail the edges selected by the Minimax\ndistances and thereby explore the ability of Minimax distances in detecting\noutlier objects. Finally, for each setting, we perform several experiments to\ndemonstrate the effectiveness of our framework.</p>\n", "tags": ["ICML", "Tools & Libraries", "Distance Metric Learning"], "tsne_embedding": [20.895828247070312, 5.264711856842041], "cluster": 7}, {"key": "chen2017darkrank", "year": "2017", "citations": "218", "title": "Darkrank: Accelerating Deep Metric Learning Via Cross Sample Similarities Transfer", "abstract": "<p>We have witnessed rapid evolution of deep neural network architecture design\nin the past years. These latest progresses greatly facilitate the developments\nin various areas such as computer vision and natural language processing.\nHowever, along with the extraordinary performance, these state-of-the-art\nmodels also bring in expensive computational cost. Directly deploying these\nmodels into applications with real-time requirement is still infeasible.\nRecently, Hinton etal. have shown that the dark knowledge within a powerful\nteacher model can significantly help the training of a smaller and faster\nstudent network. These knowledge are vastly beneficial to improve the\ngeneralization ability of the student model. Inspired by their work, we\nintroduce a new type of knowledge \u2013 cross sample similarities for model\ncompression and acceleration. This knowledge can be naturally derived from deep\nmetric learning model. To transfer them, we bring the \u201clearning to rank\u201d\ntechnique into deep metric learning formulation. We test our proposed DarkRank\nmethod on various metric learning tasks including pedestrian re-identification,\nimage retrieval and image clustering. The results are quite encouraging. Our\nmethod can improve over the baseline method by a large margin. Moreover, it is\nfully compatible with other existing methods. When combined, the performance\ncan be further boosted.</p>\n", "tags": ["Image Retrieval", "AAAI", "Distance Metric Learning", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-21.67820167541504, -5.970468997955322], "cluster": 1}, {"key": "chen2018distributed", "year": "2018", "citations": "7", "title": "Distributed Collaborative Hashing And Its Applications In Ant Financial", "abstract": "<p>Collaborative filtering, especially latent factor model, has been popularly\nused in personalized recommendation. Latent factor model aims to learn user and\nitem latent factors from user-item historic behaviors. To apply it into real\nbig data scenarios, efficiency becomes the first concern, including offline\nmodel training efficiency and online recommendation efficiency. In this paper,\nwe propose a Distributed Collaborative Hashing (DCH) model which can\nsignificantly improve both efficiencies. Specifically, we first propose a\ndistributed learning framework, following the state-of-the-art parameter server\nparadigm, to learn the offline collaborative model. Our model can be learnt\nefficiently by distributedly computing subgradients in minibatches on workers\nand updating model parameters on servers asynchronously. We then adopt hashing\ntechnique to speedup the online recommendation procedure. Recommendation can be\nquickly made through exploiting lookup hash tables. We conduct thorough\nexperiments on two real large-scale datasets. The experimental results\ndemonstrate that, comparing with the classic and state-of-the-art (distributed)\nlatent factor models, DCH has comparable performance in terms of recommendation\naccuracy but has both fast convergence speed in offline model training\nprocedure and realtime efficiency in online recommendation procedure.\nFurthermore, the encouraging performance of DCH is also shown for several\nreal-world applications in Ant Financial.</p>\n", "tags": ["KDD", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Alt", "Recommender Systems", "Tools & Libraries", "Evaluation"], "tsne_embedding": [4.244272232055664, -4.096236705780029], "cluster": 4}, {"key": "chen2019differentiable", "year": "2019", "citations": "13", "title": "Differentiable Product Quantization For End-to-end Embedding Compression", "abstract": "<p>Embedding layers are commonly used to map discrete symbols into continuous\nembedding vectors that reflect their semantic meanings. Despite their\neffectiveness, the number of parameters in an embedding layer increases\nlinearly with the number of symbols and poses a critical challenge on memory\nand storage constraints. In this work, we propose a generic and end-to-end\nlearnable compression framework termed differentiable product quantization\n(DPQ). We present two instantiations of DPQ that leverage different\napproximation techniques to enable differentiability in end-to-end learning.\nOur method can readily serve as a drop-in alternative for any existing\nembedding layer. Empirically, DPQ offers significant compression ratios\n(14-238\\(\\times\\)) at negligible or no performance cost on 10 datasets across\nthree different language tasks.</p>\n", "tags": ["DATASETS", "Alt", "Quantization", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-11.366886138916016, -17.629806518554688], "cluster": 1}, {"key": "chen2019hadamard", "year": "2019", "citations": "47", "title": "Hadamard Codebook Based Deep Hashing", "abstract": "<p>As an approximate nearest neighbor search technique, hashing has been widely\napplied in large-scale image retrieval due to its excellent efficiency. Most\nsupervised deep hashing methods have similar loss designs with embedding\nlearning, while quantizing the continuous high-dim feature into compact binary\nspace. We argue that the existing deep hashing schemes are defective in two\nissues that seriously affect the performance, i.e., bit independence and bit\nbalance. The former refers to hash codes of different classes should be\nindependent of each other, while the latter means each bit should have a\nbalanced distribution of +1s and -1s. In this paper, we propose a novel\nsupervised deep hashing method, termed Hadamard Codebook based Deep Hashing\n(HCDH), which solves the above two problems in a unified formulation.\nSpecifically, we utilize an off-the-shelf algorithm to generate a binary\nHadamard codebook to satisfy the requirement of bit independence and bit\nbalance, which subsequently serves as the desired outputs of the hash functions\nlearning. We also introduce a projection matrix to solve the inconsistency\nbetween the order of Hadamard matrix and the number of classes. Besides, the\nproposed HCDH further exploits the supervised labels by constructing a\nclassifier on top of the outputs of hash functions. Extensive experiments\ndemonstrate that HCDH can yield discriminative and balanced binary codes, which\nwell outperforms many state-of-the-arts on three widely-used benchmarks.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Neural Hashing", "Evaluation"], "tsne_embedding": [-5.840498447418213, -1.1612814664840698], "cluster": 8}, {"key": "chen2019locality", "year": "2019", "citations": "62", "title": "Locality-sensitive Hashing For F-divergences: Mutual Information Loss And Beyond", "abstract": "<p>Computing approximate nearest neighbors in high dimensional spaces is a\ncentral problem in large-scale data mining with a wide range of applications in\nmachine learning and data science. A popular and effective technique in\ncomputing nearest neighbors approximately is the locality-sensitive hashing\n(LSH) scheme. In this paper, we aim to develop LSH schemes for distance\nfunctions that measure the distance between two probability distributions,\nparticularly for f-divergences as well as a generalization to capture mutual\ninformation loss. First, we provide a general framework to design LHS schemes\nfor f-divergence distance functions and develop LSH schemes for the generalized\nJensen-Shannon divergence and triangular discrimination in this framework. We\nshow a two-sided approximation result for approximation of the generalized\nJensen-Shannon divergence by the Hellinger distance, which may be of\nindependent interest. Next, we show a general method of reducing the problem of\ndesigning an LSH scheme for a Krein kernel (which can be expressed as the\ndifference of two positive definite kernels) to the problem of maximum inner\nproduct search. We exemplify this method by applying it to the mutual\ninformation loss, due to its several important applications such as model\ncompression.</p>\n", "tags": ["Locality Sensitive Hashing", "Tools & Libraries", "Hashing Methods"], "tsne_embedding": [23.73554229736328, -0.9463644623756409], "cluster": 7}, {"key": "chen2019vector", "year": "2019", "citations": "7", "title": "Vector And Line Quantization For Billion-scale Similarity Search On Gpus", "abstract": "<p>Billion-scale high-dimensional approximate nearest neighbour (ANN) search has\nbecome an important problem for searching similar objects among the vast amount\nof images and videos available online. The existing ANN methods are usually\ncharacterized by their specific indexing structures, including the inverted\nindex and the inverted multi-index structure. The inverted index structure is\namenable to GPU-based implementations, and the state-of-the-art systems such as\nFaiss are able to exploit the massive parallelism offered by GPUs. However, the\ninverted index requires high memory overhead to index the dataset effectively.\nThe inverted multi-index structure is difficult to implement for GPUs, and also\nineffective in dealing with database with different data distributions. In this\npaper we propose a novel hierarchical inverted index structure generated by\nvector and line quantization methods. Our quantization method improves both\nsearch efficiency and accuracy, while maintaining comparable memory\nconsumption. This is achieved by reducing search space and increasing the\nnumber of indexed regions. We introduce a new ANN search system, VLQ-ADC, that\nis based on the proposed inverted index, and perform extensive evaluation on\ntwo public billion-scale benchmark datasets SIFT1B and DEEP1B. Our evaluation\nshows that VLQ-ADC significantly outperforms the state-of-the-art GPU- and\nCPU-based systems in terms of both accuracy and search speed. The source code\nof VLQ-ADC is available at\nhttps://github.com/zjuchenwei/vector-line-quantization.</p>\n", "tags": ["DATASETS", "Efficiency And Optimization", "Large Scale Search", "Similarity Search", "Quantization", "Vector Indexing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [13.610721588134766, 20.91648292541504], "cluster": 0}, {"key": "chen2020making", "year": "2020", "citations": "21", "title": "Making Online Sketching Hashing Even Faster", "abstract": "<p>Data-dependent hashing methods have demonstrated good performance in various\nmachine learning applications to learn a low-dimensional representation from\nthe original data. However, they still suffer from several obstacles: First,\nmost of existing hashing methods are trained in a batch mode, yielding\ninefficiency for training streaming data. Second, the computational cost and\nthe memory consumption increase extraordinarily in the big data setting, which\nperplexes the training procedure. Third, the lack of labeled data hinders the\nimprovement of the model performance. To address these difficulties, we utilize\nonline sketching hashing (OSH) and present a FasteR Online Sketching Hashing\n(FROSH) algorithm to sketch the data in a more compact form via an independent\ntransformation. We provide theoretical justification to guarantee that our\nproposed FROSH consumes less time and achieves a comparable sketching precision\nunder the same memory cost of OSH. We also extend FROSH to its distributed\nimplementation, namely DFROSH, to further reduce the training time cost of\nFROSH while deriving the theoretical bound of the sketching precision. Finally,\nwe conduct extensive experiments on both synthetic and real datasets to\ndemonstrate the attractive merits of FROSH and DFROSH.</p>\n", "tags": ["DATASETS", "Hashing Methods", "TACL", "Efficiency And Optimization", "Evaluation"], "tsne_embedding": [1.3123947381973267, -9.904104232788086], "cluster": 9}, {"key": "chen2021transhash", "year": "2021", "citations": "36", "title": "Transhash: Transformer-based Hamming Hashing For Efficient Image Retrieval", "abstract": "<p>Deep hamming hashing has gained growing popularity in approximate nearest\nneighbour search for large-scale image retrieval. Until now, the deep hashing\nfor the image retrieval community has been dominated by convolutional neural\nnetwork architectures, e.g. \\texttt{Resnet}\\cite{he2016deep}. In this paper,\ninspired by the recent advancements of vision transformers, we present\n\\textbf{Transhash}, a pure transformer-based framework for deep hashing\nlearning. Concretely, our framework is composed of two major modules: (1) Based\non \\textit{Vision Transformer} (ViT), we design a siamese vision transformer\nbackbone for image feature extraction. To learn fine-grained features, we\ninnovate a dual-stream feature learning on top of the transformer to learn\ndiscriminative global and local features. (2) Besides, we adopt a Bayesian\nlearning scheme with a dynamically constructed similarity matrix to learn\ncompact binary hash codes. The entire framework is jointly trained in an\nend-to-end manner.~To the best of our knowledge, this is the first work to\ntackle deep hashing learning problems without convolutional neural networks\n(\\textit{CNNs}). We perform comprehensive experiments on three widely-studied\ndatasets: \\textbf{CIFAR-10}, \\textbf{NUSWIDE} and \\textbf{IMAGENET}. The\nexperiments have evidenced our superiority against the existing\nstate-of-the-art deep hashing methods. Specifically, we achieve 8.2%, 2.6%,\n12.7% performance gains in terms of average \\textit{mAP} for different hash\nbit lengths on three public datasets, respectively.</p>\n", "tags": ["DATASETS", "Evaluation", "Neural Hashing", "Hashing Methods", "Image Retrieval", "Tools & Libraries", "Multimodal Retrieval"], "tsne_embedding": [-13.12945556640625, 0.636926531791687], "cluster": 8}, {"key": "chen2022approximate", "year": "2022", "citations": "12", "title": "Approximate Nearest Neighbor Search Under Neural Similarity Metric For Large-scale Recommendation", "abstract": "<p>Model-based methods for recommender systems have been studied extensively for\nyears. Modern recommender systems usually resort to 1) representation learning\nmodels which define user-item preference as the distance between their\nembedding representations, and 2) embedding-based Approximate Nearest Neighbor\n(ANN) search to tackle the efficiency problem introduced by large-scale corpus.\nWhile providing efficient retrieval, the embedding-based retrieval pattern also\nlimits the model capacity since the form of user-item preference measure is\nrestricted to the distance between their embedding representations. However,\nfor other more precise user-item preference measures, e.g., preference scores\ndirectly derived from a deep neural network, they are computationally\nintractable because of the lack of an efficient retrieval method, and an\nexhaustive search for all user-item pairs is impractical. In this paper, we\npropose a novel method to extend ANN search to arbitrary matching functions,\ne.g., a deep neural network. Our main idea is to perform a greedy walk with a\nmatching function in a similarity graph constructed from all items. To solve\nthe problem that the similarity measures of graph construction and user-item\nmatching function are heterogeneous, we propose a pluggable adversarial\ntraining task to ensure the graph search with arbitrary matching function can\nachieve fairly high precision. Experimental results in both open source and\nindustry datasets demonstrate the effectiveness of our method. The proposed\nmethod has been fully deployed in the Taobao display advertising platform and\nbrings a considerable advertising revenue increase. We also summarize our\ndetailed experiences in deployment in this paper.</p>\n", "tags": ["DATASETS", "Evaluation", "Robustness", "Recommender Systems", "Efficiency And Optimization", "Distance Metric Learning", "Graph Based ANN", "CIKM", "Similarity Search"], "tsne_embedding": [12.635790824890137, 15.644883155822754], "cluster": 0}, {"key": "chen2022finger", "year": "2022", "citations": "10", "title": "FINGER: Fast Inference For Graph-based Approximate Nearest Neighbor Search", "abstract": "<p>Approximate K-Nearest Neighbor Search (AKNNS) has now become ubiquitous in\nmodern applications, for example, as a fast search procedure with two tower\ndeep learning models. Graph-based methods for AKNNS in particular have received\ngreat attention due to their superior performance. These methods rely on greedy\ngraph search to traverse the data points as embedding vectors in a database.\nUnder this greedy search scheme, we make a key observation: many distance\ncomputations do not influence search updates so these computations can be\napproximated without hurting performance. As a result, we propose FINGER, a\nfast inference method to achieve efficient graph search. FINGER approximates\nthe distance function by estimating angles between neighboring residual vectors\nwith low-rank bases and distribution matching. The approximated distance can be\nused to bypass unnecessary computations, which leads to faster searches.\nEmpirically, accelerating a popular graph-based method named HNSW by FINGER is\nshown to outperform existing graph-based methods by 20%-60% across different\nbenchmark datasets.</p>\n", "tags": ["Graph Based ANN", "DATASETS", "Evaluation"], "tsne_embedding": [20.532264709472656, 11.086560249328613], "cluster": 0}, {"key": "chen2022learning", "year": "2022", "citations": "24", "title": "Learning Binarized Graph Representations With Multi-faceted Quantization Reinforcement For Top-k Recommendation", "abstract": "<p>Learning vectorized embeddings is at the core of various recommender systems\nfor user-item matching. To perform efficient online inference, representation\nquantization, aiming to embed the latent features by a compact sequence of\ndiscrete numbers, recently shows the promising potentiality in optimizing both\nmemory and computation overheads. However, existing work merely focuses on\nnumerical quantization whilst ignoring the concomitant information loss issue,\nwhich, consequently, leads to conspicuous performance degradation. In this\npaper, we propose a novel quantization framework to learn Binarized Graph\nRepresentations for Top-K Recommendation (BiGeaR). BiGeaR introduces\nmulti-faceted quantization reinforcement at the pre-, mid-, and post-stage of\nbinarized representation learning, which substantially retains the\nrepresentation informativeness against embedding binarization. In addition to\nsaving the memory footprint, BiGeaR further develops solid online inference\nacceleration with bitwise operations, providing alternative flexibility for the\nrealistic deployment. The empirical results over five large real-world\nbenchmarks show that BiGeaR achieves about 22%~40% performance improvement over\nthe state-of-the-art quantization-based recommender system, and recovers about\n95%~102% of the performance capability of the best full-precision counterpart\nwith over 8x time and space reduction.</p>\n", "tags": ["KDD", "Efficiency And Optimization", "Recommender Systems", "Alt", "Quantization", "Tools & Libraries", "Evaluation"], "tsne_embedding": [15.033674240112305, 10.105506896972656], "cluster": 0}, {"key": "chen2023bipartite", "year": "2023", "citations": "15", "title": "Bipartite Graph Convolutional Hashing For Effective And Efficient Top-n Search In Hamming Space", "abstract": "<p>Searching on bipartite graphs is basal and versatile to many real-world Web\napplications, e.g., online recommendation, database retrieval, and\nquery-document searching. Given a query node, the conventional approaches rely\non the similarity matching with the vectorized node embeddings in the\ncontinuous Euclidean space. To efficiently manage intensive similarity\ncomputation, developing hashing techniques for graph structured data has\nrecently become an emerging research direction. Despite the retrieval\nefficiency in Hamming space, prior work is however confronted with catastrophic\nperformance decay. In this work, we investigate the problem of hashing with\nGraph Convolutional Network on bipartite graphs for effective Top-N search. We\npropose an end-to-end Bipartite Graph Convolutional Hashing approach, namely\nBGCH, which consists of three novel and effective modules: (1) adaptive graph\nconvolutional hashing, (2) latent feature dispersion, and (3) Fourier\nserialized gradient estimation. Specifically, the former two modules achieve\nthe substantial retention of the structural information against the inevitable\ninformation loss in hash encoding; the last module develops Fourier Series\ndecomposition to the hashing function in the frequency domain mainly for more\naccurate gradient estimation. The extensive experiments on six real-world\ndatasets not only show the performance superiority over the competing\nhashing-based counterparts, but also demonstrate the effectiveness of all\nproposed model components contained therein.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "Recommender Systems", "Evaluation"], "tsne_embedding": [17.350984573364258, 13.555798530578613], "cluster": 0}, {"key": "chen2023supervised", "year": "2023", "citations": "105", "title": "Supervised Auto-encoding Twin-bottleneck Hashing", "abstract": "<p>Deep hashing has shown to be a complexity-efficient solution for the\nApproximate Nearest Neighbor search problem in high dimensional space. Many\nmethods usually build the loss function from pairwise or triplet data points to\ncapture the local similarity structure. Other existing methods construct the\nsimilarity graph and consider all points simultaneously. Auto-encoding\nTwin-bottleneck Hashing is one such method that dynamically builds the graph.\nSpecifically, each input data is encoded into a binary code and a continuous\nvariable, or the so-called twin bottlenecks. The similarity graph is then\ncomputed from these binary codes, which get updated consistently during the\ntraining. In this work, we generalize the original model into a supervised deep\nhashing network by incorporating the label information. In addition, we examine\nthe differences of codes structure between these two networks and consider the\nclass imbalance problem especially in multi-labeled datasets. Experiments on\nthree datasets yield statistically significant improvement against the original\nmodel. Results are also comparable and competitive to other supervised methods.</p>\n", "tags": ["DATASETS", "Hashing Methods", "CVPR", "Compact Codes", "Neural Hashing"], "tsne_embedding": [0.6655148267745972, -3.3865582942962646], "cluster": 9}, {"key": "chen2024hac", "year": "2024", "citations": "5", "title": "HAC: Hash-grid Assisted Context For 3D Gaussian Splatting Compression", "abstract": "<p>3D Gaussian Splatting (3DGS) has emerged as a promising framework for novel\nview synthesis, boasting rapid rendering speed with high fidelity. However, the\nsubstantial Gaussians and their associated attributes necessitate effective\ncompression techniques. Nevertheless, the sparse and unorganized nature of the\npoint cloud of Gaussians (or anchors in our paper) presents challenges for\ncompression. To address this, we make use of the relations between the\nunorganized anchors and the structured hash grid, leveraging their mutual\ninformation for context modeling, and propose a Hash-grid Assisted Context\n(HAC) framework for highly compact 3DGS representation. Our approach introduces\na binary hash grid to establish continuous spatial consistencies, allowing us\nto unveil the inherent spatial relations of anchors through a carefully\ndesigned context model. To facilitate entropy coding, we utilize Gaussian\ndistributions to accurately estimate the probability of each quantized\nattribute, where an adaptive quantization module is proposed to enable\nhigh-precision quantization of these attributes for improved fidelity\nrestoration. Additionally, we incorporate an adaptive masking strategy to\neliminate invalid Gaussians and anchors. Importantly, our work is the pioneer\nto explore context-based compression for 3DGS representation, resulting in a\nremarkable size reduction of over \\(75\\times\\) compared to vanilla 3DGS, while\nsimultaneously improving fidelity, and achieving over \\(11\\times\\) size reduction\nover SOTA 3DGS compression approach Scaffold-GS. Our code is available here:\nhttps://github.com/YihangChen-ee/HAC</p>\n", "tags": ["Quantization", "Tools & Libraries", "Hashing Methods", "Evaluation"], "tsne_embedding": [-5.4823784828186035, 12.745686531066895], "cluster": 6}, {"key": "chen2025deep", "year": "2025", "citations": "52", "title": "Deep Supervised Hashing With Anchor Graph", "abstract": "<p>Recently, a series of deep supervised hashing methods were proposed for binary code learning. However, due to the high computation cost and the limited hardware\u2019s memory, these methods will first select a subset from the training set, and then form a mini-batch data to update the network in each iteration. Therefore, the remaining labeled data cannot be fully utilized and the model cannot directly obtain the binary codes of the entire training set for retrieval. To address these problems, this paper proposes an interesting regularized deep model to seamlessly integrate the advantages of deep hashing and efficient binary code learning by using the anchor graph. As such, the deep features and label matrix can be jointly used to optimize the binary codes, and the network can obtain more discriminative feedback from the linear combinations of the learned bits. Moreover, we also reveal the algorithm mechanism and its computation essence. Experiments on three large-scale datasets indicate that the proposed method achieves better retrieval performance with less training time compared to previous deep hashing methods.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Compact Codes", "Neural Hashing", "ICCV", "Evaluation"], "tsne_embedding": [-3.6852993965148926, -13.67537784576416], "cluster": 9}, {"key": "chen2025enhanced", "year": "2025", "citations": "27", "title": "Enhanced Discrete Multi-modal Hashing: More Constraints Yet Less Time To Learn", "abstract": "<p>Due to the exponential growth of multimedia data, multi-modal hashing as a promising technique to make cross-view retrieval scalable is attracting more and more attention. However, most of the existing multi-modal hashing methods either divide the learning process unnaturally into two separate stages or treat the discrete optimization problem simplistically as a continuous one, which leads to suboptimal results. Recently, a few discrete multi-modal hashing methods that try to address such issues have emerged, but they still ignore several important discrete constraints (such as the balance and decorrelation of hash bits). In this paper, we overcome those limitations by proposing a novel method named \u201cEnhanced Discrete Multi-modal Hashing (EDMH)\u201d which learns binary codes and hashing functions simultaneously from the pairwise similarity matrix of data, under the aforementioned discrete constraints. Although the model of EDMH looks a lot more complex than the other models for multi-modal hashing, we are actually able to develop a fast iterative learning algorithm for it, since the subproblems of its optimization all have closed-form solutions after introducing two auxiliary variables. Our experimental results on three real-world datasets have demonstrated that EDMH not only performs much better than state-of-the-art competitors but also runs much faster than them.</p>\n", "tags": ["Compact Codes", "Alt", "Hashing Methods", "DATASETS"], "tsne_embedding": [-4.629941940307617, -6.445521354675293], "cluster": 9}, {"key": "chen2025long", "year": "2025", "citations": "9", "title": "Long-tail Hashing", "abstract": "<p>Hashing, which represents data items as compact binary codes, has\nbeen becoming a more and more popular technique, e.g., for large-scale image retrieval, owing to its super fast search speed as well\nas its extremely economical memory consumption. However, existing hashing methods all try to learn binary codes from artificially\nbalanced datasets which are not commonly available in real-world\nscenarios. In this paper, we propose Long-Tail Hashing Network\n(LTHNet), a novel two-stage deep hashing approach that addresses\nthe problem of learning to hash for more realistic datasets where\nthe data labels roughly exhibit a long-tail distribution. Specifically,\nthe first stage is to learn relaxed embeddings of the given dataset\nwith its long-tail characteristic taken into account via an end-to-end deep neural network; the second stage is to binarize those\nobtained embeddings. A critical part of LTHNet is its extended dynamic meta-embedding module which can adaptively realize visual\nknowledge transfer between head and tail classes, and thus enrich\nimage representations for hashing. Our experiments have shown\nthat LTHNet achieves dramatic performance improvements over all\nstate-of-the-art competitors on long-tail datasets, with no or little\nsacrifice on balanced datasets. Further analyses reveal that while to\nour surprise directly manipulating class weights in the loss function\nhas little effect, the extended dynamic meta-embedding module, the\nusage of cross-entropy loss instead of square loss, and the relatively\nsmall batch-size for training all contribute to LTHNet\u2019s success.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Compact Codes", "Neural Hashing", "SIGIR", "Evaluation"], "tsne_embedding": [-4.406111717224121, -8.042733192443848], "cluster": 9}, {"key": "chen2025strongly", "year": "2025", "citations": "50", "title": "Strongly Constrained Discrete Hashing", "abstract": "<p>Learning to hash is a fundamental technique widely used in large-scale image retrieval. Most existing methods for learning to hash address the involved discrete optimization problem by the continuous relaxation of the binary constraint, which usually leads to large quantization errors and consequently suboptimal binary codes. A few discrete hashing methods have emerged recently. However, they either completely ignore some useful constraints (specifically the balance and decorrelation of hash bits) or just turn those constraints into regularizers that would make the optimization easier but less accurate. In this paper, we propose a novel supervised hashing method named Strongly Constrained Discrete Hashing (SCDH) which overcomes such limitations. It can learn the binary codes for all examples in the training set, and meanwhile obtain a hash function for unseen samples with the above mentioned constraints preserved. Although the model of SCDH is fairly sophisticated, we are able to find closed-form solutions to all of its optimization subproblems and thus design an efficient algorithm that converges quickly. In addition, we extend SCDH to a kernelized version SCDH K . Our experiments on three large benchmark datasets have demonstrated that not only can SCDH and SCDH K achieve substantially higher MAP scores than state-of-the-art baselines, but they train much faster than those that are also supervised as well.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Compact Codes", "Alt", "Quantization", "Evaluation"], "tsne_embedding": [-4.489775657653809, -10.829038619995117], "cluster": 9}, {"key": "chen2025two", "year": "2025", "citations": "45", "title": "A Two-step Cross-modal Hashing By Exploiting Label Correlations And Preserving Similarity In Both Steps", "abstract": "<p>In this paper, we present a novel Two-stEp Cross-modal Hashing method, TECH for short, for cross-modal retrieval tasks. As a two-step method, it first learns hash codes based on semantic labels, while preserving the similarity in the original space and exploiting the label correlations in the label space. In the light of this, it is able to make better use of label information and generate better binary codes. In addition, different from other two-step methods that mainly focus on the hash codes learning, TECH adopts a new hash function learning strategy in the second step, which also preserves the similarity in the original space. Moreover, with the help of well designed objective function and optimization scheme, it is able to generate hash codes discretely and scalable for large scale data. To the best of our knowledge, it is the first cross-modal hashing method exploiting label correlations, and also the first two-step hashing model preserving the similarity while leaning hash function. Extensive experiments demonstrate that the proposed approach outperforms some state-of-the-art cross-modal hashing methods.</p>\n", "tags": ["Compact Codes", "Multimodal Retrieval", "Hashing Methods"], "tsne_embedding": [-6.487539768218994, -7.633549213409424], "cluster": 9}, {"key": "cheng2016adaptive", "year": "2016", "citations": "36", "title": "Adaptive Training Of Random Mapping For Data Quantization", "abstract": "<p>Data quantization learns encoding results of data with certain requirements,\nand provides a broad perspective of many real-world applications to data\nhandling. Nevertheless, the results of encoder is usually limited to\nmultivariate inputs with the random mapping, and side information of binary\ncodes are hardly to mostly depict the original data patterns as possible. In\nthe literature, cosine based random quantization has attracted much attentions\ndue to its intrinsic bounded results. Nevertheless, it usually suffers from the\nuncertain outputs, and information of original data fails to be fully preserved\nin the reduced codes. In this work, a novel binary embedding method, termed\nadaptive training quantization (ATQ), is proposed to learn the ideal transform\nof random encoder, where the limitation of cosine random mapping is tackled. As\nan adaptive learning idea, the reduced mapping is adaptively calculated with\nidea of data group, while the bias of random transform is to be improved to\nhold most matching information. Experimental results show that the proposed\nmethod is able to obtain outstanding performance compared with other random\nquantization methods.</p>\n", "tags": ["CVPR", "Quantization", "Hashing Methods", "Evaluation"], "tsne_embedding": [-1.7039906978607178, -9.621355056762695], "cluster": 9}, {"key": "cheng2018crh", "year": "2018", "citations": "6", "title": "CRH: A Simple Benchmark Approach To Continuous Hashing", "abstract": "<p>In recent years, the distinctive advancement of handling huge data promotes\nthe evolution of ubiquitous computing and analysis technologies. With the\nconstantly upward system burden and computational complexity, adaptive coding\nhas been a fascinating topic for pattern analysis, with outstanding\nperformance. In this work, a continuous hashing method, termed continuous\nrandom hashing (CRH), is proposed to encode sequential data stream, while\nignorance of previously hashing knowledge is possible. Instead, a random\nselection idea is adopted to adaptively approximate the differential encoding\npatterns of data stream, e.g., streaming media, and iteration is avoided for\nstepwise learning. Experimental results demonstrate our method is able to\nprovide outstanding performance, as a benchmark approach to continuous hashing.</p>\n", "tags": ["Hashing Methods", "Evaluation"], "tsne_embedding": [3.6808454990386963, -15.817320823669434], "cluster": 5}, {"key": "cheng2021cnn", "year": "2021", "citations": "16", "title": "CNN Retrieval Based Unsupervised Metric Learning For Near-duplicated Video Retrieval", "abstract": "<p>As important data carriers, the drastically increasing number of multimedia\nvideos often brings many duplicate and near-duplicate videos in the top results\nof search. Near-duplicate video retrieval (NDVR) can cluster and filter out the\nredundant contents. In this paper, the proposed NDVR approach extracts the\nframe-level video representation based on convolutional neural network (CNN)\nfeatures from fully-connected layer and aggregated intermediate convolutional\nlayers. Unsupervised metric learning is used for similarity measurement and\nfeature matching. An efficient re-ranking algorithm combined with k-nearest\nneighborhood fuses the retrieval results from two levels of features and\nfurther improves the retrieval performance. Extensive experiments on the widely\nused CC_WEB_VIDEO dataset shows that the proposed approach exhibits superior\nperformance over the state-of-the-art.</p>\n", "tags": ["DATASETS", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [-6.674374103546143, 21.972684860229492], "cluster": 6}, {"key": "cheng2025robust", "year": "2025", "citations": "46", "title": "Robust Unsupervised Cross-modal Hashing For Multimedia Retrieval", "abstract": "<p>With the quick development of social websites, there are more opportunities to have different media types (such as text, image, video, etc.) describing the same topic from large-scale heterogeneous data sources. To efficiently identify the inter-media correlations for multimedia retrieval, unsupervised cross-modal hashing (UCMH) has gained increased interest due to the significant reduction in computation and storage. However, most UCMH methods assume that the data from different modalities are well paired. As a result, existing UCMH methods may not achieve satisfactory performance when partially paired data are given only. In this article, we propose a new-type of UCMH method called robust unsupervised cross-modal hashing (RUCMH). The major contribution lies in jointly learning modal-specific hash function, exploring the correlations among modalities with partial or even without any pairwise correspondence, and preserving the information of original features as much as possible. The learning process can be modeled via a joint minimization problem, and the corresponding optimization algorithm is presented. A series of experiments is conducted on four real-world datasets (Wiki, MIRFlickr, NUS-WIDE, and MS-COCO). The results demonstrate that RUCMH can significantly outperform the state-of-the-art unsupervised cross-modal hashing methods, especially for the partially paired case, which validates the effectiveness of RUCMH.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Evaluation"], "tsne_embedding": [-5.059937000274658, -5.08966588973999], "cluster": 9}, {"key": "chiu2018learning", "year": "2018", "citations": "24", "title": "Learning To Index For Nearest Neighbor Search", "abstract": "<p>In this study, we present a novel ranking model based on learning\nneighborhood relationships embedded in the index space. Given a query point,\nconventional approximate nearest neighbor search calculates the distances to\nthe cluster centroids, before ranking the clusters from near to far based on\nthe distances. The data indexed in the top-ranked clusters are retrieved and\ntreated as the nearest neighbor candidates for the query. However, the loss of\nquantization between the data and cluster centroids will inevitably harm the\nsearch accuracy. To address this problem, the proposed model ranks clusters\nbased on their nearest neighbor probabilities rather than the query-centroid\ndistances. The nearest neighbor probabilities are estimated by employing neural\nnetworks to characterize the neighborhood relationships, i.e., the density\nfunction of nearest neighbors with respect to the query. The proposed\nprobability-based ranking can replace the conventional distance-based ranking\nfor finding candidate clusters, and the predicted probability can be used to\ndetermine the data quantity to be retrieved from the candidate cluster. Our\nexperimental results demonstrated that the proposed ranking model could boost\nthe search performance effectively in billion-scale datasets.</p>\n", "tags": ["Large Scale Search", "DATASETS", "Quantization", "Evaluation"], "tsne_embedding": [16.5068302154541, 7.074724197387695], "cluster": 0}, {"key": "chowdhury2018instance", "year": "2018", "citations": "5", "title": "Instance-based Inductive Deep Transfer Learning By Cross-dataset Querying With Locality Sensitive Hashing", "abstract": "<p>Supervised learning models are typically trained on a single dataset and the\nperformance of these models rely heavily on the size of the dataset, i.e.,\namount of data available with the ground truth. Learning algorithms try to\ngeneralize solely based on the data that is presented with during the training.\nIn this work, we propose an inductive transfer learning method that can augment\nlearning models by infusing similar instances from different learning tasks in\nthe Natural Language Processing (NLP) domain. We propose to use instance\nrepresentations from a source dataset, \\textit{without inheriting anything}\nfrom the source learning model. Representations of the instances of\n\\textit{source} \\&amp; \\textit{target} datasets are learned, retrieval of relevant\nsource instances is performed using soft-attention mechanism and\n\\textit{locality sensitive hashing}, and then, augmented into the model during\ntraining on the target dataset. Our approach simultaneously exploits the local\n\\textit{instance level information} as well as the macro statistical viewpoint\nof the dataset. Using this approach we have shown significant improvements for\nthree major news classification datasets over the baseline. Experimental\nevaluations also show that the proposed approach reduces dependency on labeled\ndata by a significant margin for comparable performance. With our proposed\ncross dataset learning procedure we show that one can achieve\ncompetitive/better performance than learning from a single dataset.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Evaluation", "DATASETS"], "tsne_embedding": [-20.350379943847656, 0.7896395921707153], "cluster": 3}, {"key": "christiani2016framework", "year": "2016", "citations": "21", "title": "A Framework For Similarity Search With Space-time Tradeoffs Using Locality-sensitive Filtering", "abstract": "<p>We present a framework for similarity search based on Locality-Sensitive\nFiltering (LSF), generalizing the Indyk-Motwani (STOC 1998) Locality-Sensitive\nHashing (LSH) framework to support space-time tradeoffs. Given a family of\nfilters, defined as a distribution over pairs of subsets of space with certain\nlocality-sensitivity properties, we can solve the approximate near neighbor\nproblem in \\(d\\)-dimensional space for an \\(n\\)-point data set with query time\n\\(dn^{\\rho_q+o(1)}\\), update time \\(dn^{\\rho_u+o(1)}\\), and space usage \\(dn + n^{1</p>\n<ul>\n  <li>\\rho_u + o(1)}\\). The space-time tradeoff is tied to the tradeoff between\nquery time and update time, controlled by the exponents \\(\\rho_q, \\rho_u\\) that\nare determined by the filter family. Locality-sensitive filtering was\nintroduced by Becker et al. (SODA 2016) together with a framework yielding a\nsingle, balanced, tradeoff between query time and space, further relying on the\nassumption of an efficient oracle for the filter evaluation algorithm. We\nextend the LSF framework to support space-time tradeoffs and through a\ncombination of existing techniques we remove the oracle assumption.\nBuilding on a filter family for the unit sphere by Laarhoven (arXiv 2015) we\nuse a kernel embedding technique by Rahimi &amp; Recht (NIPS 2007) to show a\nsolution to the \\((r,cr)\\)-near neighbor problem in \\(\\ell_s^d\\)-space for \\(0 &lt; s\n\\leq 2\\) with query and update exponents\n\\(\\rho_q=\\frac{c^s(1+\\lambda)^2}{(c^s+\\lambda)^2}\\) and\n\\(\\rho_u=\\frac{c^s(1-\\lambda)^2}{(c^s+\\lambda)^2}\\) where \\(\\lambda\\in[-1,1]\\) is a\ntradeoff parameter. This result improves upon the space-time tradeoff of\nKapralov (PODS 2015) and is shown to be optimal in the case of a balanced\ntradeoff. Finally, we show a lower bound for the space-time tradeoff on the\nunit sphere that matches Laarhoven\u2019s and our own upper bound in the case of\nrandom data.</li>\n</ul>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Efficiency And Optimization", "Similarity Search", "Tools & Libraries", "Evaluation"], "tsne_embedding": [30.46021842956543, 1.2412112951278687], "cluster": 7}, {"key": "christiani2016set", "year": "2016", "citations": "45", "title": "Set Similarity Search Beyond Minhash", "abstract": "<p>We consider the problem of approximate set similarity search under\nBraun-Blanquet similarity \\(B(\\mathbf{x}, \\mathbf{y}) = |\\mathbf{x} \\cap\n\\mathbf{y}| / \\max(|\\mathbf{x}|, |\\mathbf{y}|)\\). The \\((b_2, b_2)\\)-approximate\nBraun-Blanquet similarity search problem is to preprocess a collection of sets\n\\(P\\) such that, given a query set \\(\\mathbf{q}\\), if there exists \\(\\mathbf{x} \\in\nP\\) with \\(B(\\mathbf{q}, \\mathbf{x}) \\geq b_1\\), then we can efficiently return\n\\(\\mathbf{x}\u2019 \\in P\\) with \\(B(\\mathbf{q}, \\mathbf{x}\u2019) &gt; b_2\\).\n  We present a simple data structure that solves this problem with space usage\n\\(O(n^{1+\\rho}log n + \\sum_{\\mathbf{x} \\in P}|\\mathbf{x}|)\\) and query time\n\\(O(|\\mathbf{q}|n^{\\rho} log n)\\) where \\(n = |P|\\) and \\(\\rho =\nlog(1/b_1)/log(1/b_2)\\). Making use of existing lower bounds for\nlocality-sensitive hashing by O\u2019Donnell et al. (TOCT 2014) we show that this\nvalue of \\(\\rho\\) is tight across the parameter space, i.e., for every choice of\nconstants \\(0 &lt; b_2 &lt; b_1 &lt; 1\\).\n  In the case where all sets have the same size our solution strictly improves\nupon the value of \\(\\rho\\) that can be obtained through the use of\nstate-of-the-art data-independent techniques in the Indyk-Motwani\nlocality-sensitive hashing framework (STOC 1998) such as Broder\u2019s MinHash (CCS\n1997) for Jaccard similarity and Andoni et al.\u2019s cross-polytope LSH (NIPS 2015)\nfor cosine similarity. Surprisingly, even though our solution is\ndata-independent, for a large part of the parameter space we outperform the\ncurrently best data-dependent method by Andoni and Razenshteyn (STOC 2015).</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Distance Metric Learning", "Efficiency And Optimization", "Similarity Search", "Tools & Libraries"], "tsne_embedding": [31.06808090209961, -0.2460547834634781], "cluster": 7}, {"key": "christiani2017fast", "year": "2017", "citations": "14", "title": "Fast Locality-sensitive Hashing Frameworks For Approximate Near Neighbor Search", "abstract": "<p>The Indyk-Motwani Locality-Sensitive Hashing (LSH) framework (STOC 1998) is a\ngeneral technique for constructing a data structure to answer approximate near\nneighbor queries by using a distribution \\(\\mathcal{H}\\) over locality-sensitive\nhash functions that partition space. For a collection of \\(n\\) points, after\npreprocessing, the query time is dominated by \\(O(n^{\\rho} log n)\\) evaluations\nof hash functions from \\(\\mathcal{H}\\) and \\(O(n^{\\rho})\\) hash table lookups and\ndistance computations where \\(\\rho \\in (0,1)\\) is determined by the\nlocality-sensitivity properties of \\(\\mathcal{H}\\). It follows from a recent\nresult by Dahlgaard et al. (FOCS 2017) that the number of locality-sensitive\nhash functions can be reduced to \\(O(log^2 n)\\), leaving the query time to be\ndominated by \\(O(n^{\\rho})\\) distance computations and \\(O(n^{\\rho} log n)\\)\nadditional word-RAM operations. We state this result as a general framework and\nprovide a simpler analysis showing that the number of lookups and distance\ncomputations closely match the Indyk-Motwani framework, making it a viable\nreplacement in practice. Using ideas from another locality-sensitive hashing\nframework by Andoni and Indyk (SODA 2006) we are able to reduce the number of\nadditional word-RAM operations to \\(O(n^\\rho)\\).</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Graph Based ANN", "Efficiency And Optimization", "Tools & Libraries", "Evaluation"], "tsne_embedding": [28.635507583618164, -0.5327510833740234], "cluster": 7}, {"key": "christiani2017scalable", "year": "2017", "citations": "31", "title": "Scalable And Robust Set Similarity Join", "abstract": "<p>Set similarity join is a fundamental and well-studied database operator. It\nis usually studied in the exact setting where the goal is to compute all pairs\nof sets that exceed a given similarity threshold (measured e.g. as Jaccard\nsimilarity). But set similarity join is often used in settings where 100%\nrecall may not be important \u2014 indeed, where the exact set similarity join is\nitself only an approximation of the desired result set.\n  We present a new randomized algorithm for set similarity join that can\nachieve any desired recall up to 100%, and show theoretically and empirically\nthat it significantly improves on existing methods. The present\nstate-of-the-art exact methods are based on prefix-filtering, the performance\nof which depends on the data set having many rare tokens. Our method is robust\nagainst the absence of such structure in the data. At 90% recall our algorithm\nis often more than an order of magnitude faster than state-of-the-art exact\nmethods, depending on how well a data set lends itself to prefix filtering. Our\nexperiments on benchmark data sets also show that the method is several times\nfaster than comparable approximate methods. Our algorithm makes use of recent\ntheoretical advances in high-dimensional sketching and indexing that we believe\nto be of wider relevance to the data engineering community.</p>\n", "tags": ["Evaluation"], "tsne_embedding": [13.554333686828613, -4.137331485748291], "cluster": 2}, {"key": "christiani2018confirmation", "year": "2018", "citations": "6", "title": "Confirmation Sampling For Exact Nearest Neighbor Search", "abstract": "<p>Locality-sensitive hashing (LSH), introduced by Indyk and Motwani in STOC\n\u201898, has been an extremely influential framework for nearest neighbor search in\nhigh-dimensional data sets. While theoretical work has focused on the\napproximate nearest neighbor problems, in practice LSH data structures with\nsuitably chosen parameters are used to solve the exact nearest neighbor problem\n(with some error probability). Sublinear query time is often possible in\npractice even for exact nearest neighbor search, intuitively because the\nnearest neighbor tends to be significantly closer than other data points.\nHowever, theory offers little advice on how to choose LSH parameters outside of\npre-specified worst-case settings.\n  We introduce the technique of confirmation sampling for solving the exact\nnearest neighbor problem using LSH. First, we give a general reduction that\ntransforms a sequence of data structures that each find the nearest neighbor\nwith a small, unknown probability, into a data structure that returns the\nnearest neighbor with probability \\(1-\\delta\\), using as few queries as possible.\nSecond, we present a new query algorithm for the LSH Forest data structure with\n\\(L\\) trees that is able to return the exact nearest neighbor of a query point\nwithin the same time bound as an LSH Forest of \\(\u03a9(L)\\) trees with internal\nparameters specifically tuned to the query and data.</p>\n", "tags": ["Locality Sensitive Hashing", "Tools & Libraries", "Hashing Methods", "Efficiency And Optimization"], "tsne_embedding": [18.97801971435547, 1.686038851737976], "cluster": 7}, {"key": "christiani2020dartminhash", "year": "2020", "citations": "16", "title": "Dartminhash: Fast Sketching For Weighted Sets", "abstract": "<p>Weighted minwise hashing is a standard dimensionality reduction technique\nwith applications to similarity search and large-scale kernel machines. We\nintroduce a simple algorithm that takes a weighted set \\(x \\in \\mathbb{R}<em>{\\geq\n0}^{d}\\) and computes \\(k\\) independent minhashes in expected time \\(O(k log k +\n\\Vert x \\Vert</em>{0}log( \\Vert x \\Vert_1 + 1/\\Vert x \\Vert_1))\\), improving upon\nthe state-of-the-art BagMinHash algorithm (KDD \u201818) and representing the\nfastest weighted minhash algorithm for sparse data. Our experiments show\nrunning times that scale better with \\(k\\) and \\(\\Vert x \\Vert_0\\) compared to ICWS\n(ICDM \u201810) and BagMinhash, obtaining \\(10\\)x speedups in common use cases. Our\napproach also gives rise to a technique for computing fully independent\nlocality-sensitive hash values for \\((L, K)\\)-parameterized approximate near\nneighbor search under weighted Jaccard similarity in optimal expected time\n\\(O(LK + \\Vert x \\Vert_0)\\), improving on prior work even in the case of\nunweighted sets.</p>\n", "tags": ["KDD", "Locality Sensitive Hashing", "Hashing Methods", "Efficiency And Optimization", "Similarity Search"], "tsne_embedding": [19.444164276123047, -5.96796178817749], "cluster": 7}, {"key": "clifford2016approximate", "year": "2016", "citations": "9", "title": "Approximate Hamming Distance In A Stream", "abstract": "<p>We consider the problem of computing a \\((1+\\epsilon)\\)-approximation of the\nHamming distance between a pattern of length \\(n\\) and successive substrings of a\nstream. We first look at the one-way randomised communication complexity of\nthis problem, giving Alice the first half of the stream and Bob the second\nhalf. We show the following: (1) If Alice and Bob both share the pattern then\nthere is an \\(O(\\epsilon^{-4} log^2 n)\\) bit randomised one-way communication\nprotocol. (2) If only Alice has the pattern then there is an\n\\(O(\\epsilon^{-2}\\sqrt{n}log n)\\) bit randomised one-way communication protocol.\n  We then go on to develop small space streaming algorithms for\n\\((1+\\epsilon)\\)-approximate Hamming distance which give worst case running time\nguarantees per arriving symbol. (1) For binary input alphabets there is an\n\\(O(\\epsilon^{-3} \\sqrt{n} log^{2} n)\\) space and \\(O(\\epsilon^{-2} log{n})\\)\ntime streaming \\((1+\\epsilon)\\)-approximate Hamming distance algorithm. (2) For\ngeneral input alphabets there is an \\(O(\\epsilon^{-5} \\sqrt{n} log^{4} n)\\)\nspace and \\(O(\\epsilon^{-4} log^3 {n})\\) time streaming\n\\((1+\\epsilon)\\)-approximate Hamming distance algorithm.</p>\n", "tags": [], "tsne_embedding": [34.99861145019531, -1.1370794773101807], "cluster": 7}, {"key": "coleman2019sub", "year": "2019", "citations": "11", "title": "Sub-linear Memory Sketches For Near Neighbor Search On Streaming Data", "abstract": "<p>We present the first sublinear memory sketch that can be queried to find the\nnearest neighbors in a dataset. Our online sketching algorithm compresses an N\nelement dataset to a sketch of size \\(O(N^b log^3 N)\\) in \\(O(N^{(b+1)} log^3\nN)\\) time, where \\(b &lt; 1\\). This sketch can correctly report the nearest neighbors\nof any query that satisfies a stability condition parameterized by \\(b\\). We\nachieve sublinear memory performance on stable queries by combining recent\nadvances in locality sensitive hash (LSH)-based estimators, online kernel\ndensity estimation, and compressed sensing. Our theoretical results shed new\nlight on the memory-accuracy tradeoff for nearest neighbor search, and our\nsketch, which consists entirely of short integer arrays, has a variety of\nattractive features in practice. We evaluate the memory-recall tradeoff of our\nmethod on a friend recommendation task in the Google Plus social media network.\nWe obtain orders of magnitude better compression than the random projection\nbased alternative while retaining the ability to report the nearest neighbors\nof practical queries.</p>\n", "tags": ["Locality Sensitive Hashing", "DATASETS", "Recommender Systems", "Alt", "Evaluation"], "tsne_embedding": [18.073102951049805, 2.943720817565918], "cluster": 7}, {"key": "coleman2020similarity", "year": "2020", "citations": "16", "title": "Similarity Search For Efficient Active Learning And Search Of Rare Concepts", "abstract": "<p>Many active learning and search approaches are intractable for large-scale\nindustrial settings with billions of unlabeled examples. Existing approaches\nsearch globally for the optimal examples to label, scaling linearly or even\nquadratically with the unlabeled data. In this paper, we improve the\ncomputational efficiency of active learning and search methods by restricting\nthe candidate pool for labeling to the nearest neighbors of the currently\nlabeled set instead of scanning over all of the unlabeled data. We evaluate\nseveral selection strategies in this setting on three large-scale computer\nvision datasets: ImageNet, OpenImages, and a de-identified and aggregated\ndataset of 10 billion images provided by a large internet company. Our approach\nachieved similar mean average precision and recall as the traditional global\napproach while reducing the computational cost of selection by up to three\norders of magnitude, thus enabling web-scale active learning.</p>\n", "tags": ["AAAI", "DATASETS", "Efficiency And Optimization", "Large Scale Search", "Similarity Search", "Tools & Libraries", "Evaluation"], "tsne_embedding": [9.76865005493164, 23.557296752929688], "cluster": 0}, {"key": "coleman2021graph", "year": "2021", "citations": "5", "title": "Graph Reordering For Cache-efficient Near Neighbor Search", "abstract": "<p>Graph search is one of the most successful algorithmic trends in near\nneighbor search. Several of the most popular and empirically successful\nalgorithms are, at their core, a simple walk along a pruned near neighbor\ngraph. Such algorithms consistently perform at the top of industrial speed\nbenchmarks for applications such as embedding search. However, graph traversal\napplications often suffer from poor memory access patterns, and near neighbor\nsearch is no exception to this rule. Our measurements show that popular search\nindices such as the hierarchical navigable small-world graph (HNSW) can have\npoor cache miss performance. To address this problem, we apply graph reordering\nalgorithms to near neighbor graphs. Graph reordering is a memory layout\noptimization that groups commonly-accessed nodes together in memory. We present\nexhaustive experiments applying several reordering algorithms to a leading\ngraph-based near neighbor method based on the HNSW index. We find that\nreordering improves the query time by up to 40%, and we demonstrate that the\ntime needed to reorder the graph is negligible compared to the time required to\nconstruct the index.</p>\n", "tags": ["Graph Based ANN", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [19.446155548095703, 12.58350658416748], "cluster": 0}, {"key": "conjeti2016deep", "year": "2016", "citations": "8", "title": "Deep Residual Hashing", "abstract": "<p>Hashing aims at generating highly compact similarity preserving code words\nwhich are well suited for large-scale image retrieval tasks.\n  Most existing hashing methods first encode the images as a vector of\nhand-crafted features followed by a separate binarization step to generate hash\ncodes. This two-stage process may produce sub-optimal encoding. In this paper,\nfor the first time, we propose a deep architecture for supervised hashing\nthrough residual learning, termed Deep Residual Hashing (DRH), for an\nend-to-end simultaneous representation learning and hash coding. The DRH model\nconstitutes four key elements: (1) a sub-network with multiple stacked residual\nblocks; (2) hashing layer for binarization; (3) supervised retrieval loss\nfunction based on neighbourhood component analysis for similarity preserving\nembedding; and (4) hashing related losses and regularisation to control the\nquantization error and improve the quality of hash coding. We present results\nof extensive experiments on a large public chest x-ray image database with\nco-morbidities and discuss the outcome showing substantial improvements over\nthe latest state-of-the art methods.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Quantization"], "tsne_embedding": [-8.52120590209961, 3.8350632190704346], "cluster": 8}, {"key": "conjeti2017learning", "year": "2017", "citations": "12", "title": "Learning Robust Hash Codes For Multiple Instance Image Retrieval", "abstract": "<p>In this paper, for the first time, we introduce a multiple instance (MI) deep\nhashing technique for learning discriminative hash codes with weak bag-level\nsupervision suited for large-scale retrieval. We learn such hash codes by\naggregating deeply learnt hierarchical representations across bag members\nthrough a dedicated MI pool layer. For better trainability and retrieval\nquality, we propose a two-pronged approach that includes robust optimization\nand training with an auxiliary single instance hashing arm which is\ndown-regulated gradually. We pose retrieval for tumor assessment as an MI\nproblem because tumors often coexist with benign masses and could exhibit\ncomplementary signatures when scanned from different anatomical views.\nExperimental validations on benchmark mammography and histology datasets\ndemonstrate improved retrieval performance over the state-of-the-art methods.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-20.474607467651367, 14.821663856506348], "cluster": 3}, {"key": "connor2016hilbert", "year": "2016", "citations": "18", "title": "Hilbert Exclusion: Improved Metric Search Through Finite Isometric Embeddings", "abstract": "<p>Most research into similarity search in metric spaces relies upon the\ntriangle inequality property. This property allows the space to be arranged\naccording to relative distances to avoid searching some subspaces. We show that\nmany common metric spaces, notably including those using Euclidean and\nJensen-Shannon distances, also have a stronger property, sometimes called the\nfour-point property: in essence, these spaces allow an isometric embedding of\nany four points in three-dimensional Euclidean space, as well as any three\npoints in two-dimensional Euclidean space. In fact, we show that any space\nwhich is isometrically embeddable in Hilbert space has the stronger property.\nThis property gives stronger geometric guarantees, and one in particular, which\nwe name the Hilbert Exclusion property, allows any indexing mechanism which\nuses hyperplane partitioning to perform better. One outcome of this observation\nis that a number of state-of-the-art indexing mechanisms over high dimensional\nspaces can be easily extended to give a significant increase in performance;\nfurthermore, the improvement given is greater in higher dimensions. This\ntherefore leads to a significant improvement in the cost of metric search in\nthese spaces.</p>\n", "tags": ["Similarity Search", "Evaluation"], "tsne_embedding": [29.97720718383789, -7.96916389465332], "cluster": 7}, {"key": "connor2017high", "year": "2017", "citations": "19", "title": "High-dimensional Simplexes For Supermetric Search", "abstract": "<p>In 1953, Blumenthal showed that every semi-metric space that is isometrically\nembeddable in a Hilbert space has the n-point property; we have previously\ncalled such spaces supermetric spaces. Although this is a strictly stronger\nproperty than triangle inequality, it is nonetheless closely related and many\nuseful metric spaces possess it. These include Euclidean, Cosine and\nJensen-Shannon spaces of any dimension. A simple corollary of the n-point\nproperty is that, for any (n+1) objects sampled from the space, there exists an\nn-dimensional simplex in Euclidean space whose edge lengths correspond to the\ndistances among the objects. We show how the construction of such simplexes in\nhigher dimensions can be used to give arbitrarily tight lower and upper bounds\non distances within the original space. This allows the construction of an\nn-dimensional Euclidean space, from which lower and upper bounds of the\noriginal space can be calculated, and which is itself an indexable space with\nthe n-point property. For similarity search, the engineering tradeoffs are\ngood: we show significant reductions in data size and metric cost with little\nloss of accuracy, leading to a significant overall improvement in search\nperformance.</p>\n", "tags": ["Alt", "Similarity Search", "Evaluation"], "tsne_embedding": [29.93701171875, -7.961142063140869], "cluster": 7}, {"key": "conway2018optimal", "year": "2018", "citations": "6", "title": "Optimal Hashing In External Memory", "abstract": "<p>Hash tables are a ubiquitous class of dictionary data structures. However,\nstandard hash table implementations do not translate well into the external\nmemory model, because they do not incorporate locality for insertions.\n  Iacono and Patracsu established an update/query tradeoff curve for external\nhash tables: a hash table that performs insertions in \\(O(\\lambda/B)\\) amortized\nIOs requires \\(\u03a9(log_\\lambda N)\\) expected IOs for queries, where \\(N\\) is\nthe number of items that can be stored in the data structure, \\(B\\) is the size\nof a memory transfer, \\(M\\) is the size of memory, and \\(\\lambda\\) is a tuning\nparameter.\n  They provide a hashing data structure that meets this curve for \\(\\lambda\\)\nthat is \\(\u03a9(loglog M + log_M N)\\). Their data structure, which we call an\n\\defn{IP hash table}, is complicated and, to the best of our knowledge, has not\nbeen implemented.\n  In this paper, we present a new and much simpler optimal external memory hash\ntable, the \\defn{Bundle of Arrays Hash Table} (BOA). BOAs are based on\nsize-tiered LSMs, a well-studied data structure, and are almost as easy to\nimplement. The BOA is optimal for a narrower range of \\(\\lambda\\). However, the\nsimplicity of BOAs allows them to be readily modified to achieve the following\nresults:\n  \\begin{itemize}\n  \\item A new external memory data structure, the \\defn{Bundle of Trees Hash\nTable} (BOT), that matches the performance of the IP hash table, while\nretaining some of the simplicity of the BOAs.\n  \\item The \\defn{cache-oblivious Bundle of Trees Hash Table} (COBOT), the\nfirst cache-oblivious hash table. This data structure matches the optimality of\nBOTs and IP hash tables over the same range of \\(\\lambda\\). \\end{itemize}</p>\n", "tags": ["Hashing Methods", "Evaluation"], "tsne_embedding": [-4.03159761428833, -29.411148071289062], "cluster": 5}, {"key": "cox2012large", "year": "2012", "citations": "139", "title": "Large-scale Compression Of Genomic Sequence Databases With The Burrows-wheeler Transform", "abstract": "<p>Motivation\n  The Burrows-Wheeler transform (BWT) is the foundation of many algorithms for\ncompression and indexing of text data, but the cost of computing the BWT of\nvery large string collections has prevented these techniques from being widely\napplied to the large sets of sequences often encountered as the outcome of DNA\nsequencing experiments. In previous work, we presented a novel algorithm that\nallows the BWT of human genome scale data to be computed on very moderate\nhardware, thus enabling us to investigate the BWT as a tool for the compression\nof such datasets.\n  Results\n  We first used simulated reads to explore the relationship between the level\nof compression and the error rate, the length of the reads and the level of\nsampling of the underlying genome and compare choices of second-stage\ncompression algorithm.\n  We demonstrate that compression may be greatly improved by a particular\nreordering of the sequences in the collection and give a novel `implicit\nsorting\u2019 strategy that enables these benefits to be realised without the\noverhead of sorting the reads. With these techniques, a 45x coverage of real\nhuman genome sequence data compresses losslessly to under 0.5 bits per base,\nallowing the 135.3Gbp of sequence to fit into only 8.2Gbytes of space (trimming\na small proportion of low-quality bases from the reads improves the compression\nstill further).\n  This is more than 4 times smaller than the size achieved by a standard\nBWT-based compressor (bzip2) on the untrimmed reads, but an important further\nadvantage of our approach is that it facilitates the building of compressed\nfull text indexes such as the FM-index on large-scale DNA sequence collections.</p>\n", "tags": ["DATASETS"], "tsne_embedding": [-16.635793685913086, -17.54306983947754], "cluster": 1}, {"key": "csurka2014unsupervised", "year": "2014", "citations": "6", "title": "Unsupervised Visual And Textual Information Fusion In Multimedia Retrieval - A Graph-based Point Of View", "abstract": "<p>Multimedia collections are more than ever growing in size and diversity.\nEffective multimedia retrieval systems are thus critical to access these\ndatasets from the end-user perspective and in a scalable way. We are interested\nin repositories of image/text multimedia objects and we study multimodal\ninformation fusion techniques in the context of content based multimedia\ninformation retrieval. We focus on graph based methods which have proven to\nprovide state-of-the-art performances. We particularly examine two of such\nmethods : cross-media similarities and random walk based scores. From a\ntheoretical viewpoint, we propose a unifying graph based framework which\nencompasses the two aforementioned approaches. Our proposal allows us to\nhighlight the core features one should consider when using a graph based\ntechnique for the combination of visual and textual information. We compare\ncross-media and random walk based results using three different real-world\ndatasets. From a practical standpoint, our extended empirical analysis allow us\nto provide insights and guidelines about the use of graph based methods for\nmultimodal information fusion in content based multimedia information\nretrieval.</p>\n", "tags": ["Graph Based ANN", "DATASETS", "Tools & Libraries", "Evaluation"], "tsne_embedding": [14.5244722366333, 16.912742614746094], "cluster": 0}, {"key": "cui2017graphmatch", "year": "2017", "citations": "9", "title": "Graphmatch: Efficient Large-scale Graph Construction For Structure From Motion", "abstract": "<p>We present GraphMatch, an approximate yet efficient method for building the\nmatching graph for large-scale structure-from-motion (SfM) pipelines. Unlike\nmodern SfM pipelines that use vocabulary (Voc.) trees to quickly build the\nmatching graph and avoid a costly brute-force search of matching image pairs,\nGraphMatch does not require an expensive offline pre-processing phase to\nconstruct a Voc. tree. Instead, GraphMatch leverages two priors that can\npredict which image pairs are likely to match, thereby making the matching\nprocess for SfM much more efficient. The first is a score computed from the\ndistance between the Fisher vectors of any two images. The second prior is\nbased on the graph distance between vertices in the underlying matching graph.\nGraphMatch combines these two priors into an iterative \u201csample-and-propagate\u201d\nscheme similar to the PatchMatch algorithm. Its sampling stage uses Fisher\nsimilarity priors to guide the search for matching image pairs, while its\npropagation stage explores neighbors of matched pairs to find new ones with a\nhigh image similarity score. Our experiments show that GraphMatch finds the\nmost image pairs as compared to competing, approximate methods while at the\nsame time being the most efficient.</p>\n", "tags": ["Graph Based ANN"], "tsne_embedding": [21.28888511657715, 11.66541576385498], "cluster": 0}, {"key": "cui2020exchnet", "year": "2020", "citations": "31", "title": "Exchnet: A Unified Hashing Network For Large-scale Fine-grained Image Retrieval", "abstract": "<p>Retrieving content relevant images from a large-scale fine-grained dataset\ncould suffer from intolerably slow query speed and highly redundant storage\ncost, due to high-dimensional real-valued embeddings which aim to distinguish\nsubtle visual differences of fine-grained objects. In this paper, we study the\nnovel fine-grained hashing topic to generate compact binary codes for\nfine-grained images, leveraging the search and storage efficiency of hash\nlearning to alleviate the aforementioned problems. Specifically, we propose a\nunified end-to-end trainable network, termed as ExchNet. Based on attention\nmechanisms and proposed attention constraints, it can firstly obtain both local\nand global features to represent object parts and whole fine-grained objects,\nrespectively. Furthermore, to ensure the discriminative ability and semantic\nmeaning\u2019s consistency of these part-level features across images, we design a\nlocal feature alignment approach by performing a feature exchanging operation.\nLater, an alternative learning algorithm is employed to optimize the whole\nExchNet and then generate the final binary hash codes. Validated by extensive\nexperiments, our proposal consistently outperforms state-of-the-art generic\nhashing methods on five fine-grained datasets, which shows our effectiveness.\nMoreover, compared with other approximate nearest neighbor methods, ExchNet\nachieves the best speed-up and storage reduction, revealing its efficiency and\npracticality.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Alt"], "tsne_embedding": [-9.659842491149902, 9.915891647338867], "cluster": 8}, {"key": "cunningham2020k", "year": "2020", "citations": "16", "title": "K-nearest Neighbour Classifiers: 2nd Edition (with Python Examples)", "abstract": "<p>Perhaps the most straightforward classifier in the arsenal or machine\nlearning techniques is the Nearest Neighbour Classifier \u2013 classification is\nachieved by identifying the nearest neighbours to a query example and using\nthose neighbours to determine the class of the query. This approach to\nclassification is of particular importance because issues of poor run-time\nperformance is not such a problem these days with the computational power that\nis available. This paper presents an overview of techniques for Nearest\nNeighbour classification focusing on; mechanisms for assessing similarity\n(distance), computational issues in identifying nearest neighbours and\nmechanisms for reducing the dimension of the data.\n  This paper is the second edition of a paper previously published as a\ntechnical report. Sections on similarity measures for time-series, retrieval\nspeed-up and intrinsic dimensionality have been added. An Appendix is included\nproviding access to Python code for the key methods.</p>\n", "tags": ["Survey Paper", "Evaluation"], "tsne_embedding": [1.0490119457244873, -4.978965759277344], "cluster": 9}, {"key": "curtin2016fast", "year": "2016", "citations": "9", "title": "Fast Approximate Furthest Neighbors With Data-dependent Hashing", "abstract": "<p>We present a novel hashing strategy for approximate furthest neighbor search\nthat selects projection bases using the data distribution. This strategy leads\nto an algorithm, which we call DrusillaHash, that is able to outperform\nexisting approximate furthest neighbor strategies. Our strategy is motivated by\nan empirical study of the behavior of the furthest neighbor search problem,\nwhich lends intuition for where our algorithm is most useful. We also present a\nvariant of the algorithm that gives an absolute approximation guarantee; to our\nknowledge, this is the first such approximate furthest neighbor hashing\napproach to give such a guarantee. Performance studies indicate that\nDrusillaHash can achieve comparable levels of approximation to other algorithms\nwhile giving up to an order of magnitude speedup. An implementation is\navailable in the mlpack machine learning library (found at\nhttp://www.mlpack.org).</p>\n", "tags": ["Tools & Libraries", "Hashing Methods", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [19.35805320739746, -1.5154531002044678], "cluster": 7}, {"key": "curt\u00f32017segmentation", "year": "2017", "citations": "29", "title": "Segmentation Of Objects By Hashing", "abstract": "<p>We propose a novel approach to address the problem of Simultaneous Detection\nand Segmentation introduced in [Hariharan et al 2014]. Using the hierarchical\nstructures first presented in [Arbel'aez et al 2011] we use an efficient and\naccurate procedure that exploits the feature information of the hierarchy using\nLocality Sensitive Hashing. We build on recent work that utilizes convolutional\nneural networks to detect bounding boxes in an image [Ren et al 2015] and then\nuse the top similar hierarchical region that best fits each bounding box after\nhashing, we call this approach C&amp;Z Segmentation. We then refine our final\nsegmentation results by automatic hierarchical pruning. C&amp;Z Segmentation\nintroduces a train-free alternative to Hypercolumns [Hariharan et al 2015]. We\nconduct extensive experiments on PASCAL VOC 2012 segmentation dataset, showing\nthat C&amp;Z gives competitive state-of-the-art segmentations of objects.</p>\n", "tags": ["Alt", "Locality Sensitive Hashing", "Hashing Methods", "DATASETS"], "tsne_embedding": [-18.129199981689453, -7.321635723114014], "cluster": 1}, {"key": "dadaneh2020pairwise", "year": "2020", "citations": "11", "title": "Pairwise Supervised Hashing With Bernoulli Variational Auto-encoder And Self-control Gradient Estimator", "abstract": "<p>Semantic hashing has become a crucial component of fast similarity search in\nmany large-scale information retrieval systems, in particular, for text data.\nVariational auto-encoders (VAEs) with binary latent variables as hashing codes\nprovide state-of-the-art performance in terms of precision for document\nretrieval. We propose a pairwise loss function with discrete latent VAE to\nreward within-class similarity and between-class dissimilarity for supervised\nhashing. Instead of solving the optimization relying on existing biased\ngradient estimators, an unbiased low-variance gradient estimator is adopted to\noptimize the hashing function by evaluating the non-differentiable loss\nfunction over two correlated sets of binary hashing codes to control the\nvariance of gradient estimates. This new semantic hashing framework achieves\nsuperior performance compared to the state-of-the-arts, as demonstrated by our\ncomprehensive experiments.</p>\n", "tags": ["Text Retrieval", "Evaluation", "Hashing Methods", "UAI", "Similarity Search", "Tools & Libraries"], "tsne_embedding": [-1.1229380369186401, -0.3503051996231079], "cluster": 8}, {"key": "dahlgaard2017fast", "year": "2017", "citations": "30", "title": "Fast Similarity Sketching", "abstract": "<p>We consider the \\(\\textit{Similarity Sketching}\\) problem: Given a universe\n\\([u] = \\{0,\\ldots, u-1\\}\\) we want a random function \\(S\\) mapping subsets\n\\(A\\subseteq [u]\\) into vectors \\(S(A)\\) of size \\(t\\), such that the Jaccard\nsimilarity \\(J(A,B) = |A\\cap B|/|A\\cup B|\\) between sets \\(A\\) and \\(B\\) is\npreserved. More precisely, define \\(X_i = [S(A)[i] =\n  S(B)[i]]\\) and \\(X = \\sum_{i\\in [t]} X_i\\). We want \\(E[X_i]=J(A,B)\\), and we want\n\\(X\\) to be strongly concentrated around \\(E[X] = t \\cdot J(A,B)\\) (i.e.\nChernoff-style bounds). This is a fundamental problem which has found numerous\napplications in data mining, large-scale classification, computer vision,\nsimilarity search, etc. via the classic MinHash algorithm. The vectors \\(S(A)\\)\nare also called \\(\\textit{sketches}\\). Strong concentration is critical, for\noften we want to sketch many sets \\(B_1,\\ldots,B_n\\) so that we later, for a\nquery set \\(A\\), can find (one of) the most similar \\(B_i\\). It is then critical\nthat no \\(B_i\\) looks much more similar to \\(A\\) due to errors in the sketch.\n  The seminal \\(t\\times\\textit{MinHash}\\) algorithm uses \\(t\\) random hash\nfunctions \\(h_1,\\ldots, h_t\\), and stores \\(\\left ( \\min_{a\\in A} h_1(A),\\ldots,\n\\min_{a\\in A} h_t(A) \\right )\\) as the sketch of \\(A\\). The main drawback of\nMinHash is, however, its \\(O(t\\cdot |A|)\\) running time, and finding a sketch\nwith similar properties and faster running time has been the subject of several\npapers. (continued\u2026)</p>\n", "tags": ["Locality Sensitive Hashing", "Similarity Search", "Evaluation"], "tsne_embedding": [31.808486938476562, 0.2026824802160263], "cluster": 7}, {"key": "dahlgaard2017practical", "year": "2017", "citations": "16", "title": "Practical Hash Functions For Similarity Estimation And Dimensionality Reduction", "abstract": "<p>Hashing is a basic tool for dimensionality reduction employed in several\naspects of machine learning. However, the perfomance analysis is often carried\nout under the abstract assumption that a truly random unit cost hash function\nis used, without concern for which concrete hash function is employed. The\nconcrete hash function may work fine on sufficiently random input. The question\nis if it can be trusted in the real world when faced with more structured\ninput.\n  In this paper we focus on two prominent applications of hashing, namely\nsimilarity estimation with the one permutation hashing (OPH) scheme of Li et\nal. [NIPS\u201912] and feature hashing (FH) of Weinberger et al. [ICML\u201909], both of\nwhich have found numerous applications, i.e. in approximate near-neighbour\nsearch with LSH and large-scale classification with SVM.\n  We consider mixed tabulation hashing of Dahlgaard et al.[FOCS\u201915] which was\nproved to perform like a truly random hash function in many applications,\nincluding OPH. Here we first show improved concentration bounds for FH with\ntruly random hashing and then argue that mixed tabulation performs similar for\nsparse input. Our main contribution, however, is an experimental comparison of\ndifferent hashing schemes when used inside FH, OPH, and LSH.\n  We find that mixed tabulation hashing is almost as fast as the\nmultiply-mod-prime scheme ax+b mod p. Mutiply-mod-prime is guaranteed to work\nwell on sufficiently random data, but we demonstrate that in the above\napplications, it can lead to bias and poor concentration on both real-world and\nsynthetic data. We also compare with the popular MurmurHash3, which has no\nproven guarantees. Mixed tabulation and MurmurHash3 both perform similar to\ntruly random hashing in our experiments. However, mixed tabulation is 40%\nfaster than MurmurHash3, and it has the proven guarantee of good performance on\nall possible input.</p>\n", "tags": ["ICML", "Locality Sensitive Hashing", "Hashing Methods", "Evaluation"], "tsne_embedding": [-3.171082019805908, -23.975385665893555], "cluster": 5}, {"key": "dai2017stochastic", "year": "2017", "citations": "73", "title": "Stochastic Generative Hashing", "abstract": "<p>Learning-based binary hashing has become a powerful paradigm for fast search\nand retrieval in massive databases. However, due to the requirement of discrete\noutputs for the hash functions, learning such functions is known to be very\nchallenging. In addition, the objective functions adopted by existing hashing\ntechniques are mostly chosen heuristically. In this paper, we propose a novel\ngenerative approach to learn hash functions through Minimum Description Length\nprinciple such that the learned hash codes maximally compress the dataset and\ncan also be used to regenerate the inputs. We also develop an efficient\nlearning algorithm based on the stochastic distributional gradient, which\navoids the notorious difficulty caused by binary output constraints, to jointly\noptimize the parameters of the hash function and the associated generative\nmodel. Extensive experiments on a variety of large-scale datasets show that the\nproposed method achieves better retrieval results than the existing\nstate-of-the-art methods.</p>\n", "tags": ["DATASETS", "Hashing Methods"], "tsne_embedding": [-3.7158398628234863, -12.5007963180542], "cluster": 9}, {"key": "dai2020convolutional", "year": "2020", "citations": "7", "title": "Convolutional Embedding For Edit Distance", "abstract": "<p>Edit-distance-based string similarity search has many applications such as\nspell correction, data de-duplication, and sequence alignment. However,\ncomputing edit distance is known to have high complexity, which makes string\nsimilarity search challenging for large datasets. In this paper, we propose a\ndeep learning pipeline (called CNN-ED) that embeds edit distance into Euclidean\ndistance for fast approximate similarity search. A convolutional neural network\n(CNN) is used to generate fixed-length vector embeddings for a dataset of\nstrings and the loss function is a combination of the triplet loss and the\napproximation error. To justify our choice of using CNN instead of other\nstructures (e.g., RNN) as the model, theoretical analysis is conducted to show\nthat some basic operations in our CNN model preserve edit distance.\nExperimental results show that CNN-ED outperforms data-independent CGK\nembedding and RNN-based GRU embedding in terms of both accuracy and efficiency\nby a large margin. We also show that string similarity search can be\nsignificantly accelerated using CNN-based embeddings, sometimes by orders of\nmagnitude.</p>\n", "tags": ["DATASETS", "Distance Metric Learning", "Efficiency And Optimization", "SIGIR", "Similarity Search"], "tsne_embedding": [-12.542738914489746, 23.74155044555664], "cluster": 6}, {"key": "dalins2019pdq", "year": "2019", "citations": "5", "title": "PDQ & TMK + PDQF -- A Test Drive Of Facebook's Perceptual Hashing Algorithms", "abstract": "<p>Efficient and reliable automated detection of modified image and multimedia\nfiles has long been a challenge for law enforcement, compounded by the harm\ncaused by repeated exposure to psychologically harmful materials. In August\n2019 Facebook open-sourced their PDQ and TMK + PDQF algorithms for image and\nvideo similarity measurement, respectively. In this report, we review the\nalgorithms\u2019 performance on detecting commonly encountered transformations on\nreal-world case data, sourced from contemporary investigations. We also provide\na reference implementation to demonstrate the potential application and\nintegration of such algorithms within existing law enforcement systems.</p>\n", "tags": ["Survey Paper", "Hashing Methods", "Evaluation"], "tsne_embedding": [-15.79255199432373, 17.292390823364258], "cluster": 3}, {"key": "daras2020smyrf", "year": "2020", "citations": "12", "title": "SMYRF: Efficient Attention Using Asymmetric Clustering", "abstract": "<p>We propose a novel type of balanced clustering algorithm to approximate\nattention. Attention complexity is reduced from \\(O(N^2)\\) to \\(O(N log N)\\),\nwhere \\(N\\) is the sequence length. Our algorithm, SMYRF, uses Locality Sensitive\nHashing (LSH) in a novel way by defining new Asymmetric transformations and an\nadaptive scheme that produces balanced clusters. The biggest advantage of SMYRF\nis that it can be used as a drop-in replacement for dense attention layers\nwithout any retraining. On the contrary, prior fast attention methods impose\nconstraints (e.g. queries and keys share the same vector representations) and\nrequire re-training from scratch. We apply our method to pre-trained\nstate-of-the-art Natural Language Processing and Computer Vision models and we\nreport significant memory and speed benefits. Notably, SMYRF-BERT outperforms\n(slightly) BERT on GLUE, while using \\(50%\\) less memory. We also show that\nSMYRF can be used interchangeably with dense attention before and after\ntraining. Finally, we use SMYRF to train GANs with attention in high\nresolutions. Using a single TPU, we were able to scale attention to 128x128=16k\nand 256x256=65k tokens on BigGAN on CelebA-HQ.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods"], "tsne_embedding": [-8.300370216369629, -14.743897438049316], "cluster": 9}, {"key": "dasgupta2013randomized", "year": "2013", "citations": "26", "title": "Randomized Partition Trees For Exact Nearest Neighbor Search", "abstract": "<p>The k-d tree was one of the first spatial data structures proposed for\nnearest neighbor search. Its efficacy is diminished in high-dimensional spaces,\nbut several variants, with randomization and overlapping cells, have proved to\nbe successful in practice. We analyze three such schemes. We show that the\nprobability that they fail to find the nearest neighbor, for any data set and\nany query point, is directly related to a simple potential function that\ncaptures the difficulty of the point configuration. We then bound this\npotential function in two situations of interest: the first, when data come\nfrom a doubling measure, and the second, when the data are documents from a\ntopic model.</p>\n", "tags": ["Tree Based ANN"], "tsne_embedding": [15.828797340393066, -6.571316242218018], "cluster": 2}, {"key": "datar2025locality", "year": "2025", "citations": "2874", "title": "Locality-sensitive Hashing Scheme Based On P-stable Distributions", "abstract": "<p>We present a novel Locality-Sensitive Hashing scheme for the Approximate Nearest Neighbor Problem under lp norm, based on p-stable distributions.Our scheme improves the running time of the earlier algorithm for the case of the lp norm. It also yields the first known provably efficient approximate NN algorithm for the case p&lt;1. We also show that the algorithm finds the exact near neigbhor in O(log n) time for data satisfying certain \u201cbounded growth\u201d condition.Unlike earlier schemes, our LSH scheme works directly on points in the Euclidean space without embeddings. Consequently, the resulting query time bound is free of large factors and is simple and easy to implement. Our experiments (on synthetic data sets) show that the our data structure is up to 40 times faster than kd-tree.</p>\n", "tags": ["Tree Based ANN", "Locality Sensitive Hashing", "Hashing Methods", "Efficiency And Optimization"], "tsne_embedding": [14.84144115447998, -2.455941915512085], "cluster": 2}, {"key": "deng2019triplet", "year": "2019", "citations": "376", "title": "Triplet-based Deep Hashing Network For Cross-modal Retrieval", "abstract": "<p>Given the benefits of its low storage requirements and high retrieval\nefficiency, hashing has recently received increasing attention. In\nparticular,cross-modal hashing has been widely and successfully used in\nmultimedia similarity search applications. However, almost all existing methods\nemploying cross-modal hashing cannot obtain powerful hash codes due to their\nignoring the relative similarity between heterogeneous data that contains\nricher semantic information, leading to unsatisfactory retrieval performance.\nIn this paper, we propose a triplet-based deep hashing (TDH) network for\ncross-modal retrieval. First, we utilize the triplet labels, which describes\nthe relative relationships among three instances as supervision in order to\ncapture more general semantic correlations between cross-modal instances. We\nthen establish a loss function from the inter-modal view and the intra-modal\nview to boost the discriminative abilities of the hash codes. Finally, graph\nregularization is introduced into our proposed TDH method to preserve the\noriginal semantic similarity between hash codes in Hamming space. Experimental\nresults show that our proposed method outperforms several state-of-the-art\napproaches on two popular cross-modal datasets.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "Neural Hashing", "Multimodal Retrieval", "Similarity Search", "Evaluation"], "tsne_embedding": [-2.2139458656311035, 0.20834265649318695], "cluster": 8}, {"key": "deng2025two", "year": "2025", "citations": "75", "title": "Two-stream Deep Hashing With Class-specific Centers For Supervised Image Search", "abstract": "<p>Hashing has been widely used for large-scale approximate nearest neighbor search due to its storage and search efficiency. Recent supervised hashing research has shown that deep learning-based methods can significantly outperform nondeep methods. Most existing supervised deep hashing methods exploit supervisory signals to generate similar and dissimilar image pairs for training. However, natural images can have large intraclass and small interclass variations, which may degrade the accuracy of hash codes. To address this problem, we propose a novel two-stream ConvNet architecture, which learns hash codes with class-specific representation centers. Our basic idea is that if we can learn a unified binary representation for each class as a center and encourage hash codes of images to be close to the corresponding centers, the intraclass variation will be greatly reduced. Accordingly, we design a neural network that leverages label information and outputs a unified binary representation for each class. Moreover, we also design an image network to learn hash codes from images and force these hash codes to be close to the corresponding class-specific centers. These two neural networks are then seamlessly incorporated to create a unified, end-to-end trainable framework. Extensive experiments on three popular benchmarks corroborate that our proposed method outperforms current state-of-the-art methods.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Efficiency And Optimization", "Neural Hashing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-6.197675704956055, 4.3426432609558105], "cluster": 8}, {"key": "depalma2017distributed", "year": "2017", "citations": "52", "title": "Distributed Stratified Locality Sensitive Hashing For Critical Event Prediction In The Cloud", "abstract": "<p>The availability of massive healthcare data repositories calls for efficient\ntools for data-driven medicine. We introduce a distributed system for\nStratified Locality Sensitive Hashing to perform fast similarity-based\nprediction on large medical waveform datasets. Our implementation, for an ICU\nuse case, prioritizes latency over throughput and is targeted at a cloud\nenvironment. We demonstrate our system on Acute Hypotensive Episode prediction\nfrom Arterial Blood Pressure waveforms. On a dataset of \\(1.37\\) million points,\nwe show scaling up to \\(40\\) processors and a \\(21\\times\\) speedup in number of\ncomparisons to parallel exhaustive search at the price of a \\(10%\\) Matthews\ncorrelation coefficient (MCC) loss. Furthermore, if additional MCC loss can be\ntolerated, our system achieves speedups up to two orders of magnitude.</p>\n", "tags": ["CIKM", "Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Alt", "Evaluation"], "tsne_embedding": [-21.204195022583008, 21.2093563079834], "cluster": 3}, {"key": "desai2023heterogeneous", "year": "2023", "citations": "76", "title": "Heterogeneous Federated Collaborative Filtering Using FAIR: Federated Averaging In Random Subspaces", "abstract": "<p>Recommendation systems (RS) for items (e.g., movies, books) and ads are\nwidely used to tailor content to users on various internet platforms.\nTraditionally, recommendation models are trained on a central server. However,\ndue to rising concerns for data privacy and regulations like the GDPR,\nfederated learning is an increasingly popular paradigm in which data never\nleaves the client device. Applying federated learning to recommendation models\nis non-trivial due to large embedding tables, which often exceed the memory\nconstraints of most user devices. To include data from all devices in federated\nlearning, we must enable collective training of embedding tables on devices\nwith heterogeneous memory capacities. Current solutions to heterogeneous\nfederated learning can only accommodate a small range of capacities and thus\nlimit the number of devices that can participate in training. We present\nFederated Averaging in Random subspaces (FAIR), which allows arbitrary\ncompression of embedding tables based on device capacity and ensures the\nparticipation of all devices in training. FAIR uses what we call consistent and\ncollapsible subspaces defined by hashing-based random projections to jointly\ntrain large embedding tables while using varying amounts of compression on user\ndevices. We evaluate FAIR on Neural Collaborative Filtering tasks with multiple\ndatasets and verify that FAIR can gather and share information from a wide\nrange of devices with varying capacities, allowing for seamless collaboration.\nWe prove the convergence of FAIR in the homogeneous setting with non-i.i.d data\ndistribution. Our code is open source at {https://github.com/apd10/FLCF}</p>\n", "tags": ["DATASETS", "IJCAI", "Recommender Systems", "Hashing Methods", "Locality Sensitive Hashing", "AAAI"], "tsne_embedding": [0.04390636086463928, -20.321365356445312], "cluster": 5}, {"key": "ding2018mean", "year": "2018", "citations": "8", "title": "Mean Local Group Average Precision (mlgap): A New Performance Metric For Hashing-based Retrieval", "abstract": "<p>The research on hashing techniques for visual data is gaining increased\nattention in recent years due to the need for compact representations\nsupporting efficient search/retrieval in large-scale databases such as online\nimages. Among many possibilities, Mean Average Precision(mAP) has emerged as\nthe dominant performance metric for hashing-based retrieval. One glaring\nshortcoming of mAP is its inability in balancing retrieval accuracy and\nutilization of hash codes: pushing a system to attain higher mAP will\ninevitably lead to poorer utilization of the hash codes. Poor utilization of\nthe hash codes hinders good retrieval because of increased collision of samples\nin the hash space. This means that a model giving a higher mAP values does not\nnecessarily do a better job in retrieval. In this paper, we introduce a new\nmetric named Mean Local Group Average Precision (mLGAP) for better evaluation\nof the performance of hashing-based retrieval. The new metric provides a\nretrieval performance measure that also reconciles the utilization of hash\ncodes, leading to a more practically meaningful performance metric than\nconventional ones like mAP. To this end, we start by mathematical analysis of\nthe deficiencies of mAP for hashing-based retrieval. We then propose mLGAP and\nshow why it is more appropriate for hashing-based retrieval. Experiments on\nimage retrieval are used to demonstrate the effectiveness of the proposed\nmetric.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Evaluation"], "tsne_embedding": [-8.60749626159668, 10.921662330627441], "cluster": 6}, {"key": "ding2019alex", "year": "2019", "citations": "224", "title": "ALEX: An Updatable Adaptive Learned Index", "abstract": "<p>Recent work on \u201clearned indexes\u201d has changed the way we look at the\ndecades-old field of DBMS indexing. The key idea is that indexes can be thought\nof as \u201cmodels\u201d that predict the position of a key in a dataset. Indexes can,\nthus, be learned. The original work by Kraska et al. shows that a learned index\nbeats a B+Tree by a factor of up to three in search time and by an order of\nmagnitude in memory footprint. However, it is limited to static, read-only\nworkloads.\n  In this paper, we present a new learned index called ALEX which addresses\npractical issues that arise when implementing learned indexes for workloads\nthat contain a mix of point lookups, short range queries, inserts, updates, and\ndeletes. ALEX effectively combines the core insights from learned indexes with\nproven storage and indexing techniques to achieve high performance and low\nmemory footprint. On read-only workloads, ALEX beats the learned index from\nKraska et al. by up to 2.2X on performance with up to 15X smaller index size.\nAcross the spectrum of read-write workloads, ALEX beats B+Trees by up to 4.1X\nwhile never performing worse, with up to 2000X smaller index size. We believe\nALEX presents a key step towards making learned indexes practical for a broader\nclass of database workloads with dynamic updates.</p>\n", "tags": ["DATASETS", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [-10.05763053894043, -11.344559669494629], "cluster": 1}, {"key": "ding2019bilinear", "year": "2019", "citations": "14", "title": "Bilinear Supervised Hashing Based On 2D Image Features", "abstract": "<p>Hashing has been recognized as an efficient representation learning method to\neffectively handle big data due to its low computational complexity and memory\ncost. Most of the existing hashing methods focus on learning the\nlow-dimensional vectorized binary features based on the high-dimensional raw\nvectorized features. However, studies on how to obtain preferable binary codes\nfrom the original 2D image features for retrieval is very limited. This paper\nproposes a bilinear supervised discrete hashing (BSDH) method based on 2D image\nfeatures which utilizes bilinear projections to binarize the image matrix\nfeatures such that the intrinsic characteristics in the 2D image space are\npreserved in the learned binary codes. Meanwhile, the bilinear projection\napproximation and vectorization binary codes regression are seamlessly\nintegrated together to formulate the final robust learning framework.\nFurthermore, a discrete optimization strategy is developed to alternatively\nupdate each variable for obtaining the high-quality binary codes. In addition,\ntwo 2D image features, traditional SURF-based FVLAD feature and CNN-based\nAlexConv5 feature are designed for further improving the performance of the\nproposed BSDH method. Results of extensive experiments conducted on four\nbenchmark datasets show that the proposed BSDH method almost outperforms all\ncompeting hashing methods with different input features by different evaluation\nprotocols.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Compact Codes", "Alt", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-5.339221954345703, -8.146883010864258], "cluster": 9}, {"key": "ding2025collective", "year": "2025", "citations": "638", "title": "Collective Matrix Factorization Hashing For Multimodal Data", "abstract": "<p>Nearest neighbor search methods based on hashing have\nattracted considerable attention for effective and efficient\nlarge-scale similarity search in computer vision and information\nretrieval community. In this paper, we study the\nproblems of learning hash functions in the context of multimodal\ndata for cross-view similarity search. We put forward\na novel hashing method, which is referred to Collective\nMatrix Factorization Hashing (CMFH). CMFH learns unified\nhash codes by collective matrix factorization with latent\nfactor model from different modalities of one instance,\nwhich can not only supports cross-view search but also increases\nthe search accuracy by merging multiple view information\nsources. We also prove that CMFH, a similaritypreserving\nhashing learning method, has upper and lower\nboundaries. Extensive experiments verify that CMFH significantly\noutperforms several state-of-the-art methods on\nthree different datasets.</p>\n", "tags": ["CVPR", "DATASETS", "Similarity Search", "Hashing Methods"], "tsne_embedding": [6.323530673980713, 2.877497911453247], "cluster": 4}, {"key": "ding2025knn", "year": "2025", "citations": "14", "title": "Knn Hashing With Factorized Neighborhood Representation", "abstract": "<p>Hashing is very effective for many tasks in reducing the\nprocessing time and in compressing massive databases. Although lots of approaches have been developed to learn\ndata-dependent hash functions in recent years, how to learn\nhash functions to yield good performance with acceptable\ncomputational and memory cost is still a challenging problem. Based on the observation that retrieval precision is\nhighly related to the kNN classification accuracy, this paper\nproposes a novel kNN-based supervised hashing method,\nwhich learns hash functions by directly maximizing the kNN\naccuracy of the Hamming-embedded training data. To make\nit scalable well to large problem, we propose a factorized\nneighborhood representation to parsimoniously model the\nneighborhood relationships inherent in training data. Considering that real-world data are often linearly inseparable,\nwe further kernelize this basic model to improve its performance. As a result, the proposed method is able to learn\naccurate hashing functions with tolerable computation and\nstorage cost. Experiments on four benchmarks demonstrate\nthat our method outperforms the state-of-the-arts.</p>\n", "tags": ["Hashing Methods", "Efficiency And Optimization", "Alt", "ICCV", "Evaluation"], "tsne_embedding": [-3.1590511798858643, -12.567158699035645], "cluster": 9}, {"key": "dirksen2016fast", "year": "2016", "citations": "13", "title": "Fast Binary Embeddings With Gaussian Circulant Matrices: Improved Bounds", "abstract": "<p>We consider the problem of encoding a finite set of vectors into a small\nnumber of bits while approximately retaining information on the angular\ndistances between the vectors. By deriving improved variance bounds related to\nbinary Gaussian circulant embeddings, we largely fix a gap in the proof of the\nbest known fast binary embedding method. Our bounds also show that\nwell-spreadness assumptions on the data vectors, which were needed in earlier\nwork on variance bounds, are unnecessary. In addition, we propose a new binary\nembedding with a faster running time on sparse data.</p>\n", "tags": ["Hashing Methods"], "tsne_embedding": [23.927743911743164, -8.078786849975586], "cluster": 7}, {"key": "dirksen2020binarized", "year": "2020", "citations": "7", "title": "Binarized Johnson-lindenstrauss Embeddings", "abstract": "<p>We consider the problem of encoding a set of vectors into a minimal number of\nbits while preserving information on their Euclidean geometry. We show that\nthis task can be accomplished by applying a Johnson-Lindenstrauss embedding and\nsubsequently binarizing each vector by comparing each entry of the vector to a\nuniformly random threshold. Using this simple construction we produce two\nencodings of a dataset such that one can query Euclidean information for a pair\nof points using a small number of bit operations up to a desired additive error</p>\n<ul>\n  <li>Euclidean distances in the first case and inner products and squared\nEuclidean distances in the second. In the latter case, each point is encoded in\nnear-linear time. The number of bits required for these encodings is quantified\nin terms of two natural complexity parameters of the dataset - its covering\nnumbers and localized Gaussian complexity - and shown to be near-optimal.</li>\n</ul>\n", "tags": ["DATASETS", "Distance Metric Learning"], "tsne_embedding": [24.284454345703125, -6.737759113311768], "cluster": 7}, {"key": "do2016binary", "year": "2016", "citations": "20", "title": "Binary Hashing With Semidefinite Relaxation And Augmented Lagrangian", "abstract": "<p>This paper proposes two approaches for inferencing binary codes in two-step\n(supervised, unsupervised) hashing. We first introduce an unified formulation\nfor both supervised and unsupervised hashing. Then, we cast the learning of one\nbit as a Binary Quadratic Problem (BQP). We propose two approaches to solve\nBQP. In the first approach, we relax BQP as a semidefinite programming problem\nwhich its global optimum can be achieved. We theoretically prove that the\nobjective value of the binary solution achieved by this approach is well\nbounded. In the second approach, we propose an augmented Lagrangian based\napproach to solve BQP directly without relaxing the binary constraint.\nExperimental results on three benchmark datasets show that our proposed methods\ncompare favorably with the state of the art.</p>\n", "tags": ["Compact Codes", "DATASETS", "Hashing Methods", "Evaluation"], "tsne_embedding": [-4.468029022216797, -16.624099731445312], "cluster": 5}, {"key": "do2016embedding", "year": "2016", "citations": "37", "title": "Embedding Based On Function Approximation For Large Scale Image Search", "abstract": "<p>The objective of this paper is to design an embedding method that maps local\nfeatures describing an image (e.g. SIFT) to a higher dimensional representation\nuseful for the image retrieval problem. First, motivated by the relationship\nbetween the linear approximation of a nonlinear function in high dimensional\nspace and the stateof-the-art feature representation used in image retrieval,\ni.e., VLAD, we propose a new approach for the approximation. The embedded\nvectors resulted by the function approximation process are then aggregated to\nform a single representation for image retrieval. Second, in order to make the\nproposed embedding method applicable to large scale problem, we further derive\nits fast version in which the embedded vectors can be efficiently computed,\ni.e., in the closed-form. We compare the proposed embedding methods with the\nstate of the art in the context of image search under various settings: when\nthe images are represented by medium length vectors, short vectors, or binary\nvectors. The experimental results show that the proposed embedding methods\noutperform existing the state of the art on the standard public image retrieval\nbenchmarks.</p>\n", "tags": ["Image Retrieval", "Evaluation"], "tsne_embedding": [-10.783039093017578, 12.302477836608887], "cluster": 6}, {"key": "do2016learning", "year": "2016", "citations": "168", "title": "Learning To Hash With Binary Deep Neural Network", "abstract": "<p>This work proposes deep network models and learning algorithms for\nunsupervised and supervised binary hashing. Our novel network design constrains\none hidden layer to directly output the binary codes. This addresses a\nchallenging issue in some previous works: optimizing non-smooth objective\nfunctions due to binarization. Moreover, we incorporate independence and\nbalance properties in the direct and strict forms in the learning. Furthermore,\nwe include similarity preserving property in our objective function. Our\nresulting optimization with these binary, independence, and balance constraints\nis difficult to solve. We propose to attack it with alternating optimization\nand careful relaxation. Experimental results on three benchmark datasets show\nthat our proposed methods compare favorably with the state of the art.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Compact Codes", "Alt", "Evaluation"], "tsne_embedding": [-4.0768256187438965, -15.868852615356445], "cluster": 9}, {"key": "do2017compact", "year": "2017", "citations": "23", "title": "Compact Hash Code Learning With Binary Deep Neural Network", "abstract": "<p>Learning compact binary codes for image retrieval problem using deep neural\nnetworks has recently attracted increasing attention. However, training deep\nhashing networks is challenging due to the binary constraints on the hash\ncodes. In this paper, we propose deep network models and learning algorithms\nfor learning binary hash codes given image representations under both\nunsupervised and supervised manners. The novelty of our network design is that\nwe constrain one hidden layer to directly output the binary codes. This design\nhas overcome a challenging problem in some previous works: optimizing\nnon-smooth objective functions because of binarization. In addition, we propose\nto incorporate independence and balance properties in the direct and strict\nforms into the learning schemes. We also include a similarity preserving\nproperty in our objective functions. The resulting optimizations involving\nthese binary, independence, and balance constraints are difficult to solve. To\ntackle this difficulty, we propose to learn the networks with alternating\noptimization and careful relaxation. Furthermore, by leveraging the powerful\ncapacity of convolutional neural networks, we propose an end-to-end\narchitecture that jointly learns to extract visual features and produce binary\nhash codes. Experimental results for the benchmark datasets show that the\nproposed methods compare favorably or outperform the state of the art.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Compact Codes", "Alt", "Evaluation"], "tsne_embedding": [-10.269248008728027, -5.798532962799072], "cluster": 1}, {"key": "do2017simultaneous", "year": "2017", "citations": "38", "title": "Simultaneous Feature Aggregating And Hashing For Large-scale Image Search", "abstract": "<p>In most state-of-the-art hashing-based visual search systems, local image\ndescriptors of an image are first aggregated as a single feature vector. This\nfeature vector is then subjected to a hashing function that produces a binary\nhash code. In previous work, the aggregating and the hashing processes are\ndesigned independently. In this paper, we propose a novel framework where\nfeature aggregating and hashing are designed simultaneously and optimized\njointly. Specifically, our joint optimization produces aggregated\nrepresentations that can be better reconstructed by some binary codes. This\nleads to more discriminative binary hash codes and improved retrieval accuracy.\nIn addition, we also propose a fast version of the recently-proposed Binary\nAutoencoder to be used in our proposed framework. We perform extensive\nretrieval experiments on several benchmark datasets with both SIFT and\nconvolutional features. Our results suggest that the proposed framework\nachieves significant improvements over the state of the art.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "CVPR", "Compact Codes", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-4.441822528839111, 7.969493389129639], "cluster": 8}, {"key": "do2018binary", "year": "2018", "citations": "9", "title": "Binary Constrained Deep Hashing Network For Image Retrieval Without Manual Annotation", "abstract": "<p>Learning compact binary codes for image retrieval task using deep neural\nnetworks has attracted increasing attention recently. However, training deep\nhashing networks for the task is challenging due to the binary constraints on\nthe hash codes, the similarity preserving property, and the requirement for a\nvast amount of labelled images. To the best of our knowledge, none of the\nexisting methods has tackled all of these challenges completely in a unified\nframework. In this work, we propose a novel end-to-end deep learning approach\nfor the task, in which the network is trained to produce binary codes directly\nfrom image pixels without the need of manual annotation. In particular, to deal\nwith the non-smoothness of binary constraints, we propose a novel pairwise\nconstrained loss function, which simultaneously encodes the distances between\npairs of hash codes, and the binary quantization error. In order to train the\nnetwork with the proposed loss function, we propose an efficient parameter\nlearning algorithm. In addition, to provide similar / dissimilar training\nimages to train the network, we exploit 3D models reconstructed from unlabelled\nimages for automatic generation of enormous training image pairs. The extensive\nexperiments on image retrieval benchmark datasets demonstrate the improvements\nof the proposed method over the state-of-the-art compact representation methods\non the image retrieval problem.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Compact Codes", "Neural Hashing", "Quantization", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-10.63491153717041, -5.757617950439453], "cluster": 1}, {"key": "do2018selective", "year": "2018", "citations": "30", "title": "From Selective Deep Convolutional Features To Compact Binary Representations For Image Retrieval", "abstract": "<p>In the large-scale image retrieval task, the two most important requirements\nare the discriminability of image representations and the efficiency in\ncomputation and storage of representations. Regarding the former requirement,\nConvolutional Neural Network (CNN) is proven to be a very powerful tool to\nextract highly discriminative local descriptors for effective image search.\nAdditionally, in order to further improve the discriminative power of the\ndescriptors, recent works adopt fine-tuned strategies. In this paper, taking a\ndifferent approach, we propose a novel, computationally efficient, and\ncompetitive framework. Specifically, we firstly propose various strategies to\ncompute masks, namely SIFT-mask, SUM-mask, and MAX-mask, to select a\nrepresentative subset of local convolutional features and eliminate redundant\nfeatures. Our in-depth analyses demonstrate that proposed masking schemes are\neffective to address the burstiness drawback and improve retrieval accuracy.\nSecondly, we propose to employ recent embedding and aggregating methods which\ncan significantly boost the feature discriminability. Regarding the computation\nand storage efficiency, we include a hashing module to produce very compact\nbinary image representations. Extensive experiments on six image retrieval\nbenchmarks demonstrate that our proposed framework achieves the\nstate-of-the-art retrieval performances.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Efficiency And Optimization", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-11.412834167480469, 11.311179161071777], "cluster": 3}, {"key": "do2019simultaneous", "year": "2019", "citations": "14", "title": "Simultaneous Feature Aggregating And Hashing For Compact Binary Code Learning", "abstract": "<p>Representing images by compact hash codes is an attractive approach for\nlarge-scale content-based image retrieval. In most state-of-the-art\nhashing-based image retrieval systems, for each image, local descriptors are\nfirst aggregated as a global representation vector. This global vector is then\nsubjected to a hashing function to generate a binary hash code. In previous\nworks, the aggregating and the hashing processes are designed independently.\nHence these frameworks may generate suboptimal hash codes. In this paper, we\nfirst propose a novel unsupervised hashing framework in which feature\naggregating and hashing are designed simultaneously and optimized jointly.\nSpecifically, our joint optimization generates aggregated representations that\ncan be better reconstructed by some binary codes. This leads to more\ndiscriminative binary hash codes and improved retrieval accuracy. In addition,\nthe proposed method is flexible. It can be extended for supervised hashing.\nWhen the data label is available, the framework can be adapted to learn binary\ncodes which minimize the reconstruction loss w.r.t. label vectors. Furthermore,\nwe also propose a fast version of the state-of-the-art hashing method Binary\nAutoencoder to be used in our proposed frameworks. Extensive experiments on\nbenchmark datasets under various settings show that the proposed methods\noutperform state-of-the-art unsupervised and supervised hashing methods.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Compact Codes", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-4.533169269561768, 7.922077655792236], "cluster": 8}, {"key": "doan2022coophash", "year": "2022", "citations": "397", "title": "Coophash: Cooperative Learning Of Multipurpose Descriptor And Contrastive Pair Generator Via Variational MCMC Teaching For Supervised Image Hashing", "abstract": "<p>Leveraging supervised information can lead to superior retrieval performance\nin the image hashing domain but the performance degrades significantly without\nenough labeled data. One effective solution to boost performance is to employ\ngenerative models, such as Generative Adversarial Networks (GANs), to generate\nsynthetic data in an image hashing model. However, GAN-based methods are\ndifficult to train, which prevents the hashing approaches from jointly training\nthe generative models and the hash functions. This limitation results in\nsub-optimal retrieval performance. To overcome this limitation, we propose a\nnovel framework, the generative cooperative hashing network, which is based on\nenergy-based cooperative learning. This framework jointly learns a powerful\ngenerative representation of the data and a robust hash function via two\ncomponents: a top-down contrastive pair generator that synthesizes contrastive\nimages and a bottom-up multipurpose descriptor that simultaneously represents\nthe images from multiple perspectives, including probability density, hash\ncode, latent code, and category. The two components are jointly learned via a\nnovel likelihood-based cooperative learning scheme. We conduct experiments on\nseveral real-world datasets and show that the proposed method outperforms the\ncompeting hashing supervised methods, achieving up to 10% relative improvement\nover the current state-of-the-art supervised hashing methods, and exhibits a\nsignificantly better performance in out-of-distribution retrieval.</p>\n", "tags": ["Image Retrieval", "AAAI", "DATASETS", "Hashing Methods", "Tools & Libraries", "Evaluation", "Robustness"], "tsne_embedding": [-11.641907691955566, -1.312516450881958], "cluster": 8}, {"key": "doan2022one", "year": "2022", "citations": "37", "title": "One Loss For Quantization: Deep Hashing With Discrete Wasserstein Distributional Matching", "abstract": "<p>Image hashing is a principled approximate nearest neighbor approach to find\nsimilar items to a query in a large collection of images. Hashing aims to learn\na binary-output function that maps an image to a binary vector. For optimal\nretrieval performance, producing balanced hash codes with low-quantization\nerror to bridge the gap between the learning stage\u2019s continuous relaxation and\nthe inference stage\u2019s discrete quantization is important. However, in the\nexisting deep supervised hashing methods, coding balance and low-quantization\nerror are difficult to achieve and involve several losses. We argue that this\nis because the existing quantization approaches in these methods are\nheuristically constructed and not effective to achieve these objectives. This\npaper considers an alternative approach to learning the quantization\nconstraints. The task of learning balanced codes with low quantization error is\nre-formulated as matching the learned distribution of the continuous codes to a\npre-defined discrete, uniform distribution. This is equivalent to minimizing\nthe distance between two distributions. We then propose a computationally\nefficient distributional distance by leveraging the discrete property of the\nhash functions. This distributional distance is a valid distance and enjoys\nlower time and sample complexities. The proposed single-loss quantization\nobjective can be integrated into any existing supervised hashing method to\nimprove code balance and quantization error. Experiments confirm that the\nproposed approach substantially improves the performance of several\nrepresentative hashing~methods.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "CVPR", "Alt", "Neural Hashing", "Quantization", "Evaluation"], "tsne_embedding": [-2.456695318222046, 5.6606597900390625], "cluster": 8}, {"key": "dolhansky2020adversarial", "year": "2020", "citations": "9", "title": "Adversarial Collision Attacks On Image Hashing Functions", "abstract": "<p>Hashing images with a perceptual algorithm is a common approach to solving\nduplicate image detection problems. However, perceptual image hashing\nalgorithms are differentiable, and are thus vulnerable to gradient-based\nadversarial attacks. We demonstrate that not only is it possible to modify an\nimage to produce an unrelated hash, but an exact image hash collision between a\nsource and target image can be produced via minuscule adversarial\nperturbations. In a white box setting, these collisions can be replicated\nacross nearly every image pair and hash type (including both deep and\nnon-learned hashes). Furthermore, by attacking points other than the output of\na hashing function, an attacker can avoid having to know the details of a\nparticular algorithm, resulting in collisions that transfer across different\nhash sizes or model architectures. Using these techniques, an adversary can\npoison the image lookup table of a duplicate image detection service, resulting\nin undefined or unwanted behavior. Finally, we offer several potential\nmitigations to gradient-based image hash attacks.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Robustness"], "tsne_embedding": [-13.502982139587402, 15.789960861206055], "cluster": 6}, {"key": "dong2017video", "year": "2017", "citations": "17", "title": "Video Retrieval Based On Deep Convolutional Neural Network", "abstract": "<p>Recently, with the enormous growth of online videos, fast video retrieval\nresearch has received increasing attention. As an extension of image hashing\ntechniques, traditional video hashing methods mainly depend on hand-crafted\nfeatures and transform the real-valued features into binary hash codes. As\nvideos provide far more diverse and complex visual information than images,\nextracting features from videos is much more challenging than that from images.\nTherefore, high-level semantic features to represent videos are needed rather\nthan low-level hand-crafted methods. In this paper, a deep convolutional neural\nnetwork is proposed to extract high-level semantic features and a binary hash\nfunction is then integrated into this framework to achieve an end-to-end\noptimization. Particularly, our approach also combines triplet loss function\nwhich preserves the relative similarity and difference of videos and\nclassification loss function as the optimization objective. Experiments have\nbeen performed on two public datasets and the results demonstrate the\nsuperiority of our proposed method compared with other state-of-the-art video\nretrieval methods.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Distance Metric Learning", "Tools & Libraries"], "tsne_embedding": [-6.410464286804199, 21.80274772644043], "cluster": 6}, {"key": "dong2019document", "year": "2019", "citations": "19", "title": "Document Hashing With Mixture-prior Generative Models", "abstract": "<p>Hashing is promising for large-scale information retrieval tasks thanks to\nthe efficiency of distance evaluation between binary codes. Generative hashing\nis often used to generate hashing codes in an unsupervised way. However,\nexisting generative hashing methods only considered the use of simple priors,\nlike Gaussian and Bernoulli priors, which limits these methods to further\nimprove their performance. In this paper, two mixture-prior generative models\nare proposed, under the objective to produce high-quality hashing codes for\ndocuments. Specifically, a Gaussian mixture prior is first imposed onto the\nvariational auto-encoder (VAE), followed by a separate step to cast the\ncontinuous latent representation of VAE into binary code. To avoid the\nperformance loss caused by the separate casting, a model using a Bernoulli\nmixture prior is further developed, in which an end-to-end training is admitted\nby resorting to the straight-through (ST) discrete gradient estimator.\nExperimental results on several benchmark datasets demonstrate that the\nproposed methods, especially the one using Bernoulli mixture priors,\nconsistently outperform existing ones by a substantial margin.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "Compact Codes", "EMNLP", "Evaluation"], "tsne_embedding": [-1.0865744352340698, 5.405327320098877], "cluster": 8}, {"key": "dong2019learning", "year": "2019", "citations": "26", "title": "Learning Space Partitions For Nearest Neighbor Search", "abstract": "<p>Space partitions of \\(\\mathbb{R}^d\\) underlie a vast and important class of\nfast nearest neighbor search (NNS) algorithms. Inspired by recent theoretical\nwork on NNS for general metric spaces [Andoni, Naor, Nikolov, Razenshteyn,\nWaingarten STOC 2018, FOCS 2018], we develop a new framework for building space\npartitions reducing the problem to balanced graph partitioning followed by\nsupervised classification. We instantiate this general approach with the KaHIP\ngraph partitioner [Sanders, Schulz SEA 2013] and neural networks, respectively,\nto obtain a new partitioning procedure called Neural Locality-Sensitive Hashing\n(Neural LSH). On several standard benchmarks for NNS, our experiments show that\nthe partitions obtained by Neural LSH consistently outperform partitions found\nby quantization-based and tree-based methods as well as classic, data-oblivious\nLSH.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Quantization", "Tree Based ANN", "Tools & Libraries", "Evaluation"], "tsne_embedding": [17.456981658935547, 8.272339820861816], "cluster": 0}, {"key": "dong2023seine", "year": "2023", "citations": "13", "title": "SEINE: Segment-based Indexing For Neural Information Retrieval", "abstract": "<p>Many early neural Information Retrieval (NeurIR) methods are re-rankers that\nrely on a traditional first-stage retriever due to expensive query time\ncomputations. Recently, representation-based retrievers have gained much\nattention, which learns query representation and document representation\nseparately, making it possible to pre-compute document representations offline\nand reduce the workload at query time. Both dense and sparse\nrepresentation-based retrievers have been explored. However, these methods\nfocus on finding the representation that best represents a text (aka metric\nlearning) and the actual retrieval function that is responsible for similarity\nmatching between query and document is kept at a minimum by using dot product.\nOne drawback is that unlike traditional term-level inverted index, the index\nformed by these embeddings cannot be easily re-used by another retrieval\nmethod. Another drawback is that keeping the interaction at minimum hurts\nretrieval effectiveness. On the contrary, interaction-based retrievers are\nknown for their better retrieval effectiveness. In this paper, we propose a\nnovel SEgment-based Neural Indexing method, SEINE, which provides a general\nindexing framework that can flexibly support a variety of interaction-based\nneural retrieval methods. We emphasize on a careful decomposition of common\ncomponents in existing neural retrieval methods and propose to use\nsegment-level inverted index to store the atomic query-document interaction\nvalues. Experiments on LETOR MQ2007 and MQ2008 datasets show that our indexing\nmethod can accelerate multiple neural retrieval methods up to 28-times faster\nwithout sacrificing much effectiveness.</p>\n", "tags": ["DATASETS", "Tools & Libraries", "Efficiency And Optimization"], "tsne_embedding": [3.212972640991211, 0.10127677023410797], "cluster": 4}, {"key": "dou2020learning", "year": "2020", "citations": "7", "title": "Learning Global And Local Consistent Representations For Unsupervised Image Retrieval Via Deep Graph Diffusion Networks", "abstract": "<p>Diffusion has shown great success in improving accuracy of unsupervised image\nretrieval systems by utilizing high-order structures of image manifold.\nHowever, existing diffusion methods suffer from three major limitations: 1)\nthey usually rely on local structures without considering global manifold\ninformation; 2) they focus on improving pair-wise similarities within existing\nimages input output transductively while lacking flexibility to learn\nrepresentations for novel unseen instances inductively; 3) they fail to scale\nto large datasets due to prohibitive memory consumption and computational\nburden due to intrinsic high-order operations on the whole graph. In this\npaper, to address these limitations, we propose a novel method, Graph Diffusion\nNetworks (GRAD-Net), that adopts graph neural networks (GNNs), a novel variant\nof deep learning algorithms on irregular graphs. GRAD-Net learns semantic\nrepresentations by exploiting both local and global structures of image\nmanifold in an unsupervised fashion. By utilizing sparse coding techniques,\nGRAD-Net not only preserves global information on the image manifold, but also\nenables scalable training and efficient querying. Experiments on several large\nbenchmark datasets demonstrate effectiveness of our method over\nstate-of-the-art diffusion algorithms for unsupervised image retrieval.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Evaluation"], "tsne_embedding": [16.948305130004883, 14.907417297363281], "cluster": 0}, {"key": "dourado2019fusion", "year": "2019", "citations": "13", "title": "Fusion Vectors: Embedding Graph Fusions For Efficient Unsupervised Rank Aggregation", "abstract": "<p>The vast increase in amount and complexity of digital content led to a wide\ninterest in ad-hoc retrieval systems in recent years. Complementary, the\nexistence of heterogeneous data sources and retrieval models stimulated the\nproliferation of increasingly ingenious and effective rank aggregation\nfunctions. Although recently proposed rank aggregation functions are promising\nwith respect to effectiveness, existing proposals in the area usually overlook\nefficiency aspects. We propose an innovative rank aggregation function that is\nunsupervised, intrinsically multimodal, and targeted for fast retrieval and top\neffectiveness performance. We introduce the concepts of embedding and indexing\nof graph-based rank-aggregation representation models, and their application\nfor search tasks. Embedding formulations are also proposed for graph-based rank\nrepresentations. We introduce the concept of fusion vectors, a late-fusion\nrepresentation of objects based on ranks, from which an intrinsically\nrank-aggregation retrieval model is defined. Next, we present an approach for\nfast retrieval based on fusion vectors, thus promoting an efficient rank\naggregation system. Our method presents top effectiveness performance among\nstate-of-the-art related work, while bringing novel aspects of multimodality\nand effectiveness. Consistent speedups are achieved against the recent\nbaselines in all datasets considered.</p>\n", "tags": ["DATASETS", "Graph Based ANN", "Efficiency And Optimization", "Alt", "Evaluation"], "tsne_embedding": [18.11434555053711, 17.147998809814453], "cluster": 0}, {"key": "douze2016polysemous", "year": "2016", "citations": "45", "title": "Polysemous Codes", "abstract": "<p>This paper considers the problem of approximate nearest neighbor search in\nthe compressed domain. We introduce polysemous codes, which offer both the\ndistance estimation quality of product quantization and the efficient\ncomparison of binary codes with Hamming distance. Their design is inspired by\nalgorithms introduced in the 90\u2019s to construct channel-optimized vector\nquantizers. At search time, this dual interpretation accelerates the search.\nMost of the indexed vectors are filtered out with Hamming distance, letting\nonly a fraction of the vectors to be ranked with an asymmetric distance\nestimator.\n  The method is complementary with a coarse partitioning of the feature space\nsuch as the inverted multi-index. This is shown by our experiments performed on\nseveral public benchmarks such as the BIGANN dataset comprising one billion\nvectors, for which we report state-of-the-art results for query times below\n0.3\\,millisecond per core. Last but not least, our approach allows the\napproximate computation of the k-NN graph associated with the Yahoo Flickr\nCreative Commons 100M, described by CNN image descriptors, in less than 8 hours\non a single machine.</p>\n", "tags": ["DATASETS", "Efficiency And Optimization", "Compact Codes", "Quantization", "Vector Indexing", "Evaluation"], "tsne_embedding": [8.97734260559082, -3.6268393993377686], "cluster": 4}, {"key": "douze2018link", "year": "2018", "citations": "31", "title": "Link And Code: Fast Indexing With Graphs And Compact Regression Codes", "abstract": "<p>Similarity search approaches based on graph walks have recently attained\noutstanding speed-accuracy trade-offs, taking aside the memory requirements. In\nthis paper, we revisit these approaches by considering, additionally, the\nmemory constraint required to index billions of images on a single server. This\nleads us to propose a method based both on graph traversal and compact\nrepresentations. We encode the indexed vectors using quantization and exploit\nthe graph structure to refine the similarity estimation.\n  In essence, our method takes the best of these two worlds: the search\nstrategy is based on nested graphs, thereby providing high precision with a\nrelatively small set of comparisons. At the same time it offers a significant\nmemory compression. As a result, our approach outperforms the state of the art\non operating points considering 64-128 bytes per vector, as demonstrated by our\nresults on two billion-scale public benchmarks.</p>\n", "tags": ["CVPR", "Large Scale Search", "Similarity Search", "Quantization", "Evaluation"], "tsne_embedding": [19.45547866821289, 12.229926109313965], "cluster": 0}, {"key": "douze2024faiss", "year": "2024", "citations": "17", "title": "The Faiss Library", "abstract": "<p>Vector databases typically manage large collections of embedding vectors.\nCurrently, AI applications are growing rapidly, and so is the number of\nembeddings that need to be stored and indexed. The Faiss library is dedicated\nto vector similarity search, a core functionality of vector databases. Faiss is\na toolkit of indexing methods and related primitives used to search, cluster,\ncompress and transform vectors. This paper describes the trade-off space of\nvector search and the design principles of Faiss in terms of structure,\napproach to optimization and interfacing. We benchmark key features of the\nlibrary and discuss a few selected applications to highlight its broad\napplicability.</p>\n", "tags": ["Similarity Search", "Tools & Libraries", "Evaluation"], "tsne_embedding": [5.048696041107178, 9.058952331542969], "cluster": 4}, {"key": "driemel2017locality", "year": "2017", "citations": "31", "title": "Locality-sensitive Hashing Of Curves", "abstract": "<p>We study data structures for storing a set of polygonal curves in \\({\\rm R}^d\\)\nsuch that, given a query curve, we can efficiently retrieve similar curves from\nthe set, where similarity is measured using the discrete Fr'echet distance or\nthe dynamic time warping distance. To this end we devise the first\nlocality-sensitive hashing schemes for these distance measures. A major\nchallenge is posed by the fact that these distance measures internally optimize\nthe alignment between the curves. We give solutions for different types of\nalignments including constrained and unconstrained versions. For unconstrained\nalignments, we improve over a result by Indyk from 2002 for short curves. Let\n\\(n\\) be the number of input curves and let \\(m\\) be the maximum complexity of a\ncurve in the input. In the particular case where \\(m \\leq \\frac{\\alpha}{4d} log\nn\\), for some fixed \\(\\alpha&gt;0\\), our solutions imply an approximate near-neighbor\ndata structure for the discrete Fr'echet distance that uses space in\n\\(O(n^{1+\\alpha}log n)\\) and achieves query time in \\(O(n^{\\alpha}log^2 n)\\) and\nconstant approximation factor. Furthermore, our solutions provide a trade-off\nbetween approximation quality and computational performance: for any parameter\n\\(k \\in [m]\\), we can give a data structure that uses space in \\(O(2^{2k}m^{k-1} n\nlog n + nm)\\), answers queries in \\(O( 2^{2k} m^{k}log n)\\) time and achieves\napproximation factor in \\(O(m/k)\\).</p>\n", "tags": ["Graph Based ANN", "Hashing Methods", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [29.376325607299805, 1.4411346912384033], "cluster": 7}, {"key": "duan2020slade", "year": "2020", "citations": "8", "title": "SLADE: A Self-training Framework For Distance Metric Learning", "abstract": "<p>Most existing distance metric learning approaches use fully labeled data to\nlearn the sample similarities in an embedding space. We present a self-training\nframework, SLADE, to improve retrieval performance by leveraging additional\nunlabeled data. We first train a teacher model on the labeled data and use it\nto generate pseudo labels for the unlabeled data. We then train a student model\non both labels and pseudo labels to generate final feature embeddings. We use\nself-supervised representation learning to initialize the teacher model. To\nbetter deal with noisy pseudo labels generated by the teacher network, we\ndesign a new feature basis learning component for the student network, which\nlearns basis functions of feature representations for unlabeled data. The\nlearned basis vectors better measure the pairwise similarity and are used to\nselect high-confident samples for training the student network. We evaluate our\nmethod on standard retrieval benchmarks: CUB-200, Cars-196 and In-shop.\nExperimental results demonstrate that our approach significantly improves the\nperformance over the state-of-the-art methods.</p>\n", "tags": ["CVPR", "Tools & Libraries", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [-23.843589782714844, -5.386924743652344], "cluster": 1}, {"key": "duan2025enhancing", "year": "2025", "citations": "71", "title": "Enhancing Subsequent Video Retrieval Via Vision-language Models (vlms)", "abstract": "<p>The rapid growth of video content demands efficient and precise retrieval\nsystems. While vision-language models (VLMs) excel in representation learning,\nthey often struggle with adaptive, time-sensitive video retrieval. This paper\nintroduces a novel framework that combines vector similarity search with\ngraph-based data structures. By leveraging VLM embeddings for initial retrieval\nand modeling contextual relationships among video segments, our approach\nenables adaptive query refinement and improves retrieval accuracy. Experiments\ndemonstrate its precision, scalability, and robustness, offering an effective\nsolution for interactive video retrieval in dynamic environments.</p>\n", "tags": ["Graph Based ANN", "CVPR", "Similarity Search", "Tools & Libraries", "Evaluation", "Robustness"], "tsne_embedding": [-6.609645843505859, 21.092153549194336], "cluster": 6}, {"key": "dubey2021vision", "year": "2021", "citations": "47", "title": "Vision Transformer Hashing For Image Retrieval", "abstract": "<p>Deep learning has shown a tremendous growth in hashing techniques for image\nretrieval. Recently, Transformer has emerged as a new architecture by utilizing\nself-attention without convolution. Transformer is also extended to Vision\nTransformer (ViT) for the visual recognition with a promising performance on\nImageNet. In this paper, we propose a Vision Transformer based Hashing (VTS)\nfor image retrieval. We utilize the pre-trained ViT on ImageNet as the backbone\nnetwork and add the hashing head. The proposed VTS model is fine tuned for\nhashing under six different image retrieval frameworks, including Deep\nSupervised Hashing (DSH), HashNet, GreedyHash, Improved Deep Hashing Network\n(IDHN), Deep Polarized Network (DPN) and Central Similarity Quantization (CSQ)\nwith their objective functions. We perform the extensive experiments on\nCIFAR10, ImageNet, NUS-Wide, and COCO datasets. The proposed VTS based image\nretrieval outperforms the recent state-of-the-art hashing techniques with a\ngreat margin. We also find the proposed VTS model as the backbone network is\nbetter than the existing networks, such as AlexNet and ResNet. The code is\nreleased at https://github.com/shivram1987/VisionTransformerHashing.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Neural Hashing", "Quantization", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-15.201681137084961, -3.330782413482666], "cluster": 1}, {"key": "ducau2019automatic", "year": "2019", "citations": "11", "title": "Automatic Malware Description Via Attribute Tagging And Similarity Embedding", "abstract": "<p>With the rapid proliferation and increased sophistication of malicious\nsoftware (malware), detection methods no longer rely only on manually generated\nsignatures but have also incorporated more general approaches like machine\nlearning detection. Although powerful for conviction of malicious artifacts,\nthese methods do not produce any further information about the type of threat\nthat has been detected neither allows for identifying relationships between\nmalware samples. In this work, we address the information gap between machine\nlearning and signature-based detection methods by learning a representation\nspace for malware samples in which files with similar malicious behaviors\nappear close to each other. We do so by introducing a deep learning based\ntagging model trained to generate human-interpretable semantic descriptions of\nmalicious software, which, at the same time provides potentially more useful\nand flexible information than malware family names.\n  We show that the malware descriptions generated with the proposed approach\ncorrectly identify more than 95% of eleven possible tag descriptions for a\ngiven sample, at a deployable false positive rate of 1% per tag. Furthermore,\nwe use the learned representation space to introduce a similarity index between\nmalware files, and empirically demonstrate using dynamic traces from files\u2019\nexecution, that is not only more effective at identifying samples from the same\nfamilies, but also 32 times smaller than those based on raw feature vectors.</p>\n", "tags": ["Alt", "Tools & Libraries"], "tsne_embedding": [-13.185575485229492, -7.43747615814209], "cluster": 1}, {"key": "duda2012optimal", "year": "2012", "citations": "9", "title": "Optimal Compression Of Hash-origin Prefix Trees", "abstract": "<p>There is a common problem of operating on hash values of elements of some\ndatabase. In this paper there will be analyzed informational content of such\ngeneral task and how to practically approach such found lower boundaries.\nMinimal prefix tree which distinguish elements turns out to require\nasymptotically only about 2.77544 bits per element, while standard approaches\nuse a few times more. While being certain of working inside the database, the\ncost of distinguishability can be reduced further to about 2.33275 bits per\nelements. Increasing minimal depth of nodes to reduce probability of false\npositives leads to simple relation with average depth of such random tree,\nwhich is asymptotically larger by about 1.33275 bits than lg(n) of the perfect\nbinary tree. This asymptotic case can be also seen as a way to optimally encode\nn large unordered numbers - saving lg(n!) bits of information about their\nordering, which can be the major part of contained information. This ability\nitself allows to reduce memory requirements even to about 0.693 of required in\nBloom filter for the same false positive probability.</p>\n", "tags": [], "tsne_embedding": [-1.5859596729278564, -24.65452003479004], "cluster": 5}, {"key": "dutta2017stochastic", "year": "2017", "citations": "19", "title": "Stochastic Graphlet Embedding", "abstract": "<p>Graph-based methods are known to be successful in many machine learning and\npattern classification tasks. These methods consider semi-structured data as\ngraphs where nodes correspond to primitives (parts, interest points, segments,\netc.) and edges characterize the relationships between these primitives.\nHowever, these non-vectorial graph data cannot be straightforwardly plugged\ninto off-the-shelf machine learning algorithms without a preliminary step of \u2013\nexplicit/implicit \u2013 graph vectorization and embedding. This embedding process\nshould be resilient to intra-class graph variations while being highly\ndiscriminant. In this paper, we propose a novel high-order stochastic graphlet\nembedding (SGE) that maps graphs into vector spaces. Our main contribution\nincludes a new stochastic search procedure that efficiently parses a given\ngraph and extracts/samples unlimitedly high-order graphlets. We consider these\ngraphlets, with increasing orders, to model local primitives as well as their\nincreasingly complex interactions. In order to build our graph representation,\nwe measure the distribution of these graphlets into a given graph, using\nparticular hash functions that efficiently assign sampled graphlets into\nisomorphic sets with a very low probability of collision. When combined with\nmaximum margin classifiers, these graphlet-based representations have positive\nimpact on the performance of pattern comparison and recognition as corroborated\nthrough extensive experiments using standard benchmark databases.</p>\n", "tags": ["Graph Based ANN", "Hashing Methods", "Evaluation"], "tsne_embedding": [20.076133728027344, 15.27620792388916], "cluster": 0}, {"key": "dutta2018graph", "year": "2018", "citations": "5", "title": "Graph Kernels Based On High Order Graphlet Parsing And Hashing", "abstract": "<p>Graph-based methods are known to be successful in many machine learning and\npattern classification tasks. These methods consider semi-structured data as\ngraphs where nodes correspond to primitives (parts, interest points, segments,\netc.) and edges characterize the relationships between these primitives.\nHowever, these non-vectorial graph data cannot be straightforwardly plugged\ninto off-the-shelf machine learning algorithms without a preliminary step of \u2013\nexplicit/implicit \u2013 graph vectorization and embedding. This embedding process\nshould be resilient to intra-class graph variations while being highly\ndiscriminant. In this paper, we propose a novel high-order stochastic graphlet\nembedding (SGE) that maps graphs into vector spaces. Our main contribution\nincludes a new stochastic search procedure that efficiently parses a given\ngraph and extracts/samples unlimitedly high-order graphlets. We consider these\ngraphlets, with increasing orders, to model local primitives as well as their\nincreasingly complex interactions. In order to build our graph representation,\nwe measure the distribution of these graphlets into a given graph, using\nparticular hash functions that efficiently assign sampled graphlets into\nisomorphic sets with a very low probability of collision. When combined with\nmaximum margin classifiers, these graphlet-based representations have positive\nimpact on the performance of pattern comparison and recognition as corroborated\nthrough extensive experiments using standard benchmark databases.</p>\n", "tags": ["Graph Based ANN", "Hashing Methods", "Evaluation"], "tsne_embedding": [20.076133728027344, 15.27620792388916], "cluster": 0}, {"key": "dutta2018when", "year": "2018", "citations": "5", "title": "When Hashing Met Matching: Efficient Spatio-temporal Search For Ridesharing", "abstract": "<p>Carpooling, or sharing a ride with other passengers, holds immense potential\nfor urban transportation. Ridesharing platforms enable such sharing of rides\nusing real-time data. Finding ride matches in real-time at urban scale is a\ndifficult combinatorial optimization task and mostly heuristic approaches are\napplied. In this work, we mathematically model the problem as that of finding\nnear-neighbors and devise a novel efficient spatio-temporal search algorithm\nbased on the theory of locality sensitive hashing for Maximum Inner Product\nSearch (MIPS). The proposed algorithm can find \\(k\\) near-optimal potential\nmatches for every ride from a pool of \\(n\\) rides in time \\(O(n^{1 + \\rho} (k +\nlog n) log k)\\) and space \\(O(n^{1 + \\rho} log k)\\) for a small \\(\\rho &lt; 1\\). Our\nalgorithm can be extended in several useful and interesting ways increasing its\npractical appeal. Experiments with large NY yellow taxi trip datasets show that\nour algorithm consistently outperforms state-of-the-art heuristic methods\nthereby proving its practical applicability.</p>\n", "tags": ["AAAI", "Locality Sensitive Hashing", "Hashing Methods", "DATASETS"], "tsne_embedding": [18.901649475097656, -7.152695655822754], "cluster": 2}, {"key": "dutta2019probabilistic", "year": "2019", "citations": "5", "title": "A Probabilistic Approach For Learning Embeddings Without Supervision", "abstract": "<p>For challenging machine learning problems such as zero-shot learning and\nfine-grained categorization, embedding learning is the machinery of choice\nbecause of its ability to learn generic notions of similarity, as opposed to\nclass-specific concepts in standard classification models. Embedding learning\naims at learning discriminative representations of data such that similar\nexamples are pulled closer, while pushing away dissimilar ones. Despite their\nexemplary performances, supervised embedding learning approaches require huge\nnumber of annotations for training. This restricts their applicability for\nlarge datasets in new applications where obtaining labels require extensive\nmanual efforts and domain knowledge. In this paper, we propose to learn an\nembedding in a completely unsupervised manner without using any class labels.\nUsing a graph-based clustering approach to obtain pseudo-labels, we form\ntriplet-based constraints following a metric learning paradigm. Our novel\nembedding learning approach uses a probabilistic notion, that intuitively\nminimizes the chances of each triplet violating a geometric constraint. Due to\nnature of the search space, we learn the parameters of our approach using\nRiemannian geometry. Our proposed approach performs competitive to\nstate-of-the-art approaches.</p>\n", "tags": ["Graph Based ANN", "DATASETS", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [15.03412914276123, 14.579797744750977], "cluster": 0}, {"key": "efremenko2019fast", "year": "2019", "citations": "9", "title": "Fast And Bayes-consistent Nearest Neighbors", "abstract": "<p>Research on nearest-neighbor methods tends to focus somewhat dichotomously\neither on the statistical or the computational aspects \u2013 either on, say, Bayes\nconsistency and rates of convergence or on techniques for speeding up the\nproximity search. This paper aims at bridging these realms: to reap the\nadvantages of fast evaluation time while maintaining Bayes consistency, and\nfurther without sacrificing too much in the risk decay rate. We combine the\nlocality-sensitive hashing (LSH) technique with a novel missing-mass argument\nto obtain a fast and Bayes-consistent classifier. Our algorithm\u2019s prediction\nruntime compares favorably against state of the art approximate NN methods,\nwhile maintaining Bayes-consistency and attaining rates comparable to minimax.\nOn samples of size \\(n\\) in \\(\\R^d\\), our pre-processing phase has runtime \\(O(d n\nlog n)\\), while the evaluation phase has runtime \\(O(dlog n)\\) per query point.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Evaluation"], "tsne_embedding": [20.69953727722168, -3.2087275981903076], "cluster": 7}, {"key": "eghbali2016fast", "year": "2016", "citations": "15", "title": "Fast Cosine Similarity Search In Binary Space With Angular Multi-index Hashing", "abstract": "<p>Given a large dataset of binary codes and a binary query point, we address\nhow to efficiently find \\(K\\) codes in the dataset that yield the largest cosine\nsimilarities to the query. The straightforward answer to this problem is to\ncompare the query with all items in the dataset, but this is practical only for\nsmall datasets. One potential solution to enhance the search time and achieve\nsublinear cost is to use a hash table populated with binary codes of the\ndataset and then look up the nearby buckets to the query to retrieve the\nnearest neighbors. However, if codes are compared in terms of cosine similarity\nrather than the Hamming distance, then the main issue is that the order of\nbuckets to probe is not evident. To examine this issue, we first elaborate on\nthe connection between the Hamming distance and the cosine similarity. Doing\nthis allows us to systematically find the probing sequence in the hash table.\nHowever, solving the nearest neighbor search with a single table is only\npractical for short binary codes. To address this issue, we propose the angular\nmulti-index hashing search algorithm which relies on building multiple hash\ntables on binary code substrings. The proposed search algorithm solves the\nexact angular \\(K\\) nearest neighbor problem in a time that is often orders of\nmagnitude faster than the linear scan baseline and even approximation methods.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Graph Based ANN", "Distance Metric Learning", "Compact Codes", "Similarity Search", "Vector Indexing"], "tsne_embedding": [15.936997413635254, -11.603452682495117], "cluster": 2}, {"key": "eghbali2019deep", "year": "2019", "citations": "27", "title": "Deep Spherical Quantization For Image Search", "abstract": "<p>Hashing methods, which encode high-dimensional images with compact discrete\ncodes, have been widely applied to enhance large-scale image retrieval. In this\npaper, we put forward Deep Spherical Quantization (DSQ), a novel method to make\ndeep convolutional neural networks generate supervised and compact binary codes\nfor efficient image search. Our approach simultaneously learns a mapping that\ntransforms the input images into a low-dimensional discriminative space, and\nquantizes the transformed data points using multi-codebook quantization. To\neliminate the negative effect of norm variance on codebook learning, we force\nthe network to L_2 normalize the extracted features and then quantize the\nresulting vectors using a new supervised quantization technique specifically\ndesigned for points lying on a unit hypersphere. Furthermore, we introduce an\neasy-to-implement extension of our quantization technique that enforces\nsparsity on the codebooks. Extensive experiments demonstrate that DSQ and its\nsparse variant can generate semantically separable compact binary codes\noutperforming many state-of-the-art image retrieval methods on three\nbenchmarks.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "CVPR", "Compact Codes", "Quantization", "Evaluation"], "tsne_embedding": [1.4915592670440674, 14.363011360168457], "cluster": 6}, {"key": "elezi2019group", "year": "2019", "citations": "48", "title": "The Group Loss For Deep Metric Learning", "abstract": "<p>Deep metric learning has yielded impressive results in tasks such as\nclustering and image retrieval by leveraging neural networks to obtain highly\ndiscriminative feature embeddings, which can be used to group samples into\ndifferent classes. Much research has been devoted to the design of smart loss\nfunctions or data mining strategies for training such networks. Most methods\nconsider only pairs or triplets of samples within a mini-batch to compute the\nloss function, which is commonly based on the distance between embeddings. We\npropose Group Loss, a loss function based on a differentiable label-propagation\nmethod that enforces embedding similarity across all samples of a group while\npromoting, at the same time, low-density regions amongst data points belonging\nto different groups. Guided by the smoothness assumption that \u201csimilar objects\nshould belong to the same group\u201d, the proposed loss trains the neural network\nfor a classification task, enforcing a consistent labelling amongst samples\nwithin a class. We show state-of-the-art results on clustering and image\nretrieval on several datasets, and show the potential of our method when\ncombined with other techniques such as ensembles</p>\n", "tags": ["Image Retrieval", "DATASETS", "Distance Metric Learning"], "tsne_embedding": [-23.30890464782715, 2.9015579223632812], "cluster": 3}, {"key": "elezi2022group", "year": "2022", "citations": "13", "title": "The Group Loss++: A Deeper Look Into Group Loss For Deep Metric Learning", "abstract": "<p>Deep metric learning has yielded impressive results in tasks such as\nclustering and image retrieval by leveraging neural networks to obtain highly\ndiscriminative feature embeddings, which can be used to group samples into\ndifferent classes. Much research has been devoted to the design of smart loss\nfunctions or data mining strategies for training such networks. Most methods\nconsider only pairs or triplets of samples within a mini-batch to compute the\nloss function, which is commonly based on the distance between embeddings. We\npropose Group Loss, a loss function based on a differentiable label-propagation\nmethod that enforces embedding similarity across all samples of a group while\npromoting, at the same time, low-density regions amongst data points belonging\nto different groups. Guided by the smoothness assumption that \u201csimilar objects\nshould belong to the same group\u201d, the proposed loss trains the neural network\nfor a classification task, enforcing a consistent labelling amongst samples\nwithin a class. We design a set of inference strategies tailored towards our\nalgorithm, named Group Loss++ that further improve the results of our model. We\nshow state-of-the-art results on clustering and image retrieval on four\nretrieval datasets, and present competitive results on two person\nre-identification datasets, providing a unified framework for retrieval and\nre-identification.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Tools & Libraries", "Distance Metric Learning"], "tsne_embedding": [-23.30320930480957, 2.84214186668396], "cluster": 3}, {"key": "elmehdwi2013secure", "year": "2013", "citations": "359", "title": "Secure K-nearest Neighbor Query Over Encrypted Data In Outsourced Environments", "abstract": "<p>For the past decade, query processing on relational data has been studied\nextensively, and many theoretical and practical solutions to query processing\nhave been proposed under various scenarios. With the recent popularity of cloud\ncomputing, users now have the opportunity to outsource their data as well as\nthe data management tasks to the cloud. However, due to the rise of various\nprivacy issues, sensitive data (e.g., medical records) need to be encrypted\nbefore outsourcing to the cloud. In addition, query processing tasks should be\nhandled by the cloud; otherwise, there would be no point to outsource the data\nat the first place. To process queries over encrypted data without the cloud\never decrypting the data is a very challenging task. In this paper, we focus on\nsolving the k-nearest neighbor (kNN) query problem over encrypted database\noutsourced to a cloud: a user issues an encrypted query record to the cloud,\nand the cloud returns the k closest records to the user. We first present a\nbasic scheme and demonstrate that such a naive solution is not secure. To\nprovide better security, we propose a secure kNN protocol that protects the\nconfidentiality of the data, user\u2019s input query, and data access patterns.\nAlso, we empirically analyze the efficiency of our protocols through various\nexperiments. These results indicate that our secure protocol is very efficient\non the user end, and this lightweight scheme allows a user to use any mobile\ndevice to perform the kNN query.</p>\n", "tags": ["Efficiency And Optimization"], "tsne_embedding": [2.6794376373291016, -23.75758934020996], "cluster": 5}, {"key": "elnouby2021training", "year": "2021", "citations": "120", "title": "Training Vision Transformers For Image Retrieval", "abstract": "<p>Transformers have shown outstanding results for natural language\nunderstanding and, more recently, for image classification. We here extend this\nwork and propose a transformer-based approach for image retrieval: we adopt\nvision transformers for generating image descriptors and train the resulting\nmodel with a metric learning objective, which combines a contrastive loss with\na differential entropy regularizer. Our results show consistent and significant\nimprovements of transformers over convolution-based approaches. In particular,\nour method outperforms the state of the art on several public benchmarks for\ncategory-level retrieval, namely Stanford Online Product, In-Shop and CUB-200.\nFurthermore, our experiments on ROxford and RParis also show that, in\ncomparable settings, transformers are competitive for particular object\nretrieval, especially in the regime of short vector representations and\nlow-resolution images.</p>\n", "tags": ["Image Retrieval", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [2.661146640777588, 18.62391471862793], "cluster": 6}, {"key": "engels2021practical", "year": "2021", "citations": "12", "title": "Practical Near Neighbor Search Via Group Testing", "abstract": "<p>We present a new algorithm for the approximate near neighbor problem that\ncombines classical ideas from group testing with locality-sensitive hashing\n(LSH). We reduce the near neighbor search problem to a group testing problem by\ndesignating neighbors as \u201cpositives,\u201d non-neighbors as \u201cnegatives,\u201d and\napproximate membership queries as group tests. We instantiate this framework\nusing distance-sensitive Bloom Filters to Identify Near-Neighbor Groups\n(FLINNG). We prove that FLINNG has sub-linear query time and show that our\nalgorithm comes with a variety of practical advantages. For example, FLINNG can\nbe constructed in a single pass through the data, consists entirely of\nefficient integer operations, and does not require any distance computations.\nWe conduct large-scale experiments on high-dimensional search tasks such as\ngenome search, URL similarity search, and embedding search over the massive\nYFCC100M dataset. In our comparison with leading algorithms such as HNSW and\nFAISS, we find that FLINNG can provide up to a 10x query speedup with\nsubstantially smaller indexing time and memory.</p>\n", "tags": ["Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Graph Based ANN", "Efficiency And Optimization", "Similarity Search", "Tools & Libraries", "Evaluation"], "tsne_embedding": [14.680317878723145, -2.4086296558380127], "cluster": 2}, {"key": "engels2024approximate", "year": "2024", "citations": "27", "title": "Approximate Nearest Neighbor Search With Window Filters", "abstract": "<p>We define and investigate the problem of \\(\\textit{c-approximate window\nsearch}\\): approximate nearest neighbor search where each point in the dataset\nhas a numeric label, and the goal is to find nearest neighbors to queries\nwithin arbitrary label ranges. Many semantic search problems, such as image and\ndocument search with timestamp filters, or product search with cost filters,\nare natural examples of this problem. We propose and theoretically analyze a\nmodular tree-based framework for transforming an index that solves the\ntraditional c-approximate nearest neighbor problem into a data structure that\nsolves window search. On standard nearest neighbor benchmark datasets equipped\nwith random label values, adversarially constructed embeddings, and image\nsearch embeddings with real timestamps, we obtain up to a \\(75\\times\\) speedup\nover existing solutions at the same level of recall.</p>\n", "tags": ["DATASETS", "Efficiency And Optimization", "Tree Based ANN", "Tools & Libraries", "Evaluation", "Robustness"], "tsne_embedding": [21.490276336669922, -2.6919262409210205], "cluster": 7}, {"key": "engelsma2020hers", "year": "2020", "citations": "34", "title": "HERS: Homomorphically Encrypted Representation Search", "abstract": "<p>We present a method to search for a probe (or query) image representation\nagainst a large gallery in the encrypted domain. We require that the probe and\ngallery images be represented in terms of a fixed-length representation, which\nis typical for representations obtained from learned networks. Our encryption\nscheme is agnostic to how the fixed-length representation is obtained and can\ntherefore be applied to any fixed-length representation in any application\ndomain. Our method, dubbed HERS (Homomorphically Encrypted Representation\nSearch), operates by (i) compressing the representation towards its estimated\nintrinsic dimensionality with minimal loss of accuracy (ii) encrypting the\ncompressed representation using the proposed fully homomorphic encryption\nscheme, and (iii) efficiently searching against a gallery of encrypted\nrepresentations directly in the encrypted domain, without decrypting them.\nNumerical results on large galleries of face, fingerprint, and object datasets\nsuch as ImageNet show that, for the first time, accurate and fast image search\nwithin the encrypted domain is feasible at scale (500 seconds; \\(275\\times\\)\nspeed up over state-of-the-art for encrypted search against a gallery of 100\nmillion). Code is available at\nhttps://github.com/human-analysis/hers-encrypted-image-search</p>\n", "tags": ["Compact Codes", "Image Retrieval", "DATASETS"], "tsne_embedding": [-13.011746406555176, -24.795852661132812], "cluster": 5}, {"key": "ercoli2016compact", "year": "2016", "citations": "42", "title": "Compact Hash Codes For Efficient Visual Descriptors Retrieval In Large Scale Databases", "abstract": "<p>In this paper we present an efficient method for visual descriptors retrieval\nbased on compact hash codes computed using a multiple k-means assignment. The\nmethod has been applied to the problem of approximate nearest neighbor (ANN)\nsearch of local and global visual content descriptors, and it has been tested\non different datasets: three large scale public datasets of up to one billion\ndescriptors (BIGANN) and, supported by recent progress in convolutional neural\nnetworks (CNNs), also on the CIFAR-10 and MNIST datasets. Experimental results\nshow that, despite its simplicity, the proposed method obtains a very high\nperformance that makes it superior to more complex state-of-the-art methods.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Evaluation"], "tsne_embedding": [17.440677642822266, -6.015727996826172], "cluster": 2}, {"key": "ermolov2022hyperbolic", "year": "2022", "citations": "61", "title": "Hyperbolic Vision Transformers: Combining Improvements In Metric Learning", "abstract": "<p>Metric learning aims to learn a highly discriminative model encouraging the\nembeddings of similar classes to be close in the chosen metrics and pushed\napart for dissimilar ones. The common recipe is to use an encoder to extract\nembeddings and a distance-based loss function to match the representations \u2013\nusually, the Euclidean distance is utilized. An emerging interest in learning\nhyperbolic data embeddings suggests that hyperbolic geometry can be beneficial\nfor natural data. Following this line of work, we propose a new\nhyperbolic-based model for metric learning. At the core of our method is a\nvision transformer with output embeddings mapped to hyperbolic space. These\nembeddings are directly optimized using modified pairwise cross-entropy loss.\nWe evaluate the proposed model with six different formulations on four datasets\nachieving the new state-of-the-art performance. The source code is available at\nhttps://github.com/htdt/hyp_metric.</p>\n", "tags": ["CVPR", "DATASETS", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [-22.90996742248535, 7.190390586853027], "cluster": 3}, {"key": "ertl2017superminhash", "year": "2017", "citations": "13", "title": "Superminhash - A New Minwise Hashing Algorithm For Jaccard Similarity Estimation", "abstract": "<p>This paper presents a new algorithm for calculating hash signatures of sets\nwhich can be directly used for Jaccard similarity estimation. The new approach\nis an improvement over the MinHash algorithm, because it has a better runtime\nbehavior and the resulting signatures allow a more precise estimation of the\nJaccard index.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods"], "tsne_embedding": [3.2472972869873047, -12.467601776123047], "cluster": 9}, {"key": "ertl2018bagminhash", "year": "2018", "citations": "15", "title": "Bagminhash - Minwise Hashing Algorithm For Weighted Sets", "abstract": "<p>Minwise hashing has become a standard tool to calculate signatures which\nallow direct estimation of Jaccard similarities. While very efficient\nalgorithms already exist for the unweighted case, the calculation of signatures\nfor weighted sets is still a time consuming task. BagMinHash is a new algorithm\nthat can be orders of magnitude faster than current state of the art without\nany particular restrictions or assumptions on weights or data dimensionality.\nApplied to the special case of unweighted sets, it represents the first\nefficient algorithm producing independent signature components. A series of\ntests finally verifies the new algorithm and also reveals limitations of other\napproaches published in the recent past.</p>\n", "tags": ["KDD", "Locality Sensitive Hashing", "Hashing Methods"], "tsne_embedding": [4.359073162078857, -14.502124786376953], "cluster": 2}, {"key": "ertl2019probminhash", "year": "2019", "citations": "23", "title": "Probminhash -- A Class Of Locality-sensitive Hash Algorithms For The (probability) Jaccard Similarity", "abstract": "<p>The probability Jaccard similarity was recently proposed as a natural\ngeneralization of the Jaccard similarity to measure the proximity of sets whose\nelements are associated with relative frequencies or probabilities. In\ncombination with a hash algorithm that maps those weighted sets to compact\nsignatures which allow fast estimation of pairwise similarities, it constitutes\na valuable method for big data applications such as near-duplicate detection,\nnearest neighbor search, or clustering. This paper introduces a class of\none-pass locality-sensitive hash algorithms that are orders of magnitude faster\nthan the original approach. The performance gain is achieved by calculating\nsignature components not independently, but collectively. Four different\nalgorithms are proposed based on this idea. Two of them are statistically\nequivalent to the original approach and can be used as drop-in replacements.\nThe other two may even improve the estimation error by introducing statistical\ndependence between signature components. Moreover, the presented techniques can\nbe specialized for the conventional Jaccard similarity, resulting in highly\nefficient algorithms that outperform traditional minwise hashing and that are\nable to compete with the state of the art.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Evaluation"], "tsne_embedding": [17.777433395385742, -9.204755783081055], "cluster": 2}, {"key": "ertl2021setsketch", "year": "2021", "citations": "17", "title": "Setsketch: Filling The Gap Between Minhash And Hyperloglog", "abstract": "<p>MinHash and HyperLogLog are sketching algorithms that have become\nindispensable for set summaries in big data applications. While HyperLogLog\nallows counting different elements with very little space, MinHash is suitable\nfor the fast comparison of sets as it allows estimating the Jaccard similarity\nand other joint quantities. This work presents a new data structure called\nSetSketch that is able to continuously fill the gap between both use cases. Its\ncommutative and idempotent insert operation and its mergeable state make it\nsuitable for distributed environments. Fast, robust, and easy-to-implement\nestimators for cardinality and joint quantities, as well as the ability to use\nSetSketch for similarity search, enable versatile applications. The presented\njoint estimator can also be applied to other data structures such as MinHash,\nHyperLogLog, or HyperMinHash, where it even performs better than the\ncorresponding state-of-the-art estimators in many cases.</p>\n", "tags": ["Locality Sensitive Hashing", "Similarity Search", "Evaluation"], "tsne_embedding": [9.505308151245117, 3.8790547847747803], "cluster": 4}, {"key": "esen2016large", "year": "2016", "citations": "9", "title": "Large-scale Video Search With Efficient Temporal Voting Structure", "abstract": "<p>In this work, we propose a fast content-based video querying system for\nlarge-scale video search. The proposed system is distinguished from similar\nworks with two major contributions. First contribution is superiority of joint\nusage of repeated content representation and efficient hashing mechanisms.\nRepeated content representation is utilized with a simple yet robust feature,\nwhich is based on edge energy of frames. Each of the representation is\nconverted into hash code with Hamming Embedding method for further queries.\nSecond contribution is novel queue-based voting scheme that leads to modest\nmemory requirements with gradual memory allocation capability, contrary to\ncomplete brute-force temporal voting schemes. This aspect enables us to make\nqueries on large video databases conveniently, even on commodity computers with\nlimited memory capacity. Our results show that the system can respond to video\nqueries on a large video database with fast query times, high recall rate and\nvery low memory and disk requirements.</p>\n", "tags": ["Hashing Methods", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [-5.833194255828857, 22.384313583374023], "cluster": 6}, {"key": "esposito2019recsplit", "year": "2019", "citations": "20", "title": "Recsplit: Minimal Perfect Hashing Via Recursive Splitting", "abstract": "<p>A minimal perfect hash function bijectively maps a key set \\(S\\) out of a\nuniverse \\(U\\) into the first \\(|S|\\) natural numbers. Minimal perfect hash\nfunctions are used, for example, to map irregularly-shaped keys, such as\nstring, in a compact space so that metadata can then be simply stored in an\narray. While it is known that just \\(1.44\\) bits per key are necessary to store a\nminimal perfect function, no published technique can go below \\(2\\) bits per key\nin practice. We propose a new technique for storing minimal perfect hash\nfunctions with expected linear construction time and expected constant lookup\ntime that makes it possible to build for the first time, for example,\nstructures which need \\(1.56\\) bits per key, that is, within \\(8.3\\)% of the lower\nbound, in less than \\(2\\) ms per key. We show that instances of our construction\nare able to simultaneously beat the construction time, space usage and lookup\ntime of the state-of-the-art data structure reaching \\(2\\) bits per key.\nMoreover, we provide parameter choices giving structures which are competitive\nwith alternative, larger-size data structures in terms of space and lookup\ntime. The construction of our data structures can be easily parallelized or\nmapped on distributed computational units (e.g., within the MapReduce\nframework), and structures larger than the available RAM can be directly built\nin mass storage.</p>\n", "tags": ["Alt", "Tools & Libraries", "Hashing Methods", "Evaluation"], "tsne_embedding": [-7.889440536499023, -25.459354400634766], "cluster": 5}, {"key": "esser2021faster", "year": "2021", "citations": "7", "title": "A Faster Algorithm For Finding Closest Pairs In Hamming Metric", "abstract": "<p>We study the Closest Pair Problem in Hamming metric, which asks to find the\npair with the smallest Hamming distance in a collection of binary vectors. We\ngive a new randomized algorithm for the problem on uniformly random input\noutperforming previous approaches whenever the dimension of input points is\nsmall compared to the dataset size. For moderate to large dimensions, our\nalgorithm matches the time complexity of the previously best-known locality\nsensitive hashing based algorithms. Technically our algorithm follows similar\ndesign principles as Dubiner (IEEE Trans. Inf. Theory 2010) and May-Ozerov\n(Eurocrypt 2015). Besides improving the time complexity in the aforementioned\nareas, we significantly simplify the analysis of these previous works. We give\na modular analysis, which allows us to investigate the performance of the\nalgorithm also on non-uniform input distributions. Furthermore, we give a proof\nof concept implementation of our algorithm which performs well in comparison to\na quadratic search baseline. This is the first step towards answering an open\nquestion raised by May and Ozerov regarding the practicability of algorithms\nfollowing these design principles.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Graph Based ANN", "Similarity Search", "Evaluation"], "tsne_embedding": [4.544919013977051, 11.528040885925293], "cluster": 4}, {"key": "fahim2022unsupervised", "year": "2022", "citations": "8", "title": "Unsupervised Space Partitioning For Nearest Neighbor Search", "abstract": "<p>Approximate Nearest Neighbor Search (ANNS) in high dimensional spaces is\ncrucial for many real-life applications (e.g., e-commerce, web, multimedia,\netc.) dealing with an abundance of data. This paper proposes an end-to-end\nlearning framework that couples the partitioning (one critical step of ANNS)\nand learning-to-search steps using a custom loss function. A key advantage of\nour proposed solution is that it does not require any expensive pre-processing\nof the dataset, which is one of the critical limitations of the\nstate-of-the-art approach. We achieve the above edge by formulating a\nmulti-objective custom loss function that does not need ground truth labels to\nquantify the quality of a given data-space partition, making it entirely\nunsupervised. We also propose an ensembling technique by adding varying input\nweights to the loss function to train an ensemble of models to enhance the\nsearch quality. On several standard benchmarks for ANNS, we show that our\nmethod beats the state-of-the-art space partitioning method and the ubiquitous\nK-means clustering method while using fewer parameters and shorter offline\ntraining times. We also show that incorporating our space-partitioning strategy\ninto state-of-the-art ANNS techniques such as ScaNN can improve their\nperformance significantly. Finally, we present our unsupervised partitioning\napproach as a promising alternative to many widely used clustering methods,\nsuch as K-means clustering and DBSCAN.</p>\n", "tags": ["Alt", "Tools & Libraries", "Evaluation", "DATASETS"], "tsne_embedding": [-0.2004546970129013, -18.222503662109375], "cluster": 5}, {"key": "fan2019unsupervised", "year": "2019", "citations": "25", "title": "Unsupervised Co-learning On \\(\\mathcal{g}\\)-manifolds Across Irreducible Representations", "abstract": "<p>We introduce a novel co-learning paradigm for manifolds naturally equipped\nwith a group action, motivated by recent developments on learning a manifold\nfrom attached fibre bundle structures. We utilize a representation theoretic\nmechanism that canonically associates multiple independent vector bundles over\na common base manifold, which provides multiple views for the geometry of the\nunderlying manifold. The consistency across these fibre bundles provide a\ncommon base for performing unsupervised manifold co-learning through the\nredundancy created artificially across irreducible representations of the\ntransformation group. We demonstrate the efficacy of the proposed algorithmic\nparadigm through drastically improved robust nearest neighbor search and\ncommunity detection on rotation-invariant cryo-electron microscopy image\nanalysis.</p>\n", "tags": [], "tsne_embedding": [-26.753639221191406, 3.9200780391693115], "cluster": 3}, {"key": "fan2025deep", "year": "2025", "citations": "81", "title": "Deep Polarized Network For Supervised Learning Of Accurate Binary Hashing Codes", "abstract": "<p>This paper proposes a novel deep polarized network (DPN) for learning to hash, in which each channel in the network outputs is pushed far away\nfrom zero by employing a differentiable bit-wise hinge-like loss which is dubbed as polarization loss. Reformulated within a generic Hamming Distance Metric Learning framework [Norouzi et al.,\n2012], the proposed polarization loss bypasses the requirement to prepare pairwise labels for (dis-)similar items and, yet, the proposed loss strictly bounds from above the pairwise Hamming Distance based losses. The intrinsic connection between pairwise and pointwise label information, as\ndisclosed in this paper, brings about the following methodological improvements: (a) we may directly employ the proposed differentiable polarization loss with no large deviations incurred from\nthe target Hamming distance based loss; and (b) the subtask of assigning binary codes becomes extremely simple \u2014 even random codes assigned to each class suffice to result in state-of-the-art performances, as demonstrated in CIFAR10, NUS-WIDE and ImageNet100 datasets.</p>\n", "tags": ["DATASETS", "Evaluation", "IJCAI", "Hashing Methods", "Distance Metric Learning", "Compact Codes", "Tools & Libraries", "AAAI"], "tsne_embedding": [-6.228234767913818, -11.338762283325195], "cluster": 9}, {"key": "fan2025supervised", "year": "2025", "citations": "15", "title": "Supervised Binary Hash Code Learning With Jensen Shannon Divergence", "abstract": "<p>This paper proposes to learn binary hash codes within\na statistical learning framework, in which an upper bound\nof the probability of Bayes decision errors is derived for\ndifferent forms of hash functions and a rigorous proof of\nthe convergence of the upper bound is presented. Consequently, minimizing such an upper bound leads to consistent\nperformance improvements of existing hash code learning\nalgorithms, regardless of whether original algorithms are\nunsupervised or supervised. This paper also illustrates a\nfast hash coding method that exploits simple binary tests to\nachieve orders of magnitude improvement in coding speed\nas compared to projection based methods.</p>\n", "tags": ["ICCV", "Tools & Libraries", "Hashing Methods", "Evaluation"], "tsne_embedding": [-0.4703272879123688, -11.320886611938477], "cluster": 9}, {"key": "fang2020attention", "year": "2020", "citations": "12", "title": "Attention-based Saliency Hashing For Ophthalmic Image Retrieval", "abstract": "<p>Deep hashing methods have been proved to be effective for the large-scale\nmedical image search assisting reference-based diagnosis for clinicians.\nHowever, when the salient region plays a maximal discriminative role in\nophthalmic image, existing deep hashing methods do not fully exploit the\nlearning ability of the deep network to capture the features of salient regions\npointedly. The different grades or classes of ophthalmic images may be share\nsimilar overall performance but have subtle differences that can be\ndifferentiated by mining salient regions. To address this issue, we propose a\nnovel end-to-end network, named Attention-based Saliency Hashing (ASH), for\nlearning compact hash-code to represent ophthalmic images. ASH embeds a\nspatial-attention module to focus more on the representation of salient regions\nand highlights their essential role in differentiating ophthalmic images.\nBenefiting from the spatial-attention module, the information of salient\nregions can be mapped into the hash-code for similarity calculation. In the\ntraining stage, we input the image pairs to share the weights of the network,\nand a pairwise loss is designed to maximize the discriminability of the\nhash-code. In the retrieval stage, ASH obtains the hash-code by inputting an\nimage with an end-to-end manner, then the hash-code is used to similarity\ncalculation to return the most similar images. Extensive experiments on two\ndifferent modalities of ophthalmic image datasets demonstrate that the proposed\nASH can further improve the retrieval performance compared to the\nstate-of-the-art deep hashing methods due to the huge contributions of the\nspatial-attention module.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Neural Hashing", "Evaluation"], "tsne_embedding": [-21.78005027770996, 18.267621994018555], "cluster": 3}, {"key": "fang2021combating", "year": "2021", "citations": "10", "title": "Combating Ambiguity For Hash-code Learning In Medical Instance Retrieval", "abstract": "<p>When encountering a dubious diagnostic case, medical instance retrieval can\nhelp radiologists make evidence-based diagnoses by finding images containing\ninstances similar to a query case from a large image database. The similarity\nbetween the query case and retrieved similar cases is determined by visual\nfeatures extracted from pathologically abnormal regions. However, the\nmanifestation of these regions often lacks specificity, i.e., different\ndiseases can have the same manifestation, and different manifestations may\noccur at different stages of the same disease. To combat the manifestation\nambiguity in medical instance retrieval, we propose a novel deep framework\ncalled Y-Net, encoding images into compact hash-codes generated from\nconvolutional features by feature aggregation. Y-Net can learn highly\ndiscriminative convolutional features by unifying the pixel-wise segmentation\nloss and classification loss. The segmentation loss allows exploring subtle\nspatial differences for good spatial-discriminability while the classification\nloss utilizes class-aware semantic information for good semantic-separability.\nAs a result, Y-Net can enhance the visual features in pathologically abnormal\nregions and suppress the disturbing of the background during model training,\nwhich could effectively embed discriminative features into the hash-codes in\nthe retrieval stage. Extensive experiments on two medical image datasets\ndemonstrate that Y-Net can alleviate the ambiguity of pathologically abnormal\nregions and its retrieval performance outperforms the state-of-the-art method\nby an average of 9.27% on the returned list of 10.</p>\n", "tags": ["DATASETS", "Evaluation", "ALT", "Tools & Libraries", "Alt"], "tsne_embedding": [-21.871017456054688, 18.059202194213867], "cluster": 3}, {"key": "fang2021deep", "year": "2021", "citations": "50", "title": "Deep Triplet Hashing Network For Case-based Medical Image Retrieval", "abstract": "<p>Deep hashing methods have been shown to be the most efficient approximate\nnearest neighbor search techniques for large-scale image retrieval. However,\nexisting deep hashing methods have a poor small-sample ranking performance for\ncase-based medical image retrieval. The top-ranked images in the returned query\nresults may be as a different class than the query image. This ranking problem\nis caused by classification, regions of interest (ROI), and small-sample\ninformation loss in the hashing space. To address the ranking problem, we\npropose an end-to-end framework, called Attention-based Triplet Hashing (ATH)\nnetwork, to learn low-dimensional hash codes that preserve the classification,\nROI, and small-sample information. We embed a spatial-attention module into the\nnetwork structure of our ATH to focus on ROI information. The spatial-attention\nmodule aggregates the spatial information of feature maps by utilizing\nmax-pooling, element-wise maximum, and element-wise mean operations jointly\nalong the channel axis. The triplet cross-entropy loss can help to map the\nclassification information of images and similarity between images into the\nhash codes. Extensive experiments on two case-based medical datasets\ndemonstrate that our proposed ATH can further improve the retrieval performance\ncompared to the state-of-the-art deep hashing methods and boost the ranking\nperformance for small samples. Compared to the other loss methods, the triplet\ncross-entropy loss can enhance the classification performance and hash\ncode-discriminability</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Neural Hashing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-21.511154174804688, 18.26917266845703], "cluster": 3}, {"key": "fehervari2018scalable", "year": "2018", "citations": "50", "title": "Scalable Logo Recognition Using Proxies", "abstract": "<p>Logo recognition is the task of identifying and classifying logos. Logo\nrecognition is a challenging problem as there is no clear definition of a logo\nand there are huge variations of logos, brands and re-training to cover every\nvariation is impractical. In this paper, we formulate logo recognition as a\nfew-shot object detection problem. The two main components in our pipeline are\nuniversal logo detector and few-shot logo recognizer. The universal logo\ndetector is a class-agnostic deep object detector network which tries to learn\nthe characteristics of what makes a logo. It predicts bounding boxes on likely\nlogo regions. These logo regions are then classified by logo recognizer using\nnearest neighbor search, trained by triplet loss using proxies. We also\nannotated a first of its kind product logo dataset containing 2000 logos from\n295K images collected from Amazon called PL2K. Our pipeline achieves 97% recall\nwith 0.6 mAP on PL2K test dataset and state-of-the-art 0.565 mAP on the\npublicly available FlickrLogos-32 test set without fine-tuning.</p>\n", "tags": ["DATASETS", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [-6.658482551574707, 26.584819793701172], "cluster": 6}, {"key": "feinberg2020chromatic", "year": "2020", "citations": "15", "title": "Chromatic Learning For Sparse Datasets", "abstract": "<p>Learning over sparse, high-dimensional data frequently necessitates the use\nof specialized methods such as the hashing trick. In this work, we design a\nhighly scalable alternative approach that leverages the low degree of feature\nco-occurrences present in many practical settings. This approach, which we call\nChromatic Learning (CL), obtains a low-dimensional dense feature representation\nby performing graph coloring over the co-occurrence graph of features\u2014an\napproach previously used as a runtime performance optimization for GBDT\ntraining. This color-based dense representation can be combined with additional\ndense categorical encoding approaches, e.g., submodular feature compression, to\nfurther reduce dimensionality. CL exhibits linear parallelizability and\nconsumes memory linear in the size of the co-occurrence graph. By leveraging\nthe structural properties of the co-occurrence graph, CL can compress sparse\ndatasets, such as KDD Cup 2012, that contain over 50M features down to 1024,\nusing an order of magnitude fewer features than frequency-based truncation and\nthe hashing trick while maintaining the same test error for linear models. This\ncompression further enables the use of deep networks in this wide, sparse\nsetting, where CL similarly has favorable performance compared to existing\nbaselines for budgeted input dimension.</p>\n", "tags": ["KDD", "DATASETS", "Hashing Methods", "Alt", "Evaluation"], "tsne_embedding": [14.601654052734375, 12.117879867553711], "cluster": 0}, {"key": "feng2016deep", "year": "2016", "citations": "12", "title": "Deep Image Set Hashing", "abstract": "<p>In applications involving matching of image sets, the information from\nmultiple images must be effectively exploited to represent each set.\nState-of-the-art methods use probabilistic distribution or subspace to model a\nset and use specific distance measure to compare two sets. These methods are\nslow to compute and not compact to use in a large scale scenario.\nLearning-based hashing is often used in large scale image retrieval as they\nprovide a compact representation of each sample and the Hamming distance can be\nused to efficiently compare two samples. However, most hashing methods encode\neach image separately and discard knowledge that multiple images in the same\nset represent the same object or person. We investigate the set hashing problem\nby combining both set representation and hashing in a single deep neural\nnetwork. An image set is first passed to a CNN module to extract image\nfeatures, then these features are aggregated using two types of set feature to\ncapture both set specific and database-wide distribution information. The\ncomputed set feature is then fed into a multilayer perceptron to learn a\ncompact binary embedding. Triplet loss is used to train the network by forming\nset similarity relations using class labels. We extensively evaluate our\napproach on datasets used for image matching and show highly competitive\nperformance compared to state-of-the-art methods.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Distance Metric Learning", "Evaluation"], "tsne_embedding": [-11.158665657043457, 21.40497589111328], "cluster": 6}, {"key": "feng2020adversarial", "year": "2020", "citations": "43", "title": "Adversarial Attack On Deep Product Quantization Network For Image Retrieval", "abstract": "<p>Deep product quantization network (DPQN) has recently received much attention\nin fast image retrieval tasks due to its efficiency of encoding\nhigh-dimensional visual features especially when dealing with large-scale\ndatasets. Recent studies show that deep neural networks (DNNs) are vulnerable\nto input with small and maliciously designed perturbations (a.k.a., adversarial\nexamples). This phenomenon raises the concern of security issues for DPQN in\nthe testing/deploying stage as well. However, little effort has been devoted to\ninvestigating how adversarial examples affect DPQN. To this end, we propose\nproduct quantization adversarial generation (PQ-AG), a simple yet effective\nmethod to generate adversarial examples for product quantization based\nretrieval systems. PQ-AG aims to generate imperceptible adversarial\nperturbations for query images to form adversarial queries, whose nearest\nneighbors from a targeted product quantizaiton model are not semantically\nrelated to those from the original queries. Extensive experiments show that our\nPQ-AQ successfully creates adversarial examples to mislead targeted product\nquantization retrieval models. Besides, we found that our PQ-AG significantly\ndegrades retrieval performance in both white-box and black-box settings.</p>\n", "tags": ["Image Retrieval", "AAAI", "DATASETS", "Efficiency And Optimization", "Quantization", "Evaluation", "Robustness"], "tsne_embedding": [-12.751169204711914, 10.867608070373535], "cluster": 3}, {"key": "ferdowsi2017sparse", "year": "2017", "citations": "12", "title": "Sparse Ternary Codes For Similarity Search Have Higher Coding Gain Than Dense Binary Codes", "abstract": "<p>This paper addresses the problem of Approximate Nearest Neighbor (ANN) search\nin pattern recognition where feature vectors in a database are encoded as\ncompact codes in order to speed-up the similarity search in large-scale\ndatabases. Considering the ANN problem from an information-theoretic\nperspective, we interpret it as an encoding, which maps the original feature\nvectors to a less entropic sparse representation while requiring them to be as\ninformative as possible. We then define the coding gain for ANN search using\ninformation-theoretic measures. We next show that the classical approach to\nthis problem, which consists of binarization of the projected vectors is\nsub-optimal. Instead, a properly designed ternary encoding achieves higher\ncoding gains and lower complexity.</p>\n", "tags": ["Compact Codes", "Similarity Search", "Hashing Methods", "Evaluation"], "tsne_embedding": [21.14777374267578, -5.729941368103027], "cluster": 7}, {"key": "fernandes2020locality", "year": "2020", "citations": "7", "title": "Locality Sensitive Hashing With Extended Differential Privacy", "abstract": "<p>Extended differential privacy, a generalization of standard differential\nprivacy (DP) using a general metric, has been widely studied to provide\nrigorous privacy guarantees while keeping high utility. However, existing works\non extended DP are limited to few metrics, such as the Euclidean metric.\nConsequently, they have only a small number of applications, such as\nlocation-based services and document processing. In this paper, we propose a\ncouple of mechanisms providing extended DP with a different metric: angular\ndistance (or cosine distance). Our mechanisms are based on locality sensitive\nhashing (LSH), which can be applied to the angular distance and work well for\npersonal data in a high-dimensional space. We theoretically analyze the privacy\nproperties of our mechanisms, and prove extended DP for input data by taking\ninto account that LSH preserves the original metric only approximately. We\napply our mechanisms to friend matching based on high-dimensional personal data\nwith angular distance in the local model, and evaluate our mechanisms using two\nreal datasets. We show that LDP requires a very large privacy budget and that\nRAPPOR does not work in this application. Then we show that our mechanisms\nenable friend matching with high utility and rigorous privacy guarantees based\non extended DP.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "DATASETS"], "tsne_embedding": [7.422590255737305, -23.66682243347168], "cluster": 5}, {"key": "fernandez2022active", "year": "2022", "citations": "142", "title": "Active Image Indexing", "abstract": "<p>Image copy detection and retrieval from large databases leverage two\ncomponents. First, a neural network maps an image to a vector representation,\nthat is relatively robust to various transformations of the image. Second, an\nefficient but approximate similarity search algorithm trades scalability (size\nand speed) against quality of the search, thereby introducing a source of\nerror. This paper improves the robustness of image copy detection with active\nindexing, that optimizes the interplay of these two components. We reduce the\nquantization loss of a given image representation by making imperceptible\nchanges to the image before its release. The loss is back-propagated through\nthe deep neural network back to the image, under perceptual constraints. These\nmodifications make the image more retrievable. Our experiments show that the\nretrieval and copy detection of activated images is significantly improved. For\ninstance, activation improves by \\(+40%\\) the Recall1@1 on various image\ntransformations, and for several popular indexing structures based on product\nquantization and locality sensitivity hashing.</p>\n", "tags": ["Hashing Methods", "Similarity Search", "Quantization", "Evaluation", "Robustness"], "tsne_embedding": [-12.038792610168457, 12.23216724395752], "cluster": 3}, {"key": "filtser2019labelings", "year": "2019", "citations": "5", "title": "Labelings Vs. Embeddings: On Distributed Representations Of Distances", "abstract": "<p>We investigate for which metric spaces the performance of distance labeling\nand of \\(\\ell_\\infty\\)-embeddings differ, and how significant can this difference\nbe. Recall that a distance labeling is a distributed representation of\ndistances in a metric space \\((X,d)\\), where each point \\(x\\in X\\) is assigned a\nsuccinct label, such that the distance between any two points \\(x,y \\in X\\) can\nbe approximated given only their labels. A highly structured special case is an\nembedding into \\(\\ell_\\infty\\), where each point \\(x\\in X\\) is assigned a vector\n\\(f(x)\\) such that \\(|f(x)-f(y)|<em>\\infty\\) is approximately \\(d(x,y)\\). The\nperformance of a distance labeling or an \\(\\ell</em>\\infty\\)-embedding is measured\nvia its distortion and its label-size/dimension.\n  We also study the analogous question for the prioritized versions of these\ntwo measures. Here, a priority order \\(\\pi=(x_1,\\dots,x_n)\\) of the point set \\(X\\)\nis given, and higher-priority points should have shorter labels. Formally, a\ndistance labeling has prioritized label-size \\(\\alpha(\\cdot)\\) if every \\(x_j\\) has\nlabel size at most \\(\\alpha(j)\\). Similarly, an embedding \\(f: X \\to \\ell_\\infty\\)\nhas prioritized dimension \\(\\alpha(\\cdot)\\) if \\(f(x_j)\\) is non-zero only in the\nfirst \\(\\alpha(j)\\) coordinates. In addition, we compare these prioritized\nmeasures to their classical (worst-case) versions.\n  We answer these questions in several scenarios, uncovering a surprisingly\ndiverse range of behaviors. First, in some cases labelings and embeddings have\nvery similar worst-case performance, but in other cases there is a huge\ndisparity. However in the prioritized setting, we most often find a strict\nseparation between the performance of labelings and embeddings. And finally,\nwhen comparing the classical and prioritized settings, we find that the\nworst-case bound for label size often \u201ctranslates\u201d to a prioritized one, but\nalso find a surprising exception to this rule.</p>\n", "tags": ["Graph Based ANN", "Evaluation"], "tsne_embedding": [32.51909637451172, 2.4533166885375977], "cluster": 7}, {"key": "filtser2022labeled", "year": "2022", "citations": "13", "title": "Labeled Nearest Neighbor Search And Metric Spanners Via Locality Sensitive Orderings", "abstract": "<p>Chan, Har-Peled, and Jones [SICOMP 2020] developed locality-sensitive\norderings (LSO) for Euclidean space. A \\((\\tau,\\rho)\\)-LSO is a collection\n\\(\\Sigma\\) of orderings such that for every \\(x,y\\in\\mathbb{R}^d\\) there is an\nordering \\(\\sigma\\in\\Sigma\\), where all the points between \\(x\\) and \\(y\\) w.r.t.\n\\(\\sigma\\) are in the \\(\\rho\\)-neighborhood of either \\(x\\) or \\(y\\). In essence, LSO\nallow one to reduce problems to the \\(1\\)-dimensional line. Later, Filtser and Le\n[STOC 2022] developed LSO\u2019s for doubling metrics, general metric spaces, and\nminor free graphs. For Euclidean and doubling spaces, the number of orderings\nin the LSO is exponential in the dimension, which made them mainly useful for\nthe low dimensional regime. In this paper, we develop new LSO\u2019s for Euclidean,\n\\(\\ell_p\\), and doubling spaces that allow us to trade larger stretch for a much\nsmaller number of orderings. We then use our new LSO\u2019s (as well as the previous\nones) to construct path reporting low hop spanners, fault tolerant spanners,\nreliable spanners, and light spanners for different metric spaces. While many\nnearest neighbor search (NNS) data structures were constructed for metric\nspaces with implicit distance representations (where the distance between two\nmetric points can be computed using their names, e.g. Euclidean space), for\nother spaces almost nothing is known. In this paper we initiate the study of\nthe labeled NNS problem, where one is allowed to artificially assign labels\n(short names) to metric points. We use LSO\u2019s to construct efficient labeled NNS\ndata structures in this model.</p>\n", "tags": [], "tsne_embedding": [31.84803009033203, 3.286285161972046], "cluster": 7}, {"key": "firtina2025enabling", "year": "2025", "citations": "8", "title": "Enabling Fast, Accurate, And Efficient Real-time Genome Analysis Via New Algorithms And Techniques", "abstract": "<p>The advent of high-throughput sequencing technologies has revolutionized\ngenome analysis by enabling the rapid and cost-effective sequencing of large\ngenomes. Despite these advancements, the increasing complexity and volume of\ngenomic data present significant challenges related to accuracy, scalability,\nand computational efficiency. These challenges are mainly due to various forms\nof unwanted and unhandled variations in sequencing data, collectively referred\nto as noise. In this dissertation, we address these challenges by providing a\ndeep understanding of different types of noise in genomic data and developing\ntechniques to mitigate the impact of noise on genome analysis.\n  First, we introduce BLEND, a noise-tolerant hashing mechanism that quickly\nidentifies both exactly matching and highly similar sequences with arbitrary\ndifferences using a single lookup of their hash values. Second, to enable\nscalable and accurate analysis of noisy raw nanopore signals, we propose\nRawHash, a novel mechanism that effectively reduces noise in raw nanopore\nsignals and enables accurate, real-time analysis by proposing the first\nhash-based similarity search technique for raw nanopore signals. Third, we\nextend the capabilities of RawHash with RawHash2, an improved mechanism that 1)\nprovides a better understanding of noise in raw nanopore signals to reduce it\nmore effectively and 2) improves the robustness of mapping decisions. Fourth,\nwe explore the broader implications and new applications of raw nanopore signal\nanalysis by introducing Rawsamble, the first mechanism for all-vs-all\noverlapping of raw signals using hash-based search. Rawsamble enables the\nconstruction of de novo assemblies directly from raw signals without\nbasecalling, which opens up new directions and uses for raw nanopore signal\nanalysis.</p>\n", "tags": ["Hashing Methods", "Efficiency And Optimization", "Similarity Search", "Tools & Libraries", "Evaluation", "Robustness"], "tsne_embedding": [-15.64311695098877, -16.33439064025879], "cluster": 1}, {"key": "fitzgerald2021moleman", "year": "2021", "citations": "8", "title": "MOLEMAN: Mention-only Linking Of Entities With A Mention Annotation Network", "abstract": "<p>We present an instance-based nearest neighbor approach to entity linking. In\ncontrast to most prior entity retrieval systems which represent each entity\nwith a single vector, we build a contextualized mention-encoder that learns to\nplace similar mentions of the same entity closer in vector space than mentions\nof different entities. This approach allows all mentions of an entity to serve\nas \u201cclass prototypes\u201d as inference involves retrieving from the full set of\nlabeled entity mentions in the training set and applying the nearest mention\nneighbor\u2019s entity label. Our model is trained on a large multilingual corpus of\nmention pairs derived from Wikipedia hyperlinks, and performs nearest neighbor\ninference on an index of 700 million mentions. It is simpler to train, gives\nmore interpretable predictions, and outperforms all other systems on two\nmultilingual entity linking benchmarks.</p>\n", "tags": ["ACL", "Evaluation"], "tsne_embedding": [9.146236419677734, -11.390806198120117], "cluster": 2}, {"key": "fleischhacker2021property", "year": "2021", "citations": "5", "title": "Property-preserving Hash Functions From Standard Assumptions", "abstract": "<p>Property-preserving hash functions allow for compressing long inputs \\(x_0\\)\nand \\(x_1\\) into short hashes \\(h(x_0)\\) and \\(h(x_1)\\) in a manner that allows for\ncomputing a predicate \\(P(x_0, x_1)\\) given only the two hash values without\nhaving access to the original data. Such hash functions are said to be\nadversarially robust if an adversary that gets to pick \\(x_0\\) and \\(x_1\\) after\nthe hash function has been sampled, cannot find inputs for which the predicate\nevaluated on the hash values outputs the incorrect result.\n  In this work we construct robust property-preserving hash functions for the\nhamming-distance predicate which distinguishes inputs with a hamming distance\nat least some threshold \\(t\\) from those with distance less than \\(t\\). The\nsecurity of the construction is based on standard lattice hardness assumptions.\n  Our construction has several advantages over the best known previous\nconstruction by Fleischhacker and Simkin. Our construction relies on a single\nwell-studied hardness assumption from lattice cryptography whereas the previous\nwork relied on a newly introduced family of computational hardness assumptions.\nIn terms of computational effort, our construction only requires a small number\nof modular additions per input bit, whereas previously several exponentiations\nper bit as well as the interpolation and evaluation of high-degree polynomials\nover large fields were required. An additional benefit of our construction is\nthat the description of the hash function can be compressed to \\(\\lambda\\) bits\nassuming a random oracle. Previous work has descriptions of length\n\\(\\mathcal{O}(\\ell \\lambda)\\) bits for input bit-length \\(\\ell\\), which has a\nsecret structure and thus cannot be compressed.\n  We prove a lower bound on the output size of any property-preserving hash\nfunction for the hamming distance predicate. The bound shows that the size of\nour hash value is not far from optimal.</p>\n", "tags": ["Hashing Methods", "Evaluation", "Robustness"], "tsne_embedding": [-3.9236884117126465, -26.95293426513672], "cluster": 5}, {"key": "fleischhacker2023invertible", "year": "2023", "citations": "144", "title": "Invertible Bloom Lookup Tables With Less Memory And Randomness", "abstract": "<p>In this work we study Invertible Bloom Lookup Tables (IBLTs) with small\nfailure probabilities. IBLTs are highly versatile data structures that have\nfound applications in set reconciliation protocols, error-correcting codes, and\neven the design of advanced cryptographic primitives. For storing \\(n\\) elements\nand ensuring correctness with probability at least \\(1 - \\delta\\), existing IBLT\nconstructions require \\(\u03a9(n(\\frac{log(1/\\delta)}{log(n)}+1))\\) space and\nthey crucially rely on fully random hash functions.\n  We present new constructions of IBLTs that are simultaneously more space\nefficient and require less randomness. For storing \\(n\\) elements with a failure\nprobability of at most \\(\\delta\\), our data structure only requires\n\\(\\mathcal{O}\\left(n + log(1/\\delta)loglog(1/\\delta)\\right)\\) space and\n\\(\\mathcal{O}\\left(log(log(n)/\\delta)\\right)\\)-wise independent hash functions.\n  As a key technical ingredient we show that hashing \\(n\\) keys with any \\(k\\)-wise\nindependent hash function \\(h:U \\to [Cn]\\) for some sufficiently large constant\n\\(C\\) guarantees with probability \\(1 - 2^{-\u03a9(k)}\\) that at least \\(n/2\\) keys\nwill have a unique hash value. Proving this is non-trivial as \\(k\\) approaches\n\\(n\\). We believe that the techniques used to prove this statement may be of\nindependent interest.\n  We apply our new IBLTs to the encrypted compression problem, recently studied\nby Fleischhacker, Larsen, Simkin (Eurocrypt 2023). We extend their approach to\nwork for a more general class of encryption schemes and using our new IBLT we\nachieve an asymptotically better compression rate.</p>\n", "tags": ["Hashing Methods"], "tsne_embedding": [-4.16929817199707, -27.54347801208496], "cluster": 5}, {"key": "frady2020neuromorphic", "year": "2020", "citations": "47", "title": "Neuromorphic Nearest-neighbor Search Using Intel's Pohoiki Springs", "abstract": "<p>Neuromorphic computing applies insights from neuroscience to uncover\ninnovations in computing technology. In the brain, billions of interconnected\nneurons perform rapid computations at extremely low energy levels by leveraging\nproperties that are foreign to conventional computing systems, such as temporal\nspiking codes and finely parallelized processing units integrating both memory\nand computation. Here, we showcase the Pohoiki Springs neuromorphic system, a\nmesh of 768 interconnected Loihi chips that collectively implement 100 million\nspiking neurons in silicon. We demonstrate a scalable approximate k-nearest\nneighbor (k-NN) algorithm for searching large databases that exploits\nneuromorphic principles. Compared to state-of-the-art conventional CPU-based\nimplementations, we achieve superior latency, index build time, and energy\nefficiency when evaluated on several standard datasets containing over 1\nmillion high-dimensional patterns. Further, the system supports adding new data\npoints to the indexed database online in O(1) time unlike all but brute force\nconventional k-NN implementations.</p>\n", "tags": ["DATASETS", "Tools & Libraries", "Efficiency And Optimization"], "tsne_embedding": [17.457963943481445, 23.466581344604492], "cluster": 0}, {"key": "francislandau2019exact", "year": "2019", "citations": "85", "title": "Exact And/or Fast Nearest Neighbors", "abstract": "<p>Prior methods for retrieval of nearest neighbors in high dimensions are fast\nand approximate\u2013providing probabilistic guarantees of returning the correct\nanswer\u2013or slow and exact performing an exhaustive search. We present Certified\nCosine, a novel approach to nearest-neighbors which takes advantage of\nstructure present in the cosine similarity distance metric to offer\ncertificates. When a certificate is constructed, it guarantees that the nearest\nneighbor set is correct, possibly avoiding an exhaustive search. Certified\nCosine\u2019s certificates work with high dimensional data and outperform previous\nexact nearest neighbor methods on these datasets.</p>\n", "tags": ["CVPR", "DATASETS", "Graph Based ANN", "Distance Metric Learning"], "tsne_embedding": [16.090234756469727, -13.340121269226074], "cluster": 2}, {"key": "fredriksson2016geometric", "year": "2016", "citations": "6", "title": "Geometric Near-neighbor Access Tree (GNAT) Revisited", "abstract": "<p>Geometric Near-neighbor Access Tree (GNAT) is a metric space indexing method\nbased on hierarchical hyperplane partitioning of the space. While GNAT is very\nefficient in proximity searching, it has a bad reputation of being a memory\nhog. We show that this is partially based on too coarse analysis, and that the\nmemory requirements can be lowered while at the same time improving the search\nefficiency. We also show how to make GNAT memory adaptive in a smooth way, and\nthat the hyperplane partitioning can be replaced with ball partitioning, which\ncan further improve the search performance. We conclude with experimental\nresults showing the new methods can give significant performance boost.</p>\n", "tags": ["Evaluation", "Efficiency And Optimization"], "tsne_embedding": [19.728708267211914, 3.614570140838623], "cluster": 7}, {"key": "freksen2018fully", "year": "2018", "citations": "11", "title": "Fully Understanding The Hashing Trick", "abstract": "<p>Feature hashing, also known as {\\em the hashing trick}, introduced by\nWeinberger et al. (2009), is one of the key techniques used in scaling-up\nmachine learning algorithms. Loosely speaking, feature hashing uses a random\nsparse projection matrix \\(A : \\mathbb{R}^n \\to \\mathbb{R}^m\\) (where \\(m \\ll n\\))\nin order to reduce the dimension of the data from \\(n\\) to \\(m\\) while\napproximately preserving the Euclidean norm. Every column of \\(A\\) contains\nexactly one non-zero entry, equals to either \\(-1\\) or \\(1\\).\n  Weinberger et al. showed tail bounds on \\(|Ax|<em>2^2\\). Specifically they\nshowed that for every \\(\\epsilon, \\delta\\), if \\(|x|</em>{\\infty} / |x|<em>2\\) is\nsufficiently small, and \\(m\\) is sufficiently large, then $\\(\\Pr[ \\; |\n\\;|Ax|_2^2 - |x|_2^2\\; | &lt; \\epsilon |x|_2^2 \\;] \\ge 1 - \\delta \\;.\\)\\(\nThese bounds were later extended by Dasgupta \\etal (2010) and most recently\nrefined by Dahlgaard et al. (2017), however, the true nature of the performance\nof this key technique, and specifically the correct tradeoff between the\npivotal parameters \\)|x|</em>{\\infty} / |x|_2, m, \\epsilon, \\delta\\( remained\nan open question.\n  We settle this question by giving tight asymptotic bounds on the exact\ntradeoff between the central parameters, thus providing a complete\nunderstanding of the performance of feature hashing. We complement the\nasymptotic bound with empirical data, which shows that the constants \u201chiding\u201d\nin the asymptotic notation are, in fact, very close to \\)1$, thus further\nillustrating the tightness of the presented bounds in practice.</p>\n", "tags": ["Hashing Methods", "Evaluation"], "tsne_embedding": [32.308998107910156, 0.3054375648498535], "cluster": 7}, {"key": "fu2016auto", "year": "2016", "citations": "220", "title": "Auto-jacobin: Auto-encoder Jacobian Binary Hashing", "abstract": "<p>Binary codes can be used to speed up nearest neighbor search tasks in large\nscale data sets as they are efficient for both storage and retrieval. In this\npaper, we propose a robust auto-encoder model that preserves the geometric\nrelationships of high-dimensional data sets in Hamming space. This is done by\nconsidering a noise-removing function in a region surrounding the manifold\nwhere the training data points lie. This function is defined with the property\nthat it projects the data points near the manifold into the manifold wisely,\nand we approximate this function by its first order approximation. Experimental\nresults show that the proposed method achieves better than state-of-the-art\nresults on three large scale high dimensional data sets.</p>\n", "tags": ["Compact Codes", "Hashing Methods"], "tsne_embedding": [24.758426666259766, -8.41102123260498], "cluster": 7}, {"key": "fu2016efanna", "year": "2016", "citations": "65", "title": "EFANNA : An Extremely Fast Approximate Nearest Neighbor Search Algorithm Based On Knn Graph", "abstract": "<p>Approximate nearest neighbor (ANN) search is a fundamental problem in many\nareas of data mining, machine learning and computer vision. The performance of\ntraditional hierarchical structure (tree) based methods decreases as the\ndimensionality of data grows, while hashing based methods usually lack\nefficiency in practice. Recently, the graph based methods have drawn\nconsiderable attention. The main idea is that <em>a neighbor of a neighbor is\nalso likely to be a neighbor</em>, which we refer as <em>NN-expansion</em>. These\nmethods construct a \\(k\\)-nearest neighbor (\\(k\\)NN) graph offline. And at online\nsearch stage, these methods find candidate neighbors of a query point in some\nway (\\eg, random selection), and then check the neighbors of these candidate\nneighbors for closer ones iteratively. Despite some promising results, there\nare mainly two problems with these approaches: 1) These approaches tend to\nconverge to local optima. 2) Constructing a \\(k\\)NN graph is time consuming. We\nfind that these two problems can be nicely solved when we provide a good\ninitialization for NN-expansion. In this paper, we propose EFANNA, an extremely\nfast approximate nearest neighbor search algorithm based on \\(k\\)NN Graph. Efanna\nnicely combines the advantages of hierarchical structure based methods and\nnearest-neighbor-graph based methods. Extensive experiments have shown that\nEFANNA outperforms the state-of-art algorithms both on approximate nearest\nneighbor search and approximate nearest neighbor graph construction. To the\nbest of our knowledge, EFANNA is the fastest algorithm so far both on\napproximate nearest neighbor graph construction and approximate nearest\nneighbor search. A library EFANNA based on this research is released on Github.</p>\n", "tags": ["Hashing Methods", "Graph Based ANN", "Efficiency And Optimization", "Tools & Libraries", "Evaluation"], "tsne_embedding": [19.090242385864258, 13.822340965270996], "cluster": 0}, {"key": "fu2016improved", "year": "2016", "citations": "5", "title": "An Improved System For Sentence-level Novelty Detection In Textual Streams", "abstract": "<p>Novelty detection in news events has long been a difficult problem. A number\nof models performed well on specific data streams but certain issues are far\nfrom being solved, particularly in large data streams from the WWW where\nunpredictability of new terms requires adaptation in the vector space model. We\npresent a novel event detection system based on the Incremental Term\nFrequency-Inverse Document Frequency (TF-IDF) weighting incorporated with\nLocality Sensitive Hashing (LSH). Our system could efficiently and effectively\nadapt to the changes within the data streams of any new terms with continual\nupdates to the vector space model. Regarding miss probability, our proposed\nnovelty detection framework outperforms a recognised baseline system by\napproximately 16% when evaluating a benchmark dataset from Google News.</p>\n", "tags": ["Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-21.123027801513672, -13.836851119995117], "cluster": 1}, {"key": "fu2017fast", "year": "2017", "citations": "219", "title": "Fast Approximate Nearest Neighbor Search With The Navigating Spreading-out Graph", "abstract": "<p>Approximate nearest neighbor search (ANNS) is a fundamental problem in databases and data mining. A scalable ANNS algorithm should be both memory-efficient and fast. Some early graph-based approaches have shown attractive theoretical guarantees on search time complexity, but they all suffer from the problem of high indexing time complexity. Recently, some graph-based methods have been proposed to reduce indexing complexity by approximating the traditional graphs; these methods have achieved revolutionary performance on million-scale datasets. Yet, they still can not scale to billion-node databases. In this paper, to further improve the search-efficiency and scalability of graph-based methods, we start by introducing four aspects: (1) ensuring the connectivity of the graph; (2) lowering the average out-degree of the graph for fast traversal; (3) shortening the search path; and (4) reducing the index size. Then, we propose a novel graph structure called Monotonic Relative Neighborhood Graph (MRNG) which guarantees very low search complexity (close to logarithmic time). To further lower the indexing complexity and make it practical for billion-node ANNS problems, we propose a novel graph structure named Navigating Spreading-out Graph (NSG) by approximating the MRNG. The NSG takes the four aspects into account simultaneously. Extensive experiments show that NSG outperforms all the existing algorithms significantly. In addition, NSG shows superior performance in the E-commercial search scenario of Taobao (Alibaba Group) and has been integrated into their search engine at billion-node scale.</p>\n", "tags": ["Graph Based ANN", "DATASETS", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [18.621532440185547, 14.1674165725708], "cluster": 0}, {"key": "fu2018neurons", "year": "2018", "citations": "6", "title": "Neurons Merging Layer: Towards Progressive Redundancy Reduction For Deep Supervised Hashing", "abstract": "<p>Deep supervised hashing has become an active topic in information retrieval.\nIt generates hashing bits by the output neurons of a deep hashing network.\nDuring binary discretization, there often exists much redundancy between\nhashing bits that degenerates retrieval performance in terms of both storage\nand accuracy. This paper proposes a simple yet effective Neurons Merging Layer\n(NMLayer) for deep supervised hashing. A graph is constructed to represent the\nredundancy relationship between hashing bits that is used to guide the learning\nof a hashing network. Specifically, it is dynamically learned by a novel\nmechanism defined in our active and frozen phases. According to the learned\nrelationship, the NMLayer merges the redundant neurons together to balance the\nimportance of each output neuron. Moreover, multiple NMLayers are progressively\ntrained for a deep hashing network to learn a more compact hashing code from a\nlong redundant code. Extensive experiments on four datasets demonstrate that\nour proposed method outperforms state-of-the-art hashing methods.</p>\n", "tags": ["DATASETS", "Evaluation", "IJCAI", "Neural Hashing", "Hashing Methods", "AAAI"], "tsne_embedding": [-3.022395133972168, -14.343120574951172], "cluster": 9}, {"key": "fu2019high", "year": "2019", "citations": "30", "title": "High Dimensional Similarity Search With Satellite System Graph: Efficiency, Scalability, And Unindexed Query Compatibility", "abstract": "<p>Approximate Nearest Neighbor Search (ANNS) in high dimensional space is\nessential in database and information retrieval. Recently, there has been a\nsurge of interest in exploring efficient graph-based indices for the ANNS\nproblem. Among them, Navigating Spreading-out Graph (NSG) provides fine\ntheoretical analysis and achieves state-of-the-art performance. However, we\nfind there are several limitations with NSG: 1) NSG has no theoretical\nguarantee on nearest neighbor search when the query is not indexed in the\ndatabase; 2) NSG is too sparse which harms the search performance. In addition,\nNSG suffers from high indexing complexity. To address the above problems, we\npropose the Satellite System Graphs (SSG) and a practical variant NSSG.\nSpecifically, we propose a novel pruning strategy to produce SSGs from the\ncomplete graph. SSGs define a new family of MSNETs in which the out-edges of\neach node are distributed evenly in all directions. Each node in the graph\nbuilds effective connections to its neighborhood omnidirectionally, whereupon\nwe derive SSG\u2019s excellent theoretical properties for both indexed and unindexed\nqueries. We can adaptively adjust the sparsity of an SSG with a hyper-parameter\nto optimize the search performance. Further, NSSG is proposed to reduce the\nindexing complexity of the SSG for large-scale applications. Both theoretical\nand extensive experimental analyses are provided to demonstrate the strengths\nof the proposed approach over the existing representative algorithms. Our code\nhas been released at https://github.com/ZJULearning/SSG.</p>\n", "tags": ["Graph Based ANN", "Similarity Search", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [19.553274154663086, 15.748074531555176], "cluster": 0}, {"key": "fu2020deep", "year": "2020", "citations": "15", "title": "Deep Momentum Uncertainty Hashing", "abstract": "<p>Combinatorial optimization (CO) has been a hot research topic because of its\ntheoretic and practical importance. As a classic CO problem, deep hashing aims\nto find an optimal code for each data from finite discrete possibilities, while\nthe discrete nature brings a big challenge to the optimization process.\nPrevious methods usually mitigate this challenge by binary approximation,\nsubstituting binary codes for real-values via activation functions or\nregularizations. However, such approximation leads to uncertainty between\nreal-values and binary ones, degrading retrieval performance. In this paper, we\npropose a novel Deep Momentum Uncertainty Hashing (DMUH). It explicitly\nestimates the uncertainty during training and leverages the uncertainty\ninformation to guide the approximation process. Specifically, we model\nbit-level uncertainty via measuring the discrepancy between the output of a\nhashing network and that of a momentum-updated network. The discrepancy of each\nbit indicates the uncertainty of the hashing network to the approximate output\nof that bit. Meanwhile, the mean discrepancy of all bits in a hashing code can\nbe regarded as image-level uncertainty. It embodies the uncertainty of the\nhashing network to the corresponding input image. The hashing bit and image\nwith higher uncertainty are paid more attention during optimization. To the\nbest of our knowledge, this is the first work to study the uncertainty in\nhashing bits. Extensive experiments are conducted on four datasets to verify\nthe superiority of our method, including CIFAR-10, NUS-WIDE, MS-COCO, and a\nmillion-scale dataset Clothing1M. Our method achieves the best performance on\nall of the datasets and surpasses existing state-of-the-art methods by a large\nmargin.</p>\n", "tags": ["DATASETS", "Hashing Methods", "CVPR", "Compact Codes", "Neural Hashing", "Evaluation"], "tsne_embedding": [-15.592700004577637, -7.315598487854004], "cluster": 1}, {"key": "gajic2019bag", "year": "2019", "citations": "5", "title": "Bag Of Negatives For Siamese Architectures", "abstract": "<p>Training a Siamese architecture for re-identification with a large number of\nidentities is a challenging task due to the difficulty of finding relevant\nnegative samples efficiently. In this work we present Bag of Negatives (BoN), a\nmethod for accelerated and improved training of Siamese networks that scales\nwell on datasets with a very large number of identities. BoN is an efficient\nand loss-independent method, able to select a bag of high quality negatives,\nbased on a novel online hashing strategy.</p>\n", "tags": ["DATASETS", "Hashing Methods"], "tsne_embedding": [7.157320976257324, -10.766419410705566], "cluster": 2}, {"key": "gan2023binary", "year": "2023", "citations": "7", "title": "Binary Embedding-based Retrieval At Tencent", "abstract": "<p>Large-scale embedding-based retrieval (EBR) is the cornerstone of\nsearch-related industrial applications. Given a user query, the system of EBR\naims to identify relevant information from a large corpus of documents that may\nbe tens or hundreds of billions in size. The storage and computation turn out\nto be expensive and inefficient with massive documents and high concurrent\nqueries, making it difficult to further scale up. To tackle the challenge, we\npropose a binary embedding-based retrieval (BEBR) engine equipped with a\nrecurrent binarization algorithm that enables customized bits per dimension.\nSpecifically, we compress the full-precision query and document embeddings,\nformulated as float vectors in general, into a composition of multiple binary\nvectors using a lightweight transformation model with residual multilayer\nperception (MLP) blocks. We can therefore tailor the number of bits for\ndifferent applications to trade off accuracy loss and cost savings.\nImportantly, we enable task-agnostic efficient training of the binarization\nmodel using a new embedding-to-embedding strategy. We also exploit the\ncompatible training of binary embeddings so that the BEBR engine can support\nindexing among multiple embedding versions within a unified system. To further\nrealize efficient search, we propose Symmetric Distance Calculation (SDC) to\nachieve lower response time than Hamming codes. We successfully employed the\nintroduced BEBR to Tencent products, including Sogou, Tencent Video, QQ World,\netc. The binarization algorithm can be seamlessly generalized to various tasks\nwith multiple modalities. Extensive experiments on offline benchmarks and\nonline A/B tests demonstrate the efficiency and effectiveness of our method,\nsignificantly saving 30%~50% index costs with almost no loss of accuracy at the\nsystem level.</p>\n", "tags": ["KDD", "Hashing Methods", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [4.850466251373291, -1.4899109601974487], "cluster": 4}, {"key": "gao2019beyond", "year": "2019", "citations": "28", "title": "Beyond Product Quantization: Deep Progressive Quantization For Image Retrieval", "abstract": "<p>Product Quantization (PQ) has long been a mainstream for generating an\nexponentially large codebook at very low memory/time cost. Despite its success,\nPQ is still tricky for the decomposition of high-dimensional vector space, and\nthe retraining of model is usually unavoidable when the code length changes. In\nthis work, we propose a deep progressive quantization (DPQ) model, as an\nalternative to PQ, for large scale image retrieval. DPQ learns the quantization\ncodes sequentially and approximates the original feature space progressively.\nTherefore, we can train the quantization codes with different code lengths\nsimultaneously. Specifically, we first utilize the label information for\nguiding the learning of visual features, and then apply several quantization\nblocks to progressively approach the visual features. Each quantization block\nis designed to be a layer of a convolutional neural network, and the whole\nframework can be trained in an end-to-end manner. Experimental results on the\nbenchmark datasets show that our model significantly outperforms the\nstate-of-the-art for image retrieval. Our model is trained once for different\ncode lengths and therefore requires less computation time. Additional ablation\nstudy demonstrates the effect of each component of our proposed model. Our code\nis released at https://github.com/cfm-uestc/DPQ.</p>\n", "tags": ["DATASETS", "Evaluation", "IJCAI", "Quantization", "AAAI", "Image Retrieval", "Tools & Libraries", "Alt"], "tsne_embedding": [-19.460134506225586, 0.2500840127468109], "cluster": 3}, {"key": "gao2022long", "year": "2022", "citations": "5", "title": "Long-tail Cross Modal Hashing", "abstract": "<p>Existing Cross Modal Hashing (CMH) methods are mainly designed for balanced\ndata, while imbalanced data with long-tail distribution is more general in\nreal-world. Several long-tail hashing methods have been proposed but they can\nnot adapt for multi-modal data, due to the complex interplay between labels and\nindividuality and commonality information of multi-modal data. Furthermore, CMH\nmethods mostly mine the commonality of multi-modal data to learn hash codes,\nwhich may override tail labels encoded by the individuality of respective\nmodalities. In this paper, we propose LtCMH (Long-tail CMH) to handle\nimbalanced multi-modal data. LtCMH firstly adopts auto-encoders to mine the\nindividuality and commonality of different modalities by minimizing the\ndependency between the individuality of respective modalities and by enhancing\nthe commonality of these modalities. Then it dynamically combines the\nindividuality and commonality with direct features extracted from respective\nmodalities to create meta features that enrich the representation of tail\nlabels, and binaries meta features to generate hash codes. LtCMH significantly\noutperforms state-of-the-art baselines on long-tail datasets and holds a better\n(or comparable) performance on datasets with balanced labels.</p>\n", "tags": ["AAAI", "DATASETS", "Hashing Methods", "Evaluation"], "tsne_embedding": [-2.8869357109069824, -3.3036046028137207], "cluster": 9}, {"key": "gao2023high", "year": "2023", "citations": "24", "title": "High-dimensional Approximate Nearest Neighbor Search: With Reliable And Efficient Distance Comparison Operations", "abstract": "<p>Approximate K nearest neighbor (AKNN) search is a fundamental and challenging\nproblem. We observe that in high-dimensional space, the time consumption of\nnearly all AKNN algorithms is dominated by that of the distance comparison\noperations (DCOs). For each operation, it scans full dimensions of an object\nand thus, runs in linear time wrt the dimensionality. To speed it up, we\npropose a randomized algorithm named ADSampling which runs in logarithmic time\nwrt to the dimensionality for the majority of DCOs and succeeds with high\nprobability. In addition, based on ADSampling we develop one general and two\nalgorithm-specific techniques as plugins to enhance existing AKNN algorithms.\nBoth theoretical and empirical studies confirm that: (1) our techniques\nintroduce nearly no accuracy loss and (2) they consistently improve the\nefficiency.</p>\n", "tags": ["Evaluation", "Efficiency And Optimization"], "tsne_embedding": [17.48295021057129, -5.034788608551025], "cluster": 2}, {"key": "gao2024rabitq", "year": "2024", "citations": "15", "title": "Rabitq: Quantizing High-dimensional Vectors With A Theoretical Error Bound For Approximate Nearest Neighbor Search", "abstract": "<p>Searching for approximate nearest neighbors (ANN) in the high-dimensional\nEuclidean space is a pivotal problem. Recently, with the help of fast\nSIMD-based implementations, Product Quantization (PQ) and its variants can\noften efficiently and accurately estimate the distances between the vectors and\nhave achieved great success in the in-memory ANN search. Despite their\nempirical success, we note that these methods do not have a theoretical error\nbound and are observed to fail disastrously on some real-world datasets.\nMotivated by this, we propose a new randomized quantization method named\nRaBitQ, which quantizes \\(D\\)-dimensional vectors into \\(D\\)-bit strings. RaBitQ\nguarantees a sharp theoretical error bound and provides good empirical accuracy\nat the same time. In addition, we introduce efficient implementations of\nRaBitQ, supporting to estimate the distances with bitwise operations or\nSIMD-based operations. Extensive experiments on real-world datasets confirm\nthat (1) our method outperforms PQ and its variants in terms of\naccuracy-efficiency trade-off by a clear margin and (2) its empirical\nperformance is well-aligned with our theoretical analysis.</p>\n", "tags": ["DATASETS", "Efficiency And Optimization", "Similarity Search", "Quantization", "Evaluation"], "tsne_embedding": [21.454557418823242, -7.27697229385376], "cluster": 7}, {"key": "garcia2008fast", "year": "2008", "citations": "444", "title": "Fast K Nearest Neighbor Search Using GPU", "abstract": "<p>The recent improvements of graphics processing units (GPU) offer to the\ncomputer vision community a powerful processing platform. Indeed, a lot of\nhighly-parallelizable computer vision problems can be significantly accelerated\nusing GPU architecture. Among these algorithms, the k nearest neighbor search\n(KNN) is a well-known problem linked with many applications such as\nclassification, estimation of statistical properties, etc. The main drawback of\nthis task lies in its computation burden, as it grows polynomially with the\ndata size. In this paper, we show that the use of the NVIDIA CUDA API\naccelerates the search for the KNN up to a factor of 120.</p>\n", "tags": ["CVPR", "Tools & Libraries"], "tsne_embedding": [17.19125747680664, 21.536582946777344], "cluster": 0}, {"key": "garciamorato2024parametrizable", "year": "2024", "citations": "37", "title": "A Parametrizable Algorithm For Distributed Approximate Similarity Search With Arbitrary Distances", "abstract": "<p>Recent studies have explored alternative distance measures for similarity\nsearch in spaces with diverse topologies, emphasizing the importance of\nselecting an appropriate distance function to improve the performance of\nk-Nearest Neighbour search algorithms. However, a critical gap remains in\naccommodating such diverse similarity measures, as most existing methods for\nexact or approximate similarity search are explicitly designed for metric\nspaces.\n  To address this need, we propose PDASC (Parametrizable Distributed\nApproximate Similarity Search with Clustering), a novel Approximate Nearest\nNeighbour search algorithm. PDASC combines an innovative multilevel indexing\nstructure particularly adept at managing outliers, highly imbalanced datasets,\nand sparse data distributions, with the flexibility to support arbitrary\ndistance functions achieved through the integration of clustering algorithms\nthat inherently accommodate them.\n  Experimental results show that PDASC constitutes a reliable ANN search\nmethod, suitable for operating in distributed data environments and for\nhandling datasets defined in different topologies, where the selection of the\nmost appropriate distance function is often non-trivial.</p>\n", "tags": ["Alt", "Similarity Search", "Evaluation", "DATASETS"], "tsne_embedding": [10.996355056762695, 4.400726795196533], "cluster": 4}, {"key": "garg2017kernelized", "year": "2017", "citations": "8", "title": "Kernelized Hashcode Representations For Relation Extraction", "abstract": "<p>Kernel methods have produced state-of-the-art results for a number of NLP\ntasks such as relation extraction, but suffer from poor scalability due to the\nhigh cost of computing kernel similarities between natural language structures.\nA recently proposed technique, kernelized locality-sensitive hashing (KLSH),\ncan significantly reduce the computational cost, but is only applicable to\nclassifiers operating on kNN graphs. Here we propose to use random subspaces of\nKLSH codes for efficiently constructing an explicit representation of NLP\nstructures suitable for general classification methods. Further, we propose an\napproach for optimizing the KLSH model for classification problems by\nmaximizing an approximation of mutual information between the KLSH codes\n(feature vectors) and the class labels. We evaluate the proposed approach on\nbiomedical relation extraction datasets, and observe significant and robust\nimprovements in accuracy w.r.t. state-of-the-art classifiers, along with\ndrastic (orders-of-magnitude) speedup compared to conventional kernel methods.</p>\n", "tags": ["AAAI", "Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Efficiency And Optimization"], "tsne_embedding": [-20.427433013916016, 18.834630966186523], "cluster": 3}, {"key": "garg2018stochastic", "year": "2018", "citations": "12", "title": "Stochastic Learning Of Nonstationary Kernels For Natural Language Modeling", "abstract": "<p>Natural language processing often involves computations with semantic or\nsyntactic graphs to facilitate sophisticated reasoning based on structural\nrelationships. While convolution kernels provide a powerful tool for comparing\ngraph structure based on node (word) level relationships, they are difficult to\ncustomize and can be computationally expensive. We propose a generalization of\nconvolution kernels, with a nonstationary model, for better expressibility of\nnatural languages in supervised settings. For a scalable learning of the\nparameters introduced with our model, we propose a novel algorithm that\nleverages stochastic sampling on k-nearest neighbor graphs, along with\napproximations based on locality-sensitive hashing. We demonstrate the\nadvantages of our approach on a challenging real-world (structured inference)\nproblem of automatically extracting biological models from the text of\nscientific papers.</p>\n", "tags": ["ACL", "NAACL", "Hashing Methods"], "tsne_embedding": [19.614765167236328, -16.50938606262207], "cluster": 2}, {"key": "garg2020fast", "year": "2020", "citations": "14", "title": "Fast, Compact And Highly Scalable Visual Place Recognition Through Sequence-based Matching Of Overloaded Representations", "abstract": "<p>Visual place recognition algorithms trade off three key characteristics:\ntheir storage footprint, their computational requirements, and their resultant\nperformance, often expressed in terms of recall rate. Significant prior work\nhas investigated highly compact place representations, sub-linear computational\nscaling and sub-linear storage scaling techniques, but have always involved a\nsignificant compromise in one or more of these regards, and have only been\ndemonstrated on relatively small datasets. In this paper we present a novel\nplace recognition system which enables for the first time the combination of\nultra-compact place representations, near sub-linear storage scaling and\nextremely lightweight compute requirements. Our approach exploits the\ninherently sequential nature of much spatial data in the robotics domain and\ninverts the typical target criteria, through intentionally coarse scalar\nquantization-based hashing that leads to more collisions but is resolved by\nsequence-based matching. For the first time, we show how effective place\nrecognition rates can be achieved on a new very large 10 million place dataset,\nrequiring only 8 bytes of storage per place and 37K unitary operations to\nachieve over 50% recall for matching a sequence of 100 frames, where a\nconventional state-of-the-art approach both consumes 1300 times more compute\nand fails catastrophically. We present analysis investigating the effectiveness\nof our hashing overload approach under varying sizes of quantized vector\nlength, comparison of near miss matches with the actual match selections and\ncharacterise the effect of variance re-scaling of data on quantization.</p>\n", "tags": ["DATASETS", "Evaluation", "Quantization", "ICRA", "Hashing Methods"], "tsne_embedding": [-5.60644006729126, -21.029125213623047], "cluster": 5}, {"key": "gattupalli2018weakly", "year": "2018", "citations": "42", "title": "Weakly Supervised Deep Image Hashing Through Tag Embeddings", "abstract": "<p>Many approaches to semantic image hashing have been formulated as supervised\nlearning problems that utilize images and label information to learn the binary\nhash codes. However, large-scale labeled image data is expensive to obtain,\nthus imposing a restriction on the usage of such algorithms. On the other hand,\nunlabelled image data is abundant due to the existence of many Web image\nrepositories. Such Web images may often come with images tags that contain\nuseful information, although raw tags, in general, do not readily lead to\nsemantic labels. Motivated by this scenario, we formulate the problem of\nsemantic image hashing as a weakly-supervised learning problem. We utilize the\ninformation contained in the user-generated tags associated with the images to\nlearn the hash codes. More specifically, we extract the word2vec semantic\nembeddings of the tags and use the information contained in them for\nconstraining the learning. Accordingly, we name our model Weakly Supervised\nDeep Hashing using Tag Embeddings (WDHT). WDHT is tested for the task of\nsemantic image retrieval and is compared against several state-of-art models.\nResults show that our approach sets a new state-of-art in the area of weekly\nsupervised image hashing.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "CVPR", "Alt", "Neural Hashing"], "tsne_embedding": [-9.126675605773926, -4.6133036613464355], "cluster": 9}, {"key": "ge2025graph", "year": "2025", "citations": "69", "title": "Graph Cuts For Supervised Binary Coding", "abstract": "<p>Learning short binary codes is challenged by the inherent discrete\nnature of the problem. The graph cuts algorithm is a well-studied\ndiscrete label assignment solution in computer vision, but has not yet\nbeen applied to solve the binary coding problems. This is partially because\nit was unclear how to use it to learn the encoding (hashing) functions\nfor out-of-sample generalization. In this paper, we formulate supervised\nbinary coding as a single optimization problem that involves both\nthe encoding functions and the binary label assignment. Then we apply\nthe graph cuts algorithm to address the discrete optimization problem\ninvolved, with no continuous relaxation. This method, named as Graph\nCuts Coding (GCC), shows competitive results in various datasets.</p>\n", "tags": ["Compact Codes", "DATASETS", "Hashing Methods"], "tsne_embedding": [16.35500717163086, 11.318880081176758], "cluster": 0}, {"key": "gebre2024pfeed", "year": "2024", "citations": "30", "title": "Pfeed: Generating Near Real-time Personalized Feeds Using Precomputed Embedding Similarities", "abstract": "<p>In personalized recommender systems, embeddings are often used to encode\ncustomer actions and items, and retrieval is then performed in the embedding\nspace using approximate nearest neighbor search. However, this approach can\nlead to two challenges: 1) user embeddings can restrict the diversity of\ninterests captured and 2) the need to keep them up-to-date requires an\nexpensive, real-time infrastructure. In this paper, we propose a method that\novercomes these challenges in a practical, industrial setting. The method\ndynamically updates customer profiles and composes a feed every two minutes,\nemploying precomputed embeddings and their respective similarities. We tested\nand deployed this method to personalise promotional items at Bol, one of the\nlargest e-commerce platforms of the Netherlands and Belgium. The method\nenhanced customer engagement and experience, leading to a significant 4.9%\nuplift in conversions.</p>\n", "tags": ["Recommender Systems"], "tsne_embedding": [-21.821121215820312, 11.888411521911621], "cluster": 3}, {"key": "gehrig2016visual", "year": "2016", "citations": "36", "title": "Visual Place Recognition With Probabilistic Vertex Voting", "abstract": "<p>We propose a novel scoring concept for visual place recognition based on\nnearest neighbor descriptor voting and demonstrate how the algorithm naturally\nemerges from the problem formulation. Based on the observation that the number\nof votes for matching places can be evaluated using a binomial distribution\nmodel, loop closures can be detected with high precision. By casting the\nproblem into a probabilistic framework, we not only remove the need for\ncommonly employed heuristic parameters but also provide a powerful score to\nclassify matching and non-matching places. We present methods for both a 2D-2D\npose-graph vertex matching and a 2D-3D landmark matching based on the above\nscoring. The approach maintains accuracy while being efficient enough for\nonline application through the use of compact (low dimensional) descriptors and\nfast nearest neighbor retrieval techniques. The proposed methods are evaluated\non several challenging datasets in varied environments, showing\nstate-of-the-art results with high precision and high recall.</p>\n", "tags": ["DATASETS", "Tools & Libraries", "Evaluation", "ICRA"], "tsne_embedding": [13.660597801208496, 7.981267929077148], "cluster": 0}, {"key": "genuzio2016fast", "year": "2016", "citations": "19", "title": "Fast Scalable Construction Of (minimal Perfect Hash) Functions", "abstract": "<p>Recent advances in random linear systems on finite fields have paved the way\nfor the construction of constant-time data structures representing static\nfunctions and minimal perfect hash functions using less space with respect to\nexisting techniques. The main obstruction for any practical application of\nthese results is the cubic-time Gaussian elimination required to solve these\nlinear systems: despite they can be made very small, the computation is still\ntoo slow to be feasible.\n  In this paper we describe in detail a number of heuristics and programming\ntechniques to speed up the resolution of these systems by several orders of\nmagnitude, making the overall construction competitive with the standard and\nwidely used MWHC technique, which is based on hypergraph peeling. In\nparticular, we introduce broadword programming techniques for fast equation\nmanipulation and a lazy Gaussian elimination algorithm. We also describe a\nnumber of technical improvements to the data structure which further reduce\nspace usage and improve lookup speed.\n  Our implementation of these techniques yields a minimal perfect hash function\ndata structure occupying 2.24 bits per element, compared to 2.68 for MWHC-based\nones, and a static function data structure which reduces the multiplicative\noverhead from 1.23 to 1.03.</p>\n", "tags": ["Hashing Methods"], "tsne_embedding": [1.4405440092086792, -10.2510347366333], "cluster": 9}, {"key": "ghaemmaghami2022learning", "year": "2022", "citations": "6", "title": "Learning To Collide: Recommendation System Model Compression With Learned Hash Functions", "abstract": "<p>A key characteristic of deep recommendation models is the immense memory\nrequirements of their embedding tables. These embedding tables can often reach\nhundreds of gigabytes which increases hardware requirements and training cost.\nA common technique to reduce model size is to hash all of the categorical\nvariable identifiers (ids) into a smaller space. This hashing reduces the\nnumber of unique representations that must be stored in the embedding table;\nthus decreasing its size. However, this approach introduces collisions between\nsemantically dissimilar ids that degrade model quality. We introduce an\nalternative approach, Learned Hash Functions, which instead learns a new\nmapping function that encourages collisions between semantically similar ids.\nWe derive this learned mapping from historical data and embedding access\npatterns. We experiment with this technique on a production model and find that\na mapping informed by the combination of access frequency and a learned low\ndimension embedding is the most effective. We demonstrate a small improvement\nrelative to the hashing trick and other collision related compression\ntechniques. This is ongoing work that explores the impact of categorical id\ncollisions on recommendation model quality and how those collisions may be\ncontrolled to improve model performance.</p>\n", "tags": ["Alt", "Hashing Methods", "Evaluation", "Recommender Systems"], "tsne_embedding": [5.616181373596191, -3.8828065395355225], "cluster": 4}, {"key": "giannella2009new", "year": "2009", "citations": "8", "title": "New Instability Results For High Dimensional Nearest Neighbor Search", "abstract": "<p>Consider a dataset of n(d) points generated independently from R^d according\nto a common p.d.f. f_d with support(f_d) = [0,1]^d and sup{f_d([0,1]^d)}\ngrowing sub-exponentially in d. We prove that: (i) if n(d) grows\nsub-exponentially in d, then, for any query point q^d in [0,1]^d and any\nepsilon&gt;0, the ratio of the distance between any two dataset points and q^d is\nless that 1+epsilon with probability \u2013&gt;1 as d\u2013&gt;infinity; (ii) if\nn(d)&gt;[4(1+epsilon)]^d for large d, then for all q^d in [0,1]^d (except a small\nsubset) and any epsilon&gt;0, the distance ratio is less than 1+epsilon with\nlimiting probability strictly bounded away from one. Moreover, we provide\npreliminary results along the lines of (i) when f_d=N(mu_d,Sigma_d).</p>\n", "tags": ["DATASETS"], "tsne_embedding": [26.78790283203125, -4.468111991882324], "cluster": 7}, {"key": "gillick2018end", "year": "2018", "citations": "81", "title": "End-to-end Retrieval In Continuous Space", "abstract": "<p>Most text-based information retrieval (IR) systems index objects by words or\nphrases. These discrete systems have been augmented by models that use\nembeddings to measure similarity in continuous space. But continuous-space\nmodels are typically used just to re-rank the top candidates. We consider the\nproblem of end-to-end continuous retrieval, where standard approximate nearest\nneighbor (ANN) search replaces the usual discrete inverted index, and rely\nentirely on distances between learned embeddings. By training simple models\nspecifically for retrieval, with an appropriate model architecture, we improve\non a discrete baseline by 8% and 26% (MAP) on two similar-question retrieval\ntasks. We also discuss the problem of evaluation for retrieval systems, and\nshow how to modify existing pairwise similarity datasets for this purpose.</p>\n", "tags": ["DATASETS", "Evaluation"], "tsne_embedding": [3.337533473968506, 3.6617867946624756], "cluster": 4}, {"key": "gillick2019learning", "year": "2019", "citations": "188", "title": "Learning Dense Representations For Entity Retrieval", "abstract": "<p>We show that it is feasible to perform entity linking by training a dual\nencoder (two-tower) model that encodes mentions and entities in the same dense\nvector space, where candidate entities are retrieved by approximate nearest\nneighbor search. Unlike prior work, this setup does not rely on an alias table\nfollowed by a re-ranker, and is thus the first fully learned entity retrieval\nmodel. We show that our dual encoder, trained using only anchor-text links in\nWikipedia, outperforms discrete alias table and BM25 baselines, and is\ncompetitive with the best comparable results on the standard TACKBP-2010\ndataset. In addition, it can retrieve candidates extremely fast, and\ngeneralizes well to a new dataset derived from Wikinews. On the modeling side,\nwe demonstrate the dramatic value of an unsupervised negative mining algorithm\nfor this task.</p>\n", "tags": ["DATASETS"], "tsne_embedding": [7.564670562744141, -10.479198455810547], "cluster": 2}, {"key": "gionis2025similarity", "year": "2025", "citations": "3205", "title": "Similarity Search In High Dimensions Via Hashing", "abstract": "<p>The nearest- or near-neighbor query problems arise in a large variety of database applications, usually in the context of similarity searching. Of late, there has been increasing interest in building search/index structures for performing similarity search over high-dimensional data, e.g., image databases, document collections, time-series databases, and genome databases. Unfortunately,\nall known techniques for solving this problem fall prey to the curse of dimensionality. That is, the data structures scale poorly with data dimensionality;\nin fact, if the number of dimensions exceeds 10 to 20, searching in k-d trees and related structures involves the inspection of a large fraction of the database, thereby doing no better than brute-force linear search. It has been suggested that since the selection of features and the choice of a distance metric in typical applications is rather heuristic, determining an approximate nearest neighbor should suffice for most practical purposes. In this paper, we examine a novel scheme for approximate similarity search based on hashing. The basic idea is to hash the points from the database so as to ensure that the probability of collision is much higher for objects that are close to each other than for those that are far apart. We provide experimental evidence that our\nmethod gives significant improvement in running time over other methods for searching in highdimensional spaces based on hierarchical tree decomposition.\nExperimental results also indicate that our scheme scales well even for a relatively large number of dimensions (more than 50).</p>\n", "tags": ["Hashing Methods", "Distance Metric Learning", "Similarity Search", "Tree Based ANN", "Vector Indexing"], "tsne_embedding": [12.512328147888184, 3.1503243446350098], "cluster": 4}, {"key": "giraud2019superpixel", "year": "2019", "citations": "6", "title": "Superpixel-based Color Transfer", "abstract": "<p>In this work, we propose a fast superpixel-based color transfer method (SCT)\nbetween two images. Superpixels enable to decrease the image dimension and to\nextract a reduced set of color candidates. We propose to use a fast approximate\nnearest neighbor matching algorithm in which we enforce the match diversity by\nlimiting the selection of the same superpixels. A fusion framework is designed\nto transfer the matched colors, and we demonstrate the improvement obtained\nover exact matching results. Finally, we show that SCT is visually competitive\ncompared to state-of-the-art methods.</p>\n", "tags": ["Tools & Libraries"], "tsne_embedding": [-0.010848009958863258, 7.762336730957031], "cluster": 4}, {"key": "gog2013large", "year": "2013", "citations": "21", "title": "Large-scale Pattern Search Using Reduced-space On-disk Suffix Arrays", "abstract": "<p>The suffix array is an efficient data structure for in-memory pattern search.\nSuffix arrays can also be used for external-memory pattern search, via\ntwo-level structures that use an internal index to identify the correct block\nof suffix pointers. In this paper we describe a new two-level suffix\narray-based index structure that requires significantly less disk space than\nprevious approaches. Key to the saving is the use of disk blocks that are based\non prefixes rather than the more usual uniform-sampling approach, allowing\nreductions between blocks and subparts of other blocks. We also describe a new\nin-memory structure based on a condensed BWT string, and show that it allows\ncommon patterns to be resolved without access to the text. Experiments using 64\nGB of English web text and a laptop computer with just 4 GB of main memory\ndemonstrate the speed and versatility of the new approach. For this data the\nindex is around one- third the size of previous two-level mechanisms; and the\nmemory footprint of as little as 1% of the text size means that queries can be\nprocessed more quickly than is possible with a compact FM-INDEX.</p>\n", "tags": ["Vector Indexing", "Efficiency And Optimization"], "tsne_embedding": [-8.91099739074707, -18.466999053955078], "cluster": 5}, {"key": "gong2022vit2hash", "year": "2022", "citations": "10", "title": "Vit2hash: Unsupervised Information-preserving Hashing", "abstract": "<p>Unsupervised image hashing, which maps images into binary codes without\nsupervision, is a compressor with a high compression rate. Hence, how to\npreserving meaningful information of the original data is a critical problem.\nInspired by the large-scale vision pre-training model, known as ViT, which has\nshown significant progress for learning visual representations, in this paper,\nwe propose a simple information-preserving compressor to finetune the ViT model\nfor the target unsupervised hashing task. Specifically, from pixels to\ncontinuous features, we first propose a feature-preserving module, using the\ncorrupted image as input to reconstruct the original feature from the\npre-trained ViT model and the complete image, so that the feature extractor can\nfocus on preserving the meaningful information of original data. Secondly, from\ncontinuous features to hash codes, we propose a hashing-preserving module,\nwhich aims to keep the semantic information from the pre-trained ViT model by\nusing the proposed Kullback-Leibler divergence loss. Besides, the quantization\nloss and the similarity loss are added to minimize the quantization error. Our\nmethod is very simple and achieves a significantly higher degree of MAP on\nthree benchmark image datasets.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Compact Codes", "Quantization", "Evaluation"], "tsne_embedding": [-10.96684455871582, 7.495413780212402], "cluster": 8}, {"key": "gong2025iterative", "year": "2025", "citations": "1834", "title": "Iterative Quantization: A Procrustean Approach To Learning Binary Codes", "abstract": "<p>This paper addresses the problem of learning similarity preserving binary codes for efficient retrieval in large-scale image collections. We propose a simple and efficient alternating minimization scheme for finding a rotation of zerocentered data so as to minimize the quantization error of\nmapping this data to the vertices of a zero-centered binary\nhypercube. This method, dubbed iterative quantization\n(ITQ), has connections to multi-class spectral clustering\nand to the orthogonal Procrustes problem, and it can be\nused both with unsupervised data embeddings such as PCA\nand supervised embeddings such as canonical correlation\nanalysis (CCA). Our experiments show that the resulting\nbinary coding schemes decisively outperform several other\nstate-of-the-art methods.</p>\n", "tags": ["Compact Codes", "Alt", "Similarity Search", "Quantization", "Evaluation"], "tsne_embedding": [-2.635636329650879, 8.936546325683594], "cluster": 8}, {"key": "gong2025learning", "year": "2025", "citations": "183", "title": "Learning Binary Codes For High-dimensional Data Using Bilinear Projections", "abstract": "<p>Recent advances in visual recognition indicate that to\nachieve good retrieval and classification accuracy on largescale\ndatasets like ImageNet, extremely high-dimensional\nvisual descriptors, e.g., Fisher Vectors, are needed. We\npresent a novel method for converting such descriptors to\ncompact similarity-preserving binary codes that exploits\ntheir natural matrix structure to reduce their dimensionality\nusing compact bilinear projections instead of a single\nlarge projection matrix. This method achieves comparable\nretrieval and classification accuracy to the original descriptors\nand to the state-of-the-art Product Quantization\napproach while having orders of magnitude faster code generation\ntime and smaller memory footprint.</p>\n", "tags": ["DATASETS", "Efficiency And Optimization", "CVPR", "Compact Codes", "Quantization"], "tsne_embedding": [-3.0129315853118896, 11.762565612792969], "cluster": 6}, {"key": "gordo2016end", "year": "2016", "citations": "532", "title": "End-to-end Learning Of Deep Visual Representations For Image Retrieval", "abstract": "<p>While deep learning has become a key ingredient in the top performing methods\nfor many computer vision tasks, it has failed so far to bring similar\nimprovements to instance-level image retrieval. In this article, we argue that\nreasons for the underwhelming results of deep methods on image retrieval are\nthreefold: i) noisy training data, ii) inappropriate deep architecture, and\niii) suboptimal training procedure. We address all three issues.\n  First, we leverage a large-scale but noisy landmark dataset and develop an\nautomatic cleaning method that produces a suitable training set for deep\nretrieval. Second, we build on the recent R-MAC descriptor, show that it can be\ninterpreted as a deep and differentiable architecture, and present improvements\nto enhance it. Last, we train this network with a siamese architecture that\ncombines three streams with a triplet loss. At the end of the training process,\nthe proposed architecture produces a global image representation in a single\nforward pass that is well suited for image retrieval. Extensive experiments\nshow that our approach significantly outperforms previous retrieval approaches,\nincluding state-of-the-art methods based on costly local descriptor indexing\nand spatial verification. On Oxford 5k, Paris 6k and Holidays, we respectively\nreport 94.7, 96.6, and 94.8 mean average precision. Our representations can\nalso be heavily compressed using product quantization with little loss in\naccuracy. For additional material, please see\nwww.xrce.xerox.com/Deep-Image-Retrieval.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Distance Metric Learning", "Quantization", "Evaluation"], "tsne_embedding": [-15.662775993347168, 0.8679232001304626], "cluster": 8}, {"key": "goswami2016distance", "year": "2016", "citations": "7", "title": "Distance Sensitive Bloom Filters Without False Negatives", "abstract": "<p>A Bloom filter is a widely used data-structure for representing a set \\(S\\) and\nanswering queries of the form \u201cIs \\(x\\) in \\(S\\)?\u201d. By allowing some false positive\nanswers (saying \u201cyes\u201d when the answer is in fact `no\u2019) Bloom filters use space\nsignificantly below what is required for storing \\(S\\). In the distance sensitive\nsetting we work with a set \\(S\\) of (Hamming) vectors and seek a data structure\nthat offers a similar trade-off, but answers queries of the form \u201cIs \\(x\\) close\nto an element of \\(S\\)?\u201d (in Hamming distance). Previous work on distance\nsensitive Bloom filters have accepted false positive and false negative\nanswers. Absence of false negatives is of critical importance in many\napplications of Bloom filters, so it is natural to ask if this can be also\nachieved in the distance sensitive setting. Our main contributions are upper\nand lower bounds (that are tight in several cases) for space usage in the\ndistance sensitive setting where false negatives are not allowed.</p>\n", "tags": ["Graph Based ANN"], "tsne_embedding": [22.464176177978516, 1.1767041683197021], "cluster": 7}, {"key": "gottesb\u00fcren2024unleashing", "year": "2024", "citations": "19", "title": "Unleashing Graph Partitioning For Large-scale Nearest Neighbor Search", "abstract": "<p>We consider the fundamental problem of decomposing a large-scale approximate\nnearest neighbor search (ANNS) problem into smaller sub-problems. The goal is\nto partition the input points into neighborhood-preserving shards, so that the\nnearest neighbors of any point are contained in only a few shards. When a query\narrives, a routing algorithm is used to identify the shards which should be\nsearched for its nearest neighbors. This approach forms the backbone of\ndistributed ANNS, where the dataset is so large that it must be split across\nmultiple machines.\n  In this paper, we design simple and highly efficient routing methods, and\nprove strong theoretical guarantees on their performance. A crucial\ncharacteristic of our routing algorithms is that they are inherently modular,\nand can be used with any partitioning method. This addresses a key drawback of\nprior approaches, where the routing algorithms are inextricably linked to their\nassociated partitioning method. In particular, our new routing methods enable\nthe use of balanced graph partitioning, which is a high-quality partitioning\nmethod without a naturally associated routing algorithm. Thus, we provide the\nfirst methods for routing using balanced graph partitioning that are extremely\nfast to train, admit low latency, and achieve high recall. We provide a\ncomprehensive evaluation of our full partitioning and routing pipeline on\nbillion-scale datasets, where it outperforms existing scalable partitioning\nmethods by significant margins, achieving up to 2.14x higher QPS at 90%\nrecall\\(@10\\) than the best competitor.</p>\n", "tags": ["Large Scale Search", "DATASETS", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [16.295923233032227, 17.735231399536133], "cluster": 0}, {"key": "gottlieb2014near", "year": "2014", "citations": "22", "title": "Near-optimal Sample Compression For Nearest Neighbors", "abstract": "<p>We present the first sample compression algorithm for nearest neighbors with\nnon-trivial performance guarantees. We complement these guarantees by\ndemonstrating almost matching hardness lower bounds, which show that our bound\nis nearly optimal. Our result yields new insight into margin-based nearest\nneighbor classification in metric spaces and allows us to significantly sharpen\nand simplify existing bounds. Some encouraging empirical results are also\npresented.</p>\n", "tags": ["Evaluation"], "tsne_embedding": [19.327224731445312, -2.234820604324341], "cluster": 7}, {"key": "gouk2015fast", "year": "2015", "citations": "7", "title": "Fast Metric Learning For Deep Neural Networks", "abstract": "<p>Similarity metrics are a core component of many information retrieval and\nmachine learning systems. In this work we propose a method capable of learning\na similarity metric from data equipped with a binary relation. By considering\nonly the similarity constraints, and initially ignoring the features, we are\nable to learn target vectors for each instance using one of several\nappropriately designed loss functions. A regression model can then be\nconstructed that maps novel feature vectors to the same target vector space,\nresulting in a feature extractor that computes vectors for which a predefined\nmetric is a meaningful measure of similarity. We present results on both\nmulticlass and multi-label classification datasets that demonstrate\nconsiderably faster convergence, as well as higher accuracy on the majority of\nthe intrinsic evaluation tasks and all extrinsic evaluation tasks.</p>\n", "tags": ["DATASETS", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [7.807415962219238, 4.785000324249268], "cluster": 4}, {"key": "grauman2025learning", "year": "2025", "citations": "102", "title": "Learning Binary Hash Codes For Large-scale Image Search", "abstract": "<p>Algorithms to rapidly search massive image or video collections are critical for many vision applications, including visual search, content-based retrieval, and non-parametric models for object recognition. Recent work shows that learned binary projections are a powerful way to index large collections according to their content. The basic idea is to formulate the projections so as to approximately preserve a given similarity function of interest. Having done so, one can then search the data efficiently using hash tables, or by exploring the Hamming ball volume around a novel query. Both enable sub-linear time retrieval with respect to the database size. Further, depending on the design of the projections, in some cases it is possible to bound the number of database examples that must be searched in order to achieve a given level of accuracy.</p>\n\n<p>This chapter overviews data structures for fast search with binary codes, and then describes several supervised and unsupervised strategies for generating the codes. In particular, we review supervised methods that integrate metric learning, boosting, and neural networks into the hash key construction, and unsupervised methods based on spectral analysis or kernelized random projections that compute affinity-preserving binary codes.Whether learning from explicit semantic supervision or exploiting the structure among unlabeled data, these methods make scalable retrieval possible for a variety of robust visual similarity measures.We focus on defining the algorithms, and illustrate the main points with results using millions of images.</p>\n", "tags": ["Survey Paper", "Image Retrieval", "Locality Sensitive Hashing", "Hashing Methods", "Distance Metric Learning", "Compact Codes", "Large Scale Search", "Tools & Libraries"], "tsne_embedding": [4.9123358726501465, 3.9950716495513916], "cluster": 4}, {"key": "green2019hashgraph", "year": "2019", "citations": "13", "title": "Hashgraph -- Scalable Hash Tables Using A Sparse Graph Data Structure", "abstract": "<p>Hash tables are ubiquitous and used in a wide range of applications for\nefficient probing of large and unsorted data. If designed properly, hash-tables\ncan enable efficients look ups in a constant number of operations or commonly\nreferred to as O(1) operations. As data sizes continue to grow and data becomes\nless structured (as is common for big-data applications), the need for\nefficient and scalable hash table also grows. In this paper we introduce\nHashGraph, a new scalable approach for building hash tables that uses concepts\ntaken from sparse graph representations\u2013hence the name HashGraph. We show two\ndifferent variants of HashGraph, a simple algorithm that outlines the method to\ncreate the hash-table and an advanced method that creates the hash table in a\nmore efficient manner (with an improved memory access pattern). HashGraph shows\na new way to deal with hash-collisions that does not use \u201copen-addressing\u201d or\n\u201cchaining\u201d, yet has all the benefits of both these approaches. HashGraph\ncurrently works for static inputs, though recent progress with dynamic graph\ndata structures suggest that HashGraph might be extended to dynamic inputs as\nwell. We show that HashGraph can deal with a large number of hash-values per\nentry without loss of performance as most open-addressing and chaining\napproaches have. Further, we show that HashGraph is indifferent to the\nload-factor. Lastly, we show a new probing algorithm for the second phase of\nvalue lookups. Given the above, HashGraph is extremely fast and outperforms\nseveral state of the art hash-table implementations. The implementation of\nHashGraph in this paper is for NVIDIA GPUs, though HashGraph is not\narchitecture dependent. Using a NVIDIA GV100 GPU, HashGraph is anywhere from\n2X-8X faster than cuDPP, WarpDrive, and cuDF. HashGraph is able to build a\nhash-table at a rate of 2.5 billion keys per second and can probe at nearly the\nsame rate.</p>\n", "tags": ["Evaluation"], "tsne_embedding": [3.0932531356811523, -10.617982864379883], "cluster": 9}, {"key": "gripon2016associative", "year": "2016", "citations": "9", "title": "Associative Memories To Accelerate Approximate Nearest Neighbor Search", "abstract": "<p>Nearest neighbor search is a very active field in machine learning for it\nappears in many application cases, including classification and object\nretrieval. In its canonical version, the complexity of the search is linear\nwith both the dimension and the cardinal of the collection of vectors the\nsearch is performed in. Recently many works have focused on reducing the\ndimension of vectors using quantization techniques or hashing, while providing\nan approximate result. In this paper we focus instead on tackling the cardinal\nof the collection of vectors. Namely, we introduce a technique that partitions\nthe collection of vectors and stores each part in its own associative memory.\nWhen a query vector is given to the system, associative memories are polled to\nidentify which one contain the closest match. Then an exhaustive search is\nconducted only on the part of vectors stored in the selected associative\nmemory. We study the effectiveness of the system when messages to store are\ngenerated from i.i.d. uniform \\(\\pm\\)1 random variables or 0-1 sparse i.i.d.\nrandom variables. We also conduct experiment on both synthetic data and real\ndata and show it is possible to achieve interesting trade-offs between\ncomplexity and accuracy.</p>\n", "tags": ["Hashing Methods", "Quantization"], "tsne_embedding": [7.928412437438965, -6.086097240447998], "cluster": 2}, {"key": "gritta2025dresd", "year": "2025", "citations": "6", "title": "Dresd: Dense Retrieval For Speculative Decoding", "abstract": "<p>Speculative decoding (SD) accelerates Large Language Model (LLM) generation by using an efficient draft model to propose the next few tokens, which are verified by the LLM in a single forward call, reducing latency while preserving its outputs. We focus on retrieval-based SD where the draft model retrieves the next tokens from a non-parametric datastore. Sparse retrieval (REST), which operates on the surface form of strings, is currently the dominant paradigm due to its simplicity and scalability. However, its effectiveness is limited due to the usage of short contexts and exact string matching. Instead, we introduce Dense Retrieval for Speculative Decoding (DReSD), a novel framework that uses approximate nearest neighbour search with contextualised token embeddings to retrieve the most semantically relevant token sequences for SD. Extensive experiments show that DReSD achieves (on average) 87% higher acceptance rates, 65% longer accepted tokens and 19% faster generation speeds compared to sparse retrieval (REST).</p>\n", "tags": ["NAACL", "Efficiency And Optimization", "ACL", "Similarity Search", "Tools & Libraries"], "tsne_embedding": [-2.9684033393859863, -8.867938995361328], "cluster": 9}, {"key": "groh2019ggnn", "year": "2019", "citations": "33", "title": "GGNN: Graph-based GPU Nearest Neighbor Search", "abstract": "<p>Approximate nearest neighbor (ANN) search in high dimensions is an integral\npart of several computer vision systems and gains importance in deep learning\nwith explicit memory representations. Since PQT, FAISS, and SONG started to\nleverage the massive parallelism offered by GPUs, GPU-based implementations are\na crucial resource for today\u2019s state-of-the-art ANN methods. While most of\nthese methods allow for faster queries, less emphasis is devoted to\naccelerating the construction of the underlying index structures. In this\npaper, we propose a novel GPU-friendly search structure based on nearest\nneighbor graphs and information propagation on graphs. Our method is designed\nto take advantage of GPU architectures to accelerate the hierarchical\nconstruction of the index structure and for performing the query. Empirical\nevaluation shows that GGNN significantly surpasses the state-of-the-art CPU-\nand GPU-based systems in terms of build-time, accuracy and search speed.</p>\n", "tags": ["Graph Based ANN", "Quantization", "Vector Indexing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [17.606409072875977, 21.17047882080078], "cluster": 0}, {"key": "grzegorczyk2016binary", "year": "2016", "citations": "5", "title": "Binary Paragraph Vectors", "abstract": "<p>Recently Le &amp; Mikolov described two log-linear models, called Paragraph\nVector, that can be used to learn state-of-the-art distributed representations\nof documents. Inspired by this work, we present Binary Paragraph Vector models:\nsimple neural networks that learn short binary codes for fast information\nretrieval. We show that binary paragraph vectors outperform autoencoder-based\nbinary codes, despite using fewer bits. We also evaluate their precision in\ntransfer learning settings, where binary codes are inferred for documents\nunrelated to the training corpus. Results from these experiments indicate that\nbinary paragraph vectors can capture semantics relevant for various\ndomain-specific documents. Finally, we present a model that simultaneously\nlearns short binary codes and longer, real-valued representations. This model\ncan be used to rapidly retrieve a short list of highly relevant documents from\na large document collection.</p>\n", "tags": ["Compact Codes", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-10.884872436523438, -15.309669494628906], "cluster": 1}, {"key": "gu2020symmetrical", "year": "2020", "citations": "21", "title": "Symmetrical Synthesis For Deep Metric Learning", "abstract": "<p>Deep metric learning aims to learn embeddings that contain semantic\nsimilarity information among data points. To learn better embeddings, methods\nto generate synthetic hard samples have been proposed. Existing methods of\nsynthetic hard sample generation are adopting autoencoders or generative\nadversarial networks, but this leads to more hyper-parameters, harder\noptimization, and slower training speed. In this paper, we address these\nproblems by proposing a novel method of synthetic hard sample generation called\nsymmetrical synthesis. Given two original feature points from the same class,\nthe proposed method firstly generates synthetic points with each other as an\naxis of symmetry. Secondly, it performs hard negative pair mining within the\noriginal and synthetic points to select a more informative negative pair for\ncomputing the metric learning loss. Our proposed method is hyper-parameter free\nand plug-and-play for existing metric learning losses without network\nmodification. We demonstrate the superiority of our proposed method over\nexisting methods for a variety of loss functions on clustering and image\nretrieval tasks. Our implementations is publicly available.</p>\n", "tags": ["AAAI", "Distance Metric Learning", "Robustness"], "tsne_embedding": [-19.216533660888672, 5.575911521911621], "cluster": 3}, {"key": "gu2022accelerating", "year": "2022", "citations": "9", "title": "Accelerating Code Search With Deep Hashing And Code Classification", "abstract": "<p>Code search is to search reusable code snippets from source code corpus based\non natural languages queries. Deep learning-based methods of code search have\nshown promising results. However, previous methods focus on retrieval accuracy\nbut lacked attention to the efficiency of the retrieval process. We propose a\nnovel method CoSHC to accelerate code search with deep hashing and code\nclassification, aiming to perform an efficient code search without sacrificing\ntoo much accuracy. To evaluate the effectiveness of CoSHC, we apply our method\nto five code search models. Extensive experimental results indicate that\ncompared with previous code search baselines, CoSHC can save more than 90% of\nretrieval time meanwhile preserving at least 99% of retrieval accuracy.</p>\n", "tags": ["Efficiency And Optimization", "ACL", "Neural Hashing", "Hashing Methods"], "tsne_embedding": [-8.197758674621582, -13.395604133605957], "cluster": 9}, {"key": "guan2019post", "year": "2019", "citations": "16", "title": "Post-training 4-bit Quantization On Embedding Tables", "abstract": "<p>Continuous representations have been widely adopted in recommender systems\nwhere a large number of entities are represented using embedding vectors. As\nthe cardinality of the entities increases, the embedding components can easily\ncontain millions of parameters and become the bottleneck in both storage and\ninference due to large memory consumption. This work focuses on post-training\n4-bit quantization on the continuous embeddings. We propose row-wise uniform\nquantization with greedy search and codebook-based quantization that\nconsistently outperforms state-of-the-art quantization approaches on reducing\naccuracy degradation. We deploy our uniform quantization technique on a\nproduction model in Facebook and demonstrate that it can reduce the model size\nto only 13.89% of the single-precision version while the model quality stays\nneutral.</p>\n", "tags": ["Recommender Systems", "Quantization", "Evaluation"], "tsne_embedding": [9.911516189575195, 23.584230422973633], "cluster": 0}, {"key": "gui2019fast", "year": "2019", "citations": "265", "title": "Fast Supervised Discrete Hashing", "abstract": "<p>Learning-based hashing algorithms are <code class=\"language-plaintext highlighter-rouge\">hot topics\" because they can greatly\nincrease the scale at which existing methods operate. In this paper, we propose\na new learning-based hashing method called</code>fast supervised discrete hashing\u201d\n(FSDH) based on ``supervised discrete hashing\u201d (SDH). Regressing the training\nexamples (or hash code) to the corresponding class labels is widely used in\nordinary least squares regression. Rather than adopting this method, FSDH uses\na very simple yet effective regression of the class labels of training examples\nto the corresponding hash code to accelerate the algorithm. To the best of our\nknowledge, this strategy has not previously been used for hashing. Traditional\nSDH decomposes the optimization into three sub-problems, with the most critical\nsub-problem - discrete optimization for binary hash codes - solved using\niterative discrete cyclic coordinate descent (DCC), which is time-consuming.\nHowever, FSDH has a closed-form solution and only requires a single rather than\niterative hash code-solving step, which is highly efficient. Furthermore, FSDH\nis usually faster than SDH for solving the projection matrix for least squares\nregression, making FSDH generally faster than SDH. For example, our results\nshow that FSDH is about 12-times faster than SDH when the number of hashing\nbits is 128 on the CIFAR-10 data base, and FSDH is about 151-times faster than\nFastHash when the number of hashing bits is 64 on the MNIST data-base. Our\nexperimental results show that FSDH is not only fast, but also outperforms\nother comparative methods.</p>\n", "tags": ["Hashing Methods"], "tsne_embedding": [-9.581153869628906, -13.00699234008789], "cluster": 1}, {"key": "gui2019supervised", "year": "2019", "citations": "92", "title": "Supervised Discrete Hashing With Relaxation", "abstract": "<p>Data-dependent hashing has recently attracted attention due to being able to\nsupport efficient retrieval and storage of high-dimensional data such as\ndocuments, images, and videos. In this paper, we propose a novel learning-based\nhashing method called \u201cSupervised Discrete Hashing with Relaxation\u201d (SDHR)\nbased on \u201cSupervised Discrete Hashing\u201d (SDH). SDH uses ordinary least squares\nregression and traditional zero-one matrix encoding of class label information\nas the regression target (code words), thus fixing the regression target. In\nSDHR, the regression target is instead optimized. The optimized regression\ntarget matrix satisfies a large margin constraint for correct classification of\neach example. Compared with SDH, which uses the traditional zero-one matrix,\nSDHR utilizes the learned regression target matrix and, therefore, more\naccurately measures the classification error of the regression model and is\nmore flexible. As expected, SDHR generally outperforms SDH. Experimental\nresults on two large-scale image datasets (CIFAR-10 and MNIST) and a\nlarge-scale and challenging face dataset (FRGC) demonstrate the effectiveness\nand efficiency of SDHR.</p>\n", "tags": ["DATASETS", "Similarity Search", "Hashing Methods", "Efficiency And Optimization"], "tsne_embedding": [-0.922325074672699, -8.02421760559082], "cluster": 9}, {"key": "guo2019accelerating", "year": "2019", "citations": "91", "title": "Accelerating Large-scale Inference With Anisotropic Vector Quantization", "abstract": "<p>Quantization based techniques are the current state-of-the-art for scaling\nmaximum inner product search to massive databases. Traditional approaches to\nquantization aim to minimize the reconstruction error of the database points.\nBased on the observation that for a given query, the database points that have\nthe largest inner products are more relevant, we develop a family of\nanisotropic quantization loss functions. Under natural statistical assumptions,\nwe show that quantization with these loss functions leads to a new variant of\nvector quantization that more greatly penalizes the parallel component of a\ndatapoint\u2019s residual relative to its orthogonal component. The proposed\napproach achieves state-of-the-art results on the public benchmarks available\nat \\url{ann-benchmarks.com}.</p>\n", "tags": ["Quantization", "Evaluation"], "tsne_embedding": [5.7682600021362305, 7.983567714691162], "cluster": 4}, {"key": "guo2019deep", "year": "2019", "citations": "144", "title": "Deep Hashing For Signed Social Network Embedding", "abstract": "<p>Network embedding is a promising way of network representation, facilitating\nmany signed social network processing and analysis tasks such as link\nprediction and node classification. Recently, feature hashing has been adopted\nin several existing embedding algorithms to improve the efficiency, which has\nobtained a great success. However, the existing feature hashing based embedding\nalgorithms only consider the positive links in signed social networks.\nIntuitively, negative links can also help improve the performance. Thus, in\nthis paper, we propose a novel deep hashing method for signed social network\nembedding by considering simultaneously positive and negative links. Extensive\nexperiments show that the proposed method performs better than several\nstate-of-the-art baselines through link prediction task over two real-world\nsigned social networks.</p>\n", "tags": ["Efficiency And Optimization", "Neural Hashing", "Evaluation", "Hashing Methods"], "tsne_embedding": [8.166353225708008, -12.649273872375488], "cluster": 2}, {"key": "guo2020deep", "year": "2020", "citations": "5", "title": "Deep Kernel Supervised Hashing For Node Classification In Structural Networks", "abstract": "<p>Node classification in structural networks has been proven to be useful in\nmany real world applications. With the development of network embedding, the\nperformance of node classification has been greatly improved. However, nearly\nall the existing network embedding based methods are hard to capture the actual\ncategory features of a node because of the linearly inseparable problem in\nlow-dimensional space; meanwhile they cannot incorporate simultaneously network\nstructure information and node label information into network embedding. To\naddress the above problems, in this paper, we propose a novel Deep Kernel\nSupervised Hashing (DKSH) method to learn the hashing representations of nodes\nfor node classification. Specifically, a deep multiple kernel learning is first\nproposed to map nodes into suitable Hilbert space to deal with linearly\ninseparable problem. Then, instead of only considering structural similarity\nbetween two nodes, a novel similarity matrix is designed to merge both network\nstructure information and node label information. Supervised by the similarity\nmatrix, the learned hashing representations of nodes simultaneously preserve\nthe two kinds of information well from the learned Hilbert space. Extensive\nexperiments show that the proposed method significantly outperforms the\nstate-of-the-art baselines over three real world benchmark datasets.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Evaluation"], "tsne_embedding": [-2.535390615463257, -16.021005630493164], "cluster": 5}, {"key": "guo2025gpu", "year": "2025", "citations": "6", "title": "Gpu-accelerated Multi-relational Parallel Graph Retrieval For Web-scale Recommendations", "abstract": "<p>Web recommendations provide personalized items from massive catalogs for\nusers, which rely heavily on retrieval stages to trade off the effectiveness\nand efficiency of selecting a small relevant set from billion-scale candidates\nin online digital platforms. As one of the largest Chinese search engine and\nnews feed providers, Baidu resorts to Deep Neural Network (DNN) and graph-based\nApproximate Nearest Neighbor Search (ANNS) algorithms for accurate relevance\nestimation and efficient search for relevant items. However, current retrieval\nat Baidu fails in comprehensive user-item relational understanding due to\ndissected interaction modeling, and performs inefficiently in large-scale\ngraph-based ANNS because of suboptimal traversal navigation and the GPU\ncomputational bottleneck under high concurrency. To this end, we propose a\nGPU-accelerated Multi-relational Parallel Graph Retrieval (GMP-GR) framework to\nachieve effective yet efficient retrieval in web-scale recommendations. First,\nwe propose a multi-relational user-item relevance metric learning method that\nunifies diverse user behaviors through multi-objective optimization and employs\na self-covariant loss to enhance pathfinding performance. Second, we develop a\nhierarchical parallel graph-based ANNS to boost graph retrieval throughput,\nwhich conducts breadth-depth-balanced searches on a large-scale item graph and\ncost-effectively handles irregular neural computation via adaptive aggregation\non GPUs. In addition, we integrate system optimization strategies in the\ndeployment of GMP-GR in Baidu. Extensive experiments demonstrate the\nsuperiority of GMP-GR in retrieval accuracy and efficiency. Deployed across\nmore than twenty applications at Baidu, GMP-GR serves hundreds of millions of\nusers with a throughput exceeding one hundred million requests per second.</p>\n", "tags": ["KDD", "Graph Based ANN", "Efficiency And Optimization", "Distance Metric Learning", "Large Scale Search", "Recommender Systems", "Similarity Search", "Tools & Libraries", "Evaluation"], "tsne_embedding": [12.47377872467041, 16.111446380615234], "cluster": 0}, {"key": "gupta2021irli", "year": "2021", "citations": "6", "title": "IRLI: Iterative Re-partitioning For Learning To Index", "abstract": "<p>Neural models have transformed the fundamental information retrieval problem\nof mapping a query to a giant set of items. However, the need for efficient and\nlow latency inference forces the community to reconsider efficient approximate\nnear-neighbor search in the item space. To this end, learning to index is\ngaining much interest in recent times. Methods have to trade between obtaining\nhigh accuracy while maintaining load balance and scalability in distributed\nsettings. We propose a novel approach called IRLI (pronounced `early\u2019), which\niteratively partitions the items by learning the relevant buckets directly from\nthe query-item relevance data. Furthermore, IRLI employs a superior\npower-of-\\(k\\)-choices based load balancing strategy. We mathematically show that\nIRLI retrieves the correct item with high probability under very natural\nassumptions and provides superior load balancing. IRLI surpasses the best\nbaseline\u2019s precision on multi-label classification while being \\(5x\\) faster on\ninference. For near-neighbor search tasks, the same method outperforms the\nstate-of-the-art Learned Hashing approach NeuralLSH by requiring only ~\n{1/6}^th of the candidates for the same recall. IRLI is both data and model\nparallel, making it ideal for distributed GPU implementation. We demonstrate\nthis advantage by indexing 100 million dense vectors and surpassing the popular\nFAISS library by &gt;10% on recall.</p>\n", "tags": ["KDD", "Locality Sensitive Hashing", "Hashing Methods", "Efficiency And Optimization", "Tools & Libraries", "Evaluation"], "tsne_embedding": [13.81098747253418, -4.821738243103027], "cluster": 2}, {"key": "gupta2022medical", "year": "2022", "citations": "7", "title": "Medical Image Retrieval Via Nearest Neighbor Search On Pre-trained Image Features", "abstract": "<p>Nearest neighbor search (NNS) aims to locate the points in high-dimensional\nspace that is closest to the query point. The brute-force approach for finding\nthe nearest neighbor becomes computationally infeasible when the number of\npoints is large. The NNS has multiple applications in medicine, such as\nsearching large medical imaging databases, disease classification, diagnosis,\netc. With a focus on medical imaging, this paper proposes DenseLinkSearch an\neffective and efficient algorithm that searches and retrieves the relevant\nimages from heterogeneous sources of medical images. Towards this, given a\nmedical database, the proposed algorithm builds the index that consists of\npre-computed links of each point in the database. The search algorithm utilizes\nthe index to efficiently traverse the database in search of the nearest\nneighbor. We extensively tested the proposed NNS approach and compared the\nperformance with state-of-the-art NNS approaches on benchmark datasets and our\ncreated medical image datasets. The proposed approach outperformed the existing\napproach in terms of retrieving accurate neighbors and retrieval speed. We also\nexplore the role of medical image feature representation in content-based\nmedical image retrieval tasks. We propose a Transformer-based feature\nrepresentation technique that outperformed the existing pre-trained Transformer\napproach on CLEF 2011 medical image retrieval task. The source code of our\nexperiments are available at https://github.com/deepaknlp/DLS.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Evaluation"], "tsne_embedding": [-23.068971633911133, 19.875822067260742], "cluster": 3}, {"key": "gupta2023caps", "year": "2023", "citations": "6", "title": "CAPS: A Practical Partition Index For Filtered Similarity Search", "abstract": "<p>With the surging popularity of approximate near-neighbor search (ANNS),\ndriven by advances in neural representation learning, the ability to serve\nqueries accompanied by a set of constraints has become an area of intense\ninterest. While the community has recently proposed several algorithms for\nconstrained ANNS, almost all of these methods focus on integration with\ngraph-based indexes, the predominant class of algorithms achieving\nstate-of-the-art performance in latency-recall tradeoffs. In this work, we take\na different approach and focus on developing a constrained ANNS algorithm via\nspace partitioning as opposed to graphs. To that end, we introduce Constrained\nApproximate Partitioned Search (CAPS), an index for ANNS with filters via space\npartitions that not only retains the benefits of a partition-based algorithm\nbut also outperforms state-of-the-art graph-based constrained search techniques\nin recall-latency tradeoffs, with only 10% of the index size.</p>\n", "tags": ["Graph Based ANN", "Efficiency And Optimization", "SIGIR", "Similarity Search", "Evaluation"], "tsne_embedding": [17.373268127441406, 8.250387191772461], "cluster": 0}, {"key": "gupta2025retreever", "year": "2025", "citations": "6", "title": "Retreever: Tree-based Coarse-to-fine Representations For Retrieval", "abstract": "<p>Document retrieval is a core component of question-answering systems, as it\nenables conditioning answer generation on new and large-scale corpora. While\neffective, the standard practice of encoding documents into high-dimensional\nembeddings for similarity search entails large memory and compute footprints,\nand also makes it hard to inspect the inner workings of the system. In this\npaper, we propose a tree-based method for organizing and representing reference\ndocuments at various granular levels, which offers the flexibility to balance\ncost and utility, and eases the inspection of the corpus content and retrieval\noperations. Our method, called ReTreever, jointly learns a routing function per\ninternal node of a binary tree such that query and reference documents are\nassigned to similar tree branches, hence directly optimizing for retrieval\nperformance. Our evaluations show that ReTreever generally preserves full\nrepresentation accuracy. Its hierarchical structure further provides strong\ncoarse representations and enhances transparency by indirectly learning\nmeaningful semantic groupings. Among hierarchical retrieval methods, ReTreever\nachieves the best retrieval accuracy at the lowest latency, proving that this\nfamily of techniques can be viable in practical applications.</p>\n", "tags": ["Graph Based ANN", "Efficiency And Optimization", "Text Retrieval", "Similarity Search", "Tree Based ANN", "Evaluation"], "tsne_embedding": [1.4703106880187988, -2.1106977462768555], "cluster": 4}, {"key": "guruswami2018beating", "year": "2018", "citations": "9", "title": "Beating Fredman-koml\\'{o}s For Perfect \\(k\\)-hashing", "abstract": "<p>We say a subset \\(C \\subseteq \\{1,2,\\dots,k\\}^n\\) is a \\(k\\)-hash code (also\ncalled \\(k\\)-separated) if for every subset of \\(k\\) codewords from \\(C\\), there\nexists a coordinate where all these codewords have distinct values.\nUnderstanding the largest possible rate (in bits), defined as \\((log_2 |C|)/n\\),\nof a \\(k\\)-hash code is a classical problem. It arises in two equivalent\ncontexts: (i) the smallest size possible for a perfect hash family that maps a\nuniverse of \\(N\\) elements into \\(\\{1,2,\\dots,k\\}\\), and (ii) the zero-error\ncapacity for decoding with lists of size less than \\(k\\) for a certain\ncombinatorial channel.\n  A general upper bound of \\(k!/k^{k-1}\\) on the rate of a \\(k\\)-hash code (in the\nlimit of large \\(n\\)) was obtained by Fredman and Koml'{o}s in 1984 for any \\(k\n\\geq 4\\). While better bounds have been obtained for \\(k=4\\), their original bound\nhas remained the best known for each \\(k \\ge 5\\). In this work, we obtain the\nfirst improvement to the Fredman-Koml'{o}s bound for every \\(k \\ge 5\\). While we\nget explicit (numerical) bounds for \\(k=5,6\\), for larger \\(k\\) we only show that\nthe FK bound can be improved by a positive, but unspecified, amount. Under a\nconjecture on the optimum value of a certain polynomial optimization problem\nover the simplex, our methods allow an effective bound to be computed for every\n\\(k\\).</p>\n", "tags": ["Hashing Methods", "Evaluation"], "tsne_embedding": [-6.895167350769043, -27.19143295288086], "cluster": 5}, {"key": "haghiri2017comparison", "year": "2017", "citations": "11", "title": "Comparison Based Nearest Neighbor Search", "abstract": "<p>We consider machine learning in a comparison-based setting where we are given\na set of points in a metric space, but we have no access to the actual\ndistances between the points. Instead, we can only ask an oracle whether the\ndistance between two points \\(i\\) and \\(j\\) is smaller than the distance between\nthe points \\(i\\) and \\(k\\). We are concerned with data structures and algorithms to\nfind nearest neighbors based on such comparisons. We focus on a simple yet\neffective algorithm that recursively splits the space by first selecting two\nrandom pivot points and then assigning all other points to the closer of the\ntwo (comparison tree). We prove that if the metric space satisfies certain\nexpansion conditions, then with high probability the height of the comparison\ntree is logarithmic in the number of points, leading to efficient search\nperformance. We also provide an upper bound for the failure probability to\nreturn the true nearest neighbor. Experiments show that the comparison tree is\ncompetitive with algorithms that have access to the actual distance values, and\nneeds less triplet comparisons than other competitors.</p>\n", "tags": ["Evaluation"], "tsne_embedding": [20.642473220825195, 5.121488571166992], "cluster": 7}, {"key": "hamann2019hamming", "year": "2019", "citations": "6", "title": "Hamming Sentence Embeddings For Information Retrieval", "abstract": "<p>In retrieval applications, binary hashes are known to offer significant\nimprovements in terms of both memory and speed. We investigate the compression\nof sentence embeddings using a neural encoder-decoder architecture, which is\ntrained by minimizing reconstruction error. Instead of employing the original\nreal-valued embeddings, we use latent representations in Hamming space produced\nby the encoder for similarity calculations.\n  In quantitative experiments on several benchmarks for semantic similarity\ntasks, we show that our compressed hamming embeddings yield a comparable\nperformance to uncompressed embeddings (Sent2Vec, InferSent, Glove-BoW), at\ncompression ratios of up to 256:1. We further demonstrate that our model\nstrongly decorrelates input features, and that the compressor generalizes well\nwhen pre-trained on Wikipedia sentences. We publish the source code on Github\nand all experimental results.</p>\n", "tags": ["Hashing Methods", "Evaluation"], "tsne_embedding": [0.7262130379676819, -0.8841186165809631], "cluster": 4}, {"key": "han2017beyond", "year": "2017", "citations": "10", "title": "Beyond SIFT Using Binary Features For Loop Closure Detection", "abstract": "<p>In this paper a binary feature based Loop Closure Detection (LCD) method is\nproposed, which for the first time achieves higher precision-recall (PR)\nperformance compared with state-of-the-art SIFT feature based approaches. The\nproposed system originates from our previous work Multi-Index hashing for Loop\nclosure Detection (MILD), which employs Multi-Index Hashing\n(MIH)~\\cite{greene1994multi} for Approximate Nearest Neighbor (ANN) search of\nbinary features. As the accuracy of MILD is limited by repeating textures and\ninaccurate image similarity measurement, burstiness handling is introduced to\nsolve this problem and achieves considerable accuracy improvement.\nAdditionally, a comprehensive theoretical analysis on MIH used in MILD is\nconducted to further explore the potentials of hashing methods for ANN search\nof binary features from probabilistic perspective. This analysis provides more\nfreedom on best parameter choosing in MIH for different application scenarios.\nExperiments on popular public datasets show that the proposed approach achieved\nthe highest accuracy compared with state-of-the-art while running at 30Hz for\ndatabases containing thousands of images.</p>\n", "tags": ["DATASETS", "IROS", "Hashing Methods", "Similarity Search", "Vector Indexing", "Evaluation"], "tsne_embedding": [4.0749030113220215, 17.043285369873047], "cluster": 6}, {"key": "han2017mild", "year": "2017", "citations": "9", "title": "MILD: Multi-index Hashing For Loop Closure Detection", "abstract": "<p>Loop Closure Detection (LCD) has been proved to be extremely useful in global\nconsistent visual Simultaneously Localization and Mapping (SLAM) and\nappearance-based robot relocalization. Methods exploiting binary features in\nbag of words representation have recently gained a lot of popularity for their\nefficiency, but suffer from low recall due to the inherent drawback that high\ndimensional binary feature descriptors lack well-defined centroids. In this\npaper, we propose a realtime LCD approach called MILD (Multi-Index Hashing for\nLoop closure Detection), in which image similarity is measured by feature\nmatching directly to achieve high recall without introducing extra\ncomputational complexity with the aid of Multi-Index Hashing (MIH). A\ntheoretical analysis of the approximate image similarity measurement using MIH\nis presented, which reveals the trade-off between efficiency and accuracy from\na probabilistic perspective. Extensive comparisons with state-of-the-art LCD\nmethods demonstrate the superiority of MILD in both efficiency and accuracy.</p>\n", "tags": ["Hashing Methods", "Efficiency And Optimization", "Alt", "Vector Indexing", "Evaluation"], "tsne_embedding": [3.964414358139038, 17.158246994018555], "cluster": 6}, {"key": "han2024hashing", "year": "2024", "citations": "50", "title": "Hashing For Protein Structure Similarity Search", "abstract": "<p>Protein structure similarity search (PSSS), which tries to search proteins\nwith similar structures, plays a crucial role across diverse domains from drug\ndesign to protein function prediction and molecular evolution. Traditional\nalignment-based PSSS methods, which directly calculate alignment on the protein\nstructures, are highly time-consuming with high memory cost. Recently,\nalignment-free methods, which represent protein structures as fixed-length\nreal-valued vectors, are proposed for PSSS. Although these methods have lower\ntime and memory cost than alignment-based methods, their time and memory cost\nis still too high for large-scale PSSS, and their accuracy is unsatisfactory.\nIn this paper, we propose a novel method, called\n\\(\\underline{\\text{p}}\\)r\\(\\underline{\\text{o}}\\)tein\n\\(\\underline{\\text{s}}\\)tructure \\(\\underline{\\text{h}}\\)ashing (POSH), for PSSS.\nPOSH learns a binary vector representation for each protein structure, which\ncan dramatically reduce the time and memory cost for PSSS compared with\nreal-valued vector representation based methods. Furthermore, in POSH we also\npropose expressive hand-crafted features and a structure encoder to well model\nboth node and edge interactions in proteins. Experimental results on real\ndatasets show that POSH can outperform other methods to achieve\nstate-of-the-art accuracy. Furthermore, POSH achieves a memory saving of more\nthan six times and speed improvement of more than four times, compared with\nother methods.</p>\n", "tags": ["Alt", "Similarity Search", "Hashing Methods", "DATASETS"], "tsne_embedding": [10.584640502929688, -17.390520095825195], "cluster": 2}, {"key": "hansen2019unsupervised", "year": "2019", "citations": "25", "title": "Unsupervised Neural Generative Semantic Hashing", "abstract": "<p>Fast similarity search is a key component in large-scale information\nretrieval, where semantic hashing has become a popular strategy for\nrepresenting documents as binary hash codes. Recent advances in this area have\nbeen obtained through neural network based models: generative models trained by\nlearning to reconstruct the original documents. We present a novel unsupervised\ngenerative semantic hashing approach, \\textit{Ranking based Semantic Hashing}\n(RBSH) that consists of both a variational and a ranking based component.\nSimilarly to variational autoencoders, the variational component is trained to\nreconstruct the original document conditioned on its generated hash code, and\nas in prior work, it only considers documents individually. The ranking\ncomponent solves this limitation by incorporating inter-document similarity\ninto the hash code generation, modelling document ranking through a hinge loss.\nTo circumvent the need for labelled data to compute the hinge loss, we use a\nweak labeller and thus keep the approach fully unsupervised.\n  Extensive experimental evaluation on four publicly available datasets against\ntraditional baselines and recent state-of-the-art methods for semantic hashing\nshows that RBSH significantly outperforms all other methods across all\nevaluated hash code lengths. In fact, RBSH hash codes are able to perform\nsimilarly to state-of-the-art hash codes while using 2-4x fewer bits.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Text Retrieval", "SIGIR", "Similarity Search", "Evaluation"], "tsne_embedding": [-1.7459118366241455, -4.628472328186035], "cluster": 9}, {"key": "hansen2020content", "year": "2020", "citations": "36", "title": "Content-aware Neural Hashing For Cold-start Recommendation", "abstract": "<p>Content-aware recommendation approaches are essential for providing\nmeaningful recommendations for \\textit{new} (i.e., \\textit{cold-start}) items\nin a recommender system. We present a content-aware neural hashing-based\ncollaborative filtering approach (NeuHash-CF), which generates binary hash\ncodes for users and items, such that the highly efficient Hamming distance can\nbe used for estimating user-item relevance. NeuHash-CF is modelled as an\nautoencoder architecture, consisting of two joint hashing components for\ngenerating user and item hash codes. Inspired from semantic hashing, the item\nhashing component generates a hash code directly from an item\u2019s content\ninformation (i.e., it generates cold-start and seen item hash codes in the same\nmanner). This contrasts existing state-of-the-art models, which treat the two\nitem cases separately. The user hash codes are generated directly based on user\nid, through learning a user embedding matrix. We show experimentally that\nNeuHash-CF significantly outperforms state-of-the-art baselines by up to 12%\nNDCG and 13% MRR in cold-start recommendation settings, and up to 4% in both\nNDCG and MRR in standard settings where all items are present while training.\nOur approach uses 2-4x shorter hash codes, while obtaining the same or better\nperformance compared to the state of the art, thus consequently also enabling a\nnotable storage reduction.</p>\n", "tags": ["Hashing Methods", "Text Retrieval", "Recommender Systems", "Neural Hashing", "SIGIR", "Evaluation"], "tsne_embedding": [2.552657127380371, -3.5714895725250244], "cluster": 4}, {"key": "hansen2020unsupervised", "year": "2020", "citations": "22", "title": "Unsupervised Semantic Hashing With Pairwise Reconstruction", "abstract": "<p>Semantic Hashing is a popular family of methods for efficient similarity\nsearch in large-scale datasets. In Semantic Hashing, documents are encoded as\nshort binary vectors (i.e., hash codes), such that semantic similarity can be\nefficiently computed using the Hamming distance. Recent state-of-the-art\napproaches have utilized weak supervision to train better performing hashing\nmodels. Inspired by this, we present Semantic Hashing with Pairwise\nReconstruction (PairRec), which is a discrete variational autoencoder based\nhashing model. PairRec first encodes weakly supervised training pairs (a query\ndocument and a semantically similar document) into two hash codes, and then\nlearns to reconstruct the same query document from both of these hash codes\n(i.e., pairwise reconstruction). This pairwise reconstruction enables our model\nto encode local neighbourhood structures within the hash code directly through\nthe decoder. We experimentally compare PairRec to traditional and\nstate-of-the-art approaches, and obtain significant performance improvements in\nthe task of document similarity search.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Text Retrieval", "SIGIR", "Similarity Search", "Evaluation"], "tsne_embedding": [-0.6016212701797485, -4.384291648864746], "cluster": 9}, {"key": "hansen2021representation", "year": "2021", "citations": "16", "title": "Representation Learning For Efficient And Effective Similarity Search And Recommendation", "abstract": "<p>How data is represented and operationalized is critical for building\ncomputational solutions that are both effective and efficient. A common\napproach is to represent data objects as binary vectors, denoted \\textit{hash\ncodes}, which require little storage and enable efficient similarity search\nthrough direct indexing into a hash table or through similarity computations in\nan appropriate space. Due to the limited expressibility of hash codes, compared\nto real-valued representations, a core open challenge is how to generate hash\ncodes that well capture semantic content or latent properties using a small\nnumber of bits, while ensuring that the hash codes are distributed in a way\nthat does not reduce their search efficiency. State of the art methods use\nrepresentation learning for generating such hash codes, focusing on neural\nautoencoder architectures where semantics are encoded into the hash codes by\nlearning to reconstruct the original inputs of the hash codes. This thesis\naddresses the above challenge and makes a number of contributions to\nrepresentation learning that (i) improve effectiveness of hash codes through\nmore expressive representations and a more effective similarity measure than\nthe current state of the art, namely the Hamming distance, and (ii) improve\nefficiency of hash codes by learning representations that are especially suited\nto the choice of search method. The contributions are empirically validated on\nseveral tasks related to similarity search and recommendation.</p>\n", "tags": ["Hashing Methods", "Efficiency And Optimization", "Recommender Systems", "SIGIR", "Similarity Search"], "tsne_embedding": [-5.421092987060547, -13.00538444519043], "cluster": 9}, {"key": "hansen2021unsupervised", "year": "2021", "citations": "8", "title": "Unsupervised Multi-index Semantic Hashing", "abstract": "<p>Semantic hashing represents documents as compact binary vectors (hash codes)\nand allows both efficient and effective similarity search in large-scale\ninformation retrieval. The state of the art has primarily focused on learning\nhash codes that improve similarity search effectiveness, while assuming a\nbrute-force linear scan strategy for searching over all the hash codes, even\nthough much faster alternatives exist. One such alternative is multi-index\nhashing, an approach that constructs a smaller candidate set to search over,\nwhich depending on the distribution of the hash codes can lead to sub-linear\nsearch time. In this work, we propose Multi-Index Semantic Hashing (MISH), an\nunsupervised hashing model that learns hash codes that are both effective and\nhighly efficient by being optimized for multi-index hashing. We derive novel\ntraining objectives, which enable to learn hash codes that reduce the candidate\nsets produced by multi-index hashing, while being end-to-end trainable. In\nfact, our proposed training objectives are model agnostic, i.e., not tied to\nhow the hash codes are generated specifically in MISH, and are straight-forward\nto include in existing and future semantic hashing models. We experimentally\ncompare MISH to state-of-the-art semantic hashing baselines in the task of\ndocument similarity search. We find that even though multi-index hashing also\nimproves the efficiency of the baselines compared to a linear scan, they are\nstill upwards of 33% slower than MISH, while MISH is still able to obtain\nstate-of-the-art effectiveness.</p>\n", "tags": ["Hashing Methods", "Efficiency And Optimization", "Alt", "Text Retrieval", "Similarity Search", "Vector Indexing"], "tsne_embedding": [-6.089618682861328, -8.965738296508789], "cluster": 9}, {"key": "harpeled2019near", "year": "2019", "citations": "8", "title": "Near Neighbor: Who Is The Fairest Of Them All?", "abstract": "<p>\\(\\newcommand{\\ball}{\\mathbb{B}}\\newcommand{\\dsQ}{{\\mathcal{Q}}}\\newcommand{\\dsS}{{\\mathcal{S}}}\\)In\nthis work we study a fair variant of the near neighbor problem. Namely, given a\nset of \\(n\\) points \\(P\\) and a parameter \\(r\\), the goal is to preprocess the\npoints, such that given a query point \\(q\\), any point in the \\(r\\)-neighborhood of\nthe query, i.e., \\(\\ball(q,r)\\), have the same probability of being reported as\nthe near neighbor.\n  We show that LSH based algorithms can be made fair, without a significant\nloss in efficiency. Specifically, we show an algorithm that reports a point in\nthe \\(r\\)-neighborhood of a query \\(q\\) with almost uniform probability. The query\ntime is proportional to \\(O\\bigl( \\mathrm{dns}(q.r) \\dsQ(n,c) \\bigr)\\), and its\nspace is \\(O(\\dsS(n,c))\\), where \\(\\dsQ(n,c)\\) and \\(\\dsS(n,c)\\) are the query time\nand space of an LSH algorithm for \\(c\\)-approximate near neighbor, and\n\\(\\mathrm{dns}(q,r)\\) is a function of the local density around \\(q\\).\n  Our approach works more generally for sampling uniformly from a\nsub-collection of sets of a given collection and can be used in a few other\napplications. Finally, we run experiments to show performance of our approach\non real data.</p>\n", "tags": ["Locality Sensitive Hashing", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [29.72690200805664, 1.615514874458313], "cluster": 7}, {"key": "hashimoto2021case", "year": "2021", "citations": "18", "title": "Case-based Similar Image Retrieval For Weakly Annotated Large Histopathological Images Of Malignant Lymphoma Using Deep Metric Learning", "abstract": "<p>In the present study, we propose a novel case-based similar image retrieval\n(SIR) method for hematoxylin and eosin (H&amp;E)-stained histopathological images\nof malignant lymphoma. When a whole slide image (WSI) is used as an input\nquery, it is desirable to be able to retrieve similar cases by focusing on\nimage patches in pathologically important regions such as tumor cells. To\naddress this problem, we employ attention-based multiple instance learning,\nwhich enables us to focus on tumor-specific regions when the similarity between\ncases is computed. Moreover, we employ contrastive distance metric learning to\nincorporate immunohistochemical (IHC) staining patterns as useful supervised\ninformation for defining appropriate similarity between heterogeneous malignant\nlymphoma cases. In the experiment with 249 malignant lymphoma patients, we\nconfirmed that the proposed method exhibited higher evaluation measures than\nthe baseline case-based SIR methods. Furthermore, the subjective evaluation by\npathologists revealed that our similarity measure using IHC staining patterns\nis appropriate for representing the similarity of H&amp;E-stained tissue images for\nmalignant lymphoma.</p>\n", "tags": ["Image Retrieval", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [-22.535728454589844, 18.612070083618164], "cluster": 3}, {"key": "he2017hashing", "year": "2017", "citations": "89", "title": "Hashing As Tie-aware Learning To Rank", "abstract": "<p>Hashing, or learning binary embeddings of data, is frequently used in nearest\nneighbor retrieval. In this paper, we develop learning to rank formulations for\nhashing, aimed at directly optimizing ranking-based evaluation metrics such as\nAverage Precision (AP) and Normalized Discounted Cumulative Gain (NDCG). We\nfirst observe that the integer-valued Hamming distance often leads to tied\nrankings, and propose to use tie-aware versions of AP and NDCG to evaluate\nhashing for retrieval. Then, to optimize tie-aware ranking metrics, we derive\ntheir continuous relaxations, and perform gradient-based optimization with deep\nneural networks. Our results establish the new state-of-the-art for image\nretrieval by Hamming ranking in common benchmarks.</p>\n", "tags": ["CVPR", "Hashing Methods", "Evaluation"], "tsne_embedding": [-7.394482135772705, 3.523855447769165], "cluster": 8}, {"key": "he2018local", "year": "2018", "citations": "209", "title": "Local Descriptors Optimized For Average Precision", "abstract": "<p>Extraction of local feature descriptors is a vital stage in the solution\npipelines for numerous computer vision tasks. Learning-based approaches improve\nperformance in certain tasks, but still cannot replace handcrafted features in\ngeneral. In this paper, we improve the learning of local feature descriptors by\noptimizing the performance of descriptor matching, which is a common stage that\nfollows descriptor extraction in local feature based pipelines, and can be\nformulated as nearest neighbor retrieval. Specifically, we directly optimize a\nranking-based retrieval performance metric, Average Precision, using deep\nneural networks. This general-purpose solution can also be viewed as a listwise\nlearning to rank approach, which is advantageous compared to recent local\nranking approaches. On standard benchmarks, descriptors learned with our\nformulation achieve state-of-the-art results in patch verification, patch\nretrieval, and image matching.</p>\n", "tags": ["CVPR", "Evaluation"], "tsne_embedding": [-15.719879150390625, 7.4569010734558105], "cluster": 3}, {"key": "he2019one", "year": "2019", "citations": "9", "title": "One Network For Multi-domains: Domain Adaptive Hashing With Intersectant Generative Adversarial Network", "abstract": "<p>With the recent explosive increase of digital data, image recognition and\nretrieval become a critical practical application. Hashing is an effective\nsolution to this problem, due to its low storage requirement and high query\nspeed. However, most of past works focus on hashing in a single (source)\ndomain. Thus, the learned hash function may not adapt well in a new (target)\ndomain that has a large distributional difference with the source domain. In\nthis paper, we explore an end-to-end domain adaptive learning framework that\nsimultaneously and precisely generates discriminative hash codes and classifies\ntarget domain images. Our method encodes two domains images into a semantic\ncommon space, followed by two independent generative adversarial networks\narming at crosswise reconstructing two domains\u2019 images, reducing domain\ndisparity and improving alignment in the shared space. We evaluate our\nframework on {four} public benchmark datasets, all of which show that our\nmethod is superior to the other state-of-the-art methods on the tasks of object\nrecognition and image retrieval.</p>\n", "tags": ["DATASETS", "Evaluation", "IJCAI", "Robustness", "Hashing Methods", "Image Retrieval", "Tools & Libraries", "AAAI"], "tsne_embedding": [-5.453554630279541, 3.140184164047241], "cluster": 8}, {"key": "he2021unsupervised", "year": "2021", "citations": "98", "title": "Unsupervised Domain-adaptive Hash For Networks", "abstract": "<p>Abundant real-world data can be naturally represented by large-scale\nnetworks, which demands efficient and effective learning algorithms. At the\nsame time, labels may only be available for some networks, which demands these\nalgorithms to be able to adapt to unlabeled networks. Domain-adaptive hash\nlearning has enjoyed considerable success in the computer vision community in\nmany practical tasks due to its lower cost in both retrieval time and storage\nfootprint. However, it has not been applied to multiple-domain networks. In\nthis work, we bridge this gap by developing an unsupervised domain-adaptive\nhash learning method for networks, dubbed UDAH. Specifically, we develop four\n{task-specific yet correlated} components: (1) network structure preservation\nvia a hard groupwise contrastive loss, (2) relaxation-free supervised hashing,\n(3) cross-domain intersected discriminators, and (4) semantic center alignment.\nWe conduct a wide range of experiments to evaluate the effectiveness and\nefficiency of our method on a range of tasks including link prediction, node\nclassification, and neighbor recommendation. Our evaluation results demonstrate\nthat our model achieves better performance than the state-of-the-art\nconventional discrete embedding methods over all the tasks.</p>\n", "tags": ["Hashing Methods", "Distance Metric Learning", "Efficiency And Optimization", "Recommender Systems", "Evaluation"], "tsne_embedding": [-2.693382501602173, -16.645299911499023], "cluster": 5}, {"key": "he2024hybridhash", "year": "2024", "citations": "5", "title": "Hybridhash: Hybrid Convolutional And Self-attention Deep Hashing For Image Retrieval", "abstract": "<p>Deep image hashing aims to map input images into simple binary hash codes via\ndeep neural networks and thus enable effective large-scale image retrieval.\nRecently, hybrid networks that combine convolution and Transformer have\nachieved superior performance on various computer tasks and have attracted\nextensive attention from researchers. Nevertheless, the potential benefits of\nsuch hybrid networks in image retrieval still need to be verified. To this end,\nwe propose a hybrid convolutional and self-attention deep hashing method known\nas HybridHash. Specifically, we propose a backbone network with stage-wise\narchitecture in which the block aggregation function is introduced to achieve\nthe effect of local self-attention and reduce the computational complexity. The\ninteraction module has been elaborately designed to promote the communication\nof information between image blocks and to enhance the visual representations.\nWe have conducted comprehensive experiments on three widely used datasets:\nCIFAR-10, NUS-WIDE and IMAGENET. The experimental results demonstrate that the\nmethod proposed in this paper has superior performance with respect to\nstate-of-the-art deep hashing methods. Source code is available\nhttps://github.com/shuaichaochao/HybridHash.</p>\n", "tags": ["DATASETS", "Evaluation", "Neural Hashing", "Hashing Methods", "Image Retrieval", "Multimodal Retrieval"], "tsne_embedding": [-1.6440129280090332, 14.0756254196167], "cluster": 6}, {"key": "he2025k", "year": "2025", "citations": "31", "title": "K-nearest Neighbors Hashing", "abstract": "<p>Hashing based approximate nearest neighbor search embeds high dimensional data to compact binary codes, which\nenables efficient similarity search and storage. However,\nthe non-isometry sign(\u00b7) function makes it hard to project\nthe nearest neighbors in continuous data space into the\nclosest codewords in discrete Hamming space. In this work,\nwe revisit the sign(\u00b7) function from the perspective of space partitioning.\nIn specific, we bridge the gap between\nk-nearest neighbors and binary hashing codes with Shannon entropy. We further propose a novel K-Nearest Neighbors Hashing (KNNH) method to learn binary representations from KNN within the subspaces generated by sign(\u00b7).\nTheoretical and experimental results show that the KNN relation is of central importance to neighbor preserving embeddings, and the proposed method outperforms the state-of-the-arts on benchmark datasets.</p>\n", "tags": ["DATASETS", "Hashing Methods", "CVPR", "Compact Codes", "Similarity Search", "Evaluation"], "tsne_embedding": [16.36669921875, -11.883928298950195], "cluster": 2}, {"key": "heddes2022hyperdimensional", "year": "2022", "citations": "10", "title": "Hyperdimensional Hashing: A Robust And Efficient Dynamic Hash Table", "abstract": "<p>Most cloud services and distributed applications rely on hashing algorithms\nthat allow dynamic scaling of a robust and efficient hash table. Examples\ninclude AWS, Google Cloud and BitTorrent. Consistent and rendezvous hashing are\nalgorithms that minimize key remapping as the hash table resizes. While memory\nerrors in large-scale cloud deployments are common, neither algorithm offers\nboth efficiency and robustness. Hyperdimensional Computing is an emerging\ncomputational model that has inherent efficiency, robustness and is well suited\nfor vector or hardware acceleration. We propose Hyperdimensional (HD) hashing\nand show that it has the efficiency to be deployed in large systems. Moreover,\na realistic level of memory errors causes more than 20% mismatches for\nconsistent hashing while HD hashing remains unaffected.</p>\n", "tags": ["Efficiency And Optimization", "Hashing Methods", "Evaluation", "Robustness"], "tsne_embedding": [11.357397079467773, 23.6782283782959], "cluster": 0}, {"key": "helbling2020directed", "year": "2020", "citations": "23", "title": "Directed Graph Hashing", "abstract": "<p>This paper presents several algorithms for hashing directed graphs. The\nalgorithms given are capable of hashing entire graphs as well as assigning hash\nvalues to specific nodes in a given graph. The notion of node symmetry is made\nprecise via computation of vertex orbits and the graph automorphism group, and\nnodes that are symmetrically identical are assigned equal hashes. We also\npresent a novel Merkle-style hashing algorithm that seeks to fulfill the\nrecursive principle that a hash of a node should depend only on the hash of its\nneighbors. This algorithm works even in the presence of cycles, which would not\nbe possible with a naive approach. Structurally hashing trees has seen\nwidespread use in blockchain, source code version control, and web\napplications. Despite the popularity of tree hashing, directed graph hashing\nremains unstudied in the literature. Our algorithms open new possibilities to\nhashing both directed graphs and more complex data structures that can be\nreduced to directed graphs such as hypergraphs.</p>\n", "tags": ["Hashing Methods"], "tsne_embedding": [18.13376235961914, 12.595178604125977], "cluster": 0}, {"key": "hemati2022learning", "year": "2022", "citations": "9", "title": "Learning Binary And Sparse Permutation-invariant Representations For Fast And Memory Efficient Whole Slide Image Search", "abstract": "<p>Learning suitable Whole slide images (WSIs) representations for efficient\nretrieval systems is a non-trivial task. The WSI embeddings obtained from\ncurrent methods are in Euclidean space not ideal for efficient WSI retrieval.\nFurthermore, most of the current methods require high GPU memory due to the\nsimultaneous processing of multiple sets of patches. To address these\nchallenges, we propose a novel framework for learning binary and sparse WSI\nrepresentations utilizing a deep generative modelling and the Fisher Vector. We\nintroduce new loss functions for learning sparse and binary\npermutation-invariant WSI representations that employ instance-based training\nachieving better memory efficiency. The learned WSI representations are\nvalidated on The Cancer Genomic Atlas (TCGA) and Liver-Kidney-Stomach (LKS)\ndatasets. The proposed method outperforms Yottixel (a recent search engine for\nhistopathology images) both in terms of retrieval accuracy and speed. Further,\nwe achieve competitive performance against SOTA on the public benchmark LKS\ndataset for WSI classification.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Efficiency And Optimization", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-20.249942779541016, 15.102270126342773], "cluster": 3}, {"key": "heo2025spherical", "year": "2025", "citations": "380", "title": "Spherical Hashing", "abstract": "<p>Many binary code encoding schemes based on hashing\nhave been actively studied recently, since they can provide\nefficient similarity search, especially nearest neighbor\nsearch, and compact data representations suitable for handling\nlarge scale image databases in many computer vision\nproblems. Existing hashing techniques encode highdimensional\ndata points by using hyperplane-based hashing\nfunctions. In this paper we propose a novel hyperspherebased\nhashing function, spherical hashing, to map more\nspatially coherent data points into a binary code compared\nto hyperplane-based hashing functions. Furthermore, we\npropose a new binary code distance function, spherical\nHamming distance, that is tailored to our hyperspherebased\nbinary coding scheme, and design an efficient iterative\noptimization process to achieve balanced partitioning\nof data points for each hash function and independence between\nhashing functions. Our extensive experiments show\nthat our spherical hashing technique significantly outperforms\nsix state-of-the-art hashing techniques based on hyperplanes\nacross various image benchmarks of sizes ranging\nfrom one to 75 million of GIST descriptors. The performance\ngains are consistent and large, up to 100% improvements.\nThe excellent results confirm the unique merits of\nthe proposed idea in using hyperspheres to encode proximity\nregions in high-dimensional spaces. Finally, our method\nis intuitive and easy to implement.</p>\n", "tags": ["Hashing Methods", "CVPR", "Compact Codes", "Similarity Search", "Evaluation"], "tsne_embedding": [21.014909744262695, 2.3382468223571777], "cluster": 7}, {"key": "hoang2018simultaneous", "year": "2018", "citations": "11", "title": "Simultaneous Compression And Quantization: A Joint Approach For Efficient Unsupervised Hashing", "abstract": "<p>For unsupervised data-dependent hashing, the two most important requirements\nare to preserve similarity in the low-dimensional feature space and to minimize\nthe binary quantization loss. A well-established hashing approach is Iterative\nQuantization (ITQ), which addresses these two requirements in separate steps.\nIn this paper, we revisit the ITQ approach and propose novel formulations and\nalgorithms to the problem. Specifically, we propose a novel approach, named\nSimultaneous Compression and Quantization (SCQ), to jointly learn to compress\n(reduce dimensionality) and binarize input data in a single formulation under\nstrict orthogonal constraint. With this approach, we introduce a loss function\nand its relaxed version, termed Orthonormal Encoder (OnE) and Orthogonal\nEncoder (OgE) respectively, which involve challenging binary and orthogonal\nconstraints. We propose to attack the optimization using novel algorithms based\non recent advances in cyclic coordinate descent approach. Comprehensive\nexperiments on unsupervised image retrieval demonstrate that our proposed\nmethods consistently outperform other state-of-the-art hashing methods.\nNotably, our proposed methods outperform recent deep neural networks and GAN\nbased hashing in accuracy, while being very computationally-efficient.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Quantization"], "tsne_embedding": [-2.3125929832458496, 6.272355079650879], "cluster": 8}, {"key": "hoang2020unsupervised", "year": "2020", "citations": "27", "title": "Unsupervised Deep Cross-modality Spectral Hashing", "abstract": "<p>This paper presents a novel framework, namely Deep Cross-modality Spectral\nHashing (DCSH), to tackle the unsupervised learning problem of binary hash\ncodes for efficient cross-modal retrieval. The framework is a two-step hashing\napproach which decouples the optimization into (1) binary optimization and (2)\nhashing function learning. In the first step, we propose a novel spectral\nembedding-based algorithm to simultaneously learn single-modality and binary\ncross-modality representations. While the former is capable of well preserving\nthe local structure of each modality, the latter reveals the hidden patterns\nfrom all modalities. In the second step, to learn mapping functions from\ninformative data inputs (images and word embeddings) to binary codes obtained\nfrom the first step, we leverage the powerful CNN for images and propose a\nCNN-based deep architecture to learn text modality. Quantitative evaluations on\nthree standard benchmark datasets demonstrate that the proposed DCSH method\nconsistently outperforms other state-of-the-art methods.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Compact Codes", "Multimodal Retrieval", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-12.276338577270508, 23.593368530273438], "cluster": 6}, {"key": "hoang2021multi", "year": "2021", "citations": "27", "title": "Multi-modal Mutual Information Maximization: A Novel Approach For Unsupervised Deep Cross-modal Hashing", "abstract": "<p>In this paper, we adopt the maximizing mutual information (MI) approach to\ntackle the problem of unsupervised learning of binary hash codes for efficient\ncross-modal retrieval. We proposed a novel method, dubbed Cross-Modal Info-Max\nHashing (CMIMH). First, to learn informative representations that can preserve\nboth intra- and inter-modal similarities, we leverage the recent advances in\nestimating variational lower-bound of MI to maximize the MI between the binary\nrepresentations and input features and between binary representations of\ndifferent modalities. By jointly maximizing these MIs under the assumption that\nthe binary representations are modelled by multivariate Bernoulli\ndistributions, we can learn binary representations, which can preserve both\nintra- and inter-modal similarities, effectively in a mini-batch manner with\ngradient descent. Furthermore, we find out that trying to minimize the modality\ngap by learning similar binary representations for the same instance from\ndifferent modalities could result in less informative representations. Hence,\nbalancing between reducing the modality gap and losing modality-private\ninformation is important for the cross-modal retrieval tasks. Quantitative\nevaluations on standard benchmark datasets demonstrate that the proposed method\nconsistently outperforms other state-of-the-art cross-modal retrieval methods.</p>\n", "tags": ["Multimodal Retrieval", "DATASETS", "Hashing Methods", "Evaluation"], "tsne_embedding": [-1.7173744440078735, 5.988389492034912], "cluster": 8}, {"key": "hoe2021one", "year": "2021", "citations": "46", "title": "One Loss For All: Deep Hashing With A Single Cosine Similarity Based Learning Objective", "abstract": "<p>A deep hashing model typically has two main learning objectives: to make the\nlearned binary hash codes discriminative and to minimize a quantization error.\nWith further constraints such as bit balance and code orthogonality, it is not\nuncommon for existing models to employ a large number (&gt;4) of losses. This\nleads to difficulties in model training and subsequently impedes their\neffectiveness. In this work, we propose a novel deep hashing model with only a\nsingle learning objective. Specifically, we show that maximizing the cosine\nsimilarity between the continuous codes and their corresponding binary\northogonal codes can ensure both hash code discriminativeness and quantization\nerror minimization. Further, with this learning objective, code balancing can\nbe achieved by simply using a Batch Normalization (BN) layer and multi-label\nclassification is also straightforward with label smoothing. The result is an\none-loss deep hashing model that removes all the hassles of tuning the weights\nof various losses. Importantly, extensive experiments show that our model is\nhighly effective, outperforming the state-of-the-art multi-loss hashing models\non three large-scale instance retrieval benchmarks, often by significant\nmargins. Code is available at https://github.com/kamwoh/orthohash</p>\n", "tags": ["Hashing Methods", "Distance Metric Learning", "Neural Hashing", "Quantization", "Evaluation"], "tsne_embedding": [-6.52815055847168, -10.584062576293945], "cluster": 9}, {"key": "hoffer2016semi", "year": "2016", "citations": "28", "title": "Semi-supervised Deep Learning By Metric Embedding", "abstract": "<p>Deep networks are successfully used as classification models yielding\nstate-of-the-art results when trained on a large number of labeled samples.\nThese models, however, are usually much less suited for semi-supervised\nproblems because of their tendency to overfit easily when trained on small\namounts of data. In this work we will explore a new training objective that is\ntargeting a semi-supervised regime with only a small subset of labeled data.\nThis criterion is based on a deep metric embedding over distance relations\nwithin the set of labeled samples, together with constraints over the\nembeddings of the unlabeled set. The final learned representations are\ndiscriminative in euclidean space, and hence can be used with subsequent\nnearest-neighbor classification using the labeled samples.</p>\n", "tags": [], "tsne_embedding": [-17.445457458496094, 5.6972336769104], "cluster": 3}, {"key": "horaud2023polyhedral", "year": "2023", "citations": "48", "title": "Polyhedral Object Recognition By Indexing", "abstract": "<p>In computer vision, the indexing problem is the problem of recognizing a few\nobjects in a large database of objects while avoiding the help of the classical\nimage-feature-to-object-feature matching paradigm. In this paper we address the\nproblem of recognizing 3-D polyhedral objects from 2-D images by indexing. Both\nthe objects to be recognized and the images are represented by weighted graphs.\nThe indexing problem is therefore the problem of determining whether a graph\nextracted from the image is present or absent in a database of model graphs. We\nintroduce a novel method for performing this graph indexing process which is\nbased both on polynomial characterization of binary and weighted graphs and on\nhashing. We describe in detail this polynomial characterization and then we\nshow how it can be used in the context of polyhedral object recognition. Next\nwe describe a practical recognition-by-indexing system that includes the\norganization of the database, the representation of polyhedral objects in terms\nof 2-D characteristic views, the representation of this views in terms of\nweighted graphs, and the associated image processing. Finally, some\nexperimental results allow the evaluation of the system performance.</p>\n", "tags": ["CVPR", "Hashing Methods", "Evaluation"], "tsne_embedding": [16.39177703857422, 12.329731941223145], "cluster": 0}, {"key": "hou2023semstamp", "year": "2023", "citations": "7", "title": "Semstamp: A Semantic Watermark With Paraphrastic Robustness For Text Generation", "abstract": "<p>Existing watermarking algorithms are vulnerable to paraphrase attacks because\nof their token-level design. To address this issue, we propose SemStamp, a\nrobust sentence-level semantic watermarking algorithm based on\nlocality-sensitive hashing (LSH), which partitions the semantic space of\nsentences. The algorithm encodes and LSH-hashes a candidate sentence generated\nby an LLM, and conducts sentence-level rejection sampling until the sampled\nsentence falls in watermarked partitions in the semantic embedding space. A\nmargin-based constraint is used to enhance its robustness. To show the\nadvantages of our algorithm, we propose a \u201cbigram\u201d paraphrase attack using the\nparaphrase that has the fewest bigram overlaps with the original sentence. This\nattack is shown to be effective against the existing token-level watermarking\nmethod. Experimental results show that our novel semantic watermark algorithm\nis not only more robust than the previous state-of-the-art method on both\ncommon and bigram paraphrase attacks, but also is better at preserving the\nquality of generation.</p>\n", "tags": ["NAACL", "Robustness", "Hashing Methods", "Locality Sensitive Hashing", "ACL"], "tsne_embedding": [2.5868780612945557, -18.892704010009766], "cluster": 5}, {"key": "houen2022understanding", "year": "2022", "citations": "6", "title": "Understanding The Moments Of Tabulation Hashing Via Chaoses", "abstract": "<p>Simple tabulation hashing dates back to Zobrist in 1970 and is defined as\nfollows: Each key is viewed as \\(c\\) characters from some alphabet \\(\\Sigma\\), we\nhave \\(c\\) fully random hash functions \\(h_0, \\ldots, h_{c - 1} \\colon \\Sigma \\to\n\\{0, \\ldots, 2^l - 1\\}\\), and a key \\(x = (x_0, \\ldots, x_{c - 1})\\) is hashed to\n\\(h(x) = h_0(x_0) \\oplus \\ldots \\oplus h_{c - 1}(x_{c - 1})\\) where \\(\\oplus\\) is\nthe bitwise XOR operation. The previous results on tabulation hashing by P{\\v\na}tra{\\c s}cu and Thorup~[J.ACM\u201911] and by Aamand et al.~[STOC\u201920] focused on\nproving Chernoff-style tail bounds on hash-based sums, e.g., the number keys\nhashing to a given value, for simple tabulation hashing, but their bounds do\nnot cover the entire tail.\n  Chaoses are random variables of the form \\(\\sum a_{i_0, \\ldots, i_{c - 1}}\nX_{i_0} \\cdot \\ldots \\cdot X_{i_{c - 1}}\\) where \\(X_i\\) are independent random\nvariables. Chaoses are a well-studied concept from probability theory, and\ntight analysis has been proven in several instances, e.g., when the independent\nrandom variables are standard Gaussian variables and when the independent\nrandom variables have logarithmically convex tails. We notice that hash-based\nsums of simple tabulation hashing can be seen as a sum of chaoses that are not\nindependent. This motivates us to use techniques from the theory of chaoses to\nanalyze hash-based sums of simple tabulation hashing.\n  In this paper, we obtain bounds for all the moments of hash-based sums for\nsimple tabulation hashing which are tight up to constants depending only on\n\\(c\\). In contrast with the previous attempts, our approach will mostly be\nanalytical and does not employ intricate combinatorial arguments. The improved\nanalysis of simple tabulation hashing allows us to obtain bounds for the\nmoments of hash-based sums for the mixed tabulation hashing introduced by\nDahlgaard et al.~[FOCS\u201915].</p>\n", "tags": ["Hashing Methods"], "tsne_embedding": [32.79407501220703, -1.1775343418121338], "cluster": 7}, {"key": "hu2017learning", "year": "2017", "citations": "206", "title": "Learning Discrete Representations Via Information Maximizing Self-augmented Training", "abstract": "<p>Learning discrete representations of data is a central machine learning task\nbecause of the compactness of the representations and ease of interpretation.\nThe task includes clustering and hash learning as special cases. Deep neural\nnetworks are promising to be used because they can model the non-linearity of\ndata and scale to large datasets. However, their model complexity is huge, and\ntherefore, we need to carefully regularize the networks in order to learn\nuseful representations that exhibit intended invariance for applications of\ninterest. To this end, we propose a method called Information Maximizing\nSelf-Augmented Training (IMSAT). In IMSAT, we use data augmentation to impose\nthe invariance on discrete representations. More specifically, we encourage the\npredicted representations of augmented data points to be close to those of the\noriginal data points in an end-to-end fashion. At the same time, we maximize\nthe information-theoretic dependency between data and their predicted discrete\nrepresentations. Extensive experiments on benchmark datasets show that IMSAT\nproduces state-of-the-art results for both clustering and unsupervised hash\nlearning.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Evaluation"], "tsne_embedding": [-1.0550987720489502, -16.60841941833496], "cluster": 5}, {"key": "hu2018deep", "year": "2018", "citations": "97", "title": "Deep LDA Hashing", "abstract": "<p>The conventional supervised hashing methods based on classification do not\nentirely meet the requirements of hashing technique, but Linear Discriminant\nAnalysis (LDA) does. In this paper, we propose to perform a revised LDA\nobjective over deep networks to learn efficient hashing codes in a truly\nend-to-end fashion. However, the complicated eigenvalue decomposition within\neach mini-batch in every epoch has to be faced with when simply optimizing the\ndeep network w.r.t. the LDA objective. In this work, the revised LDA objective\nis transformed into a simple least square problem, which naturally overcomes\nthe intractable problems and can be easily solved by the off-the-shelf\noptimizer. Such deep extension can also overcome the weakness of LDA Hashing in\nthe limited linear projection and feature learning. Amounts of experiments are\nconducted on three benchmark datasets. The proposed Deep LDA Hashing shows\nnearly 70 points improvement over the conventional one on the CIFAR-10 dataset.\nIt also beats several state-of-the-art methods on various metrics.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Evaluation"], "tsne_embedding": [-3.9217448234558105, -10.38333797454834], "cluster": 9}, {"key": "hu2018hashing", "year": "2018", "citations": "42", "title": "From Hashing To Cnns: Training Binaryweight Networks Via Hashing", "abstract": "<p>Deep convolutional neural networks (CNNs) have shown appealing performance on\nvarious computer vision tasks in recent years. This motivates people to deploy\nCNNs to realworld applications. However, most of state-of-art CNNs require\nlarge memory and computational resources, which hinders the deployment on\nmobile devices. Recent studies show that low-bit weight representation can\nreduce much storage and memory demand, and also can achieve efficient network\ninference. To achieve this goal, we propose a novel approach named BWNH to\ntrain Binary Weight Networks via Hashing. In this paper, we first reveal the\nstrong connection between inner-product preserving hashing and binary weight\nnetworks, and show that training binary weight networks can be intrinsically\nregarded as a hashing problem. Based on this perspective, we propose an\nalternating optimization method to learn the hash codes instead of directly\nlearning binary weights. Extensive experiments on CIFAR10, CIFAR100 and\nImageNet demonstrate that our proposed BWNH outperforms current state-of-art by\na large margin.</p>\n", "tags": ["Alt", "Hashing Methods", "Evaluation"], "tsne_embedding": [-13.765825271606445, 24.443058013916016], "cluster": 6}, {"key": "hu2020creating", "year": "2020", "citations": "117", "title": "Creating Something From Nothing: Unsupervised Knowledge Distillation For Cross-modal Hashing", "abstract": "<p>In recent years, cross-modal hashing (CMH) has attracted increasing\nattentions, mainly because its potential ability of mapping contents from\ndifferent modalities, especially in vision and language, into the same space,\nso that it becomes efficient in cross-modal data retrieval. There are two main\nframeworks for CMH, differing from each other in whether semantic supervision\nis required. Compared to the unsupervised methods, the supervised methods often\nenjoy more accurate results, but require much heavier labors in data\nannotation. In this paper, we propose a novel approach that enables guiding a\nsupervised method using outputs produced by an unsupervised method.\nSpecifically, we make use of teacher-student optimization for propagating\nknowledge. Experiments are performed on two popular CMH benchmarks, i.e., the\nMIRFlickr and NUS-WIDE datasets. Our approach outperforms all existing\nunsupervised methods by a large margin.</p>\n", "tags": ["DATASETS", "Hashing Methods", "CVPR", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-23.022233963012695, -6.2300262451171875], "cluster": 1}, {"key": "hu2022badhash", "year": "2022", "citations": "26", "title": "Badhash: Invisible Backdoor Attacks Against Deep Hashing With Clean Label", "abstract": "<p>Due to its powerful feature learning capability and high efficiency, deep\nhashing has achieved great success in large-scale image retrieval. Meanwhile,\nextensive works have demonstrated that deep neural networks (DNNs) are\nsusceptible to adversarial examples, and exploring adversarial attack against\ndeep hashing has attracted many research efforts. Nevertheless, backdoor\nattack, another famous threat to DNNs, has not been studied for deep hashing\nyet. Although various backdoor attacks have been proposed in the field of image\nclassification, existing approaches failed to realize a truly imperceptive\nbackdoor attack that enjoys invisible triggers and clean label setting\nsimultaneously, and they also cannot meet the intrinsic demand of image\nretrieval backdoor. In this paper, we propose BadHash, the first\ngenerative-based imperceptible backdoor attack against deep hashing, which can\neffectively generate invisible and input-specific poisoned images with clean\nlabel. Specifically, we first propose a new conditional generative adversarial\nnetwork (cGAN) pipeline to effectively generate poisoned samples. For any given\nbenign image, it seeks to generate a natural-looking poisoned counterpart with\na unique invisible trigger. In order to improve the attack effectiveness, we\nintroduce a label-based contrastive learning network LabCLN to exploit the\nsemantic characteristics of different labels, which are subsequently used for\nconfusing and misleading the target model to learn the embedded trigger. We\nfinally explore the mechanism of backdoor attacks on image retrieval in the\nhash space. Extensive experiments on multiple benchmark datasets verify that\nBadHash can generate imperceptible poisoned samples with strong attack ability\nand transferability over state-of-the-art deep hashing schemes.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Alt", "Neural Hashing", "Evaluation", "Robustness"], "tsne_embedding": [-15.913195610046387, 14.235859870910645], "cluster": 3}, {"key": "hu2025separated", "year": "2025", "citations": "30", "title": "Separated Variational Hashing Networks For Cross-modal Retrieval", "abstract": "<p>Cross-modal hashing, due to its low storage cost and high query speed, has been successfully used for similarity search in multimedia retrieval applications. It projects high-dimensional data into a shared isomorphic Hamming space with similar binary codes for semantically-similar data. In some applications, all modalities may not be obtained or trained simultaneously for some reasons, such as privacy, secret, storage limitation, and computational resource limitation. However, most existing cross-modal hashing methods need all modalities to jointly learn the common Hamming space, thus hindering them from handling these problems. In this paper, we propose a novel approach called Separated Variational Hashing Networks (SVHNs) to overcome the above challenge. Firstly, it adopts a label network (LabNet) to exploit available and nonspecific label annotations to learn a latent common Hamming space by projecting each semantic label into a common binary representation. Then, each modality-specific network can separately map the samples of the corresponding modality into their binary semantic codes learned by LabNet. We achieve it by conducting variational inference to match the aggregated posterior of the hashing code of LabNet with an arbitrary prior distribution. The effectiveness and efficiency of our SVHNs are verified by extensive experiments carried out on four widely-used multimedia databases, in comparison with 11 state-of-the-art approaches.</p>\n", "tags": ["Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Multimodal Retrieval", "Similarity Search", "Evaluation"], "tsne_embedding": [-3.0249242782592773, -1.5502114295959473], "cluster": 8}, {"key": "huang2016local", "year": "2016", "citations": "124", "title": "Local Similarity-aware Deep Feature Embedding", "abstract": "<p>Existing deep embedding methods in vision tasks are capable of learning a\ncompact Euclidean space from images, where Euclidean distances correspond to a\nsimilarity metric. To make learning more effective and efficient, hard sample\nmining is usually employed, with samples identified through computing the\nEuclidean feature distance. However, the global Euclidean distance cannot\nfaithfully characterize the true feature similarity in a complex visual feature\nspace, where the intraclass distance in a high-density region may be larger\nthan the interclass distance in low-density regions. In this paper, we\nintroduce a Position-Dependent Deep Metric (PDDM) unit, which is capable of\nlearning a similarity metric adaptive to local feature structure. The metric\ncan be used to select genuinely hard samples in a local neighborhood to guide\nthe deep embedding learning in an online and robust manner. The new layer is\nappealing in that it is pluggable to any convolutional networks and is trained\nend-to-end. Our local similarity-aware feature embedding not only demonstrates\nfaster convergence and boosted performance on two complex image retrieval\ndatasets, its large margin nature also leads to superior generalization results\nunder the large and open set scenarios of transfer learning and zero-shot\nlearning on ImageNet 2010 and ImageNet-10K datasets.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Distance Metric Learning", "Evaluation"], "tsne_embedding": [-19.733034133911133, 7.69114351272583], "cluster": 3}, {"key": "huang2017online", "year": "2017", "citations": "99", "title": "Online Hashing", "abstract": "<p>Although hash function learning algorithms have achieved great success in\nrecent years, most existing hash models are off-line, which are not suitable\nfor processing sequential or online data. To address this problem, this work\nproposes an online hash model to accommodate data coming in stream for online\nlearning. Specifically, a new loss function is proposed to measure the\nsimilarity loss between a pair of data samples in hamming space. Then, a\nstructured hash model is derived and optimized in a passive-aggressive way.\nTheoretical analysis on the upper bound of the cumulative loss for the proposed\nonline hash model is provided. Furthermore, we extend our online hashing from a\nsingle-model to a multi-model online hashing that trains multiple models so as\nto retain diverse online hashing models in order to avoid biased update. The\ncompetitive efficiency and effectiveness of the proposed online hash models are\nverified through extensive experiments on several large-scale datasets as\ncompared to related hashing methods.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "Alt", "ICCV"], "tsne_embedding": [-3.261157751083374, -18.39320945739746], "cluster": 5}, {"key": "huang2017unsupervised", "year": "2017", "citations": "54", "title": "Unsupervised Triplet Hashing For Fast Image Retrieval", "abstract": "<p>Hashing has played a pivotal role in large-scale image retrieval. With the\ndevelopment of Convolutional Neural Network (CNN), hashing learning has shown\ngreat promise. But existing methods are mostly tuned for classification, which\nare not optimized for retrieval tasks, especially for instance-level retrieval.\nIn this study, we propose a novel hashing method for large-scale image\nretrieval. Considering the difficulty in obtaining labeled datasets for image\nretrieval task in large scale, we propose a novel CNN-based unsupervised\nhashing method, namely Unsupervised Triplet Hashing (UTH). The unsupervised\nhashing network is designed under the following three principles: 1) more\ndiscriminative representations for image retrieval; 2) minimum quantization\nloss between the original real-valued feature descriptors and the learned hash\ncodes; 3) maximum information entropy for the learned hash codes. Extensive\nexperiments on CIFAR-10, MNIST and In-shop datasets have shown that UTH\noutperforms several state-of-the-art unsupervised hashing methods in terms of\nretrieval accuracy.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Quantization"], "tsne_embedding": [-13.11275863647461, 22.279970169067383], "cluster": 6}, {"key": "huang2023lightweight", "year": "2023", "citations": "5", "title": "Lightweight-yet-efficient: Revitalizing Ball-tree For Point-to-hyperplane Nearest Neighbor Search", "abstract": "<p>Finding the nearest neighbor to a hyperplane (or Point-to-Hyperplane Nearest\nNeighbor Search, simply P2HNNS) is a new and challenging problem with\napplications in many research domains. While existing state-of-the-art hashing\nschemes (e.g., NH and FH) are able to achieve sublinear time complexity without\nthe assumption of the data being in a unit hypersphere, they require an\nasymmetric transformation, which increases the data dimension from \\(d\\) to\n\\(\u03a9(d^2)\\). This leads to considerable overhead for indexing and incurs\nsignificant distortion errors.\n  In this paper, we investigate a tree-based approach for solving P2HNNS using\nthe classical Ball-Tree index. Compared to hashing-based methods, tree-based\nmethods usually require roughly linear costs for construction, and they provide\ndifferent kinds of approximations with excellent flexibility. A simple\nbranch-and-bound algorithm with a novel lower bound is first developed on\nBall-Tree for performing P2HNNS. Then, a new tree structure named BC-Tree,\nwhich maintains the Ball and Cone structures in the leaf nodes of Ball-Tree, is\ndescribed together with two effective strategies, i.e., point-level pruning and\ncollaborative inner product computing. BC-Tree inherits both the low\nconstruction cost and lightweight property of Ball-Tree while providing a\nsimilar or more efficient search. Experimental results over 16 real-world data\nsets show that Ball-Tree and BC-Tree are around 1.1\\(\\sim\\)10\\(\\times\\) faster than\nNH and FH, and they can reduce the index size and indexing time by about\n1\\(\\sim\\)3 orders of magnitudes on average. The code is available at\nhttps://github.com/HuangQiang/BC-Tree.</p>\n", "tags": ["Tree Based ANN", "Hashing Methods", "Efficiency And Optimization"], "tsne_embedding": [23.550748825073242, 3.797499656677246], "cluster": 7}, {"key": "huang2025accelerate", "year": "2025", "citations": "23", "title": "Accelerate Learning Of Deep Hashing With Gradient Attention", "abstract": "<p>Recent years have witnessed the success of learning to hash in fast large-scale image retrieval. As deep learning has shown its superior performance on many computer vision applications, recent designs of learning-based hashing models have been moving from shallow ones to deep architectures. However, based on our analysis, we find that gradient descent based algorithms used in deep hashing models would potentially cause hash codes of a pair of training instances to be updated towards the directions of each other simultaneously during optimization. In the worst case, the paired hash codes switch their directions after update, and consequently, their corresponding distance in the Hamming space remain unchanged. This makes the overall learning process highly inefficient. To address this issue, we propose a new deep hashing model integrated with a novel gradient attention mechanism. Extensive experimental results on three benchmark datasets show that our proposed algorithm is able to accelerate the learning process and obtain competitive retrieval performance compared with state-of-the-art deep hashing models.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Neural Hashing", "ICCV", "Evaluation"], "tsne_embedding": [-14.533430099487305, -4.148008823394775], "cluster": 1}, {"key": "huynh2018fast", "year": "2018", "citations": "12", "title": "Fast Binary Embeddings, And Quantized Compressed Sensing With Structured Matrices", "abstract": "<p>This paper deals with two related problems, namely distance-preserving binary\nembeddings and quantization for compressed sensing . First, we propose fast\nmethods to replace points from a subset \\(\\mathcal{X} \\subset \\mathbb{R}^n\\),\nassociated with the Euclidean metric, with points in the cube \\(\\{\\pm 1\\}^m\\) and\nwe associate the cube with a pseudo-metric that approximates Euclidean distance\namong points in \\(\\mathcal{X}\\). Our methods rely on quantizing fast\nJohnson-Lindenstrauss embeddings based on bounded orthonormal systems and\npartial circulant ensembles, both of which admit fast transforms. Our\nquantization methods utilize noise-shaping, and include Sigma-Delta schemes and\ndistributed noise-shaping schemes. The resulting approximation errors decay\npolynomially and exponentially fast in \\(m\\), depending on the embedding method.\nThis dramatically outperforms the current decay rates associated with binary\nembeddings and Hamming distances. Additionally, it is the first such binary\nembedding result that applies to fast Johnson-Lindenstrauss maps while\npreserving \\(\u2113\u2082\\) norms.\n  Second, we again consider noise-shaping schemes, albeit this time to quantize\ncompressed sensing measurements arising from bounded orthonormal ensembles and\npartial circulant matrices. We show that these methods yield a reconstruction\nerror that again decays with the number of measurements (and bits), when using\nconvex optimization for reconstruction. Specifically, for Sigma-Delta schemes,\nthe error decays polynomially in the number of measurements, and it decays\nexponentially for distributed noise-shaping schemes based on beta encoding.\nThese results are near optimal and the first of their kind dealing with bounded\northonormal systems.</p>\n", "tags": ["Hashing Methods", "Distance Metric Learning", "Quantization", "Tools & Libraries", "Evaluation"], "tsne_embedding": [34.9332275390625, 1.7643393278121948], "cluster": 7}, {"key": "im2016learning", "year": "2016", "citations": "5", "title": "Learning A Metric For Class-conditional KNN", "abstract": "<p>Naive Bayes Nearest Neighbour (NBNN) is a simple and effective framework\nwhich addresses many of the pitfalls of K-Nearest Neighbour (KNN)\nclassification. It has yielded competitive results on several computer vision\nbenchmarks. Its central tenet is that during NN search, a query is not compared\nto every example in a database, ignoring class information. Instead, NN\nsearches are performed within each class, generating a score per class. A key\nproblem with NN techniques, including NBNN, is that they fail when the data\nrepresentation does not capture perceptual (e.g.~class-based) similarity. NBNN\ncircumvents this by using independent engineered descriptors (e.g.~SIFT). To\nextend its applicability outside of image-based domains, we propose to learn a\nmetric which captures perceptual similarity. Similar to how Neighbourhood\nComponents Analysis optimizes a differentiable form of KNN classification, we\npropose \u201cClass Conditional\u201d metric learning (CCML), which optimizes a soft form\nof the NBNN selection rule. Typical metric learning algorithms learn either a\nglobal or local metric. However, our proposed method can be adjusted to a\nparticular level of locality by tuning a single parameter. An empirical\nevaluation on classification and retrieval tasks demonstrates that our proposed\nmethod clearly outperforms existing learned distance metrics across a variety\nof image and non-image datasets.</p>\n", "tags": ["DATASETS", "Tools & Libraries", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [-2.034575939178467, 4.221755504608154], "cluster": 8}, {"key": "indyk2016simultaneous", "year": "2016", "citations": "195", "title": "Simultaneous Nearest Neighbor Search", "abstract": "<p>Motivated by applications in computer vision and databases, we introduce and\nstudy the Simultaneous Nearest Neighbor Search (SNN) problem. Given a set of\ndata points, the goal of SNN is to design a data structure that, given a\ncollection of queries, finds a collection of close points that are compatible\nwith each other. Formally, we are given \\(k\\) query points \\(Q=q_1,\\cdots,q_k\\),\nand a compatibility graph \\(G\\) with vertices in \\(Q\\), and the goal is to return\ndata points \\(p_1,\\cdots,p_k\\) that minimize (i) the weighted sum of the\ndistances from \\(q_i\\) to \\(p_i\\) and (ii) the weighted sum, over all edges \\((i,j)\\)\nin the compatibility graph \\(G\\), of the distances between \\(p_i\\) and \\(p_j\\). The\nproblem has several applications, where one wants to return a set of consistent\nanswers to multiple related queries. This generalizes well-studied\ncomputational problems, including NN, Aggregate NN and the 0-extension problem.\n  In this paper we propose and analyze the following general two-step method\nfor designing efficient data structures for SNN. In the first step, for each\nquery point \\(q_i\\) we find its (approximate) nearest neighbor point \\(\\hat{p}_i\\);\nthis can be done efficiently using existing approximate nearest neighbor\nstructures. In the second step, we solve an off-line optimization problem over\nsets \\(q_1,\\cdots,q_k\\) and \\(\\hat{p}_1,\\cdots,\\hat{p}_k\\); this can be done\nefficiently given that \\(k\\) is much smaller than \\(n\\). Even though\n\\(\\hat{p}_1,\\cdots,\\hat{p}_k\\) might not constitute the optimal answers to\nqueries \\(q_1,\\cdots,q_k\\), we show that, for the unweighted case, the resulting\nalgorithm is \\(O(log k/log log k)\\)-approximation. Also, we show that the\napproximation factor can be in fact reduced to a constant for compatibility\ngraphs frequently occurring in practice.\n  Finally, we show that the \u201cempirical approximation factor\u201d provided by the\nabove approach is very close to 1.</p>\n", "tags": ["Graph Based ANN"], "tsne_embedding": [29.94092559814453, 2.3990797996520996], "cluster": 7}, {"key": "indyk2018approximate", "year": "2018", "citations": "6", "title": "Approximate Nearest Neighbors In Limited Space", "abstract": "<p>We consider the \\((1+\\epsilon)\\)-approximate nearest neighbor search problem:\ngiven a set \\(X\\) of \\(n\\) points in a \\(d\\)-dimensional space, build a data\nstructure that, given any query point \\(y\\), finds a point \\(x \\in X\\) whose\ndistance to \\(y\\) is at most \\((1+\\epsilon) \\min_{x \\in X} |x-y|\\) for an\naccuracy parameter \\(\\epsilon \\in (0,1)\\). Our main result is a data structure\nthat occupies only \\(O(\\epsilon^{-2} n log(n) log(1/\\epsilon))\\) bits of space,\nassuming all point coordinates are integers in the range \\(\\{-n^{O(1)} \\ldots\nn^{O(1)}\\}\\), i.e., the coordinates have \\(O(log n)\\) bits of precision. This\nimproves over the best previously known space bound of \\(O(\\epsilon^{-2} n\nlog(n)^2)\\), obtained via the randomized dimensionality reduction method of\nJohnson and Lindenstrauss (1984). We also consider the more general problem of\nestimating all distances from a collection of query points to all data points\n\\(X\\), and provide almost tight upper and lower bounds for the space complexity\nof this problem.</p>\n", "tags": ["Evaluation"], "tsne_embedding": [30.381488800048828, -2.749451160430908], "cluster": 7}, {"key": "indyk2023worst", "year": "2023", "citations": "34", "title": "Worst-case Performance Of Popular Approximate Nearest Neighbor Search Implementations: Guarantees And Limitations", "abstract": "<p>Graph-based approaches to nearest neighbor search are popular and powerful\ntools for handling large datasets in practice, but they have limited\ntheoretical guarantees. We study the worst-case performance of recent\ngraph-based approximate nearest neighbor search algorithms, such as HNSW, NSG\nand DiskANN. For DiskANN, we show that its \u201cslow preprocessing\u201d version\nprovably supports approximate nearest neighbor search query with constant\napproximation ratio and poly-logarithmic query time, on data sets with bounded\n\u201cintrinsic\u201d dimension. For the other data structure variants studied, including\nDiskANN with \u201cfast preprocessing\u201d, HNSW and NSG, we present a family of\ninstances on which the empirical query time required to achieve a \u201creasonable\u201d\naccuracy is linear in instance size. For example, for DiskANN, we show that the\nquery procedure can take at least \\(0.1 n\\) steps on instances of size \\(n\\) before\nit encounters any of the \\(5\\) nearest neighbors of the query.</p>\n", "tags": ["Graph Based ANN", "DATASETS", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [19.837596893310547, 8.931440353393555], "cluster": 0}, {"key": "irie2025locally", "year": "2025", "citations": "94", "title": "Locally Linear Hashing For Extracting Non-linear Manifolds", "abstract": "<p>Previous efforts in hashing intend to preserve data variance\nor pairwise affinity, but neither is adequate in capturing\nthe manifold structures hidden in most visual data. In\nthis paper, we tackle this problem by reconstructing the locally\nlinear structures of manifolds in the binary Hamming\nspace, which can be learned by locality-sensitive sparse\ncoding. We cast the problem as a joint minimization of\nreconstruction error and quantization loss, and show that,\ndespite its NP-hardness, a local optimum can be obtained\nefficiently via alternative optimization. Our method distinguishes\nitself from existing methods in its remarkable ability\nto extract the nearest neighbors of the query from the\nsame manifold, instead of from the ambient space. On extensive\nexperiments on various image benchmarks, our results\nimprove previous state-of-the-art by 28-74% typically,\nand 627% on the Yale face data.</p>\n", "tags": ["Hashing Methods", "CVPR", "Alt", "Quantization", "Evaluation"], "tsne_embedding": [-3.451525926589966, 9.635111808776855], "cluster": 8}, {"key": "iscen2017fast", "year": "2017", "citations": "37", "title": "Fast Spectral Ranking For Similarity Search", "abstract": "<p>Despite the success of deep learning on representing images for particular\nobject retrieval, recent studies show that the learned representations still\nlie on manifolds in a high dimensional space. This makes the Euclidean nearest\nneighbor search biased for this task. Exploring the manifolds online remains\nexpensive even if a nearest neighbor graph has been computed offline. This work\nintroduces an explicit embedding reducing manifold search to Euclidean search\nfollowed by dot product similarity search. This is equivalent to linear graph\nfiltering of a sparse signal in the frequency domain. To speed up online\nsearch, we compute an approximate Fourier basis of the graph offline. We\nimprove the state of art on particular object retrieval datasets including the\nchallenging Instre dataset containing small objects. At a scale of 10^5 images,\nthe offline cost is only a few hours, while query time is comparable to\nstandard similarity search.</p>\n", "tags": ["CVPR", "DATASETS", "Similarity Search", "Efficiency And Optimization"], "tsne_embedding": [20.380897521972656, 8.163771629333496], "cluster": 0}, {"key": "ishaq2019clustered", "year": "2019", "citations": "5", "title": "Clustered Hierarchical Entropy-scaling Search Of Astronomical And Biological Data", "abstract": "<p>Both astronomy and biology are experiencing explosive growth of data,\nresulting in a \u201cbig data\u201d problem that stands in the way of a \u201cbig data\u201d\nopportunity for discovery. One common question asked of such data is that of\napproximate search (\\(\\rho-\\)nearest neighbors search). We present a hierarchical\nsearch algorithm for such data sets that takes advantage of particular\ngeometric properties apparent in both astronomical and biological data sets,\nnamely the metric entropy and fractal dimensionality of the data. We present\nCHESS (Clustered Hierarchical Entropy-Scaling Search), a search tool with\nvirtually no loss in specificity or sensitivity, demonstrating a \\(13.6\\times\\)\nspeedup over linear search on the Sloan Digital Sky Survey\u2019s APOGEE data set\nand a \\(68\\times\\) speedup on the GreenGenes 16S metagenomic data set, as well as\nasymptotically fewer distance comparisons on APOGEE when compared to the\nFALCONN locality-sensitive hashing library. CHESS demonstrates an asymptotic\ncomplexity not directly dependent on data set size, and is in practice at least\nan order of magnitude faster than linear search by performing fewer distance\ncomparisons. Unlike locality-sensitive hashing approaches, CHESS can work with\nany user-defined distance function. CHESS also allows for implicit data\ncompression, which we demonstrate on the APOGEE data set. We also discuss an\nextension allowing for efficient k-nearest neighbors search.</p>\n", "tags": ["Survey Paper", "Hashing Methods", "Efficiency And Optimization", "Tools & Libraries", "Evaluation"], "tsne_embedding": [21.733139038085938, 3.0251033306121826], "cluster": 7}, {"key": "islam2024spatially", "year": "2024", "citations": "61", "title": "Spatially Optimized Compact Deep Metric Learning Model For Similarity Search", "abstract": "<p>Spatial optimization is often overlooked in many computer vision tasks.\nFilters should be able to recognize the features of an object regardless of\nwhere it is in the image. Similarity search is a crucial task where spatial\nfeatures decide an important output. The capacity of convolution to capture\nvisual patterns across various locations is limited. In contrast to\nconvolution, the involution kernel is dynamically created at each pixel based\non the pixel value and parameters that have been learned. This study\ndemonstrates that utilizing a single layer of involution feature extractor\nalongside a compact convolution model significantly enhances the performance of\nsimilarity search. Additionally, we improve predictions by using the GELU\nactivation function rather than the ReLU. The negligible amount of weight\nparameters in involution with a compact model with better performance makes the\nmodel very useful in real-world implementations. Our proposed model is below 1\nmegabyte in size. We have experimented with our proposed methodology and other\nmodels on CIFAR-10, FashionMNIST, and MNIST datasets. Our proposed method\noutperforms across all three datasets.</p>\n", "tags": ["DATASETS", "Similarity Search", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [-12.042933464050293, 14.247258186340332], "cluster": 6}, {"key": "iwamura2016scalable", "year": "2016", "citations": "56", "title": "Scalable Solution For Approximate Nearest Subspace Search", "abstract": "<p>Finding the nearest subspace is a fundamental problem and influential to many\napplications. In particular, a scalable solution that is fast and accurate for\na large problem has a great impact. The existing methods for the problem are,\nhowever, useless in a large-scale problem with a large number of subspaces and\nhigh dimensionality of the feature space. A cause is that they are designed\nbased on the traditional idea to represent a subspace by a single point. In\nthis paper, we propose a scalable solution for the approximate nearest subspace\nsearch (ANSS) problem. Intuitively, the proposed method represents a subspace\nby multiple points unlike the existing methods. This makes a large-scale ANSS\nproblem tractable. In the experiment with 3036 subspaces in the\n1024-dimensional space, we confirmed that the proposed method was 7.3 times\nfaster than the previous state-of-the-art without loss of accuracy.</p>\n", "tags": [], "tsne_embedding": [8.303075790405273, 19.123044967651367], "cluster": 0}, {"key": "iwasaki2018optimization", "year": "2018", "citations": "37", "title": "Optimization Of Indexing Based On K-nearest Neighbor Graph For Proximity Search In High-dimensional Data", "abstract": "<p>Searching for high-dimensional vector data with high accuracy is an\ninevitable search technology for various types of data. Graph-based indexes are\nknown to reduce the query time for high-dimensional data. To further improve\nthe query time by using graphs, we focused on the indegrees and outdegrees of\ngraphs. While a sufficient number of incoming edges (indegrees) are\nindispensable for increasing search accuracy, an excessive number of outgoing\nedges (outdegrees) should be suppressed so as to not increase the query time.\nTherefore, we propose three degree-adjustment methods: static degree adjustment\nof not only outdegrees but also indegrees, dynamic degree adjustment with which\noutdegrees are determined by the search accuracy users require, and path\nadjustment to remove edges that have alternative search paths to reduce\noutdegrees. We also show how to obtain optimal degree-adjustment parameters and\nthat our methods outperformed previous methods for image and textual data.</p>\n", "tags": ["Alt", "Graph Based ANN", "Efficiency And Optimization"], "tsne_embedding": [20.809322357177734, 15.436233520507812], "cluster": 0}, {"key": "jaber2025linear", "year": "2025", "citations": "54", "title": "Linear Hashing Is Optimal", "abstract": "<p>We prove that hashing \\(n\\) balls into \\(n\\) bins via a random matrix over \\(\\mathbf{F}_2\\) yields expected maximum load \\(O(log n / log log n)\\). This matches the expected maximum load of a fully random function and resolves an open question posed by Alon, Dietzfelbinger, Miltersen, Petrank, and Tardos (STOC \u201897, JACM \u201899). More generally, we show that the maximum load exceeds \\(r\\cdotlog n/loglog n\\) with probability at most \\(O(1/r^2)\\).</p>\n", "tags": ["Hashing Methods"], "tsne_embedding": [26.554584503173828, -6.325267791748047], "cluster": 7}, {"key": "jacques2016time", "year": "2016", "citations": "31", "title": "Time For Dithering: Fast And Quantized Random Embeddings Via The Restricted Isometry Property", "abstract": "<p>Recently, many works have focused on the characterization of non-linear\ndimensionality reduction methods obtained by quantizing linear embeddings,\ne.g., to reach fast processing time, efficient data compression procedures,\nnovel geometry-preserving embeddings or to estimate the information/bits stored\nin this reduced data representation. In this work, we prove that many linear\nmaps known to respect the restricted isometry property (RIP) can induce a\nquantized random embedding with controllable multiplicative and additive\ndistortions with respect to the pairwise distances of the data points beings\nconsidered. In other words, linear matrices having fast matrix-vector\nmultiplication algorithms (e.g., based on partial Fourier ensembles or on the\nadjacency matrix of unbalanced expanders) can be readily used in the definition\nof fast quantized embeddings with small distortions. This implication is made\npossible by applying right after the linear map an additive and random \u201cdither\u201d\nthat stabilizes the impact of the uniform scalar quantization operator applied\nafterwards. For different categories of RIP matrices, i.e., for different\nlinear embeddings of a metric space \\((\\mathcal K \\subset \\mathbb R^n, \\ell_q)\\)\nin \\((\\mathbb R^m, \\ell_p)\\) with \\(p,q \\geq 1\\), we derive upper bounds on the\nadditive distortion induced by quantization, showing that it decays either when\nthe embedding dimension \\(m\\) increases or when the distance of a pair of\nembedded vectors in \\(\\mathcal K\\) decreases. Finally, we develop a novel\n\u201cbi-dithered\u201d quantization scheme, which allows for a reduced distortion that\ndecreases when the embedding dimension grows and independently of the\nconsidered pair of vectors.</p>\n", "tags": ["Quantization", "Evaluation"], "tsne_embedding": [35.022342681884766, 1.8638153076171875], "cluster": 7}, {"key": "jafari2022experimental", "year": "2022", "citations": "13", "title": "Experimental Analysis Of Machine Learning Techniques For Finding Search Radius In Locality Sensitive Hashing", "abstract": "<p>Finding similar data in high-dimensional spaces is one of the important tasks\nin multimedia applications. Approaches introduced to find exact searching\ntechniques often use tree-based index structures which are known to suffer from\nthe curse of the dimensionality problem that limits their performance.\nApproximate searching techniques prefer performance over accuracy and they\nreturn good enough results while achieving a better performance. Locality\nSensitive Hashing (LSH) is one of the most popular approximate nearest neighbor\nsearch techniques for high-dimensional spaces. One of the most time-consuming\nprocesses in LSH is to find the neighboring points in the projected spaces. An\nimproved LSH-based index structure, called radius-optimized Locality Sensitive\nHashing (roLSH) has been proposed to utilize Machine Learning and efficiently\nfind these neighboring points; thus, further improve the overall performance of\nLSH. In this paper, we extend roLSH by experimentally studying the effect of\ndifferent types of famous Machine Learning techniques on overall performance.\nWe compare ten regression techniques on four real-world datasets and show that\nNeural Network-based techniques are the best fit to be used in roLSH as their\naccuracy and performance trade-off are the best compared to the other\ntechniques.</p>\n", "tags": ["Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Tree Based ANN", "Vector Indexing", "Evaluation"], "tsne_embedding": [11.732401847839355, -0.35537195205688477], "cluster": 4}, {"key": "jagadeesan2019understanding", "year": "2019", "citations": "6", "title": "Understanding Sparse JL For Feature Hashing", "abstract": "<p>Feature hashing and other random projection schemes are commonly used to\nreduce the dimensionality of feature vectors. The goal is to efficiently\nproject a high-dimensional feature vector living in \\(\\mathbb{R}^n\\) into a much\nlower-dimensional space \\(\\mathbb{R}^m\\), while approximately preserving\nEuclidean norm. These schemes can be constructed using sparse random\nprojections, for example using a sparse Johnson-Lindenstrauss (JL) transform. A\nline of work introduced by Weinberger et. al (ICML \u201809) analyzes the accuracy\nof sparse JL with sparsity 1 on feature vectors with small\n\\(\\ell_\\infty\\)-to-\\(\u2113\u2082\\) norm ratio. Recently, Freksen, Kamma, and Larsen\n(NeurIPS \u201818) closed this line of work by proving a tight tradeoff between\n\\(\\ell_\\infty\\)-to-\\(\u2113\u2082\\) norm ratio and accuracy for sparse JL with sparsity\n\\(1\\).\n  In this paper, we demonstrate the benefits of using sparsity \\(s\\) greater than\n\\(1\\) in sparse JL on feature vectors. Our main result is a tight tradeoff\nbetween \\(\\ell_\\infty\\)-to-\\(\u2113\u2082\\) norm ratio and accuracy for a general\nsparsity \\(s\\), that significantly generalizes the result of Freksen et. al. Our\nresult theoretically demonstrates that sparse JL with \\(s &gt; 1\\) can have\nsignificantly better norm-preservation properties on feature vectors than\nsparse JL with \\(s = 1\\); we also empirically demonstrate this finding.</p>\n", "tags": ["ICML", "Locality Sensitive Hashing", "Hashing Methods"], "tsne_embedding": [33.22461700439453, 1.1476082801818848], "cluster": 7}, {"key": "jain2016approximate", "year": "2016", "citations": "17", "title": "Approximate Search With Quantized Sparse Representations", "abstract": "<p>This paper tackles the task of storing a large collection of vectors, such as\nvisual descriptors, and of searching in it. To this end, we propose to\napproximate database vectors by constrained sparse coding, where possible atom\nweights are restricted to belong to a finite subset. This formulation\nencompasses, as particular cases, previous state-of-the-art methods such as\nproduct or residual quantization. As opposed to traditional sparse coding\nmethods, quantized sparse coding includes memory usage as a design constraint,\nthereby allowing us to index a large collection such as the BIGANN\nbillion-sized benchmark. Our experiments, carried out on standard benchmarks,\nshow that our formulation leads to competitive solutions when considering\ndifferent trade-offs between learning/coding time, index size and search\nquality.</p>\n", "tags": ["Quantization", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [8.182172775268555, -6.502747058868408], "cluster": 2}, {"key": "jain2017asymmetric", "year": "2017", "citations": "20", "title": "Asymmetric Learning Vector Quantization For Efficient Nearest Neighbor Classification In Dynamic Time Warping Spaces", "abstract": "<p>The nearest neighbor method together with the dynamic time warping (DTW)\ndistance is one of the most popular approaches in time series classification.\nThis method suffers from high storage and computation requirements for large\ntraining sets. As a solution to both drawbacks, this article extends learning\nvector quantization (LVQ) from Euclidean spaces to DTW spaces. The proposed LVQ\nscheme uses asymmetric weighted averaging as update rule. Empirical results\nexhibited superior performance of asymmetric generalized LVQ (GLVQ) over other\nstate-of-the-art prototype generation methods for nearest neighbor\nclassification.</p>\n", "tags": ["CVPR", "Quantization", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [-0.6046276092529297, -9.233084678649902], "cluster": 9}, {"key": "jain2017compact", "year": "2017", "citations": "6", "title": "Compact Environment-invariant Codes For Robust Visual Place Recognition", "abstract": "<p>Robust visual place recognition (VPR) requires scene representations that are\ninvariant to various environmental challenges such as seasonal changes and\nvariations due to ambient lighting conditions during day and night. Moreover, a\npractical VPR system necessitates compact representations of environmental\nfeatures. To satisfy these requirements, in this paper we suggest a\nmodification to the existing pipeline of VPR systems to incorporate supervised\nhashing. The modified system learns (in a supervised setting) compact binary\ncodes from image feature descriptors. These binary codes imbibe robustness to\nthe visual variations exposed to it during the training phase, thereby, making\nthe system adaptive to severe environmental changes. Also, incorporating\nsupervised hashing makes VPR computationally more efficient and easy to\nimplement on simple hardware. This is because binary embeddings can be learned\nover simple-to-compute features and the distance computation is also in the\nlow-dimensional hamming space of binary codes. We have performed experiments on\nseveral challenging data sets covering seasonal, illumination and viewpoint\nvariations. We also compare two widely used supervised hashing methods of\nCCAITQ and MLH and show that this new pipeline out-performs or closely matches\nthe state-of-the-art deep learning VPR methods that are based on\nhigh-dimensional features extracted from pre-trained deep convolutional neural\nnetworks.</p>\n", "tags": ["Compact Codes", "Hashing Methods", "Robustness"], "tsne_embedding": [-8.012017250061035, 13.631234169006348], "cluster": 6}, {"key": "jain2017learning", "year": "2017", "citations": "14", "title": "Learning A Complete Image Indexing Pipeline", "abstract": "<p>To work at scale, a complete image indexing system comprises two components:\nAn inverted file index to restrict the actual search to only a subset that\nshould contain most of the items relevant to the query; An approximate distance\ncomputation mechanism to rapidly scan these lists. While supervised deep\nlearning has recently enabled improvements to the latter, the former continues\nto be based on unsupervised clustering in the literature. In this work, we\npropose a first system that learns both components within a unifying neural\nframework of structured binary encoding.</p>\n", "tags": ["CVPR", "Vector Indexing", "Tools & Libraries", "Hashing Methods"], "tsne_embedding": [-5.903992176055908, 6.86659574508667], "cluster": 8}, {"key": "jain2017subic", "year": "2017", "citations": "61", "title": "SUBIC: A Supervised, Structured Binary Code For Image Search", "abstract": "<p>For large-scale visual search, highly compressed yet meaningful\nrepresentations of images are essential. Structured vector quantizers based on\nproduct quantization and its variants are usually employed to achieve such\ncompression while minimizing the loss of accuracy. Yet, unlike binary hashing\nschemes, these unsupervised methods have not yet benefited from the\nsupervision, end-to-end learning and novel architectures ushered in by the deep\nlearning revolution. We hence propose herein a novel method to make deep\nconvolutional neural networks produce supervised, compact, structured binary\ncodes for visual search. Our method makes use of a novel block-softmax\nnon-linearity and of batch-based entropy losses that together induce structure\nin the learned encodings. We show that our method outperforms state-of-the-art\ncompact representations based on deep hashing or structured quantization in\nsingle and cross-domain category retrieval, instance retrieval and\nclassification. We make our code and models publicly available online.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Compact Codes", "Neural Hashing", "ICCV", "Quantization"], "tsne_embedding": [-6.08902645111084, 5.915395736694336], "cluster": 8}, {"key": "jain2025fast", "year": "2025", "citations": "264", "title": "Fast Similarity Search For Learned Metrics", "abstract": "<p>We propose a method to efficiently index into a large database of examples according to a learned metric.\nGiven a collection of examples, we learn a Mahalanobis distance using an information-theoretic metric\nlearning technique that adapts prior knowledge about pairwise distances to incorporate similarity and dissimilarity\nconstraints. To enable sub-linear time similarity search under the learned metric, we show how\nto encode a learned Mahalanobis parameterization into randomized locality-sensitive hash functions. We\nfurther formulate an indirect solution that enables metric learning and hashing for sparse input vector spaces\nwhose high dimensionality make it infeasible to learn an explicit weighting over the feature dimensions.\nWe demonstrate the approach applied to systems and image datasets, and show that our learned metrics\nimprove accuracy relative to commonly-used metric baselines, while our hashing construction permits effi-\ncient indexing with a learned distance and very large databases.</p>\n", "tags": ["DATASETS", "Similarity Search", "Hashing Methods", "Distance Metric Learning"], "tsne_embedding": [-18.936586380004883, 8.461661338806152], "cluster": 3}, {"key": "jain2025hashing", "year": "2025", "citations": "69", "title": "Hashing Hyperplane Queries To Near Points With Applications To Large-scale Active Learning", "abstract": "<p>We consider the problem of retrieving the database points nearest to a given hyperplane query without exhaustively scanning the \ndatabase. We propose two hashing-based solutions. Our first approach maps the data to two-bit binary keys that are locality-sensitive for the angle between the hyperplane normal and a database point. Our second approach embeds the data into a vector space where the Euclidean norm reflects the desired distance between the original points and hyperplane query. Both use hashing to retrieve near points in sub-linear time. Our first method\u2019s preprocessing stage is more efficient, while the second has stronger accuracy guarantees. We apply both to pool-based active learning: taking the current hyperplane classifier as a query, our algorithm identifies those points (approximately) satisfying the well-known minimal distance-to-hyperplane selection criterion. We empirically demonstrate our methods\u2019 tradeoffs, and show that they make it practical to perform active selection with millions \nof unlabeled points.</p>\n", "tags": ["Tools & Libraries", "Hashing Methods", "Evaluation"], "tsne_embedding": [8.228623390197754, -4.722035884857178], "cluster": 2}, {"key": "jaiswal2022ood", "year": "2022", "citations": "47", "title": "Ood-diskann: Efficient And Scalable Graph ANNS For Out-of-distribution Queries", "abstract": "<p>State-of-the-art algorithms for Approximate Nearest Neighbor Search (ANNS)\nsuch as DiskANN, FAISS-IVF, and HNSW build data dependent indices that offer\nsubstantially better accuracy and search efficiency over data-agnostic indices\nby overfitting to the index data distribution. When the query data is drawn\nfrom a different distribution - e.g., when index represents image embeddings\nand query represents textual embeddings - such algorithms lose much of this\nperformance advantage. On a variety of datasets, for a fixed recall target,\nlatency is worse by an order of magnitude or more for Out-Of-Distribution (OOD)\nqueries as compared to In-Distribution (ID) queries. The question we address in\nthis work is whether ANNS algorithms can be made efficient for OOD queries if\nthe index construction is given access to a small sample set of these queries.\nWe answer positively by presenting OOD-DiskANN, which uses a sparing sample (1%\nof index set size) of OOD queries, and provides up to 40% improvement in mean\nquery latency over SoTA algorithms of a similar memory footprint. OOD-DiskANN\nis scalable and has the efficiency of graph-based ANNS indices. Some of our\ncontributions can improve query efficiency for ID queries as well.</p>\n", "tags": ["DATASETS", "Graph Based ANN", "Efficiency And Optimization", "Vector Indexing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [11.464598655700684, 1.6574360132217407], "cluster": 4}, {"key": "jang2020generalized", "year": "2020", "citations": "41", "title": "Generalized Product Quantization Network For Semi-supervised Image Retrieval", "abstract": "<p>Image retrieval methods that employ hashing or vector quantization have\nachieved great success by taking advantage of deep learning. However, these\napproaches do not meet expectations unless expensive label information is\nsufficient. To resolve this issue, we propose the first quantization-based\nsemi-supervised image retrieval scheme: Generalized Product Quantization (GPQ)\nnetwork. We design a novel metric learning strategy that preserves semantic\nsimilarity between labeled data, and employ entropy regularization term to\nfully exploit inherent potentials of unlabeled data. Our solution increases the\ngeneralization capacity of the quantization network, which allows overcoming\nprevious limitations in the retrieval community. Extensive experimental results\ndemonstrate that GPQ yields state-of-the-art performance on large-scale real\nimage benchmark datasets.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Distance Metric Learning", "CVPR", "Quantization", "Evaluation"], "tsne_embedding": [-17.022602081298828, 11.239457130432129], "cluster": 3}, {"key": "jang2021deep", "year": "2021", "citations": "23", "title": "Deep Hash Distillation For Image Retrieval", "abstract": "<p>In hash-based image retrieval systems, degraded or transformed inputs usually\ngenerate different codes from the original, deteriorating the retrieval\naccuracy. To mitigate this issue, data augmentation can be applied during\ntraining. However, even if augmented samples of an image are similar in real\nfeature space, the quantization can scatter them far away in Hamming space.\nThis results in representation discrepancies that can impede training and\ndegrade performance. In this work, we propose a novel self-distilled hashing\nscheme to minimize the discrepancy while exploiting the potential of augmented\ndata. By transferring the hash knowledge of the weakly-transformed samples to\nthe strong ones, we make the hash code insensitive to various transformations.\nWe also introduce hash proxy-based similarity learning and binary cross\nentropy-based quantization loss to provide fine quality hash codes. Ultimately,\nwe construct a deep hashing framework that not only improves the existing deep\nhashing approaches, but also achieves the state-of-the-art retrieval results.\nExtensive experiments are conducted and confirm the effectiveness of our work.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Neural Hashing", "Quantization", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-11.785058975219727, 5.237826347351074], "cluster": 8}, {"key": "jang2021self", "year": "2021", "citations": "52", "title": "Self-supervised Product Quantization For Deep Unsupervised Image Retrieval", "abstract": "<p>Supervised deep learning-based hash and vector quantization are enabling fast\nand large-scale image retrieval systems. By fully exploiting label annotations,\nthey are achieving outstanding retrieval performances compared to the\nconventional methods. However, it is painstaking to assign labels precisely for\na vast amount of training data, and also, the annotation process is\nerror-prone. To tackle these issues, we propose the first deep unsupervised\nimage retrieval method dubbed Self-supervised Product Quantization (SPQ)\nnetwork, which is label-free and trained in a self-supervised manner. We design\na Cross Quantized Contrastive learning strategy that jointly learns codewords\nand deep visual descriptors by comparing individually transformed images\n(views). Our method analyzes the image contents to extract descriptive\nfeatures, allowing us to understand image representations for accurate\nretrieval. By conducting extensive experiments on benchmarks, we demonstrate\nthat the proposed method yields state-of-the-art results even without\nsupervised pretraining.</p>\n", "tags": ["ICCV", "Image Retrieval", "Quantization", "Evaluation"], "tsne_embedding": [-19.1711483001709, -0.6893317103385925], "cluster": 1}, {"key": "jang2021similarity", "year": "2021", "citations": "8", "title": "Similarity Guided Deep Face Image Retrieval", "abstract": "<p>Face image retrieval, which searches for images of the same identity from the\nquery input face image, is drawing more attention as the size of the image\ndatabase increases rapidly. In order to conduct fast and accurate retrieval, a\ncompact hash code-based methods have been proposed, and recently, deep face\nimage hashing methods with supervised classification training have shown\noutstanding performance. However, classification-based scheme has a\ndisadvantage in that it cannot reveal complex similarities between face images\ninto the hash code learning. In this paper, we attempt to improve the face\nimage retrieval quality by proposing a Similarity Guided Hashing (SGH) method,\nwhich gently considers self and pairwise-similarity simultaneously. SGH employs\nvarious data augmentations designed to explore elaborate similarities between\nface images, solving both intra and inter identity-wise difficulties. Extensive\nexperimental results on the protocols with existing benchmarks and an\nadditionally proposed large scale higher resolution face image dataset\ndemonstrate that our SGH delivers state-of-the-art retrieval performance.</p>\n", "tags": ["DATASETS", "Evaluation", "Hashing Methods", "Image Retrieval", "Tools & Libraries", "Multimodal Retrieval"], "tsne_embedding": [-13.676864624023438, 3.8082871437072754], "cluster": 8}, {"key": "jang2021ultra", "year": "2021", "citations": "9", "title": "Ultra-high Dimensional Sparse Representations With Binarization For Efficient Text Retrieval", "abstract": "<p>The semantic matching capabilities of neural information retrieval can\nameliorate synonymy and polysemy problems of symbolic approaches. However,\nneural models\u2019 dense representations are more suitable for re-ranking, due to\ntheir inefficiency. Sparse representations, either in symbolic or latent form,\nare more efficient with an inverted index. Taking the merits of the sparse and\ndense representations, we propose an ultra-high dimensional (UHD)\nrepresentation scheme equipped with directly controllable sparsity. UHD\u2019s large\ncapacity and minimal noise and interference among the dimensions allow for\nbinarized representations, which are highly efficient for storage and search.\nAlso proposed is a bucketing method, where the embeddings from multiple layers\nof BERT are selected/merged to represent diverse linguistic aspects. We test\nour models with MS MARCO and TREC CAR, showing that our models outperforms\nother sparse models</p>\n", "tags": ["Text Retrieval", "EMNLP", "Efficiency And Optimization"], "tsne_embedding": [12.701111793518066, -9.753987312316895], "cluster": 2}, {"key": "jedidi2024zero", "year": "2024", "citations": "77", "title": "Zero-shot Dense Retrieval With Embeddings From Relevance Feedback", "abstract": "<p>Building effective dense retrieval systems remains difficult when relevance\nsupervision is not available. Recent work has looked to overcome this challenge\nby using a Large Language Model (LLM) to generate hypothetical documents that\ncan be used to find the closest real document. However, this approach relies\nsolely on the LLM to have domain-specific knowledge relevant to the query,\nwhich may not be practical. Furthermore, generating hypothetical documents can\nbe inefficient as it requires the LLM to generate a large number of tokens for\neach query. To address these challenges, we introduce Real Document Embeddings\nfrom Relevance Feedback (ReDE-RF). Inspired by relevance feedback, ReDE-RF\nproposes to re-frame hypothetical document generation as a relevance estimation\ntask, using an LLM to select which documents should be used for nearest\nneighbor search. Through this re-framing, the LLM no longer needs\ndomain-specific knowledge but only needs to judge what is relevant.\nAdditionally, relevance estimation only requires the LLM to output a single\ntoken, thereby improving search latency. Our experiments show that ReDE-RF\nconsistently surpasses state-of-the-art zero-shot dense retrieval methods\nacross a wide range of low-resource retrieval datasets while also making\nsignificant improvements in latency per-query.</p>\n", "tags": ["DATASETS", "ACL", "Efficiency And Optimization"], "tsne_embedding": [-19.041845321655273, -9.651677131652832], "cluster": 1}, {"key": "jegou2025searching", "year": "2025", "citations": "17", "title": "Searching With Quantization: Approximate Nearest Neighbor Search Using Short Codes And Distance Estimators", "abstract": "<p>We propose an approximate nearest neighbor search method based\non quantization. It uses, in particular, product quantizer to produce short codes\nand corresponding distance estimators approximating the Euclidean distance\nbetween the orginal vectors. The method is advantageously used in an asymmetric\nmanner, by computing the distance between a vector and code, unlike\ncompeting techniques such as spectral hashing that only compare codes.\nOur approach approximates the Euclidean distance based on memory efficient codes and, thus, permits efficient nearest neighbor search. Experiments\nperformed on SIFT and GIST image descriptors show excellent search accuracy.\nThe method is shown to outperform two state-of-the-art approaches of the literature.\nTimings measured when searching a vector set of 2 billion vectors are\nshown to be excellent given the high accuracy of the method.</p>\n", "tags": ["Compact Codes", "Hashing Methods", "Quantization", "Distance Metric Learning"], "tsne_embedding": [21.523643493652344, -7.125648021697998], "cluster": 7}, {"key": "jeong2018efficient", "year": "2018", "citations": "9", "title": "Efficient End-to-end Learning For Quantizable Representations", "abstract": "<p>Embedding representation learning via neural networks is at the core\nfoundation of modern similarity based search. While much effort has been put in\ndeveloping algorithms for learning binary hamming code representations for\nsearch efficiency, this still requires a linear scan of the entire dataset per\neach query and trades off the search accuracy through binarization. To this\nend, we consider the problem of directly learning a quantizable embedding\nrepresentation and the sparse binary hash code end-to-end which can be used to\nconstruct an efficient hash table not only providing significant search\nreduction in the number of data but also achieving the state of the art search\naccuracy outperforming previous state of the art deep metric learning methods.\nWe also show that finding the optimal sparse binary hash code in a mini-batch\ncan be computed exactly in polynomial time by solving a minimum cost flow\nproblem. Our results on Cifar-100 and on ImageNet datasets show the state of\nthe art search accuracy in precision@k and NMI metrics while providing up to\n98X and 478X search speedup respectively over exhaustive linear search. The\nsource code is available at\nhttps://github.com/maestrojeong/Deep-Hash-Table-ICML18</p>\n", "tags": ["ICML", "DATASETS", "Hashing Methods", "Distance Metric Learning", "Efficiency And Optimization", "Evaluation"], "tsne_embedding": [-4.052663803100586, -12.105870246887207], "cluster": 9}, {"key": "ji2018attribute", "year": "2018", "citations": "83", "title": "Attribute-guided Network For Cross-modal Zero-shot Hashing", "abstract": "<p>Zero-Shot Hashing aims at learning a hashing model that is trained only by\ninstances from seen categories but can generate well to those of unseen\ncategories. Typically, it is achieved by utilizing a semantic embedding space\nto transfer knowledge from seen domain to unseen domain. Existing efforts\nmainly focus on single-modal retrieval task, especially Image-Based Image\nRetrieval (IBIR). However, as a highlighted research topic in the field of\nhashing, cross-modal retrieval is more common in real world applications. To\naddress the Cross-Modal Zero-Shot Hashing (CMZSH) retrieval task, we propose a\nnovel Attribute-Guided Network (AgNet), which can perform not only IBIR, but\nalso Text-Based Image Retrieval (TBIR). In particular, AgNet aligns different\nmodal data into a semantically rich attribute space, which bridges the gap\ncaused by modality heterogeneity and zero-shot setting. We also design an\neffective strategy that exploits the attribute to guide the generation of hash\ncodes for image and text within the same network. Extensive experimental\nresults on three benchmark datasets (AwA, SUN, and ImageNet) demonstrate the\nsuperiority of AgNet on both cross-modal and single-modal zero-shot image\nretrieval tasks.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Multimodal Retrieval", "Evaluation"], "tsne_embedding": [-12.536656379699707, 1.843204140663147], "cluster": 8}, {"key": "jia2019efficient", "year": "2019", "citations": "129", "title": "Efficient Task-specific Data Valuation For Nearest Neighbor Algorithms", "abstract": "<p>Given a data set \\(\\mathcal{D}\\) containing millions of data points and a data\nconsumer who is willing to pay for $\\(X\\) to train a machine learning (ML) model\nover \\(\\mathcal{D}\\), how should we distribute this $\\(X\\) to each data point to\nreflect its \u201cvalue\u201d? In this paper, we define the \u201crelative value of data\u201d via\nthe Shapley value, as it uniquely possesses properties with appealing\nreal-world interpretations, such as fairness, rationality and\ndecentralizability. For general, bounded utility functions, the Shapley value\nis known to be challenging to compute: to get Shapley values for all \\(N\\) data\npoints, it requires \\(O(2^N)\\) model evaluations for exact computation and\n\\(O(Nlog N)\\) for \\((\\epsilon, \\delta)\\)-approximation. In this paper, we focus on\none popular family of ML models relying on \\(K\\)-nearest neighbors (\\(K\\)NN). The\nmost surprising result is that for unweighted \\(K\\)NN classifiers and regressors,\nthe Shapley value of all \\(N\\) data points can be computed, exactly, in \\(O(Nlog\nN)\\) time \u2013 an exponential improvement on computational complexity! Moreover,\nfor \\((\\epsilon, \\delta)\\)-approximation, we are able to develop an algorithm\nbased on Locality Sensitive Hashing (LSH) with only sublinear complexity\n\\(O(N^{h(\\epsilon,K)}log N)\\) when \\(\\epsilon\\) is not too small and \\(K\\) is not\ntoo large. We empirically evaluate our algorithms on up to \\(10\\) million data\npoints and even our exact algorithm is up to three orders of magnitude faster\nthan the baseline approximation algorithm. The LSH-based approximation\nalgorithm can accelerate the value calculation process even further. We then\nextend our algorithms to other scenarios such as (1) weighed \\(K\\)NN classifiers,\n(2) different data points are clustered by different data curators, and (3)\nthere are data analysts providing computation who also requires proper\nvaluation.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Evaluation"], "tsne_embedding": [29.55815315246582, 0.32791152596473694], "cluster": 7}, {"key": "jia2021joint", "year": "2021", "citations": "46", "title": "Joint Representation Learning And Novel Category Discovery On Single- And Multi-modal Data", "abstract": "<p>This paper studies the problem of novel category discovery on single- and\nmulti-modal data with labels from different but relevant categories. We present\na generic, end-to-end framework to jointly learn a reliable representation and\nassign clusters to unlabelled data. To avoid over-fitting the learnt embedding\nto labelled data, we take inspiration from self-supervised representation\nlearning by noise-contrastive estimation and extend it to jointly handle\nlabelled and unlabelled data. In particular, we propose using category\ndiscrimination on labelled data and cross-modal discrimination on multi-modal\ndata to augment instance discrimination used in conventional contrastive\nlearning approaches. We further employ Winner-Take-All (WTA) hashing algorithm\non the shared representation space to generate pairwise pseudo labels for\nunlabelled data to better predict cluster assignments. We thoroughly evaluate\nour framework on large-scale multi-modal video benchmarks Kinetics-400 and\nVGG-Sound, and image benchmarks CIFAR10, CIFAR100 and ImageNet, obtaining\nstate-of-the-art results.</p>\n", "tags": ["ICCV", "Tools & Libraries", "Hashing Methods", "Evaluation"], "tsne_embedding": [-3.2993273735046387, 1.5905892848968506], "cluster": 8}, {"key": "jia2022fast", "year": "2022", "citations": "6", "title": "Fast Online Hashing With Multi-label Projection", "abstract": "<p>Hashing has been widely researched to solve the large-scale approximate\nnearest neighbor search problem owing to its time and storage superiority. In\nrecent years, a number of online hashing methods have emerged, which can update\nthe hash functions to adapt to the new stream data and realize dynamic\nretrieval. However, existing online hashing methods are required to update the\nwhole database with the latest hash functions when a query arrives, which leads\nto low retrieval efficiency with the continuous increase of the stream data. On\nthe other hand, these methods ignore the supervision relationship among the\nexamples, especially in the multi-label case. In this paper, we propose a novel\nFast Online Hashing (FOH) method which only updates the binary codes of a small\npart of the database. To be specific, we first build a query pool in which the\nnearest neighbors of each central point are recorded. When a new query arrives,\nonly the binary codes of the corresponding potential neighbors are updated. In\naddition, we create a similarity matrix which takes the multi-label supervision\ninformation into account and bring in the multi-label projection loss to\nfurther preserve the similarity among the multi-label data. The experimental\nresults on two common benchmarks show that the proposed FOH can achieve\ndramatic superiority on query time up to 6.28 seconds less than\nstate-of-the-art baselines with competitive retrieval accuracy.</p>\n", "tags": ["AAAI", "Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Evaluation"], "tsne_embedding": [4.604401588439941, -8.908449172973633], "cluster": 2}, {"key": "jiang2016deep", "year": "2016", "citations": "752", "title": "Deep Cross-modal Hashing", "abstract": "<p>Due to its low storage cost and fast query speed, cross-modal hashing (CMH)\nhas been widely used for similarity search in multimedia retrieval\napplications. However, almost all existing CMH methods are based on\nhand-crafted features which might not be optimally compatible with the\nhash-code learning procedure. As a result, existing CMH methods with\nhandcrafted features may not achieve satisfactory performance. In this paper,\nwe propose a novel cross-modal hashing method, called deep crossmodal hashing\n(DCMH), by integrating feature learning and hash-code learning into the same\nframework. DCMH is an end-to-end learning framework with deep neural networks,\none for each modality, to perform feature learning from scratch. Experiments on\ntwo real datasets with text-image modalities show that DCMH can outperform\nother baselines to achieve the state-of-the-art performance in cross-modal\nretrieval applications.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "CVPR", "Similarity Search", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-4.049768924713135, -1.885961890220642], "cluster": 8}, {"key": "jiang2017asymmetric", "year": "2017", "citations": "248", "title": "Asymmetric Deep Supervised Hashing", "abstract": "<p>Hashing has been widely used for large-scale approximate nearest neighbor\nsearch because of its storage and search efficiency. Recent work has found that\ndeep supervised hashing can significantly outperform non-deep supervised\nhashing in many applications. However, most existing deep supervised hashing\nmethods adopt a symmetric strategy to learn one deep hash function for both\nquery points and database (retrieval) points. The training of these symmetric\ndeep supervised hashing methods is typically time-consuming, which makes them\nhard to effectively utilize the supervised information for cases with\nlarge-scale database. In this paper, we propose a novel deep supervised hashing\nmethod, called asymmetric deep supervised hashing (ADSH), for large-scale\nnearest neighbor search. ADSH treats the query points and database points in an\nasymmetric way. More specifically, ADSH learns a deep hash function only for\nquery points, while the hash codes for database points are directly learned.\nThe training of ADSH is much more efficient than that of traditional symmetric\ndeep supervised hashing methods. Experiments show that ADSH can achieve\nstate-of-the-art performance in real applications.</p>\n", "tags": ["AAAI", "Hashing Methods", "Efficiency And Optimization", "Neural Hashing", "Evaluation"], "tsne_embedding": [-3.9195923805236816, -9.19041633605957], "cluster": 9}, {"key": "jiang2017discrete", "year": "2017", "citations": "143", "title": "Discrete Latent Factor Model For Cross-modal Hashing", "abstract": "<p>Due to its storage and retrieval efficiency, cross-modal hashing~(CMH) has\nbeen widely used for cross-modal similarity search in multimedia applications.\nAccording to the training strategy, existing CMH methods can be mainly divided\ninto two categories: relaxation-based continuous methods and discrete methods.\nIn general, the training of relaxation-based continuous methods is faster than\ndiscrete methods, but the accuracy of relaxation-based continuous methods is\nnot satisfactory. On the contrary, the accuracy of discrete methods is\ntypically better than relaxation-based continuous methods, but the training of\ndiscrete methods is time-consuming. In this paper, we propose a novel CMH\nmethod, called discrete latent factor model based cross-modal hashing~(DLFH),\nfor cross modal similarity search. DLFH is a discrete method which can directly\nlearn the binary hash codes for CMH. At the same time, the training of DLFH is\nefficient. Experiments on real datasets show that DLFH can achieve\nsignificantly better accuracy than existing methods, and the training time of\nDLFH is comparable to that of relaxation-based continuous methods which are\nmuch faster than existing discrete methods.</p>\n", "tags": ["DATASETS", "Similarity Search", "Hashing Methods", "Efficiency And Optimization"], "tsne_embedding": [-4.182002067565918, -7.33543586730957], "cluster": 9}, {"key": "jiang2019evaluation", "year": "2019", "citations": "15", "title": "On The Evaluation Metric For Hashing", "abstract": "<p>Due to its low storage cost and fast query speed, hashing has been widely\nused for large-scale approximate nearest neighbor (ANN) search. Bucket search,\nalso called hash lookup, can achieve fast query speed with a sub-linear time\ncost based on the inverted index table constructed from hash codes. Many\nmetrics have been adopted to evaluate hashing algorithms. However, all existing\nmetrics are improper to evaluate the hash codes for bucket search. On one hand,\nall existing metrics ignore the retrieval time cost which is an important\nfactor reflecting the performance of search. On the other hand, some of them,\nsuch as mean average precision (MAP), suffer from the uncertainty problem as\nthe ranked list is based on integer-valued Hamming distance, and are\ninsensitive to Hamming radius as these metrics only depend on relative Hamming\ndistance. Other metrics, such as precision at Hamming radius R, fail to\nevaluate global performance as these metrics only depend on one specific\nHamming radius. In this paper, we first point out the problems of existing\nmetrics which have been ignored by the hashing community, and then propose a\nnovel evaluation metric called radius aware mean average precision (RAMAP) to\nevaluate hash codes for bucket search. Furthermore, two coding strategies are\nalso proposed to qualitatively show the problems of existing metrics.\nExperiments demonstrate that our proposed RAMAP can provide more proper\nevaluation than existing metrics.</p>\n", "tags": ["Hashing Methods", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [-0.5245591402053833, -28.119733810424805], "cluster": 5}, {"key": "jiang2019graph", "year": "2019", "citations": "28", "title": "Graph-based Multi-view Binary Learning For Image Clustering", "abstract": "<p>Hashing techniques, also known as binary code learning, have recently gained\nincreasing attention in large-scale data analysis and storage. Generally, most\nexisting hash clustering methods are single-view ones, which lack complete\nstructure or complementary information from multiple views. For cluster tasks,\nabundant prior researches mainly focus on learning discrete hash code while few\nworks take original data structure into consideration. To address these\nproblems, we propose a novel binary code algorithm for clustering, which adopts\ngraph embedding to preserve the original data structure, called (Graph-based\nMulti-view Binary Learning) GMBL in this paper. GMBL mainly focuses on encoding\nthe information of multiple views into a compact binary code, which explores\ncomplementary information from multiple views. In particular, in order to\nmaintain the graph-based structure of the original data, we adopt a Laplacian\nmatrix to preserve the local linear relationship of the data and map it to the\nHamming space. Considering different views have distinctive contributions to\nthe final clustering results, GMBL adopts a strategy of automatically assign\nweights for each view to better guide the clustering. Finally, An alternating\niterative optimization method is adopted to optimize discrete binary codes\ndirectly instead of relaxing the binary constraint in two steps. Experiments on\nfive public datasets demonstrate the superiority of our proposed method\ncompared with previous approaches in terms of clustering performance.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Graph Based ANN", "Compact Codes", "Alt", "Evaluation"], "tsne_embedding": [15.317449569702148, 11.812299728393555], "cluster": 0}, {"key": "jiang2025scalable", "year": "2025", "citations": "208", "title": "Scalable Graph Hashing With Feature Transformation", "abstract": "<p>Hashing has been widely used for approximate nearest\nneighbor (ANN) search in big data applications\nbecause of its low storage cost and fast retrieval\nspeed. The goal of hashing is to map the data\npoints from the original space into a binary-code\nspace where the similarity (neighborhood structure)\nin the original space is preserved. By directly\nexploiting the similarity to guide the hashing\ncode learning procedure, graph hashing has attracted\nmuch attention. However, most existing graph\nhashing methods cannot achieve satisfactory performance\nin real applications due to the high complexity\nfor graph modeling. In this paper, we propose\na novel method, called scalable graph hashing\nwith feature transformation (SGH), for large-scale\ngraph hashing. Through feature transformation, we\ncan effectively approximate the whole graph without\nexplicitly computing the similarity graph matrix,\nbased on which a sequential learning method\nis proposed to learn the hash functions in a bit-wise\nmanner. Experiments on two datasets with one million\ndata points show that our SGH method can\noutperform the state-of-the-art methods in terms of\nboth accuracy and scalability.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [18.253955841064453, 13.291036605834961], "cluster": 0}, {"key": "jin2017ranking", "year": "2017", "citations": "195", "title": "Ranking Based Locality Sensitive Hashing Enabled Cancelable Biometrics: Index-of-max Hashing", "abstract": "<p>In this paper, we propose a ranking based locality sensitive hashing inspired\ntwo-factor cancelable biometrics, dubbed \u201cIndex-of-Max\u201d (IoM) hashing for\nbiometric template protection. With externally generated random parameters, IoM\nhashing transforms a real-valued biometric feature vector into discrete index\n(max ranked) hashed code. We demonstrate two realizations from IoM hashing\nnotion, namely Gaussian Random Projection based and Uniformly Random\nPermutation based hashing schemes. The discrete indices representation nature\nof IoM hashed codes enjoy serveral merits. Firstly, IoM hashing empowers strong\nconcealment to the biometric information. This contributes to the solid ground\nof non-invertibility guarantee. Secondly, IoM hashing is insensitive to the\nfeatures magnitude, hence is more robust against biometric features variation.\nThirdly, the magnitude-independence trait of IoM hashing makes the hash codes\nbeing scale-invariant, which is critical for matching and feature alignment.\nThe experimental results demonstrate favorable accuracy performance on\nbenchmark FVC2002 and FVC2004 fingerprint databases. The analyses justify its\nresilience to the existing and newly introduced security and privacy attacks as\nwell as satisfy the revocability and unlinkability criteria of cancelable\nbiometrics.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Evaluation"], "tsne_embedding": [6.135211944580078, -26.382532119750977], "cluster": 5}, {"key": "jin2018deep", "year": "2018", "citations": "57", "title": "Deep Saliency Hashing", "abstract": "<p>In recent years, hashing methods have been proved to be effective and\nefficient for the large-scale Web media search. However, the existing general\nhashing methods have limited discriminative power for describing fine-grained\nobjects that share similar overall appearance but have subtle difference. To\nsolve this problem, we for the first time introduce the attention mechanism to\nthe learning of fine-grained hashing codes. Specifically, we propose a novel\ndeep hashing model, named deep saliency hashing (DSaH), which automatically\nmines salient regions and learns semantic-preserving hashing codes\nsimultaneously. DSaH is a two-step end-to-end model consisting of an attention\nnetwork and a hashing network. Our loss function contains three basic\ncomponents, including the semantic loss, the saliency loss, and the\nquantization loss. As the core of DSaH, the saliency loss guides the attention\nnetwork to mine discriminative regions from pairs of images. We conduct\nextensive experiments on both fine-grained and general retrieval datasets for\nperformance evaluation. Experimental results on fine-grained datasets,\nincluding Oxford Flowers-17, Stanford Dogs-120, and CUB Bird demonstrate that\nour DSaH performs the best for fine-grained retrieval task and beats the\nstrongest competitor (DTQ) by approximately 10% on both Stanford Dogs-120 and\nCUB Bird. DSaH is also comparable to several state-of-the-art hashing methods\non general datasets, including CIFAR-10 and NUS-WIDE.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Neural Hashing", "Quantization", "Evaluation"], "tsne_embedding": [-13.906015396118164, 0.9680071473121643], "cluster": 8}, {"key": "jin2018unsupervised", "year": "2018", "citations": "25", "title": "Unsupervised Semantic Deep Hashing", "abstract": "<p>In recent years, deep hashing methods have been proved to be efficient since\nit employs convolutional neural network to learn features and hashing codes\nsimultaneously. However, these methods are mostly supervised. In real-world\napplication, it is a time-consuming and overloaded task for annotating a large\nnumber of images. In this paper, we propose a novel unsupervised deep hashing\nmethod for large-scale image retrieval. Our method, namely unsupervised\nsemantic deep hashing (\\textbf{USDH}), uses semantic information preserved in\nthe CNN feature layer to guide the training of network. We enforce four\ncriteria on hashing codes learning based on VGG-19 model: 1) preserving\nrelevant information of feature space in hashing space; 2) minimizing\nquantization loss between binary-like codes and hashing codes; 3) improving the\nusage of each bit in hashing codes by using maximum information entropy, and 4)\ninvariant to image rotation. Extensive experiments on CIFAR-10, NUSWIDE have\ndemonstrated that \\textbf{USDH} outperforms several state-of-the-art\nunsupervised hashing methods for image retrieval. We also conduct experiments\non Oxford 17 datasets for fine-grained classification to verify its efficiency\nfor other computer vision tasks.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Neural Hashing", "Quantization"], "tsne_embedding": [-13.382657051086426, -5.497564792633057], "cluster": 1}, {"key": "jin2019deep", "year": "2019", "citations": "90", "title": "Deep Semantic Multimodal Hashing Network For Scalable Image-text And Video-text Retrievals", "abstract": "<p>Hashing has been widely applied to multimodal retrieval on large-scale\nmultimedia data due to its efficiency in computation and storage. In this\narticle, we propose a novel deep semantic multimodal hashing network (DSMHN)\nfor scalable image-text and video-text retrieval. The proposed deep hashing\nframework leverages 2-D convolutional neural networks (CNN) as the backbone\nnetwork to capture the spatial information for image-text retrieval, while the\n3-D CNN as the backbone network to capture the spatial and temporal information\nfor video-text retrieval. In the DSMHN, two sets of modality-specific hash\nfunctions are jointly learned by explicitly preserving both intermodality\nsimilarities and intramodality semantic labels. Specifically, with the\nassumption that the learned hash codes should be optimal for the classification\ntask, two stream networks are jointly trained to learn the hash functions by\nembedding the semantic labels on the resultant hash codes. Moreover, a unified\ndeep multimodal hashing framework is proposed to learn compact and high-quality\nhash codes by exploiting the feature representation learning, intermodality\nsimilarity-preserving learning, semantic label-preserving learning, and hash\nfunction learning with different types of loss functions simultaneously. The\nproposed DSMHN method is a generic and scalable deep hashing framework for both\nimage-text and video-text retrievals, which can be flexibly integrated with\ndifferent types of loss functions. We conduct extensive experiments for both\nsingle modal- and cross-modal-retrieval tasks on four widely used\nmultimodal-retrieval data sets. Experimental results on both image-text- and\nvideo-text-retrieval tasks demonstrate that the DSMHN significantly outperforms\nthe state-of-the-art methods.</p>\n", "tags": ["Hashing Methods", "Efficiency And Optimization", "Text Retrieval", "Neural Hashing", "Multimodal Retrieval", "Tools & Libraries"], "tsne_embedding": [-10.836390495300293, 0.9820166230201721], "cluster": 8}, {"key": "jin2019node2bits", "year": "2019", "citations": "27", "title": "Node2bits: Compact Time- And Attribute-aware Node Representations For User Stitching", "abstract": "<p>Identity stitching, the task of identifying and matching various online\nreferences (e.g., sessions over different devices and timespans) to the same\nuser in real-world web services, is crucial for personalization and\nrecommendations. However, traditional user stitching approaches, such as\ngrouping or blocking, require quadratic pairwise comparisons between a massive\nnumber of user activities, thus posing both computational and storage\nchallenges. Recent works, which are often application-specific, heuristically\nseek to reduce the amount of comparisons, but they suffer from low precision\nand recall. To solve the problem in an application-independent way, we take a\nheterogeneous network-based approach in which users (nodes) interact with\ncontent (e.g., sessions, websites), and may have attributes (e.g., location).\nWe propose node2bits, an efficient framework that represents multi-dimensional\nfeatures of node contexts with binary hashcodes. node2bits leverages\nfeature-based temporal walks to encapsulate short- and long-term interactions\nbetween nodes in heterogeneous web networks, and adopts SimHash to obtain\ncompact, binary representations and avoid the quadratic complexity for\nsimilarity search. Extensive experiments on large-scale real networks show that\nnode2bits outperforms traditional techniques and existing works that generate\nreal-valued embeddings by up to 5.16% in F1 score on user stitching, while\ntaking only up to 1.56% as much storage.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Recommender Systems", "Similarity Search", "Tools & Libraries", "Evaluation"], "tsne_embedding": [5.238082408905029, -6.107595920562744], "cluster": 2}, {"key": "jin2019ssah", "year": "2019", "citations": "28", "title": "SSAH: Semi-supervised Adversarial Deep Hashing With Self-paced Hard Sample Generation", "abstract": "<p>Deep hashing methods have been proved to be effective and efficient for\nlarge-scale Web media search. The success of these data-driven methods largely\ndepends on collecting sufficient labeled data, which is usually a crucial\nlimitation in practical cases. The current solutions to this issue utilize\nGenerative Adversarial Network (GAN) to augment data in semi-supervised\nlearning. However, existing GAN-based methods treat image generations and\nhashing learning as two isolated processes, leading to generation\nineffectiveness. Besides, most works fail to exploit the semantic information\nin unlabeled data. In this paper, we propose a novel Semi-supervised Self-pace\nAdversarial Hashing method, named SSAH to solve the above problems in a unified\nframework. The SSAH method consists of an adversarial network (A-Net) and a\nhashing network (H-Net). To improve the quality of generative images, first,\nthe A-Net learns hard samples with multi-scale occlusions and multi-angle\nrotated deformations which compete against the learning of accurate hashing\ncodes. Second, we design a novel self-paced hard generation policy to gradually\nincrease the hashing difficulty of generated samples. To make use of the\nsemantic information in unlabeled ones, we propose a semi-supervised consistent\nloss. The experimental results show that our method can significantly improve\nstate-of-the-art models on both the widely-used hashing datasets and\nfine-grained datasets.</p>\n", "tags": ["AAAI", "DATASETS", "Hashing Methods", "Neural Hashing", "Tools & Libraries", "Robustness"], "tsne_embedding": [-9.21549129486084, -2.524122953414917], "cluster": 8}, {"key": "jin2025complementary", "year": "2025", "citations": "59", "title": "Complementary Projection Hashing", "abstract": "<p>Recently, hashing techniques have been widely applied\nto solve the approximate nearest neighbors search problem\nin many vision applications. Generally, these hashing\napproaches generate 2^c buckets, where c is the length\nof the hash code. A good hashing method should satisfy\nthe following two requirements: 1) mapping the nearby\ndata points into the same bucket or nearby (measured by\nthe Hamming distance) buckets. 2) all the data points are\nevenly distributed among all the buckets. In this paper,\nwe propose a novel algorithm named Complementary Projection\nHashing (CPH) to find the optimal hashing functions\nwhich explicitly considers the above two requirements.\nSpecifically, CPH aims at sequentially finding a series of hyperplanes\n(hashing functions) which cross the sparse region\nof the data. At the same time, the data points are evenly distributed\nin the hypercubes generated by these hyperplanes.\nThe experiments comparing with the state-of-the-art hashing\nmethods demonstrate the effectiveness of the proposed\nmethod.</p>\n", "tags": ["ICCV", "Hashing Methods", "Evaluation"], "tsne_embedding": [8.81054973602295, -2.270911931991577], "cluster": 4}, {"key": "jin2025deep", "year": "2025", "citations": "57", "title": "Deep Saliency Hashing For Fine-grained Retrieval", "abstract": "<p>In recent years, hashing methods have been proved to be\neffective and efficient for the large-scale Web media search.\nHowever, the existing general hashing methods have limited discriminative power for describing fine-grained objects that share similar overall appearance but have subtle\ndifference. To solve this problem, we for the first time introduce the attention mechanism to the learning of fine-grained\nhashing codes. Specifically, we propose a novel deep hashing model, named deep saliency hashing (DSaH), which\nautomatically mines salient regions and learns semanticpreserving hashing codes simultaneously. DSaH is a twostep end-to-end model consisting of an attention network\nand a hashing network. Our loss function contains three\nbasic components, including the semantic loss, the saliency\nloss, and the quantization loss. As the core of DSaH, the\nsaliency loss guides the attention network to mine discriminative regions from pairs of images. We conduct extensive experiments on both fine-grained and general retrieval\ndatasets for performance evaluation. Experimental results\non fine grained dataset, including Oxford Flowers-17, Stanford Dogs-120 and CUB Bird demonstrate that our DSaH\nperforms the best for fine-grained retrieval task and beats\nstrongest competitor (DTQ) by approximately 10% on both\nStanford Dogs-120 and CUB Bird. DSaH is also comparable to several state-of-the-art hashing methods on general\ndatasets, including CIFAR-10 and NUS-WIDE.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Neural Hashing", "Quantization", "Evaluation"], "tsne_embedding": [-13.903121948242188, 0.9469243288040161], "cluster": 8}, {"key": "jin2025unsupervised", "year": "2025", "citations": "14", "title": "Unsupervised Discrete Hashing With Affinity Similarity", "abstract": "<p>In recent years, supervised hashing has been validated to greatly boost the performance of image retrieval. However, the label-hungry property requires massive label collection, making it intractable in practical scenarios. To liberate the model training procedure from laborious manual annotations, some unsupervised methods are proposed. However, the following two factors make unsupervised algorithms inferior to their supervised counterparts: (1) Without manually-defined labels, it is difficult to capture the semantic information across data, which is of crucial importance to guide robust binary code learning. (2) The widely adopted relaxation on binary constraints results in quantization error accumulation in the optimization procedure. To address the above-mentioned problems, in this paper, we propose a novel Unsupervised Discrete Hashing method (UDH). Specifically, to capture the semantic information, we propose a balanced graph-based semantic loss which explores the affinity priors in the original feature space. Then, we propose a novel self-supervised loss, termed orthogonal consistent loss, which can leverage semantic loss of instance and impose independence of codes. Moreover, by integrating the discrete optimization into the proposed unsupervised framework, the binary constraints are consistently preserved, alleviating the influence of quantization errors. Extensive experiments demonstrate that UDH outperforms state-of-the-art unsupervised methods for image retrieval.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Graph Based ANN", "Compact Codes", "Quantization", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-7.480782508850098, -5.385426998138428], "cluster": 9}, {"key": "jinnai2017hash", "year": "2017", "citations": "5", "title": "On Hash-based Work Distribution Methods For Parallel Best-first Search", "abstract": "<p>Parallel best-first search algorithms such as Hash Distributed A* (HDA<em>)\ndistribute work among the processes using a global hash function. We analyze\nthe search and communication overheads of state-of-the-art hash-based parallel\nbest-first search algorithms, and show that although Zobrist hashing, the\nstandard hash function used by HDA</em>, achieves good load balance for many\ndomains, it incurs significant communication overhead since almost all\ngenerated nodes are transferred to a different processor than their parents. We\npropose Abstract Zobrist hashing, a new work distribution method for parallel\nsearch which, instead of computing a hash value based on the raw features of a\nstate, uses a feature projection function to generate a set of abstract\nfeatures which results in a higher locality, resulting in reduced\ncommunications overhead. We show that Abstract Zobrist hashing outperforms\nprevious methods on search domains using hand-coded, domain specific feature\nprojection functions. We then propose GRAZHDA<em>, a graph-partitioning based\napproach to automatically generating feature projection functions. GRAZHDA</em>\nseeks to approximate the partitioning of the actual search space graph by\npartitioning the domain transition graph, an abstraction of the state space\ngraph. We show that GRAZHDA* outperforms previous methods on domain-independent\nplanning.</p>\n", "tags": ["Alt", "Hashing Methods"], "tsne_embedding": [9.71589183807373, -0.35375168919563293], "cluster": 4}, {"key": "johnson2017billion", "year": "2017", "citations": "2024", "title": "Billion-scale Similarity Search With Gpus", "abstract": "<p>Similarity search finds application in specialized database systems handling\ncomplex data such as images or videos, which are typically represented by\nhigh-dimensional features and require specific indexing structures. This paper\ntackles the problem of better utilizing GPUs for this task. While GPUs excel at\ndata-parallel tasks, prior approaches are bottlenecked by algorithms that\nexpose less parallelism, such as k-min selection, or make poor use of the\nmemory hierarchy.\n  We propose a design for k-selection that operates at up to 55% of theoretical\npeak performance, enabling a nearest neighbor implementation that is 8.5x\nfaster than prior GPU state of the art. We apply it in different similarity\nsearch scenarios, by proposing optimized design for brute-force, approximate\nand compressed-domain search based on product quantization. In all these\nsetups, we outperform the state of the art by large margins. Our implementation\nenables the construction of a high accuracy k-NN graph on 95 million images\nfrom the Yfcc100M dataset in 35 minutes, and of a graph connecting 1 billion\nvectors in less than 12 hours on 4 Maxwell Titan X GPUs. We have open-sourced\nour approach for the sake of comparison and reproducibility.</p>\n", "tags": ["DATASETS", "Large Scale Search", "Similarity Search", "Quantization", "Evaluation"], "tsne_embedding": [13.45543098449707, 5.963242530822754], "cluster": 0}, {"key": "joly2025random", "year": "2025", "citations": "150", "title": "Random Maximum Margin Hashing", "abstract": "<p>Following the success of hashing methods for multidimensional\nindexing, more and more works are interested\nin embedding visual feature space in compact hash codes.\nSuch approaches are not an alternative to using index structures\nbut a complementary way to reduce both the memory\nusage and the distance computation cost. Several data\ndependent hash functions have notably been proposed to\nclosely fit data distribution and provide better selectivity\nthan usual random projections such as LSH. However, improvements\noccur only for relatively small hash code sizes\nup to 64 or 128 bits. As discussed in the paper, this is mainly\ndue to the lack of independence between the produced hash\nfunctions. We introduce a new hash function family that\nattempts to solve this issue in any kernel space. Rather\nthan boosting the collision probability of close points, our\nmethod focus on data scattering. By training purely random\nsplits of the data, regardless the closeness of the training\nsamples, it is indeed possible to generate consistently\nmore independent hash functions. On the other side, the\nuse of large margin classifiers allows to maintain good generalization\nperformances. Experiments show that our new\nRandom Maximum Margin Hashing scheme (RMMH) outperforms\nfour state-of-the-art hashing methods, notably in\nkernel spaces.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "CVPR", "Alt", "Vector Indexing", "Evaluation"], "tsne_embedding": [-1.9687108993530273, -7.367087364196777], "cluster": 9}, {"key": "jose2020optimized", "year": "2020", "citations": "7", "title": "Optimized Feature Space Learning For Generating Efficient Binary Codes For Image Retrieval", "abstract": "<p>In this paper we propose an approach for learning low dimensional optimized\nfeature space with minimum intra-class variance and maximum inter-class\nvariance. We address the problem of high-dimensionality of feature vectors\nextracted from neural networks by taking care of the global statistics of\nfeature space. Classical approach of Linear Discriminant Analysis (LDA) is\ngenerally used for generating an optimized low dimensional feature space for\nsingle-labeled images. Since, image retrieval involves both multi-labeled and\nsingle-labeled images, we utilize the equivalence between LDA and Canonical\nCorrelation Analysis (CCA) to generate an optimized feature space for\nsingle-labeled images and use CCA to generate an optimized feature space for\nmulti-labeled images. Our approach correlates the projections of feature\nvectors with label vectors in our CCA based network architecture. The neural\nnetwork minimize a loss function which maximizes the correlation coefficients.\nWe binarize our generated feature vectors with the popular Iterative\nQuantization (ITQ) approach and also propose an ensemble network to generate\nbinary codes of desired bit length for image retrieval. Our measurement of mean\naverage precision shows competitive results on other state-of-the-art\nsingle-labeled and multi-labeled image retrieval datasets.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Compact Codes", "Quantization", "Evaluation"], "tsne_embedding": [-10.266603469848633, 13.84494400024414], "cluster": 6}, {"key": "joulin2016fasttext", "year": "2016", "citations": "872", "title": "Fasttext.zip: Compressing Text Classification Models", "abstract": "<p>We consider the problem of producing compact architectures for text\nclassification, such that the full model fits in a limited amount of memory.\nAfter considering different solutions inspired by the hashing literature, we\npropose a method built upon product quantization to store word embeddings.\nWhile the original technique leads to a loss in accuracy, we adapt this method\nto circumvent quantization artefacts. Our experiments carried out on several\nbenchmarks show that our approach typically requires two orders of magnitude\nless memory than fastText while being only slightly inferior with respect to\naccuracy. As a result, it outperforms the state of the art by a good margin in\nterms of the compromise between memory usage and accuracy.</p>\n", "tags": ["Quantization", "Hashing Methods", "Evaluation"], "tsne_embedding": [10.203513145446777, -7.676851272583008], "cluster": 2}, {"key": "jung2022few", "year": "2022", "citations": "5", "title": "Few-shot Metric Learning: Online Adaptation Of Embedding For Retrieval", "abstract": "<p>Metric learning aims to build a distance metric typically by learning an\neffective embedding function that maps similar objects into nearby points in\nits embedding space. Despite recent advances in deep metric learning, it\nremains challenging for the learned metric to generalize to unseen classes with\na substantial domain gap. To tackle the issue, we explore a new problem of\nfew-shot metric learning that aims to adapt the embedding function to the\ntarget domain with only a few annotated data. We introduce three few-shot\nmetric learning baselines and propose the Channel-Rectifier Meta-Learning\n(CRML), which effectively adapts the metric space online by adjusting channels\nof intermediate layers. Experimental analyses on miniImageNet, CUB-200-2011,\nMPII, as well as a new dataset, miniDeepFashion, demonstrate that our method\nconsistently improves the learned metric by adapting it to target classes and\nachieves a greater gain in image retrieval when the domain gap from the source\nclasses is larger.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [-23.206798553466797, 6.764825344085693], "cluster": 3}, {"key": "junussov2019note", "year": "2019", "citations": "13", "title": "Note On Distance Matrix Hashing", "abstract": "<p>Hashing algorithm of dynamical set of distances is described. Proposed\nhashing function is residual. Data structure which implementation accelerates\ncomputations is presented</p>\n", "tags": ["Hashing Methods"], "tsne_embedding": [6.877063274383545, -6.117293357849121], "cluster": 2}, {"key": "juvekar2024cos", "year": "2024", "citations": "12", "title": "Cos-mix: Cosine Similarity And Distance Fusion For Improved Information Retrieval", "abstract": "<p>This study proposes a novel hybrid retrieval strategy for Retrieval-Augmented\nGeneration (RAG) that integrates cosine similarity and cosine distance measures\nto improve retrieval performance, particularly for sparse data. The traditional\ncosine similarity measure is widely used to capture the similarity between\nvectors in high-dimensional spaces. However, it has been shown that this\nmeasure can yield arbitrary results in certain scenarios. To address this\nlimitation, we incorporate cosine distance measures to provide a complementary\nperspective by quantifying the dissimilarity between vectors. Our approach is\nexperimented on proprietary data, unlike recent publications that have used\nopen-source datasets. The proposed method demonstrates enhanced retrieval\nperformance and provides a more comprehensive understanding of the semantic\nrelationships between documents or items. This hybrid strategy offers a\npromising solution for efficiently and accurately retrieving relevant\ninformation in knowledge-intensive applications, leveraging techniques such as\nBM25 (sparse) retrieval , vector (Dense) retrieval, and cosine distance based\nretrieval to facilitate efficient information retrieval.</p>\n", "tags": ["DATASETS", "Distance Metric Learning", "ICCV", "Evaluation"], "tsne_embedding": [0.05759650468826294, 0.36918434500694275], "cluster": 4}, {"key": "j\u00e4\u00e4saari2018efficient", "year": "2018", "citations": "11", "title": "Efficient Autotuning Of Hyperparameters In Approximate Nearest Neighbor Search", "abstract": "<p>Approximate nearest neighbor algorithms are used to speed up nearest neighbor\nsearch in a wide array of applications. However, current indexing methods\nfeature several hyperparameters that need to be tuned to reach an acceptable\naccuracy\u2013speed trade-off. A grid search in the parameter space is often\nimpractically slow due to a time-consuming index-building procedure. Therefore,\nwe propose an algorithm for automatically tuning the hyperparameters of\nindexing methods based on randomized space-partitioning trees. In particular,\nwe present results using randomized k-d trees, random projection trees and\nrandomized PCA trees. The tuning algorithm adds minimal overhead to the\nindex-building process but is able to find the optimal hyperparameters\naccurately. We demonstrate that the algorithm is significantly faster than\nexisting approaches, and that the indexing methods used are competitive with\nthe state-of-the-art methods in query time while being faster to build.</p>\n", "tags": ["Tree Based ANN", "Locality Sensitive Hashing", "Efficiency And Optimization"], "tsne_embedding": [15.323383331298828, 4.95894718170166], "cluster": 0}, {"key": "j\u00e4\u00e4saari2025vibe", "year": "2025", "citations": "6", "title": "VIBE: Vector Index Benchmark For Embeddings", "abstract": "<p>Approximate nearest neighbor (ANN) search is a performance-critical component of many machine learning pipelines. Rigorous benchmarking is essential for evaluating the performance of vector indexes for ANN search. However, the datasets of the existing benchmarks are no longer representative of the current applications of ANN search. Hence, there is an urgent need for an up-to-date set of benchmarks. To this end, we introduce Vector Index Benchmark for Embeddings (VIBE), an open source project for benchmarking ANN algorithms. VIBE contains a pipeline for creating benchmark datasets using dense embedding models characteristic of modern applications, such as retrieval-augmented generation (RAG). To replicate real-world workloads, we also include out-of-distribution (OOD) datasets where the queries and the corpus are drawn from different distributions. We use VIBE to conduct a comprehensive evaluation of SOTA vector indexes, benchmarking 21 implementations on 12 in-distribution and 6 out-of-distribution datasets.</p>\n", "tags": ["Vector Indexing", "Similarity Search", "Evaluation", "DATASETS"], "tsne_embedding": [6.279906272888184, 8.138731002807617], "cluster": 4}, {"key": "kalra2019yottixel", "year": "2019", "citations": "115", "title": "Yottixel -- An Image Search Engine For Large Archives Of Histopathology Whole Slide Images", "abstract": "<p>With the emergence of digital pathology, searching for similar images in\nlarge archives has gained considerable attention. Image retrieval can provide\npathologists with unprecedented access to the evidence embodied in already\ndiagnosed and treated cases from the past. This paper proposes a search engine\nspecialized for digital pathology, called Yottixel, a portmanteau for \u201cone\nyotta pixel,\u201d alluding to the big-data nature of histopathology images. The\nmost impressive characteristic of Yottixel is its ability to represent whole\nslide images (WSIs) in a compact manner. Yottixel can perform millions of\nsearches in real-time with a high search accuracy and low storage profile.\nYottixel uses an intelligent indexing algorithm capable of representing WSIs\nwith a mosaic of patches by converting them into a small number of methodically\nextracted barcodes, called \u201cBunch of Barcodes\u201d (BoB), the most prominent\nperformance enabler of Yottixel. The performance of the prototype platform is\nqualitatively tested using 300 WSIs from the University of Pittsburgh Medical\nCenter (UPMC) and 2,020 WSIs from The Cancer Genome Atlas Program (TCGA)\nprovided by the National Cancer Institute. Both datasets amount to more than\n4,000,000 patches of 1000x1000 pixels. We report three sets of experiments that\nshow that Yottixel can accurately retrieve organs and malignancies, and its\nsemantic ordering shows good agreement with the subjective evaluation of human\nobservers.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Evaluation"], "tsne_embedding": [-24.30936050415039, 16.863082885742188], "cluster": 3}, {"key": "kanda2020succinct", "year": "2020", "citations": "11", "title": "Succinct Trit-array Trie For Scalable Trajectory Similarity Search", "abstract": "<p>Massive datasets of spatial trajectories representing the mobility of a\ndiversity of moving objects are ubiquitous in research and industry. Similarity\nsearch of a large collection of trajectories is indispensable for turning these\ndatasets into knowledge. Locality sensitive hashing (LSH) is a powerful\ntechnique for fast similarity searches. Recent methods employ LSH and attempt\nto realize an efficient similarity search of trajectories; however, those\nmethods are inefficient in terms of search time and memory when applied to\nmassive datasets. To address this problem, we present the trajectory-indexing\nsuccinct trit-array trie (tSTAT), which is a scalable method leveraging LSH for\ntrajectory similarity searches. tSTAT quickly performs the search on a tree\ndata structure called trie. We also present two novel techniques that enable to\ndramatically enhance the memory efficiency of tSTAT. One is a node reduction\ntechnique that substantially omits redundant trie nodes while maintaining the\ntime performance. The other is a space-efficient representation that leverages\nthe idea behind succinct data structures (i.e., a compressed data structure\nsupporting fast data operations). We experimentally test tSTAT on its ability\nto retrieve similar trajectories for a query from large collections of\ntrajectories and show that tSTAT performs superiorly in comparison to\nstate-of-the-art similarity search methods.</p>\n", "tags": ["Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Similarity Search", "Evaluation"], "tsne_embedding": [9.881036758422852, 3.274343967437744], "cluster": 4}, {"key": "kang2019candidate", "year": "2019", "citations": "53", "title": "Candidate Generation With Binary Codes For Large-scale Top-n Recommendation", "abstract": "<p>Generating the Top-N recommendations from a large corpus is computationally\nexpensive to perform at scale. Candidate generation and re-ranking based\napproaches are often adopted in industrial settings to alleviate efficiency\nproblems. However it remains to be fully studied how well such schemes\napproximate complete rankings (or how many candidates are required to achieve a\ngood approximation), or to develop systematic approaches to generate\nhigh-quality candidates efficiently. In this paper, we seek to investigate\nthese questions via proposing a candidate generation and re-ranking based\nframework (CIGAR), which first learns a preference-preserving binary embedding\nfor building a hash table to retrieve candidates, and then learns to re-rank\nthe candidates using real-valued ranking models with a candidate-oriented\nobjective. We perform a comprehensive study on several large-scale real-world\ndatasets consisting of millions of users/items and hundreds of millions of\ninteractions. Our results show that CIGAR significantly boosts the Top-N\naccuracy against state-of-the-art recommendation models, while reducing the\nquery time by orders of magnitude. We hope that this work could draw more\nattention to the candidate generation problem in recommender systems.</p>\n", "tags": ["CIKM", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Recommender Systems", "Tools & Libraries"], "tsne_embedding": [4.682969570159912, -2.0634710788726807], "cluster": 4}, {"key": "kang2020learning", "year": "2020", "citations": "34", "title": "Learning To Embed Categorical Features Without Embedding Tables For Recommendation", "abstract": "<p>Embedding learning of categorical features (e.g. user/item IDs) is at the\ncore of various recommendation models including matrix factorization and neural\ncollaborative filtering. The standard approach creates an embedding table where\neach row represents a dedicated embedding vector for every unique feature\nvalue. However, this method fails to efficiently handle high-cardinality\nfeatures and unseen feature values (e.g. new video ID) that are prevalent in\nreal-world recommendation systems. In this paper, we propose an alternative\nembedding framework Deep Hash Embedding (DHE), replacing embedding tables by a\ndeep embedding network to compute embeddings on the fly. DHE first encodes the\nfeature value to a unique identifier vector with multiple hashing functions and\ntransformations, and then applies a DNN to convert the identifier vector to an\nembedding. The encoding module is deterministic, non-learnable, and free of\nstorage, while the embedding network is updated during the training time to\nlearn embedding generation. Empirical results show that DHE achieves comparable\nAUC against the standard one-hot full embedding, with smaller model sizes. Our\nwork sheds light on the design of DNN-based alternative embedding schemes for\ncategorical features without using embedding table lookup.</p>\n", "tags": ["KDD", "Hashing Methods", "Alt", "Recommender Systems", "Neural Hashing", "Tools & Libraries"], "tsne_embedding": [-17.765466690063477, 0.34874024987220764], "cluster": 3}, {"key": "kang2025column", "year": "2025", "citations": "299", "title": "Column Sampling Based Discrete Supervised Hashing", "abstract": "<p>By leveraging semantic (label) information, supervised hashing has demonstrated better accuracy than unsupervised hashing in many real applications. Because the hashing-code learning problem is essentially a discrete optimization problem which is hard to solve, most existing supervised hashing methods try to solve a relaxed continuous optimization problem by dropping the discrete constraints.\nHowever, these methods typically suffer from poor performance due to the errors caused by the relaxation. Some other methods try to directly solve the discrete optimization problem. However, they are typically time-consuming and unscalable. In this paper, we propose a novel method, called column sampling based discrete supervised hashing (COSDISH), to directly learn the discrete hashing code from semantic information.\nCOSDISH is an iterative method, in each iteration of which several columns are sampled from the semantic similarity matrix and then the hashing code is decomposed into two parts which can be alternately optimized in a discrete way. Theoretical analysis shows that the learning (optimization) algorithm of COSDISH has a constant-approximation bound in each step of the alternating optimization procedure. Empirical results on datasets with semantic labels illustrate that COSDISH can outperform the state-of-the-art methods in real applications like image retrieval.</p>\n", "tags": ["Image Retrieval", "AAAI", "DATASETS", "Hashing Methods", "Alt", "Evaluation"], "tsne_embedding": [-6.746004581451416, -6.380656719207764], "cluster": 9}, {"key": "kang2025maximum", "year": "2025", "citations": "37", "title": "Maximum-margin Hamming Hashing", "abstract": "<p>Deep hashing enables computation and memory efficient\nimage search through end-to-end learning of feature representations and binary codes. While linear scan over binary\nhash codes is more efficient than over the high-dimensional\nrepresentations, its linear-time complexity is still unacceptable for very large databases. Hamming space retrieval enables constant-time search through hash lookups, where for\neach query, there is a Hamming ball centered at the query\nand the data points within the ball are returned as relevant.\nSince inside the Hamming ball implies retrievable while\noutside irretrievable, it is crucial to explicitly characterize\nthe Hamming ball. The main idea of this work is to directly\nembody the Hamming radius into the loss functions, leading\nto Maximum-Margin Hamming Hashing (MMHH), a new\nmodel specifically optimized for Hamming space retrieval.\nWe introduce a max-margin t-distribution loss, where the\nt-distribution concentrates more similar data points to be\nwithin the Hamming ball, and the margin characterizes the\nHamming radius such that less penalization is applied to\nsimilar data points within the Hamming ball. The loss function also introduces robustness to data noise, where the similarity supervision may be inaccurate in practical problems.\nThe model is trained end-to-end using a new semi-batch optimization algorithm tailored to extremely imbalanced data.\nOur method yields state-of-the-art results on four datasets\nand shows superior performance on noisy data.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Compact Codes", "Neural Hashing", "ICCV", "Evaluation", "Robustness"], "tsne_embedding": [-6.910024642944336, 11.306018829345703], "cluster": 6}, {"key": "kanji2016self", "year": "2016", "citations": "20", "title": "Self-localization From Images With Small Overlap", "abstract": "<p>With the recent success of visual features from deep convolutional neural\nnetworks (DCNN) in visual robot self-localization, it has become important and\npractical to address more general self-localization scenarios. In this paper,\nwe address the scenario of self-localization from images with small overlap. We\nexplicitly introduce a localization difficulty index as a decreasing function\nof view overlap between query and relevant database images and investigate\nperformance versus difficulty for challenging cross-view self-localization\ntasks. We then reformulate the self-localization as a scalable\nbag-of-visual-features (BoVF) scene retrieval and present an efficient solution\ncalled PCA-NBNN, aiming to facilitate fast and yet discriminative\ncorrespondence between partially overlapping images. The proposed approach\nadopts recent findings in discriminativity preserving encoding of DCNN features\nusing principal component analysis (PCA) and cross-domain scene matching using\nnaive Bayes nearest neighbor distance metric (NBNN). We experimentally\ndemonstrate that the proposed PCA-NBNN framework frequently achieves comparable\nresults to previous DCNN features and that the BoVF model is significantly more\nefficient. We further address an important alternative scenario of\n\u201cself-localization from images with NO overlap\u201d and report the result.</p>\n", "tags": ["IROS", "Distance Metric Learning", "Alt", "Tools & Libraries", "Evaluation"], "tsne_embedding": [2.1033987998962402, 17.674795150756836], "cluster": 6}, {"key": "kaplan2020locality", "year": "2020", "citations": "15", "title": "Locality Sensitive Hashing For Set-queries, Motivated By Group Recommendations", "abstract": "<p>Locality Sensitive Hashing (LSH) is an effective method to index a set of\npoints such that we can efficiently find the nearest neighbors of a query\npoint. We extend this method to our novel Set-query LSH (SLSH), such that it\ncan find the nearest neighbors of a set of points, given as a query.\n  Let \\( s(x,y) \\) be the similarity between two points \\( x \\) and \\( y \\). We\ndefine a similarity between a set \\( Q\\) and a point \\( x \\) by aggregating the\nsimilarities \\( s(p,x) \\) for all \\( p\\in Q \\). For example, we can take \\( s(p,x) \\)\nto be the angular similarity between \\( p \\) and \\( x \\) (i.e., \\(1-{\\angle\n(x,p)}/{\\pi}\\)), and aggregate by arithmetic or geometric averaging, or taking\nthe lowest similarity.\n  We develop locality sensitive hash families and data structures for a large\nset of such arithmetic and geometric averaging similarities, and analyze their\ncollision probabilities. We also establish an analogous framework and hash\nfamilies for distance functions. Specifically, we give a structure for the\neuclidean distance aggregated by either averaging or taking the maximum.\n  We leverage SLSH to solve a geometric extension of the approximate near\nneighbors problem. In this version, we consider a metric for which the unit\nball is an ellipsoid and its orientation is specified with the query.\n  An important application that motivates our work is group recommendation\nsystems. Such a system embeds movies and users in the same feature space, and\nthe task of recommending a movie for a group to watch together, translates to a\nset-query \\( Q \\) using an appropriate similarity.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Distance Metric Learning", "Recommender Systems", "Tools & Libraries"], "tsne_embedding": [27.218645095825195, 3.6781928539276123], "cluster": 7}, {"key": "kapralov2017sample", "year": "2017", "citations": "31", "title": "Sample Efficient Estimation And Recovery In Sparse FFT Via Isolation On Average", "abstract": "<p>The problem of computing the Fourier Transform of a signal whose spectrum is\ndominated by a small number \\(k\\) of frequencies quickly and using a small number\nof samples of the signal in time domain (the Sparse FFT problem) has received\nsignificant attention recently. It is known how to approximately compute the\n\\(k\\)-sparse Fourier transform in \\(\\approx klog^2 n\\) time [Hassanieh et\nal\u2019STOC\u201912], or using the optimal number \\(O(klog n)\\) of samples [Indyk et\nal\u2019FOCS\u201914] in time domain, or come within \\((loglog n)^{O(1)}\\) factors of\nboth these bounds simultaneously, but no algorithm achieving the optimal\n\\(O(klog n)\\) bound in sublinear time is known.\n  In this paper we propose a new technique for analysing noisy hashing schemes\nthat arise in Sparse FFT, which we refer to as isolation on average. We apply\nthis technique to two problems in Sparse FFT: estimating the values of a list\nof frequencies using few samples and computing Sparse FFT itself, achieving\nsample-optimal results in \\(klog^{O(1)} n\\) time for both. We feel that our\napproach will likely be of interest in designing Fourier sampling schemes for\nmore general settings (e.g. model based Sparse FFT).</p>\n", "tags": ["Hashing Methods"], "tsne_embedding": [20.856298446655273, -4.078002452850342], "cluster": 7}, {"key": "kapralov2020scaling", "year": "2020", "citations": "7", "title": "Scaling Up Kernel Ridge Regression Via Locality Sensitive Hashing", "abstract": "<p>Random binning features, introduced in the seminal paper of Rahimi and Recht\n(2007), are an efficient method for approximating a kernel matrix using\nlocality sensitive hashing. Random binning features provide a very simple and\nefficient way of approximating the Laplace kernel but unfortunately do not\napply to many important classes of kernels, notably ones that generate smooth\nGaussian processes, such as the Gaussian kernel and Matern kernel. In this\npaper, we introduce a simple weighted version of random binning features and\nshow that the corresponding kernel function generates Gaussian processes of any\ndesired smoothness. We show that our weighted random binning features provide a\nspectral approximation to the corresponding kernel matrix, leading to efficient\nalgorithms for kernel ridge regression. Experiments on large scale regression\ndatasets show that our method outperforms the accuracy of random Fourier\nfeatures method.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "DATASETS"], "tsne_embedding": [18.480735778808594, -0.30841970443725586], "cluster": 7}, {"key": "karaman2019unsupervised", "year": "2019", "citations": "14", "title": "Unsupervised Rank-preserving Hashing For Large-scale Image Retrieval", "abstract": "<p>We propose an unsupervised hashing method which aims to produce binary codes\nthat preserve the ranking induced by a real-valued representation. Such compact\nhash codes enable the complete elimination of real-valued feature storage and\nallow for significant reduction of the computation complexity and storage cost\nof large-scale image retrieval applications. Specifically, we learn a neural\nnetwork-based model, which transforms the input representation into a binary\nrepresentation. We formalize the training objective of the network in an\nintuitive and effective way, considering each training sample as a query and\naiming to obtain the same retrieval results using the produced hash codes as\nthose obtained with the original features. This training formulation directly\noptimizes the hashing model for the target usage of the hash codes it produces.\nWe further explore the addition of a decoder trained to obtain an approximated\nreconstruction of the original features. At test time, we retrieved the most\npromising database samples with an efficient graph-based search procedure using\nonly our hash codes and perform re-ranking using the reconstructed features,\nthus without needing to access the original features at all. Experiments\nconducted on multiple publicly available large-scale datasets show that our\nmethod consistently outperforms all compared state-of-the-art unsupervised\nhashing methods and that the reconstruction procedure can effectively boost the\nsearch accuracy with a minimal constant additional cost.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "Graph Based ANN", "Compact Codes", "Image Retrieval", "Multimodal Retrieval"], "tsne_embedding": [-5.556617736816406, -12.129016876220703], "cluster": 9}, {"key": "karpusha2020calibrated", "year": "2020", "citations": "102", "title": "Calibrated Neighborhood Aware Confidence Measure For Deep Metric Learning", "abstract": "<p>Deep metric learning has gained promising improvement in recent years\nfollowing the success of deep learning. It has been successfully applied to\nproblems in few-shot learning, image retrieval, and open-set classifications.\nHowever, measuring the confidence of a deep metric learning model and\nidentifying unreliable predictions is still an open challenge. This paper\nfocuses on defining a calibrated and interpretable confidence metric that\nclosely reflects its classification accuracy. While performing similarity\ncomparison directly in the latent space using the learned distance metric, our\napproach approximates the distribution of data points for each class using a\nGaussian kernel smoothing function. The post-processing calibration algorithm\nwith proposed confidence metric on the held-out validation dataset improves\ngeneralization and robustness of state-of-the-art deep metric learning models\nwhile provides an interpretable estimation of the confidence. Extensive tests\non four popular benchmark datasets (Caltech-UCSD Birds, Stanford Online\nProduct, Stanford Car-196, and In-shop Clothes Retrieval) show consistent\nimprovements even at the presence of distribution shifts in test data related\nto additional noise or adversarial examples.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Distance Metric Learning", "CVPR", "Alt", "Evaluation", "Robustness"], "tsne_embedding": [-23.00547981262207, -0.5777748823165894], "cluster": 3}, {"key": "kato2009solving", "year": "2009", "citations": "37", "title": "Solving \\(k\\)-nearest Neighbor Problem On Multiple Graphics Processors", "abstract": "<p>The recommendation system is a software system to predict customers\u2019 unknown\npreferences from known preferences. In the recommendation system, customers\u2019\npreferences are encoded into vectors, and finding the nearest vectors to each\nvector is an essential part. This vector-searching part of the problem is\ncalled a \\(k\\)-nearest neighbor problem. We give an effective algorithm to solve\nthis problem on multiple graphics processor units (GPUs).\n  Our algorithm consists of two parts: an \\(N\\)-body problem and a partial sort.\nFor a algorithm of the \\(N\\)-body problem, we applied the idea of a known\nalgorithm for the \\(N\\)-body problem in physics, although another trick is need\nto overcome the problem of small sized shared memory. For the partial sort, we\ngive a novel GPU algorithm which is effective for small \\(k\\). In our partial\nsort algorithm, a heap is accessed in parallel by threads with a low cost of\nsynchronization. Both of these two parts of our algorithm utilize maximal power\nof coalesced memory access, so that a full bandwidth is achieved.\n  By an experiment, we show that when the size of the problem is large, an\nimplementation of the algorithm on two GPUs runs more than 330 times faster\nthan a single core implementation on a latest CPU. We also show that our\nalgorithm scales well with respect to the number of GPUs.</p>\n", "tags": ["Alt", "Recommender Systems"], "tsne_embedding": [17.119468688964844, 4.06685733795166], "cluster": 0}, {"key": "kazemi2020memory", "year": "2020", "citations": "42", "title": "In-memory Nearest Neighbor Search With Fefet Multi-bit Content-addressable Memories", "abstract": "<p>Nearest neighbor (NN) search is an essential operation in many applications,\nsuch as one/few-shot learning and image classification. As such, fast and\nlow-energy hardware support for accurate NN search is highly desirable. Ternary\ncontent-addressable memories (TCAMs) have been proposed to accelerate NN search\nfor few-shot learning tasks by implementing \\(L_\\infty\\) and Hamming distance\nmetrics, but they cannot achieve software-comparable accuracies. This paper\nproposes a novel distance function that can be natively evaluated with\nmulti-bit content-addressable memories (MCAMs) based on ferroelectric FETs\n(FeFETs) to perform a single-step, in-memory NN search. Moreover, this approach\nachieves accuracies comparable to floating-point precision implementations in\nsoftware for NN classification and one/few-shot learning tasks. As an example,\nthe proposed method achieves a 98.34% accuracy for a 5-way, 5-shot\nclassification task for the Omniglot dataset (only 0.8% lower than\nsoftware-based implementations) with a 3-bit MCAM. This represents a 13%\naccuracy improvement over state-of-the-art TCAM-based implementations at\niso-energy and iso-delay. The presented distance function is resilient to the\neffects of FeFET device-to-device variations. Furthermore, this work\nexperimentally demonstrates a 2-bit implementation of FeFET MCAM using AND\narrays from GLOBALFOUNDRIES to further validate proof of concept.</p>\n", "tags": ["DATASETS", "Evaluation"], "tsne_embedding": [-6.073307514190674, 13.824223518371582], "cluster": 6}, {"key": "ke2022compare", "year": "2022", "citations": "6", "title": "Compare Learning: Bi-attention Network For Few-shot Learning", "abstract": "<p>Learning with few labeled data is a key challenge for visual recognition, as\ndeep neural networks tend to overfit using a few samples only. One of the\nFew-shot learning methods called metric learning addresses this challenge by\nfirst learning a deep distance metric to determine whether a pair of images\nbelong to the same category, then applying the trained metric to instances from\nother test set with limited labels. This method makes the most of the few\nsamples and limits the overfitting effectively. However, extant metric networks\nusually employ Linear classifiers or Convolutional neural networks (CNN) that\nare not precise enough to globally capture the subtle differences between\nvectors. In this paper, we propose a novel approach named Bi-attention network\nto compare the instances, which can measure the similarity between embeddings\nof instances precisely, globally and efficiently. We verify the effectiveness\nof our model on two benchmarks. Experiments show that our approach achieved\nimproved accuracy and convergence speed over baseline models.</p>\n", "tags": ["ICASSP", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [-22.520179748535156, 5.038510799407959], "cluster": 3}, {"key": "kehl2016hashmod", "year": "2016", "citations": "46", "title": "Hashmod: A Hashing Method For Scalable 3D Object Detection", "abstract": "<p>We present a scalable method for detecting objects and estimating their 3D\nposes in RGB-D data. To this end, we rely on an efficient representation of\nobject views and employ hashing techniques to match these views against the\ninput frame in a scalable way. While a similar approach already exists for 2D\ndetection, we show how to extend it to estimate the 3D pose of the detected\nobjects. In particular, we explore different hashing strategies and identify\nthe one which is more suitable to our problem. We show empirically that the\ncomplexity of our method is sublinear with the number of objects and we enable\ndetection and pose estimation of many 3D objects with high accuracy while\noutperforming the state-of-the-art in terms of runtime.</p>\n", "tags": ["Hashing Methods"], "tsne_embedding": [-1.1446716785430908, 20.254009246826172], "cluster": 6}, {"key": "keisler2020visual", "year": "2020", "citations": "21", "title": "Visual Search Over Billions Of Aerial And Satellite Images", "abstract": "<p>We present a system for performing visual search over billions of aerial and\nsatellite images. The purpose of visual search is to find images that are\nvisually similar to a query image. We define visual similarity using 512\nabstract visual features generated by a convolutional neural network that has\nbeen trained on aerial and satellite imagery. The features are converted to\nbinary values to reduce data and compute requirements. We employ a hash-based\nsearch using Bigtable, a scalable database service from Google Cloud. Searching\nthe continental United States at 1-meter pixel resolution, corresponding to\napproximately 2 billion images, takes approximately 0.1 seconds. This system\nenables real-time visual search over the surface of the earth, and an\ninteractive demo is available at https://search.descarteslabs.com.</p>\n", "tags": ["Image Retrieval"], "tsne_embedding": [0.29787153005599976, 18.32041358947754], "cluster": 6}, {"key": "kennedy2016fast", "year": "2016", "citations": "9", "title": "Fast Cross-polytope Locality-sensitive Hashing", "abstract": "<p>We provide a variant of cross-polytope locality sensitive hashing with\nrespect to angular distance which is provably optimal in asymptotic sensitivity\nand enjoys \\(\\mathcal{O}(d \\ln d )\\) hash computation time. Building on a recent\nresult (by Andoni, Indyk, Laarhoven, Razenshteyn, Schmidt, 2015), we show that\noptimal asymptotic sensitivity for cross-polytope LSH is retained even when the\ndense Gaussian matrix is replaced by a fast Johnson-Lindenstrauss transform\nfollowed by discrete pseudo-rotation, reducing the hash computation time from\n\\(\\mathcal{O}(d^2)\\) to \\(\\mathcal{O}(d \\ln d )\\). Moreover, our scheme achieves\nthe optimal rate of convergence for sensitivity. By incorporating a\nlow-randomness Johnson-Lindenstrauss transform, our scheme can be modified to\nrequire only \\(\\mathcal{O}(\\ln^9(d))\\) random bits</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods"], "tsne_embedding": [27.382064819335938, -3.3607029914855957], "cluster": 7}, {"key": "khan2021deep", "year": "2021", "citations": "8", "title": "A Deep Metric Learning Approach To Account Linking", "abstract": "<p>We consider the task of linking social media accounts that belong to the same\nauthor in an automated fashion on the basis of the content and metadata of\ntheir corresponding document streams. We focus on learning an embedding that\nmaps variable-sized samples of user activity \u2013 ranging from single posts to\nentire months of activity \u2013 to a vector space, where samples by the same\nauthor map to nearby points. The approach does not require human-annotated data\nfor training purposes, which allows us to leverage large amounts of social\nmedia content. The proposed model outperforms several competitive baselines\nunder a novel evaluation framework modeled after established recognition\nbenchmarks in other domains. Our method achieves high linking accuracy, even\nwith small samples from accounts not seen at training time, a prerequisite for\npractical applications of the proposed linking framework.</p>\n", "tags": ["Evaluation", "NAACL", "ACL", "Distance Metric Learning", "Tools & Libraries"], "tsne_embedding": [8.172444343566895, -12.609490394592285], "cluster": 2}, {"key": "kho2018fixed", "year": "2018", "citations": "11", "title": "Fixed-length Bit-string Representation Of Fingerprint By Normalized Local Structures", "abstract": "<p>In this paper, we propose a method to represent a fingerprint image by an\nordered, fixed-length bit-string providing improved accuracy performance,\nfaster matching time and compressibility. First, we devise a novel\nminutia-based local structure modeled by a mixture of 2D elliptical Gaussian\nfunctions in the pixel space. Each local structure is mapped to the Euclidean\nspace by normalizing the local structure with the number of minutiae that\nassociates to it. This simple yet crucial crux enables fast dissimilarity\ncomputation of two local structures with Euclidean distance without distortion.\nA complementary texture-based local structure to the minutia-based local\nstructure is also introduced whereby both can be compressed via principal\ncomponent analysis and fused easily in the Euclidean space. The fused local\nstructure is then converted to a K-bit ordered string via a K-means clustering\nalgorithm. This chain of computation with sole use of Euclidean distance is\nvital for speedy and discriminative bit-string conversion. The accuracy can be\nfurther improved by a finger-specific bit-training algorithm in which two\ncriteria are leveraged to select useful bit positions for matching. Experiments\nare performed on Fingerprint Verification Competition (FVC) databases for\ncomparison with existing techniques to show the superiority of the proposed\nmethod.</p>\n", "tags": ["CVPR", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [23.112863540649414, -5.598667621612549], "cluster": 7}, {"key": "kilias2018idel", "year": "2018", "citations": "8", "title": "IDEL: In-database Entity Linking With Neural Embeddings", "abstract": "<p>We present a novel architecture, In-Database Entity Linking (IDEL), in which\nwe integrate the analytics-optimized RDBMS MonetDB with neural text mining\nabilities. Our system design abstracts core tasks of most neural entity linking\nsystems for MonetDB. To the best of our knowledge, this is the first defacto\nimplemented system integrating entity-linking in a database. We leverage the\nability of MonetDB to support in-database-analytics with user defined functions\n(UDFs) implemented in Python. These functions call machine learning libraries\nfor neural text mining, such as TensorFlow. The system achieves zero cost for\ndata shipping and transformation by utilizing MonetDB\u2019s ability to embed Python\nprocesses in the database kernel and exchange data in NumPy arrays. IDEL\nrepresents text and relational data in a joint vector space with neural\nembeddings and can compensate errors with ambiguous entity representations. For\ndetecting matching entities, we propose a novel similarity function based on\njoint neural embeddings which are learned via minimizing pairwise contrastive\nranking loss. This function utilizes a high dimensional index structures for\nfast retrieval of matching entities. Our first implementation and experiments\nusing the WebNLG corpus show the effectiveness and the potentials of IDEL.</p>\n", "tags": ["Vector Indexing", "Efficiency And Optimization"], "tsne_embedding": [10.061670303344727, -13.907014846801758], "cluster": 2}, {"key": "kim2018attention", "year": "2018", "citations": "237", "title": "Attention-based Ensemble For Deep Metric Learning", "abstract": "<p>Deep metric learning aims to learn an embedding function, modeled as deep\nneural network. This embedding function usually puts semantically similar\nimages close while dissimilar images far from each other in the learned\nembedding space. Recently, ensemble has been applied to deep metric learning to\nyield state-of-the-art results. As one important aspect of ensemble, the\nlearners should be diverse in their feature embeddings. To this end, we propose\nan attention-based ensemble, which uses multiple attention masks, so that each\nlearner can attend to different parts of the object. We also propose a\ndivergence loss, which encourages diversity among the learners. The proposed\nmethod is applied to the standard benchmarks of deep metric learning and\nexperimental results show that it outperforms the state-of-the-art methods by a\nsignificant margin on image retrieval tasks.</p>\n", "tags": ["Image Retrieval", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [-23.748899459838867, 4.070261001586914], "cluster": 3}, {"key": "kim2019representation", "year": "2019", "citations": "7", "title": "Representation Learning With Weighted Inner Product For Universal Approximation Of General Similarities", "abstract": "<p>We propose \\(\\textit{weighted inner product similarity}\\) (WIPS) for neural\nnetwork-based graph embedding. In addition to the parameters of neural\nnetworks, we optimize the weights of the inner product by allowing positive and\nnegative values. Despite its simplicity, WIPS can approximate arbitrary general\nsimilarities including positive definite, conditionally positive definite, and\nindefinite kernels. WIPS is free from similarity model selection, since it can\nlearn any similarity models such as cosine similarity, negative Poincar'e\ndistance and negative Wasserstein distance. Our experiments show that the\nproposed method can learn high-quality distributed representations of nodes\nfrom real datasets, leading to an accurate approximation of similarities as\nwell as high performance in inductive tasks.</p>\n", "tags": ["DATASETS", "Evaluation", "IJCAI", "Distance Metric Learning", "AAAI"], "tsne_embedding": [15.82201862335205, 9.411019325256348], "cluster": 0}, {"key": "kim2020boosted", "year": "2020", "citations": "9", "title": "Boosted Locality Sensitive Hashing: Discriminative Binary Codes For Source Separation", "abstract": "<p>Speech enhancement tasks have seen significant improvements with the advance\nof deep learning technology, but with the cost of increased computational\ncomplexity. In this study, we propose an adaptive boosting approach to learning\nlocality sensitive hash codes, which represent audio spectra efficiently. We\nuse the learned hash codes for single-channel speech denoising tasks as an\nalternative to a complex machine learning model, particularly to address the\nresource-constrained environments. Our adaptive boosting algorithm learns\nsimple logistic regressors as the weak learners. Once trained, their binary\nclassification results transform each spectrum of test noisy speech into a bit\nstring. Simple bitwise operations calculate Hamming distance to find the\nK-nearest matching frames in the dictionary of training noisy speech spectra,\nwhose associated ideal binary masks are averaged to estimate the denoising mask\nfor that test mixture. Our proposed learning algorithm differs from AdaBoost in\nthe sense that the projections are trained to minimize the distances between\nthe self-similarity matrix of the hash codes and that of the original spectra,\nrather than the misclassification rate. We evaluate our discriminative hash\ncodes on the TIMIT corpus with various noise types, and show comparative\nperformance to deep learning methods in terms of denoising performance and\ncomplexity.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Compact Codes", "Alt", "ICASSP", "Evaluation"], "tsne_embedding": [-8.800317764282227, -10.664042472839355], "cluster": 9}, {"key": "kim2021multi", "year": "2021", "citations": "11", "title": "Multi-level Distance Regularization For Deep Metric Learning", "abstract": "<p>We propose a novel distance-based regularization method for deep metric\nlearning called Multi-level Distance Regularization (MDR). MDR explicitly\ndisturbs a learning procedure by regularizing pairwise distances between\nembedding vectors into multiple levels that represents a degree of similarity\nbetween a pair. In the training stage, the model is trained with both MDR and\nan existing loss function of deep metric learning, simultaneously; the two\nlosses interfere with the objective of each other, and it makes the learning\nprocess difficult. Moreover, MDR prevents some examples from being ignored or\noverly influenced in the learning process. These allow the parameters of the\nembedding network to be settle on a local optima with better generalization.\nWithout bells and whistles, MDR with simple Triplet loss achieves\nthe-state-of-the-art performance in various benchmark datasets: CUB-200-2011,\nCars-196, Stanford Online Products, and In-Shop Clothes Retrieval. We\nextensively perform ablation studies on its behaviors to show the effectiveness\nof MDR. By easily adopting our MDR, the previous approaches can be improved in\nperformance and generalization ability.</p>\n", "tags": ["AAAI", "DATASETS", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [-16.827762603759766, 6.77944803237915], "cluster": 3}, {"key": "kim2022accelerating", "year": "2022", "citations": "20", "title": "Accelerating Large-scale Graph-based Nearest Neighbor Search On A Computational Storage Platform", "abstract": "<p>K-nearest neighbor search is one of the fundamental tasks in various\napplications and the hierarchical navigable small world (HNSW) has recently\ndrawn attention in large-scale cloud services, as it easily scales up the\ndatabase while offering fast search. On the other hand, a computational storage\ndevice (CSD) that combines programmable logic and storage modules on a single\nboard becomes popular to address the data bandwidth bottleneck of modern\ncomputing systems. In this paper, we propose a computational storage platform\nthat can accelerate a large-scale graph-based nearest neighbor search algorithm\nbased on SmartSSD CSD. To this end, we modify the algorithm more amenable on\nthe hardware and implement two types of accelerators using HLS- and RTL-based\nmethodology with various optimization methods. In addition, we scale up the\nproposed platform to have 4 SmartSSDs and apply graph parallelism to boost the\nsystem performance further. As a result, the proposed computational storage\nplatform achieves 75.59 query per second throughput for the SIFT1B dataset at\n258.66W power dissipation, which is 12.83x and 17.91x faster and 10.43x and\n24.33x more energy efficient than the conventional CPU-based and GPU-based\nserver platform, respectively. With multi-terabyte storage and custom\nacceleration capability, we believe that the proposed computational storage\nplatform is a promising solution for cost-sensitive cloud datacenters.</p>\n", "tags": ["Graph Based ANN", "DATASETS", "Evaluation"], "tsne_embedding": [18.48313331604004, 18.739999771118164], "cluster": 0}, {"key": "kim2025rt", "year": "2025", "citations": "10", "title": "RT-HDIST: Ray-tracing Core-based Hausdorff Distance Computation", "abstract": "<p>The Hausdorff distance is a fundamental metric with widespread applications\nacross various fields. However, its computation remains computationally\nexpensive, especially for large-scale datasets. In this work, we present\nRT-HDIST, the first Hausdorff distance algorithm accelerated by ray-tracing\ncores (RT-cores). By reformulating the Hausdorff distance problem as a series\nof nearest-neighbor searches and introducing a novel quantized index space,\nRT-HDIST achieves significant reductions in computational overhead while\nmaintaining exact results. Extensive benchmarks demonstrate up to a\ntwo-order-of-magnitude speedup over prior state-of-the-art methods,\nunderscoring RT-HDIST\u2019s potential for real-time and large-scale applications.</p>\n", "tags": ["DATASETS", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [8.815229415893555, 17.44340705871582], "cluster": 0}, {"key": "klein2017end", "year": "2017", "citations": "59", "title": "End-to-end Supervised Product Quantization For Image Search And Retrieval", "abstract": "<p>Product Quantization, a dictionary based hashing method, is one of the\nleading unsupervised hashing techniques. While it ignores the labels, it\nharnesses the features to construct look up tables that can approximate the\nfeature space. In recent years, several works have achieved state of the art\nresults on hashing benchmarks by learning binary representations in a\nsupervised manner. This work presents Deep Product Quantization (DPQ), a\ntechnique that leads to more accurate retrieval and classification than the\nlatest state of the art methods, while having similar computational complexity\nand memory footprint as the Product Quantization method. To our knowledge, this\nis the first work to introduce a dictionary-based representation that is\ninspired by Product Quantization and which is learned end-to-end, and thus\nbenefits from the supervised signal. DPQ explicitly learns soft and hard\nrepresentations to enable an efficient and accurate asymmetric search, by using\na straight-through estimator. Our method obtains state of the art results on an\nextensive array of retrieval and classification experiments.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Efficiency And Optimization", "CVPR", "Quantization", "Evaluation"], "tsne_embedding": [-7.359379768371582, -11.732442855834961], "cluster": 9}, {"key": "ko2020embedding", "year": "2020", "citations": "47", "title": "Embedding Expansion: Augmentation In Embedding Space For Deep Metric Learning", "abstract": "<p>Learning the distance metric between pairs of samples has been studied for\nimage retrieval and clustering. With the remarkable success of pair-based\nmetric learning losses, recent works have proposed the use of generated\nsynthetic points on metric learning losses for augmentation and generalization.\nHowever, these methods require additional generative networks along with the\nmain network, which can lead to a larger model size, slower training speed, and\nharder optimization. Meanwhile, post-processing techniques, such as query\nexpansion and database augmentation, have proposed the combination of feature\npoints to obtain additional semantic information. In this paper, inspired by\nquery expansion and database augmentation, we propose an augmentation method in\nan embedding space for pair-based metric learning losses, called embedding\nexpansion. The proposed method generates synthetic points containing augmented\ninformation by a combination of feature points and performs hard negative pair\nmining to learn with the most informative feature representations. Because of\nits simplicity and flexibility, it can be used for existing metric learning\nlosses without affecting model size, training speed, or optimization\ndifficulty. Finally, the combination of embedding expansion and representative\nmetric learning losses outperforms the state-of-the-art losses and previous\nsample generation methods in both image retrieval and clustering tasks. The\nimplementation is publicly available.</p>\n", "tags": ["CVPR", "Image Retrieval", "Distance Metric Learning"], "tsne_embedding": [-19.48525619506836, 5.481049537658691], "cluster": 3}, {"key": "ko2021low", "year": "2021", "citations": "1863", "title": "Low-precision Quantization For Efficient Nearest Neighbor Search", "abstract": "<p>Fast k-Nearest Neighbor search over real-valued vector spaces (KNN) is an\nimportant algorithmic task for information retrieval and recommendation\nsystems. We present a method for using reduced precision to represent vectors\nthrough quantized integer values, enabling both a reduction in the memory\noverhead of indexing these vectors and faster distance computations at query\ntime. While most traditional quantization techniques focus on minimizing the\nreconstruction error between a point and its uncompressed counterpart, we focus\ninstead on preserving the behavior of the underlying distance metric.\nFurthermore, our quantization approach is applied at the implementation level\nand can be combined with existing KNN algorithms. Our experiments on both open\nsource and proprietary datasets across multiple popular KNN frameworks validate\nthat quantized distance metrics can reduce memory by 60% and improve query\nthroughput by 30%, while incurring only a 2% reduction in recall.</p>\n", "tags": ["DATASETS", "Distance Metric Learning", "Recommender Systems", "Quantization", "Tools & Libraries", "Evaluation"], "tsne_embedding": [16.012475967407227, -5.140441417694092], "cluster": 2}, {"key": "kociumaka2017longest", "year": "2017", "citations": "20", "title": "Longest Common Substring With Approximately \\(k\\) Mismatches", "abstract": "<p>In the longest common substring problem, we are given two strings of length\n\\(n\\) and must find a substring of maximal length that occurs in both strings. It\nis well known that the problem can be solved in linear time, but the solution\nis not robust and can vary greatly when the input strings are changed even by\none character. To circumvent this, Leimeister and Morgenstern introduced the\nproblem of the longest common substring with \\(k\\) mismatches. Lately, this\nproblem has received a lot of attention in the literature. In this paper, we\nfirst show a conditional lower bound based on the SETH hypothesis implying that\nthere is little hope to improve existing solutions. We then introduce a new but\nclosely related problem of the longest common substring with approximately \\(k\\)\nmismatches and use locality-sensitive hashing to show that it admits a solution\nwith strongly subquadratic running time. We also apply these results to obtain\na strongly subquadratic-time 2-approximation algorithm for the longest common\nsubstring with \\(k\\) mismatches problem and show conditional hardness of\nimproving its approximation ratio.</p>\n", "tags": ["Hashing Methods", "ALT"], "tsne_embedding": [-1.3449724912643433, -28.358613967895508], "cluster": 5}, {"key": "koerkamp2025ptrhash", "year": "2025", "citations": "5", "title": "Ptrhash: Minimal Perfect Hashing At RAM Throughput", "abstract": "<p>Given a set \\(K\\) of \\(n\\) keys, a minimal perfect hash function (MPHF) is a collision-free bijective map \\(\\mathsf{H_{mphf}}\\) from \\(K\\) to \\(\\{0, \\dots, n-1\\}\\). This work presents a (minimal) perfect hash function that first prioritizes query throughput, while also allowing efficient construction for \\(10^9\\) or more elements using 2.4 bits of memory per key.\n  Both PTHash and PHOBIC first map all \\(n\\) keys to \\(n/\\lambda &lt; n\\) buckets. Then, each bucket stores a pilot that controls the final hash value of the keys mapping to it. PtrHash builds on this by using 1) fixed-width (uncompressed) 8-bit pilots, 2) a construction algorithm similar to cuckoo-hashing to find suitable pilot values. Further, it 3) uses the same number of buckets and slots for each part, with 4) a single remap table to map intermediate positions \\(\\geq n\\) to \\(&lt;n\\), 5) encoded using per-cacheline Elias-Fano coding. Lastly, 6) PtrHash support streaming queries, where we use prefetching to answer a stream of multiple queries more efficiently than one-by-one processing.\n  With default parameters, PtrHash takes 2.0 bits per key. On 300 million string keys, PtrHash is as fast or faster to build than other MPHFs, and at least \\(2.1\\times\\) faster to query. When streaming multiple queries, this improves to \\(3.3\\times\\) speedup over the fastest alternative, while also being significantly faster to construct. When using \\(10^9\\) integer keys instead, query times are as low as 12 ns/key when iterating in a for loop, or even down to 8 ns/key when using the streaming approach, just short of the 7.4 ns inverse throughput of random memory accesses.</p>\n", "tags": ["Hashing Methods", "Graph Based ANN", "Efficiency And Optimization", "Alt", "Evaluation"], "tsne_embedding": [-6.880146026611328, -26.159809112548828], "cluster": 5}, {"key": "komorowski2017random", "year": "2017", "citations": "9", "title": "Random Binary Trees For Approximate Nearest Neighbour Search In Binary Space", "abstract": "<p>Approximate nearest neighbour (ANN) search is one of the most important\nproblems in computer science fields such as data mining or computer vision. In\nthis paper, we focus on ANN for high-dimensional binary vectors and we propose\na simple yet powerful search method that uses Random Binary Search Trees\n(RBST). We apply our method to a dataset of 1.25M binary local feature\ndescriptors obtained from a real-life image-based localisation system provided\nby Google as a part of Project Tango. An extensive evaluation of our method\nagainst the state-of-the-art variations of Locality Sensitive Hashing (LSH),\nnamely Uniform LSH and Multi-probe LSH, shows the superiority of our method in\nterms of retrieval precision with performance boost of over 20%</p>\n", "tags": ["Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Similarity Search", "Evaluation"], "tsne_embedding": [13.05449104309082, -2.3527238368988037], "cluster": 2}, {"key": "kong2025isotropic", "year": "2025", "citations": "260", "title": "Isotropic Hashing", "abstract": "<p>Most existing hashing methods adopt some projection functions to project the original data into several dimensions of real values, and then each of these projected dimensions is quantized into one bit (zero or one) by thresholding. Typically, the variances of different projected dimensions are different for existing projection functions such as principal component analysis (PCA). Using the same number of bits for different projected dimensions is unreasonable because larger-variance dimensions will carry more information. Although this viewpoint has been widely accepted by many researchers, it is still not verified by either theory or experiment because no methods have been proposed to find a projection with equal variances for different dimensions. In this paper, we propose a novel method, called isotropic hashing (IsoHash), to learn projection functions which can produce projected dimensions with isotropic variances (equal variances). Experimental results on real data sets show that IsoHash can outperform its counterpart with different variances for different dimensions, which verifies the viewpoint that projections with isotropic variances will be better than those with anisotropic variances.</p>\n", "tags": ["Alt", "Hashing Methods"], "tsne_embedding": [20.146289825439453, -9.570207595825195], "cluster": 2}, {"key": "kong2025manhattan", "year": "2025", "citations": "105", "title": "Manhattan Hashing For Large-scale Image Retrieval", "abstract": "<p>Hashing is used to learn binary-code representation for data with\nexpectation of preserving the neighborhood structure in the original\nfeature space. Due to its fast query speed and reduced storage\ncost, hashing has been widely used for efficient nearest neighbor\nsearch in a large variety of applications like text and image retrieval.\nMost existing hashing methods adopt Hamming distance to\nmeasure the similarity (neighborhood) between points in the hashcode\nspace. However, one problem with Hamming distance is that\nit may destroy the neighborhood structure in the original feature\nspace, which violates the essential goal of hashing. In this paper,\nManhattan hashing (MH), which is based on Manhattan distance, is\nproposed to solve the problem of Hamming distance based hashing.\nThe basic idea of MH is to encode each projected dimension with\nmultiple bits of natural binary code (NBC), based on which the\nManhattan distance between points in the hashcode space is calculated\nfor nearest neighbor search. MH can effectively preserve the\nneighborhood structure in the data to achieve the goal of hashing.\nTo the best of our knowledge, this is the first work to adopt Manhattan\ndistance with NBC for hashing. Experiments on several largescale\nimage data sets containing up to one million points show that\nour MH method can significantly outperform other state-of-the-art\nmethods.</p>\n", "tags": ["Compact Codes", "Image Retrieval", "SIGIR", "Hashing Methods"], "tsne_embedding": [18.807693481445312, -13.285576820373535], "cluster": 2}, {"key": "koo2021semantic", "year": "2021", "citations": "11", "title": "Semantic-aware Binary Code Representation With BERT", "abstract": "<p>A wide range of binary analysis applications, such as bug discovery, malware\nanalysis and code clone detection, require recovery of contextual meanings on a\nbinary code. Recently, binary analysis techniques based on machine learning\nhave been proposed to automatically reconstruct the code representation of a\nbinary instead of manually crafting specifics of the analysis algorithm.\nHowever, the existing approaches utilizing machine learning are still\nspecialized to solve one domain of problems, rendering recreation of models for\ndifferent types of binary analysis. In this paper, we propose DeepSemantic\nutilizing BERT in producing the semantic-aware code representation of a binary\ncode.\n  To this end, we introduce well-balanced instruction normalization that holds\nrich information for each of instructions yet minimizing an out-of-vocabulary\n(OOV) problem. DeepSemantic has been carefully designed based on our study with\nlarge swaths of binaries. Besides, DeepSemantic leverages the essence of the\nBERT architecture into re-purposing a pre-trained generic model that is readily\navailable as a one-time processing, followed by quickly applying specific\ndownstream tasks with a fine-tuning process. We demonstrate DeepSemantic with\ntwo downstream tasks, namely, binary similarity comparison and compiler\nprovenance (i.e., compiler and optimization level) prediction. Our experimental\nresults show that the binary similarity model outperforms two state-of-the-art\nbinary similarity tools, DeepBinDiff and SAFE, 49.84% and 15.83% on average,\nrespectively.</p>\n", "tags": ["Compact Codes", "Evaluation"], "tsne_embedding": [-8.457803726196289, -11.87861156463623], "cluster": 9}, {"key": "kordopatiszilos2021dns", "year": "2021", "citations": "27", "title": "Dns: Distill-and-select For Efficient And Accurate Video Indexing And Retrieval", "abstract": "<p>In this paper, we address the problem of high performance and computationally\nefficient content-based video retrieval in large-scale datasets. Current\nmethods typically propose either: (i) fine-grained approaches employing\nspatio-temporal representations and similarity calculations, achieving high\nperformance at a high computational cost or (ii) coarse-grained approaches\nrepresenting/indexing videos as global vectors, where the spatio-temporal\nstructure is lost, providing low performance but also having low computational\ncost. In this work, we propose a Knowledge Distillation framework, called\nDistill-and-Select (DnS), that starting from a well-performing fine-grained\nTeacher Network learns: a) Student Networks at different retrieval performance\nand computational efficiency trade-offs and b) a Selector Network that at test\ntime rapidly directs samples to the appropriate student to maintain both high\nretrieval performance and high computational efficiency. We train several\nstudents with different architectures and arrive at different trade-offs of\nperformance and efficiency, i.e., speed and storage requirements, including\nfine-grained students that store/index videos using binary representations.\nImportantly, the proposed scheme allows Knowledge Distillation in large,\nunlabelled datasets \u2013 this leads to good students. We evaluate DnS on five\npublic datasets on three different video retrieval tasks and demonstrate a)\nthat our students achieve state-of-the-art performance in several cases and b)\nthat the DnS framework provides an excellent trade-off between retrieval\nperformance, computational speed, and storage space. In specific\nconfigurations, the proposed method achieves similar mAP with the teacher but\nis 20 times faster and requires 240 times less storage space. The collected\ndataset and implementation are publicly available:\nhttps://github.com/mever-team/distill-and-select.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-24.00415802001953, -5.618136405944824], "cluster": 1}, {"key": "koutaki2016fast", "year": "2016", "citations": "7", "title": "Fast Supervised Discrete Hashing And Its Analysis", "abstract": "<p>In this paper, we propose a learning-based supervised discrete hashing\nmethod. Binary hashing is widely used for large-scale image retrieval as well\nas video and document searches because the compact representation of binary\ncode is essential for data storage and reasonable for query searches using\nbit-operations. The recently proposed Supervised Discrete Hashing (SDH)\nefficiently solves mixed-integer programming problems by alternating\noptimization and the Discrete Cyclic Coordinate descent (DCC) method. We show\nthat the SDH model can be simplified without performance degradation based on\nsome preliminary experiments; we call the approximate model for this the \u201cFast\nSDH\u201d (FSDH) model. We analyze the FSDH model and provide a mathematically exact\nsolution for it. In contrast to SDH, our model does not require an alternating\noptimization algorithm and does not depend on initial values. FSDH is also\neasier to implement than Iterative Quantization (ITQ). Experimental results\ninvolving a large-scale database showed that FSDH outperforms conventional SDH\nin terms of precision, recall, and computation time.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Alt", "Quantization", "Evaluation"], "tsne_embedding": [-2.5428850650787354, -11.48751449584961], "cluster": 9}, {"key": "krauthgamer2025power", "year": "2025", "citations": "7", "title": "The Power Of Recursive Embeddings For \\(\\ell_p\\) Metrics", "abstract": "<p>Metric embedding is a powerful tool used extensively in mathematics and\ncomputer science. We devise a new method of using metric embeddings\nrecursively, which turns out to be particularly effective in \\(\\ell_p\\) spaces,\n\\(p&gt;2\\), yielding state-of-the-art results for Lipschitz decomposition, for\nNearest Neighbor Search, and for embedding into \\(\u2113\u2082\\). In a nutshell, our\nmethod composes metric embeddings by viewing them as reductions between\nproblems, and thereby obtains a new reduction that is substantially more\neffective than the known reduction that employs a single embedding. We in fact\napply this method recursively, oftentimes using double recursion, which further\namplifies the gap from a single embedding.</p>\n", "tags": [], "tsne_embedding": [31.31873893737793, -7.244185924530029], "cluster": 7}, {"key": "kulis2025kernelized", "year": "2025", "citations": "907", "title": "Kernelized Locality-sensitive Hashing For Scalable Image Search", "abstract": "<p>Fast retrieval methods are critical for large-scale and\ndata-driven vision applications. Recent work has explored\nways to embed high-dimensional features or complex distance\nfunctions into a low-dimensional Hamming space\nwhere items can be efficiently searched. However, existing\nmethods do not apply for high-dimensional kernelized\ndata when the underlying feature embedding for the kernel\nis unknown. We show how to generalize locality-sensitive\nhashing to accommodate arbitrary kernel functions, making\nit possible to preserve the algorithm\u2019s sub-linear time similarity\nsearch guarantees for a wide class of useful similarity\nfunctions. Since a number of successful image-based kernels\nhave unknown or incomputable embeddings, this is especially\nvaluable for image retrieval tasks. We validate our\ntechnique on several large-scale datasets, and show that it\nenables accurate and fast performance for example-based\nobject classification, feature matching, and content-based\nretrieval.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "ICCV", "Evaluation"], "tsne_embedding": [-11.21218490600586, 9.670158386230469], "cluster": 8}, {"key": "kulis2025learning", "year": "2025", "citations": "841", "title": "Learning To Hash With Binary Reconstructive Embeddings", "abstract": "<p>Fast retrieval methods are increasingly critical for many large-scale analysis tasks, and there have been\nseveral recent methods that attempt to learn hash functions for fast and accurate nearest neighbor searches.\nIn this paper, we develop an algorithm for learning hash functions based on explicitly minimizing the\nreconstruction error between the original distances and the Hamming distances of the corresponding binary\nembeddings. We develop a scalable coordinate-descent algorithm for our proposed hashing objective that\nis able to efficiently learn hash functions in a variety of settings. Unlike existing methods such as semantic\nhashing and spectral hashing, our method is easily kernelized and does not require restrictive assumptions\nabout the underlying distribution of the data. We present results over several domains to demonstrate that\nour method outperforms existing state-of-the-art techniques.</p>\n", "tags": ["Hashing Methods", "Efficiency And Optimization"], "tsne_embedding": [3.1260838508605957, -14.344039916992188], "cluster": 9}, {"key": "kulkarni2023lexically", "year": "2023", "citations": "13", "title": "Lexically-accelerated Dense Retrieval", "abstract": "<p>Retrieval approaches that score documents based on learned dense vectors\n(i.e., dense retrieval) rather than lexical signals (i.e., conventional\nretrieval) are increasingly popular. Their ability to identify related\ndocuments that do not necessarily contain the same terms as those appearing in\nthe user\u2019s query (thereby improving recall) is one of their key advantages.\nHowever, to actually achieve these gains, dense retrieval approaches typically\nrequire an exhaustive search over the document collection, making them\nconsiderably more expensive at query-time than conventional lexical approaches.\nSeveral techniques aim to reduce this computational overhead by approximating\nthe results of a full dense retriever. Although these approaches reasonably\napproximate the top results, they suffer in terms of recall \u2013 one of the key\nadvantages of dense retrieval. We introduce \u2018LADR\u2019 (Lexically-Accelerated Dense\nRetrieval), a simple-yet-effective approach that improves the efficiency of\nexisting dense retrieval models without compromising on retrieval\neffectiveness. LADR uses lexical retrieval techniques to seed a dense retrieval\nexploration that uses a document proximity graph. We explore two variants of\nLADR: a proactive approach that expands the search space to the neighbors of\nall seed documents, and an adaptive approach that selectively searches the\ndocuments with the highest estimated relevance in an iterative fashion. Through\nextensive experiments across a variety of dense retrieval models, we find that\nLADR establishes a new dense retrieval effectiveness-efficiency Pareto frontier\namong approximate k nearest neighbor techniques. Further, we find that when\ntuned to take around 8ms per query in retrieval latency on our hardware, LADR\nconsistently achieves both precision and recall that are on par with an\nexhaustive search on standard benchmarks.</p>\n", "tags": ["Graph Based ANN", "Efficiency And Optimization", "Alt", "SIGIR", "Evaluation"], "tsne_embedding": [4.493533134460449, 0.32600244879722595], "cluster": 4}, {"key": "kumar2017neural", "year": "2017", "citations": "7", "title": "Neural Signatures For Licence Plate Re-identification", "abstract": "<p>The problem of vehicle licence plate re-identification is generally\nconsidered as a one-shot image retrieval problem. The objective of this task is\nto learn a feature representation (called a \u201csignature\u201d) for licence plates.\nIncoming licence plate images are converted to signatures and matched to a\npreviously collected template database through a distance measure. Then, the\ninput image is recognized as the template whose signature is \u201cnearest\u201d to the\ninput signature. The template database is restricted to contain only a single\nsignature per unique licence plate for our problem.\n  We measure the performance of deep convolutional net-based features adapted\nfrom face recognition on this task. In addition, we also test a hybrid approach\ncombining the Fisher vector with a neural network-based embedding called \u201cf2nn\u201d\ntrained with the Triplet loss function. We find that the hybrid approach\nperforms comparably while providing computational benefits. The signature\ngenerated by the hybrid approach also shows higher generalizability to datasets\nmore dissimilar to the training corpus.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [-19.036476135253906, 6.42636775970459], "cluster": 3}, {"key": "kumar2025learning", "year": "2025", "citations": "438", "title": "Learning Hash Functions For Cross-view Similarity Search", "abstract": "<p>Many applications in Multilingual and Multimodal\nInformation Access involve searching large\ndatabases of high dimensional data objects with\nmultiple (conditionally independent) views. In this\nwork we consider the problem of learning hash\nfunctions for similarity search across the views\nfor such applications. We propose a principled\nmethod for learning a hash function for each view\ngiven a set of multiview training data objects. The\nhash functions map similar objects to similar codes\nacross the views thus enabling cross-view similarity\nsearch. We present results from an extensive\nempirical study of the proposed approach\nwhich demonstrate its effectiveness on Japanese\nlanguage People Search and Multilingual People\nSearch problems.</p>\n", "tags": ["Similarity Search", "Hashing Methods", "Evaluation"], "tsne_embedding": [5.831757545471191, 3.540785789489746], "cluster": 4}, {"key": "kuszmaul2022hash", "year": "2022", "citations": "5", "title": "A Hash Table Without Hash Functions, And How To Get The Most Out Of Your Random Bits", "abstract": "<p>This paper considers the basic question of how strong of a probabilistic\nguarantee can a hash table, storing \\(n\\) \\((1 + \\Theta(1)) log n\\)-bit key/value\npairs, offer? Past work on this question has been bottlenecked by limitations\nof the known families of hash functions: The only hash tables to achieve\nfailure probabilities less than \\(1 / 2^{\\polylog n}\\) require access to\nfully-random hash functions \u2013 if the same hash tables are implemented using\nthe known explicit families of hash functions, their failure probabilities\nbecome \\(1 / \\poly(n)\\).\n  To get around these obstacles, we show how to construct a randomized data\nstructure that has the same guarantees as a hash table, but that <em>avoids\nthe direct use of hash functions</em>. Building on this, we are able to construct a\nhash table using \\(O(n)\\) random bits that achieves failure probability \\(1 /\nn^{n^{1 - \\epsilon}}\\) for an arbitrary positive constant \\(\\epsilon\\).\n  In fact, we show that this guarantee can even be achieved by a <em>succinct\ndictionary</em>, that is, by a dictionary that uses space within a \\(1 + o(1)\\)\nfactor of the information-theoretic optimum.\n  Finally we also construct a succinct hash table whose probabilistic\nguarantees fall on a different extreme, offering a failure probability of \\(1 /\n\\poly(n)\\) while using only \\(\\tilde{O}(log n)\\) random bits. This latter result\nmatches (up to low-order terms) a guarantee previously achieved by\nDietzfelbinger et al., but with increased space efficiency and with several\nsurprising technical components.</p>\n", "tags": ["TACL", "Hashing Methods", "Efficiency And Optimization"], "tsne_embedding": [-4.211964130401611, -27.102283477783203], "cluster": 5}, {"key": "kwok2025learning", "year": "2025", "citations": "10", "title": "Learning To Hash With A Dimension Analysis-based Quantizer For Image Retrieval", "abstract": "<p>The last few years have witnessed the rise of the big data era in which approximate nearest neighbor search is a fundamental problem in many applications, such as large-scale image retrieval. Recently, many research results have demonstrated that hashing can achieve promising performance due to its appealing storage and search efficiency. Since complex optimization problems for loss functions are difficult to solve, most hashing methods decompose the hash code learning problem into two steps: projection and quantization. In the quantization step, binary codes are widely used because ranking them by the Hamming distance is very efficient. However, the massive information loss produced by the quantization step should be reduced in applications where high search accuracy is required, such as in image retrieval. Since many two-step hashing methods produce uneven projected dimensions in the projection step, in this paper, we propose a novel dimension analysis-based quantization (DAQ) on two-step hashing methods for image retrieval. We first perform an importance analysis of the projected dimensions and select a subset of them that are more informative than others, and then we divide the selected projected dimensions into several regions with our quantizer. Every region is quantized with its corresponding codebook. Finally, the similarity between two hash codes is estimated by the Manhattan distance between their corresponding codebooks, which is also efficient. We conduct experiments on three public benchmarks containing up to one million descriptors and show that the proposed DAQ method consistently leads to significant accuracy improvements over state-of-the-art quantization methods.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Quantization", "Evaluation"], "tsne_embedding": [-7.9142303466796875, 11.005842208862305], "cluster": 6}, {"key": "laarhoven2017faster", "year": "2017", "citations": "27", "title": "Faster Tuple Lattice Sieving Using Spherical Locality-sensitive Filters", "abstract": "<p>To overcome the large memory requirement of classical lattice sieving\nalgorithms for solving hard lattice problems, Bai-Laarhoven-Stehl'{e} [ANTS\n2016] studied tuple lattice sieving, where tuples instead of pairs of lattice\nvectors are combined to form shorter vectors. Herold-Kirshanova [PKC 2017]\nrecently improved upon their results for arbitrary tuple sizes, for example\nshowing that a triple sieve can solve the shortest vector problem (SVP) in\ndimension \\(d\\) in time \\(2^{0.3717d + o(d)}\\), using a technique similar to\nlocality-sensitive hashing for finding nearest neighbors.\n  In this work, we generalize the spherical locality-sensitive filters of\nBecker-Ducas-Gama-Laarhoven [SODA 2016] to obtain space-time tradeoffs for near\nneighbor searching on dense data sets, and we apply these techniques to tuple\nlattice sieving to obtain even better time complexities. For instance, our\ntriple sieve heuristically solves SVP in time \\(2^{0.3588d + o(d)}\\). For\npractical sieves based on Micciancio-Voulgaris\u2019 GaussSieve [SODA 2010], this\nshows that a triple sieve uses less space and less time than the current best\nnear-linear space double sieve.</p>\n", "tags": ["Hashing Methods"], "tsne_embedding": [26.41081428527832, -1.6051610708236694], "cluster": 7}, {"key": "laarhoven2017graph", "year": "2017", "citations": "5", "title": "Graph-based Time-space Trade-offs For Approximate Near Neighbors", "abstract": "<p>We take a first step towards a rigorous asymptotic analysis of graph-based\napproaches for finding (approximate) nearest neighbors in high-dimensional\nspaces, by analyzing the complexity of (randomized) greedy walks on the\napproximate near neighbor graph. For random data sets of size \\(n = 2^{o(d)}\\) on\nthe \\(d\\)-dimensional Euclidean unit sphere, using near neighbor graphs we can\nprovably solve the approximate nearest neighbor problem with approximation\nfactor \\(c &gt; 1\\) in query time \\(n^{\\rho_q + o(1)}\\) and space \\(n^{1 + \\rho_s +\no(1)}\\), for arbitrary \\(\\rho_q, \\rho_s \\geq 0\\) satisfying \\begin{align} (2c^2 -\n1) \\rho_q + 2 c^2 (c^2 - 1) \\sqrt{\\rho_s (1 - \\rho_s)} \\geq c^4. \\end{align}\nGraph-based near neighbor searching is especially competitive with hash-based\nmethods for small \\(c\\) and near-linear memory, and in this regime the asymptotic\nscaling of a greedy graph-based search matches the recent optimal hash-based\ntrade-offs of Andoni-Laarhoven-Razenshteyn-Waingarten [SODA\u201917]. We further\nstudy how the trade-offs scale when the data set is of size \\(n =\n2^{\\Theta(d)}\\), and analyze asymptotic complexities when applying these results\nto lattice sieving.</p>\n", "tags": ["Graph Based ANN", "Efficiency And Optimization"], "tsne_embedding": [29.495038986206055, 3.368027925491333], "cluster": 7}, {"key": "laarhoven2019polytopes", "year": "2019", "citations": "16", "title": "Polytopes, Lattices, And Spherical Codes For The Nearest Neighbor Problem", "abstract": "<p>We study locality-sensitive hash methods for the nearest neighbor problem for\nthe angular distance, focusing on the approach of first projecting down onto a\nlow-dimensional subspace, and then partitioning the projected vectors according\nto Voronoi cells induced by a suitable spherical code. This approach\ngeneralizes and interpolates between the fast but suboptimal hyperplane hashing\nof Charikar [STOC\u201902] and the asymptotically optimal but practically often\nslower hash families of Andoni-Indyk [FOCS\u201906], Andoni-Indyk-Nguyen-Razenshteyn\n[SODA\u201914] and Andoni-Indyk-Laarhoven-Razenshteyn-Schmidt [NIPS\u201915]. We set up a\nframework for analyzing the performance of any spherical code in this context,\nand we provide results for various codes from the literature, such as those\nrelated to regular polytopes and root lattices. Similar to hyperplane hashing,\nand unlike cross-polytope hashing, our analysis of collision probabilities and\nquery exponents is exact and does not hide order terms which vanish only for\nlarge \\(d\\), facilitating an easy parameter selection.\n  For the two-dimensional case, we derive closed-form expressions for arbitrary\nspherical codes, and we show that the equilateral triangle is optimal,\nachieving a better performance than the two-dimensional analogues of hyperplane\nand cross-polytope hashing. In three and four dimensions, we numerically find\nthat the tetrahedron, \\(5\\)-cell, and \\(16\\)-cell achieve the best query exponents,\nwhile in five or more dimensions orthoplices appear to outperform regular\nsimplices, as well as the root lattice families \\(A_k\\) and \\(D_k\\). We argue that\nin higher dimensions, larger spherical codes will likely exist which will\noutperform orthoplices in theory, and we argue why using the \\(D_k\\) root\nlattices will likely lead to better results in practice, due to a better\ntrade-off between the asymptotic query exponent and the concrete costs of\nhashing.</p>\n", "tags": ["Tools & Libraries", "Evaluation", "Hashing Methods"], "tsne_embedding": [29.840635299682617, -1.0057684183120728], "cluster": 7}, {"key": "lai2016instance", "year": "2016", "citations": "78", "title": "Instance-aware Hashing For Multi-label Image Retrieval", "abstract": "<p>Similarity-preserving hashing is a commonly used method for nearest neighbour\nsearch in large-scale image retrieval. For image retrieval, deep-networks-based\nhashing methods are appealing since they can simultaneously learn effective\nimage representations and compact hash codes. This paper focuses on\ndeep-networks-based hashing for multi-label images, each of which may contain\nobjects of multiple categories. In most existing hashing methods, each image is\nrepresented by one piece of hash code, which is referred to as semantic\nhashing. This setting may be suboptimal for multi-label image retrieval. To\nsolve this problem, we propose a deep architecture that learns\n\\textbf{instance-aware} image representations for multi-label image data, which\nare organized in multiple groups, with each group containing the features for\none category. The instance-aware representations not only bring advantages to\nsemantic hashing, but also can be used in category-aware hashing, in which an\nimage is represented by multiple pieces of hash codes and each piece of code\ncorresponds to a category. Extensive evaluations conducted on several benchmark\ndatasets demonstrate that, for both semantic hashing and category-aware\nhashing, the proposed method shows substantial improvement over the\nstate-of-the-art supervised and unsupervised hashing methods.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Text Retrieval", "Evaluation"], "tsne_embedding": [-8.73140811920166, 4.207755088806152], "cluster": 8}, {"key": "lai2017improved", "year": "2017", "citations": "12", "title": "Improved Search In Hamming Space Using Deep Multi-index Hashing", "abstract": "<p>Similarity-preserving hashing is a widely-used method for nearest neighbour\nsearch in large-scale image retrieval tasks. There has been considerable\nresearch on generating efficient image representation via the\ndeep-network-based hashing methods. However, the issue of efficient searching\nin the deep representation space remains largely unsolved. To this end, we\npropose a simple yet efficient deep-network-based multi-index hashing method\nfor simultaneously learning the powerful image representation and the efficient\nsearching. To achieve these two goals, we introduce the multi-index hashing\n(MIH) mechanism into the proposed deep architecture, which divides the binary\ncodes into multiple substrings. Due to the non-uniformly distributed codes will\nresult in inefficiency searching, we add the two balanced constraints at\nfeature-level and instance-level, respectively. Extensive evaluations on\nseveral benchmark image retrieval datasets show that the learned balanced\nbinary codes bring dramatic speedups and achieve comparable performance over\nthe existing baselines.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Vector Indexing", "Evaluation"], "tsne_embedding": [-9.10854434967041, 9.229129791259766], "cluster": 8}, {"key": "lai2017transductive", "year": "2017", "citations": "9", "title": "Transductive Zero-shot Hashing Via Coarse-to-fine Similarity Mining", "abstract": "<p>Zero-shot Hashing (ZSH) is to learn hashing models for novel/target classes\nwithout training data, which is an important and challenging problem. Most\nexisting ZSH approaches exploit transfer learning via an intermediate shared\nsemantic representations between the seen/source classes and novel/target\nclasses. However, due to having disjoint, the hash functions learned from the\nsource dataset are biased when applied directly to the target classes. In this\npaper, we study the transductive ZSH, i.e., we have unlabeled data for novel\nclasses. We put forward a simple yet efficient joint learning approach via\ncoarse-to-fine similarity mining which transfers knowledges from source data to\ntarget data. It mainly consists of two building blocks in the proposed deep\narchitecture: 1) a shared two-streams network, which the first stream operates\non the source data and the second stream operates on the unlabeled data, to\nlearn the effective common image representations, and 2) a coarse-to-fine\nmodule, which begins with finding the most representative images from target\nclasses and then further detect similarities among these images, to transfer\nthe similarities of the source data to the target data in a greedy fashion.\nExtensive evaluation results on several benchmark datasets demonstrate that the\nproposed hashing method achieves significant improvement over the\nstate-of-the-art methods.</p>\n", "tags": ["DATASETS", "Evaluation", "Hashing Methods", "Multimodal Retrieval"], "tsne_embedding": [-7.510890960693359, -0.7438096404075623], "cluster": 8}, {"key": "lai2025simultaneous", "year": "2025", "citations": "916", "title": "Simultaneous Feature Learning And Hash Coding With Deep Neural Networks", "abstract": "<p>Similarity-preserving hashing is a widely-used method\nfor nearest neighbour search in large-scale image retrieval\ntasks. For most existing hashing methods, an image is\nfirst encoded as a vector of hand-engineering visual features,\nfollowed by another separate projection or quantization\nstep that generates binary codes. However, such visual\nfeature vectors may not be optimally compatible with the\ncoding process, thus producing sub-optimal hashing codes.\nIn this paper, we propose a deep architecture for supervised\nhashing, in which images are mapped into binary codes via\ncarefully designed deep neural networks. The pipeline of\nthe proposed deep architecture consists of three building\nblocks: 1) a sub-network with a stack of convolution layers\nto produce the effective intermediate image features; 2)\na divide-and-encode module to divide the intermediate image\nfeatures into multiple branches, each encoded into one\nhash bit; and 3) a triplet ranking loss designed to characterize\nthat one image is more similar to the second image than\nto the third one. Extensive evaluations on several benchmark\nimage datasets show that the proposed simultaneous\nfeature learning and hash coding pipeline brings substantial\nimprovements over other state-of-the-art supervised or\nunsupervised hashing methods.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "CVPR", "Compact Codes", "Similarity Search", "Quantization", "Evaluation"], "tsne_embedding": [-8.490053176879883, 3.604111433029175], "cluster": 8}, {"key": "lakshman2021embracing", "year": "2021", "citations": "56", "title": "Embracing Structure In Data For Billion-scale Semantic Product Search", "abstract": "<p>We present principled approaches to train and deploy dyadic neural embedding\nmodels at the billion scale, focusing our investigation on the application of\nsemantic product search. When training a dyadic model, one seeks to embed two\ndifferent types of entities (e.g., queries and documents or users and movies)\nin a common vector space such that pairs with high relevance are positioned\nnearby. During inference, given an embedding of one type (e.g., a query or a\nuser), one seeks to retrieve the entities of the other type (e.g., documents or\nmovies, respectively) that are highly relevant. In this work, we show that\nexploiting the natural structure of real-world datasets helps address both\nchallenges efficiently. Specifically, we model dyadic data as a bipartite graph\nwith edges between pairs with positive associations. We then propose to\npartition this network into semantically coherent clusters and thus reduce our\nsearch space by focusing on a small subset of these partitions for a given\ninput. During training, this technique enables us to efficiently mine hard\nnegative examples while, at inference, we can quickly find the nearest\nneighbors for a given embedding. We provide offline experimental results that\ndemonstrate the efficacy of our techniques for both training and inference on a\nbillion-scale Amazon.com product search dataset.</p>\n", "tags": ["KDD", "Large Scale Search", "DATASETS"], "tsne_embedding": [14.237339973449707, 15.343984603881836], "cluster": 0}, {"key": "lam2018word2bits", "year": "2018", "citations": "27", "title": "Word2bits - Quantized Word Vectors", "abstract": "<p>Word vectors require significant amounts of memory and storage, posing issues\nto resource limited devices like mobile phones and GPUs. We show that high\nquality quantized word vectors using 1-2 bits per parameter can be learned by\nintroducing a quantization function into Word2Vec. We furthermore show that\ntraining with the quantization function acts as a regularizer. We train word\nvectors on English Wikipedia (2017) and evaluate them on standard word\nsimilarity and analogy tasks and on question answering (SQuAD). Our quantized\nword vectors not only take 8-16x less space than full precision (32 bit) word\nvectors but also outperform them on word similarity tasks and question\nanswering.</p>\n", "tags": ["Quantization", "Evaluation", "Graph Based ANN"], "tsne_embedding": [-9.172224998474121, -17.853965759277344], "cluster": 5}, {"key": "larocca2014density", "year": "2014", "citations": "5", "title": "Density Adaptive Parallel Clustering", "abstract": "<p>In this paper we are going to introduce a new nearest neighbours based\napproach to clustering, and compare it with previous solutions; the resulting\nalgorithm, which takes inspiration from both DBscan and minimum spanning tree\napproaches, is deterministic but proves simpler, faster and doesnt require to\nset in advance a value for k, the number of clusters.</p>\n", "tags": [], "tsne_embedding": [19.18766975402832, 6.2444024085998535], "cluster": 0}, {"key": "lassance2022composite", "year": "2022", "citations": "5", "title": "Composite Code Sparse Autoencoders For First Stage Retrieval", "abstract": "<p>We propose a Composite Code Sparse Autoencoder (CCSA) approach for\nApproximate Nearest Neighbor (ANN) search of document representations based on\nSiamese-BERT models. In Information Retrieval (IR), the ranking pipeline is\ngenerally decomposed in two stages: the first stage focus on retrieving a\ncandidate set from the whole collection. The second stage re-ranks the\ncandidate set by relying on more complex models. Recently, Siamese-BERT models\nhave been used as first stage ranker to replace or complement the traditional\nbag-of-word models. However, indexing and searching a large document collection\nrequire efficient similarity search on dense vectors and this is why ANN\ntechniques come into play. Since composite codes are naturally sparse, we first\nshow how CCSA can learn efficient parallel inverted index thanks to an\nuniformity regularizer. Second, CCSA can be used as a binary quantization\nmethod and we propose to combine it with the recent graph based ANN techniques.\nOur experiments on MSMARCO dataset reveal that CCSA outperforms IVF with\nproduct quantization. Furthermore, CCSA binary quantization is beneficial for\nthe index size, and memory usage for the graph-based HNSW method, while\nmaintaining a good level of recall and MRR. Third, we compare with recent\nsupervised quantization methods for image retrieval and find that CCSA is able\nto outperform them.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Graph Based ANN", "Efficiency And Optimization", "SIGIR", "Similarity Search", "Quantization", "Vector Indexing", "Evaluation"], "tsne_embedding": [6.255884170532227, 0.66144198179245], "cluster": 4}, {"key": "lau2017end", "year": "2017", "citations": "7", "title": "End-to-end Network For Twitter Geolocation Prediction And Hashing", "abstract": "<p>We propose an end-to-end neural network to predict the geolocation of a\ntweet. The network takes as input a number of raw Twitter metadata such as the\ntweet message and associated user account information. Our model is language\nindependent, and despite minimal feature engineering, it is interpretable and\ncapable of learning location indicative words and timing patterns. Compared to\nstate-of-the-art systems, our model outperforms them by 2%-6%. Additionally, we\npropose extensions to the model to compress representation learnt by the\nnetwork into binary codes. Experiments show that it produces compact codes\ncompared to benchmark hashing algorithms. An implementation of the model is\nreleased publicly.</p>\n", "tags": ["Compact Codes", "Hashing Methods", "Evaluation"], "tsne_embedding": [7.307129383087158, -14.006080627441406], "cluster": 2}, {"key": "le2019btel", "year": "2019", "citations": "5", "title": "BTEL: A Binary Tree Encoding Approach For Visual Localization", "abstract": "<p>Visual localization algorithms have achieved significant improvements in\nperformance thanks to recent advances in camera technology and vision-based\ntechniques. However, there remains one critical caveat: all current approaches\nthat are based on image retrieval currently scale at best linearly with the\nsize of the environment with respect to both storage, and consequentially in\nmost approaches, query time. This limitation severely curtails the capability\nof autonomous systems in a wide range of compute, power, storage, size, weight\nor cost constrained applications such as drones. In this work, we present a\nnovel binary tree encoding approach for visual localization which can serve as\nan alternative for existing quantization and indexing techniques. The proposed\ntree structure allows us to derive a compressed training scheme that achieves\nsub-linearity in both required storage and inference time. The encoding memory\ncan be easily configured to satisfy different storage constraints. Moreover,\nour approach is amenable to an optional sequence filtering mechanism to further\nimprove the localization results, while maintaining the same amount of storage.\nOur system is entirely agnostic to the front-end descriptors, allowing it to be\nused on top of recent state-of-the-art image representations. Experimental\nresults show that the proposed method significantly outperforms\nstate-of-the-art approaches under limited storage constraints.</p>\n", "tags": ["Image Retrieval", "Efficiency And Optimization", "Alt", "Quantization", "Evaluation"], "tsne_embedding": [-13.310766220092773, 9.5900239944458], "cluster": 3}, {"key": "lebedev2018impostor", "year": "2018", "citations": "39", "title": "Impostor Networks For Fast Fine-grained Recognition", "abstract": "<p>In this work we introduce impostor networks, an architecture that allows to\nperform fine-grained recognition with high accuracy and using a light-weight\nconvolutional network, making it particularly suitable for fine-grained\napplications on low-power and non-GPU enabled platforms. Impostor networks\ncompensate for the lightness of its `backend\u2019 network by combining it with a\nlightweight non-parametric classifier. The combination of a convolutional\nnetwork and such non-parametric classifier is trained in an end-to-end fashion.\nSimilarly to convolutional neural networks, impostor networks can fit\nlarge-scale training datasets very well, while also being able to generalize to\nnew data points. At the same time, the bulk of computations within impostor\nnetworks happen through nearest neighbor search in high-dimensions. Such search\ncan be performed efficiently on a variety of architectures including standard\nCPUs, where deep convolutional networks are inefficient. In a series of\nexperiments with three fine-grained datasets, we show that impostor networks\nare able to boost the classification accuracy of a moderate-sized convolutional\nnetwork considerably at a very small computational cost.</p>\n", "tags": ["ICCV", "DATASETS"], "tsne_embedding": [-1.0471142530441284, -16.68749237060547], "cluster": 5}, {"key": "lee2019network", "year": "2019", "citations": "5", "title": "Network Pruning For Low-rank Binary Indexing", "abstract": "<p>Pruning is an efficient model compression technique to remove redundancy in\nthe connectivity of deep neural networks (DNNs). Computations using sparse\nmatrices obtained by pruning parameters, however, exhibit vastly different\nparallelism depending on the index representation scheme. As a result,\nfine-grained pruning has not gained much attention due to its irregular index\nform leading to large memory footprint and low parallelism for convolutions and\nmatrix multiplications. In this paper, we propose a new network pruning\ntechnique that generates a low-rank binary index matrix to compress index data\nwhile decompressing index data is performed by simple binary matrix\nmultiplication. This proposed compression method finds a particular\nfine-grained pruning mask that can be decomposed into two binary matrices. We\nalso propose a tile-based factorization technique that not only lowers memory\nrequirements but also enhances compression ratio. Various DNN models can be\npruned with much fewer indexes compared to previous sparse matrix formats while\nmaintaining the same pruning rate.</p>\n", "tags": ["Efficiency And Optimization"], "tsne_embedding": [1.96058189868927, -8.47690486907959], "cluster": 9}, {"key": "lee2020flexor", "year": "2020", "citations": "9", "title": "Flexor: Trainable Fractional Quantization", "abstract": "<p>Quantization based on the binary codes is gaining attention because each\nquantized bit can be directly utilized for computations without dequantization\nusing look-up tables. Previous attempts, however, only allow for integer\nnumbers of quantization bits, which ends up restricting the search space for\ncompression ratio and accuracy. In this paper, we propose an encryption\nalgorithm/architecture to compress quantized weights so as to achieve\nfractional numbers of bits per weight. Decryption during inference is\nimplemented by digital XOR-gate networks added into the neural network model\nwhile XOR gates are described by utilizing \\(\\tanh(x)\\) for backward propagation\nto enable gradient calculations. We perform experiments using MNIST, CIFAR-10,\nand ImageNet to show that inserting XOR gates learns quantization/encrypted bit\ndecisions through training and obtains high accuracy even for fractional sub\n1-bit weights. As a result, our proposed method yields smaller size and higher\nmodel accuracy compared to binary neural networks.</p>\n", "tags": ["Compact Codes", "Quantization"], "tsne_embedding": [-5.639259338378906, -14.44347095489502], "cluster": 9}, {"key": "lee2020metric", "year": "2020", "citations": "11", "title": "Metric Learning Vs Classification For Disentangled Music Representation Learning", "abstract": "<p>Deep representation learning offers a powerful paradigm for mapping input\ndata onto an organized embedding space and is useful for many music information\nretrieval tasks. Two central methods for representation learning include deep\nmetric learning and classification, both having the same goal of learning a\nrepresentation that can generalize well across tasks. Along with\ngeneralization, the emerging concept of disentangled representations is also of\ngreat interest, where multiple semantic concepts (e.g., genre, mood,\ninstrumentation) are learned jointly but remain separable in the learned\nrepresentation space. In this paper we present a single representation learning\nframework that elucidates the relationship between metric learning,\nclassification, and disentanglement in a holistic manner. For this, we (1)\noutline past work on the relationship between metric learning and\nclassification, (2) extend this relationship to multi-label data by exploring\nthree different learning approaches and their disentangled versions, and (3)\nevaluate all models on four tasks (training time, similarity retrieval,\nauto-tagging, and triplet prediction). We find that classification-based models\nare generally advantageous for training time, similarity retrieval, and\nauto-tagging, while deep metric learning exhibits better performance for\ntriplet-prediction. Finally, we show that our proposed approach yields\nstate-of-the-art results for music auto-tagging.</p>\n", "tags": ["Similarity Search", "Tools & Libraries", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [-25.171688079833984, 7.323073863983154], "cluster": 3}, {"key": "lehmann2023sliding", "year": "2023", "citations": "103", "title": "Sliding Block Hashing (slick) -- Basic Algorithmic Ideas", "abstract": "<p>We present {\\bf Sli}ding Blo{\\bf ck} Hashing (Slick), a simple hash table\ndata structure that combines high performance with very good space efficiency.\nThis preliminary report outlines avenues for analysis and implementation that\nwe intend to pursue.</p>\n", "tags": ["Hashing Methods", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [16.622108459472656, -16.351354598999023], "cluster": 2}, {"key": "lehmann2025combined", "year": "2025", "citations": "5", "title": "Combined Search And Encoding For Seeds, With An Application To Minimal Perfect Hashing", "abstract": "<p>Randomised algorithms often employ methods that can fail and that are retried with independent randomness until they succeed. Randomised data structures therefore often store indices of successful attempts, called seeds. If \\(n\\) such seeds are required (e.g., for independent substructures) the standard approach is to compute for each \\(i \\in [n]\\) the smallest successful seed \\(S_i\\) and store \\(\\vec{S} = (S_1, \\ldots, S_n)\\).\n  The central observation of this paper is that this is not space-optimal. We present a different algorithm that computes a sequence \\(\\vec{S}\u2019 = (S_1\u2019, \\ldots, S_n\u2019)\\) of successful seeds such that the entropy of \\(\\vec{S\u2019}\\) undercuts the entropy of \\(\\vec{S}\\) by \\(\u03a9(n)\\) bits in most cases. To achieve a memory consumption of \\(\\mathrm{OPT}+\\epsilon n\\), the expected number of inspected seeds increases by a factor of \\(O(1/\\epsilon)\\).\n  We demonstrate the usefulness of our findings with a novel construction for minimal perfect hash functions that, for \\(n\\) keys and any \\(\\epsilon \\in [n^{-3/7}, 1]\\), has space requirement \\((1+\\epsilon)\\mathrm{OPT}\\) and construction time \\(O(n/\\epsilon)\\). All previous approaches only support \\(\\epsilon = \\omega(1 / log n)\\) or have construction times that increase exponentially with \\(1/\\epsilon\\). Our implementation beats the construction throughput of the state of the art by more than two orders of magnitude for \\(\\epsilon \\leq 3%\\).</p>\n", "tags": ["Hashing Methods"], "tsne_embedding": [-4.6210246086120605, -26.345048904418945], "cluster": 5}, {"key": "lehmann2025modern", "year": "2025", "citations": "5", "title": "Modern Minimal Perfect Hashing: A Survey", "abstract": "<p>Given a set \\(S\\) of \\(n\\) keys, a perfect hash function for \\(S\\) maps the keys in \\(S\\) to the first \\(m \\geq n\\) integers without collisions. It may return an arbitrary result for any key not in \\(S\\) and is called minimal if \\(m = n\\). The most important parameters are its space consumption, construction time, and query time. Years of research now enable modern perfect hash functions to be extremely fast to query, very space-efficient, and scale to billions of keys. Different approaches give different trade-offs between these aspects. For example, the smallest constructions get within 0.1% of the space lower bound of \\(log_2(e)\\) bits per key. Others are particularly fast to query, requiring only one memory access. Perfect hashing has many applications, for example to avoid collision resolution in static hash tables, and is used in databases, bioinformatics, and stringology.\n  Since the last comprehensive survey in 1997, significant progress has been made. This survey covers the latest developments and provides a starting point for getting familiar with the topic. Additionally, our extensive experimental evaluation can serve as a guide to select a perfect hash function for use in applications.</p>\n", "tags": ["Survey Paper", "Hashing Methods", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [-7.708430290222168, -24.901473999023438], "cluster": 5}, {"key": "lei2020locality", "year": "2020", "citations": "24", "title": "Locality-sensitive Hashing Scheme Based On Longest Circular Co-substring", "abstract": "<p>Locality-Sensitive Hashing (LSH) is one of the most popular methods for\n\\(c\\)-Approximate Nearest Neighbor Search (\\(c\\)-ANNS) in high-dimensional spaces.\nIn this paper, we propose a novel LSH scheme based on the Longest Circular\nCo-Substring (LCCS) search framework (LCCS-LSH) with a theoretical guarantee.\nWe introduce a novel concept of LCCS and a new data structure named Circular\nShift Array (CSA) for \\(k\\)-LCCS search. The insight of LCCS search framework is\nthat close data objects will have a longer LCCS than the far-apart ones with\nhigh probability. LCCS-LSH is <em>LSH-family-independent</em>, and it supports\n\\(c\\)-ANNS with different kinds of distance metrics. We also introduce a\nmulti-probe version of LCCS-LSH and conduct extensive experiments over five\nreal-life datasets. The experimental results demonstrate that LCCS-LSH\noutperforms state-of-the-art LSH schemes.</p>\n", "tags": ["Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Distance Metric Learning", "Tools & Libraries"], "tsne_embedding": [15.533039093017578, -1.026390552520752], "cluster": 2}, {"key": "lejeune2019adaptive", "year": "2019", "citations": "8", "title": "Adaptive Estimation For Approximate K-nearest-neighbor Computations", "abstract": "<p>Algorithms often carry out equally many computations for \u201ceasy\u201d and \u201chard\u201d\nproblem instances. In particular, algorithms for finding nearest neighbors\ntypically have the same running time regardless of the particular problem\ninstance. In this paper, we consider the approximate k-nearest-neighbor\nproblem, which is the problem of finding a subset of O(k) points in a given set\nof points that contains the set of k nearest neighbors of a given query point.\nWe propose an algorithm based on adaptively estimating the distances, and show\nthat it is essentially optimal out of algorithms that are only allowed to\nadaptively estimate distances. We then demonstrate both theoretically and\nexperimentally that the algorithm can achieve significant speedups relative to\nthe naive method.</p>\n", "tags": ["Efficiency And Optimization"], "tsne_embedding": [18.208354949951172, -4.334322452545166], "cluster": 2}, {"key": "leng2025hashing", "year": "2025", "citations": "30", "title": "Hashing For Distributed Data", "abstract": "<p>Recently, hashing based approximate nearest\nneighbors search has attracted much attention.\nExtensive centralized hashing algorithms have\nbeen proposed and achieved promising performance. However, due to the large scale of many\napplications, the data is often stored or even collected in a distributed manner. Learning hash\nfunctions by aggregating all the data into a fusion\ncenter is infeasible because of the prohibitively\nexpensive communication and computation overhead.\nIn this paper, we develop a novel hashing\nmodel to learn hash functions in a distributed setting. We cast a centralized hashing model as a\nset of subproblems with consensus constraints.\nWe find these subproblems can be analytically\nsolved in parallel on the distributed compute nodes. Since no training data is transmitted across\nthe nodes in the learning process, the communication cost of our model is independent to the data size. Extensive experiments on several large\nscale datasets containing up to 100 million samples demonstrate the efficacy of our method.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Evaluation"], "tsne_embedding": [-3.0534467697143555, -17.919580459594727], "cluster": 5}, {"key": "leroux2024euclidean", "year": "2024", "citations": "13", "title": "Euclidean Distance Compression Via Deep Random Features", "abstract": "<p>Motivated by the problem of compressing point sets into as few bits as\npossible while maintaining information about approximate distances between\npoints, we construct random nonlinear maps \\(\\varphi_\\ell\\) that compress point\nsets in the following way. For a point set \\(S\\), the map\n\\(\\varphi_\\ell:\\mathbb{R}^d \\to N^{-1/2}\\{-1,1\\}^N\\) has the property that\nstoring \\(\\varphi_\\ell(S)\\) (a <em>sketch</em> of \\(S\\)) allows one to report\npairwise squared distances between points in \\(S\\) up to some multiplicative\n\\((1\\pm \\epsilon)\\) error with high probability as long as the minimum distance\nis not too small compared to \\(\\epsilon\\). The maps \\(\\varphi_\\ell\\) are the\n\\(\\ell\\)-fold composition of a certain type of random feature mapping. Moreover,\nwe determine how large \\(N\\) needs to be as a function of \\(\\epsilon\\) and other\nparameters of the point set.\n  Compared to existing techniques, our maps offer several advantages. The\nstandard method for compressing point sets by random mappings relies on the\nJohnson-Lindenstrauss lemma which implies that if a set of \\(n\\) points is mapped\nby a Gaussian random matrix to \\(\\mathbb{R}^k\\) with \\(k =\\Theta(\\epsilon^{-2}log\nn)\\), then pairwise distances between points are preserved up to a\nmultiplicative \\((1\\pm \\epsilon)\\) error with high probability. The main\nadvantage of our maps \\(\\varphi_\\ell\\) over random linear maps is that ours map\npoint sets directly into the discrete cube \\(N^{-1/2}\\{-1,1\\}^N\\) and so there is\nno additional step needed to convert the sketch to bits. For some range of\nparameters, our maps \\(\\varphi_\\ell\\) produce sketches which require fewer bits\nof storage space.</p>\n", "tags": ["Evaluation", "Distance Metric Learning"], "tsne_embedding": [33.13565444946289, 1.1340125799179077], "cluster": 7}, {"key": "lessley2018data", "year": "2018", "citations": "33", "title": "Data-parallel Hashing Techniques For GPU Architectures", "abstract": "<p>Hash tables are one of the most fundamental data structures for effectively\nstoring and accessing sparse data, with widespread usage in domains ranging\nfrom computer graphics to machine learning. This study surveys the\nstate-of-the-art research on data-parallel hashing techniques for emerging\nmassively-parallel, many-core GPU architectures. Key factors affecting the\nperformance of different hashing schemes are discovered and used to suggest\nbest practices and pinpoint areas for further research.</p>\n", "tags": ["Survey Paper", "Hashing Methods", "Evaluation"], "tsne_embedding": [18.521854400634766, 21.82940673828125], "cluster": 0}, {"key": "levi2020rethinking", "year": "2020", "citations": "15", "title": "Rethinking Preventing Class-collapsing In Metric Learning With Margin-based Losses", "abstract": "<p>Metric learning seeks perceptual embeddings where visually similar instances\nare close and dissimilar instances are apart, but learned representations can\nbe sub-optimal when the distribution of intra-class samples is diverse and\ndistinct sub-clusters are present. Although theoretically with optimal\nassumptions, margin-based losses such as the triplet loss and margin loss have\na diverse family of solutions. We theoretically prove and empirically show that\nunder reasonable noise assumptions, margin-based losses tend to project all\nsamples of a class with various modes onto a single point in the embedding\nspace, resulting in a class collapse that usually renders the space ill-sorted\nfor classification or retrieval. To address this problem, we propose a simple\nmodification to the embedding losses such that each sample selects its nearest\nsame-class counterpart in a batch as the positive element in the tuple. This\nallows for the presence of multiple sub-clusters within each class. The\nadaptation can be integrated into a wide range of metric learning losses. The\nproposed sampling method demonstrates clear benefits on various fine-grained\nimage retrieval datasets over a variety of existing losses; qualitative\nretrieval results show that samples with similar visual patterns are indeed\ncloser in the embedding space.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Distance Metric Learning", "Alt", "ICCV"], "tsne_embedding": [-24.31235122680664, 3.356632947921753], "cluster": 3}, {"key": "levrard2018quantization", "year": "2018", "citations": "6", "title": "Quantization/clustering: When And Why Does K-means Work?", "abstract": "<p>Though mostly used as a clustering algorithm, k-means are originally designed\nas a quantization algorithm. Namely, it aims at providing a compression of a\nprobability distribution with k points. Building upon [21, 33], we try to\ninvestigate how and when these two approaches are compatible. Namely, we show\nthat provided the sample distribution satisfies a margin like condition (in the\nsense of [27] for supervised learning), both the associated empirical risk\nminimizer and the output of Lloyd\u2019s algorithm provide almost optimal\nclassification in certain cases (in the sense of [6]). Besides, we also show\nthat they achieved fast and optimal convergence rates in terms of sample size\nand compression risk.</p>\n", "tags": ["Quantization"], "tsne_embedding": [18.978118896484375, -2.985912561416626], "cluster": 7}, {"key": "leyvavallina2023data", "year": "2023", "citations": "23", "title": "Data-efficient Large Scale Place Recognition With Graded Similarity Supervision", "abstract": "<p>Visual place recognition (VPR) is a fundamental task of computer vision for\nvisual localization. Existing methods are trained using image pairs that either\ndepict the same place or not. Such a binary indication does not consider\ncontinuous relations of similarity between images of the same place taken from\ndifferent positions, determined by the continuous nature of camera pose. The\nbinary similarity induces a noisy supervision signal into the training of VPR\nmethods, which stall in local minima and require expensive hard mining\nalgorithms to guarantee convergence. Motivated by the fact that two images of\nthe same place only partially share visual cues due to camera pose differences,\nwe deploy an automatic re-annotation strategy to re-label VPR datasets. We\ncompute graded similarity labels for image pairs based on available\nlocalization metadata. Furthermore, we propose a new Generalized Contrastive\nLoss (GCL) that uses graded similarity labels for training contrastive\nnetworks. We demonstrate that the use of the new labels and GCL allow to\ndispense from hard-pair mining, and to train image descriptors that perform\nbetter in VPR by nearest neighbor search, obtaining superior or comparable\nresults than methods that require expensive hard-pair mining and re-ranking\ntechniques. Code and models available at:\nhttps://github.com/marialeyvallina/generalized_contrastive_loss</p>\n", "tags": ["CVPR", "DATASETS"], "tsne_embedding": [-8.854629516601562, 7.967535972595215], "cluster": 8}, {"key": "li2013sign", "year": "2013", "citations": "6", "title": "Sign Stable Projections, Sign Cauchy Projections And Chi-square Kernels", "abstract": "<p>The method of stable random projections is popular for efficiently computing\nthe Lp distances in high dimension (where 0&lt;p&lt;=2), using small space. Because\nit adopts nonadaptive linear projections, this method is naturally suitable\nwhen the data are collected in a dynamic streaming fashion (i.e., turnstile\ndata streams). In this paper, we propose to use only the signs of the projected\ndata and analyze the probability of collision (i.e., when the two signs\ndiffer). We derive a bound of the collision probability which is exact when p=2\nand becomes less sharp when p moves away from 2. Interestingly, when p=1 (i.e.,\nCauchy random projections), we show that the probability of collision can be\naccurately approximated as functions of the chi-square similarity. For example,\nwhen the (un-normalized) data are binary, the maximum approximation error of\nthe collision probability is smaller than 0.0192. In text and vision\napplications, the chi-square similarity is a popular measure for nonnegative\ndata when the features are generated from histograms. Our experiments confirm\nthat the proposed method is promising for large-scale learning applications.</p>\n", "tags": ["AAAI", "Locality Sensitive Hashing"], "tsne_embedding": [27.004840850830078, 7.365784645080566], "cluster": 7}, {"key": "li20162", "year": "2016", "citations": "5", "title": "2-bit Random Projections, Nonlinear Estimators, And Approximate Near Neighbor Search", "abstract": "<p>The method of random projections has become a standard tool for machine\nlearning, data mining, and search with massive data at Web scale. The effective\nuse of random projections requires efficient coding schemes for quantizing\n(real-valued) projected data into integers. In this paper, we focus on a simple\n2-bit coding scheme. In particular, we develop accurate nonlinear estimators of\ndata similarity based on the 2-bit strategy. This work will have important\npractical applications. For example, in the task of near neighbor search, a\ncrucial step (often called re-ranking) is to compute or estimate data\nsimilarities once a set of candidate data points have been identified by hash\ntable techniques. This re-ranking step can take advantage of the proposed\ncoding scheme and estimator.\n  As a related task, in this paper, we also study a simple uniform quantization\nscheme for the purpose of building hash tables with projected data. Our\nanalysis shows that typically only a small number of bits are needed. For\nexample, when the target similarity level is high, 2 or 3 bits might be\nsufficient. When the target similarity level is not so high, it is preferable\nto use only 1 or 2 bits. Therefore, a 2-bit scheme appears to be overall a good\nchoice for the task of sublinear time approximate near neighbor search via hash\ntables.\n  Combining these results, we conclude that 2-bit random projections should be\nrecommended for approximate near neighbor search and similarity estimation.\nExtensive experimental results are provided.</p>\n", "tags": ["Locality Sensitive Hashing", "Quantization"], "tsne_embedding": [9.886401176452637, 1.8723562955856323], "cluster": 4}, {"key": "li2016generalized", "year": "2016", "citations": "99", "title": "Generalized Intersection Kernel", "abstract": "<p>Following the very recent line of work on the <code class=\"language-plaintext highlighter-rouge\">generalized min-max'' (GMM)\nkernel, this study proposes the</code>generalized intersection\u2019\u2019 (GInt) kernel and\nthe related <code class=\"language-plaintext highlighter-rouge\">normalized generalized min-max'' (NGMM) kernel. In computer\nvision, the (histogram) intersection kernel has been popular, and the GInt\nkernel generalizes it to data which can have both negative and positive\nentries. Through an extensive empirical classification study on 40 datasets\nfrom the UCI repository, we are able to show that this (tuning-free) GInt\nkernel performs fairly well.\n  The empirical results also demonstrate that the NGMM kernel typically\noutperforms the GInt kernel. Interestingly, the NGMM kernel has another\ninterpretation --- it is the</code>asymmetrically transformed\u2019\u2019 version of the GInt\nkernel, based on the idea of ``asymmetric hashing\u2019\u2019. Just like the GMM kernel,\nthe NGMM kernel can be efficiently linearized through (e.g.,) generalized\nconsistent weighted sampling (GCWS), as empirically validated in our study.\nOwing to the discrete nature of hashed values, it also provides a scheme for\napproximate near neighbor search.</p>\n", "tags": ["DATASETS", "Hashing Methods"], "tsne_embedding": [13.801572799682617, -17.40589714050293], "cluster": 2}, {"key": "li2016theory", "year": "2016", "citations": "15", "title": "Theory Of The GMM Kernel", "abstract": "<p>We develop some theoretical results for a robust similarity measure named\n\u201cgeneralized min-max\u201d (GMM). This similarity has direct applications in machine\nlearning as a positive definite kernel and can be efficiently computed via\nprobabilistic hashing. Owing to the discrete nature, the hashed values can also\nbe used for efficient near neighbor search. We prove the theoretical limit of\nGMM and the consistency result, assuming that the data follow an elliptical\ndistribution, which is a very general family of distributions and includes the\nmultivariate \\(t\\)-distribution as a special case. The consistency result holds\nas long as the data have bounded first moment (an assumption which essentially\nholds for datasets commonly encountered in practice). Furthermore, we establish\nthe asymptotic normality of GMM. Compared to the \u201ccosine\u201d similarity which is\nroutinely adopted in current practice in statistics and machine learning, the\nconsistency of GMM requires much weaker conditions. Interestingly, when the\ndata follow the \\(t\\)-distribution with \\(\\nu\\) degrees of freedom, GMM typically\nprovides a better measure of similarity than \u201ccosine\u201d roughly when \\(\\nu&lt;8\\)\n(which is already very close to normal). These theoretical results will help\nexplain the recent success of GMM in learning tasks.</p>\n", "tags": ["DATASETS", "Hashing Methods"], "tsne_embedding": [15.538881301879883, 1.93380868434906], "cluster": 4}, {"key": "li2017deep", "year": "2017", "citations": "126", "title": "Deep Binary Reconstruction For Cross-modal Hashing", "abstract": "<p>With the increasing demand of massive multimodal data storage and\norganization, cross-modal retrieval based on hashing technique has drawn much\nattention nowadays. It takes the binary codes of one modality as the query to\nretrieve the relevant hashing codes of another modality. However, the existing\nbinary constraint makes it difficult to find the optimal cross-modal hashing\nfunction. Most approaches choose to relax the constraint and perform\nthresholding strategy on the real-value representation instead of directly\nsolving the original objective. In this paper, we first provide a concrete\nanalysis about the effectiveness of multimodal networks in preserving the\ninter- and intra-modal consistency. Based on the analysis, we provide a\nso-called Deep Binary Reconstruction (DBRC) network that can directly learn the\nbinary hashing codes in an unsupervised fashion. The superiority comes from a\nproposed simple but efficient activation function, named as Adaptive Tanh\n(ATanh). The ATanh function can adaptively learn the binary codes and be\ntrained via back-propagation. Extensive experiments on three benchmark datasets\ndemonstrate that DBRC outperforms several state-of-the-art methods in both\nimage2text and text2image retrieval task.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Compact Codes", "Multimodal Retrieval", "Evaluation"], "tsne_embedding": [-6.696060657501221, -10.495295524597168], "cluster": 9}, {"key": "li2017fast", "year": "2017", "citations": "14", "title": "Fast K-nearest Neighbour Search Via Prioritized DCI", "abstract": "<p>Most exact methods for k-nearest neighbour search suffer from the curse of\ndimensionality; that is, their query times exhibit exponential dependence on\neither the ambient or the intrinsic dimensionality. Dynamic Continuous Indexing\n(DCI) offers a promising way of circumventing the curse and successfully\nreduces the dependence of query time on intrinsic dimensionality from\nexponential to sublinear. In this paper, we propose a variant of DCI, which we\ncall Prioritized DCI, and show a remarkable improvement in the dependence of\nquery time on intrinsic dimensionality. In particular, a linear increase in\nintrinsic dimensionality, or equivalently, an exponential increase in the\nnumber of points near a query, can be mostly counteracted with just a linear\nincrease in space. We also demonstrate empirically that Prioritized DCI\nsignificantly outperforms prior methods. In particular, relative to\nLocality-Sensitive Hashing (LSH), Prioritized DCI reduces the number of\ndistance evaluations by a factor of 14 to 116 and the memory consumption by a\nfactor of 21.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Efficiency And Optimization", "Similarity Search", "Evaluation"], "tsne_embedding": [15.487136840820312, -4.651917934417725], "cluster": 2}, {"key": "li2017image", "year": "2017", "citations": "16", "title": "Image Super-resolution Via Feature-augmented Random Forest", "abstract": "<p>Recent random-forest (RF)-based image super-resolution approaches inherit\nsome properties from dictionary-learning-based algorithms, but the\neffectiveness of the properties in RF is overlooked in the literature. In this\npaper, we present a novel feature-augmented random forest (FARF) for image\nsuper-resolution, where the conventional gradient-based features are augmented\nwith gradient magnitudes and different feature recipes are formulated on\ndifferent stages in an RF. The advantages of our method are that, firstly, the\ndictionary-learning-based features are enhanced by adding gradient magnitudes,\nbased on the observation that the non-linear gradient magnitude are with highly\ndiscriminative property. Secondly, generalized locality-sensitive hashing (LSH)\nis used to replace principal component analysis (PCA) for feature\ndimensionality reduction and original high-dimensional features are employed,\ninstead of the compressed ones, for the leaf-nodes\u2019 regressors, since\nregressors can benefit from higher dimensional features. This\noriginal-compressed coupled feature sets scheme unifies the unsupervised LSH\nevaluation on both image super-resolution and content-based image retrieval\n(CBIR). Finally, we present a generalized weighted ridge regression (GWRR)\nmodel for the leaf-nodes\u2019 regressors. Experiment results on several public\nbenchmark datasets show that our FARF method can achieve an average gain of\nabout 0.3 dB, compared to traditional RF-based methods. Furthermore, a\nfine-tuned FARF model can compare to or (in many cases) outperform some recent\nstateof-the-art deep-learning-based algorithms.</p>\n", "tags": ["Image Retrieval", "Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Evaluation"], "tsne_embedding": [2.3911619186401367, 1.5686436891555786], "cluster": 4}, {"key": "li2018dual", "year": "2018", "citations": "16", "title": "Dual Asymmetric Deep Hashing Learning", "abstract": "<p>Due to the impressive learning power, deep learning has achieved a remarkable\nperformance in supervised hash function learning. In this paper, we propose a\nnovel asymmetric supervised deep hashing method to preserve the semantic\nstructure among different categories and generate the binary codes\nsimultaneously. Specifically, two asymmetric deep networks are constructed to\nreveal the similarity between each pair of images according to their semantic\nlabels. The deep hash functions are then learned through two networks by\nminimizing the gap between the learned features and discrete codes.\nFurthermore, since the binary codes in the Hamming space also should keep the\nsemantic affinity existing in the original space, another asymmetric pairwise\nloss is introduced to capture the similarity between the binary codes and\nreal-value features. This asymmetric loss not only improves the retrieval\nperformance, but also contributes to a quick convergence at the training phase.\nBy taking advantage of the two-stream deep structures and two types of\nasymmetric pairwise functions, an alternating algorithm is designed to optimize\nthe deep features and high-quality binary codes efficiently. Experimental\nresults on three real-world datasets substantiate the effectiveness and\nsuperiority of our approach as compared with state-of-the-art.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Compact Codes", "Alt", "Neural Hashing", "Evaluation"], "tsne_embedding": [-6.689975738525391, -8.441142082214355], "cluster": 9}, {"key": "li2018hashtran", "year": "2018", "citations": "18", "title": "Hashtran-dnn: A Framework For Enhancing Robustness Of Deep Neural Networks Against Adversarial Malware Samples", "abstract": "<p>Adversarial machine learning in the context of image processing and related\napplications has received a large amount of attention. However, adversarial\nmachine learning, especially adversarial deep learning, in the context of\nmalware detection has received much less attention despite its apparent\nimportance. In this paper, we present a framework for enhancing the robustness\nof Deep Neural Networks (DNNs) against adversarial malware samples, dubbed\nHashing Transformation Deep Neural Networks} (HashTran-DNN). The core idea is\nto use hash functions with a certain locality-preserving property to transform\nsamples to enhance the robustness of DNNs in malware classification. The\nframework further uses a Denoising Auto-Encoder (DAE) regularizer to\nreconstruct the hash representations of samples, making the resulting DNN\nclassifiers capable of attaining the locality information in the latent space.\nWe experiment with two concrete instantiations of the HashTran-DNN framework to\nclassify Android malware. Experimental results show that four known attacks can\nrender standard DNNs useless in classifying Android malware, that known\ndefenses can at most defend three of the four attacks, and that HashTran-DNN\ncan effectively defend against all of the four attacks.</p>\n", "tags": ["Tools & Libraries", "Hashing Methods", "Robustness"], "tsne_embedding": [-8.560284614562988, 6.518310070037842], "cluster": 8}, {"key": "li2018self", "year": "2018", "citations": "423", "title": "Self-supervised Adversarial Hashing Networks For Cross-modal Retrieval", "abstract": "<p>Thanks to the success of deep learning, cross-modal retrieval has made\nsignificant progress recently. However, there still remains a crucial\nbottleneck: how to bridge the modality gap to further enhance the retrieval\naccuracy. In this paper, we propose a self-supervised adversarial hashing\n(\\textbf{SSAH}) approach, which lies among the early attempts to incorporate\nadversarial learning into cross-modal hashing in a self-supervised fashion. The\nprimary contribution of this work is that two adversarial networks are\nleveraged to maximize the semantic correlation and consistency of the\nrepresentations between different modalities. In addition, we harness a\nself-supervised semantic network to discover high-level semantic information in\nthe form of multi-label annotations. Such information guides the feature\nlearning process and preserves the modality relationships in both the common\nsemantic space and the Hamming space. Extensive experiments carried out on\nthree benchmark datasets validate that the proposed SSAH surpasses the\nstate-of-the-art methods.</p>\n", "tags": ["DATASETS", "Hashing Methods", "CVPR", "Multimodal Retrieval", "Evaluation", "Robustness"], "tsne_embedding": [-15.350075721740723, -1.362383484840393], "cluster": 1}, {"key": "li2018sign", "year": "2018", "citations": "8", "title": "Sign-full Random Projections", "abstract": "<p>The method of 1-bit (\u201csign-sign\u201d) random projections has been a popular tool\nfor efficient search and machine learning on large datasets. Given two \\(D\\)-dim\ndata vectors \\(u\\), \\(v\\in\\mathbb{R}^D\\), one can generate \\(x = \\sum_{i=1}^D u_i\nr_i\\), and \\(y = \\sum_{i=1}^D v_i r_i\\), where \\(r_i\\sim N(0,1)\\) iid. The\n\u201ccollision probability\u201d is \\({Pr}\\left(sgn(x)=sgn(y)\\right) =\n1-\\frac{\\cos^{-1}\\rho}{\\pi}\\), where \\(\\rho = \\rho(u,v)\\) is the cosine\nsimilarity.\n  We develop \u201csign-full\u201d random projections by estimating \\(\\rho\\) from (e.g.,)\nthe expectation \\(E(sgn(x)y)=\\sqrt{\\frac{2}{\\pi}} \\rho\\), which can be further\nsubstantially improved by normalizing \\(y\\). For nonnegative data, we recommend\nan interesting estimator based on \\(E\\left(y_- 1<em>{x\\geq 0} + y</em>+ 1_{x&lt;0}\\right)\\)\nand its normalized version. The recommended estimator almost matches the\naccuracy of the (computationally expensive) maximum likelihood estimator. At\nhigh similarity (\\(\\rho\\rightarrow1\\)), the asymptotic variance of recommended\nestimator is only \\(\\frac{4}{3\\pi} \\approx 0.4\\) of the estimator for sign-sign\nprojections. At small \\(k\\) and high similarity, the improvement would be even\nmuch more substantial.</p>\n", "tags": ["AAAI", "Locality Sensitive Hashing", "DATASETS"], "tsne_embedding": [32.45153045654297, -0.2146691530942917], "cluster": 7}, {"key": "li2019coupled", "year": "2019", "citations": "105", "title": "Coupled Cyclegan: Unsupervised Hashing Network For Cross-modal Retrieval", "abstract": "<p>In recent years, hashing has attracted more and more attention owing to its\nsuperior capacity of low storage cost and high query efficiency in large-scale\ncross-modal retrieval. Benefiting from deep leaning, continuously compelling\nresults in cross-modal retrieval community have been achieved. However,\nexisting deep cross-modal hashing methods either rely on amounts of labeled\ninformation or have no ability to learn an accuracy correlation between\ndifferent modalities. In this paper, we proposed Unsupervised coupled Cycle\ngenerative adversarial Hashing networks (UCH), for cross-modal retrieval, where\nouter-cycle network is used to learn powerful common representation, and\ninner-cycle network is explained to generate reliable hash codes. Specifically,\nour proposed UCH seamlessly couples these two networks with generative\nadversarial mechanism, which can be optimized simultaneously to learn\nrepresentation and hash codes. Extensive experiments on three popular benchmark\ndatasets show that the proposed UCH outperforms the state-of-the-art\nunsupervised cross-modal hashing methods.</p>\n", "tags": ["AAAI", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Multimodal Retrieval", "Evaluation", "Robustness"], "tsne_embedding": [1.7274874448776245, -15.374335289001465], "cluster": 5}, {"key": "li2019design", "year": "2019", "citations": "34", "title": "The Design And Implementation Of A Real Time Visual Search System On JD E-commerce Platform", "abstract": "<p>We present the design and implementation of a visual search system for real\ntime image retrieval on JD.com, the world\u2019s third largest and China\u2019s largest\ne-commerce site. We demonstrate that our system can support real time visual\nsearch with hundreds of billions of product images at sub-second timescales and\nhandle frequent image updates through distributed hierarchical architecture and\nefficient indexing methods. We hope that sharing our practice with our real\nproduction system will inspire the middleware community\u2019s interest and\nappreciation for building practical large scale systems for emerging\napplications, such as ecommerce visual search.</p>\n", "tags": ["Image Retrieval"], "tsne_embedding": [-19.655479431152344, 11.784614562988281], "cluster": 3}, {"key": "li2019push", "year": "2019", "citations": "7", "title": "Push For Quantization: Deep Fisher Hashing", "abstract": "<p>Current massive datasets demand light-weight access for analysis. Discrete\nhashing methods are thus beneficial because they map high-dimensional data to\ncompact binary codes that are efficient to store and process, while preserving\nsemantic similarity. To optimize powerful deep learning methods for image\nhashing, gradient-based methods are required. Binary codes, however, are\ndiscrete and thus have no continuous derivatives. Relaxing the problem by\nsolving it in a continuous space and then quantizing the solution is not\nguaranteed to yield separable binary codes. The quantization needs to be\nincluded in the optimization. In this paper we push for quantization: We\noptimize maximum class separability in the binary space. We introduce a margin\non distances between dissimilar image pairs as measured in the binary space. In\naddition to pair-wise distances, we draw inspiration from Fisher\u2019s Linear\nDiscriminant Analysis (Fisher LDA) to maximize the binary distances between\nclasses and at the same time minimize the binary distance of images within the\nsame class. Experiments on CIFAR-10, NUS-WIDE and ImageNet100 demonstrate\ncompact codes comparing favorably to the current state of the art.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Compact Codes", "Quantization", "Evaluation"], "tsne_embedding": [-4.52224063873291, 10.318679809570312], "cluster": 6}, {"key": "li2020deep", "year": "2020", "citations": "75", "title": "Deep Unsupervised Image Hashing By Maximizing Bit Entropy", "abstract": "<p>Unsupervised hashing is important for indexing huge image or video\ncollections without having expensive annotations available. Hashing aims to\nlearn short binary codes for compact storage and efficient semantic retrieval.\nWe propose an unsupervised deep hashing layer called Bi-half Net that maximizes\nentropy of the binary codes. Entropy is maximal when both possible values of\nthe bit are uniformly (half-half) distributed. To maximize bit entropy, we do\nnot add a term to the loss function as this is difficult to optimize and tune.\nInstead, we design a new parameter-free network layer to explicitly force\ncontinuous image features to approximate the optimal half-half bit\ndistribution. This layer is shown to minimize a penalized term of the\nWasserstein distance between the learned continuous image features and the\noptimal half-half bit distribution. Experimental results on the image datasets\nFlickr25k, Nus-wide, Cifar-10, Mscoco, Mnist and the video datasets Ucf-101 and\nHmdb-51 show that our approach leads to compact codes and compares favorably to\nthe current state-of-the-art.</p>\n", "tags": ["Image Retrieval", "AAAI", "DATASETS", "Hashing Methods", "Compact Codes", "Neural Hashing"], "tsne_embedding": [-5.687530517578125, 10.747343063354492], "cluster": 6}, {"key": "li2020hamming", "year": "2020", "citations": "5", "title": "Hamming OCR: A Locality Sensitive Hashing Neural Network For Scene Text Recognition", "abstract": "<p>Recently, inspired by Transformer, self-attention-based scene text\nrecognition approaches have achieved outstanding performance. However, we find\nthat the size of model expands rapidly with the lexicon increasing.\nSpecifically, the number of parameters for softmax classification layer and\noutput embedding layer are proportional to the vocabulary size. It hinders the\ndevelopment of a lightweight text recognition model especially applied for\nChinese and multiple languages. Thus, we propose a lightweight scene text\nrecognition model named Hamming OCR. In this model, a novel Hamming classifier,\nwhich adopts locality sensitive hashing (LSH) algorithm to encode each\ncharacter, is proposed to replace the softmax regression and the generated LSH\ncode is directly employed to replace the output embedding. We also present a\nsimplified transformer decoder to reduce the number of parameters by removing\nthe feed-forward network and using cross-layer parameter sharing technique.\nCompared with traditional methods, the number of parameters in both\nclassification and embedding layers is independent on the size of vocabulary,\nwhich significantly reduces the storage requirement without loss of accuracy.\nExperimental results on several datasets, including four public benchmaks and a\nChinese text dataset synthesized by SynthText with more than 20,000 characters,\nshows that Hamming OCR achieves competitive results.</p>\n", "tags": ["Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Tools & Libraries", "Evaluation"], "tsne_embedding": [2.704888343811035, 1.6488292217254639], "cluster": 4}, {"key": "li2020perceptual", "year": "2020", "citations": "5", "title": "Perceptual Robust Hashing For Color Images With Canonical Correlation Analysis", "abstract": "<p>In this paper, a novel perceptual image hashing scheme for color images is\nproposed based on ring-ribbon quadtree and color vector angle. First, original\nimage is subjected to normalization and Gaussian low-pass filtering to produce\na secondary image, which is divided into a series of ring-ribbons with\ndifferent radii and the same number of pixels. Then, both textural and color\nfeatures are extracted locally and globally. Quadtree decomposition (QD) is\napplied on luminance values of the ring-ribbons to extract local textural\nfeatures, and the gray level co-occurrence matrix (GLCM) is used to extract\nglobal textural features. Local color features of significant corner points on\nouter boundaries of ring-ribbons are extracted through color vector angles\n(CVA), and color low-order moments (CLMs) is utilized to extract global color\nfeatures. Finally, two types of feature vectors are fused via canonical\ncorrelation analysis (CCA) to prodcue the final hash after scrambling. Compared\nwith direct concatenation, the CCA feature fusion method improves\nclassification performance, which better reflects overall correlation between\ntwo sets of feature vectors. Receiver operating characteristic (ROC) curve\nshows that our scheme has satisfactory performances with respect to robustness,\ndiscrimination and security, which can be effectively used in copy detection\nand content authentication.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Evaluation", "Robustness"], "tsne_embedding": [-4.3412065505981445, 12.861069679260254], "cluster": 6}, {"key": "li2020task", "year": "2020", "citations": "17", "title": "Task-adaptive Asymmetric Deep Cross-modal Hashing", "abstract": "<p>Supervised cross-modal hashing aims to embed the semantic correlations of\nheterogeneous modality data into the binary hash codes with discriminative\nsemantic labels. Because of its advantages on retrieval and storage efficiency,\nit is widely used for solving efficient cross-modal retrieval. However,\nexisting researches equally handle the different tasks of cross-modal\nretrieval, and simply learn the same couple of hash functions in a symmetric\nway for them. Under such circumstance, the uniqueness of different cross-modal\nretrieval tasks are ignored and sub-optimal performance may be brought.\nMotivated by this, we present a Task-adaptive Asymmetric Deep Cross-modal\nHashing (TA-ADCMH) method in this paper. It can learn task-adaptive hash\nfunctions for two sub-retrieval tasks via simultaneous modality representation\nand asymmetric hash learning. Unlike previous cross-modal hashing approaches,\nour learning framework jointly optimizes semantic preserving that transforms\ndeep features of multimedia data into binary hash codes, and the semantic\nregression which directly regresses query modality representation to explicit\nlabel. With our model, the binary codes can effectively preserve semantic\ncorrelations across different modalities, meanwhile, adaptively capture the\nquery semantics. The superiority of TA-ADCMH is proved on two standard datasets\nfrom many aspects.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Multimodal Retrieval", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-2.8326008319854736, -4.071317672729492], "cluster": 9}, {"key": "li2020topology", "year": "2020", "citations": "5", "title": "Topology-aware Hashing For Effective Control Flow Graph Similarity Analysis", "abstract": "<p>Control Flow Graph (CFG) similarity analysis is an essential technique for a\nvariety of security analysis tasks, including malware detection and malware\nclustering. Even though various algorithms have been developed, existing CFG\nsimilarity analysis methods still suffer from limited efficiency, accuracy, and\nusability. In this paper, we propose a novel fuzzy hashing scheme called\ntopology-aware hashing (TAH) for effective and efficient CFG similarity\nanalysis. Given the CFGs constructed from program binaries, we extract blended\nn-gram graphical features of the CFGs, encode the graphical features into\nnumeric vectors (called graph signatures), and then measure the graph\nsimilarity by comparing the graph signatures. We further employ a fuzzy hashing\ntechnique to convert the numeric graph signatures into smaller fixed-size fuzzy\nhash signatures for efficient similarity calculation. Our comprehensive\nevaluation demonstrates that TAH is more effective and efficient compared to\nexisting CFG comparison techniques. To demonstrate the applicability of TAH to\nreal-world security analysis tasks, we develop a binary similarity analysis\ntool based on TAH, and show that it outperforms existing similarity analysis\ntools while conducting malware clustering.</p>\n", "tags": ["Hashing Methods", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [12.302023887634277, 10.617527961730957], "cluster": 0}, {"key": "li2021c", "year": "2021", "citations": "5", "title": "C-minhash: Practically Reducing Two Permutations To Just One", "abstract": "<p>Traditional minwise hashing (MinHash) requires applying \\(K\\) independent\npermutations to estimate the Jaccard similarity in massive binary (0/1) data,\nwhere \\(K\\) can be (e.g.,) 1024 or even larger, depending on applications. The\nrecent work on C-MinHash (Li and Li, 2021) has shown, with rigorous proofs,\nthat only two permutations are needed. An initial permutation is applied to\nbreak whatever structures which might exist in the data, and a second\npermutation is re-used \\(K\\) times to produce \\(K\\) hashes, via a circulant\nshifting fashion. (Li and Li, 2021) has proved that, perhaps surprisingly, even\nthough the \\(K\\) hashes are correlated, the estimation variance is strictly\nsmaller than the variance of the traditional MinHash.\n  It has been demonstrated in (Li and Li, 2021) that the initial permutation in\nC-MinHash is indeed necessary. For the ease of theoretical analysis, they have\nused two independent permutations. In this paper, we show that one can actually\nsimply use one permutation. That is, one single permutation is used for both\nthe initial pre-processing step to break the structures in the data and the\ncirculant hashing step to generate \\(K\\) hashes. Although the theoretical\nanalysis becomes very complicated, we are able to explicitly write down the\nexpression for the expectation of the estimator. The new estimator is no longer\nunbiased but the bias is extremely small and has essentially no impact on the\nestimation accuracy (mean square errors). An extensive set of experiments are\nprovided to verify our claim for using just one permutation.</p>\n", "tags": ["Alt", "Locality Sensitive Hashing", "Hashing Methods"], "tsne_embedding": [27.20597267150879, 7.753473281860352], "cluster": 7}, {"key": "li2021ce", "year": "2021", "citations": "5", "title": "Ce-dedup: Cost-effective Convolutional Neural Nets Training Based On Image Deduplication", "abstract": "<p>Attributed to the ever-increasing large image datasets, Convolutional Neural\nNetworks (CNNs) have become popular for vision-based tasks. It is generally\nadmirable to have larger-sized datasets for higher network training accuracies.\nHowever, the impact of dataset quality has not to be involved. It is reasonable\nto assume the near-duplicate images exist in the datasets. For instance, the\nStreet View House Numbers (SVHN) dataset having cropped house plate digits from\n0 to 9 are likely to have repetitive digits from the same/similar house plates.\nRedundant images may take up a certain portion of the dataset without\nconsciousness. While contributing little to no accuracy improvement for the\nCNNs training, these duplicated images unnecessarily pose extra resource and\ncomputation consumption. To this end, this paper proposes a framework to assess\nthe impact of the near-duplicate images on CNN training performance, called\nCE-Dedup. Specifically, CE-Dedup associates a hashing-based image deduplication\napproach with downstream CNNs-based image classification tasks. CE-Dedup\nbalances the tradeoff between a large deduplication ratio and a stable accuracy\nby adjusting the deduplication threshold. The effectiveness of CE-Dedup is\nvalidated through extensive experiments on well-known CNN benchmarks. On one\nhand, while maintaining the same validation accuracy, CE-Dedup can reduce the\ndataset size by 23%. On the other hand, when allowing a small validation\naccuracy drop (by 5%), CE-Dedup can trim the dataset size by 75%.</p>\n", "tags": ["DATASETS", "Tools & Libraries", "Hashing Methods", "Evaluation"], "tsne_embedding": [-15.605293273925781, 22.364961624145508], "cluster": 6}, {"key": "li2021extra", "year": "2021", "citations": "29", "title": "EXTRA: Explanation Ranking Datasets For Explainable Recommendation", "abstract": "<p>Recently, research on explainable recommender systems has drawn much\nattention from both academia and industry, resulting in a variety of\nexplainable models. As a consequence, their evaluation approaches vary from\nmodel to model, which makes it quite difficult to compare the explainability of\ndifferent models. To achieve a standard way of evaluating recommendation\nexplanations, we provide three benchmark datasets for EXplanaTion RAnking\n(denoted as EXTRA), on which explainability can be measured by ranking-oriented\nmetrics. Constructing such datasets, however, poses great challenges. First,\nuser-item-explanation triplet interactions are rare in existing recommender\nsystems, so how to find alternatives becomes a challenge. Our solution is to\nidentify nearly identical sentences from user reviews. This idea then leads to\nthe second challenge, i.e., how to efficiently categorize the sentences in a\ndataset into different groups, since it has quadratic runtime complexity to\nestimate the similarity between any two sentences. To mitigate this issue, we\nprovide a more efficient method based on Locality Sensitive Hashing (LSH) that\ncan detect near-duplicates in sub-linear time for a given query. Moreover, we\nmake our code publicly available to allow researchers in the community to\ncreate their own datasets.</p>\n", "tags": ["Survey Paper", "Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Alt", "Recommender Systems", "SIGIR", "Evaluation"], "tsne_embedding": [-18.819326400756836, -10.418038368225098], "cluster": 1}, {"key": "li2021more", "year": "2021", "citations": "23", "title": "More Robust Dense Retrieval With Contrastive Dual Learning", "abstract": "<p>Dense retrieval conducts text retrieval in the embedding space and has shown\nmany advantages compared to sparse retrieval. Existing dense retrievers\noptimize representations of queries and documents with contrastive training and\nmap them to the embedding space. The embedding space is optimized by aligning\nthe matched query-document pairs and pushing the negative documents away from\nthe query. However, in such training paradigm, the queries are only optimized\nto align to the documents and are coarsely positioned, leading to an\nanisotropic query embedding space. In this paper, we analyze the embedding\nspace distributions and propose an effective training paradigm, Contrastive\nDual Learning for Approximate Nearest Neighbor (DANCE) to learn fine-grained\nquery representations for dense retrieval. DANCE incorporates an additional\ndual training object of query retrieval, inspired by the classic information\nretrieval training axiom, query likelihood. With contrastive learning, the dual\ntraining object of DANCE learns more tailored representations for queries and\ndocuments to keep the embedding space smooth and uniform, thriving on the\nranking performance of DANCE on the MS MARCO document retrieval task. Different\nfrom ANCE that only optimized with the document retrieval task, DANCE\nconcentrates the query embeddings closer to document representations while\nmaking the document distribution more discriminative. Such concentrated query\nembedding distribution assigns more uniform negative sampling probabilities to\nqueries and helps to sufficiently optimize query representations in the query\nretrieval task. Our codes are released at https://github.com/thunlp/DANCE.</p>\n", "tags": ["Text Retrieval", "SIGIR", "Evaluation"], "tsne_embedding": [-16.81800651550293, -9.914108276367188], "cluster": 1}, {"key": "li2022adaptive", "year": "2022", "citations": "22", "title": "Adaptive Structural Similarity Preserving For Unsupervised Cross Modal Hashing", "abstract": "<p>Cross-modal hashing is an important approach for multimodal data management\nand application. Existing unsupervised cross-modal hashing algorithms mainly\nrely on data features in pre-trained models to mine their similarity\nrelationships. However, their optimization objectives are based on the static\nmetric between the original uni-modal features, without further exploring data\ncorrelations during the training. In addition, most of them mainly focus on\nassociation mining and alignment among pairwise instances in continuous space\nbut ignore the latent structural correlations contained in the semantic hashing\nspace. In this paper, we propose an unsupervised hash learning framework,\nnamely Adaptive Structural Similarity Preservation Hashing (ASSPH), to solve\nthe above problems. Firstly, we propose an adaptive learning scheme, with\nlimited data and training batches, to enrich semantic correlations of unlabeled\ninstances during the training process and meanwhile to ensure a smooth\nconvergence of the training process. Secondly, we present an asymmetric\nstructural semantic representation learning scheme. We introduce structural\nsemantic metrics based on graph adjacency relations during the semantic\nreconstruction and correlation mining stage and meanwhile align the structure\nsemantics in the hash space with an asymmetric binary optimization process.\nFinally, we conduct extensive experiments to validate the enhancements of our\nwork in comparison with existing works.</p>\n", "tags": ["Text Retrieval", "Tools & Libraries", "Hashing Methods", "Evaluation"], "tsne_embedding": [-8.065703392028809, -7.3673014640808105], "cluster": 9}, {"key": "li2022asymmetric", "year": "2022", "citations": "113", "title": "Asymmetric Scalable Cross-modal Hashing", "abstract": "<p>Cross-modal hashing is a successful method to solve large-scale multimedia\nretrieval issue. A lot of matrix factorization-based hashing methods are\nproposed. However, the existing methods still struggle with a few problems,\nsuch as how to generate the binary codes efficiently rather than directly relax\nthem to continuity. In addition, most of the existing methods choose to use an\n\\(n\\times n\\) similarity matrix for optimization, which makes the memory and\ncomputation unaffordable. In this paper we propose a novel Asymmetric Scalable\nCross-Modal Hashing (ASCMH) to address these issues. It firstly introduces a\ncollective matrix factorization to learn a common latent space from the\nkernelized features of different modalities, and then transforms the similarity\nmatrix optimization to a distance-distance difference problem minimization with\nthe help of semantic labels and common latent space. Hence, the computational\ncomplexity of the \\(n\\times n\\) asymmetric optimization is relieved. In the\ngeneration of hash codes we also employ an orthogonal constraint of label\ninformation, which is indispensable for search accuracy. So the redundancy of\ncomputation can be much reduced. For efficient optimization and scalable to\nlarge-scale datasets, we adopt the two-step approach rather than optimizing\nsimultaneously. Extensive experiments on three benchmark datasets: Wiki,\nMIRFlickr-25K, and NUS-WIDE, demonstrate that our ASCMH outperforms the\nstate-of-the-art cross-modal hashing methods in terms of accuracy and\nefficiency.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Evaluation"], "tsne_embedding": [-4.14192008972168, -4.718554973602295], "cluster": 9}, {"key": "li2023constructing", "year": "2023", "citations": "8", "title": "Constructing Tree-based Index For Efficient And Effective Dense Retrieval", "abstract": "<p>Recent studies have shown that Dense Retrieval (DR) techniques can\nsignificantly improve the performance of first-stage retrieval in IR systems.\nDespite its empirical effectiveness, the application of DR is still limited. In\ncontrast to statistic retrieval models that rely on highly efficient inverted\nindex solutions, DR models build dense embeddings that are difficult to be\npre-processed with most existing search indexing systems. To avoid the\nexpensive cost of brute-force search, the Approximate Nearest Neighbor (ANN)\nalgorithm and corresponding indexes are widely applied to speed up the\ninference process of DR models. Unfortunately, while ANN can improve the\nefficiency of DR models, it usually comes with a significant price on retrieval\nperformance.\n  To solve this issue, we propose JTR, which stands for Joint optimization of\nTRee-based index and query encoding. Specifically, we design a new unified\ncontrastive learning loss to train tree-based index and query encoder in an\nend-to-end manner. The tree-based negative sampling strategy is applied to make\nthe tree have the maximum heap property, which supports the effectiveness of\nbeam search well. Moreover, we treat the cluster assignment as an optimization\nproblem to update the tree-based index that allows overlapped clustering. We\nevaluate JTR on numerous popular retrieval benchmarks. Experimental results\nshow that JTR achieves better retrieval performance while retaining high system\nefficiency compared with widely-adopted baselines. It provides a potential\nsolution to balance efficiency and effectiveness in neural retrieval system\ndesigns.</p>\n", "tags": ["Tree Based ANN", "SIGIR", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [-16.61064910888672, -13.442873001098633], "cluster": 1}, {"key": "li2023differentially", "year": "2023", "citations": "36", "title": "Differentially Private One Permutation Hashing And Bin-wise Consistent Weighted Sampling", "abstract": "<p>Minwise hashing (MinHash) is a standard algorithm widely used in the\nindustry, for large-scale search and learning applications with the binary\n(0/1) Jaccard similarity. One common use of MinHash is for processing massive\nn-gram text representations so that practitioners do not have to materialize\nthe original data (which would be prohibitive). Another popular use of MinHash\nis for building hash tables to enable sub-linear time approximate near neighbor\n(ANN) search. MinHash has also been used as a tool for building large-scale\nmachine learning systems. The standard implementation of MinHash requires\napplying \\(K\\) random permutations. In comparison, the method of one permutation\nhashing (OPH), is an efficient alternative of MinHash which splits the data\nvectors into \\(K\\) bins and generates hash values within each bin. OPH is\nsubstantially more efficient and also more convenient to use.\n  In this paper, we combine the differential privacy (DP) with OPH (as well as\nMinHash), to propose the DP-OPH framework with three variants: DP-OPH-fix,\nDP-OPH-re and DP-OPH-rand, depending on which densification strategy is adopted\nto deal with empty bins in OPH. A detailed roadmap to the algorithm design is\npresented along with the privacy analysis. An analytical comparison of our\nproposed DP-OPH methods with the DP minwise hashing (DP-MH) is provided to\njustify the advantage of DP-OPH. Experiments on similarity search confirm the\nmerits of DP-OPH, and guide the choice of the proper variant in different\npractical scenarios. Our technique is also extended to bin-wise consistent\nweighted sampling (BCWS) to develop a new DP algorithm called DP-BCWS for\nnon-binary data. Experiments on classification tasks demonstrate that DP-BCWS\nis able to achieve excellent utility at around \\(\\epsilon = 5\\sim 10\\), where\n\\(\\epsilon\\) is the standard parameter in the language of \\((\\epsilon,\n\\delta)\\)-DP.</p>\n", "tags": ["KDD", "Locality Sensitive Hashing", "Hashing Methods", "Large Scale Search", "Alt", "Similarity Search", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-3.394023895263672, -23.51448631286621], "cluster": 5}, {"key": "li2023dual", "year": "2023", "citations": "16", "title": "Dual-stream Knowledge-preserving Hashing For Unsupervised Video Retrieval", "abstract": "<p>Unsupervised video hashing usually optimizes binary codes by learning to\nreconstruct input videos. Such reconstruction constraint spends much effort on\nframe-level temporal context changes without focusing on video-level global\nsemantics that are more useful for retrieval. Hence, we address this problem by\ndecomposing video information into reconstruction-dependent and\nsemantic-dependent information, which disentangles the semantic extraction from\nreconstruction constraint. Specifically, we first design a simple dual-stream\nstructure, including a temporal layer and a hash layer. Then, with the help of\nsemantic similarity knowledge obtained from self-supervision, the hash layer\nlearns to capture information for semantic retrieval, while the temporal layer\nlearns to capture the information for reconstruction. In this way, the model\nnaturally preserves the disentangled semantics into binary codes. Validated by\ncomprehensive experiments, our method consistently outperforms the\nstate-of-the-arts on three video benchmarks.</p>\n", "tags": ["Compact Codes", "Hashing Methods", "Evaluation"], "tsne_embedding": [-7.180366516113281, 17.190025329589844], "cluster": 6}, {"key": "li2023slim", "year": "2023", "citations": "7", "title": "SLIM: Sparsified Late Interaction For Multi-vector Retrieval With Inverted Indexes", "abstract": "<p>This paper introduces Sparsified Late Interaction for Multi-vector (SLIM)\nretrieval with inverted indexes. Multi-vector retrieval methods have\ndemonstrated their effectiveness on various retrieval datasets, and among them,\nColBERT is the most established method based on the late interaction of\ncontextualized token embeddings of pre-trained language models. However,\nefficient ColBERT implementations require complex engineering and cannot take\nadvantage of off-the-shelf search libraries, impeding their practical use. To\naddress this issue, SLIM first maps each contextualized token vector to a\nsparse, high-dimensional lexical space before performing late interaction\nbetween these sparse token embeddings. We then introduce an efficient two-stage\nretrieval architecture that includes inverted index retrieval followed by a\nscore refinement module to approximate the sparsified late interaction, which\nis fully compatible with off-the-shelf lexical search libraries such as Lucene.\nSLIM achieves competitive accuracy on MS MARCO Passages and BEIR compared to\nColBERT while being much smaller and faster on CPUs. To our knowledge, we are\nthe first to explore using sparse token representations for multi-vector\nretrieval. Source code and data are integrated into the Pyserini IR toolkit.</p>\n", "tags": ["SIGIR", "Evaluation", "DATASETS"], "tsne_embedding": [3.167250394821167, -1.114499568939209], "cluster": 4}, {"key": "li2024mixed", "year": "2024", "citations": "89", "title": "Mixed-precision Embeddings For Large-scale Recommendation Models", "abstract": "<p>Embedding techniques have become essential components of large databases in\nthe deep learning era. By encoding discrete entities, such as words, items, or\ngraph nodes, into continuous vector spaces, embeddings facilitate more\nefficient storage, retrieval, and processing in large databases. Especially in\nthe domain of recommender systems, millions of categorical features are encoded\nas unique embedding vectors, which facilitates the modeling of similarities and\ninteractions among features. However, numerous embedding vectors can result in\nsignificant storage overhead. In this paper, we aim to compress the embedding\ntable through quantization techniques. Given that features vary in importance\nlevels, we seek to identify an appropriate precision for each feature to\nbalance model accuracy and memory usage. To this end, we propose a novel\nembedding compression method, termed Mixed-Precision Embeddings (MPE).\nSpecifically, to reduce the size of the search space, we first group features\nby frequency and then search precision for each feature group. MPE further\nlearns the probability distribution over precision levels for each feature\ngroup, which can be used to identify the most suitable precision with a\nspecially designed sampling strategy. Extensive experiments on three public\ndatasets demonstrate that MPE significantly outperforms existing embedding\ncompression methods. Remarkably, MPE achieves about 200x compression on the\nCriteo dataset without comprising the prediction accuracy.</p>\n", "tags": ["DATASETS", "Evaluation", "Quantization", "Recommender Systems", "RecSys", "Compact Codes"], "tsne_embedding": [6.1489033699035645, -0.41889095306396484], "cluster": 4}, {"key": "li20250", "year": "2025", "citations": "58", "title": "0-bit Consistent Weighted Sampling", "abstract": "<p>We develop 0-bit consistent weighted sampling (CWS) for efficiently estimating min-max kernel, which is a generalization of the resemblance kernel originally designed for binary data. Because the estimator of 0-bit CWS constitutes a positive definite kernel, this method can be naturally applied to large-scale data mining problems. Basically, if we feed the sampled data from 0-bit CWS to a highly efficient linear classifier (e.g., linear SVM), we effectively (and approximately) train a nonlinear classifier based on the min-max kernel. The accuracy improves as we increase the sample size.</p>\n\n<p>In this paper, we first demonstrate, through an extensive classification study using kernel machines, that the min-max kernel often provides an effective measure of similarity for nonnegative data. This helps justify the use of min-max kernel. However, as the min-max kernel is nonlinear and might be difficult to be used for industrial applications with massive data, we propose to linearize the min-max kernel via 0-bit CWS, a simplification of the original CWS method.</p>\n\n<p>The previous remarkable work on consistent weighted sampling (CWS) produces samples in the form of (i<em>, t</em>) where the i* records the location (and in fact also the weights) information analogous to the samples produced by classical minwise hashing on binary data. Because the t* is theoretically unbounded, it was not immediately clear how to effectively implement CWS for building large-scale linear classifiers. We provide a simple solution by discarding t* (which we refer to as the \u201c0-bit\u201d scheme). Via an extensive empirical study, we show that this 0-bit scheme does not lose essential information. We then apply 0-bit CWS for building linear classifiers to approximate min-max kernel classifiers, as extensively validated on a wide range of public datasets.</p>\n\n<p>We expect this work will generate interests among data mining practitioners who would like to efficiently utilize the nonlinear information of non-binary and nonnegative data.</p>\n", "tags": ["KDD", "DATASETS", "Hashing Methods"], "tsne_embedding": [29.111906051635742, 5.450916767120361], "cluster": 7}, {"key": "li2025clean", "year": "2025", "citations": "61", "title": "Clean Image May Be Dangerous: Data Poisoning Attacks Against Deep Hashing", "abstract": "<p>Large-scale image retrieval using deep hashing has become increasingly\npopular due to the exponential growth of image data and the remarkable feature\nextraction capabilities of deep neural networks (DNNs). However, deep hashing\nmethods are vulnerable to malicious attacks, including adversarial and backdoor\nattacks. It is worth noting that these attacks typically involve altering the\nquery images, which is not a practical concern in real-world scenarios. In this\npaper, we point out that even clean query images can be dangerous, inducing\nmalicious target retrieval results, like undesired or illegal images. To the\nbest of our knowledge, we are the first to study data \\textbf{p}oisoning\n\\textbf{a}ttacks against \\textbf{d}eep \\textbf{hash}ing\n\\textbf{(\\textit{PADHASH})}. Specifically, we first train a surrogate model to\nsimulate the behavior of the target deep hashing model. Then, a strict gradient\nmatching strategy is proposed to generate the poisoned images. Extensive\nexperiments on different models, datasets, hash methods, and hash code lengths\ndemonstrate the effectiveness and generality of our attack method.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Alt", "Neural Hashing", "Robustness"], "tsne_embedding": [-15.950409889221191, 14.347101211547852], "cluster": 3}, {"key": "li2025feature", "year": "2025", "citations": "509", "title": "Feature Learning Based Deep Supervised Hashing With Pairwise Labels", "abstract": "<p>Recent years have witnessed wide application of\nhashing for large-scale image retrieval. However,\nmost existing hashing methods are based on handcrafted features which might not be optimally compatible with the hashing procedure. Recently, deep\nhashing methods have been proposed to perform simultaneous feature learning and hash-code learning with deep neural networks, which have shown\nbetter performance than traditional hashing methods with hand-crafted features. Most of these deep\nhashing methods are supervised whose supervised\ninformation is given with triplet labels. For another common application scenario with pairwise labels, there have not existed methods for simultaneous feature learning and hash-code learning. In this\npaper, we propose a novel deep hashing method,\ncalled deep pairwise-supervised hashing (DPSH),\nto perform simultaneous feature learning and hashcode learning for applications with pairwise labels.\nExperiments on real datasets show that our DPSH\nmethod can outperform other methods to achieve\nthe state-of-the-art performance in image retrieval\napplications.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Neural Hashing", "Evaluation"], "tsne_embedding": [-7.720005035400391, 5.451807022094727], "cluster": 8}, {"key": "li2025learning", "year": "2025", "citations": "93", "title": "Learning Hash Functions Using Column Generation", "abstract": "<p>Fast nearest neighbor searching is becoming\nan increasingly important tool in solving\nmany large-scale problems. Recently\na number of approaches to learning datadependent\nhash functions have been developed.\nIn this work, we propose a column\ngeneration based method for learning datadependent\nhash functions on the basis of\nproximity comparison information. Given a\nset of triplets that encode the pairwise proximity\ncomparison information, our method\nlearns hash functions that preserve the relative\ncomparison relationships in the data\nas well as possible within the large-margin\nlearning framework. The learning procedure\nis implemented using column generation and\nhence is named CGHash. At each iteration\nof the column generation procedure, the best\nhash function is selected. Unlike most other\nhashing methods, our method generalizes to\nnew data points naturally; and has a training\nobjective which is convex, thus ensuring\nthat the global optimum can be identi-\nfied. Experiments demonstrate that the proposed\nmethod learns compact binary codes\nand that its retrieval performance compares\nfavorably with state-of-the-art methods when\ntested on a few benchmark datasets.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Compact Codes", "Tools & Libraries", "Evaluation"], "tsne_embedding": [0.3449925482273102, -12.321236610412598], "cluster": 9}, {"key": "li2025neighborhood", "year": "2025", "citations": "40", "title": "Neighborhood Preserving Hashing For Scalable Video Retrieval", "abstract": "<p>In this paper, we propose a Neighborhood Preserving\nHashing (NPH) method for scalable video retrieval in an\nunsupervised manner. Unlike most existing deep video\nhashing methods which indiscriminately compress an entire video into a binary code, we embed the spatial-temporal\nneighborhood information into the encoding network such\nthat the neighborhood-relevant visual content of a video can\nbe preferentially encoded into a binary code under the guidance of the neighborhood information. Specifically, we propose a neighborhood attention mechanism which focuses\non partial useful content of each input frame conditioned\non the neighborhood information. We then integrate the\nneighborhood attention mechanism into an RNN-based reconstruction scheme to encourage the binary codes to capture the spatial-temporal structure in a video which is consistent with that in the neighborhood. As a consequence, the\nlearned hashing functions can map similar videos to similar\nbinary codes. Extensive experiments on three widely-used\nbenchmark datasets validate the effectiveness of our proposed approach.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Compact Codes", "ICCV", "Evaluation"], "tsne_embedding": [-7.491940975189209, 18.285863876342773], "cluster": 6}, {"key": "li2025self", "year": "2025", "citations": "38", "title": "Self-supervised Video Hashing Via Bidirectional Transformers", "abstract": "<p>Most existing unsupervised video hashing methods are built on unidirectional models with less reliable training objectives, which underuse the correlations among frames and the similarity structure between videos. To enable efficient scalable video retrieval, we propose a self-supervised video Hashing method based on Bidirectional Transformers (BTH). Based on the encoder-decoder structure of transformers, we design a visual cloze task to fully exploit the bidirectional correlations between frames. To unveil the similarity structure between unlabeled video data, we further develop a similarity reconstruction task by establishing reliable and effective similarity connections in the video space. Furthermore, we develop a cluster assignment task to exploit the structural statistics of the whole dataset such that more discriminative binary codes can be learned. Extensive experiments implemented on three public benchmark datasets, FCVID, ActivityNet and YFCC, demonstrate the superiority of our proposed approach.</p>\n", "tags": ["DATASETS", "Hashing Methods", "CVPR", "Compact Codes", "Evaluation"], "tsne_embedding": [-8.273809432983398, 18.077526092529297], "cluster": 6}, {"key": "li2025two", "year": "2025", "citations": "31", "title": "Two Birds, One Stone: Jointly Learning Binary Code For Large-scale Face Image Retrieval And Attributes Prediction", "abstract": "<p>We address the challenging large-scale content-based\nface image retrieval problem, intended as searching images\nbased on the presence of specific subject, given one face\nimage of him/her. To this end, one natural demand is a supervised binary code learning method. While the learned\ncodes might be discriminating, people often have a further\nexpectation that whether some semantic message (e.g., visual attributes) can be read from the human-incomprehensible\ncodes. For this purpose, we propose a novel binary code\nlearning framework by jointly encoding identity discriminability and a number of facial attributes into unified binary code. In this way, the learned binary codes can be applied to not only fine-grained face image retrieval, but also\nfacial attributes prediction, which is the very innovation of\nthis work, just like killing two birds with one stone. To evaluate the effectiveness of the proposed method, extensive experiments are conducted on a new purified large-scale web\ncelebrity database, named CFW 60K, with abundant manual identity and attributes annotation, and experimental results exhibit the superiority of our method over state-of-the-art.</p>\n", "tags": ["ICCV", "Compact Codes", "Image Retrieval", "Tools & Libraries"], "tsne_embedding": [-12.90367603302002, 4.136117935180664], "cluster": 8}, {"key": "li2025very", "year": "2025", "citations": "632", "title": "Very Sparse Random Projections", "abstract": "<p>There has been considerable interest in random projections, an approximate algorithm for estimating distances between pairs of points in a high-dimensional vector space. Let A in Rn x D be our n points in D dimensions. The method multiplies A by a random matrix R in RD x k, reducing the D dimensions down to just k for speeding up the computation. R typically consists of entries of standard normal N(0,1). It is well known that random projections preserve pairwise distances (in the expectation). Achlioptas proposed sparse random projections by replacing the N(0,1) entries in R with entries in -1,0,1 with probabilities 1/6, 2/3, 1/6, achieving a threefold speedup in processing time.We recommend using R of entries in -1,0,1 with probabilities 1/2\u221aD, 1-1\u221aD, 1/2\u221aD for achieving a significant \u221aD-fold speedup, with little loss in accuracy.</p>\n", "tags": ["KDD", "Locality Sensitive Hashing", "Efficiency And Optimization"], "tsne_embedding": [22.542991638183594, -7.136936664581299], "cluster": 7}, {"key": "liang2020dynamic", "year": "2020", "citations": "5", "title": "Dynamic Sampling For Deep Metric Learning", "abstract": "<p>Deep metric learning maps visually similar images onto nearby locations and\nvisually dissimilar images apart from each other in an embedding manifold. The\nlearning process is mainly based on the supplied image negative and positive\ntraining pairs. In this paper, a dynamic sampling strategy is proposed to\norganize the training pairs in an easy-to-hard order to feed into the network.\nIt allows the network to learn general boundaries between categories from the\neasy training pairs at its early stages and finalize the details of the model\nmainly relying on the hard training samples in the later. Compared to the\nexisting training sample mining approaches, the hard samples are mined with\nlittle harm to the learned general model. This dynamic sampling strategy is\nformularized as two simple terms that are compatible with various loss\nfunctions. Consistent performance boost is observed when it is integrated with\nseveral popular loss functions on fashion search, fine-grained classification,\nand person re-identification tasks.</p>\n", "tags": ["Evaluation", "Distance Metric Learning"], "tsne_embedding": [-20.66822052001953, 4.09412145614624], "cluster": 3}, {"key": "liberman2019search", "year": "2019", "citations": "7", "title": "Search-based Serving Architecture Of Embeddings-based Recommendations", "abstract": "<p>Over the past 10 years, many recommendation techniques have been based on\nembedding users and items in latent vector spaces, where the inner product of a\n(user,item) pair of vectors represents the predicted affinity of the user to\nthe item. A wealth of literature has focused on the various modeling approaches\nthat result in embeddings, and has compared their quality metrics, learning\ncomplexity, etc. However, much less attention has been devoted to the issues\nsurrounding productization of an embeddings-based high throughput, low latency\nrecommender system. In particular, how the system might keep up with the\nchanging embeddings as new models are learnt. This paper describes a reference\narchitecture of a high-throughput, large scale recommendation service which\nleverages a search engine as its runtime core. We describe how the search index\nand the query builder adapt to changes in the embeddings, which often happen at\na different cadence than index builds. We provide solutions for both id-based\nand feature-based embeddings, as well as for batch indexing and incremental\nindexing setups. The described system is at the core of a Web content discovery\nservice that serves tens of billions recommendations per day in response to\nbillions of user requests.</p>\n", "tags": ["ICCV", "Recommender Systems", "Alt", "Efficiency And Optimization"], "tsne_embedding": [4.522643089294434, -4.544942378997803], "cluster": 4}, {"key": "lillis2017hierarchical", "year": "2017", "citations": "5", "title": "Hierarchical Bloom Filter Trees For Approximate Matching", "abstract": "<p>Bytewise approximate matching algorithms have in recent years shown\nsignificant promise in de- tecting files that are similar at the byte level.\nThis is very useful for digital forensic investigators, who are regularly faced\nwith the problem of searching through a seized device for pertinent data. A\ncommon scenario is where an investigator is in possession of a collection of\n\u201cknown-illegal\u201d files (e.g. a collection of child abuse material) and wishes to\nfind whether copies of these are stored on the seized device. Approximate\nmatching addresses shortcomings in traditional hashing, which can only find\nidentical files, by also being able to deal with cases of merged files,\nembedded files, partial files, or if a file has been changed in any way.\n  Most approximate matching algorithms work by comparing pairs of files, which\nis not a scalable approach when faced with large corpora. This paper\ndemonstrates the effectiveness of using a \u201cHierarchical Bloom Filter Tree\u201d\n(HBFT) data structure to reduce the running time of\ncollection-against-collection matching, with a specific focus on the MRSH-v2\nalgorithm. Three experiments are discussed, which explore the effects of\ndifferent configurations of HBFTs. The proposed approach dramatically reduces\nthe number of pairwise comparisons required, and demonstrates substantial speed\ngains, while maintaining effectiveness.</p>\n", "tags": ["Hashing Methods", "Evaluation"], "tsne_embedding": [1.0373419523239136, -6.348180770874023], "cluster": 9}, {"key": "limasset2017fast", "year": "2017", "citations": "38", "title": "Fast And Scalable Minimal Perfect Hashing For Massive Key Sets", "abstract": "<p>Minimal perfect hash functions provide space-efficient and collision-free\nhashing on static sets. Existing algorithms and implementations that build such\nfunctions have practical limitations on the number of input elements they can\nprocess, due to high construction time, RAM or external memory usage. We\nrevisit a simple algorithm and show that it is highly competitive with the\nstate of the art, especially in terms of construction time and memory usage. We\nprovide a parallel C++ implementation called BBhash. It is capable of creating\na minimal perfect hash function of \\(10^{10}\\) elements in less than 7 minutes\nusing 8 threads and 5 GB of memory, and the resulting function uses 3.7\nbits/element. To the best of our knowledge, this is also the first\nimplementation that has been successfully tested on an input of cardinality\n\\(10^{12}\\). Source code: https://github.com/rizkg/BBHash</p>\n", "tags": ["Hashing Methods"], "tsne_embedding": [-8.925278663635254, -24.83140754699707], "cluster": 5}, {"key": "lin2016structured", "year": "2016", "citations": "11", "title": "Structured Learning Of Binary Codes With Column Generation", "abstract": "<p>Hashing methods aim to learn a set of hash functions which map the original\nfeatures to compact binary codes with similarity preserving in the Hamming\nspace. Hashing has proven a valuable tool for large-scale information\nretrieval. We propose a column generation based binary code learning framework\nfor data-dependent hash function learning. Given a set of triplets that encode\nthe pairwise similarity comparison information, our column generation based\nmethod learns hash functions that preserve the relative comparison relations\nwithin the large-margin learning framework. Our method iteratively learns the\nbest hash functions during the column generation procedure. Existing hashing\nmethods optimize over simple objectives such as the reconstruction error or\ngraph Laplacian related loss functions, instead of the performance evaluation\ncriteria of interest\u2014multivariate performance measures such as the AUC and\nNDCG. Our column generation based method can be further generalized from the\ntriplet loss to a general structured learning based framework that allows one\nto directly optimize multivariate performance measures. For optimizing general\nranking measures, the resulting optimization problem can involve exponentially\nor infinitely many variables and constraints, which is more challenging than\nstandard structured output learning. We use a combination of column generation\nand cutting-plane techniques to solve the optimization problem. To speed-up the\ntraining we further explore stage-wise training and propose to use a simplified\nNDCG loss for efficient inference. We demonstrate the generality of our method\nby applying it to ranking prediction and image retrieval, and show that it\noutperforms a few state-of-the-art hashing methods.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Distance Metric Learning", "Compact Codes", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-8.525447845458984, -7.727854251861572], "cluster": 9}, {"key": "lin2018local", "year": "2018", "citations": "78", "title": "Local Binary Pattern Networks", "abstract": "<p>Memory and computation efficient deep learning architec- tures are crucial to\ncontinued proliferation of machine learning capabili- ties to new platforms and\nsystems. Binarization of operations in convo- lutional neural networks has\nshown promising results in reducing model size and computing efficiency. In\nthis paper, we tackle the problem us- ing a strategy different from the\nexisting literature by proposing local binary pattern networks or LBPNet, that\nis able to learn and perform binary operations in an end-to-end fashion.\nLBPNet1 uses local binary comparisons and random projection in place of\nconventional convolu- tion (or approximation of convolution) operations. These\noperations can be implemented efficiently on different platforms including\ndirect hard- ware implementation. We applied LBPNet and its variants on\nstandard benchmarks. The results are promising across benchmarks while provid-\ning an important means to improve memory and speed efficiency that is\nparticularly suited for small footprint devices and hardware accelerators.</p>\n", "tags": ["Locality Sensitive Hashing", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [-5.802151679992676, -14.378276824951172], "cluster": 9}, {"key": "lin2018towards", "year": "2018", "citations": "21", "title": "Towards A Theoretical Understanding Of Hashing-based Neural Nets", "abstract": "<p>Parameter reduction has been an important topic in deep learning due to the\never-increasing size of deep neural network models and the need to train and\nrun them on resource limited machines. Despite many efforts in this area, there\nwere no rigorous theoretical guarantees on why existing neural net compression\nmethods should work. In this paper, we provide provable guarantees on some\nhashing-based parameter reduction methods in neural nets. First, we introduce a\nneural net compression scheme based on random linear sketching (which is\nusually implemented efficiently via hashing), and show that the sketched\n(smaller) network is able to approximate the original network on all input data\ncoming from any smooth and well-conditioned low-dimensional manifold. The\nsketched network can also be trained directly via back-propagation. Next, we\nstudy the previously proposed HashedNets architecture and show that the\noptimization landscape of one-hidden-layer HashedNets has a local strong\nconvexity property similar to a normal fully connected neural network. We\ncomplement our theoretical results with empirical verifications.</p>\n", "tags": ["Hashing Methods"], "tsne_embedding": [-3.3203587532043457, -15.101591110229492], "cluster": 9}, {"key": "lin2019hadamard", "year": "2019", "citations": "41", "title": "Hadamard Matrix Guided Online Hashing", "abstract": "<p>Online image hashing has attracted increasing research attention recently,\nwhich receives large-scale data in a streaming manner to update the hash\nfunctions on-the-fly. Its key challenge lies in the difficulty of balancing the\nlearning timeliness and model accuracy. To this end, most works follow a\nsupervised setting, i.e., using class labels to boost the hashing performance,\nwhich defects in two aspects: First, strong constraints, e.g., orthogonal or\nsimilarity preserving, are used, which however are typically relaxed and lead\nto large accuracy drop. Second, large amounts of training batches are required\nto learn the up-to-date hash functions, which largely increase the learning\ncomplexity. To handle the above challenges, a novel supervised online hashing\nscheme termed Hadamard Matrix Guided Online Hashing (HMOH) is proposed in this\npaper. Our key innovation lies in introducing Hadamard matrix, which is an\northogonal binary matrix built via Sylvester method. In particular, to release\nthe need of strong constraints, we regard each column of Hadamard matrix as the\ntarget code for each class label, which by nature satisfies several desired\nproperties of hashing codes. To accelerate the online training, LSH is first\nadopted to align the lengths of target code and to-be-learned binary code. We\nthen treat the learning of hash functions as a set of binary classification\nproblems to fit the assigned target code. Finally, extensive experiments\ndemonstrate the superior accuracy and efficiency of the proposed method over\nvarious state-of-the-art methods. Codes are available at\nhttps://github.com/lmbxmu/mycode.</p>\n", "tags": ["Image Retrieval", "Locality Sensitive Hashing", "Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Evaluation"], "tsne_embedding": [-11.877199172973633, -10.278263092041016], "cluster": 1}, {"key": "lin2019supervised", "year": "2019", "citations": "47", "title": "Supervised Online Hashing Via Similarity Distribution Learning", "abstract": "<p>Online hashing has attracted extensive research attention when facing\nstreaming data. Most online hashing methods, learning binary codes based on\npairwise similarities of training instances, fail to capture the semantic\nrelationship, and suffer from a poor generalization in large-scale applications\ndue to large variations. In this paper, we propose to model the similarity\ndistributions between the input data and the hashing codes, upon which a novel\nsupervised online hashing method, dubbed as Similarity Distribution based\nOnline Hashing (SDOH), is proposed, to keep the intrinsic semantic relationship\nin the produced Hamming space. Specifically, we first transform the discrete\nsimilarity matrix into a probability matrix via a Gaussian-based normalization\nto address the extremely imbalanced distribution issue. And then, we introduce\na scaling Student t-distribution to solve the challenging initialization\nproblem, and efficiently bridge the gap between the known and unknown\ndistributions. Lastly, we align the two distributions via minimizing the\nKullback-Leibler divergence (KL-diverence) with stochastic gradient descent\n(SGD), by which an intuitive similarity constraint is imposed to update hashing\nmodel on the new streaming data with a powerful generalizing ability to the\npast data. Extensive experiments on three widely-used benchmarks validate the\nsuperiority of the proposed SDOH over the state-of-the-art methods in the\nonline retrieval task.</p>\n", "tags": ["Compact Codes", "Hashing Methods", "Evaluation"], "tsne_embedding": [-0.9173100590705872, 2.908383846282959], "cluster": 8}, {"key": "lin2019towards", "year": "2019", "citations": "50", "title": "Towards Optimal Discrete Online Hashing With Balanced Similarity", "abstract": "<p>When facing large-scale image datasets, online hashing serves as a promising\nsolution for online retrieval and prediction tasks. It encodes the online\nstreaming data into compact binary codes, and simultaneously updates the hash\nfunctions to renew codes of the existing dataset. To this end, the existing\nmethods update hash functions solely based on the new data batch, without\ninvestigating the correlation between such new data and the existing dataset.\nIn addition, existing works update the hash functions using a relaxation\nprocess in its corresponding approximated continuous space. And it remains as\nan open problem to directly apply discrete optimizations in online hashing. In\nthis paper, we propose a novel supervised online hashing method, termed\nBalanced Similarity for Online Discrete Hashing (BSODH), to solve the above\nproblems in a unified framework. BSODH employs a well-designed hashing\nalgorithm to preserve the similarity between the streaming data and the\nexisting dataset via an asymmetric graph regularization. We further identify\nthe \u201cdata-imbalance\u201d problem brought by the constructed asymmetric graph, which\nrestricts the application of discrete optimization in our problem. Therefore, a\nnovel balanced similarity is further proposed, which uses two equilibrium\nfactors to balance the similar and dissimilar weights and eventually enables\nthe usage of discrete optimizations. Extensive experiments conducted on three\nwidely-used benchmarks demonstrate the advantages of the proposed method over\nthe state-of-the-art methods.</p>\n", "tags": ["AAAI", "DATASETS", "Hashing Methods", "Compact Codes", "Tools & Libraries", "Evaluation"], "tsne_embedding": [6.87910795211792, -1.6349475383758545], "cluster": 4}, {"key": "lin2020fast", "year": "2020", "citations": "22", "title": "Fast Class-wise Updating For Online Hashing", "abstract": "<p>Online image hashing has received increasing research attention recently,\nwhich processes large-scale data in a streaming fashion to update the hash\nfunctions on-the-fly. To this end, most existing works exploit this problem\nunder a supervised setting, i.e., using class labels to boost the hashing\nperformance, which suffers from the defects in both adaptivity and efficiency:\nFirst, large amounts of training batches are required to learn up-to-date hash\nfunctions, which leads to poor online adaptivity. Second, the training is\ntime-consuming, which contradicts with the core need of online learning. In\nthis paper, a novel supervised online hashing scheme, termed Fast Class-wise\nUpdating for Online Hashing (FCOH), is proposed to address the above two\nchallenges by introducing a novel and efficient inner product operation. To\nachieve fast online adaptivity, a class-wise updating method is developed to\ndecompose the binary code learning and alternatively renew the hash functions\nin a class-wise fashion, which well addresses the burden on large amounts of\ntraining batches. Quantitatively, such a decomposition further leads to at\nleast 75% storage saving. To further achieve online efficiency, we propose a\nsemi-relaxation optimization, which accelerates the online training by treating\ndifferent binary constraints independently. Without additional constraints and\nvariables, the time complexity is significantly reduced. Such a scheme is also\nquantitatively shown to well preserve past information during updating hashing\nfunctions. We have quantitatively demonstrated that the collective effort of\nclass-wise updating and semi-relaxation optimization provides a superior\nperformance comparing to various state-of-the-art methods, which is verified\nthrough extensive experiments on three widely-used datasets.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Alt", "Evaluation"], "tsne_embedding": [-11.986714363098145, -10.52012825012207], "cluster": 1}, {"key": "lin2021deep", "year": "2021", "citations": "8", "title": "Deep Self-adaptive Hashing For Image Retrieval", "abstract": "<p>Hashing technology has been widely used in image retrieval due to its\ncomputational and storage efficiency. Recently, deep unsupervised hashing\nmethods have attracted increasing attention due to the high cost of human\nannotations in the real world and the superiority of deep learning technology.\nHowever, most deep unsupervised hashing methods usually pre-compute a\nsimilarity matrix to model the pairwise relationship in the pre-trained feature\nspace. Then this similarity matrix would be used to guide hash learning, in\nwhich most of the data pairs are treated equivalently. The above process is\nconfronted with the following defects: 1) The pre-computed similarity matrix is\ninalterable and disconnected from the hash learning process, which cannot\nexplore the underlying semantic information. 2) The informative data pairs may\nbe buried by the large number of less-informative data pairs. To solve the\naforementioned problems, we propose a Deep Self-Adaptive Hashing (DSAH) model\nto adaptively capture the semantic information with two special designs:\nAdaptive Neighbor Discovery (AND) and Pairwise Information Content (PIC).\nFirstly, we adopt the AND to initially construct a neighborhood-based\nsimilarity matrix, and then refine this initial similarity matrix with a novel\nupdate strategy to further investigate the semantic structure behind the\nlearned representation. Secondly, we measure the priorities of data pairs with\nPIC and assign adaptive weights to them, which is relies on the assumption that\nmore dissimilar data pairs contain more discriminative information for hash\nlearning. Extensive experiments on several datasets demonstrate that the above\ntwo technologies facilitate the deep hashing model to achieve superior\nperformance.</p>\n", "tags": ["DATASETS", "Evaluation", "Neural Hashing", "Hashing Methods", "Efficiency And Optimization", "CIKM", "Image Retrieval", "Alt"], "tsne_embedding": [-7.139434814453125, -1.7221201658248901], "cluster": 8}, {"key": "lin2022deep", "year": "2022", "citations": "17", "title": "Deep Unsupervised Hashing With Latent Semantic Components", "abstract": "<p>Deep unsupervised hashing has been appreciated in the regime of image\nretrieval. However, most prior arts failed to detect the semantic components\nand their relationships behind the images, which makes them lack discriminative\npower. To make up the defect, we propose a novel Deep Semantic Components\nHashing (DSCH), which involves a common sense that an image normally contains a\nbunch of semantic components with homology and co-occurrence relationships.\nBased on this prior, DSCH regards the semantic components as latent variables\nunder the Expectation-Maximization framework and designs a two-step iterative\nalgorithm with the objective of maximum likelihood of training data. Firstly,\nDSCH constructs a semantic component structure by uncovering the fine-grained\nsemantics components of images with a Gaussian Mixture Modal~(GMM), where an\nimage is represented as a mixture of multiple components, and the semantics\nco-occurrence are exploited. Besides, coarse-grained semantics components, are\ndiscovered by considering the homology relationships between fine-grained\ncomponents, and the hierarchy organization is then constructed. Secondly, DSCH\nmakes the images close to their semantic component centers at both fine-grained\nand coarse-grained levels, and also makes the images share similar semantic\ncomponents close to each other. Extensive experiments on three benchmark\ndatasets demonstrate that the proposed hierarchical semantic components indeed\nfacilitate the hashing model to achieve superior performance.</p>\n", "tags": ["AAAI", "DATASETS", "Hashing Methods", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-8.804136276245117, -0.8500837683677673], "cluster": 8}, {"key": "lin2023rafic", "year": "2023", "citations": "5", "title": "RAFIC: Retrieval-augmented Few-shot Image Classification", "abstract": "<p>Few-shot image classification is the task of classifying unseen images to one\nof N mutually exclusive classes, using only a small number of training examples\nfor each class. The limited availability of these examples (denoted as K)\npresents a significant challenge to classification accuracy in some cases. To\naddress this, we have developed a method for augmenting the set of K with an\naddition set of A retrieved images. We call this system Retrieval-Augmented\nFew-shot Image Classification (RAFIC). Through a series of experiments, we\ndemonstrate that RAFIC markedly improves performance of few-shot image\nclassification across two challenging datasets. RAFIC consists of two main\ncomponents: (a) a retrieval component which uses CLIP, LAION-5B, and faiss, in\norder to efficiently retrieve images similar to the supplied images, and (b)\nretrieval meta-learning, which learns to judiciously utilize the retrieved\nimages. Code and data is available at github.com/amirziai/rafic.</p>\n", "tags": ["DATASETS", "Evaluation", "ACL", "Tools & Libraries", "EMNLP"], "tsne_embedding": [-24.560733795166016, 5.675076484680176], "cluster": 3}, {"key": "lin2023searching", "year": "2023", "citations": "17", "title": "Searching Dense Representations With Inverted Indexes", "abstract": "<p>Nearly all implementations of top-\\(k\\) retrieval with dense vector\nrepresentations today take advantage of hierarchical navigable small-world\nnetwork (HNSW) indexes. However, the generation of vector representations and\nefficiently searching large collections of vectors are distinct challenges that\ncan be decoupled. In this work, we explore the contrarian approach of\nperforming top-\\(k\\) retrieval on dense vector representations using inverted\nindexes. We present experiments on the MS MARCO passage ranking dataset,\nevaluating three dimensions of interest: output quality, speed, and index size.\nResults show that searching dense representations using inverted indexes is\npossible. Our approach exhibits reasonable effectiveness with compact indexes,\nbut is impractically slow. Thus, while workable, our solution does not provide\na compelling tradeoff and is perhaps best characterized today as a \u201ctechnical\ncuriosity\u201d.</p>\n", "tags": ["DATASETS", "SIGIR", "Graph Based ANN", "Efficiency And Optimization"], "tsne_embedding": [13.017454147338867, -7.949214935302734], "cluster": 2}, {"key": "lin2025deep", "year": "2025", "citations": "626", "title": "Deep Learning Of Binary Hash Codes For Fast Image Retrieval", "abstract": "<p>Approximate nearest neighbor search is an efficient strategy for large-scale image retrieval. Encouraged by the recent advances in convolutional neural networks (CNNs), we propose an effective deep learning framework to generate binary hash codes for fast image retrieval. Our idea is that when the data labels are available, binary codes can be learned by employing a hidden layer for representing the latent concepts that dominate the class labels.\nhe utilization of the CNN also allows for learning image representations. Unlike other supervised methods that require pair-wised inputs for binary code learning, our method learns hash codes and image representations in a point-wised manner, making it suitable for large-scale datasets. Experimental results show that our method outperforms several state-of-the-art hashing algorithms on the CIFAR-10 and MNIST datasets. We further demonstrate its scalability and efficacy on a large-scale dataset of 1 million clothing images.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "CVPR", "Compact Codes", "Tools & Libraries"], "tsne_embedding": [-10.983237266540527, 19.021556854248047], "cluster": 6}, {"key": "lin2025fast", "year": "2025", "citations": "453", "title": "Fast Supervised Hashing With Decision Trees For High-dimensional Data", "abstract": "<p>Supervised hashing aims to map the original features to\ncompact binary codes that are able to preserve label based\nsimilarity in the Hamming space. Non-linear hash functions\nhave demonstrated their advantage over linear ones due to\ntheir powerful generalization capability. In the literature,\nkernel functions are typically used to achieve non-linearity\nin hashing, which achieve encouraging retrieval performance at the price of slow evaluation and training time.\nHere we propose to use boosted decision trees for achieving\nnon-linearity in hashing, which are fast to train and evaluate, hence more suitable for hashing with high dimensional\ndata. In our approach, we first propose sub-modular formulations for the hashing binary code inference problem\nand an efficient GraphCut based block search method for\nsolving large-scale inference.\nThen we learn hash functions by training boosted decision trees to fit the binary\ncodes. Experiments demonstrate that our proposed method\nsignificantly outperforms most state-of-the-art methods in\nretrieval precision and training time. Especially for highdimensional data, our method is orders of magnitude faster\nthan many methods in terms of training time.</p>\n", "tags": ["CVPR", "Compact Codes", "Hashing Methods", "Evaluation"], "tsne_embedding": [-3.480194330215454, -11.1240234375], "cluster": 9}, {"key": "lin2025general", "year": "2025", "citations": "199", "title": "A General Two-step Approach To Learning-based Hashing", "abstract": "<p>Most existing approaches to hashing apply a single form of hash function, and an optimization process which\nis typically deeply coupled to this specific form. This tight coupling restricts the flexibility of the method to\nrespond to the data, and can result in complex optimization problems that are difficult to solve. Here we propose\na flexible yet simple framework that is able to accommodate different types of loss functions and hash functions.\nThis framework allows a number of existing approaches to hashing to be placed in context, and simplifies the\ndevelopment of new problem-specific hashing methods. Our framework decomposes hashing learning problem\ninto two steps: hash bit learning and hash function learning based on the learned bits. The first step can typically\nbe formulated as binary quadratic problems, and the second step can be accomplished by training standard binary\nclassifiers. Both problems have been extensively studied in the literature. Our extensive experiments demonstrate\nthat the proposed framework is effective, flexible and outperforms the state-of-the-art.</p>\n", "tags": ["ICCV", "Tools & Libraries", "Hashing Methods"], "tsne_embedding": [-4.5443196296691895, -14.378083229064941], "cluster": 9}, {"key": "lin2025optimizing", "year": "2025", "citations": "23", "title": "Optimizing Ranking Measures For Compact Binary Code Learning", "abstract": "<p>Hashing has proven a valuable tool for large-scale information retrieval. Despite much success, existing hashing methods optimize over simple objectives such as the reconstruction error or graph Laplacian related loss functions, instead of the performance evaluation criteria of interest\u2014multivariate performance measures such as the AUC and NDCG. Here we present a general framework (termed StructHash) that allows one to directly optimize multivariate performance measures.\nThe resulting optimization problem can involve exponentially or infinitely many variables and constraints, which is more challenging than standard structured output learning. To solve the StructHash optimization problem, we use a combination of column generation and cutting-plane techniques. We demonstrate the generality of StructHash by applying it to ranking prediction and image retrieval, and show that it outperforms a few state-of-the-art hashing methods.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Compact Codes", "Tools & Libraries", "Evaluation"], "tsne_embedding": [4.58586311340332, -10.782331466674805], "cluster": 2}, {"key": "lin2025semantics", "year": "2025", "citations": "540", "title": "Semantics-preserving Hashing For Cross-view Retrieval", "abstract": "<p>With benefits of low storage costs and high query speeds,\nhashing methods are widely researched for efficiently retrieving large-scale data, which commonly contains multiple views, e.g. a news report with images, videos and texts.\nIn this paper, we study the problem of cross-view retrieval\nand propose an effective Semantics-Preserving Hashing\nmethod, termed SePH. Given semantic affinities of training data as supervised information, SePH transforms them\ninto a probability distribution and approximates it with tobe-learnt hash codes in Hamming space via minimizing the\nKullback-Leibler divergence. Then kernel logistic regression with a sampling strategy is utilized to learn the nonlinear projections from features in each view to the learnt\nhash codes. And for any unseen instance, predicted hash\ncodes and their corresponding output probabilities from observed views are utilized to determine its unified hash code,\nusing a novel probabilistic approach. Extensive experiments conducted on three benchmark datasets well demonstrate the effectiveness and reasonableness of SePH.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "CVPR", "Evaluation"], "tsne_embedding": [-1.3809713125228882, -10.41433048248291], "cluster": 9}, {"key": "linderman2017efficient", "year": "2017", "citations": "192", "title": "Efficient Algorithms For T-distributed Stochastic Neighborhood Embedding", "abstract": "<p>t-distributed Stochastic Neighborhood Embedding (t-SNE) is a method for\ndimensionality reduction and visualization that has become widely popular in\nrecent years. Efficient implementations of t-SNE are available, but they scale\npoorly to datasets with hundreds of thousands to millions of high dimensional\ndata-points. We present Fast Fourier Transform-accelerated Interpolation-based\nt-SNE (FIt-SNE), which dramatically accelerates the computation of t-SNE. The\nmost time-consuming step of t-SNE is a convolution that we accelerate by\ninterpolating onto an equispaced grid and subsequently using the fast Fourier\ntransform to perform the convolution. We also optimize the computation of input\nsimilarities in high dimensions using multi-threaded approximate nearest\nneighbors. We further present a modification to t-SNE called \u201clate\nexaggeration,\u201d which allows for easier identification of clusters in t-SNE\nembeddings. Finally, for datasets that cannot be loaded into the memory, we\npresent out-of-core randomized principal component analysis (oocPCA), so that\nthe top principal components of a dataset can be computed without ever fully\nloading the matrix, hence allowing for t-SNE of large datasets to be computed\non resource-limited machines.</p>\n", "tags": ["DATASETS"], "tsne_embedding": [15.179726600646973, 4.962123394012451], "cluster": 0}, {"key": "lindgren2017leveraging", "year": "2017", "citations": "12", "title": "Leveraging Sparsity For Efficient Submodular Data Summarization", "abstract": "<p>The facility location problem is widely used for summarizing large datasets\nand has additional applications in sensor placement, image retrieval, and\nclustering. One difficulty of this problem is that submodular optimization\nalgorithms require the calculation of pairwise benefits for all items in the\ndataset. This is infeasible for large problems, so recent work proposed to only\ncalculate nearest neighbor benefits. One limitation is that several strong\nassumptions were invoked to obtain provable approximation guarantees. In this\npaper we establish that these extra assumptions are not necessary\u2014solving the\nsparsified problem will be almost optimal under the standard assumptions of the\nproblem. We then analyze a different method of sparsification that is a better\nmodel for methods such as Locality Sensitive Hashing to accelerate the nearest\nneighbor computations and extend the use of the problem to a broader family of\nsimilarities. We validate our approach by demonstrating that it rapidly\ngenerates interpretable summaries.</p>\n", "tags": ["Image Retrieval", "Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Tools & Libraries"], "tsne_embedding": [17.481842041015625, 0.42406755685806274], "cluster": 7}, {"key": "ling2023vector", "year": "2023", "citations": "5", "title": "Vector Quantization With Error Uniformly Distributed Over An Arbitrary Set", "abstract": "<p>For uniform scalar quantization, the error distribution is approximately a\nuniform distribution over an interval (which is also a 1-dimensional ball).\nNevertheless, for lattice vector quantization, the error distribution is\nuniform not over a ball, but over the basic cell of the quantization lattice.\nIn this paper, we construct vector quantizers with periodic properties, where\nthe error is uniformly distributed over the n-ball, or any other prescribed\nset. We then prove upper and lower bounds on the entropy of the quantized\nsignals. We also discuss how our construction can be applied to give a\nrandomized quantization scheme with a nonuniform error distribution.</p>\n", "tags": ["Quantization"], "tsne_embedding": [25.599843978881836, -6.769071102142334], "cluster": 7}, {"key": "liong2025cross", "year": "2025", "citations": "98", "title": "Cross-modal Deep Variational Hashing", "abstract": "<p>In this paper, we propose a cross-modal deep variational hashing (CMDVH) method for cross-modality multimedia retrieval. Unlike existing cross-modal hashing methods\nwhich learn a single pair of projections to map each example as a binary vector, we design a couple of deep neural\nnetwork to learn non-linear transformations from imagetext input pairs, so that unified binary codes can be obtained. We then design the modality-specific neural networks in a probabilistic manner where we model a latent\nvariable as close as possible from the inferred binary codes,\nwhich is approximated by a posterior distribution regularized by a known prior. Experimental results on three benchmark datasets show the efficacy of the proposed approach.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Compact Codes", "ICCV", "Evaluation"], "tsne_embedding": [-1.6306408643722534, 10.291253089904785], "cluster": 6}, {"key": "liong2025deep", "year": "2025", "citations": "56", "title": "Deep Variational And Structural Hashing", "abstract": "<p>In this paper, we propose a deep variational and structural hashing (DVStH) method to learn compact binary codes for multimedia retrieval. Unlike most existing deep hashing methods which use a series of convolution and fully-connected layers to learn binary features, we develop a probabilistic framework to infer latent feature representation inside the network. Then, we design a struct layer rather than a bottleneck hash layer, to obtain binary codes through a simple encoding procedure. By doing these, we are able to obtain binary codes discriminatively and generatively. To make it applicable to cross-modal scalable multimedia retrieval, we extend our method to a cross-modal deep variational and structural hashing (CM-DVStH). We design a deep fusion network with a struct layer to maximize the correlation between image-text input pairs during the training stage so that a unified binary vector can be obtained. We then design modality-specific hashing networks to handle the out-of-sample extension scenario. Specifically, we train a network for each modality which outputs a latent representation that is as close as possible to the binary codes which are inferred from the fusion network. Experimental results on five benchmark datasets are presented to show the efficacy of the proposed approach.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Compact Codes", "Neural Hashing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-10.4812650680542, 2.0441322326660156], "cluster": 8}, {"key": "liu2016generalized", "year": "2016", "citations": "5", "title": "Generalized Residual Vector Quantization For Large Scale Data", "abstract": "<p>Vector quantization is an essential tool for tasks involving large scale\ndata, for example, large scale similarity search, which is crucial for\ncontent-based information retrieval and analysis. In this paper, we propose a\nnovel vector quantization framework that iteratively minimizes quantization\nerror. First, we provide a detailed review on a relevant vector quantization\nmethod named \\textit{residual vector quantization} (RVQ). Next, we propose\n\\textit{generalized residual vector quantization} (GRVQ) to further improve\nover RVQ. Many vector quantization methods can be viewed as the special cases\nof our proposed framework. We evaluate GRVQ on several large scale benchmark\ndatasets for large scale search, classification and object retrieval. We\ncompared GRVQ with existing methods in detail. Extensive experiments\ndemonstrate our GRVQ framework substantially outperforms existing methods in\nterm of quantization accuracy and computation efficiency.</p>\n", "tags": ["Survey Paper", "DATASETS", "Efficiency And Optimization", "Similarity Search", "Quantization", "Tools & Libraries", "Evaluation"], "tsne_embedding": [5.614377975463867, 7.007912635803223], "cluster": 4}, {"key": "liu2016ordinal", "year": "2016", "citations": "23", "title": "Ordinal Constrained Binary Code Learning For Nearest Neighbor Search", "abstract": "<p>Recent years have witnessed extensive attention in binary code learning,\na.k.a. hashing, for nearest neighbor search problems. It has been seen that\nhigh-dimensional data points can be quantized into binary codes to give an\nefficient similarity approximation via Hamming distance. Among existing\nschemes, ranking-based hashing is recent promising that targets at preserving\nordinal relations of ranking in the Hamming space to minimize retrieval loss.\nHowever, the size of the ranking tuples, which shows the ordinal relations, is\nquadratic or cubic to the size of training samples. By given a large-scale\ntraining data set, it is very expensive to embed such ranking tuples in binary\ncode learning. Besides, it remains a dificulty to build ranking tuples\nefficiently for most ranking-preserving hashing, which are deployed over an\nordinal graph-based setting. To handle these problems, we propose a novel\nranking-preserving hashing method, dubbed Ordinal Constraint Hashing (OCH),\nwhich efficiently learns the optimal hashing functions with a graph-based\napproximation to embed the ordinal relations. The core idea is to reduce the\nsize of ordinal graph with ordinal constraint projection, which preserves the\nordinal relations through a small data set (such as clusters or random\nsamples). In particular, to learn such hash functions effectively, we further\nrelax the discrete constraints and design a specific stochastic gradient decent\nalgorithm for optimization. Experimental results on three large-scale visual\nsearch benchmark datasets, i.e. LabelMe, Tiny100K and GIST1M, show that the\nproposed OCH method can achieve superior performance over the state-of-the-arts\napproaches.</p>\n", "tags": ["AAAI", "DATASETS", "Hashing Methods", "Graph Based ANN", "Compact Codes", "Evaluation"], "tsne_embedding": [12.555188179016113, 14.550969123840332], "cluster": 0}, {"key": "liu2016supervised", "year": "2016", "citations": "65", "title": "Supervised Matrix Factorization For Cross-modality Hashing", "abstract": "<p>Matrix factorization has been recently utilized for the task of multi-modal\nhashing for cross-modality visual search, where basis functions are learned to\nmap data from different modalities to the same Hamming embedding. In this\npaper, we propose a novel cross-modality hashing algorithm termed Supervised\nMatrix Factorization Hashing (SMFH) which tackles the multi-modal hashing\nproblem with a collective non-matrix factorization across the different\nmodalities. In particular, SMFH employs a well-designed binary code learning\nalgorithm to preserve the similarities among multi-modal original features\nthrough a graph regularization. At the same time, semantic labels, when\navailable, are incorporated into the learning procedure. We conjecture that all\nthese would facilitate to preserve the most relevant information during the\nbinary quantization process, and hence improve the retrieval accuracy. We\ndemonstrate the superior performance of SMFH on three cross-modality visual\nsearch benchmarks, i.e., the PASCAL-Sentence, Wiki, and NUS-WIDE, with\nquantitative comparison to various state-of-the-art methods</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Compact Codes", "Quantization", "Evaluation"], "tsne_embedding": [13.836007118225098, -14.637804985046387], "cluster": 2}, {"key": "liu2017deep", "year": "2017", "citations": "10", "title": "Deep Hashing With Category Mask For Fast Video Retrieval", "abstract": "<p>This paper proposes an end-to-end deep hashing framework with category mask\nfor fast video retrieval. We train our network in a supervised way by fully\nexploiting inter-class diversity and intra-class identity. Classification loss\nis optimized to maximize inter-class diversity, while intra-pair is introduced\nto learn representative intra-class identity. We investigate the binary bits\ndistribution related to categories and find out that the effectiveness of\nbinary bits is highly correlated with data categories, and some bits may\ndegrade classification performance of some categories. We then design hash code\ngeneration scheme with category mask to filter out bits with negative\ncontribution. Experimental results demonstrate the proposed method outperforms\nseveral state-of-the-arts under various evaluation metrics on public datasets.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Neural Hashing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-8.407502174377441, 18.51028060913086], "cluster": 6}, {"key": "liu2017end", "year": "2017", "citations": "7", "title": "End-to-end Binary Representation Learning Via Direct Binary Embedding", "abstract": "<p>Learning binary representation is essential to large-scale computer vision\ntasks. Most existing algorithms require a separate quantization constraint to\nlearn effective hashing functions. In this work, we present Direct Binary\nEmbedding (DBE), a simple yet very effective algorithm to learn binary\nrepresentation in an end-to-end fashion. By appending an ingeniously designed\nDBE layer to the deep convolutional neural network (DCNN), DBE learns binary\ncode directly from the continuous DBE layer activation without quantization\nerror. By employing the deep residual network (ResNet) as DCNN component, DBE\ncaptures rich semantics from images. Furthermore, in the effort of handling\nmultilabel images, we design a joint cross entropy loss that includes both\nsoftmax cross entropy and weighted binary cross entropy in consideration of the\ncorrelation and independence of labels, respectively. Extensive experiments\ndemonstrate the significant superiority of DBE over state-of-the-art methods on\ntasks of natural object recognition, image retrieval and image annotation.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Quantization"], "tsne_embedding": [-6.497864723205566, 7.704989433288574], "cluster": 8}, {"key": "liu2018adversarial", "year": "2018", "citations": "36", "title": "Adversarial Binary Coding For Efficient Person Re-identification", "abstract": "<p>Person re-identification (ReID) aims at matching persons across different\nviews/scenes. In addition to accuracy, the matching efficiency has received\nmore and more attention because of demanding applications using large-scale\ndata. Several binary coding based methods have been proposed for efficient\nReID, which either learn projections to map high-dimensional features to\ncompact binary codes, or directly adopt deep neural networks by simply\ninserting an additional fully-connected layer with tanh-like activations.\nHowever, the former approach requires time-consuming hand-crafted feature\nextraction and complicated (discrete) optimizations; the latter lacks the\nnecessary discriminative information greatly due to the straightforward\nactivation functions. In this paper, we propose a simple yet effective\nframework for efficient ReID inspired by the recent advances in adversarial\nlearning. Specifically, instead of learning explicit projections or adding\nfully-connected mapping layers, the proposed Adversarial Binary Coding (ABC)\nframework guides the extraction of binary codes implicitly and effectively. The\ndiscriminability of the extracted codes is further enhanced by equipping the\nABC with a deep triplet network for the ReID task. More importantly, the ABC\nand triplet network are simultaneously optimized in an end-to-end manner.\nExtensive experiments on three large-scale ReID benchmarks demonstrate the\nsuperiority of our approach over the state-of-the-art methods.</p>\n", "tags": ["Efficiency And Optimization", "Compact Codes", "Tools & Libraries", "Evaluation", "Robustness"], "tsne_embedding": [-14.67978286743164, -19.22032928466797], "cluster": 1}, {"key": "liu2018discriminative", "year": "2018", "citations": "5", "title": "Discriminative Cross-view Binary Representation Learning", "abstract": "<p>Learning compact representation is vital and challenging for large scale\nmultimedia data. Cross-view/cross-modal hashing for effective binary\nrepresentation learning has received significant attention with exponentially\ngrowing availability of multimedia content. Most existing cross-view hashing\nalgorithms emphasize the similarities in individual views, which are then\nconnected via cross-view similarities. In this work, we focus on the\nexploitation of the discriminative information from different views, and\npropose an end-to-end method to learn semantic-preserving and discriminative\nbinary representation, dubbed Discriminative Cross-View Hashing (DCVH), in\nlight of learning multitasking binary representation for various tasks\nincluding cross-view retrieval, image-to-image retrieval, and image\nannotation/tagging. The proposed DCVH has the following key components. First,\nit uses convolutional neural network (CNN) based nonlinear hashing functions\nand multilabel classification for both images and texts simultaneously. Such\nhashing functions achieve effective continuous relaxation during training\nwithout explicit quantization loss by using Direct Binary Embedding (DBE)\nlayers. Second, we propose an effective view alignment via Hamming distance\nminimization, which is efficiently accomplished by bit-wise XOR operation.\nExtensive experiments on two image-text benchmark datasets demonstrate that\nDCVH outperforms state-of-the-art cross-view hashing algorithms as well as\nsingle-view image hashing algorithms. In addition, DCVH can provide competitive\nperformance for image annotation/tagging.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Quantization", "Evaluation"], "tsne_embedding": [-10.822674751281738, 1.7124285697937012], "cluster": 8}, {"key": "liu2018escaping", "year": "2018", "citations": "14", "title": "Escaping The Curse Of Dimensionality In Similarity Learning: Efficient Frank-wolfe Algorithm And Generalization Bounds", "abstract": "<p>Similarity and metric learning provides a principled approach to construct a\ntask-specific similarity from weakly supervised data. However, these methods\nare subject to the curse of dimensionality: as the number of features grows\nlarge, poor generalization is to be expected and training becomes intractable\ndue to high computational and memory costs. In this paper, we propose a\nsimilarity learning method that can efficiently deal with high-dimensional\nsparse data. This is achieved through a parameterization of similarity\nfunctions by convex combinations of sparse rank-one matrices, together with the\nuse of a greedy approximate Frank-Wolfe algorithm which provides an efficient\nway to control the number of active features. We show that the convergence rate\nof the algorithm, as well as its time and memory complexity, are independent of\nthe data dimension. We further provide a theoretical justification of our\nmodeling choices through an analysis of the generalization error, which depends\nlogarithmically on the sparsity of the solution rather than on the number of\nfeatures. Our experiments on datasets with up to one million features\ndemonstrate the ability of our approach to generalize well despite the high\ndimensionality as well as its superiority compared to several competing\nmethods.</p>\n", "tags": ["DATASETS", "Tools & Libraries", "Distance Metric Learning"], "tsne_embedding": [15.772124290466309, 2.668546438217163], "cluster": 4}, {"key": "liu2018mtfh", "year": "2018", "citations": "171", "title": "MTFH: A Matrix Tri-factorization Hashing Framework For Efficient Cross-modal Retrieval", "abstract": "<p>Hashing has recently sparked a great revolution in cross-modal retrieval\nbecause of its low storage cost and high query speed. Recent cross-modal\nhashing methods often learn unified or equal-length hash codes to represent the\nmulti-modal data and make them intuitively comparable. However, such unified or\nequal-length hash representations could inherently sacrifice their\nrepresentation scalability because the data from different modalities may not\nhave one-to-one correspondence and could be encoded more efficiently by\ndifferent hash codes of unequal lengths. To mitigate these problems, this paper\nexploits a related and relatively unexplored problem: encode the heterogeneous\ndata with varying hash lengths and generalize the cross-modal retrieval in\nvarious challenging scenarios. To this end, a generalized and flexible\ncross-modal hashing framework, termed Matrix Tri-Factorization Hashing (MTFH),\nis proposed to work seamlessly in various settings including paired or unpaired\nmulti-modal data, and equal or varying hash length encoding scenarios. More\nspecifically, MTFH exploits an efficient objective function to flexibly learn\nthe modality-specific hash codes with different length settings, while\nsynchronously learning two semantic correlation matrices to semantically\ncorrelate the different hash representations for heterogeneous data comparable.\nAs a result, the derived hash codes are more semantically meaningful for\nvarious challenging cross-modal retrieval tasks. Extensive experiments\nevaluated on public benchmark datasets highlight the superiority of MTFH under\nvarious retrieval scenarios and show its competitive performance with the\nstate-of-the-arts.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "Multimodal Retrieval", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-3.862051248550415, -4.0329365730285645], "cluster": 9}, {"key": "liu2018stochastic", "year": "2018", "citations": "96", "title": "Stochastic Attraction-repulsion Embedding For Large Scale Image Localization", "abstract": "<p>This paper tackles the problem of large-scale image-based localization (IBL)\nwhere the spatial location of a query image is determined by finding out the\nmost similar reference images in a large database. For solving this problem, a\ncritical task is to learn discriminative image representation that captures\ninformative information relevant for localization. We propose a novel\nrepresentation learning method having higher location-discriminating power. It\nprovides the following contributions: 1) we represent a place (location) as a\nset of exemplar images depicting the same landmarks and aim to maximize\nsimilarities among intra-place images while minimizing similarities among\ninter-place images; 2) we model a similarity measure as a probability\ndistribution on L_2-metric distances between intra-place and inter-place image\nrepresentations; 3) we propose a new Stochastic Attraction and Repulsion\nEmbedding (SARE) loss function minimizing the KL divergence between the learned\nand the actual probability distributions; 4) we give theoretical comparisons\nbetween SARE, triplet ranking and contrastive losses. It provides insights into\nwhy SARE is better by analyzing gradients. Our SARE loss is easy to implement\nand pluggable to any CNN. Experiments show that our proposed method improves\nthe localization performance on standard benchmarks by a large margin.\nDemonstrating the broad applicability of our method, we obtained the third\nplace out of 209 teams in the 2018 Google Landmark Retrieval Challenge. Our\ncode and model are available at https://github.com/Liumouliu/deepIBL.</p>\n", "tags": ["ICCV", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [7.090983867645264, 11.120011329650879], "cluster": 0}, {"key": "liu2019compositional", "year": "2019", "citations": "15", "title": "Compositional Coding For Collaborative Filtering", "abstract": "<p>Efficiency is crucial to the online recommender systems. Representing users\nand items as binary vectors for Collaborative Filtering (CF) can achieve fast\nuser-item affinity computation in the Hamming space, in recent years, we have\nwitnessed an emerging research effort in exploiting binary hashing techniques\nfor CF methods. However, CF with binary codes naturally suffers from low\naccuracy due to limited representation capability in each bit, which impedes it\nfrom modeling complex structure of the data.\n  In this work, we attempt to improve the efficiency without hurting the model\nperformance by utilizing both the accuracy of real-valued vectors and the\nefficiency of binary codes to represent users/items. In particular, we propose\nthe Compositional Coding for Collaborative Filtering (CCCF) framework, which\nnot only gains better recommendation efficiency than the state-of-the-art\nbinarized CF approaches but also achieves even higher accuracy than the\nreal-valued CF method. Specifically, CCCF innovatively represents each\nuser/item with a set of binary vectors, which are associated with a sparse\nreal-value weight vector. Each value of the weight vector encodes the\nimportance of the corresponding binary vector to the user/item. The continuous\nweight vectors greatly enhances the representation capability of binary codes,\nand its sparsity guarantees the processing speed. Furthermore, an integer\nweight approximation scheme is proposed to further accelerate the speed. Based\non the CCCF framework, we design an efficient discrete optimization algorithm\nto learn its parameters. Extensive experiments on three real-world datasets\nshow that our method outperforms the state-of-the-art binarized CF methods\n(even achieves better performance than the real-valued CF method) by a large\nmargin in terms of both recommendation accuracy and efficiency.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Recommender Systems", "SIGIR", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-2.9555139541625977, -5.637524127960205], "cluster": 9}, {"key": "liu2019cross", "year": "2019", "citations": "83", "title": "Cross-modal Zero-shot Hashing", "abstract": "<p>Hashing has been widely studied for big data retrieval due to its low storage\ncost and fast query speed. Zero-shot hashing (ZSH) aims to learn a hashing\nmodel that is trained using only samples from seen categories, but can\ngeneralize well to samples of unseen categories. ZSH generally uses category\nattributes to seek a semantic embedding space to transfer knowledge from seen\ncategories to unseen ones. As a result, it may perform poorly when labeled data\nare insufficient. ZSH methods are mainly designed for single-modality data,\nwhich prevents their application to the widely spread multi-modal data. On the\nother hand, existing cross-modal hashing solutions assume that all the\nmodalities share the same category labels, while in practice the labels of\ndifferent data modalities may be different. To address these issues, we propose\na general Cross-modal Zero-shot Hashing (CZHash) solution to effectively\nleverage unlabeled and labeled multi-modality data with different label spaces.\nCZHash first quantifies the composite similarity between instances using label\nand feature information. It then defines an objective function to achieve deep\nfeature learning compatible with the composite similarity preserving, category\nattribute space learning, and hashing coding function learning. CZHash further\nintroduces an alternative optimization procedure to jointly optimize these\nlearning objectives. Experiments on benchmark multi-modal datasets show that\nCZHash significantly outperforms related representative hashing approaches both\non effectiveness and adaptability.</p>\n", "tags": ["Alt", "Hashing Methods", "Evaluation", "DATASETS"], "tsne_embedding": [-6.988414764404297, -2.725213050842285], "cluster": 8}, {"key": "liu2019deep", "year": "2019", "citations": "106", "title": "Deep Triplet Quantization", "abstract": "<p>Deep hashing establishes efficient and effective image retrieval by\nend-to-end learning of deep representations and hash codes from similarity\ndata. We present a compact coding solution, focusing on deep learning to\nquantization approach that has shown superior performance over hashing\nsolutions for similarity retrieval. We propose Deep Triplet Quantization (DTQ),\na novel approach to learning deep quantization models from the similarity\ntriplets. To enable more effective triplet training, we design a new triplet\nselection approach, Group Hard, that randomly selects hard triplets in each\nimage group. To generate compact binary codes, we further apply a triplet\nquantization with weak orthogonality during triplet training. The quantization\nloss reduces the codebook redundancy and enhances the quantizability of deep\nrepresentations through back-propagation. Extensive experiments demonstrate\nthat DTQ can generate high-quality and compact binary codes, which yields\nstate-of-the-art image retrieval performance on three benchmark datasets,\nNUS-WIDE, CIFAR-10, and MS-COCO.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Compact Codes", "Neural Hashing", "Similarity Search", "Quantization", "Evaluation"], "tsne_embedding": [-10.908273696899414, 4.748165607452393], "cluster": 8}, {"key": "liu2019general", "year": "2019", "citations": "550", "title": "The General Pair-based Weighting Loss For Deep Metric Learning", "abstract": "<p>Deep metric learning aims at learning the distance metric between pair of\nsamples, through the deep neural networks to extract the semantic feature\nembeddings where similar samples are close to each other while dissimilar\nsamples are farther apart. A large amount of loss functions based on pair\ndistances have been presented in the literature for guiding the training of\ndeep metric learning. In this paper, we unify them in a general pair-based\nweighting loss function, where the minimizing objective loss is just the\ndistances weighting of informative pairs. The general pair-based weighting loss\nincludes two main aspects, (1) samples mining and (2) pairs weighting. Samples\nmining aims at selecting the informative positive and negative pair sets to\nexploit the structured relationship of samples in a mini-batch and also reduce\nthe number of non-trivial pairs. Pair weighting aims at assigning different\nweights for different pairs according to the pair distances for\ndiscriminatively training the network. We detailedly review those existing\npair-based losses inline with our general loss function, and explore some\npossible methods from the perspective of samples mining and pairs weighting.\nFinally, extensive experiments on three image retrieval datasets show that our\ngeneral pair-based weighting loss obtains new state-of-the-art performance,\ndemonstrating the effectiveness of the pair-based samples mining and pairs\nweighting for deep metric learning.</p>\n", "tags": ["Survey Paper", "Image Retrieval", "DATASETS", "Distance Metric Learning", "CVPR", "Evaluation"], "tsne_embedding": [-20.877153396606445, 5.06080436706543], "cluster": 3}, {"key": "liu2019mutual", "year": "2019", "citations": "17", "title": "Mutual Linear Regression-based Discrete Hashing", "abstract": "<p>Label information is widely used in hashing methods because of its\neffectiveness of improving the precision. The existing hashing methods always\nuse two different projections to represent the mutual regression between hash\ncodes and class labels. In contrast to the existing methods, we propose a novel\nlearning-based hashing method termed stable supervised discrete hashing with\nmutual linear regression (S2DHMLR) in this study, where only one stable\nprojection is used to describe the linear correlation between hash codes and\ncorresponding labels. To the best of our knowledge, this strategy has not been\nused for hashing previously. In addition, we further use a boosting strategy to\nimprove the final performance of the proposed method without adding extra\nconstraints and with little extra expenditure in terms of time and space.\nExtensive experiments conducted on three image benchmarks demonstrate the\nsuperior performance of the proposed method.</p>\n", "tags": ["Hashing Methods", "Evaluation"], "tsne_embedding": [-1.8337010145187378, -11.542718887329102], "cluster": 9}, {"key": "liu2019optimal", "year": "2019", "citations": "31", "title": "Optimal Projection Guided Transfer Hashing For Image Retrieval", "abstract": "<p>Recently, learning to hash has been widely studied for image retrieval thanks\nto the computation and storage efficiency of binary codes. For most existing\nlearning to hash methods, sufficient training images are required and used to\nlearn precise hashing codes. However, in some real-world applications, there\nare not always sufficient training images in the domain of interest. In\naddition, some existing supervised approaches need a amount of labeled data,\nwhich is an expensive process in term of time, label and human expertise. To\nhandle such problems, inspired by transfer learning, we propose a simple yet\neffective unsupervised hashing method named Optimal Projection Guided Transfer\nHashing (GTH) where we borrow the images of other different but related domain\ni.e., source domain to help learn precise hashing codes for the domain of\ninterest i.e., target domain. Besides, we propose to seek for the maximum\nlikelihood estimation (MLE) solution of the hashing functions of target and\nsource domains due to the domain gap. Furthermore,an alternating optimization\nmethod is adopted to obtain the two projections of target and source domains\nsuch that the domain hashing disparity is reduced gradually. Extensive\nexperiments on various benchmark databases verify that our method outperforms\nmany state-of-the-art learning to hash methods. The implementation details are\navailable at https://github.com/liuji93/GTH.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Alt", "Evaluation"], "tsne_embedding": [-10.413912773132324, -6.600820541381836], "cluster": 1}, {"key": "liu2019query", "year": "2019", "citations": "74", "title": "Query-adaptive Hash Code Ranking For Large-scale Multi-view Visual Search", "abstract": "<p>Hash based nearest neighbor search has become attractive in many\napplications. However, the quantization in hashing usually degenerates the\ndiscriminative power when using Hamming distance ranking. Besides, for\nlarge-scale visual search, existing hashing methods cannot directly support the\nefficient search over the data with multiple sources, and while the literature\nhas shown that adaptively incorporating complementary information from diverse\nsources or views can significantly boost the search performance. To address the\nproblems, this paper proposes a novel and generic approach to building multiple\nhash tables with multiple views and generating fine-grained ranking results at\nbitwise and tablewise levels. For each hash table, a query-adaptive bitwise\nweighting is introduced to alleviate the quantization loss by simultaneously\nexploiting the quality of hash functions and their complement for nearest\nneighbor search. From the tablewise aspect, multiple hash tables are built for\ndifferent data views as a joint index, over which a query-specific rank fusion\nis proposed to rerank all results from the bitwise ranking by diffusing in a\ngraph. Comprehensive experiments on image search over three well-known\nbenchmarks show that the proposed method achieves up to 17.11% and 20.28%\nperformance gains on single and multiple table search over state-of-the-art\nmethods.</p>\n", "tags": ["Image Retrieval", "Quantization", "Hashing Methods", "Evaluation"], "tsne_embedding": [8.114624977111816, -0.9223183989524841], "cluster": 4}, {"key": "liu2019ranking", "year": "2019", "citations": "59", "title": "Ranking-based Deep Cross-modal Hashing", "abstract": "<p>Cross-modal hashing has been receiving increasing interests for its low\nstorage cost and fast query speed in multi-modal data retrievals. However, most\nexisting hashing methods are based on hand-crafted or raw level features of\nobjects, which may not be optimally compatible with the coding process.\nBesides, these hashing methods are mainly designed to handle simple pairwise\nsimilarity. The complex multilevel ranking semantic structure of instances\nassociated with multiple labels has not been well explored yet. In this paper,\nwe propose a ranking-based deep cross-modal hashing approach (RDCMH). RDCMH\nfirstly uses the feature and label information of data to derive a\nsemi-supervised semantic ranking list. Next, to expand the semantic\nrepresentation power of hand-crafted features, RDCMH integrates the semantic\nranking information into deep cross-modal hashing and jointly optimizes the\ncompatible parameters of deep feature representations and of hashing functions.\nExperiments on real multi-modal datasets show that RDCMH outperforms other\ncompetitive baselines and achieves the state-of-the-art performance in\ncross-modal retrieval applications.</p>\n", "tags": ["AAAI", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Multimodal Retrieval", "Evaluation"], "tsne_embedding": [-1.844260811805725, -1.256973385810852], "cluster": 8}, {"key": "liu2019weakly", "year": "2019", "citations": "17", "title": "Weakly-paired Cross-modal Hashing", "abstract": "<p>Hashing has been widely adopted for large-scale data retrieval in many\ndomains, due to its low storage cost and high retrieval speed. Existing\ncross-modal hashing methods optimistically assume that the correspondence\nbetween training samples across modalities are readily available. This\nassumption is unrealistic in practical applications. In addition, these methods\ngenerally require the same number of samples across different modalities, which\nrestricts their flexibility. We propose a flexible cross-modal hashing approach\n(Flex-CMH) to learn effective hashing codes from weakly-paired data, whose\ncorrespondence across modalities are partially (or even totally) unknown.\nFlexCMH first introduces a clustering-based matching strategy to explore the\nlocal structure of each cluster, and thus to find the potential correspondence\nbetween clusters (and samples therein) across modalities. To reduce the impact\nof an incomplete correspondence, it jointly optimizes in a unified objective\nfunction the potential correspondence, the cross-modal hashing functions\nderived from the correspondence, and a hashing quantitative loss. An\nalternative optimization technique is also proposed to coordinate the\ncorrespondence and hash functions, and to reinforce the reciprocal effects of\nthe two objectives. Experiments on publicly multi-modal datasets show that\nFlexCMH achieves significantly better results than state-of-the-art methods,\nand it indeed offers a high degree of flexibility for practical cross-modal\nhashing tasks.</p>\n", "tags": ["Alt", "DATASETS", "Hashing Methods", "Efficiency And Optimization"], "tsne_embedding": [-1.36686372756958, -5.944868087768555], "cluster": 9}, {"key": "liu2020reinforcing", "year": "2020", "citations": "28", "title": "Reinforcing Short-length Hashing", "abstract": "<p>Due to the compelling efficiency in retrieval and storage,\nsimilarity-preserving hashing has been widely applied to approximate nearest\nneighbor search in large-scale image retrieval. However, existing methods have\npoor performance in retrieval using an extremely short-length hash code due to\nweak ability of classification and poor distribution of hash bit. To address\nthis issue, in this study, we propose a novel reinforcing short-length hashing\n(RSLH). In this proposed RSLH, mutual reconstruction between the hash\nrepresentation and semantic labels is performed to preserve the semantic\ninformation. Furthermore, to enhance the accuracy of hash representation, a\npairwise similarity matrix is designed to make a balance between accuracy and\ntraining expenditure on memory. In addition, a parameter boosting strategy is\nintegrated to reinforce the precision with hash bits fusion. Extensive\nexperiments on three large-scale image benchmarks demonstrate the superior\nperformance of RSLH under various short-length hashing scenarios.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [-4.133947372436523, 2.9599955081939697], "cluster": 8}, {"key": "liu2020shuffle", "year": "2020", "citations": "8", "title": "Shuffle And Learn: Minimizing Mutual Information For Unsupervised Hashing", "abstract": "<p>Unsupervised binary representation allows fast data retrieval without any\nannotations, enabling practical application like fast person re-identification\nand multimedia retrieval. It is argued that conflicts in binary space are one\nof the major barriers to high-performance unsupervised hashing as current\nmethods failed to capture the precise code conflicts in the full domain. A\nnovel relaxation method called Shuffle and Learn is proposed to tackle code\nconflicts in the unsupervised hash. Approximated derivatives for joint\nprobability and the gradients for the binary layer are introduced to bridge the\nupdate from the hash to the input. Proof on \\(\\epsilon\\)-Convergence of joint\nprobability with approximated derivatives is provided to guarantee the\npreciseness on update applied on the mutual information. The proposed algorithm\nis carried out with iterative global updates to minimize mutual information,\ndiverging the code before regular unsupervised optimization. Experiments\nsuggest that the proposed method can relax the code optimization from local\noptimum and help to generate binary representations that are more\ndiscriminative and informative without any annotations. Performance benchmarks\non image retrieval with the unsupervised binary code are conducted on three\nopen datasets, and the model achieves state-of-the-art accuracy on image\nretrieval task for all those datasets. Datasets and reproducible code are\nprovided.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Compact Codes", "Evaluation"], "tsne_embedding": [-2.727628469467163, 6.614469528198242], "cluster": 8}, {"key": "liu2021fddh", "year": "2021", "citations": "49", "title": "FDDH: Fast Discriminative Discrete Hashing For Large-scale Cross-modal Retrieval", "abstract": "<p>Cross-modal hashing, favored for its effectiveness and efficiency, has\nreceived wide attention to facilitating efficient retrieval across different\nmodalities. Nevertheless, most existing methods do not sufficiently exploit the\ndiscriminative power of semantic information when learning the hash codes,\nwhile often involving time-consuming training procedure for handling the\nlarge-scale dataset. To tackle these issues, we formulate the learning of\nsimilarity-preserving hash codes in terms of orthogonally rotating the semantic\ndata so as to minimize the quantization loss of mapping such data to hamming\nspace, and propose an efficient Fast Discriminative Discrete Hashing (FDDH)\napproach for large-scale cross-modal retrieval. More specifically, FDDH\nintroduces an orthogonal basis to regress the targeted hash codes of training\nexamples to their corresponding semantic labels, and utilizes \u201c-dragging\ntechnique to provide provable large semantic margins. Accordingly, the\ndiscriminative power of semantic information can be explicitly captured and\nmaximized. Moreover, an orthogonal transformation scheme is further proposed to\nmap the nonlinear embedding data into the semantic subspace, which can well\nguarantee the semantic consistency between the data feature and its semantic\nrepresentation. Consequently, an efficient closed form solution is derived for\ndiscriminative hash code learning, which is very computationally efficient. In\naddition, an effective and stable online learning strategy is presented for\noptimizing modality-specific projection functions, featuring adaptivity to\ndifferent training sizes and streaming data. The proposed FDDH approach\ntheoretically approximates the bi-Lipschitz continuity, runs sufficiently fast,\nand also significantly improves the retrieval performance over the\nstate-of-the-art methods. The source code is released at:\nhttps://github.com/starxliu/FDDH.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "Multimodal Retrieval", "Similarity Search", "Quantization", "Evaluation"], "tsne_embedding": [-10.410155296325684, -3.4071075916290283], "cluster": 8}, {"key": "liu2021ternary", "year": "2021", "citations": "35", "title": "Ternary Hashing", "abstract": "<p>This paper proposes a novel ternary hash encoding for learning to hash\nmethods, which provides a principled more efficient coding scheme with\nperformances better than those of the state-of-the-art binary hashing\ncounterparts. Two kinds of axiomatic ternary logic, Kleene logic and\n{\\L}ukasiewicz logic are adopted to calculate the Ternary Hamming Distance\n(THD) for both the learning/encoding and testing/querying phases. Our work\ndemonstrates that, with an efficient implementation of ternary logic on\nstandard binary machines, the proposed ternary hashing is compared favorably to\nthe binary hashing methods with consistent improvements of retrieval mean\naverage precision (mAP) ranging from 1% to 5.9% as shown in CIFAR10, NUS-WIDE\nand ImageNet100 datasets.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Evaluation"], "tsne_embedding": [4.327467918395996, -12.415511131286621], "cluster": 2}, {"key": "liu2022das", "year": "2022", "citations": "13", "title": "DAS: Densely-anchored Sampling For Deep Metric Learning", "abstract": "<p>Deep Metric Learning (DML) serves to learn an embedding function to project\nsemantically similar data into nearby embedding space and plays a vital role in\nmany applications, such as image retrieval and face recognition. However, the\nperformance of DML methods often highly depends on sampling methods to choose\neffective data from the embedding space in the training. In practice, the\nembeddings in the embedding space are obtained by some deep models, where the\nembedding space is often with barren area due to the absence of training\npoints, resulting in so called \u201cmissing embedding\u201d issue. This issue may impair\nthe sample quality, which leads to degenerated DML performance. In this work,\nwe investigate how to alleviate the \u201cmissing embedding\u201d issue to improve the\nsampling quality and achieve effective DML. To this end, we propose a\nDensely-Anchored Sampling (DAS) scheme that considers the embedding with\ncorresponding data point as \u201canchor\u201d and exploits the anchor\u2019s nearby embedding\nspace to densely produce embeddings without data points. Specifically, we\npropose to exploit the embedding space around single anchor with Discriminative\nFeature Scaling (DFS) and multiple anchors with Memorized Transformation\nShifting (MTS). In this way, by combing the embeddings with and without data\npoints, we are able to provide more embeddings to facilitate the sampling\nprocess thus boosting the performance of DML. Our method is effortlessly\nintegrated into existing DML frameworks and improves them without bells and\nwhistles. Extensive experiments on three benchmark datasets demonstrate the\nsuperiority of our method.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Distance Metric Learning", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-16.865177154541016, 2.951035261154175], "cluster": 3}, {"key": "liu2022towards", "year": "2022", "citations": "7", "title": "Towards Fast And Accurate Federated Learning With Non-iid Data For Cloud-based Iot Applications", "abstract": "<p>As a promising method of central model training on decentralized device data\nwhile securing user privacy, Federated Learning (FL)is becoming popular in\nInternet of Things (IoT) design. However, when the data collected by IoT\ndevices are highly skewed in a non-independent and identically distributed\n(non-IID) manner, the accuracy of vanilla FL method cannot be guaranteed.\nAlthough there exist various solutions that try to address the bottleneck of FL\nwith non-IID data, most of them suffer from extra intolerable communication\noverhead and low model accuracy. To enable fast and accurate FL, this paper\nproposes a novel data-based device grouping approach that can effectively\nreduce the disadvantages of weight divergence during the training of non-IID\ndata. However, since our grouping method is based on the similarity of\nextracted feature maps from IoT devices, it may incur additional risks of\nprivacy exposure. To solve this problem, we propose an improved version by\nexploiting similarity information using the Locality-Sensitive Hashing (LSH)\nalgorithm without exposing extracted feature maps. Comprehensive experimental\nresults on well-known benchmarks show that our approach can not only accelerate\nthe convergence rate, but also improve the prediction accuracy for FL with\nnon-IID data.</p>\n", "tags": ["Alt", "Locality Sensitive Hashing", "Hashing Methods", "Evaluation"], "tsne_embedding": [1.9688197374343872, -21.932100296020508], "cluster": 5}, {"key": "liu2022wl", "year": "2022", "citations": "9", "title": "Wl-align: Weisfeiler-lehman Relabeling For Aligning Users Across Networks Via Regularized Representation Learning", "abstract": "<p>Aligning users across networks using graph representation learning has been\nfound effective where the alignment is accomplished in a low-dimensional\nembedding space. Yet, achieving highly precise alignment is still challenging,\nespecially when nodes with long-range connectivity to the labeled anchors are\nencountered. To alleviate this limitation, we purposefully designed WL-Align\nwhich adopts a regularized representation learning framework to learn\ndistinctive node representations. It extends the Weisfeiler-Lehman Isormorphism\nTest and learns the alignment in alternating phases of \u201cacross-network\nWeisfeiler-Lehman relabeling\u201d and \u201cproximity-preserving representation\nlearning\u201d. The across-network Weisfeiler-Lehman relabeling is achieved through\niterating the anchor-based label propagation and a similarity-based hashing to\nexploit the known anchors\u2019 connectivity to different nodes in an efficient and\nrobust manner. The representation learning module preserves the second-order\nproximity within individual networks and is regularized by the across-network\nWeisfeiler-Lehman hash labels. Extensive experiments on real-world and\nsynthetic datasets have demonstrated that our proposed WL-Align outperforms the\nstate-of-the-art methods, achieving significant performance improvements in the\n\u201cexact matching\u201d scenario. Data and code of WL-Align are available at\nhttps://github.com/ChenPengGang/WLAlignCode.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Alt", "Tools & Libraries", "Evaluation"], "tsne_embedding": [14.351285934448242, 13.57948112487793], "cluster": 0}, {"key": "liu2023hs", "year": "2023", "citations": "32", "title": "HS-GCN: Hamming Spatial Graph Convolutional Networks For Recommendation", "abstract": "<p>An efficient solution to the large-scale recommender system is to represent\nusers and items as binary hash codes in the Hamming space. Towards this end,\nexisting methods tend to code users by modeling their Hamming similarities with\nthe items they historically interact with, which are termed as the first-order\nsimilarities in this work. Despite their efficiency, these methods suffer from\nthe suboptimal representative capacity, since they forgo the correlation\nestablished by connecting multiple first-order similarities, i.e., the relation\namong the indirect instances, which could be defined as the high-order\nsimilarity. To tackle this drawback, we propose to model both the first- and\nthe high-order similarities in the Hamming space through the user-item\nbipartite graph. Therefore, we develop a novel learning to hash framework,\nnamely Hamming Spatial Graph Convolutional Networks (HS-GCN), which explicitly\nmodels the Hamming similarity and embeds it into the codes of users and items.\nExtensive experiments on three public benchmark datasets demonstrate that our\nproposed model significantly outperforms several state-of-the-art hashing\nmodels, and obtains performance comparable with the real-valued recommendation\nmodels.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "Recommender Systems", "Tools & Libraries", "Evaluation"], "tsne_embedding": [2.5409603118896484, -3.321774959564209], "cluster": 4}, {"key": "liu2025collaborative", "year": "2025", "citations": "130", "title": "Collaborative Hashing", "abstract": "<p>Hashing technique has become a promising approach for\nfast similarity search. Most of existing hashing research\npursue the binary codes for the same type of entities by\npreserving their similarities. In practice, there are many\nscenarios involving nearest neighbor search on the data\ngiven in matrix form, where two different types of, yet\nnaturally associated entities respectively correspond to its\ntwo dimensions or views. To fully explore the duality\nbetween the two views, we propose a collaborative hashing\nscheme for the data in matrix form to enable fast search\nin various applications such as image search using bag of\nwords and recommendation using user-item ratings. By\nsimultaneously preserving both the entity similarities in\neach view and the interrelationship between views, our\ncollaborative hashing effectively learns the compact binary\ncodes and the explicit hash functions for out-of-sample\nextension in an alternating optimization way. Extensive\nevaluations are conducted on three well-known datasets\nfor search inside a single view and search across different\nviews, demonstrating that our proposed method outperforms\nstate-of-the-art baselines, with significant accuracy\ngains ranging from 7.67% to 45.87% relatively.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "CVPR", "Compact Codes", "Alt", "Recommender Systems", "Similarity Search", "Evaluation"], "tsne_embedding": [6.123315334320068, 2.8593387603759766], "cluster": 4}, {"key": "liu2025discrete", "year": "2025", "citations": "496", "title": "Discrete Graph Hashing", "abstract": "<p>Hashing has emerged as a popular technique for fast nearest neighbor search in gigantic\ndatabases. In particular, learning based hashing has received considerable\nattention due to its appealing storage and search efficiency. However, the performance\nof most unsupervised learning based hashing methods deteriorates rapidly\nas the hash code length increases. We argue that the degraded performance is due\nto inferior optimization procedures used to achieve discrete binary codes. This\npaper presents a graph-based unsupervised hashing model to preserve the neighborhood\nstructure of massive data in a discrete code space. We cast the graph\nhashing problem into a discrete optimization framework which directly learns the\nbinary codes. A tractable alternating maximization algorithm is then proposed to\nexplicitly deal with the discrete constraints, yielding high-quality codes to well\ncapture the local neighborhoods. Extensive experiments performed on four large\ndatasets with up to one million samples show that our discrete optimization based\ngraph hashing method obtains superior search accuracy over state-of-the-art unsupervised\nhashing methods, especially for longer codes.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Graph Based ANN", "Efficiency And Optimization", "Compact Codes", "Alt", "Tools & Libraries", "Evaluation"], "tsne_embedding": [17.50075912475586, 9.903292655944824], "cluster": 0}, {"key": "liu2025discretely", "year": "2025", "citations": "49", "title": "Discretely Coding Semantic Rank Orders For Supervised Image Hashing", "abstract": "<p>Learning to hash has been recognized to accomplish highly efficient storage and retrieval for large-scale visual data. Particularly, ranking-based hashing techniques have recently attracted broad research attention because ranking accuracy among the retrieved data is well explored and their objective is more applicable to realistic search tasks. However, directly optimizing discrete hash codes without continuous-relaxations on a nonlinear ranking objective is infeasible by either traditional optimization methods or even recent discrete hashing algorithms. To address this challenging issue, in this paper, we introduce a novel supervised hashing method, dubbed Discrete Semantic Ranking Hashing (DSeRH), which aims to directly embed semantic rank orders into binary codes. In DSeRH, a generalized Adaptive Discrete Minimization (ADM) approach is proposed to discretely optimize binary codes with the quadratic nonlinear ranking objective in an iterative manner and is guaranteed to converge quickly. Additionally, instead of using 0/1 independent labels to form rank orders as in previous works, we generate the listwise rank orders from the high-level semantic word embeddings which can quantitatively capture the intrinsic correlation between different categories. We evaluate our DSeRH, coupled with both linear and deep convolutional neural network (CNN) hash functions, on three image datasets, i.e., CIFAR-10, SUN397 and ImageNet100, and the results manifest that DSeRH can outperform the state-of-the-art ranking-based hashing methods.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "CVPR", "Compact Codes"], "tsne_embedding": [-4.776383399963379, -0.4818386137485504], "cluster": 8}, {"key": "liu2025hash", "year": "2025", "citations": "91", "title": "Hash Bit Selection: A Unified Solution For Selection Problems In Hashing", "abstract": "<p>Hashing based methods recently have been shown promising for large-scale nearest neighbor search. However, good designs involve difficult decisions of many unknowns \u2013 data features, hashing algorithms, parameter settings, kernels, etc. In this paper, we provide a unified solution as hash bit selection, i.e., selecting the most informative hash bits from a pool of candidates that may have been generated under various conditions mentioned above. We represent the candidate bit pool as a vertex- and edge-weighted graph with the pooled bits as vertices. Then we formulate the bit selection problem as quadratic programming over the graph, and solve it efficiently by replicator dynamics. Extensive experiments show that our bit selection approach can achieve superior performance over both naive selection methods and state-of-the-art methods under each scenario, usually with significant accuracy gains from 10% to 50% relatively.</p>\n", "tags": ["CVPR", "Hashing Methods", "Evaluation"], "tsne_embedding": [17.717533111572266, 10.79437255859375], "cluster": 0}, {"key": "liu2025hashing", "year": "2025", "citations": "861", "title": "Hashing With Graphs", "abstract": "<p>Hashing is becoming increasingly popular for\nefficient nearest neighbor search in massive\ndatabases. However, learning short codes\nthat yield good search performance is still\na challenge. Moreover, in many cases realworld\ndata lives on a low-dimensional manifold,\nwhich should be taken into account\nto capture meaningful nearest neighbors. In\nthis paper, we propose a novel graph-based\nhashing method which automatically discovers\nthe neighborhood structure inherent in\nthe data to learn appropriate compact codes.\nTo make such an approach computationally\nfeasible, we utilize Anchor Graphs to obtain\ntractable low-rank adjacency matrices. Our\nformulation allows constant time hashing of a\nnew data point by extrapolating graph Laplacian\neigenvectors to eigenfunctions. Finally,\nwe describe a hierarchical threshold learning\nprocedure in which each eigenfunction yields\nmultiple bits, leading to higher search accuracy.\nExperimental comparison with the\nother state-of-the-art methods on two large\ndatasets demonstrates the efficacy of the proposed\nmethod.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Graph Based ANN", "Compact Codes", "Evaluation"], "tsne_embedding": [17.557126998901367, 9.767448425292969], "cluster": 0}, {"key": "liu2025joint", "year": "2025", "citations": "148", "title": "Joint-modal Distribution-based Similarity Hashing For Large-scale Unsupervised Deep Cross-modal Retrieval", "abstract": "<p>Hashing-based cross-modal search which aims to map multiple modality features into binary codes has attracted increasingly attention due to its storage and search efficiency especially in large-scale database retrieval. Recent unsupervised deep cross-modal hashing methods have shown promising results. However, existing approaches typically suffer from two limitations: (1) They usually learn cross-modal similarity information separately or in a redundant fusion manner, which may fail to capture semantic correlations among instances from different modalities sufficiently and effectively. (2) They seldom consider the sampling and weighting schemes for unsupervised cross-modal hashing, resulting in the lack of satisfactory discriminative ability in hash codes. To overcome these limitations, we propose a novel unsupervised deep cross-modal hashing method called Joint-modal Distribution-based Similarity Hashing (JDSH) for large-scale cross-modal retrieval. Firstly, we propose a novel cross-modal joint-training method by constructing a joint-modal similarity matrix to fully preserve the cross-modal semantic correlations among instances. Secondly, we propose a sampling and weighting scheme termed the Distribution-based Similarity Decision and Weighting (DSDW) method for unsupervised cross-modal hashing, which is able to generate more discriminative hash codes by pushing semantic similar instance pairs closer and pulling semantic dissimilar instance pairs apart. The experimental results demonstrate the superiority of JDSH compared with several unsupervised cross-modal hashing methods on two public datasets NUS-WIDE and MIRFlickr.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Multimodal Retrieval", "SIGIR", "Evaluation"], "tsne_embedding": [-5.270852088928223, -3.4668118953704834], "cluster": 9}, {"key": "liu2025moboost", "year": "2025", "citations": "5", "title": "Moboost: A Self-improvement Framework For Linear-based Hashing", "abstract": "<p>The linear model is commonly utilized in hashing methods owing to its efficiency. To obtain better accuracy, linear-based hashing methods focus on designing a generalized linear objective function with different constraints or penalty terms that consider neighborhood information. In this study, we propose a novel generalized framework called Model Boost (MoBoost), which can achieve the self-improvement of the linear-based hashing. The proposed MoBoost is used to improve model parameter optimization for linear-based hashing methods without adding new constraints or penalty terms. In the proposed MoBoost, given a linear-based hashing method, we first execute the method several times to get several different hash codes for training samples, and then combine these different hash codes into one set utilizing one novel fusion strategy. Based on this set of hash codes, we learn some new parameters for the linear hash function that can significantly improve accuracy. The proposed MoBoost can be generally adopted in existing linear-based hashing methods, achieving more precise and stable performance compared to the original methods while imposing negligible added expenditure in terms of time and space. Extensive experiments are performed based on three benchmark datasets, and the results demonstrate the superior performance of the proposed framework.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "Alt", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-13.577054023742676, -13.447306632995605], "cluster": 1}, {"key": "liu2025model", "year": "2025", "citations": "22", "title": "Model Optimization Boosting Framework For Linear Model Hash Learning", "abstract": "<p>Efficient hashing techniques have attracted extensive research interests in both storage and retrieval of high dimensional data, such as images and videos. In existing hashing methods, a linear model is commonly utilized owing to its efficiency. To obtain better accuracy, linear-based hashing methods focus on designing a generalized linear objective function with different constraints or penalty terms that consider the inherent characteristics and neighborhood information of samples. Differing from existing hashing methods, in this study, we propose a self-improvement framework called Model Boost (MoBoost) to improve model parameter optimization for linear-based hashing methods without adding new constraints or penalty terms. In the proposed MoBoost, for a linear-based hashing method, we first repeatedly execute the hashing method to obtain several hash codes to training samples. Then, utilizing two novel fusion strategies, these codes are fused into a single set. We also propose two new criteria to evaluate the goodness of hash bits during the fusion process. Based on the fused set of hash codes, we learn new parameters for the linear hash function that can significantly improve the accuracy. In general, the proposed MoBoost can be adopted by existing linear-based hashing methods, achieving more precise and stable performance compared to the original methods, and adopting the proposed MoBoost will incur negligible time and space costs. To evaluate the proposed MoBoost, we performed extensive experiments on four benchmark datasets, and the results demonstrate superior performance.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "Alt", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-13.545742988586426, -13.396129608154297], "cluster": 1}, {"key": "liu2025multi", "year": "2025", "citations": "57", "title": "Multi-view Complementary Hash Tables For Nearest Neighbor Search", "abstract": "<p>Recent years have witnessed the success of hashing techniques in fast nearest neighbor search. In practice many\napplications (e.g., visual search, object detection, image\nmatching, etc.) have enjoyed the benefits of complementary hash tables and information fusion over multiple views.\nHowever, most of prior research mainly focused on compact hash code cleaning, and rare work studies how to build\nmultiple complementary hash tables, much less to adaptively integrate information stemming from multiple views.\nIn\nthis paper we first present a novel multi-view complementary hash table method that learns complementary hash tables from the data with multiple views. For single multiview table, using exemplar based feature fusion, we approximate the inherent data similarities with a low-rank matrix,\nand learn discriminative hash functions in an efficient way.\nTo build complementary tables and meanwhile maintain scalable training and fast out-of-sample extension, an exemplar reweighting scheme is introduced to update the induced low-rank similarity in the sequential table construction framework, which indeed brings mutual benefits between tables by placing greater importance on exemplars\nshared by mis-separated neighbors. Extensive experiments\non three large-scale image datasets demonstrate that the\nproposed method significantly outperforms various naive\nsolutions and state-of-the-art multi-table methods.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "ICCV", "Tools & Libraries"], "tsne_embedding": [7.9124603271484375, -1.2159937620162964], "cluster": 4}, {"key": "liu2025supervised", "year": "2025", "citations": "1447", "title": "Supervised Hashing With Kernels", "abstract": "<p>Recent years have witnessed the growing popularity of\nhashing in large-scale vision problems. It has been shown\nthat the hashing quality could be boosted by leveraging supervised\ninformation into hash function learning. However,\nthe existing supervised methods either lack adequate performance\nor often incur cumbersome model training. In this\npaper, we propose a novel kernel-based supervised hashing\nmodel which requires a limited amount of supervised information,\ni.e., similar and dissimilar data pairs, and a feasible\ntraining cost in achieving high quality hashing. The idea\nis to map the data to compact binary codes whose Hamming\ndistances are minimized on similar pairs and simultaneously\nmaximized on dissimilar pairs. Our approach is\ndistinct from prior works by utilizing the equivalence between\noptimizing the code inner products and the Hamming\ndistances. This enables us to sequentially and efficiently\ntrain the hash functions one bit at a time, yielding very\nshort yet discriminative codes. We carry out extensive experiments\non two image benchmarks with up to one million\nsamples, demonstrating that our approach significantly outperforms\nthe state-of-the-arts in searching both metric distance\nneighbors and semantically similar neighbors, with\naccuracy gains ranging from 13% to 46%.</p>\n", "tags": ["CVPR", "Compact Codes", "Hashing Methods", "Evaluation"], "tsne_embedding": [-2.2972524166107178, -10.90270709991455], "cluster": 9}, {"key": "loncaric2018convolutional", "year": "2018", "citations": "42", "title": "Convolutional Hashing For Automated Scene Matching", "abstract": "<p>We present a powerful new loss function and training scheme for learning\nbinary hash functions. In particular, we demonstrate our method by creating for\nthe first time a neural network that outperforms state-of-the-art Haar wavelets\nand color layout descriptors at the task of automated scene matching. By\naccurately relating distance on the manifold of network outputs to distance in\nHamming space, we achieve a 100-fold reduction in nontrivial false positive\nrate and significantly higher true positive rate. We expect our insights to\nprovide large wins for hashing models applied to other information retrieval\nhashing tasks as well.</p>\n", "tags": ["Hashing Methods"], "tsne_embedding": [-4.253615856170654, 5.069821834564209], "cluster": 8}, {"key": "loncaric2018learning", "year": "2018", "citations": "11", "title": "Learning Hash Codes Via Hamming Distance Targets", "abstract": "<p>We present a powerful new loss function and training scheme for learning\nbinary hash codes with any differentiable model and similarity function. Our\nloss function improves over prior methods by using log likelihood loss on top\nof an accurate approximation for the probability that two inputs fall within a\nHamming distance target. Our novel training scheme obtains a good estimate of\nthe true gradient by better sampling inputs and evaluating loss terms between\nall pairs of inputs in each minibatch. To fully leverage the resulting hashes,\nwe use multi-indexing. We demonstrate that these techniques provide large\nimprovements to a similarity search tasks. We report the best results to date\non competitive information retrieval tasks for ImageNet and SIFT 1M, improving\nMAP from 73% to 84% and reducing query cost by a factor of 2-8, respectively.</p>\n", "tags": ["Vector Indexing", "Similarity Search", "Hashing Methods", "Evaluation"], "tsne_embedding": [16.98204231262207, -19.005359649658203], "cluster": 2}, {"key": "long2025deep", "year": "2025", "citations": "21", "title": "Deep Domain Adaptation Hashing With Adversarial Learning", "abstract": "<p>The recent advances in deep neural networks have demonstrated high capability in a wide variety of scenarios. Nevertheless, fine-tuning deep models in a new domain still requires a significant amount of labeled data despite expensive labeling efforts. A valid question is how to leverage the source knowledge plus unlabeled or only sparsely labeled target data for learning a new model in target domain. The core problem is to bring the source and target distributions closer in the feature space. In the paper, we facilitate this issue in an adversarial learning framework, in which a domain discriminator is devised to handle domain shift. Particularly, we explore the learning in the context of hashing problem, which has been studied extensively due to its great efficiency in gigantic data. Specifically, a novel Deep Domain Adaptation Hashing with Adversarial learning (DeDAHA) architecture is presented, which mainly consists of three components: a deep convolutional neural networks (CNN) for learning basic image/frame representation followed by an adversary stream on one hand to optimize the domain discriminator, and on the other, to interact with each domain-specific hashing stream for encoding image representation to hash codes. The whole architecture is trained end-to-end by jointly optimizing two types of losses, i.e., triplet ranking loss to preserve the relative similarity ordering in the input triplets and adversarial loss to maximally fool the domain discriminator with the learnt source and target feature distributions. Extensive experiments are conducted on three domain transfer tasks, including cross-domain digits retrieval, image to image and image to video transfers, on several benchmarks. Our DeDAHA framework achieves superior results when compared to the state-of-the-art techniques.</p>\n", "tags": ["Hashing Methods", "Efficiency And Optimization", "SIGIR", "Tools & Libraries", "Evaluation", "Robustness"], "tsne_embedding": [-13.218727111816406, -2.660414934158325], "cluster": 1}, {"key": "lu2018fmhash", "year": "2018", "citations": "9", "title": "Fmhash: Deep Hashing Of In-air-handwriting For User Identification", "abstract": "<p>Many mobile systems and wearable devices, such as Virtual Reality (VR) or\nAugmented Reality (AR) headsets, lack a keyboard or touchscreen to type an ID\nand password for signing into a virtual website. However, they are usually\nequipped with gesture capture interfaces to allow the user to interact with the\nsystem directly with hand gestures. Although gesture-based authentication has\nbeen well-studied, less attention is paid to the gesture-based user\nidentification problem, which is essentially an input method of account ID and\nan efficient searching and indexing method of a database of gesture signals. In\nthis paper, we propose FMHash (i.e., Finger Motion Hash), a user identification\nframework that can generate a compact binary hash code from a piece of\nin-air-handwriting of an ID string. This hash code enables indexing and fast\nsearch of a large account database using the in-air-handwriting by a hash\ntable. To demonstrate the effectiveness of the framework, we implemented a\nprototype and achieved &gt;99.5% precision and &gt;92.6% recall with exact hash code\nmatch on a dataset of 200 accounts collected by us. The ability of hashing\nin-air-handwriting pattern to binary code can be used to achieve convenient\nsign-in and sign-up with in-air-handwriting gesture ID on future mobile and\nwearable systems connected to the Internet.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Compact Codes", "Alt", "Neural Hashing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [4.556994915008545, -19.178144454956055], "cluster": 5}, {"key": "lu2021learnable", "year": "2021", "citations": "23", "title": "Learnable Locality-sensitive Hashing For Video Anomaly Detection", "abstract": "<p>Video anomaly detection (VAD) mainly refers to identifying anomalous events\nthat have not occurred in the training set where only normal samples are\navailable. Existing works usually formulate VAD as a reconstruction or\nprediction problem. However, the adaptability and scalability of these methods\nare limited. In this paper, we propose a novel distance-based VAD method to\ntake advantage of all the available normal data efficiently and flexibly. In\nour method, the smaller the distance between a testing sample and normal\nsamples, the higher the probability that the testing sample is normal.\nSpecifically, we propose to use locality-sensitive hashing (LSH) to map samples\nwhose similarity exceeds a certain threshold into the same bucket in advance.\nIn this manner, the complexity of near neighbor search is cut down\nsignificantly. To make the samples that are semantically similar get closer and\nsamples not similar get further apart, we propose a novel learnable version of\nLSH that embeds LSH into a neural network and optimizes the hash functions with\ncontrastive learning strategy. The proposed method is robust to data imbalance\nand can handle the large intra-class variations in normal data flexibly.\nBesides, it has a good ability of scalability. Extensive experiments\ndemonstrate the superiority of our method, which achieves new state-of-the-art\nresults on VAD benchmarks.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Evaluation"], "tsne_embedding": [17.23973274230957, -0.660862386226654], "cluster": 7}, {"key": "lu2022asymmetric", "year": "2022", "citations": "8", "title": "Asymmetric Transfer Hashing With Adaptive Bipartite Graph Learning", "abstract": "<p>Thanks to the efficient retrieval speed and low storage consumption, learning\nto hash has been widely used in visual retrieval tasks. However, existing\nhashing methods assume that the query and retrieval samples lie in homogeneous\nfeature space within the same domain. As a result, they cannot be directly\napplied to heterogeneous cross-domain retrieval. In this paper, we propose a\nGeneralized Image Transfer Retrieval (GITR) problem, which encounters two\ncrucial bottlenecks: 1) the query and retrieval samples may come from different\ndomains, leading to an inevitable {domain distribution gap}; 2) the features of\nthe two domains may be heterogeneous or misaligned, bringing up an additional\n{feature gap}. To address the GITR problem, we propose an Asymmetric Transfer\nHashing (ATH) framework with its unsupervised/semi-supervised/supervised\nrealizations. Specifically, ATH characterizes the domain distribution gap by\nthe discrepancy between two asymmetric hash functions, and minimizes the\nfeature gap with the help of a novel adaptive bipartite graph constructed on\ncross-domain data. By jointly optimizing asymmetric hash functions and the\nbipartite graph, not only can knowledge transfer be achieved but information\nloss caused by feature alignment can also be avoided. Meanwhile, to alleviate\nnegative transfer, the intrinsic geometrical structure of single-domain data is\npreserved by involving a domain affinity graph. Extensive experiments on both\nsingle-domain and cross-domain benchmarks under different GITR subtasks\nindicate the superiority of our ATH method in comparison with the\nstate-of-the-art hashing methods.</p>\n", "tags": ["Similarity Search", "Tools & Libraries", "Hashing Methods", "Evaluation"], "tsne_embedding": [-6.746954441070557, -2.073014736175537], "cluster": 8}, {"key": "lu2023attributes", "year": "2023", "citations": "8", "title": "Attributes Grouping And Mining Hashing For Fine-grained Image Retrieval", "abstract": "<p>In recent years, hashing methods have been popular in the large-scale media\nsearch for low storage and strong representation capabilities. To describe\nobjects with similar overall appearance but subtle differences, more and more\nstudies focus on hashing-based fine-grained image retrieval. Existing hashing\nnetworks usually generate both local and global features through attention\nguidance on the same deep activation tensor, which limits the diversity of\nfeature representations. To handle this limitation, we substitute convolutional\ndescriptors for attention-guided features and propose an Attributes Grouping\nand Mining Hashing (AGMH), which groups and embeds the category-specific visual\nattributes in multiple descriptors to generate a comprehensive feature\nrepresentation for efficient fine-grained image retrieval. Specifically, an\nAttention Dispersion Loss (ADL) is designed to force the descriptors to attend\nto various local regions and capture diverse subtle details. Moreover, we\npropose a Stepwise Interactive External Attention (SIEA) to mine critical\nattributes in each descriptor and construct correlations between fine-grained\nattributes and objects. The attention mechanism is dedicated to learning\ndiscrete attributes, which will not cost additional computations in hash codes\ngeneration. Finally, the compact binary codes are learned by preserving\npairwise similarities. Experimental results demonstrate that AGMH consistently\nyields the best performance against state-of-the-art methods on fine-grained\nbenchmark datasets.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Compact Codes", "Evaluation"], "tsne_embedding": [-10.360703468322754, 10.521245002746582], "cluster": 8}, {"key": "lu2025online", "year": "2025", "citations": "128", "title": "Online Multi-modal Hashing With Dynamic Query-adaption", "abstract": "<p>Multi-modal hashing is an effective technique to support large-scale multimedia retrieval, due to its capability of encoding heterogeneous multi-modal features into compact and similarity-preserving binary codes. Although great progress has been achieved so far, existing methods still suffer from several problems, including: 1) All existing methods simply adopt fixed modality combination weights in online hashing process to generate the query hash codes. This strategy cannot adaptively capture the variations of different queries. 2) They either suffer from insufficient semantics (for unsupervised methods) or require high computation and storage cost (for the supervised methods, which rely on pair-wise semantic matrix). 3) They solve the hash codes with relaxed optimization strategy or bit-by-bit discrete optimization, which results in significant quantization loss or consumes considerable computation time. To address the above limitations, in this paper, we propose an Online Multi-modal Hashing with Dynamic Query-adaption (OMH-DQ) method in a novel fashion. Specifically, a self-weighted fusion strategy is designed to adaptively preserve the multi-modal feature information into hash codes by exploiting their complementarity. The hash codes are learned with the supervision of pair-wise semantic labels to enhance their discriminative capability, while avoiding the challenging symmetric similarity matrix factorization. Under such learning framework, the binary hash codes can be directly obtained with efficient operations and without quantization errors. Accordingly, our method can benefit from the semantic labels, and simultaneously, avoid the high computation complexity. Moreover, to accurately capture the query variations, at the online retrieval stage, we design a parameter-free online hashing module which can adaptively learn the query hash codes according to the dynamic query contents. Extensive experiments demonstrate the state-of-the-art performance of the proposed approach from various aspects.</p>\n", "tags": ["Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Alt", "SIGIR", "Quantization", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-4.852305889129639, -4.241593360900879], "cluster": 9}, {"key": "luo2016ssh", "year": "2016", "citations": "18", "title": "SSH (sketch, Shingle, & Hash) For Indexing Massive-scale Time Series", "abstract": "<p>Similarity search on time series is a frequent operation in large-scale\ndata-driven applications. Sophisticated similarity measures are standard for\ntime series matching, as they are usually misaligned. Dynamic Time Warping or\nDTW is the most widely used similarity measure for time series because it\ncombines alignment and matching at the same time. However, the alignment makes\nDTW slow. To speed up the expensive similarity search with DTW, branch and\nbound based pruning strategies are adopted. However, branch and bound based\npruning are only useful for very short queries (low dimensional time series),\nand the bounds are quite weak for longer queries. Due to the loose bounds\nbranch and bound pruning strategy boils down to a brute-force search.\n  To circumvent this issue, we design SSH (Sketch, Shingle, &amp; Hashing), an\nefficient and approximate hashing scheme which is much faster than the\nstate-of-the-art branch and bound searching technique: the UCR suite. SSH uses\na novel combination of sketching, shingling and hashing techniques to produce\n(probabilistic) indexes which align (near perfectly) with DTW similarity\nmeasure. The generated indexes are then used to create hash buckets for\nsub-linear search. Our results show that SSH is very effective for longer time\nsequence and prunes around 95% candidates, leading to the massive speedup in\nsearch with DTW. Empirical results on two large-scale benchmark time series\ndata show that our proposed method can be around 20 times faster than the\nstate-of-the-art package (UCR suite) without any significant loss in accuracy.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Efficiency And Optimization", "Similarity Search", "Evaluation"], "tsne_embedding": [-13.168220520019531, -21.154502868652344], "cluster": 1}, {"key": "luo2017arrays", "year": "2017", "citations": "5", "title": "Arrays Of (locality-sensitive) Count Estimators (ACE): High-speed Anomaly Detection Via Cache Lookups", "abstract": "<p>Anomaly detection is one of the frequent and important subroutines deployed\nin large-scale data processing systems. Even being a well-studied topic,\nexisting techniques for unsupervised anomaly detection require storing\nsignificant amounts of data, which is prohibitive from memory and latency\nperspective. In the big-data world existing methods fail to address the new set\nof memory and latency constraints. In this paper, we propose ACE (Arrays of\n(locality-sensitive) Count Estimators) algorithm that can be 60x faster than\nthe ELKI package~\\cite{DBLP:conf/ssd/AchtertBKSZ09}, which has the fastest\nimplementation of the unsupervised anomaly detection algorithms. ACE algorithm\nrequires less than \\(4MB\\) memory, to dynamically compress the full data\ninformation into a set of count arrays. These tiny \\(4MB\\) arrays of counts are\nsufficient for unsupervised anomaly detection. At the core of the ACE\nalgorithm, there is a novel statistical estimator which is derived from the\nsampling view of Locality Sensitive Hashing(LSH). This view is significantly\ndifferent and efficient than the widely popular view of LSH for near-neighbor\nsearch. We show the superiority of ACE algorithm over 11 popular baselines on 3\nbenchmark datasets, including the KDD-Cup99 data which is the largest available\nbenchmark comprising of more than half a million entries with ground truth\nanomaly labels.</p>\n", "tags": ["KDD", "DATASETS", "Locality Sensitive Hashing", "Hashing Methods", "Efficiency And Optimization", "Evaluation"], "tsne_embedding": [-6.841491222381592, -22.12046241760254], "cluster": 5}, {"key": "luo2018collaborative", "year": "2018", "citations": "14", "title": "Collaborative Learning For Extremely Low Bit Asymmetric Hashing", "abstract": "<p>Hashing techniques are in great demand for a wide range of real-world\napplications such as image retrieval and network compression. Nevertheless,\nexisting approaches could hardly guarantee a satisfactory performance with the\nextremely low-bit (e.g., 4-bit) hash codes due to the severe information loss\nand the shrink of the discrete solution space. In this paper, we propose a\nnovel \\textit{Collaborative Learning} strategy that is tailored for generating\nhigh-quality low-bit hash codes. The core idea is to jointly distill\nbit-specific and informative representations for a group of pre-defined code\nlengths. The learning of short hash codes among the group can benefit from the\nmanifold shared with other long codes, where multiple views from different hash\ncodes provide the supplementary guidance and regularization, making the\nconvergence faster and more stable. To achieve that, an asymmetric hashing\nframework with two variants of multi-head embedding structures is derived,\ntermed as Multi-head Asymmetric Hashing (MAH), leading to great efficiency of\ntraining and querying. Extensive experiments on three benchmark datasets have\nbeen conducted to verify the superiority of the proposed MAH, and have shown\nthat the 8-bit hash codes generated by MAH achieve \\(94.3%\\) of the MAP (Mean\nAverage Precision (MAP)) score on the CIFAR-10 dataset, which significantly\nsurpasses the performance of the 48-bit codes by the state-of-the-arts in image\nretrieval tasks.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-8.814727783203125, -2.6946070194244385], "cluster": 8}, {"key": "luo2019snap", "year": "2019", "citations": "37", "title": "Snap And Find: Deep Discrete Cross-domain Garment Image Retrieval", "abstract": "<p>With the increasing number of online stores, there is a pressing need for\nintelligent search systems to understand the item photos snapped by customers\nand search against large-scale product databases to find their desired items.\nHowever, it is challenging for conventional retrieval systems to match up the\nitem photos captured by customers and the ones officially released by stores,\nespecially for garment images. To bridge the customer- and store- provided\ngarment photos, existing studies have been widely exploiting the clothing\nattributes (\\textit{e.g.,} black) and landmarks (\\textit{e.g.,} collar) to\nlearn a common embedding space for garment representations. Unfortunately they\nomit the sequential correlation of attributes and consume large quantity of\nhuman labors to label the landmarks. In this paper, we propose a deep\nmulti-task cross-domain hashing termed \\textit{DMCH}, in which cross-domain\nembedding and sequential attribute learning are modeled simultaneously.\nSequential attribute learning not only provides the semantic guidance for\nembedding, but also generates rich attention on discriminative local details\n(\\textit{e.g.,} black buttons) of clothing items without requiring extra\nlandmark labels. This leads to promising performance and 306\\(\\times\\) boost on\nefficiency when compared with the state-of-the-art models, which is\ndemonstrated through rigorous experiments on two public fashion datasets.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Evaluation"], "tsne_embedding": [-23.494735717773438, 10.72488021850586], "cluster": 3}, {"key": "luo2020challenge", "year": "2020", "citations": "9", "title": "Challenge Report: Recognizing Families In The Wild Data Challenge", "abstract": "<p>This paper is a brief report to our submission to the Recognizing Families In\nthe Wild Data Challenge (4th Edition), in conjunction with FG 2020 Forum.\nAutomatic kinship recognition has attracted many researchers\u2019 attention for its\nfull application, but it is still a very challenging task because of the\nlimited information that can be used to determine whether a pair of faces are\nblood relatives or not. In this paper, we studied previous methods and proposed\nour method. We try many methods, like deep metric learning-based, to extract\ndeep embedding feature for every image, then determine if they are blood\nrelatives by Euclidean distance or method based on classes. Finally, we find\nsome tricks like sampling more negative samples and high resolution that can\nhelp get better performance. Moreover, we proposed a symmetric network with a\nbinary classification based method to get our best score in all tasks.</p>\n", "tags": ["Evaluation", "Distance Metric Learning"], "tsne_embedding": [10.684525489807129, 6.514316082000732], "cluster": 4}, {"key": "luo2020cimon", "year": "2020", "citations": "26", "title": "CIMON: Towards High-quality Hash Codes", "abstract": "<p>Recently, hashing is widely used in approximate nearest neighbor search for\nits storage and computational efficiency. Most of the unsupervised hashing\nmethods learn to map images into semantic similarity-preserving hash codes by\nconstructing local semantic similarity structure from the pre-trained model as\nthe guiding information, i.e., treating each point pair similar if their\ndistance is small in feature space. However, due to the inefficient\nrepresentation ability of the pre-trained model, many false positives and\nnegatives in local semantic similarity will be introduced and lead to error\npropagation during the hash code learning. Moreover, few of the methods\nconsider the robustness of models, which will cause instability of hash codes\nto disturbance. In this paper, we propose a new method named\n{\\textbf{C}}omprehensive s{\\textbf{I}}milarity {\\textbf{M}}ining and\nc{\\textbf{O}}nsistency lear{\\textbf{N}}ing (CIMON). First, we use global\nrefinement and similarity statistical distribution to obtain reliable and\nsmooth guidance. Second, both semantic and contrastive consistency learning are\nintroduced to derive both disturb-invariant and discriminative hash codes.\nExtensive experiments on several benchmark datasets show that the proposed\nmethod outperforms a wide range of state-of-the-art methods in both retrieval\nperformance and robustness.</p>\n", "tags": ["DATASETS", "Evaluation", "IJCAI", "Robustness", "Hashing Methods", "Efficiency And Optimization", "AAAI"], "tsne_embedding": [-8.230274200439453, -1.5591703653335571], "cluster": 8}, {"key": "luo2020survey", "year": "2020", "citations": "113", "title": "A Survey On Deep Hashing Methods", "abstract": "<p>Nearest neighbor search aims to obtain the samples in the database with the\nsmallest distances from them to the queries, which is a basic task in a range\nof fields, including computer vision and data mining. Hashing is one of the\nmost widely used methods for its computational and storage efficiency. With the\ndevelopment of deep learning, deep hashing methods show more advantages than\ntraditional methods. In this survey, we detailedly investigate current deep\nhashing algorithms including deep supervised hashing and deep unsupervised\nhashing. Specifically, we categorize deep supervised hashing methods into\npairwise methods, ranking-based methods, pointwise methods as well as\nquantization according to how measuring the similarities of the learned hash\ncodes. Moreover, deep unsupervised hashing is categorized into similarity\nreconstruction-based methods, pseudo-label-based methods and prediction-free\nself-supervised learning-based methods based on their semantic learning\nmanners. We also introduce three related important topics including\nsemi-supervised deep hashing, domain adaption deep hashing and multi-modal deep\nhashing. Meanwhile, we present some commonly used public datasets and the\nscheme to measure the performance of deep hashing algorithms. Finally, we\ndiscuss some potential research directions in conclusion.</p>\n", "tags": ["Survey Paper", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Neural Hashing", "Quantization", "Evaluation"], "tsne_embedding": [0.29035964608192444, -4.387257099151611], "cluster": 9}, {"key": "luo2024fine", "year": "2024", "citations": "38", "title": "Fine-grained Embedding Dimension Optimization During Training For Recommender Systems", "abstract": "<p>Huge embedding tables in modern deep learning recommender models (DLRM)\nrequire prohibitively large memory during training and inference. This paper\nproposes FIITED, a system to automatically reduce the memory footprint via\nFIne-grained In-Training Embedding Dimension pruning. By leveraging the key\ninsight that embedding vectors are not equally important, FIITED adaptively\nadjusts the dimension of each individual embedding vector during model\ntraining, assigning larger dimensions to more important embeddings while\nadapting to dynamic changes in data. We prioritize embedding dimensions with\nhigher frequencies and gradients as more important. To enable efficient pruning\nof embeddings and their dimensions during model training, we propose an\nembedding storage system based on virtually-hashed physically-indexed hash\ntables. Experiments on two industry models and months of realistic datasets\nshow that FIITED can reduce DLRM embedding size by more than 65% while\npreserving model quality, outperforming state-of-the-art in-training embedding\npruning methods. On public datasets, FIITED can reduce the size of embedding\ntables by 2.1x to 800x with negligible accuracy drop, while improving model\nthroughput.</p>\n", "tags": ["Efficiency And Optimization", "DATASETS", "Recommender Systems"], "tsne_embedding": [-7.922068119049072, -15.643269538879395], "cluster": 9}, {"key": "luo2024learning", "year": "2024", "citations": "705", "title": "Learning To Hash For Recommendation: A Survey", "abstract": "<p>With the explosive growth of users and items, Recommender Systems (RS) are\nfacing unprecedented challenges on both retrieval efficiency and storage cost.\nFortunately, Learning to Hash (L2H) techniques have been shown as a promising\nsolution to address the two dilemmas, whose core idea is encoding\nhigh-dimensional data into compact hash codes. To this end, L2H for RS (HashRec\nfor short) has recently received widespread attention to support large-scale\nrecommendations. In this survey, we present a comprehensive review of current\nHashRec algorithms. Specifically, we first introduce the commonly used\ntwo-tower models in the recall stage and identify two search strategies\nfrequently employed in L2H. Then, we categorize prior works into two-tier\ntaxonomy based on: (i) the type of loss function and (ii) the optimization\nstrategy. We also introduce some commonly used evaluation metrics to measure\nthe performance of HashRec algorithms. Finally, we shed light on the\nlimitations of the current research and outline the future research directions.\nFurthermore, the summary of HashRec methods reviewed in this survey can be\nfound at\n\\href{https://github.com/Luo-Fangyuan/HashRec}{https://github.com/Luo-Fangyuan/HashRec}.</p>\n", "tags": ["Survey Paper", "Hashing Methods", "Efficiency And Optimization", "Recommender Systems", "Evaluation"], "tsne_embedding": [-15.326371192932129, -11.03915786743164], "cluster": 1}, {"key": "luo2025fast", "year": "2025", "citations": "89", "title": "Fast Scalable Supervised Hashing", "abstract": "<p>Despite significant progress in supervised hashing, there are three\ncommon limitations of existing methods. First, most pioneer methods discretely learn hash codes bit by bit, making the learning\nprocedure rather time-consuming. Second, to reduce the large complexity of the n by n pairwise similarity matrix, most methods apply\nsampling strategies during training, which inevitably results in information loss and suboptimal performance; some recent methods\ntry to replace the large matrix with a smaller one, but the size is\nstill large. Third, among the methods that leverage the pairwise\nsimilarity matrix, most of them only encode the semantic label\ninformation in learning the hash codes, failing to fully capture\nthe characteristics of data. In this paper, we present a novel supervised hashing method, called Fast Scalable Supervised Hashing\n(FSSH), which circumvents the use of the large similarity matrix by\nintroducing a pre-computed intermediate term whose size is independent with the size of training data. Moreover, FSSH can learn\nthe hash codes with not only the semantic information but also\nthe features of data. Extensive experiments on three widely used\ndatasets demonstrate its superiority over several state-of-the-art\nmethods in both accuracy and scalability. Our experiment codes\nare available at: https://lcbwlx.wixsite.com/fssh.</p>\n", "tags": ["SIGIR", "Hashing Methods", "Evaluation", "DATASETS"], "tsne_embedding": [-4.910157680511475, -10.23351764678955], "cluster": 9}, {"key": "lv2025multi", "year": "2025", "citations": "620", "title": "Multi-probe LSH: Efficient Indexing For High-dimensional Similarity Search", "abstract": "<p>Similarity indices for high-dimensional data are very desirable for building content-based search systems for featurerich data such as audio, images, videos, and other sensor\ndata. Recently, locality sensitive hashing (LSH) and its\nvariations have been proposed as indexing techniques for\napproximate similarity search. A significant drawback of\nthese approaches is the requirement for a large number of\nhash tables in order to achieve good search quality. This paper proposes a new indexing scheme called multi-probe LSH\nthat overcomes this drawback. Multi-probe LSH is built on\nthe well-known LSH technique, but it intelligently probes\nmultiple buckets that are likely to contain query results in\na hash table. Our method is inspired by and improves upon\nrecent theoretical work on entropy-based LSH designed to\nreduce the space requirement of the basic LSH method. We\nhave implemented the multi-probe LSH method and evaluated the implementation with two different high-dimensional\ndatasets. Our evaluation shows that the multi-probe LSH\nmethod substantially improves upon previously proposed\nmethods in both space and time efficiency. To achieve the\nsame search quality, multi-probe LSH has a similar timeefficiency as the basic LSH method while reducing the number of hash tables by an order of magnitude. In comparison\nwith the entropy-based LSH method, to achieve the same\nsearch quality, multi-probe LSH uses less query time and 5\nto 8 times fewer number of hash tables.</p>\n", "tags": ["Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Similarity Search", "Evaluation"], "tsne_embedding": [8.980138778686523, 0.7648383975028992], "cluster": 4}, {"key": "ma2019hierarchy", "year": "2019", "citations": "22", "title": "Hierarchy Neighborhood Discriminative Hashing For An Unified View Of Single-label And Multi-label Image Retrieval", "abstract": "<p>Recently, deep supervised hashing methods have become popular for large-scale\nimage retrieval task. To preserve the semantic similarity notion between\nexamples, they typically utilize the pairwise supervision or the triplet\nsupervised information for hash learning. However, these methods usually ignore\nthe semantic class information which can help the improvement of the semantic\ndiscriminative ability of hash codes. In this paper, we propose a novel\nhierarchy neighborhood discriminative hashing method. Specifically, we\nconstruct a bipartite graph to build coarse semantic neighbourhood relationship\nbetween the sub-class feature centers and the embeddings features. Moreover, we\nutilize the pairwise supervised information to construct the fined semantic\nneighbourhood relationship between embeddings features. Finally, we propose a\nhierarchy neighborhood discriminative hashing loss to unify the single-label\nand multilabel image retrieval problem with a one-stream deep neural network\narchitecture. Experimental results on two largescale datasets demonstrate that\nthe proposed method can outperform the state-of-the-art hashing methods.</p>\n", "tags": ["DATASETS", "IJCAI", "Hashing Methods", "Image Retrieval", "AAAI"], "tsne_embedding": [-4.52012825012207, 1.0623153448104858], "cluster": 8}, {"key": "ma2021rank", "year": "2021", "citations": "14", "title": "Rank-consistency Deep Hashing For Scalable Multi-label Image Search", "abstract": "<p>As hashing becomes an increasingly appealing technique for large-scale image\nretrieval, multi-label hashing is also attracting more attention for the\nability to exploit multi-level semantic contents. In this paper, we propose a\nnovel deep hashing method for scalable multi-label image search. Unlike\nexisting approaches with conventional objectives such as contrast and triplet\nlosses, we employ a rank list, rather than pairs or triplets, to provide\nsufficient global supervision information for all the samples. Specifically, a\nnew rank-consistency objective is applied to align the similarity orders from\ntwo spaces, the original space and the hamming space. A powerful loss function\nis designed to penalize the samples whose semantic similarity and hamming\ndistance are mismatched in two spaces. Besides, a multi-label softmax\ncross-entropy loss is presented to enhance the discriminative power with a\nconcise formulation of the derivative function. In order to manipulate the\nneighborhood structure of the samples with different labels, we design a\nmulti-label clustering loss to cluster the hashing vectors of the samples with\nthe same labels by reducing the distances between the samples and their\nmultiple corresponding class centers. The state-of-the-art experimental results\nachieved on three public multi-label datasets, MIRFLICKR-25K, IAPRTC12 and\nNUS-WIDE, demonstrate the effectiveness of the proposed method.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Neural Hashing", "Hashing Methods"], "tsne_embedding": [1.1480075120925903, 6.556591510772705], "cluster": 4}, {"key": "ma2022deep", "year": "2022", "citations": "16", "title": "Deep Forest With Hashing Screening And Window Screening", "abstract": "<p>As a novel deep learning model, gcForest has been widely used in various\napplications. However, the current multi-grained scanning of gcForest produces\nmany redundant feature vectors, and this increases the time cost of the model.\nTo screen out redundant feature vectors, we introduce a hashing screening\nmechanism for multi-grained scanning and propose a model called HW-Forest which\nadopts two strategies, hashing screening and window screening. HW-Forest\nemploys perceptual hashing algorithm to calculate the similarity between\nfeature vectors in hashing screening strategy, which is used to remove the\nredundant feature vectors produced by multi-grained scanning and can\nsignificantly decrease the time cost and memory consumption. Furthermore, we\nadopt a self-adaptive instance screening strategy to improve the performance of\nour approach, called window screening, which can achieve higher accuracy\nwithout hyperparameter tuning on different datasets. Our experimental results\nshow that HW-Forest has higher accuracy than other models, and the time cost is\nalso reduced.</p>\n", "tags": ["DATASETS", "Tools & Libraries", "Hashing Methods", "Evaluation"], "tsne_embedding": [3.207836866378784, 8.029521942138672], "cluster": 4}, {"key": "ma2023anserini", "year": "2023", "citations": "5", "title": "Anserini Gets Dense Retrieval: Integration Of Lucene's HNSW Indexes", "abstract": "<p>Anserini is a Lucene-based toolkit for reproducible information retrieval\nresearch in Java that has been gaining traction in the community. It provides\nretrieval capabilities for both \u201ctraditional\u201d bag-of-words retrieval models\nsuch as BM25 as well as retrieval using learned sparse representations such as\nSPLADE. With Pyserini, which provides a Python interface to Anserini, users\ngain access to both sparse and dense retrieval models, as Pyserini implements\nbindings to the Faiss vector search library alongside Lucene inverted indexes\nin a uniform, consistent interface. Nevertheless, hybrid fusion techniques that\nintegrate sparse and dense retrieval models need to stitch together results\nfrom two completely different \u201csoftware stacks\u201d, which creates unnecessary\ncomplexities and inefficiencies. However, the introduction of HNSW indexes for\ndense vector search in Lucene promises the integration of both dense and sparse\nretrieval within a single software framework. We explore exactly this\nintegration in the context of Anserini. Experiments on the MS MARCO passage and\nBEIR datasets show that our Anserini HNSW integration supports (reasonably)\neffective and (reasonably) efficient approximate nearest neighbor search for\ndense retrieval models, using only Lucene.</p>\n", "tags": ["CIKM", "DATASETS", "Tools & Libraries", "Graph Based ANN"], "tsne_embedding": [10.293984413146973, -9.211612701416016], "cluster": 2}, {"key": "ma2025harr", "year": "2025", "citations": "5", "title": "HARR: Learning Discriminative And High-quality Hash Codes For Image Retrieval", "abstract": "<p>This article studies deep unsupervised hashing, which has attracted increasing attention in large-scale image retrieval. The majority of recent approaches usually reconstruct semantic similarity information, which then guides the hash code learning. However, they still fail to achieve satisfactory performance in reality for two reasons. On the one hand, without accurate supervised information, these methods usually fail to produce independent and robust hash codes with semantics information well preserved, which may hinder effective image retrieval. On the other hand, due to discrete constraints, how to effectively optimize the hashing network in an end-to-end manner with small quantization errors remains a problem. To address these difficulties, we propose a novel unsupervised hashing method called HARR to learn discriminative and high-quality hash codes. To comprehensively explore semantic similarity structure, HARR adopts the Winner-Take-All hash to model the similarity structure. Then similarity-preserving hash codes are learned under the reliable guidance of the reconstructed similarity structure. Additionally, we improve the quality of hash codes by a bit correlation reduction module, which forces the cross-correlation matrix between a batch of hash codes under different augmentations to approach the identity matrix. In this way, the generated hash bits are expected to be invariant to disturbances with minimal redundancy, which can be further interpreted as an instantiation of the information bottleneck principle. Finally, for effective hashing network training, we minimize the cosine distances between real-value network outputs and their binary codes for small quantization errors. Extensive experiments demonstrate the effectiveness of our proposed HARR.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Compact Codes", "Quantization", "Evaluation"], "tsne_embedding": [-7.256557941436768, -1.674925684928894], "cluster": 8}, {"key": "ma2025progressive", "year": "2025", "citations": "18", "title": "Progressive Generative Hashing For Image Retrieval", "abstract": "<p>Recent years have witnessed the success of the emerging hashing techniques in large-scale image\nretrieval. Owing to the great learning capacity,\ndeep hashing has become one of the most promising solutions, and achieved attractive performance\nin practice. However, without semantic label information, the unsupervised deep hashing still remains\nan open question. In this paper, we propose a novel\nprogressive generative hashing (PGH) framework\nto help learn a discriminative hashing network in an\nunsupervised way. Different from existing studies,\nit first treats the hash codes as a kind of semantic\ncondition for the similar image generation, and simultaneously feeds the original image and its codes\ninto the generative adversarial networks (GANs).\nThe real images together with the synthetic ones\ncan further help train a discriminative hashing network based on a triplet loss. By iteratively inputting\nthe learnt codes into the hash conditioned GANs, we can progressively enable the hashing network\nto discover the semantic relations. Extensive experiments on the widely-used image datasets demonstrate that PGH can significantly outperform stateof-the-art unsupervised hashing methods.</p>\n", "tags": ["DATASETS", "Evaluation", "IJCAI", "Robustness", "Neural Hashing", "Hashing Methods", "Distance Metric Learning", "Image Retrieval", "Tools & Libraries", "AAAI"], "tsne_embedding": [-14.878853797912598, -3.4107677936553955], "cluster": 1}, {"key": "macdonald2021approximate", "year": "2021", "citations": "14", "title": "On Approximate Nearest Neighbour Selection For Multi-stage Dense Retrieval", "abstract": "<p>Dense retrieval, which describes the use of contextualised language models\nsuch as BERT to identify documents from a collection by leveraging approximate\nnearest neighbour (ANN) techniques, has been increasing in popularity. Two\nfamilies of approaches have emerged, depending on whether documents and queries\nare represented by single or multiple embeddings. ColBERT, the exemplar of the\nlatter, uses an ANN index and approximate scores to identify a set of candidate\ndocuments for each query embedding, which are then re-ranked using accurate\ndocument representations. In this manner, a large number of documents can be\nretrieved for each query, hindering the efficiency of the approach. In this\nwork, we investigate the use of ANN scores for ranking the candidate documents,\nin order to decrease the number of candidate documents being fully scored.\nExperiments conducted on the MSMARCO passage ranking corpus demonstrate that,\nby cutting of the candidate set by using the approximate scores to only 200\ndocuments, we can still obtain an effective ranking without statistically\nsignificant differences in effectiveness, and resulting in a 2x speedup in\nefficiency.</p>\n", "tags": ["Efficiency And Optimization", "Vector Indexing", "CIKM", "Similarity Search"], "tsne_embedding": [10.492684364318848, -5.3565592765808105], "cluster": 2}, {"key": "macgregor2023fast", "year": "2023", "citations": "12", "title": "Fast Approximation Of Similarity Graphs With Kernel Density Estimation", "abstract": "<p>Constructing a similarity graph from a set \\(X\\) of data points in\n\\(\\mathbb{R}^d\\) is the first step of many modern clustering algorithms. However,\ntypical constructions of a similarity graph have high time complexity, and a\nquadratic space dependency with respect to \\(|X|\\). We address this limitation\nand present a new algorithmic framework that constructs a sparse approximation\nof the fully connected similarity graph while preserving its cluster structure.\nOur presented algorithm is based on the kernel density estimation problem, and\nis applicable for arbitrary kernel functions. We compare our designed algorithm\nwith the well-known implementations from the scikit-learn library and the FAISS\nlibrary, and find that our method significantly outperforms the implementation\nfrom both libraries on a variety of datasets.</p>\n", "tags": ["DATASETS", "Tools & Libraries"], "tsne_embedding": [18.58481788635254, 6.797547817230225], "cluster": 0}, {"key": "magliani2018efficient", "year": "2018", "citations": "8", "title": "Efficient Nearest Neighbors Search For Large-scale Landmark Recognition", "abstract": "<p>The problem of landmark recognition has achieved excellent results in\nsmall-scale datasets. When dealing with large-scale retrieval, issues that were\nirrelevant with small amount of data, quickly become fundamental for an\nefficient retrieval phase. In particular, computational time needs to be kept\nas low as possible, whilst the retrieval accuracy has to be preserved as much\nas possible. In this paper we propose a novel multi-index hashing method called\nBag of Indexes (BoI) for Approximate Nearest Neighbors (ANN) search. It allows\nto drastically reduce the query time and outperforms the accuracy results\ncompared to the state-of-the-art methods for large-scale landmark recognition.\nIt has been demonstrated that this family of algorithms can be applied on\ndifferent embedding techniques like VLAD and R-MAC obtaining excellent results\nin very short times on different public datasets: Holidays+Flickr1M, Oxford105k\nand Paris106k.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "Similarity Search", "Vector Indexing"], "tsne_embedding": [10.761183738708496, -6.1629319190979], "cluster": 2}, {"key": "magliani2019efficient", "year": "2019", "citations": "8", "title": "An Efficient Approximate Knn Graph Method For Diffusion On Image Retrieval", "abstract": "<p>The application of the diffusion in many computer vision and artificial\nintelligence projects has been shown to give excellent improvements in\nperformance. One of the main bottlenecks of this technique is the quadratic\ngrowth of the kNN graph size due to the high-quantity of new connections\nbetween nodes in the graph, resulting in long computation times. Several\nstrategies have been proposed to address this, but none are effective and\nefficient. Our novel technique, based on LSH projections, obtains the same\nperformance as the exact kNN graph after diffusion, but in less time\n(approximately 18 times faster on a dataset of a hundred thousand images). The\nproposed method was validated and compared with other state-of-the-art on\nseveral public image datasets, including Oxford5k, Paris6k, and Oxford105k.</p>\n", "tags": ["Image Retrieval", "Locality Sensitive Hashing", "Evaluation", "DATASETS"], "tsne_embedding": [16.83204460144043, 19.85489273071289], "cluster": 0}, {"key": "maier2017dynamic", "year": "2017", "citations": "9", "title": "Dynamic Space Efficient Hashing", "abstract": "<p>We consider space efficient hash tables that can grow and shrink dynamically\nand are always highly space efficient, i.e., their space consumption is always\nclose to the lower bound even while growing and when taking into account\nstorage that is only needed temporarily. None of the traditionally used hash\ntables have this property. We show how known approaches like linear probing and\nbucket cuckoo hashing can be adapted to this scenario by subdividing them into\nmany subtables or using virtual memory overcommitting. However, these rather\nstraightforward solutions suffer from slow amortized insertion times due to\nfrequent reallocation in small increments.\n  Our main result is DySECT ({\\bf Dy}namic {\\bf S}pace {\\bf E}fficient {\\bf\nC}uckoo {\\bf T}able) which avoids these problems. DySECT consists of many\nsubtables which grow by doubling their size. The resulting inhomogeneity in\nsubtable sizes is equalized by the flexibility available in bucket cuckoo\nhashing where each element can go to several buckets each of which containing\nseveral cells. Experiments indicate that DySECT works well with load factors up\nto 98%. With up to 2.7 times better performance than the next best solution.</p>\n", "tags": ["Evaluation", "Hashing Methods", "ALT"], "tsne_embedding": [-6.619520664215088, -23.973352432250977], "cluster": 5}, {"key": "malali2022learning", "year": "2022", "citations": "8", "title": "Learning To Embed Semantic Similarity For Joint Image-text Retrieval", "abstract": "<p>We present a deep learning approach for learning the joint semantic\nembeddings of images and captions in a Euclidean space, such that the semantic\nsimilarity is approximated by the L2 distances in the embedding space. For\nthat, we introduce a metric learning scheme that utilizes multitask learning to\nlearn the embedding of identical semantic concepts using a center loss. By\nintroducing a differentiable quantization scheme into the end-to-end trainable\nnetwork, we derive a semantic embedding of semantically similar concepts in\nEuclidean space. We also propose a novel metric learning formulation using an\nadaptive margin hinge loss, that is refined during the training phase. The\nproposed scheme was applied to the MS-COCO, Flicke30K and Flickr8K datasets,\nand was shown to compare favorably with contemporary state-of-the-art\napproaches.</p>\n", "tags": ["Text Retrieval", "DATASETS", "Quantization", "Distance Metric Learning"], "tsne_embedding": [-23.259666442871094, 7.215405464172363], "cluster": 3}, {"key": "malkov2016efficient", "year": "2016", "citations": "1063", "title": "Efficient And Robust Approximate Nearest Neighbor Search Using Hierarchical Navigable Small World Graphs", "abstract": "<p>We present a new approach for the approximate K-nearest neighbor search based\non navigable small world graphs with controllable hierarchy (Hierarchical NSW,\nHNSW). The proposed solution is fully graph-based, without any need for\nadditional search structures, which are typically used at the coarse search\nstage of the most proximity graph techniques. Hierarchical NSW incrementally\nbuilds a multi-layer structure consisting from hierarchical set of proximity\ngraphs (layers) for nested subsets of the stored elements. The maximum layer in\nwhich an element is present is selected randomly with an exponentially decaying\nprobability distribution. This allows producing graphs similar to the\npreviously studied Navigable Small World (NSW) structures while additionally\nhaving the links separated by their characteristic distance scales. Starting\nsearch from the upper layer together with utilizing the scale separation boosts\nthe performance compared to NSW and allows a logarithmic complexity scaling.\nAdditional employment of a heuristic for selecting proximity graph neighbors\nsignificantly increases performance at high recall and in case of highly\nclustered data. Performance evaluation has demonstrated that the proposed\ngeneral metric space search index is able to strongly outperform previous\nopensource state-of-the-art vector-only approaches. Similarity of the algorithm\nto the skip list structure allows straightforward balanced distributed\nimplementation.</p>\n", "tags": ["Graph Based ANN", "Evaluation"], "tsne_embedding": [18.61590576171875, 7.447945594787598], "cluster": 0}, {"key": "mandal2020novel", "year": "2020", "citations": "5", "title": "A Novel Incremental Cross-modal Hashing Approach", "abstract": "<p>Cross-modal retrieval deals with retrieving relevant items from one modality,\nwhen provided with a search query from another modality. Hashing techniques,\nwhere the data is represented as binary bits have specifically gained\nimportance due to the ease of storage, fast computations and high accuracy. In\nreal world, the number of data categories is continuously increasing, which\nrequires algorithms capable of handling this dynamic scenario. In this work, we\npropose a novel incremental cross-modal hashing algorithm termed \u201ciCMH\u201d, which\ncan adapt itself to handle incoming data of new categories. The proposed\napproach consists of two sequential stages, namely, learning the hash codes and\ntraining the hash functions. At every stage, a small amount of old category\ndata termed \u201cexemplars\u201d is is used so as not to forget the old data while\ntrying to learn for the new incoming data, i.e. to avoid catastrophic\nforgetting. In the first stage, the hash codes for the exemplars is used, and\nsimultaneously, hash codes for the new data is computed such that it maintains\nthe semantic relations with the existing data. For the second stage, we propose\nboth a non-deep and deep architectures to learn the hash functions effectively.\nExtensive experiments across a variety of cross-modal datasets and comparisons\nwith state-of-the-art cross-modal algorithms shows the usefulness of our\napproach.</p>\n", "tags": ["Multimodal Retrieval", "DATASETS", "Hashing Methods", "Evaluation"], "tsne_embedding": [-10.666060447692871, -10.192681312561035], "cluster": 1}, {"key": "mandarapu2023arkade", "year": "2023", "citations": "5", "title": "Arkade: K-nearest Neighbor Search With Non-euclidean Distances Using GPU Ray Tracing", "abstract": "<p>High-performance implementations of \\(k\\)-Nearest Neighbor Search (\\(k\\)NN) in\nlow dimensions use tree-based data structures. Tree algorithms are hard to\nparallelize on GPUs due to their irregularity. However, newer Nvidia GPUs offer\nhardware support for tree operations through ray-tracing cores. Recent works\nhave proposed using RT cores to implement \\(k\\)NN search, but they all have a\nhardware-imposed constraint on the distance metric used in the search \u2013 the\nEuclidean distance. We propose and implement two reductions to support \\(k\\)NN\nfor a broad range of distances other than the Euclidean distance: Arkade\nFilter-Refine and Arkade Monotone Transformation, each of which allows\nnon-Euclidean distance-based nearest neighbor queries to be performed in terms\nof the Euclidean distance. With our reductions, we observe that \\(k\\)NN search\ntime speedups range between \\(1.6\\)x-\\(200\\)x and \\(1.3\\)x-\\(33.1\\)x over various\nstate-of-the-art GPU shader core and RT core baselines, respectively. In\nevaluation, we provide several insights on RT architectures\u2019 ability to\nefficiently build and traverse the tree by analyzing the \\(k\\)NN search time\ntrends.</p>\n", "tags": ["Tree Based ANN", "Distance Metric Learning", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [23.563085556030273, 3.611361265182495], "cluster": 7}, {"key": "manocha2017content", "year": "2017", "citations": "38", "title": "Content-based Representations Of Audio Using Siamese Neural Networks", "abstract": "<p>In this paper, we focus on the problem of content-based retrieval for audio,\nwhich aims to retrieve all semantically similar audio recordings for a given\naudio clip query. This problem is similar to the problem of query by example of\naudio, which aims to retrieve media samples from a database, which are similar\nto the user-provided example. We propose a novel approach which encodes the\naudio into a vector representation using Siamese Neural Networks. The goal is\nto obtain an encoding similar for files belonging to the same audio class, thus\nallowing retrieval of semantically similar audio. Using simple similarity\nmeasures such as those based on simple euclidean distance and cosine similarity\nwe show that these representations can be very effectively used for retrieving\nrecordings similar in audio content.</p>\n", "tags": ["ICASSP", "Distance Metric Learning"], "tsne_embedding": [0.8186268210411072, 2.984898090362549], "cluster": 4}, {"key": "manohar2023parlayann", "year": "2023", "citations": "5", "title": "Parlayann: Scalable And Deterministic Parallel Graph-based Approximate Nearest Neighbor Search Algorithms", "abstract": "<p>Approximate nearest-neighbor search (ANNS) algorithms are a key part of the\nmodern deep learning stack due to enabling efficient similarity search over\nhigh-dimensional vector space representations (i.e., embeddings) of data. Among\nvarious ANNS algorithms, graph-based algorithms are known to achieve the best\nthroughput-recall tradeoffs. Despite the large scale of modern ANNS datasets,\nexisting parallel graph based implementations suffer from significant\nchallenges to scale to large datasets due to heavy use of locks and other\nsequential bottlenecks, which 1) prevents them from efficiently scaling to a\nlarge number of processors, and 2) results in nondeterminism that is\nundesirable in certain applications.\n  In this paper, we introduce ParlayANN, a library of deterministic and\nparallel graph-based approximate nearest neighbor search algorithms, along with\na set of useful tools for developing such algorithms. In this library, we\ndevelop novel parallel implementations for four state-of-the-art graph-based\nANNS algorithms that scale to billion-scale datasets. Our algorithms are\ndeterministic and achieve high scalability across a diverse set of challenging\ndatasets. In addition to the new algorithmic ideas, we also conduct a detailed\nexperimental study of our new algorithms as well as two existing non-graph\napproaches. Our experimental results both validate the effectiveness of our new\ntechniques, and lead to a comprehensive comparison among ANNS algorithms on\nlarge scale datasets with a list of interesting findings.</p>\n", "tags": ["DATASETS", "Graph Based ANN", "Large Scale Search", "Similarity Search", "Tools & Libraries", "Evaluation"], "tsne_embedding": [18.243085861206055, 15.457316398620605], "cluster": 0}, {"key": "marchet2016resource", "year": "2016", "citations": "8", "title": "A Resource-frugal Probabilistic Dictionary And Applications In (meta)genomics", "abstract": "<p>Genomic and metagenomic fields, generating huge sets of short genomic\nsequences, brought their own share of high performance problems. To extract\nrelevant pieces of information from the huge data sets generated by current\nsequencing techniques, one must rely on extremely scalable methods and\nsolutions. Indexing billions of objects is a task considered too expensive\nwhile being a fundamental need in this field. In this paper we propose a\nstraightforward indexing structure that scales to billions of element and we\npropose two direct applications in genomics and metagenomics. We show that our\nproposal solves problem instances for which no other known solution scales-up.\nWe believe that many tools and applications could benefit from either the\nfundamental data structure we provide or from the applications developed from\nthis structure.</p>\n", "tags": ["Evaluation"], "tsne_embedding": [8.818779945373535, -17.043119430541992], "cluster": 2}, {"key": "marchet2017resource", "year": "2017", "citations": "26", "title": "A Resource-frugal Probabilistic Dictionary And Applications In Bioinformatics", "abstract": "<p>Indexing massive data sets is extremely expensive for large scale problems.\nIn many fields, huge amounts of data are currently generated, however\nextracting meaningful information from voluminous data sets, such as computing\nsimilarity between elements, is far from being trivial. It remains nonetheless\na fundamental need. This work proposes a probabilistic data structure based on\na minimal perfect hash function for indexing large sets of keys. Our structure\nout-compete the hash table for construction, query times and for memory usage,\nin the case of the indexation of a static set. To illustrate the impact of\nalgorithms performances, we provide two applications based on similarity\ncomputation between collections of sequences, and for which this calculation is\nan expensive but required operation. In particular, we show a practical case in\nwhich other bioinformatics tools fail to scale up the tested data set or\nprovide lower recall quality results.</p>\n", "tags": ["Hashing Methods", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [9.324036598205566, -16.87372589111328], "cluster": 2}, {"key": "markchit2019effective", "year": "2019", "citations": "6", "title": "Effective And Efficient Indexing In Cross-modal Hashing-based Datasets", "abstract": "<p>To overcome the barrier of storage and computation, the hashing technique has\nbeen widely used for nearest neighbor search in multimedia retrieval\napplications recently. Particularly, cross-modal retrieval that searches across\ndifferent modalities becomes an active but challenging problem. Although dozens\nof cross-modal hashing algorithms are proposed to yield compact binary codes,\nthe exhaustive search is impractical for the real-time purpose, and Hamming\ndistance computation suffers inaccurate results. In this paper, we propose a\nnovel search method that utilizes a probability-based index scheme over binary\nhash codes in cross-modal retrieval. The proposed hash code indexing scheme\nexploits a few binary bits of the hash code as the index code. We construct an\ninverted index table based on index codes and train a neural network to improve\nthe indexing accuracy and efficiency. Experiments are performed on two\nbenchmark datasets for retrieval across image and text modalities, where hash\ncodes are generated by three cross-modal hashing methods. Results show the\nproposed method effectively boost the performance on these hash methods.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Alt", "Multimodal Retrieval", "Evaluation"], "tsne_embedding": [-3.579192638397217, 0.21819613873958588], "cluster": 8}, {"key": "marshall2017exact", "year": "2017", "citations": "25", "title": "Exact Clustering In Linear Time", "abstract": "<p>The time complexity of data clustering has been viewed as fundamentally\nquadratic, slowing with the number of data items, as each item is compared for\nsimilarity to preceding items. Clustering of large data sets has been\ninfeasible without resorting to probabilistic methods or to capping the number\nof clusters. Here we introduce MIMOSA, a novel class of algorithms which\nachieve linear time computational complexity on clustering tasks. MIMOSA\nalgorithms mark and match partial-signature keys in a hash table to obtain\nexact, error-free cluster retrieval. Benchmark measurements, on clustering a\ndata set of 10,000,000 news articles by news topic, found that a MIMOSA\nimplementation finished more than four orders of magnitude faster than a\nstandard centroid implementation.</p>\n", "tags": ["AAAI", "Evaluation"], "tsne_embedding": [6.079675197601318, -15.991735458374023], "cluster": 2}, {"key": "massarelli2018safe", "year": "2018", "citations": "155", "title": "SAFE: Self-attentive Function Embeddings For Binary Similarity", "abstract": "<p>The binary similarity problem consists in determining if two functions are\nsimilar by only considering their compiled form. Advanced techniques for binary\nsimilarity recently gained momentum as they can be applied in several fields,\nsuch as copyright disputes, malware analysis, vulnerability detection, etc.,\nand thus have an immediate practical impact. Current solutions compare\nfunctions by first transforming their binary code in multi-dimensional vector\nrepresentations (embeddings), and then comparing vectors through simple and\nefficient geometric operations. However, embeddings are usually derived from\nbinary code using manual feature extraction, that may fail in considering\nimportant function characteristics, or may consider features that are not\nimportant for the binary similarity problem. In this paper we propose SAFE, a\nnovel architecture for the embedding of functions based on a self-attentive\nneural network. SAFE works directly on disassembled binary functions, does not\nrequire manual feature extraction, is computationally more efficient than\nexisting solutions (i.e., it does not incur in the computational overhead of\nbuilding or manipulating control flow graphs), and is more general as it works\non stripped binaries and on multiple architectures. We report the results from\na quantitative and qualitative analysis that show how SAFE provides a\nnoticeable performance improvement with respect to previous solutions.\nFurthermore, we show how clusters of our embedding vectors are closely related\nto the semantic of the implemented algorithms, paving the way for further\ninteresting applications (e.g. semantic-based binary function search).</p>\n", "tags": ["Compact Codes", "Evaluation"], "tsne_embedding": [-1.0150381326675415, -18.501285552978516], "cluster": 5}, {"key": "matsui2017pqtable", "year": "2017", "citations": "8", "title": "Pqtable: Non-exhaustive Fast Search For Product-quantized Codes Using Hash Tables", "abstract": "<p>In this paper, we propose a product quantization table (PQTable); a fast\nsearch method for product-quantized codes via hash-tables. An identifier of\neach database vector is associated with the slot of a hash table by using its\nPQ-code as a key. For querying, an input vector is PQ-encoded and hashed, and\nthe items associated with that code are then retrieved. The proposed PQTable\nproduces the same results as a linear PQ scan, and is 10^2 to 10^5 times\nfaster. Although state-of-the-art performance can be achieved by previous\ninverted-indexing-based approaches, such methods require manually-designed\nparameter setting and significant training; our PQTable is free of these\nlimitations, and therefore offers a practical and effective solution for\nreal-world problems. Specifically, when the vectors are highly compressed, our\nPQTable achieves one of the fastest search performances on a single CPU to date\nwith significantly efficient memory usage (0.059 ms per query over 10^9 data\npoints with just 5.5 GB memory consumption). Finally, we show that our proposed\nPQTable can naturally handle the codes of an optimized product quantization\n(OPQTable).</p>\n", "tags": ["Alt", "Quantization", "Evaluation"], "tsne_embedding": [-8.046599388122559, -23.95327377319336], "cluster": 5}, {"key": "maziarz2021hashing", "year": "2021", "citations": "7", "title": "Hashing Modulo Alpha-equivalence", "abstract": "<p>In many applications one wants to identify identical subtrees of a program\nsyntax tree. This identification should ideally be robust to alpha-renaming of\nthe program, but no existing technique has been shown to achieve this with good\nefficiency (better than \\(\\mathcal{O}(n^2)\\) in expression size). We present a\nnew, asymptotically efficient way to hash modulo alpha-equivalence. A key\ninsight of our method is to use a weak (commutative) hash combiner at exactly\none point in the construction, which admits an algorithm with \\(\\mathcal{O}(n\n(log n)^2)\\) time complexity. We prove that the use of the commutative combiner\nnevertheless yields a strong hash with low collision probability. Numerical\nbenchmarks attest to the asymptotic behaviour of the method.</p>\n", "tags": ["Hashing Methods", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [-1.4603899717330933, -13.408540725708008], "cluster": 9}, {"key": "mccarter2022look", "year": "2022", "citations": "1027", "title": "Look-ups Are Not (yet) All You Need For Deep Learning Inference", "abstract": "<p>Fast approximations to matrix multiplication have the potential to\ndramatically reduce the cost of neural network inference. Recent work on\napproximate matrix multiplication proposed to replace costly multiplications\nwith table-lookups by fitting a fast hash function from training data. In this\nwork, we propose improvements to this previous work, targeted to the deep\nlearning inference setting, where one has access to both training data and\nfixed (already learned) model weight matrices. We further propose a fine-tuning\nprocedure for accelerating entire neural networks while minimizing loss in\naccuracy. Finally, we analyze the proposed method on a simple image\nclassification task. While we show improvements to prior work, overall\nclassification accuracy remains substantially diminished compared to exact\nmatrix multiplication. Our work, despite this negative result, points the way\ntowards future efforts to accelerate inner products with fast nonlinear hashing\nmethods.</p>\n", "tags": ["Hashing Methods"], "tsne_embedding": [1.059316873550415, -8.8899564743042], "cluster": 9}, {"key": "mccauley2018adaptive", "year": "2018", "citations": "6", "title": "Adaptive Mapreduce Similarity Joins", "abstract": "<p>Similarity joins are a fundamental database operation. Given data sets S and\nR, the goal of a similarity join is to find all points x in S and y in R with\ndistance at most r. Recent research has investigated how locality-sensitive\nhashing (LSH) can be used for similarity join, and in particular two recent\nlines of work have made exciting progress on LSH-based join performance. Hu,\nTao, and Yi (PODS 17) investigated joins in a massively parallel setting,\nshowing strong results that adapt to the size of the output. Meanwhile, Ahle,\nAum\"uller, and Pagh (SODA 17) showed a sequential algorithm that adapts to the\nstructure of the data, matching classic bounds in the worst case but improving\nthem significantly on more structured data. We show that this adaptive strategy\ncan be adapted to the parallel setting, combining the advantages of these\napproaches. In particular, we show that a simple modification to Hu et al.\u2019s\nalgorithm achieves bounds that depend on the density of points in the dataset\nas well as the total outsize of the output. Our algorithm uses no extra\nparameters over other LSH approaches (in particular, its execution does not\ndepend on the structure of the dataset), and is likely to be efficient in\npractice.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Evaluation", "DATASETS"], "tsne_embedding": [8.034566879272461, 0.1340891718864441], "cluster": 4}, {"key": "mckeown2022hamming", "year": "2022", "citations": "9", "title": "Hamming Distributions Of Popular Perceptual Hashing Techniques", "abstract": "<p>Content-based file matching has been widely deployed for decades, largely for\nthe detection of sources of copyright infringement, extremist materials, and\nabusive sexual media. Perceptual hashes, such as Microsoft\u2019s PhotoDNA, are one\nautomated mechanism for facilitating detection, allowing for machines to\napproximately match visual features of an image or video in a robust manner.\nHowever, there does not appear to be much public evaluation of such approaches,\nparticularly when it comes to how effective they are against content-preserving\nmodifications to media files. In this paper, we present a million-image scale\nevaluation of several perceptual hashing archetypes for popular algorithms\n(including Facebook\u2019s PDQ, Apple\u2019s Neuralhash, and the popular pHash library)\nagainst seven image variants. The focal point is the distribution of Hamming\ndistance scores between both unrelated images and image variants to better\nunderstand the problems faced by each approach.</p>\n", "tags": ["Tools & Libraries", "Hashing Methods", "Evaluation"], "tsne_embedding": [-15.340209007263184, 17.058927536010742], "cluster": 3}, {"key": "medini2020solar", "year": "2020", "citations": "6", "title": "SOLAR: Sparse Orthogonal Learned And Random Embeddings", "abstract": "<p>Dense embedding models are commonly deployed in commercial search engines,\nwherein all the document vectors are pre-computed, and near-neighbor search\n(NNS) is performed with the query vector to find relevant documents. However,\nthe bottleneck of indexing a large number of dense vectors and performing an\nNNS hurts the query time and accuracy of these models. In this paper, we argue\nthat high-dimensional and ultra-sparse embedding is a significantly superior\nalternative to dense low-dimensional embedding for both query efficiency and\naccuracy. Extreme sparsity eliminates the need for NNS by replacing them with\nsimple lookups, while its high dimensionality ensures that the embeddings are\ninformative even when sparse. However, learning extremely high dimensional\nembeddings leads to blow up in the model size. To make the training feasible,\nwe propose a partitioning algorithm that learns such high dimensional\nembeddings across multiple GPUs without any communication. This is facilitated\nby our novel asymmetric mixture of Sparse, Orthogonal, Learned and Random\n(SOLAR) Embeddings. The label vectors are random, sparse, and near-orthogonal\nby design, while the query vectors are learned and sparse. We theoretically\nprove that our way of one-sided learning is equivalent to learning both query\nand label embeddings. With these unique properties, we can successfully train\n500K dimensional SOLAR embeddings for the tasks of searching through 1.6M books\nand multi-label classification on the three largest public datasets. We achieve\nsuperior precision and recall compared to the respective state-of-the-art\nbaselines for each of the tasks with up to 10 times faster speed.</p>\n", "tags": ["Alt", "DATASETS", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [-5.950394630432129, -20.89617347717285], "cluster": 5}, {"key": "meel2017hashing", "year": "2017", "citations": "8", "title": "On Hashing-based Approaches To Approximate Dnf-counting", "abstract": "<p>Propositional model counting is a fundamental problem in artificial\nintelligence with a wide variety of applications, such as probabilistic\ninference, decision making under uncertainty, and probabilistic databases.\nConsequently, the problem is of theoretical as well as practical interest. When\nthe constraints are expressed as DNF formulas, Monte Carlo-based techniques\nhave been shown to provide a fully polynomial randomized approximation scheme\n(FPRAS). For CNF constraints, hashing-based approximation techniques have been\ndemonstrated to be highly successful. Furthermore, it was shown that\nhashing-based techniques also yield an FPRAS for DNF counting without usage of\nMonte Carlo sampling. Our analysis, however, shows that the proposed\nhashing-based approach to DNF counting provides poor time complexity compared\nto the Monte Carlo-based DNF counting techniques. Given the success of\nhashing-based techniques for CNF constraints, it is natural to ask: Can\nhashing-based techniques provide an efficient FPRAS for DNF counting? In this\npaper, we provide a positive answer to this question. To this end, we introduce\ntwo novel algorithmic techniques: <em>Symbolic Hashing</em> and <em>Stochastic\nCell Counting</em>, along with a new hash family of <em>Row-Echelon hash\nfunctions</em>. These innovations allow us to design a hashing-based FPRAS for DNF\ncounting of similar complexity (up to polylog factors) as that of prior works.\nFurthermore, we expect these techniques to have potential applications beyond\nDNF counting.</p>\n", "tags": ["Hashing Methods", "Graph Based ANN"], "tsne_embedding": [-3.179898262023926, -25.738460540771484], "cluster": 5}, {"key": "meel2020sparse", "year": "2020", "citations": "15", "title": "Sparse Hashing For Scalable Approximate Model Counting: Theory And Practice", "abstract": "<p>Given a CNF formula F on n variables, the problem of model counting or #SAT\nis to compute the number of satisfying assignments of F . Model counting is a\nfundamental but hard problem in computer science with varied applications.\nRecent years have witnessed a surge of effort towards developing efficient\nalgorithmic techniques that combine the classical 2-universal hashing with the\nremarkable progress in SAT solving over the past decade. These techniques\naugment the CNF formula F with random XOR constraints and invoke an NP oracle\nrepeatedly on the resultant CNF-XOR formulas. In practice, calls to the NP\noracle calls are replaced a SAT solver whose runtime performance is adversely\naffected by size of XOR constraints. The standard construction of 2-universal\nhash functions chooses every variable with probability p = 1/2 leading to XOR\nconstraints of size n/2 in expectation. Consequently, the challenge is to\ndesign sparse hash functions where variables can be chosen with smaller\nprobability and lead to smaller sized XOR constraints.\n  In this paper, we address this challenge from theoretical and practical\nperspectives. First, we formalize a relaxation of universal hashing, called\nconcentrated hashing and establish a novel and beautiful connection between\nconcentration measures of these hash functions and isoperimetric inequalities\non boolean hypercubes. This allows us to obtain (log m) tight bounds on\nvariance and dispersion index and show that p = O( log(m)/m ) suffices for\ndesign of sparse hash functions from {0, 1}^n to {0, 1}^m. We then use sparse\nhash functions belonging to this concentrated hash family to develop new\napproximate counting algorithms. A comprehensive experimental evaluation of our\nalgorithm on 1893 benchmarks demonstrates that usage of sparse hash functions\ncan lead to significant speedups.</p>\n", "tags": ["Hashing Methods", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [-2.384629964828491, -26.471410751342773], "cluster": 5}, {"key": "mei2025temporal", "year": "2025", "citations": "8", "title": "Temporal-aware Spiking Transformer Hashing Based On 3D-DWT", "abstract": "<p>With the rapid growth of dynamic vision sensor (DVS) data, constructing a\nlow-energy, efficient data retrieval system has become an urgent task. Hash\nlearning is one of the most important retrieval technologies which can keep the\ndistance between hash codes consistent with the distance between DVS data. As\nspiking neural networks (SNNs) can encode information through spikes, they\ndemonstrate great potential in promoting energy efficiency. Based on the binary\ncharacteristics of SNNs, we first propose a novel supervised hashing method\nnamed Spikinghash with a hierarchical lightweight structure. Spiking WaveMixer\n(SWM) is deployed in shallow layers, utilizing a multilevel 3D discrete wavelet\ntransform (3D-DWT) to decouple spatiotemporal features into various\nlow-frequency and high frequency components, and then employing efficient\nspectral feature fusion. SWM can effectively capture the temporal dependencies\nand local spatial features. Spiking Self-Attention (SSA) is deployed in deeper\nlayers to further extract global spatiotemporal information. We also design a\nhash layer utilizing binary characteristic of SNNs, which integrates\ninformation over multiple time steps to generate final hash codes. Furthermore,\nwe propose a new dynamic soft similarity loss for SNNs, which utilizes membrane\npotentials to construct a learnable similarity matrix as soft labels to fully\ncapture the similarity differences between classes and compensate information\nloss in SNNs, thereby improving retrieval performance. Experiments on multiple\ndatasets demonstrate that Spikinghash can achieve state-of-the-art results with\nlow energy consumption and fewer parameters.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "Neural Hashing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-5.800240993499756, 13.040864944458008], "cluster": 6}, {"key": "memmesheimer2020skeleton", "year": "2020", "citations": "28", "title": "Skeleton-dml: Deep Metric Learning For Skeleton-based One-shot Action Recognition", "abstract": "<p>One-shot action recognition allows the recognition of human-performed actions\nwith only a single training example. This can influence human-robot-interaction\npositively by enabling the robot to react to previously unseen behaviour. We\nformulate the one-shot action recognition problem as a deep metric learning\nproblem and propose a novel image-based skeleton representation that performs\nwell in a metric learning setting. Therefore, we train a model that projects\nthe image representations into an embedding space. In embedding space the\nsimilar actions have a low euclidean distance while dissimilar actions have a\nhigher distance. The one-shot action recognition problem becomes a\nnearest-neighbor search in a set of activity reference samples. We evaluate the\nperformance of our proposed representation against a variety of other\nskeleton-based image representations. In addition, we present an ablation study\nthat shows the influence of different embedding vector sizes, losses and\naugmentation. Our approach lifts the state-of-the-art by 3.3% for the one-shot\naction recognition protocol on the NTU RGB+D 120 dataset under a comparable\ntraining setup. With additional augmentation our result improved over 7.7%.</p>\n", "tags": ["DATASETS", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [0.6877806782722473, 20.971532821655273], "cluster": 6}, {"key": "messina2022aladin", "year": "2022", "citations": "20", "title": "ALADIN: Distilling Fine-grained Alignment Scores For Efficient Image-text Matching And Retrieval", "abstract": "<p>Image-text matching is gaining a leading role among tasks involving the joint\nunderstanding of vision and language. In literature, this task is often used as\na pre-training objective to forge architectures able to jointly deal with\nimages and texts. Nonetheless, it has a direct downstream application:\ncross-modal retrieval, which consists in finding images related to a given\nquery text or vice-versa. Solving this task is of critical importance in\ncross-modal search engines. Many recent methods proposed effective solutions to\nthe image-text matching problem, mostly using recent large vision-language (VL)\nTransformer networks. However, these models are often computationally\nexpensive, especially at inference time. This prevents their adoption in\nlarge-scale cross-modal retrieval scenarios, where results should be provided\nto the user almost instantaneously. In this paper, we propose to fill in the\ngap between effectiveness and efficiency by proposing an ALign And DIstill\nNetwork (ALADIN). ALADIN first produces high-effective scores by aligning at\nfine-grained level images and texts. Then, it learns a shared embedding space -\nwhere an efficient kNN search can be performed - by distilling the relevance\nscores obtained from the fine-grained alignments. We obtained remarkable\nresults on MS-COCO, showing that our method can compete with state-of-the-art\nVL Transformers while being almost 90 times faster. The code for reproducing\nour results is available at https://github.com/mesnico/ALADIN.</p>\n", "tags": ["Multimodal Retrieval", "Similarity Search", "Efficiency And Optimization"], "tsne_embedding": [2.423943281173706, -0.1513286828994751], "cluster": 4}, {"key": "meyer2017deep", "year": "2017", "citations": "29", "title": "Deep Metric Learning And Image Classification With Nearest Neighbour Gaussian Kernels", "abstract": "<p>We present a Gaussian kernel loss function and training algorithm for\nconvolutional neural networks that can be directly applied to both distance\nmetric learning and image classification problems. Our method treats all\ntraining features from a deep neural network as Gaussian kernel centres and\ncomputes loss by summing the influence of a feature\u2019s nearby centres in the\nfeature embedding space. Our approach is made scalable by treating it as an\napproximate nearest neighbour search problem. We show how to make end-to-end\nlearning feasible, resulting in a well formed embedding space, in which\nsemantically related instances are likely to be located near one another,\nregardless of whether or not the network was trained on those classes. Our\napproach outperforms state-of-the-art deep metric learning approaches on\nembedding learning challenges, as well as conventional softmax classification\non several datasets.</p>\n", "tags": ["DATASETS", "Similarity Search", "Distance Metric Learning"], "tsne_embedding": [-23.137500762939453, 3.5510334968566895], "cluster": 3}, {"key": "miao2024locality", "year": "2024", "citations": "52", "title": "Locality-sensitive Hashing-based Efficient Point Transformer With Applications In High-energy Physics", "abstract": "<p>This study introduces a novel transformer model optimized for large-scale\npoint cloud processing in scientific domains such as high-energy physics (HEP)\nand astrophysics. Addressing the limitations of graph neural networks and\nstandard transformers, our model integrates local inductive bias and achieves\nnear-linear complexity with hardware-friendly regular operations. One\ncontribution of this work is the quantitative analysis of the error-complexity\ntradeoff of various sparsification techniques for building efficient\ntransformers. Our findings highlight the superiority of using\nlocality-sensitive hashing (LSH), especially OR &amp; AND-construction LSH, in\nkernel approximation for large-scale point cloud data with local inductive\nbias. Based on this finding, we propose LSH-based Efficient Point Transformer\n(HEPT), which combines E\\(^2\\)LSH with OR &amp; AND constructions and is built upon\nregular computations. HEPT demonstrates remarkable performance on two critical\nyet time-consuming HEP tasks, significantly outperforming existing GNNs and\ntransformers in accuracy and computational speed, marking a significant\nadvancement in geometric deep learning and large-scale scientific data\nprocessing. Our code is available at https://github.com/Graph-COM/HEPT.</p>\n", "tags": ["CIKM", "Locality Sensitive Hashing", "Hashing Methods", "Evaluation"], "tsne_embedding": [8.514435768127441, 14.486420631408691], "cluster": 0}, {"key": "miech2021thinking", "year": "2021", "citations": "111", "title": "Thinking Fast And Slow: Efficient Text-to-visual Retrieval With Transformers", "abstract": "<p>Our objective is language-based search of large-scale image and video\ndatasets. For this task, the approach that consists of independently mapping\ntext and vision to a joint embedding space, a.k.a. dual encoders, is attractive\nas retrieval scales and is efficient for billions of images using approximate\nnearest neighbour search. An alternative approach of using vision-text\ntransformers with cross-attention gives considerable improvements in accuracy\nover the joint embeddings, but is often inapplicable in practice for\nlarge-scale retrieval given the cost of the cross-attention mechanisms required\nfor each sample at test time. This work combines the best of both worlds. We\nmake the following three contributions. First, we equip transformer-based\nmodels with a new fine-grained cross-attention architecture, providing\nsignificant improvements in retrieval accuracy whilst preserving scalability.\nSecond, we introduce a generic approach for combining a Fast dual encoder model\nwith our Slow but accurate transformer-based model via distillation and\nre-ranking. Finally, we validate our approach on the Flickr30K image dataset\nwhere we show an increase in inference speed by several orders of magnitude\nwhile having results competitive to the state of the art. We also extend our\nmethod to the video domain, improving the state of the art on the VATEX\ndataset.</p>\n", "tags": ["DATASETS", "CVPR", "Alt", "Similarity Search", "Evaluation"], "tsne_embedding": [-9.588238716125488, 16.365642547607422], "cluster": 6}, {"key": "mikriukov2022deep", "year": "2022", "citations": "19", "title": "Deep Unsupervised Contrastive Hashing For Large-scale Cross-modal Text-image Retrieval In Remote Sensing", "abstract": "<p>Due to the availability of large-scale multi-modal data (e.g., satellite\nimages acquired by different sensors, text sentences, etc) archives, the\ndevelopment of cross-modal retrieval systems that can search and retrieve\nsemantically relevant data across different modalities based on a query in any\nmodality has attracted great attention in RS. In this paper, we focus our\nattention on cross-modal text-image retrieval, where queries from one modality\n(e.g., text) can be matched to archive entries from another (e.g., image). Most\nof the existing cross-modal text-image retrieval systems require a high number\nof labeled training samples and also do not allow fast and memory-efficient\nretrieval due to their intrinsic characteristics. These issues limit the\napplicability of the existing cross-modal retrieval systems for large-scale\napplications in RS. To address this problem, in this paper we introduce a novel\ndeep unsupervised cross-modal contrastive hashing (DUCH) method for RS\ntext-image retrieval. The proposed DUCH is made up of two main modules: 1)\nfeature extraction module (which extracts deep representations of the\ntext-image modalities); and 2) hashing module (which learns to generate\ncross-modal binary hash codes from the extracted representations). Within the\nhashing module, we introduce a novel multi-objective loss function including:\ni) contrastive objectives that enable similarity preservation in both intra-\nand inter-modal similarities; ii) an adversarial objective that is enforced\nacross two modalities for cross-modal representation consistency; iii)\nbinarization objectives for generating representative hash codes. Experimental\nresults show that the proposed DUCH outperforms state-of-the-art unsupervised\ncross-modal hashing methods on two multi-modal (image and text) benchmark\narchives in RS. Our code is publicly available at\nhttps://git.tu-berlin.de/rsim/duch.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Multimodal Retrieval", "Evaluation", "Robustness"], "tsne_embedding": [-10.102812767028809, -0.7059450745582581], "cluster": 8}, {"key": "mikriukov2022unsupervised", "year": "2022", "citations": "50", "title": "Unsupervised Contrastive Hashing For Cross-modal Retrieval In Remote Sensing", "abstract": "<p>The development of cross-modal retrieval systems that can search and retrieve\nsemantically relevant data across different modalities based on a query in any\nmodality has attracted great attention in remote sensing (RS). In this paper,\nwe focus our attention on cross-modal text-image retrieval, where queries from\none modality (e.g., text) can be matched to archive entries from another (e.g.,\nimage). Most of the existing cross-modal text-image retrieval systems in RS\nrequire a high number of labeled training samples and also do not allow fast\nand memory-efficient retrieval. These issues limit the applicability of the\nexisting cross-modal retrieval systems for large-scale applications in RS. To\naddress this problem, in this paper we introduce a novel unsupervised\ncross-modal contrastive hashing (DUCH) method for text-image retrieval in RS.\nTo this end, the proposed DUCH is made up of two main modules: 1) feature\nextraction module, which extracts deep representations of two modalities; 2)\nhashing module that learns to generate cross-modal binary hash codes from the\nextracted representations. We introduce a novel multi-objective loss function\nincluding: i) contrastive objectives that enable similarity preservation in\nintra- and inter-modal similarities; ii) an adversarial objective that is\nenforced across two modalities for cross-modal representation consistency; and\niii) binarization objectives for generating hash codes. Experimental results\nshow that the proposed DUCH outperforms state-of-the-art methods. Our code is\npublicly available at https://git.tu-berlin.de/rsim/duch.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Multimodal Retrieval", "Similarity Search", "ICASSP", "Robustness"], "tsne_embedding": [-10.027310371398926, -0.6808055639266968], "cluster": 8}, {"key": "min2017exemplar", "year": "2017", "citations": "8", "title": "Exemplar-centered Supervised Shallow Parametric Data Embedding", "abstract": "<p>Metric learning methods for dimensionality reduction in combination with\nk-Nearest Neighbors (kNN) have been extensively deployed in many\nclassification, data embedding, and information retrieval applications.\nHowever, most of these approaches involve pairwise training data comparisons,\nand thus have quadratic computational complexity with respect to the size of\ntraining set, preventing them from scaling to fairly big datasets. Moreover,\nduring testing, comparing test data against all the training data points is\nalso expensive in terms of both computational cost and resources required.\nFurthermore, previous metrics are either too constrained or too expressive to\nbe well learned. To effectively solve these issues, we present an\nexemplar-centered supervised shallow parametric data embedding model, using a\nMaximally Collapsing Metric Learning (MCML) objective. Our strategy learns a\nshallow high-order parametric embedding function and compares training/test\ndata only with learned or precomputed exemplars, resulting in a cost function\nwith linear computational complexity for both training and testing. We also\nempirically demonstrate, using several benchmark datasets, that for\nclassification in two-dimensional embedding space, our approach not only gains\nspeedup of kNN by hundreds of times, but also outperforms state-of-the-art\nsupervised embedding approaches.</p>\n", "tags": ["Distance Metric Learning", "DATASETS", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [-22.110315322875977, -2.3874800205230713], "cluster": 1}, {"key": "mishra2019finding", "year": "2019", "citations": "12", "title": "Finding Nearest Neighbors In Graphs Locally", "abstract": "<p>Many distributed learning techniques have been motivated by the increasing\nsize of datasets and their inability to fit into main memory on a single\nmachine. We propose an algorithm that finds the nearest neighbor in a graph\nlocally without the need of visiting the whole graph. Our algorithm is\ndistributed which further encourage scalability. We prove the convergence of\nthe algorithm</p>\n", "tags": ["DATASETS"], "tsne_embedding": [19.428176879882812, 10.247574806213379], "cluster": 0}, {"key": "misra2018bernoulli", "year": "2018", "citations": "9", "title": "Bernoulli Embeddings For Graphs", "abstract": "<p>Just as semantic hashing can accelerate information retrieval, binary valued\nembeddings can significantly reduce latency in the retrieval of graphical data.\nWe introduce a simple but effective model for learning such binary vectors for\nnodes in a graph. By imagining the embeddings as independent coin flips of\nvarying bias, continuous optimization techniques can be applied to the\napproximate expected loss. Embeddings optimized in this fashion consistently\noutperform the quantization of both spectral graph embeddings and various\nlearned real-valued embeddings, on both ranking and pre-ranking tasks for a\nvariety of datasets.</p>\n", "tags": ["AAAI", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Text Retrieval", "Quantization"], "tsne_embedding": [15.8522367477417, 10.018364906311035], "cluster": 0}, {"key": "mohammadi2018multi", "year": "2018", "citations": "74", "title": "Multi-reference Cosine: A New Approach To Text Similarity Measurement In Large Collections", "abstract": "<p>The importance of an efficient and scalable document similarity detection\nsystem is undeniable nowadays. Search engines need batch text similarity\nmeasures to detect duplicated and near-duplicated web pages in their indexes in\norder to prevent indexing a web page multiple times. Furthermore, in the\nscoring phase, search engines need similarity measures to detect duplicated\ncontents on web pages so as to increase the quality of their results. In this\npaper, a new approach to batch text similarity detection is proposed by\ncombining some ideas from dimensionality reduction techniques and information\ngain theory. The new approach is focused on search engines need to detect\nduplicated and near-duplicated web pages. The new approach is evaluated on the\nNEWS20 dataset and the results show that the new approach is faster than the\ncosine text similarity algorithm in terms of speed and performance. On top of\nthat, It is faster and more accurate than the other rival method, Simhash\nsimilarity algorithm.</p>\n", "tags": ["Locality Sensitive Hashing", "Evaluation", "DATASETS"], "tsne_embedding": [11.686514854431152, -11.82109546661377], "cluster": 2}, {"key": "mohoney2025quake", "year": "2025", "citations": "21", "title": "Quake: Adaptive Indexing For Vector Search", "abstract": "<p>Vector search, the task of finding the k-nearest neighbors of a query vector against a database of high-dimensional vectors, underpins many machine learning applications, including retrieval-augmented generation, recommendation systems, and information retrieval. However, existing approximate nearest neighbor (ANN) methods perform poorly under dynamic and skewed workloads where data distributions evolve. We introduce Quake, an adaptive indexing system that maintains low latency and high recall in such environments. Quake employs a multi-level partitioning scheme that adjusts to updates and changing access patterns, guided by a cost model that predicts query latency based on partition sizes and access frequencies. Quake also dynamically sets query execution parameters to meet recall targets using a novel recall estimation model. Furthermore, Quake utilizes NUMA-aware intra-query parallelism for improved memory bandwidth utilization during search. To evaluate Quake, we prepare a Wikipedia vector search workload and develop a workload generator to create vector search workloads with configurable access patterns. Our evaluation shows that on dynamic workloads, Quake achieves query latency reductions of 1.5-38x and update latency reductions of 4.5-126x compared to state-of-the-art indexes such as SVS, DiskANN, HNSW, and SCANN.</p>\n", "tags": ["Graph Based ANN", "Efficiency And Optimization", "Recommender Systems", "Tools & Libraries", "Evaluation"], "tsne_embedding": [12.640939712524414, -4.995250225067139], "cluster": 2}, {"key": "morales2016streaming", "year": "2016", "citations": "27", "title": "Streaming Similarity Self-join", "abstract": "<p>We introduce and study the problem of computing the similarity self-join in a\nstreaming context (SSSJ), where the input is an unbounded stream of items\narriving continuously. The goal is to find all pairs of items in the stream\nwhose similarity is greater than a given threshold. The simplest formulation of\nthe problem requires unbounded memory, and thus, it is intractable. To make the\nproblem feasible, we introduce the notion of time-dependent similarity: the\nsimilarity of two items decreases with the difference in their arrival time. By\nleveraging the properties of this time-dependent similarity function, we design\ntwo algorithmic frameworks to solve the sssj problem. The first one, MiniBatch\n(MB), uses existing index-based filtering techniques for the static version of\nthe problem, and combines them in a pipeline. The second framework, Streaming\n(STR), adds time filtering to the existing indexes, and integrates new\ntime-based bounds deeply in the working of the algorithms. We also introduce a\nnew indexing technique (L2), which is based on an existing state-of-the-art\nindexing technique (L2AP), but is optimized for the streaming case. Extensive\nexperiments show that the STR algorithm, when instantiated with the L2 index,\nis the most scalable option across a wide array of datasets and parameters.</p>\n", "tags": ["DATASETS", "Tools & Libraries"], "tsne_embedding": [6.583578109741211, -0.2222011685371399], "cluster": 4}, {"key": "moran2025enhancing", "year": "2025", "citations": "29", "title": "Enhancing First Story Detection Using Word Embeddings", "abstract": "<p>In this paper we show how word embeddings can be used to increase the effectiveness of a state-of-the art Locality Sensitive Hashing (LSH) based first story detection (FSD) system over a standard tweet corpus. Vocabulary mismatch, in which related tweets use different words, is a serious hindrance to the effectiveness of a modern FSD system. In this case, a tweet could be flagged as a first story even if a related tweet, which uses different but synonymous words, was already returned as a first story. In this work, we propose a novel approach to mitigate this problem of lexical variation, based on tweet expansion. In particular, we propose to expand tweets with semantically related paraphrases identified via automatically mined word embeddings over a background tweet corpus. Through experimentation on a large data stream comprised of 50 million tweets, we show that FSD effectiveness can be improved by 9.5% over a state-of-the-art FSD system.</p>\n", "tags": ["Locality Sensitive Hashing", "SIGIR", "Hashing Methods"], "tsne_embedding": [-18.818870544433594, -18.222148895263672], "cluster": 1}, {"key": "moran2025neighbourhood", "year": "2025", "citations": "22", "title": "Neighbourhood Preserving Quantisation For LSH", "abstract": "<p>We introduce a scheme for optimally allocating multiple bits per hyperplane for Locality Sensitive Hashing (LSH). Existing approaches binarise LSH projections by thresholding at zero yielding a single bit per dimension. We demonstrate that this is a sub-optimal bit allocation approach that can easily destroy the neighbourhood structure in the original feature space. Our proposed method, dubbed Neighbourhood Preserving Quantization (NPQ), assigns multiple bits per hyperplane based upon adaptively learned thresholds. NPQ exploits a pairwise affinity matrix to discretise each dimension such that nearest neighbours in the original feature space fall within the same quantisation thresholds and are therefore assigned identical bits. NPQ is not only applicable to LSH, but can also be applied to any low-dimensional projection scheme. Despite using half the number of hyperplanes, NPQ is shown to improve LSH-based retrieval accuracy by up to 65% compared to the state-of-the-art.</p>\n", "tags": ["Locality Sensitive Hashing", "SIGIR", "Quantization", "Hashing Methods"], "tsne_embedding": [20.50391387939453, -0.6074764132499695], "cluster": 7}, {"key": "moran2025regularised", "year": "2025", "citations": "18", "title": "Regularised Cross-modal Hashing", "abstract": "<p>In this paper we propose Regularised Cross-Modal Hashing (RCMH) a new cross-modal hashing scheme that projects annotation and visual feature descriptors into a common Hamming space. RCMH optimises the intra-modality similarity of data-points in the annotation modality using an iterative three-step hashing algorithm: in the first step each training image is assigned a K-bit hashcode based on hyperplanes learnt at the previous iteration; in the second step the binary bits are smoothed by a formulation of graph regularisation so that similar data-points have similar bits; in the third step a set of binary classifiers are trained to predict the regularised bits with maximum margin. Visual descriptors are projected into the annotation Hamming space by a set of binary classifiers learnt using the bits of the corresponding annotations as labels. RCMH is shown to consistently improve retrieval effectiveness over state-of-the-art baselines.</p>\n", "tags": ["SIGIR", "Hashing Methods"], "tsne_embedding": [13.820571899414062, -14.669380187988281], "cluster": 2}, {"key": "moran2025variable", "year": "2025", "citations": "21", "title": "Variable Bit Quantisation For LSH", "abstract": "<p>We introduce a scheme for optimally allocating\na variable number of bits per\nLSH hyperplane. Previous approaches assign\na constant number of bits per hyperplane.\nThis neglects the fact that a subset\nof hyperplanes may be more informative\nthan others. Our method, dubbed Variable\nBit Quantisation (VBQ), provides a datadriven\nnon-uniform bit allocation across\nhyperplanes. Despite only using a fraction\nof the available hyperplanes, VBQ outperforms\nuniform quantisation by up to 168%\nfor retrieval across standard text and image\ndatasets.</p>\n", "tags": ["Locality Sensitive Hashing", "DATASETS"], "tsne_embedding": [25.09457778930664, -10.606917381286621], "cluster": 7}, {"key": "morgado2020deep", "year": "2020", "citations": "6", "title": "Deep Hashing With Hash-consistent Large Margin Proxy Embeddings", "abstract": "<p>Image hash codes are produced by binarizing the embeddings of convolutional\nneural networks (CNN) trained for either classification or retrieval. While\nproxy embeddings achieve good performance on both tasks, they are non-trivial\nto binarize, due to a rotational ambiguity that encourages non-binary\nembeddings. The use of a fixed set of proxies (weights of the CNN\nclassification layer) is proposed to eliminate this ambiguity, and a procedure\nto design proxy sets that are nearly optimal for both classification and\nhashing is introduced. The resulting hash-consistent large margin (HCLM)\nproxies are shown to encourage saturation of hashing units, thus guaranteeing a\nsmall binarization error, while producing highly discriminative hash-codes. A\nsemantic extension (sHCLM), aimed to improve hashing performance in a transfer\nscenario, is also proposed. Extensive experiments show that sHCLM embeddings\nachieve significant improvements over state-of-the-art hashing procedures on\nseveral small and large datasets, both within and beyond the set of training\nclasses.</p>\n", "tags": ["DATASETS", "Neural Hashing", "Evaluation", "Hashing Methods"], "tsne_embedding": [-14.107460021972656, 22.783525466918945], "cluster": 6}, {"key": "morozov2019unsupervised", "year": "2019", "citations": "21", "title": "Unsupervised Neural Quantization For Compressed-domain Similarity Search", "abstract": "<p>We tackle the problem of unsupervised visual descriptors compression, which\nis a key ingredient of large-scale image retrieval systems. While the deep\nlearning machinery has benefited literally all computer vision pipelines, the\nexisting state-of-the-art compression methods employ shallow architectures, and\nwe aim to close this gap by our paper. In more detail, we introduce a DNN\narchitecture for the unsupervised compressed-domain retrieval, based on\nmulti-codebook quantization. The proposed architecture is designed to\nincorporate both fast data encoding and efficient distances computation via\nlookup tables. We demonstrate the exceptional advantage of our scheme over\nexisting quantization approaches on several datasets of visual descriptors via\noutperforming the previous state-of-the-art by a large margin.</p>\n", "tags": ["Image Retrieval", "DATASETS", "ICCV", "Similarity Search", "Quantization"], "tsne_embedding": [-3.3537659645080566, 11.044532775878906], "cluster": 6}, {"key": "morris2016faster", "year": "2016", "citations": "87", "title": "Faster Kernels For Graphs With Continuous Attributes Via Hashing", "abstract": "<p>While state-of-the-art kernels for graphs with discrete labels scale well to\ngraphs with thousands of nodes, the few existing kernels for graphs with\ncontinuous attributes, unfortunately, do not scale well. To overcome this\nlimitation, we present hash graph kernels, a general framework to derive\nkernels for graphs with continuous attributes from discrete ones. The idea is\nto iteratively turn continuous attributes into discrete labels using randomized\nhash functions. We illustrate hash graph kernels for the Weisfeiler-Lehman\nsubtree kernel and for the shortest-path kernel. The resulting novel graph\nkernels are shown to be, both, able to handle graphs with continuous attributes\nand scalable to large graphs and data sets. This is supported by our\ntheoretical analysis and demonstrated by an extensive experimental evaluation.</p>\n", "tags": ["Tools & Libraries", "Hashing Methods", "Evaluation"], "tsne_embedding": [17.920846939086914, 12.121689796447754], "cluster": 0}, {"key": "mor\u00e8re2016group", "year": "2016", "citations": "6", "title": "Group Invariant Deep Representations For Image Instance Retrieval", "abstract": "<p>Most image instance retrieval pipelines are based on comparison of vectors\nknown as global image descriptors between a query image and the database\nimages. Due to their success in large scale image classification,\nrepresentations extracted from Convolutional Neural Networks (CNN) are quickly\ngaining ground on Fisher Vectors (FVs) as state-of-the-art global descriptors\nfor image instance retrieval. While CNN-based descriptors are generally\nremarked for good retrieval performance at lower bitrates, they nevertheless\npresent a number of drawbacks including the lack of robustness to common object\ntransformations such as rotations compared with their interest point based FV\ncounterparts.\n  In this paper, we propose a method for computing invariant global descriptors\nfrom CNNs. Our method implements a recently proposed mathematical theory for\ninvariance in a sensory cortex modeled as a feedforward neural network. The\nresulting global descriptors can be made invariant to multiple arbitrary\ntransformation groups while retaining good discriminativeness.\n  Based on a thorough empirical evaluation using several publicly available\ndatasets, we show that our method is able to significantly and consistently\nimprove retrieval results every time a new type of invariance is incorporated.\nWe also show that our method which has few parameters is not prone to\noverfitting: improvements generalize well across datasets with different\nproperties with regard to invariances. Finally, we show that our descriptors\nare able to compare favourably to other state-of-the-art compact descriptors in\nsimilar bitranges, exceeding the highest retrieval results reported in the\nliterature on some datasets. A dedicated dimensionality reduction step\n\u2013quantization or hashing\u2013 may be able to further improve the competitiveness\nof the descriptors.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Quantization", "Evaluation", "Robustness"], "tsne_embedding": [-14.691349029541016, 21.709077835083008], "cluster": 6}, {"key": "mor\u00e8re2016nested", "year": "2016", "citations": "17", "title": "Nested Invariance Pooling And RBM Hashing For Image Instance Retrieval", "abstract": "<p>The goal of this work is the computation of very compact binary hashes for\nimage instance retrieval. Our approach has two novel contributions. The first\none is Nested Invariance Pooling (NIP), a method inspired from i-theory, a\nmathematical theory for computing group invariant transformations with\nfeed-forward neural networks. NIP is able to produce compact and\nwell-performing descriptors with visual representations extracted from\nconvolutional neural networks. We specifically incorporate scale, translation\nand rotation invariances but the scheme can be extended to any arbitrary sets\nof transformations. We also show that using moments of increasing order\nthroughout nesting is important. The NIP descriptors are then hashed to the\ntarget code size (32-256 bits) with a Restricted Boltzmann Machine with a novel\nbatch-level regularization scheme specifically designed for the purpose of\nhashing (RBMH). A thorough empirical evaluation with state-of-the-art shows\nthat the results obtained both with the NIP descriptors and the NIP+RBMH hashes\nare consistently outstanding across a wide range of datasets.</p>\n", "tags": ["DATASETS", "Evaluation", "Hashing Methods", "Multimodal Retrieval"], "tsne_embedding": [1.6554874181747437, 14.306129455566406], "cluster": 6}, {"key": "moulton2018maximally", "year": "2018", "citations": "15", "title": "Maximally Consistent Sampling And The Jaccard Index Of Probability Distributions", "abstract": "<p>We introduce simple, efficient algorithms for computing a MinHash of a\nprobability distribution, suitable for both sparse and dense data, with\nequivalent running times to the state of the art for both cases. The collision\nprobability of these algorithms is a new measure of the similarity of positive\nvectors which we investigate in detail. We describe the sense in which this\ncollision probability is optimal for any Locality Sensitive Hash based on\nsampling. We argue that this similarity measure is more useful for probability\ndistributions than the similarity pursued by other algorithms for weighted\nMinHash, and is the natural generalization of the Jaccard index.</p>\n", "tags": ["Locality Sensitive Hashing"], "tsne_embedding": [18.045936584472656, -9.034948348999023], "cluster": 2}, {"key": "mu2016deep", "year": "2016", "citations": "9", "title": "Deep Hashing: A Joint Approach For Image Signature Learning", "abstract": "<p>Similarity-based image hashing represents crucial technique for visual data\nstorage reduction and expedited image search. Conventional hashing schemes\ntypically feed hand-crafted features into hash functions, which separates the\nprocedures of feature extraction and hash function learning. In this paper, we\npropose a novel algorithm that concurrently performs feature engineering and\nnon-linear supervised hashing function learning. Our technical contributions in\nthis paper are two-folds: 1) deep network optimization is often achieved by\ngradient propagation, which critically requires a smooth objective function.\nThe discrete nature of hash codes makes them not amenable for gradient-based\noptimization. To address this issue, we propose an exponentiated hashing loss\nfunction and its bilinear smooth approximation. Effective gradient calculation\nand propagation are thereby enabled; 2) pre-training is an important trick in\nsupervised deep learning. The impact of pre-training on the hash code quality\nhas never been discussed in current deep hashing literature. We propose a\npre-training scheme inspired by recent advance in deep network based image\nclassification, and experimentally demonstrate its effectiveness. Comprehensive\nquantitative evaluations are conducted on several widely-used image benchmarks.\nOn all benchmarks, our proposed deep hashing algorithm outperforms all\nstate-of-the-art competitors by significant margins. In particular, our\nalgorithm achieves a near-perfect 0.99 in terms of Hamming ranking accuracy\nwith only 12 bits on MNIST, and a new record of 0.74 on the CIFAR10 dataset. In\ncomparison, the best accuracies obtained on CIFAR10 by existing hashing\nalgorithms without or with deep networks are known to be 0.36 and 0.58\nrespectively.</p>\n", "tags": ["Image Retrieval", "AAAI", "DATASETS", "Hashing Methods", "Neural Hashing", "Evaluation"], "tsne_embedding": [-11.08913803100586, -5.523730754852295], "cluster": 1}, {"key": "mu2018towards", "year": "2018", "citations": "11", "title": "Towards Practical Visual Search Engine Within Elasticsearch", "abstract": "<p>In this paper, we describe our end-to-end content-based image retrieval\nsystem built upon Elasticsearch, a well-known and popular textual search\nengine. As far as we know, this is the first time such a system has been\nimplemented in eCommerce, and our efforts have turned out to be highly\nworthwhile. We end up with a novel and exciting visual search solution that is\nextremely easy to be deployed, distributed, scaled and monitored in a\ncost-friendly manner. Moreover, our platform is intrinsically flexible in\nsupporting multimodal searches, where visual and textual information can be\njointly leveraged in retrieval.\n  The core idea is to encode image feature vectors into a collection of string\ntokens in a way such that closer vectors will share more string tokens in\ncommon. By doing that, we can utilize Elasticsearch to efficiently retrieve\nsimilar images based on similarities within encoded sting tokens. As part of\nthe development, we propose a novel vector to string encoding method, which is\nshown to substantially outperform the previous ones in terms of both precision\nand latency.\n  First-hand experiences in implementing this Elasticsearch-based platform are\nextensively addressed, which should be valuable to practitioners also\ninterested in building visual search engine on top of Elasticsearch.</p>\n", "tags": ["Image Retrieval", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [-1.9190962314605713, 13.922832489013672], "cluster": 6}, {"key": "mu2019empirical", "year": "2019", "citations": "11", "title": "An Empirical Comparison Of FAISS And FENSHSES For Nearest Neighbor Search In Hamming Space", "abstract": "<p>In this paper, we compare the performances of FAISS and FENSHSES on nearest\nneighbor search in Hamming space\u2013a fundamental task with ubiquitous\napplications in nowadays eCommerce. Comprehensive evaluations are made in terms\nof indexing speed, search latency and RAM consumption. This comparison is\nconducted towards a better understanding on trade-offs between nearest neighbor\nsearch systems implemented in main memory and the ones implemented in secondary\nmemory, which is largely unaddressed in literature.</p>\n", "tags": ["Tools & Libraries", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [8.526673316955566, -7.0778961181640625], "cluster": 2}, {"key": "mukherjee2025nmf", "year": "2025", "citations": "14", "title": "An NMF Perspective On Binary Hashing", "abstract": "<p>The pervasiveness of massive data repositories has led\nto much interest in efficient methods for indexing, search,\nand retrieval. For image data, a rapidly developing body of\nwork for these applications shows impressive performance\nwith methods that broadly fall under the umbrella term of\nBinary Hashing. Given a distance matrix, a binary hashing\nalgorithm solves for a binary code for the given set of examples, whose Hamming distance nicely approximates the\noriginal distances. The formulation is non-convex \u2014 so existing solutions adopt spectral relaxations or perform coordinate descent (or quantization) on a surrogate objective\nthat is numerically more tractable. In this paper, we first\nderive an Augmented Lagrangian approach to optimize the\nstandard binary Hashing objective (i.e., maintain fidelity\nwith a given distance matrix). With appropriate step sizes,\nwe find that this scheme already yields results that match or\nsubstantially outperform state of the art methods on most\nbenchmarks used in the literature. Then, to allow the model\nto scale to large datasets, we obtain an interesting reformulation of the binary hashing objective as a non-negative matrix factorization. Later, this leads to a simple multiplicative updates algorithm \u2014 whose parallelization properties\nare exploited to obtain a fast GPU based implementation.\nWe give a probabilistic analysis of our initialization scheme\nand present a range of experiments to show that the method\nis simple to implement and competes favorably with available methods (both for optimization and generalization).</p>\n", "tags": ["DATASETS", "Hashing Methods", "Compact Codes", "ICCV", "Quantization", "Tools & Libraries", "Evaluation"], "tsne_embedding": [2.9569854736328125, 14.14242172241211], "cluster": 6}, {"key": "nardini2024efficient", "year": "2024", "citations": "10", "title": "Efficient Multi-vector Dense Retrieval Using Bit Vectors", "abstract": "<p>Dense retrieval techniques employ pre-trained large language models to build\na high-dimensional representation of queries and passages. These\nrepresentations compute the relevance of a passage w.r.t. to a query using\nefficient similarity measures. In this line, multi-vector representations show\nimproved effectiveness at the expense of a one-order-of-magnitude increase in\nmemory footprint and query latency by encoding queries and documents on a\nper-token level. Recently, PLAID has tackled these problems by introducing a\ncentroid-based term representation to reduce the memory impact of multi-vector\nsystems. By exploiting a centroid interaction mechanism, PLAID filters out\nnon-relevant documents, thus reducing the cost of the successive ranking\nstages. This paper proposes ``Efficient Multi-Vector dense retrieval with Bit\nvectors\u2019\u2019 (EMVB), a novel framework for efficient query processing in\nmulti-vector dense retrieval. First, EMVB employs a highly efficient\npre-filtering step of passages using optimized bit vectors. Second, the\ncomputation of the centroid interaction happens column-wise, exploiting SIMD\ninstructions, thus reducing its latency. Third, EMVB leverages Product\nQuantization (PQ) to reduce the memory footprint of storing vector\nrepresentations while jointly allowing for fast late interaction. Fourth, we\nintroduce a per-document term filtering method that further improves the\nefficiency of the last step. Experiments on MS MARCO and LoTTE show that EMVB\nis up to 2.8x faster while reducing the memory footprint by 1.8x with no loss\nin retrieval accuracy compared to PLAID.</p>\n", "tags": ["Tools & Libraries", "Quantization", "Efficiency And Optimization"], "tsne_embedding": [3.3897299766540527, 0.5254074335098267], "cluster": 4}, {"key": "nathan2019learning", "year": "2019", "citations": "166", "title": "Learning Multi-dimensional Indexes", "abstract": "<p>Scanning and filtering over multi-dimensional tables are key operations in\nmodern analytical database engines. To optimize the performance of these\noperations, databases often create clustered indexes over a single dimension or\nmulti-dimensional indexes such as R-trees, or use complex sort orders (e.g.,\nZ-ordering). However, these schemes are often hard to tune and their\nperformance is inconsistent across different datasets and queries. In this\npaper, we introduce Flood, a multi-dimensional in-memory index that\nautomatically adapts itself to a particular dataset and workload by jointly\noptimizing the index structure and data storage. Flood achieves up to three\norders of magnitude faster performance for range scans with predicates than\nstate-of-the-art multi-dimensional indexes or sort orders on real-world\ndatasets and workloads. Our work serves as a building block towards an\nend-to-end learned database system.</p>\n", "tags": ["Vector Indexing", "Tools & Libraries", "Evaluation", "DATASETS"], "tsne_embedding": [-4.53599739074707, 20.832963943481445], "cluster": 6}, {"key": "neuman2023graph", "year": "2023", "citations": "10", "title": "Graph Laplacians On Shared Nearest Neighbor Graphs And Graph Laplacians On \\(k\\)-nearest Neighbor Graphs Having The Same Limit", "abstract": "<p>A Shared Nearest Neighbor (SNN) graph is a type of graph construction using\nshared nearest neighbor information, which is a secondary similarity measure\nbased on the rankings induced by a primary \\(k\\)-nearest neighbor (\\(k\\)-NN)\nmeasure. SNN measures have been touted as being less prone to the curse of\ndimensionality than conventional distance measures, and thus methods using SNN\ngraphs have been widely used in applications, particularly in clustering\nhigh-dimensional data sets and in finding outliers in subspaces of high\ndimensional data. Despite this, the theoretical study of SNN graphs and graph\nLaplacians remains unexplored. In this pioneering work, we make the first\ncontribution in this direction. We show that large scale asymptotics of an SNN\ngraph Laplacian reach a consistent continuum limit; this limit is the same as\nthat of a \\(k\\)-NN graph Laplacian. Moreover, we show that the pointwise\nconvergence rate of the graph Laplacian is linear with respect to \\((k/n)^{1/m}\\)\nwith high probability.</p>\n", "tags": ["Graph Based ANN"], "tsne_embedding": [22.13633155822754, 12.237709999084473], "cluster": 0}, {"key": "neyshabur2025power", "year": "2025", "citations": "57", "title": "The Power Of Asymmetry In Binary Hashing", "abstract": "<p>When approximating binary similarity using the hamming distance between short\nbinary hashes, we show that even if the similarity is symmetric, we can have\nshorter and more accurate hashes by using two distinct code maps. I.e. by approximating the similarity between x and x\n0\nas the hamming distance between f(x)\nand g(x0), for two distinct binary codes f, g, rather than as the hamming distance\nbetween f(x) and f(x0).</p>\n", "tags": ["Compact Codes", "Hashing Methods", "Evaluation"], "tsne_embedding": [19.876293182373047, -11.896549224853516], "cluster": 2}, {"key": "ng2023unsupervised", "year": "2023", "citations": "15", "title": "Unsupervised Hashing With Similarity Distribution Calibration", "abstract": "<p>Unsupervised hashing methods typically aim to preserve the similarity between\ndata points in a feature space by mapping them to binary hash codes. However,\nthese methods often overlook the fact that the similarity between data points\nin the continuous feature space may not be preserved in the discrete hash code\nspace, due to the limited similarity range of hash codes. The similarity range\nis bounded by the code length and can lead to a problem known as similarity\ncollapse. That is, the positive and negative pairs of data points become less\ndistinguishable from each other in the hash space. To alleviate this problem,\nin this paper a novel Similarity Distribution Calibration (SDC) method is\nintroduced. SDC aligns the hash code similarity distribution towards a\ncalibration distribution (e.g., beta distribution) with sufficient spread\nacross the entire similarity range, thus alleviating the similarity collapse\nproblem. Extensive experiments show that our SDC outperforms significantly the\nstate-of-the-art alternatives on coarse category-level and instance-level image\nretrieval. Code is available at https://github.com/kamwoh/sdc.</p>\n", "tags": ["Alt", "Hashing Methods", "Evaluation"], "tsne_embedding": [0.7291930913925171, 5.202629089355469], "cluster": 4}, {"key": "nguyen2021oscar", "year": "2021", "citations": "14", "title": "Oscar-net: Object-centric Scene Graph Attention For Image Attribution", "abstract": "<p>Images tell powerful stories but cannot always be trusted. Matching images\nback to trusted sources (attribution) enables users to make a more informed\njudgment of the images they encounter online. We propose a robust image hashing\nalgorithm to perform such matching. Our hash is sensitive to manipulation of\nsubtle, salient visual details that can substantially change the story told by\nan image. Yet the hash is invariant to benign transformations (changes in\nquality, codecs, sizes, shapes, etc.) experienced by images during online\nredistribution. Our key contribution is OSCAR-Net (Object-centric Scene Graph\nAttention for Image Attribution Network); a robust image hashing model inspired\nby recent successes of Transformers in the visual domain. OSCAR-Net constructs\na scene graph representation that attends to fine-grained changes of every\nobject\u2019s visual appearance and their spatial relationships. The network is\ntrained via contrastive learning on a dataset of original and manipulated\nimages yielding a state of the art image hash for content fingerprinting that\nscales to millions of images.</p>\n", "tags": ["ICCV", "Image Retrieval", "DATASETS", "Hashing Methods"], "tsne_embedding": [-13.850132942199707, 13.23522663116455], "cluster": 3}, {"key": "nguyennhu2025lightweight", "year": "2025", "citations": "6", "title": "A Lightweight Moment Retrieval System With Global Re-ranking And Robust Adaptive Bidirectional Temporal Search", "abstract": "<p>The exponential growth of digital video content has posed critical challenges\nin moment-level video retrieval, where existing methodologies struggle to\nefficiently localize specific segments within an expansive video corpus.\nCurrent retrieval systems are constrained by computational inefficiencies,\ntemporal context limitations, and the intrinsic complexity of navigating video\ncontent. In this paper, we address these limitations through a novel\nInteractive Video Corpus Moment Retrieval framework that integrates a\nSuperGlobal Reranking mechanism and Adaptive Bidirectional Temporal Search\n(ABTS), strategically optimizing query similarity, temporal stability, and\ncomputational resources. By preprocessing a large corpus of videos using a\nkeyframe extraction model and deduplication technique through image hashing,\nour approach provides a scalable solution that significantly reduces storage\nrequirements while maintaining high localization precision across diverse video\nrepositories.</p>\n", "tags": ["Image Retrieval", "Tools & Libraries", "Hashing Methods", "Evaluation"], "tsne_embedding": [-6.199402809143066, 21.637184143066406], "cluster": 6}, {"key": "nikoli\u01072020bitpruning", "year": "2020", "citations": "13", "title": "Bitpruning: Learning Bitlengths For Aggressive And Accurate Quantization", "abstract": "<p>Neural networks have demonstrably achieved state-of-the art accuracy using\nlow-bitlength integer quantization, yielding both execution time and energy\nbenefits on existing hardware designs that support short bitlengths. However,\nthe question of finding the minimum bitlength for a desired accuracy remains\nopen. We introduce a training method for minimizing inference bitlength at any\ngranularity while maintaining accuracy. Namely, we propose a regularizer that\npenalizes large bitlength representations throughout the architecture and show\nhow it can be modified to minimize other quantifiable criteria, such as number\nof operations or memory footprint. We demonstrate that our method learns\nthrifty representations while maintaining accuracy. With ImageNet, the method\nproduces an average per layer bitlength of 4.13, 3.76 and 4.36 bits on AlexNet,\nResNet18 and MobileNet V2 respectively, remaining within 2.0%, 0.5% and 0.5% of\nthe base TOP-1 accuracy.</p>\n", "tags": ["Quantization", "Efficiency And Optimization"], "tsne_embedding": [-6.239542007446289, -16.526437759399414], "cluster": 5}, {"key": "ning2016scalable", "year": "2016", "citations": "40", "title": "Scalable Image Retrieval By Sparse Product Quantization", "abstract": "<p>Fast Approximate Nearest Neighbor (ANN) search technique for high-dimensional\nfeature indexing and retrieval is the crux of large-scale image retrieval. A\nrecent promising technique is Product Quantization, which attempts to index\nhigh-dimensional image features by decomposing the feature space into a\nCartesian product of low dimensional subspaces and quantizing each of them\nseparately. Despite the promising results reported, their quantization approach\nfollows the typical hard assignment of traditional quantization methods, which\nmay result in large quantization errors and thus inferior search performance.\nUnlike the existing approaches, in this paper, we propose a novel approach\ncalled Sparse Product Quantization (SPQ) to encoding the high-dimensional\nfeature vectors into sparse representation. We optimize the sparse\nrepresentations of the feature vectors by minimizing their quantization errors,\nmaking the resulting representation is essentially close to the original data\nin practice. Experiments show that the proposed SPQ technique is not only able\nto compress data, but also an effective encoding technique. We obtain\nstate-of-the-art results for ANN search on four public image datasets and the\npromising results of content-based image retrieval further validate the\nefficacy of our proposed method.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Similarity Search", "Quantization", "Evaluation"], "tsne_embedding": [-9.496007919311523, 11.751519203186035], "cluster": 6}, {"key": "norouzi2025hamming", "year": "2025", "citations": "540", "title": "Hamming Distance Metric Learning", "abstract": "<p>Motivated by large-scale multimedia applications we propose to learn mappings\nfrom high-dimensional data to binary codes that preserve semantic similarity.\nBinary codes are well suited to large-scale applications as they are storage efficient and permit exact sub-linear kNN search. The framework is applicable\nto broad families of mappings, and uses a flexible form of triplet ranking loss.\nWe overcome discontinuous optimization of the discrete mappings by minimizing\na piecewise-smooth upper bound on empirical loss, inspired by latent structural\nSVMs. We develop a new loss-augmented inference algorithm that is quadratic in\nthe code length. We show strong retrieval performance on CIFAR-10 and MNIST,\nwith promising classification results using no more than kNN on the binary codes.</p>\n", "tags": ["Distance Metric Learning", "Compact Codes", "Similarity Search", "Tools & Libraries", "Evaluation"], "tsne_embedding": [0.0962488055229187, 10.762691497802734], "cluster": 6}, {"key": "norouzi2025minimal", "year": "2025", "citations": "730", "title": "Minimal Loss Hashing", "abstract": "<p>We propose a method for learning similaritypreserving\nhash functions that map highdimensional\ndata onto binary codes. The\nformulation is based on structured prediction\nwith latent variables and a hinge-like\nloss function. It is efficient to train for large\ndatasets, scales well to large code lengths,\nand outperforms state-of-the-art methods.</p>\n", "tags": ["Compact Codes", "DATASETS", "Hashing Methods", "Evaluation"], "tsne_embedding": [2.194319248199463, -12.290441513061523], "cluster": 9}, {"key": "noshad2018scalable", "year": "2018", "citations": "7", "title": "Scalable Hash-based Estimation Of Divergence Measures", "abstract": "<p>We propose a scalable divergence estimation method based on hashing. Consider\ntwo continuous random variables \\(X\\) and \\(Y\\) whose densities have bounded\nsupport. We consider a particular locality sensitive random hashing, and\nconsider the ratio of samples in each hash bin having non-zero numbers of Y\nsamples. We prove that the weighted average of these ratios over all of the\nhash bins converges to f-divergences between the two samples sets. We show that\nthe proposed estimator is optimal in terms of both MSE rate and computational\ncomplexity. We derive the MSE rates for two families of smooth functions; the\nH\"{o}lder smoothness class and differentiable functions. In particular, it is\nproved that if the density functions have bounded derivatives up to the order\n\\(d/2\\), where \\(d\\) is the dimension of samples, the optimal parametric MSE rate\nof \\(O(1/N)\\) can be achieved. The computational complexity is shown to be\n\\(O(N)\\), which is optimal. To the best of our knowledge, this is the first\nempirical divergence estimator that has optimal computational complexity and\nachieves the optimal parametric MSE estimation rate.</p>\n", "tags": ["Hashing Methods"], "tsne_embedding": [25.625839233398438, -0.21687015891075134], "cluster": 7}, {"key": "nouredanesh2016gabor", "year": "2016", "citations": "9", "title": "Gabor Barcodes For Medical Image Retrieval", "abstract": "<p>In recent years, advances in medical imaging have led to the emergence of\nmassive databases, containing images from a diverse range of modalities. This\nhas significantly heightened the need for automated annotation of the images on\none side, and fast and memory-efficient content-based image retrieval systems\non the other side. Binary descriptors have recently gained more attention as a\npotential vehicle to achieve these goals. One of the recently introduced binary\ndescriptors for tagging of medical images are Radon barcodes (RBCs) that are\ndriven from Radon transform via local thresholding. Gabor transform is also a\npowerful transform to extract texture-based information. Gabor features have\nexhibited robustness against rotation, scale, and also photometric\ndisturbances, such as illumination changes and image noise in many\napplications. This paper introduces Gabor Barcodes (GBCs), as a novel framework\nfor the image annotation. To find the most discriminative GBC for a given query\nimage, the effects of employing Gabor filters with different parameters, i.e.,\ndifferent sets of scales and orientations, are investigated, resulting in\ndifferent barcode lengths and retrieval performances. The proposed method has\nbeen evaluated on the IRMA dataset with 193 classes comprising of 12,677 x-ray\nimages for indexing, and 1,733 x-rays images for testing. A total error score\nas low as \\(351\\) (\\(\\approx 80%\\) accuracy for the first hit) was achieved.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Tools & Libraries", "Evaluation", "Robustness"], "tsne_embedding": [-24.0332088470459, 17.048959732055664], "cluster": 3}, {"key": "novotn\u00fd2018implementation", "year": "2018", "citations": "27", "title": "Implementation Notes For The Soft Cosine Measure", "abstract": "<p>The standard bag-of-words vector space model (VSM) is efficient, and\nubiquitous in information retrieval, but it underestimates the similarity of\ndocuments with the same meaning, but different terminology. To overcome this\nlimitation, Sidorov et al. proposed the Soft Cosine Measure (SCM) that\nincorporates term similarity relations. Charlet and Damnati showed that the SCM\nis highly effective in question answering (QA) systems. However, the\northonormalization algorithm proposed by Sidorov et al. has an impractical time\ncomplexity of \\(\\mathcal O(n^4)\\), where n is the size of the vocabulary.\n  In this paper, we prove a tighter lower worst-case time complexity bound of\n\\(\\mathcal O(n^3)\\). We also present an algorithm for computing the similarity\nbetween documents and we show that its worst-case time complexity is \\(\\mathcal\nO(1)\\) given realistic conditions. Lastly, we describe implementation in\ngeneral-purpose vector databases such as Annoy, and Faiss and in the inverted\nindices of text search engines such as Apache Lucene, and ElasticSearch. Our\nresults enable the deployment of the SCM in real-world information retrieval\nsystems.</p>\n", "tags": ["CIKM", "Text Retrieval", "Tools & Libraries", "Graph Based ANN"], "tsne_embedding": [4.333441257476807, 0.7260883450508118], "cluster": 4}, {"key": "ootomo2023cagra", "year": "2023", "citations": "7", "title": "CAGRA: Highly Parallel Graph Construction And Approximate Nearest Neighbor Search For Gpus", "abstract": "<p>Approximate Nearest Neighbor Search (ANNS) plays a critical role in various\ndisciplines spanning data mining and artificial intelligence, from information\nretrieval and computer vision to natural language processing and recommender\nsystems. Data volumes have soared in recent years and the computational cost of\nan exhaustive exact nearest neighbor search is often prohibitive, necessitating\nthe adoption of approximate techniques. The balanced performance and recall of\ngraph-based approaches have more recently garnered significant attention in\nANNS algorithms, however, only a few studies have explored harnessing the power\nof GPUs and multi-core processors despite the widespread use of massively\nparallel and general-purpose computing. To bridge this gap, we introduce a\nnovel parallel computing hardware-based proximity graph and search algorithm.\nBy leveraging the high-performance capabilities of modern hardware, our\napproach achieves remarkable efficiency gains. In particular, our method\nsurpasses existing CPU and GPU-based methods in constructing the proximity\ngraph, demonstrating higher throughput in both large- and small-batch searches\nwhile maintaining compatible accuracy. In graph construction time, our method,\nCAGRA, is 2.2~27x faster than HNSW, which is one of the CPU SOTA\nimplementations. In large-batch query throughput in the 90% to 95% recall\nrange, our method is 33~77x faster than HNSW, and is 3.8~8.8x faster than the\nSOTA implementations for GPU. For a single query, our method is 3.4~53x faster\nthan HNSW at 95% recall.</p>\n", "tags": ["Graph Based ANN", "Recommender Systems", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [17.699569702148438, 19.977693557739258], "cluster": 0}, {"key": "opitz2018deep", "year": "2018", "citations": "164", "title": "Deep Metric Learning With BIER: Boosting Independent Embeddings Robustly", "abstract": "<p>Learning similarity functions between image pairs with deep neural networks\nyields highly correlated activations of embeddings. In this work, we show how\nto improve the robustness of such embeddings by exploiting the independence\nwithin ensembles. To this end, we divide the last embedding layer of a deep\nnetwork into an embedding ensemble and formulate training this ensemble as an\nonline gradient boosting problem. Each learner receives a reweighted training\nsample from the previous learners. Further, we propose two loss functions which\nincrease the diversity in our ensemble. These loss functions can be applied\neither for weight initialization or during training. Together, our\ncontributions leverage large embedding sizes more effectively by significantly\nreducing correlation of the embedding and consequently increase retrieval\naccuracy of the embedding. Our method works with any differentiable loss\nfunction and does not introduce any additional parameters during test time. We\nevaluate our metric learning method on image retrieval tasks and show that it\nimproves over state-of-the-art methods on the CUB 200-2011, Cars-196, Stanford\nOnline Products, In-Shop Clothes Retrieval and VehicleID datasets.</p>\n", "tags": ["Distance Metric Learning", "Image Retrieval", "DATASETS", "Robustness"], "tsne_embedding": [-21.50260353088379, 3.1303939819335938], "cluster": 3}, {"key": "ortega2022unconventional", "year": "2022", "citations": "5", "title": "Unconventional Application Of K-means For Distributed Approximate Similarity Search", "abstract": "<p>Similarity search based on a distance function in metric spaces is a\nfundamental problem for many applications. Queries for similar objects lead to\nthe well-known machine learning task of nearest-neighbours identification. Many\ndata indexing strategies, collectively known as Metric Access Methods (MAM),\nhave been proposed to speed up queries for similar elements in this context.\nMoreover, since exact approaches to solve similarity queries can be complex and\ntime-consuming, alternative options have appeared to reduce query execution\ntime, such as returning approximate results or resorting to distributed\ncomputing platforms. In this paper, we introduce MASK (Multilevel Approximate\nSimilarity search with \\(k\\)-means), an unconventional application of the\n\\(k\\)-means algorithm as the foundation of a multilevel index structure for\napproximate similarity search, suitable for metric spaces. We show that\ninherent properties of \\(k\\)-means, like representing high-density data areas\nwith fewer prototypes, can be leveraged for this purpose. An implementation of\nthis new indexing method is evaluated, using a synthetic dataset and a\nreal-world dataset in a high-dimensional and high-sparsity space. Results are\npromising and underpin the applicability of this novel indexing method in\nmultiple domains.</p>\n", "tags": ["Alt", "Similarity Search", "Vector Indexing", "DATASETS"], "tsne_embedding": [10.92097282409668, 4.391054630279541], "cluster": 4}, {"key": "oymak2016near", "year": "2016", "citations": "13", "title": "Near-optimal Sample Complexity Bounds For Circulant Binary Embedding", "abstract": "<p>Binary embedding is the problem of mapping points from a high-dimensional\nspace to a Hamming cube in lower dimension while preserving pairwise distances.\nAn efficient way to accomplish this is to make use of fast embedding techniques\ninvolving Fourier transform e.g.~circulant matrices. While binary embedding has\nbeen studied extensively, theoretical results on fast binary embedding are\nrather limited. In this work, we build upon the recent literature to obtain\nsignificantly better dependencies on the problem parameters. A set of \\(N\\)\npoints in \\(\\mathbb{R}^n\\) can be properly embedded into the Hamming cube \\(\\{\\pm\n1\\}^k\\) with \\(\\delta\\) distortion, by using \\(k\\sim\\delta^{-3}log N\\) samples\nwhich is optimal in the number of points \\(N\\) and compares well with the optimal\ndistortion dependency \\(\\delta^{-2}\\). Our optimal embedding result applies in\nthe regime \\(log N\\lesssim n^{1/3}\\). Furthermore, if the looser condition \\(log\nN\\lesssim \\sqrt{n}\\) holds, we show that all but an arbitrarily small fraction\nof the points can be optimally embedded. We believe our techniques can be\nuseful to obtain improved guarantees for other nonlinear embedding problems.</p>\n", "tags": ["ICASSP", "Hashing Methods", "Evaluation"], "tsne_embedding": [34.75071334838867, 0.3980098068714142], "cluster": 7}, {"key": "pachori2016zero", "year": "2016", "citations": "138", "title": "Zero Shot Hashing", "abstract": "<p>This paper provides a framework to hash images containing instances of\nunknown object classes. In many object recognition problems, we might have\naccess to huge amount of data. It may so happen that even this huge data\ndoesn\u2019t cover the objects belonging to classes that we see in our day to day\nlife. Zero shot learning exploits auxiliary information (also called as\nsignatures) in order to predict the labels corresponding to unknown classes. In\nthis work, we attempt to generate the hash codes for images belonging to unseen\nclasses, information of which is available only through the textual corpus. We\nformulate this as an unsupervised hashing formulation as the exact labels are\nnot available for the instances of unseen classes. We show that the proposed\nsolution is able to generate hash codes which can predict labels corresponding\nto unseen classes with appreciably good precision.</p>\n", "tags": ["Tools & Libraries", "Hashing Methods", "Evaluation"], "tsne_embedding": [-17.96211814880371, -3.895864725112915], "cluster": 1}, {"key": "pachori2017hashing", "year": "2017", "citations": "24", "title": "Hashing In The Zero Shot Framework With Domain Adaptation", "abstract": "<p>Techniques to learn hash codes which can store and retrieve large dimensional\nmultimedia data efficiently have attracted broad research interests in the\nrecent years. With rapid explosion of newly emerged concepts and online data,\nexisting supervised hashing algorithms suffer from the problem of scarcity of\nground truth annotations due to the high cost of obtaining manual annotations.\nTherefore, we propose an algorithm to learn a hash function from training\nimages belonging to <code class=\"language-plaintext highlighter-rouge\">seen' classes which can efficiently encode images of\n</code>unseen\u2019 classes to binary codes. Specifically, we project the image features\nfrom visual space and semantic features from semantic space into a common\nHamming subspace. Earlier works to generate hash codes have tried to relax the\ndiscrete constraints on hash codes and solve the continuous optimization\nproblem. However, it often leads to quantization errors. In this work, we use\nthe max-margin classifier to learn an efficient hash function. To address the\nconcern of domain-shift which may arise due to the introduction of new classes,\nwe also introduce an unsupervised domain adaptation model in the proposed\nhashing framework. Results on the three datasets show the advantage of using\ndomain adaptation in learning a high-quality hash function and superiority of\nour method for the task of image retrieval performance as compared to several\nstate-of-the-art hashing methods.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Compact Codes", "Quantization", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-11.228230476379395, -6.917665004730225], "cluster": 1}, {"key": "pacuk2016locality", "year": "2016", "citations": "7", "title": "Locality-sensitive Hashing Without False Negatives For L_p", "abstract": "<p>In this paper, we show a construction of locality-sensitive hash functions\nwithout false negatives, i.e., which ensure collision for every pair of points\nwithin a given radius \\(R\\) in \\(d\\) dimensional space equipped with \\(l_p\\) norm\nwhen \\(p \\in [1,\\infty]\\). Furthermore, we show how to use these hash functions\nto solve the \\(c\\)-approximate nearest neighbor search problem without false\nnegatives. Namely, if there is a point at distance \\(R\\), we will certainly\nreport it and points at distance greater than \\(cR\\) will not be reported for\n\\(c=\u03a9(\\sqrt{d},d^{1-\\frac{1}{p}})\\). The constructed algorithms work: - with\npreprocessing time \\(\\mathcal{O}(n log(n))\\) and sublinear expected query time,</p>\n<ul>\n  <li>with preprocessing time \\(\\mathcal{O}(\\mathrm{poly}(n))\\) and expected query\ntime \\(\\mathcal{O}(log(n))\\). Our paper reports progress on answering the open\nproblem presented by Pagh [8] who considered the nearest neighbor search\nwithout false negatives for the Hamming distance.</li>\n</ul>\n", "tags": ["Hashing Methods", "Graph Based ANN", "Efficiency And Optimization"], "tsne_embedding": [31.52728271484375, -2.0798425674438477], "cluster": 7}, {"key": "pagh2016approximate", "year": "2016", "citations": "10", "title": "Approximate Furthest Neighbor With Application To Annulus Query", "abstract": "<p>Much recent work has been devoted to approximate nearest neighbor queries.\nMotivated by applications in recommender systems, we consider approximate\nfurthest neighbor (AFN) queries and present a simple, fast, and highly\npractical data structure for answering AFN queries in high- dimensional\nEuclidean space. The method builds on the technique of In- dyk (SODA 2003),\nstoring random projections to provide sublinear query time for AFN. However, we\nintroduce a different query algorithm, improving on Indyk\u2019s approximation\nfactor and reducing the running time by a logarithmic factor. We also present a\nvariation based on a query- independent ordering of the database points; while\nthis does not have the provable approximation factor of the query-dependent\ndata structure, it offers significant improvement in time and space complexity.\nWe give a theoretical analysis, and experimental results. As an application,\nthe query-dependent approach is used for deriving a data structure for the\napproximate annulus query problem, which is defined as follows: given an input\nset S and two parameters r &gt; 0 and w &gt;= 1, construct a data structure that\nreturns for each query point q a point p in S such that the distance between p\nand q is at least r/w and at most wr.</p>\n", "tags": ["Recommender Systems", "Locality Sensitive Hashing", "Graph Based ANN", "Efficiency And Optimization"], "tsne_embedding": [19.484683990478516, 1.1939165592193604], "cluster": 7}, {"key": "palmer2023efficient", "year": "2023", "citations": "16", "title": "Efficient Online String Matching Through Linked Weak Factors", "abstract": "<p>Online string matching is a computational problem involving the search for\npatterns or substrings in a large text dataset, with the pattern and text being\nprocessed sequentially, without prior access to the entire text. Its relevance\nstems from applications in data compression, data mining, text editing, and\nbioinformatics, where rapid and efficient pattern matching is crucial. Various\nsolutions have been proposed over the past few decades, employing diverse\ntechniques. Recently, weak recognition approaches have attracted increasing\nattention. This paper presents Hash Chain, a new algorithm based on a robust\nweak factor recognition approach that connects adjacent factors through\nhashing. Despite its O(nm) complexity, the algorithm exhibits a sublinear\nbehavior in practice and achieves superior performance compared to the most\neffective algorithms.</p>\n", "tags": ["DATASETS", "Tools & Libraries", "Hashing Methods", "Evaluation"], "tsne_embedding": [5.457125186920166, -15.062957763671875], "cluster": 2}, {"key": "pan2020tcdesc", "year": "2020", "citations": "24", "title": "Tcdesc: Learning Topology Consistent Descriptors For Image Matching", "abstract": "<p>The constraint of neighborhood consistency or local consistency is widely\nused for robust image matching. In this paper, we focus on learning\nneighborhood topology consistent descriptors (TCDesc), while former works of\nlearning descriptors, such as HardNet and DSM, only consider point-to-point\nEuclidean distance among descriptors and totally neglect neighborhood\ninformation of descriptors. To learn topology consistent descriptors, first we\npropose the linear combination weights to depict the topological relationship\nbetween center descriptor and its kNN descriptors, where the difference between\ncenter descriptor and the linear combination of its kNN descriptors is\nminimized. Then we propose the global mapping function which maps the local\nlinear combination weights to the global topology vector and define the\ntopology distance of matching descriptors as l1 distance between their topology\nvectors. Last we employ adaptive weighting strategy to jointly minimize\ntopology distance and Euclidean distance, which automatically adjust the weight\nor attention of two distances in triplet loss. Our method has the following two\nadvantages: (1) We are the first to consider neighborhood information of\ndescriptors, while former works mainly focus on neighborhood consistency of\nfeature points; (2) Our method can be applied in any former work of learning\ndescriptors by triplet loss. Experimental results verify the generalization of\nour method: We can improve the performances of both HardNet and DSM on several\nbenchmarks.</p>\n", "tags": ["Evaluation", "Distance Metric Learning"], "tsne_embedding": [31.944589614868164, 4.228348255157471], "cluster": 7}, {"key": "pang2023locally", "year": "2023", "citations": "11", "title": "Locally Stylized Neural Radiance Fields", "abstract": "<p>In recent years, there has been increasing interest in applying stylization\non 3D scenes from a reference style image, in particular onto neural radiance\nfields (NeRF). While performing stylization directly on NeRF guarantees\nappearance consistency over arbitrary novel views, it is a challenging problem\nto guide the transfer of patterns from the style image onto different parts of\nthe NeRF scene. In this work, we propose a stylization framework for NeRF based\non local style transfer. In particular, we use a hash-grid encoding to learn\nthe embedding of the appearance and geometry components, and show that the\nmapping defined by the hash table allows us to control the stylization to a\ncertain extent. Stylization is then achieved by optimizing the appearance\nbranch while keeping the geometry branch fixed. To support local style\ntransfer, we propose a new loss function that utilizes a segmentation network\nand bipartite matching to establish region correspondences between the style\nimage and the content images obtained from volume rendering. Our experiments\nshow that our method yields plausible stylization results with novel view\nsynthesis while having flexible controllability via manipulating and\ncustomizing the region correspondences.</p>\n", "tags": ["ICCV", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-1.6481534242630005, 19.402843475341797], "cluster": 6}, {"key": "pansare2022learning", "year": "2022", "citations": "9", "title": "Learning Compressed Embeddings For On-device Inference", "abstract": "<p>In deep learning, embeddings are widely used to represent categorical\nentities such as words, apps, and movies. An embedding layer maps each entity\nto a unique vector, causing the layer\u2019s memory requirement to be proportional\nto the number of entities. In the recommendation domain, a given category can\nhave hundreds of thousands of entities, and its embedding layer can take\ngigabytes of memory. The scale of these networks makes them difficult to deploy\nin resource constrained environments. In this paper, we propose a novel\napproach for reducing the size of an embedding table while still mapping each\nentity to its own unique embedding. Rather than maintaining the full embedding\ntable, we construct each entity\u2019s embedding \u201con the fly\u201d using two separate\nembedding tables. The first table employs hashing to force multiple entities to\nshare an embedding. The second table contains one trainable weight per entity,\nallowing the model to distinguish between entities sharing the same embedding.\nSince these two tables are trained jointly, the network is able to learn a\nunique embedding per entity, helping it maintain a discriminative capability\nsimilar to a model with an uncompressed embedding table. We call this approach\nMEmCom (Multi-Embedding Compression). We compare with state-of-the-art model\ncompression techniques for multiple problem classes including classification\nand ranking. On four popular recommender system datasets, MEmCom had a 4%\nrelative loss in nDCG while compressing the input embedding sizes of our\nrecommendation models by 16x, 4x, 12x, and 40x. MEmCom outperforms the\nstate-of-the-art techniques, which achieved 16%, 6%, 10%, and 8% relative loss\nin nDCG at the respective compression ratios. Additionally, MEmCom is able to\ncompress the RankNet ranking model by 32x on a dataset with millions of users\u2019\ninteractions with games while incurring only a 1% relative loss in nDCG.</p>\n", "tags": ["Recommender Systems", "Hashing Methods", "Evaluation", "DATASETS"], "tsne_embedding": [6.2466206550598145, -4.20255708694458], "cluster": 4}, {"key": "paria2020minimizing", "year": "2020", "citations": "14", "title": "Minimizing Flops To Learn Efficient Sparse Representations", "abstract": "<p>Deep representation learning has become one of the most widely adopted\napproaches for visual search, recommendation, and identification. Retrieval of\nsuch representations from a large database is however computationally\nchallenging. Approximate methods based on learning compact representations,\nhave been widely explored for this problem, such as locality sensitive hashing,\nproduct quantization, and PCA. In this work, in contrast to learning compact\nrepresentations, we propose to learn high dimensional and sparse\nrepresentations that have similar representational capacity as dense embeddings\nwhile being more efficient due to sparse matrix multiplication operations which\ncan be much faster than dense multiplication. Following the key insight that\nthe number of operations decreases quadratically with the sparsity of\nembeddings provided the non-zero entries are distributed uniformly across\ndimensions, we propose a novel approach to learn such distributed sparse\nembeddings via the use of a carefully constructed regularization function that\ndirectly minimizes a continuous relaxation of the number of floating-point\noperations (FLOPs) incurred during retrieval. Our experiments show that our\napproach is competitive to the other baselines and yields a similar or better\nspeed-vs-accuracy tradeoff on practical datasets.</p>\n", "tags": ["Image Retrieval", "Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Recommender Systems", "Quantization"], "tsne_embedding": [1.9104840755462646, -8.941312789916992], "cluster": 9}, {"key": "pariente2025infinity", "year": "2025", "citations": "8", "title": "Infinity Search: Approximate Vector Search With Projections On Q-metric Spaces", "abstract": "<p>Despite the ubiquity of vector search applications, prevailing search algorithms overlook the metric structure of vector embeddings, treating it as a constraint rather than exploiting its underlying properties. In this paper, we demonstrate that in \\(q\\)-metric spaces, metric trees can leverage a stronger version of the triangle inequality to reduce comparisons for exact search. Notably, as \\(q\\) approaches infinity, the search complexity becomes logarithmic. Therefore, we propose a novel projection method that embeds vector datasets with arbitrary dissimilarity measures into \\(q\\)-metric spaces while preserving the nearest neighbor. We propose to learn an approximation of this projection to efficiently transform query points to a space where euclidean distances satisfy the desired properties. Our experimental results with text and image vector embeddings show that learning \\(q\\)-metric approximations enables classic metric tree algorithms \u2013 which typically underperform with high-dimensional data \u2013 to achieve competitive performance against state-of-the-art search methods.</p>\n", "tags": ["DATASETS", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [23.54547119140625, 1.5667048692703247], "cluster": 7}, {"key": "parravicini2021scaling", "year": "2021", "citations": "9", "title": "Scaling Up HBM Efficiency Of Top-k Spmv For Approximate Embedding Similarity On Fpgas", "abstract": "<p>Top-K SpMV is a key component of similarity-search on sparse embeddings. This\nsparse workload does not perform well on general-purpose NUMA systems that\nemploy traditional caching strategies. Instead, modern FPGA accelerator cards\nhave a few tricks up their sleeve. We introduce a Top-K SpMV FPGA design that\nleverages reduced precision and a novel packet-wise CSR matrix compression,\nenabling custom data layouts and delivering bandwidth efficiency often\nunreachable even in architectures with higher peak bandwidth. With HBM-based\nboards, we are 100x faster than a multi-threaded CPU implementation and 2x\nfaster than a GPU with 20% higher bandwidth, with 14.2x higher\npower-efficiency.</p>\n", "tags": ["Evaluation", "Efficiency And Optimization"], "tsne_embedding": [16.062685012817383, 22.720077514648438], "cluster": 0}, {"key": "pascualgaspar2022fast", "year": "2022", "citations": "43", "title": "Fast On-line Signature Recognition Based On VQ With Time Modeling", "abstract": "<p>This paper proposes a multi-section vector quantization approach for on-line\nsignature recognition. We have used the MCYT database, which consists of 330\nusers and 25 skilled forgeries per person performed by 5 different impostors.\nThis database is larger than those typically used in the literature.\nNevertheless, we also provide results from the SVC database.\n  Our proposed system outperforms the winner of SVC with a reduced\ncomputational requirement, which is around 47 times lower than DTW. In\naddition, our system improves the database storage requirements due to vector\ncompression, and is more privacy-friendly as it is not possible to recover the\noriginal signature using the codebooks. Experimental results with MCYT provide\na 99.76% identification rate and 2.46% EER (skilled forgeries and individual\nthreshold). Experimental results with SVC are 100% of identification rate and\n0% (individual threshold) and 0.31% (general threshold) when using a\ntwo-section VQ approach.</p>\n", "tags": ["Quantization"], "tsne_embedding": [5.788636684417725, -21.648088455200195], "cluster": 5}, {"key": "passalis2019deep", "year": "2019", "citations": "14", "title": "Deep Supervised Hashing Leveraging Quadratic Spherical Mutual Information For Content-based Image Retrieval", "abstract": "<p>Several deep supervised hashing techniques have been proposed to allow for\nefficiently querying large image databases. However, deep supervised image\nhashing techniques are developed, to a great extent, heuristically often\nleading to suboptimal results. Contrary to this, we propose an efficient deep\nsupervised hashing algorithm that optimizes the learned codes using an\ninformation-theoretic measure, the Quadratic Mutual Information (QMI). The\nproposed method is adapted to the needs of large-scale hashing and information\nretrieval leading to a novel information-theoretic measure, the Quadratic\nSpherical Mutual Information (QSMI). Apart from demonstrating the effectiveness\nof the proposed method under different scenarios and outperforming existing\nstate-of-the-art image hashing techniques, this paper provides a structured way\nto model the process of information retrieval and develop novel methods adapted\nto the needs of each application.</p>\n", "tags": ["Image Retrieval", "Hashing Methods"], "tsne_embedding": [-7.392481327056885, 6.6262946128845215], "cluster": 8}, {"key": "patel2021recall", "year": "2021", "citations": "28", "title": "Recall@k Surrogate Loss With Large Batches And Similarity Mixup", "abstract": "<p>This work focuses on learning deep visual representation models for retrieval\nby exploring the interplay between a new loss function, the batch size, and a\nnew regularization approach. Direct optimization, by gradient descent, of an\nevaluation metric, is not possible when it is non-differentiable, which is the\ncase for recall in retrieval. A differentiable surrogate loss for the recall is\nproposed in this work. Using an implementation that sidesteps the hardware\nconstraints of the GPU memory, the method trains with a very large batch size,\nwhich is essential for metrics computed on the entire retrieval database. It is\nassisted by an efficient mixup regularization approach that operates on\npairwise scalar similarities and virtually increases the batch size further.\nThe suggested method achieves state-of-the-art performance in several image\nretrieval benchmarks when used for deep metric learning. For instance-level\nrecognition, the method outperforms similar approaches that train using an\napproximation of average precision.</p>\n", "tags": ["CVPR", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [-18.408159255981445, 9.64072036743164], "cluster": 3}, {"key": "patel2024acorn", "year": "2024", "citations": "13", "title": "ACORN: Performant And Predicate-agnostic Search Over Vector Embeddings And Structured Data", "abstract": "<p>Applications increasingly leverage mixed-modality data, and must jointly\nsearch over vector data, such as embedded images, text and video, as well as\nstructured data, such as attributes and keywords. Proposed methods for this\nhybrid search setting either suffer from poor performance or support a severely\nrestricted set of search predicates (e.g., only small sets of equality\npredicates), making them impractical for many applications. To address this, we\npresent ACORN, an approach for performant and predicate-agnostic hybrid search.\nACORN builds on Hierarchical Navigable Small Worlds (HNSW), a state-of-the-art\ngraph-based approximate nearest neighbor index, and can be implemented\nefficiently by extending existing HNSW libraries. ACORN introduces the idea of\npredicate subgraph traversal to emulate a theoretically ideal, but impractical,\nhybrid search strategy. ACORN\u2019s predicate-agnostic construction algorithm is\ndesigned to enable this effective search strategy, while supporting a wide\narray of predicate sets and query semantics. We systematically evaluate ACORN\non both prior benchmark datasets, with simple, low-cardinality predicate sets,\nand complex multi-modal datasets not supported by prior methods. We show that\nACORN achieves state-of-the-art performance on all datasets, outperforming\nprior methods with 2-1,000x higher throughput at a fixed recall.</p>\n", "tags": ["Graph Based ANN", "DATASETS", "Evaluation"], "tsne_embedding": [18.007835388183594, 16.231348037719727], "cluster": 0}, {"key": "patel2024three", "year": "2024", "citations": "39", "title": "Three Things To Know About Deep Metric Learning", "abstract": "<p>This paper addresses supervised deep metric learning for open-set image\nretrieval, focusing on three key aspects: the loss function, mixup\nregularization, and model initialization. In deep metric learning, optimizing\nthe retrieval evaluation metric, recall@k, via gradient descent is desirable\nbut challenging due to its non-differentiable nature. To overcome this, we\npropose a differentiable surrogate loss that is computed on large batches,\nnearly equivalent to the entire training set. This computationally intensive\nprocess is made feasible through an implementation that bypasses the GPU memory\nlimitations. Additionally, we introduce an efficient mixup regularization\ntechnique that operates on pairwise scalar similarities, effectively increasing\nthe batch size even further. The training process is further enhanced by\ninitializing the vision encoder using foundational models, which are\npre-trained on large-scale datasets. Through a systematic study of these\ncomponents, we demonstrate that their synergy enables large models to nearly\nsolve popular benchmarks.</p>\n", "tags": ["DATASETS", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [-18.305850982666016, 9.623743057250977], "cluster": 3}, {"key": "patgiri2021deepbf", "year": "2021", "citations": "21", "title": "Deepbf: Malicious URL Detection Using Learned Bloom Filter And Evolutionary Deep Learning", "abstract": "<p>Malicious URL detection is an emerging research area due to continuous\nmodernization of various systems, for instance, Edge Computing. In this\narticle, we present a novel malicious URL detection technique, called deepBF\n(deep learning and Bloom Filter). deepBF is presented in two-fold. Firstly, we\npropose a learned Bloom Filter using 2-dimensional Bloom Filter. We\nexperimentally decide the best non-cryptography string hash function. Then, we\nderive a modified non-cryptography string hash function from the selected hash\nfunction for deepBF by introducing biases in the hashing method and compared\namong the string hash functions. The modified string hash function is compared\nto other variants of diverse non-cryptography string hash functions. It is also\ncompared with various filters, particularly, counting Bloom Filter, Kirsch\n\\textit{et al.}, and Cuckoo Filter using various use cases. The use cases\nunearth weakness and strength of the filters. Secondly, we propose a malicious\nURL detection mechanism using deepBF. We apply the evolutionary convolutional\nneural network to identify the malicious URLs. The evolutionary convolutional\nneural network is trained and tested with malicious URL datasets. The output is\ntested in deepBF for accuracy. We have achieved many conclusions from our\nexperimental evaluation and results and are able to reach various conclusive\ndecisions which are presented in the article.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Evaluation"], "tsne_embedding": [-16.66029930114746, 14.390022277832031], "cluster": 3}, {"key": "paudel2024pixelmod", "year": "2024", "citations": "5", "title": "PIXELMOD: Improving Soft Moderation Of Visual Misleading Information On Twitter", "abstract": "<p>Images are a powerful and immediate vehicle to carry misleading or outright\nfalse messages, yet identifying image-based misinformation at scale poses\nunique challenges. In this paper, we present PIXELMOD, a system that leverages\nperceptual hashes, vector databases, and optical character recognition (OCR) to\nefficiently identify images that are candidates to receive soft moderation\nlabels on Twitter. We show that PIXELMOD outperforms existing image similarity\napproaches when applied to soft moderation, with negligible performance\noverhead. We then test PIXELMOD on a dataset of tweets surrounding the 2020 US\nPresidential Election, and find that it is able to identify visually misleading\nimages that are candidates for soft moderation with 0.99% false detection and\n2.06% false negatives.</p>\n", "tags": ["DATASETS", "Evaluation"], "tsne_embedding": [-14.393649101257324, 16.56462860107422], "cluster": 3}, {"key": "pauleve2025locality", "year": "2025", "citations": "299", "title": "Locality Sensitive Hashing: A Comparison Of Hash Function Types And Querying Mechanisms", "abstract": "<p>It is well known that high-dimensional nearest-neighbor retrieval is very expensive. Dramatic performance gains are obtained using\napproximate search schemes, such as the popular Locality-Sensitive Hashing (LSH). Several extensions have been proposed to\naddress the limitations of this algorithm, in particular, by choosing more appropriate hash functions to better partition the vector\nspace. All the proposed extensions, however, rely on a structured quantizer for hashing, poorly fitting real data sets, limiting\nits performance in practice. In this paper, we compare several families of space hashing functions in a real setup, namely when\nsearching for high-dimension SIFT descriptors. The comparison of random projections, lattice quantizers, k-means and hierarchical\nk-means reveal that unstructured quantizer significantly improves the accuracy of LSH, as it closely fits the data in the feature space.\nWe then compare two querying mechanisms introduced in the literature with the one originally proposed in LSH, and discuss their\nrespective merits and limitations.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Evaluation"], "tsne_embedding": [11.093742370605469, 0.9781114459037781], "cluster": 4}, {"key": "peer2023towards", "year": "2023", "citations": "7", "title": "Towards Writer Retrieval For Historical Datasets", "abstract": "<p>This paper presents an unsupervised approach for writer retrieval based on\nclustering SIFT descriptors detected at keypoint locations resulting in\npseudo-cluster labels. With those cluster labels, a residual network followed\nby our proposed NetRVLAD, an encoding layer with reduced complexity compared to\nNetVLAD, is trained on 32x32 patches at keypoint locations. Additionally, we\nsuggest a graph-based reranking algorithm called SGR to exploit similarities of\nthe page embeddings to boost the retrieval performance. Our approach is\nevaluated on two historical datasets (Historical-WI and HisIR19). We include an\nevaluation of different backbones and NetRVLAD. It competes with related work\non historical datasets without using explicit encodings. We set a new\nState-of-the-art on both datasets by applying our reranking scheme and show\nthat our approach achieves comparable performance on a modern dataset as well.</p>\n", "tags": ["Graph Based ANN", "DATASETS", "Evaluation"], "tsne_embedding": [9.730762481689453, -10.1129732131958], "cluster": 2}, {"key": "pele2016interpolated", "year": "2016", "citations": "8", "title": "Interpolated Discretized Embedding Of Single Vectors And Vector Pairs For Classification, Metric Learning And Distance Approximation", "abstract": "<p>We propose a new embedding method for a single vector and for a pair of\nvectors. This embedding method enables: a) efficient classification and\nregression of functions of single vectors; b) efficient approximation of\ndistance functions; and c) non-Euclidean, semimetric learning. To the best of\nour knowledge, this is the first work that enables learning any general,\nnon-Euclidean, semimetrics. That is, our method is a universal semimetric\nlearning and approximation method that can approximate any distance function\nwith as high accuracy as needed with or without semimetric constraints. The\nproject homepage including code is at: http://www.ariel.ac.il/sites/ofirpele/ID</p>\n", "tags": ["CVPR", "Distance Metric Learning"], "tsne_embedding": [1.2645666599273682, 12.81761360168457], "cluster": 6}, {"key": "peng2018deep", "year": "2018", "citations": "44", "title": "Deep Reinforcement Learning For Image Hashing", "abstract": "<p>Deep hashing methods have received much attention recently, which achieve\npromising results by taking advantage of the strong representation power of\ndeep networks. However, most existing deep hashing methods learn a whole set of\nhashing functions independently, while ignore the correlations between\ndifferent hashing functions that can promote the retrieval accuracy greatly.\nInspired by the sequential decision ability of deep reinforcement learning, we\npropose a new Deep Reinforcement Learning approach for Image Hashing (DRLIH).\nOur proposed DRLIH approach models the hashing learning problem as a sequential\ndecision process, which learns each hashing function by correcting the errors\nimposed by previous ones and promotes retrieval accuracy. To the best of our\nknowledge, this is the first work to address hashing problem from deep\nreinforcement learning perspective. The main contributions of our proposed\nDRLIH approach can be summarized as follows: (1) We propose a deep\nreinforcement learning hashing network. In the proposed network, we utilize\nrecurrent neural network (RNN) as agents to model the hashing functions, which\ntake actions of projecting images into binary codes sequentially, so that the\ncurrent hashing function learning can take previous hashing functions\u2019 error\ninto account. (2) We propose a sequential learning strategy based on proposed\nDRLIH. We define the state as a tuple of internal features of RNN\u2019s hidden\nlayers and image features, which can reflect history decisions made by the\nagents. We also propose an action group method to enhance the correlation of\nhash functions in the same group. Experiments on three widely-used datasets\ndemonstrate the effectiveness of our proposed DRLIH approach.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Compact Codes", "Neural Hashing"], "tsne_embedding": [-14.399247169494629, -3.3515303134918213], "cluster": 1}, {"key": "perez2016mahalanobis", "year": "2016", "citations": "5", "title": "Mahalanobis Distance Metric Learning Algorithm For Instance-based Data Stream Classification", "abstract": "<p>With the massive data challenges nowadays and the rapid growing of\ntechnology, stream mining has recently received considerable attention. To\naddress the large number of scenarios in which this phenomenon manifests itself\nsuitable tools are required in various research fields. Instance-based data\nstream algorithms generally employ the Euclidean distance for the\nclassification task underlying this problem. A novel way to look into this\nissue is to take advantage of a more flexible metric due to the increased\nrequirements imposed by the data stream scenario. In this paper we present a\nnew algorithm that learns a Mahalanobis metric using similarity and\ndissimilarity constraints in an online manner. This approach hybridizes a\nMahalanobis distance metric learning algorithm and a k-NN data stream\nclassification algorithm with concept drift detection. First, some basic\naspects of Mahalanobis distance metric learning are described taking into\naccount key properties as well as online distance metric learning algorithms.\nSecond, we implement specific evaluation methodologies and comparative metrics\nsuch as Q statistic for data stream classification algorithms. Finally, our\nalgorithm is evaluated on different datasets by comparing its results with one\nof the best instance-based data stream classification algorithm of the state of\nthe art. The results demonstrate that our proposal is better</p>\n", "tags": ["DATASETS", "Tools & Libraries", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [-20.05811309814453, 7.878994941711426], "cluster": 3}, {"key": "petrovic2025streaming", "year": "2025", "citations": "565", "title": "Streaming First Story Detection With Application To Twitter", "abstract": "<p>With the recent rise in popularity and size of\nsocial media, there is a growing need for systems\nthat can extract useful information from\nthis amount of data. We address the problem\nof detecting new events from a stream of\nTwitter posts. To make event detection feasible\non web-scale corpora, we present an algorithm\nbased on locality-sensitive hashing which\nis able overcome the limitations of traditional\napproaches, while maintaining competitive results.\nIn particular, a comparison with a stateof-the-art\nsystem on the first story detection\ntask shows that we achieve over an order of\nmagnitude speedup in processing time, while\nretaining comparable performance. Event detection\nexperiments on a collection of 160 million\nTwitter posts show that celebrity deaths\nare the fastest spreading news on Twitter.</p>\n", "tags": ["Large Scale Search", "Hashing Methods", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [-20.32509994506836, -18.258541107177734], "cluster": 1}, {"key": "petrovic2025using", "year": "2025", "citations": "91", "title": "Using Paraphrases For Improving First Story Detection In News And Twitter", "abstract": "<p>First story detection (FSD) involves identifying\nfirst stories about events from a continuous\nstream of documents. A major problem in this\ntask is the high degree of lexical variation in\ndocuments which makes it very difficult to detect\nstories that talk about the same event but\nexpressed using different words. We suggest\nusing paraphrases to alleviate this problem,\nmaking this the first work to use paraphrases\nfor FSD. We show a novel way of integrating\nparaphrases with locality sensitive hashing\n(LSH) in order to obtain an efficient FSD system\nthat can scale to very large datasets. Our\nsystem achieves state-of-the-art results on the\nfirst story detection task, beating both the best\nsupervised and unsupervised systems. To test\nour approach on large data, we construct a corpus\nof events for Twitter, consisting of 50 million\ndocuments, and show that paraphrasing is\nalso beneficial in this domain.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "DATASETS"], "tsne_embedding": [-20.0493106842041, -18.223827362060547], "cluster": 1}, {"key": "pham2016scalability", "year": "2016", "citations": "11", "title": "Scalability And Total Recall With Fast Coveringlsh", "abstract": "<p>Locality-sensitive hashing (LSH) has emerged as the dominant algorithmic\ntechnique for similarity search with strong performance guarantees in\nhigh-dimensional spaces. A drawback of traditional LSH schemes is that they may\nhave <em>false negatives</em>, i.e., the recall is less than 100%. This limits\nthe applicability of LSH in settings requiring precise performance guarantees.\nBuilding on the recent theoretical \u201cCoveringLSH\u201d construction that eliminates\nfalse negatives, we propose a fast and practical covering LSH scheme for\nHamming space called <em>Fast CoveringLSH (fcLSH)</em>. Inheriting the design\nbenefits of CoveringLSH our method avoids false negatives and always reports\nall near neighbors. Compared to CoveringLSH we achieve an asymptotic\nimprovement to the hash function computation time from \\(\\mathcal{O}(dL)\\) to\n\\(\\mathcal{O}(d + Llog{L})\\), where \\(d\\) is the dimensionality of data and \\(L\\) is\nthe number of hash tables. Our experiments on synthetic and real-world data\nsets demonstrate that <em>fcLSH</em> is comparable (and often superior) to\ntraditional hashing-based approaches for search radius up to 20 in\nhigh-dimensional Hamming space.</p>\n", "tags": ["CIKM", "Locality Sensitive Hashing", "Hashing Methods", "Similarity Search", "Evaluation"], "tsne_embedding": [14.83610725402832, -1.3441966772079468], "cluster": 2}, {"key": "pham2021training", "year": "2021", "citations": "14", "title": "Training Multi-bit Quantized And Binarized Networks With A Learnable Symmetric Quantizer", "abstract": "<p>Quantizing weights and activations of deep neural networks is essential for\ndeploying them in resource-constrained devices, or cloud platforms for at-scale\nservices. While binarization is a special case of quantization, this extreme\ncase often leads to several training difficulties, and necessitates specialized\nmodels and training methods. As a result, recent quantization methods do not\nprovide binarization, thus losing the most resource-efficient option, and\nquantized and binarized networks have been distinct research areas. We examine\nbinarization difficulties in a quantization framework and find that all we need\nto enable the binary training are a symmetric quantizer, good initialization,\nand careful hyperparameter selection. These techniques also lead to substantial\nimprovements in multi-bit quantization. We demonstrate our unified quantization\nframework, denoted as UniQ, on the ImageNet dataset with various architectures\nsuch as ResNet-18,-34 and MobileNetV2. For multi-bit quantization, UniQ\noutperforms existing methods to achieve the state-of-the-art accuracy. In\nbinarization, the achieved accuracy is comparable to existing state-of-the-art\nmethods even without modifying the original architectures.</p>\n", "tags": ["DATASETS", "Tools & Libraries", "Quantization"], "tsne_embedding": [-14.551920890808105, 9.24903678894043], "cluster": 3}, {"key": "pibiri2021parallel", "year": "2021", "citations": "9", "title": "Parallel And External-memory Construction Of Minimal Perfect Hash Functions With Pthash", "abstract": "<p>A function \\(f : U \\to \\{0,\\ldots,n-1\\}\\) is a minimal perfect hash function\nfor a set \\(S \\subseteq U\\) of size \\(n\\), if \\(f\\) bijectively maps \\(S\\) into the\nfirst \\(n\\) natural numbers. These functions are important for many practical\napplications in computing, such as search engines, computer networks, and\ndatabases. Several algorithms have been proposed to build minimal perfect hash\nfunctions that: scale well to large sets, retain fast evaluation time, and take\nvery little space, e.g., 2 - 3 bits/key. PTHash is one such algorithm,\nachieving very fast evaluation in compressed space, typically several times\nfaster than other techniques. In this work, we propose a new construction\nalgorithm for PTHash enabling: (1) multi-threading, to either build functions\nmore quickly or more space-efficiently, and (2) external-memory processing to\nscale to inputs much larger than the available internal memory. Only few other\nalgorithms in the literature share these features, despite of their big\npractical impact. We conduct an extensive experimental assessment on large\nreal-world string collections and show that, with respect to other techniques,\nPTHash is competitive in construction time and space consumption, but retains 2</p>\n<ul>\n  <li>6\\(\\times\\) better lookup time.</li>\n</ul>\n", "tags": ["Hashing Methods", "Evaluation"], "tsne_embedding": [-7.453067302703857, -24.929914474487305], "cluster": 5}, {"key": "pibiri2021pthash", "year": "2021", "citations": "17", "title": "Pthash: Revisiting FCH Minimal Perfect Hashing", "abstract": "<p>Given a set \\(S\\) of \\(n\\) distinct keys, a function \\(f\\) that bijectively maps\nthe keys of \\(S\\) into the range \\(\\{0,\\ldots,n-1\\}\\) is called a minimal perfect\nhash function for \\(S\\). Algorithms that find such functions when \\(n\\) is large\nand retain constant evaluation time are of practical interest; for instance,\nsearch engines and databases typically use minimal perfect hash functions to\nquickly assign identifiers to static sets of variable-length keys such as\nstrings. The challenge is to design an algorithm which is efficient in three\ndifferent aspects: time to find \\(f\\) (construction time), time to evaluate \\(f\\)\non a key of \\(S\\) (lookup time), and space of representation for \\(f\\). Several\nalgorithms have been proposed to trade-off between these aspects. In 1992, Fox,\nChen, and Heath (FCH) presented an algorithm at SIGIR providing very fast\nlookup evaluation. However, the approach received little attention because of\nits large construction time and higher space consumption compared to other\nsubsequent techniques. Almost thirty years later we revisit their framework and\npresent an improved algorithm that scales well to large sets and reduces space\nconsumption altogether, without compromising the lookup time. We conduct an\nextensive experimental assessment and show that the algorithm finds functions\nthat are competitive in space with state-of-the art techniques and provide\n\\(2-4\\times\\) better lookup time.</p>\n", "tags": ["Hashing Methods", "Alt", "SIGIR", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-7.325812816619873, -25.502504348754883], "cluster": 5}, {"key": "pibiri2022locality", "year": "2022", "citations": "5", "title": "Locality-preserving Minimal Perfect Hashing Of K-mers", "abstract": "<p>Minimal perfect hashing is the problem of mapping a static set of \\(n\\)\ndistinct keys into the address space \\(\\{1,\\ldots,n\\}\\) bijectively. It is\nwell-known that \\(nlog_2(e)\\) bits are necessary to specify a minimal perfect\nhash function (MPHF) \\(f\\), when no additional knowledge of the input keys is to\nbe used. However, it is often the case in practice that the input keys have\nintrinsic relationships that we can exploit to lower the bit complexity of \\(f\\).\nFor example, consider a string and the set of all its distinct \\(k\\)-mers as\ninput keys: since two consecutive \\(k\\)-mers share an overlap of \\(k-1\\) symbols,\nit seems possible to beat the classic \\(log_2(e)\\) bits/key barrier in this\ncase. Moreover, we would like \\(f\\) to map consecutive \\(k\\)-mers to consecutive\naddresses, as to also preserve as much as possible their relationship in the\ncodomain. This is a useful feature in practice as it guarantees a certain\ndegree of locality of reference for \\(f\\), resulting in a better evaluation time\nwhen querying consecutive \\(k\\)-mers. Motivated by these premises, we initiate\nthe study of a new type of locality-preserving MPHF designed for \\(k\\)-mers\nextracted consecutively from a collection of strings. We design a construction\nwhose space usage decreases for growing \\(k\\) and discuss experiments with a\npractical implementation of the method: in practice, the functions built with\nour method can be several times smaller and even faster to query than the most\nefficient MPHFs in the literature.</p>\n", "tags": ["Hashing Methods", "Evaluation"], "tsne_embedding": [-6.93597936630249, -26.856657028198242], "cluster": 5}, {"key": "podlesnaya2016deep", "year": "2016", "citations": "20", "title": "Deep Learning Based Semantic Video Indexing And Retrieval", "abstract": "<p>We share the implementation details and testing results for video retrieval\nsystem based exclusively on features extracted by convolutional neural\nnetworks. We show that deep learned features might serve as universal signature\nfor semantic content of video useful in many search and retrieval tasks. We\nfurther show that graph-based storage structure for video index allows to\nefficiently retrieving the content with complicated spatial and temporal search\nqueries.</p>\n", "tags": ["Graph Based ANN"], "tsne_embedding": [-7.198737621307373, 20.4608211517334], "cluster": 6}, {"key": "pourdamghani2024hash", "year": "2024", "citations": "6", "title": "Hash & Adjust: Competitive Demand-aware Consistent Hashing", "abstract": "<p>Distributed systems often serve dynamic workloads and resource demands evolve\nover time. Such a temporal behavior stands in contrast to the static and\ndemand-oblivious nature of most data structures used by these systems. In this\npaper, we are particularly interested in consistent hashing, a fundamental\nbuilding block in many large distributed systems. Our work is motivated by the\nhypothesis that a more adaptive approach to consistent hashing can leverage\nstructure in the demand, and hence improve storage utilization and reduce\naccess time. We initiate the study of demand-aware consistent hashing. Our main\ncontribution is H&amp;A, a constant-competitive online algorithm (i.e., it comes\nwith provable performance guarantees over time). H&amp;A is demand-aware and\noptimizes its internal structure to enable faster access times, while offering\na high utilization of storage. We further evaluate H&amp;A empirically.</p>\n", "tags": ["Hashing Methods", "Evaluation"], "tsne_embedding": [3.5588958263397217, -16.46481704711914], "cluster": 5}, {"key": "prasath2017distance", "year": "2017", "citations": "92", "title": "Distance And Similarity Measures Effect On The Performance Of K-nearest Neighbor Classifier -- A Review", "abstract": "<p>The K-nearest neighbor (KNN) classifier is one of the simplest and most\ncommon classifiers, yet its performance competes with the most complex\nclassifiers in the literature. The core of this classifier depends mainly on\nmeasuring the distance or similarity between the tested examples and the\ntraining examples. This raises a major question about which distance measures\nto be used for the KNN classifier among a large number of distance and\nsimilarity measures available? This review attempts to answer this question\nthrough evaluating the performance (measured by accuracy, precision and recall)\nof the KNN using a large number of distance measures, tested on a number of\nreal-world datasets, with and without adding different levels of noise. The\nexperimental results show that the performance of KNN classifier depends\nsignificantly on the distance used, and the results showed large gaps between\nthe performances of different distances. We found that a recently proposed\nnon-convex distance performed the best when applied on most datasets comparing\nto the other tested distances. In addition, the performance of the KNN with\nthis top performing distance degraded only about \\(20%\\) while the noise level\nreaches \\(90%\\), this is true for most of the distances used as well. This means\nthat the KNN classifier using any of the top \\(10\\) distances tolerate noise to a\ncertain degree. Moreover, the results show that some distances are less\naffected by the added noise comparing to other distances.</p>\n", "tags": ["Survey Paper", "Graph Based ANN", "DATASETS", "Evaluation"], "tsne_embedding": [17.096147537231445, -4.041134357452393], "cluster": 2}, {"key": "pratap2017efficient", "year": "2017", "citations": "8", "title": "Efficient Compression Technique For Sparse Sets", "abstract": "<p>Recent technological advancements have led to the generation of huge amounts\nof data over the web, such as text, image, audio and video. Most of this data\nis high dimensional and sparse, for e.g., the bag-of-words representation used\nfor representing text. Often, an efficient search for similar data points needs\nto be performed in many applications like clustering, nearest neighbour search,\nranking and indexing. Even though there have been significant increases in\ncomputational power, a simple brute-force similarity-search on such datasets is\ninefficient and at times impossible. Thus, it is desirable to get a compressed\nrepresentation which preserves the similarity between data points. In this\nwork, we consider the data points as sets and use Jaccard similarity as the\nsimilarity measure. Compression techniques are generally evaluated on the\nfollowing parameters \u20131) Randomness required for compression, 2) Time required\nfor compression, 3) Dimension of the data after compression, and 4) Space\nrequired to store the compressed data. Ideally, the compressed representation\nof the data should be such, that the similarity between each pair of data\npoints is preserved, while keeping the time and the randomness required for\ncompression as low as possible.\n  We show that the compression technique suggested by Pratap and Kulkarni also\nworks well for Jaccard similarity. We present a theoretical proof of the same\nand complement it with rigorous experimentations on synthetic as well as\nreal-world datasets. We also compare our results with the state-of-the-art\n\u201cmin-wise independent permutation\u201d, and show that our compression algorithm\nachieves almost equal accuracy while significantly reducing the compression\ntime and the randomness.</p>\n", "tags": ["Compact Codes", "DATASETS", "Similarity Search"], "tsne_embedding": [4.72291374206543, 1.7226598262786865], "cluster": 4}, {"key": "pratap2019efficient", "year": "2019", "citations": "11", "title": "Efficient Sketching Algorithm For Sparse Binary Data", "abstract": "<p>Recent advancement of the WWW, IOT, social network, e-commerce, etc. have\ngenerated a large volume of data. These datasets are mostly represented by high\ndimensional and sparse datasets. Many fundamental subroutines of common data\nanalytic tasks such as clustering, classification, ranking, nearest neighbour\nsearch, etc. scale poorly with the dimension of the dataset. In this work, we\naddress this problem and propose a sketching (alternatively, dimensionality\nreduction) algorithm \u2013 \\(\\binsketch\\) (Binary Data Sketch) \u2013 for sparse binary\ndatasets. \\(\\binsketch\\) preserves the binary version of the dataset after\nsketching and maintains estimates for multiple similarity measures such as\nJaccard, Cosine, Inner-Product similarities, and Hamming distance, on the same\nsketch. We present a theoretical analysis of our algorithm and complement it\nwith extensive experimentation on several real-world datasets. We compare the\nperformance of our algorithm with the state-of-the-art algorithms on the task\nof mean-square-error and ranking. Our proposed algorithm offers a comparable\naccuracy while suggesting a significant speedup in the dimensionality reduction\ntime, with respect to the other candidate algorithms. Our proposal is simple,\neasy to implement, and therefore can be adopted in practice.</p>\n", "tags": ["Alt", "DATASETS", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [8.17318058013916, 7.870947360992432], "cluster": 4}, {"key": "prezza2023algorithms", "year": "2023", "citations": "36", "title": "Algorithms For Massive Data -- Lecture Notes", "abstract": "<p>These are the lecture notes for the course CM0622 - Algorithms for Massive\nData, Ca\u2019 Foscari University of Venice. The goal of this course is to introduce\nalgorithmic techniques for dealing with massive data: data so large that it\ndoes not fit in the computer\u2019s memory. There are two main solutions to deal\nwith massive data: (lossless) compressed data structures and (lossy) data\nsketches. These notes cover both topics: compressed suffix arrays,\nprobabilistic filters, sketching under various metrics, Locality Sensitive\nHashing, nearest neighbour search, algorithms on streams.</p>\n", "tags": ["Similarity Search", "Hashing Methods"], "tsne_embedding": [8.168380737304688, -7.667735576629639], "cluster": 2}, {"key": "puram2024quantum", "year": "2024", "citations": "32", "title": "Quantum Algorithm For Jaccard Similarity", "abstract": "<p>Jaccard Similarity is a very common proximity measurement used to compute the\nsimilarity between two asymmetric binary vectors. Jaccard Similarity is the\nratio between the 1s (Intersection of two vectors) to 1s (Union of two\nvectors). This paper introduces a quantum algorithm for finding the Jaccard\nSimilarity 1s, in the Intersection and Union of two binary vectors. There are\ntwo sub-algorithms one for each. Measuring the register for respective\nalgorithm gives count of number of 1 s in binary format. Implementation on IBM\ncomposer is also included.</p>\n", "tags": [], "tsne_embedding": [17.532371520996094, -10.269503593444824], "cluster": 2}, {"key": "qi2017efficient", "year": "2017", "citations": "8", "title": "An Efficient Deep Learning Hashing Neural Network For Mobile Visual Search", "abstract": "<p>Mobile visual search applications are emerging that enable users to sense\ntheir surroundings with smart phones. However, because of the particular\nchallenges of mobile visual search, achieving a high recognition bitrate has\nbecomes a consistent target of previous related works. In this paper, we\npropose a few-parameter, low-latency, and high-accuracy deep hashing approach\nfor constructing binary hash codes for mobile visual search. First, we exploit\nthe architecture of the MobileNet model, which significantly decreases the\nlatency of deep feature extraction by reducing the number of model parameters\nwhile maintaining accuracy. Second, we add a hash-like layer into MobileNet to\ntrain the model on labeled mobile visual data. Evaluations show that the\nproposed system can exceed state-of-the-art accuracy performance in terms of\nthe MAP. More importantly, the memory consumption is much less than that of\nother deep learning models. The proposed method requires only \\(13\\) MB of memory\nfor the neural network and achieves a MAP of \\(97.80%\\) on the mobile location\nrecognition dataset used for testing.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Neural Hashing", "Evaluation"], "tsne_embedding": [-12.679749488830566, -17.20761489868164], "cluster": 1}, {"key": "qi2022principled", "year": "2022", "citations": "19", "title": "A Principled Design Of Image Representation: Towards Forensic Tasks", "abstract": "<p>Image forensics is a rising topic as the trustworthy multimedia content is\ncritical for modern society. Like other vision-related applications, forensic\nanalysis relies heavily on the proper image representation. Despite the\nimportance, current theoretical understanding for such representation remains\nlimited, with varying degrees of neglect for its key role. For this gap, we\nattempt to investigate the forensic-oriented image representation as a distinct\nproblem, from the perspectives of theory, implementation, and application. Our\nwork starts from the abstraction of basic principles that the representation\nfor forensics should satisfy, especially revealing the criticality of\nrobustness, interpretability, and coverage. At the theoretical level, we\npropose a new representation framework for forensics, called Dense Invariant\nRepresentation (DIR), which is characterized by stable description with\nmathematical guarantees. At the implementation level, the discrete calculation\nproblems of DIR are discussed, and the corresponding accurate and fast\nsolutions are designed with generic nature and constant complexity. We\ndemonstrate the above arguments on the dense-domain pattern detection and\nmatching experiments, providing comparison results with state-of-the-art\ndescriptors. Also, at the application level, the proposed DIR is initially\nexplored in passive and active forensics, namely copy-move forgery detection\nand perceptual hashing, exhibiting the benefits in fulfilling the requirements\nof such forensic tasks.</p>\n", "tags": ["Tools & Libraries", "Hashing Methods", "Evaluation", "Robustness"], "tsne_embedding": [-15.205443382263184, 10.651939392089844], "cluster": 3}, {"key": "qiao2019deep", "year": "2019", "citations": "21", "title": "Deep Heterogeneous Hashing For Face Video Retrieval", "abstract": "<p>Retrieving videos of a particular person with face image as a query via\nhashing technique has many important applications. While face images are\ntypically represented as vectors in Euclidean space, characterizing face videos\nwith some robust set modeling techniques (e.g. covariance matrices as exploited\nin this study, which reside on Riemannian manifold), has recently shown\nappealing advantages. This hence results in a thorny heterogeneous spaces\nmatching problem. Moreover, hashing with handcrafted features as done in many\nexisting works is clearly inadequate to achieve desirable performance for this\ntask. To address such problems, we present an end-to-end Deep Heterogeneous\nHashing (DHH) method that integrates three stages including image feature\nlearning, video modeling, and heterogeneous hashing in a single framework, to\nlearn unified binary codes for both face images and videos. To tackle the key\nchallenge of hashing on the manifold, a well-studied Riemannian kernel mapping\nis employed to project data (i.e. covariance matrices) into Euclidean space and\nthus enables to embed the two heterogeneous representations into a common\nHamming space, where both intra-space discriminability and inter-space\ncompatibility are considered. To perform network optimization, the gradient of\nthe kernel mapping is innovatively derived via structured matrix\nbackpropagation in a theoretically principled way. Experiments on three\nchallenging datasets show that our method achieves quite competitive\nperformance compared with existing hashing methods.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Compact Codes", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-12.856815338134766, 6.8542046546936035], "cluster": 8}, {"key": "qiu2017foresthash", "year": "2017", "citations": "8", "title": "Foresthash: Semantic Hashing With Shallow Random Forests And Tiny Convolutional Networks", "abstract": "<p>Hash codes are efficient data representations for coping with the ever\ngrowing amounts of data. In this paper, we introduce a random forest semantic\nhashing scheme that embeds tiny convolutional neural networks (CNN) into\nshallow random forests, with near-optimal information-theoretic code\naggregation among trees. We start with a simple hashing scheme, where random\ntrees in a forest act as hashing functions by setting <code class=\"language-plaintext highlighter-rouge\">1' for the visited tree\nleaf, and </code>0\u2019 for the rest. We show that traditional random forests fail to\ngenerate hashes that preserve the underlying similarity between the trees,\nrendering the random forests approach to hashing challenging. To address this,\nwe propose to first randomly group arriving classes at each tree split node\ninto two groups, obtaining a significantly simplified two-class classification\nproblem, which can be handled using a light-weight CNN weak learner. Such\nrandom class grouping scheme enables code uniqueness by enforcing each class to\nshare its code with different classes in different trees. A non-conventional\nlow-rank loss is further adopted for the CNN weak learners to encourage code\nconsistency by minimizing intra-class variations and maximizing inter-class\ndistance for the two random class groups. Finally, we introduce an\ninformation-theoretic approach for aggregating codes of individual trees into a\nsingle hash code, producing a near-optimal unique hash for each class. The\nproposed approach significantly outperforms state-of-the-art hashing methods\nfor image retrieval tasks on large-scale public datasets, while performing at\nthe level of other state-of-the-art image classification techniques while\nutilizing a more compact and efficient scalable representation. This work\nproposes a principled and robust procedure to train and deploy in parallel an\nensemble of light-weight CNNs, instead of simply going deeper.</p>\n", "tags": ["Image Retrieval", "Text Retrieval", "Hashing Methods", "DATASETS"], "tsne_embedding": [13.399735450744629, 13.008529663085938], "cluster": 0}, {"key": "qiu2018deep", "year": "2018", "citations": "97", "title": "Deep Semantic Hashing With Generative Adversarial Networks", "abstract": "<p>Hashing has been a widely-adopted technique for nearest neighbor search in\nlarge-scale image retrieval tasks. Recent research has shown that leveraging\nsupervised information can lead to high quality hashing. However, the cost of\nannotating data is often an obstacle when applying supervised hashing to a new\ndomain. Moreover, the results can suffer from the robustness problem as the\ndata at training and test stage could come from similar but different\ndistributions. This paper studies the exploration of generating synthetic data\nthrough semi-supervised generative adversarial networks (GANs), which leverages\nlargely unlabeled and limited labeled training data to produce highly\ncompelling data with intrinsic invariance and global coherence, for better\nunderstanding statistical structures of natural data. We demonstrate that the\nabove two limitations can be well mitigated by applying the synthetic data for\nhashing. Specifically, a novel deep semantic hashing with GANs (DSH-GANs) is\npresented, which mainly consists of four components: a deep convolution neural\nnetworks (CNN) for learning image representations, an adversary stream to\ndistinguish synthetic images from real ones, a hash stream for encoding image\nrepresentations to hash codes and a classification stream. The whole\narchitecture is trained end-to-end by jointly optimizing three losses, i.e.,\nadversarial loss to correct label of synthetic or real for each sample, triplet\nranking loss to preserve the relative similarity ordering in the input\nreal-synthetic triplets and classification loss to classify each sample\naccurately. Extensive experiments conducted on both CIFAR-10 and NUS-WIDE image\nbenchmarks validate the capability of exploiting synthetic images for hashing.\nOur framework also achieves superior results when compared to state-of-the-art\ndeep hash models.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "TACL", "Text Retrieval", "Neural Hashing", "SIGIR", "Tools & Libraries", "Evaluation", "Robustness"], "tsne_embedding": [-12.185202598571777, -1.8418359756469727], "cluster": 8}, {"key": "qiu2021unsupervised", "year": "2021", "citations": "51", "title": "Unsupervised Hashing With Contrastive Information Bottleneck", "abstract": "<p>Many unsupervised hashing methods are implicitly established on the idea of\nreconstructing the input data, which basically encourages the hashing codes to\nretain as much information of original data as possible. However, this\nrequirement may force the models spending lots of their effort on\nreconstructing the unuseful background information, while ignoring to preserve\nthe discriminative semantic information that is more important for the hashing\ntask. To tackle this problem, inspired by the recent success of contrastive\nlearning in learning continuous representations, we propose to adapt this\nframework to learn binary hashing codes. Specifically, we first propose to\nmodify the objective function to meet the specific requirement of hashing and\nthen introduce a probabilistic binary representation layer into the model to\nfacilitate end-to-end training of the entire model. We further prove the strong\nconnection between the proposed contrastive-learning-based hashing method and\nthe mutual information, and show that the proposed model can be considered\nunder the broader framework of the information bottleneck (IB). Under this\nperspective, a more general hashing model is naturally obtained. Extensive\nexperimental results on three benchmark image datasets demonstrate that the\nproposed hashing method significantly outperforms existing baselines.</p>\n", "tags": ["DATASETS", "Evaluation", "IJCAI", "Hashing Methods", "Tools & Libraries", "AAAI"], "tsne_embedding": [-9.730457305908203, -9.18272876739502], "cluster": 1}, {"key": "qiu2022hashvfl", "year": "2022", "citations": "8", "title": "Hashvfl: Defending Against Data Reconstruction Attacks In Vertical Federated Learning", "abstract": "<p>Vertical Federated Learning (VFL) is a trending collaborative machine\nlearning model training solution. Existing industrial frameworks employ secure\nmulti-party computation techniques such as homomorphic encryption to ensure\ndata security and privacy. Despite these efforts, studies have revealed that\ndata leakage remains a risk in VFL due to the correlations between intermediate\nrepresentations and raw data. Neural networks can accurately capture these\ncorrelations, allowing an adversary to reconstruct the data. This emphasizes\nthe need for continued research into securing VFL systems.\n  Our work shows that hashing is a promising solution to counter data\nreconstruction attacks. The one-way nature of hashing makes it difficult for an\nadversary to recover data from hash codes. However, implementing hashing in VFL\npresents new challenges, including vanishing gradients and information loss. To\naddress these issues, we propose HashVFL, which integrates hashing and\nsimultaneously achieves learnability, bit balance, and consistency.\n  Experimental results indicate that HashVFL effectively maintains task\nperformance while defending against data reconstruction attacks. It also brings\nadditional benefits in reducing the degree of label leakage, mitigating\nadversarial attacks, and detecting abnormal inputs. We hope our work will\ninspire further research into the potential applications of HashVFL.</p>\n", "tags": ["Tools & Libraries", "Hashing Methods", "Evaluation", "Robustness"], "tsne_embedding": [3.4646897315979004, -22.281044006347656], "cluster": 5}, {"key": "qiu2024hihpq", "year": "2024", "citations": "5", "title": "Hihpq: Hierarchical Hyperbolic Product Quantization For Unsupervised Image Retrieval", "abstract": "<p>Existing unsupervised deep product quantization methods primarily aim for the\nincreased similarity between different views of the identical image, whereas\nthe delicate multi-level semantic similarities preserved between images are\noverlooked. Moreover, these methods predominantly focus on the Euclidean space\nfor computational convenience, compromising their ability to map the\nmulti-level semantic relationships between images effectively. To mitigate\nthese shortcomings, we propose a novel unsupervised product quantization method\ndubbed \\textbf{Hi}erarchical \\textbf{H}yperbolic \\textbf{P}roduct\n\\textbf{Q}uantization (HiHPQ), which learns quantized representations by\nincorporating hierarchical semantic similarity within hyperbolic geometry.\nSpecifically, we propose a hyperbolic product quantizer, where the hyperbolic\ncodebook attention mechanism and the quantized contrastive learning on the\nhyperbolic product manifold are introduced to expedite quantization.\nFurthermore, we propose a hierarchical semantics learning module, designed to\nenhance the distinction between similar and non-matching images for a query by\nutilizing the extracted hierarchical semantics as an additional training\nsupervision. Experiments on benchmarks show that our proposed method\noutperforms state-of-the-art baselines.</p>\n", "tags": ["Image Retrieval", "AAAI", "Quantization", "Evaluation"], "tsne_embedding": [-15.581911087036133, 5.140844821929932], "cluster": 3}, {"key": "qu2017joint", "year": "2017", "citations": "40", "title": "Joint Hierarchical Category Structure Learning And Large-scale Image Classification", "abstract": "<p>We investigate the scalable image classification problem with a large number\nof categories. Hierarchical visual data structures are helpful for improving\nthe efficiency and performance of large-scale multi-class classification. We\npropose a novel image classification method based on learning hierarchical\ninter-class structures. Specifically, we first design a fast algorithm to\ncompute the similarity metric between categories, based on which a visual tree\nis constructed by hierarchical spectral clustering. Using the learned visual\ntree, a test sample label is efficiently predicted by searching for the best\npath over the entire tree. The proposed method is extensively evaluated on the\nILSVRC2010 and Caltech 256 benchmark datasets. Experimental results show that\nour method obtains significantly better category hierarchies than other\nstate-of-the-art visual tree-based methods and, therefore, much more accurate\nclassification.</p>\n", "tags": ["DATASETS", "Distance Metric Learning", "Efficiency And Optimization", "Alt", "Tree Based ANN", "Evaluation"], "tsne_embedding": [-1.2063170671463013, 14.689460754394531], "cluster": 6}, {"key": "quedenfeld2017variant", "year": "2017", "citations": "6", "title": "Variant Tolerant Read Mapping Using Min-hashing", "abstract": "<p>DNA read mapping is a ubiquitous task in bioinformatics, and many tools have\nbeen developed to solve the read mapping problem. However, there are two trends\nthat are changing the landscape of readmapping: First, new sequencing\ntechnologies provide very long reads with high error rates (up to 15%). Second,\nmany genetic variants in the population are known, so the reference genome is\nnot considered as a single string over ACGT, but as a complex object containing\nthese variants. Most existing read mappers do not handle these new\ncircumstances appropriately.\n  We introduce a new read mapper prototype called VATRAM that considers\nvariants. It is based on Min-Hashing of q-gram sets of reference genome\nwindows. Min-Hashing is one form of locality sensitive hashing. The variants\nare directly inserted into VATRAMs index which leads to a fast mapping process.\nOur results show that VATRAM achieves better precision and recall than\nstate-of-the-art read mappers like BWA under certain cirumstances. VATRAM is\nopen source and can be accessed at\nhttps://bitbucket.org/Quedenfeld/vatram-src/.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Evaluation"], "tsne_embedding": [8.536412239074707, -18.716028213500977], "cluster": 2}, {"key": "rabbani2023large", "year": "2023", "citations": "7", "title": "Large-scale Distributed Learning Via Private On-device Locality-sensitive Hashing", "abstract": "<p>Locality-sensitive hashing (LSH) based frameworks have been used efficiently\nto select weight vectors in a dense hidden layer with high cosine similarity to\nan input, enabling dynamic pruning. While this type of scheme has been shown to\nimprove computational training efficiency, existing algorithms require repeated\nrandomized projection of the full layer weight, which is impractical for\ncomputational- and memory-constrained devices. In a distributed setting,\ndeferring LSH analysis to a centralized host is (i) slow if the device cluster\nis large and (ii) requires access to input data which is forbidden in a\nfederated context. Using a new family of hash functions, we develop one of the\nfirst private, personalized, and memory-efficient on-device LSH frameworks. Our\nframework enables privacy and personalization by allowing each device to\ngenerate hash tables, without the help of a central host, using device-specific\nhashing hyper-parameters (e.g. number of hash tables or hash length). Hash\ntables are generated with a compressed set of the full weights, and can be\nserially generated and discarded if the process is memory-intensive. This\nallows devices to avoid maintaining (i) the fully-sized model and (ii) large\namounts of hash tables in local memory for LSH analysis. We prove several\nstatistical and sensitivity properties of our hash functions, and\nexperimentally demonstrate that our framework is competitive in training\nlarge-scale recommender networks compared to other LSH frameworks which assume\nunrestricted on-device capacity.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Distance Metric Learning", "Efficiency And Optimization", "Recommender Systems", "Tools & Libraries"], "tsne_embedding": [1.5165331363677979, -22.567392349243164], "cluster": 5}, {"key": "radenovi\u01072016cnn", "year": "2016", "citations": "523", "title": "CNN Image Retrieval Learns From Bow: Unsupervised Fine-tuning With Hard Examples", "abstract": "<p>Convolutional Neural Networks (CNNs) achieve state-of-the-art performance in\nmany computer vision tasks. However, this achievement is preceded by extreme\nmanual annotation in order to perform either training from scratch or\nfine-tuning for the target task. In this work, we propose to fine-tune CNN for\nimage retrieval from a large collection of unordered images in a fully\nautomated manner. We employ state-of-the-art retrieval and\nStructure-from-Motion (SfM) methods to obtain 3D models, which are used to\nguide the selection of the training data for CNN fine-tuning. We show that both\nhard positive and hard negative examples enhance the final performance in\nparticular object retrieval with compact codes.</p>\n", "tags": ["Compact Codes", "Image Retrieval", "Hashing Methods", "Evaluation"], "tsne_embedding": [-11.897392272949219, 24.5760555267334], "cluster": 6}, {"key": "radhakrishnan2021deep", "year": "2021", "citations": "50", "title": "Deep Metric Learning For Ground Images", "abstract": "<p>Ground texture based localization methods are potential prospects for\nlow-cost, high-accuracy self-localization solutions for robots. These methods\nestimate the pose of a given query image, i.e. the current observation of the\nground from a downward-facing camera, in respect to a set of reference images\nwhose poses are known in the application area. In this work, we deal with the\ninitial localization task, in which we have no prior knowledge about the\ncurrent robot positioning. In this situation, the localization method would\nhave to consider all available reference images. However, in order to reduce\ncomputational effort and the risk of receiving a wrong result, we would like to\nconsider only those reference images that are actually overlapping with the\nquery image. For this purpose, we propose a deep metric learning approach that\nretrieves the most similar reference images to the query image. In contrast to\nexisting approaches to image retrieval for ground images, our approach achieves\nsignificantly better recall performance and improves the localization\nperformance of a state-of-the-art ground texture based localization method.</p>\n", "tags": ["Image Retrieval", "AAAI", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [0.1445510983467102, 19.861591339111328], "cluster": 6}, {"key": "raff2017lempel", "year": "2017", "citations": "22", "title": "Lempel-ziv Jaccard Distance, An Effective Alternative To Ssdeep And Sdhash", "abstract": "<p>Recent work has proposed the Lempel-Ziv Jaccard Distance (LZJD) as a method\nto measure the similarity between binary byte sequences for malware\nclassification. We propose and test LZJD\u2019s effectiveness as a similarity digest\nhash for digital forensics. To do so we develop a high performance Java\nimplementation with the same command-line arguments as sdhash, making it easy\nto integrate into existing workflows. Our testing shows that LZJD is effective\nfor this task, and significantly outperforms sdhash and ssdeep in its ability\nto match related file fragments and files corrupted with random noise. In\naddition, LZJD is up to 60x faster than sdhash at comparison time.</p>\n", "tags": ["Alt", "Evaluation"], "tsne_embedding": [5.433773994445801, -12.30090045928955], "cluster": 2}, {"key": "raginsky2025locality", "year": "2025", "citations": "633", "title": "Locality-sensitive Binary Codes From Shift-invariant Kernels", "abstract": "<p>This paper addresses the problem of designing binary codes for high-dimensional\ndata such that vectors that are similar in the original space map to similar binary\nstrings. We introduce a simple distribution-free encoding scheme based on\nrandom projections, such that the expected Hamming distance between the binary\ncodes of two vectors is related to the value of a shift-invariant kernel (e.g., a\nGaussian kernel) between the vectors. We present a full theoretical analysis of the\nconvergence properties of the proposed scheme, and report favorable experimental\nperformance as compared to a recent state-of-the-art method, spectral hashing.</p>\n", "tags": ["Compact Codes", "Locality Sensitive Hashing", "Hashing Methods", "Evaluation"], "tsne_embedding": [24.199411392211914, -7.673866271972656], "cluster": 7}, {"key": "rajput2023recommender", "year": "2023", "citations": "17", "title": "Recommender Systems With Generative Retrieval", "abstract": "<p>Modern recommender systems perform large-scale retrieval by first embedding\nqueries and item candidates in the same unified space, followed by approximate\nnearest neighbor search to select top candidates given a query embedding. In\nthis paper, we propose a novel generative retrieval approach, where the\nretrieval model autoregressively decodes the identifiers of the target\ncandidates. To that end, we create semantically meaningful tuple of codewords\nto serve as a Semantic ID for each item. Given Semantic IDs for items in a user\nsession, a Transformer-based sequence-to-sequence model is trained to predict\nthe Semantic ID of the next item that the user will interact with. To the best\nof our knowledge, this is the first Semantic ID-based generative model for\nrecommendation tasks. We show that recommender systems trained with the\nproposed paradigm significantly outperform the current SOTA models on various\ndatasets. In addition, we show that incorporating Semantic IDs into the\nsequence-to-sequence model enhances its ability to generalize, as evidenced by\nthe improved retrieval performance observed for items with no prior interaction\nhistory.</p>\n", "tags": ["Recommender Systems", "Evaluation", "DATASETS"], "tsne_embedding": [3.028310775756836, -5.248225212097168], "cluster": 9}, {"key": "ramos2025blockboost", "year": "2025", "citations": "61", "title": "Blockboost: Scalable And Efficient Blocking Through Boosting", "abstract": "<p>As datasets grow larger, matching and merging entries from different databases has become a costly task in modern data pipelines. To avoid expensive comparisons between entries, blocking similar items is a popular preprocessing step. In this paper, we introduce BlockBoost, a novel boosting-based method that generates compact binary hash codes for database entries, through which blocking can be performed efficiently. The algorithm is fast and scalable, resulting in computational costs that are orders of magnitude lower than current benchmarks. Unlike existing alternatives, BlockBoost comes with associated feature importance measures for interpretability, and possesses strong theoretical guarantees, including lower bounds on critical performance metrics like recall and reduction ratio. Finally, we show that BlockBoost delivers great empirical results, outperforming state-of-the-art blocking benchmarks in terms of both performance metrics and computational cost.</p>\n", "tags": ["Alt", "Hashing Methods", "Evaluation", "DATASETS"], "tsne_embedding": [10.630499839782715, -6.836700439453125], "cluster": 2}, {"key": "rashtchian2020lsf", "year": "2020", "citations": "5", "title": "Lsf-join: Locality Sensitive Filtering For Distributed All-pairs Set Similarity Under Skew", "abstract": "<p>All-pairs set similarity is a widely used data mining task, even for large\nand high-dimensional datasets. Traditionally, similarity search has focused on\ndiscovering very similar pairs, for which a variety of efficient algorithms are\nknown. However, recent work highlights the importance of finding pairs of sets\nwith relatively small intersection sizes. For example, in a recommender system,\ntwo users may be alike even though their interests only overlap on a small\npercentage of items. In such systems, some dimensions are often highly skewed\nbecause they are very popular. Together these two properties render previous\napproaches infeasible for large input sizes. To address this problem, we\npresent a new distributed algorithm, LSF-Join, for approximate all-pairs set\nsimilarity. The core of our algorithm is a randomized selection procedure based\non Locality Sensitive Filtering. Our method deviates from prior approximate\nalgorithms, which are based on Locality Sensitive Hashing. Theoretically, we\nshow that LSF-Join efficiently finds most close pairs, even for small\nsimilarity thresholds and for skewed input sets. We prove guarantees on the\ncommunication, work, and maximum load of LSF-Join, and we also experimentally\ndemonstrate its accuracy on multiple graphs.</p>\n", "tags": ["Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Recommender Systems", "Similarity Search"], "tsne_embedding": [12.559311866760254, 3.570730447769165], "cluster": 4}, {"key": "ravanbakhsh2016efficient", "year": "2016", "citations": "7", "title": "Efficient Convolutional Neural Network With Binary Quantization Layer", "abstract": "<p>In this paper we introduce a novel method for segmentation that can benefit\nfrom general semantics of Convolutional Neural Network (CNN). Our segmentation\nproposes visually and semantically coherent image segments. We use binary\nencoding of CNN features to overcome the difficulty of the clustering on the\nhigh-dimensional CNN feature space. These binary encoding can be embedded into\nthe CNN as an extra layer at the end of the network. This results in real-time\nsegmentation. To the best of our knowledge our method is the first attempt on\ngeneral semantic image segmentation using CNN. All the previous papers were\nlimited to few number of category of the images (e.g. PASCAL VOC). Experiments\nshow that our segmentation algorithm outperform the state-of-the-art\nnon-semantic segmentation methods by a large margin.</p>\n", "tags": ["Hashing Methods", "Quantization"], "tsne_embedding": [-14.2113037109375, 24.671798706054688], "cluster": 6}, {"key": "ravfogel2023description", "year": "2023", "citations": "8", "title": "Description-based Text Similarity", "abstract": "<p>Identifying texts with a given semantics is central for many information\nseeking scenarios. Similarity search over vector embeddings appear to be\ncentral to this ability, yet the similarity reflected in current text\nembeddings is corpus-driven, and is inconsistent and sub-optimal for many use\ncases. What, then, is a good notion of similarity for effective retrieval of\ntext?\n  We identify the need to search for texts based on abstract descriptions of\ntheir content, and the corresponding notion of <em>description based\nsimilarity</em>. We demonstrate the inadequacy of current text embeddings and\npropose an alternative model that significantly improves when used in standard\nnearest neighbor search. The model is trained using positive and negative pairs\nsourced through prompting a LLM, demonstrating how data from LLMs can be used\nfor creating new capabilities not immediately possible using the original\nmodel.</p>\n", "tags": ["Alt", "Similarity Search"], "tsne_embedding": [3.4409356117248535, 3.714909791946411], "cluster": 4}, {"key": "razeghi2017privacy", "year": "2017", "citations": "25", "title": "Privacy Preserving Identification Using Sparse Approximation With Ambiguization", "abstract": "<p>In this paper, we consider a privacy preserving encoding framework for\nidentification applications covering biometrics, physical object security and\nthe Internet of Things (IoT). The proposed framework is based on a sparsifying\ntransform, which consists of a trained linear map, an element-wise\nnonlinearity, and privacy amplification. The sparsifying transform and privacy\namplification are not symmetric for the data owner and data user. We\ndemonstrate that the proposed approach is closely related to sparse ternary\ncodes (STC), a recent information-theoretic concept proposed for fast\napproximate nearest neighbor (ANN) search in high dimensional feature spaces\nthat being machine learning in nature also offers significant benefits in\ncomparison to sparse approximation and binary embedding approaches. We\ndemonstrate that the privacy of the database outsourced to a server as well as\nthe privacy of the data user are preserved at a low computational cost, storage\nand communication burdens.</p>\n", "tags": ["Tools & Libraries", "Hashing Methods", "Evaluation"], "tsne_embedding": [5.395921230316162, -22.05428123474121], "cluster": 5}, {"key": "reimers2020curse", "year": "2020", "citations": "31", "title": "The Curse Of Dense Low-dimensional Information Retrieval For Large Index Sizes", "abstract": "<p>Information Retrieval using dense low-dimensional representations recently\nbecame popular and showed out-performance to traditional sparse-representations\nlike BM25. However, no previous work investigated how dense representations\nperform with large index sizes. We show theoretically and empirically that the\nperformance for dense representations decreases quicker than sparse\nrepresentations for increasing index sizes. In extreme cases, this can even\nlead to a tipping point where at a certain index size sparse representations\noutperform dense representations. We show that this behavior is tightly\nconnected to the number of dimensions of the representations: The lower the\ndimension, the higher the chance for false positives, i.e. returning irrelevant\ndocuments.</p>\n", "tags": ["Efficiency And Optimization", "ACL", "Evaluation"], "tsne_embedding": [12.13330078125, -8.380189895629883], "cluster": 2}, {"key": "ri2018fingerprint", "year": "2018", "citations": "152", "title": "A Fingerprint Indexing Method Based On Minutia Descriptor And Clustering", "abstract": "<p>In this paper we propose a novel fingerprint indexing approach for speeding\nup in the fingerprint recognition system. What kind of features are used for\nindexing and how to employ the extracted features for searching are crucial for\nthe fingerprint indexing. In this paper, we select a minutia descriptor, which\nhas been used to improve the accuracy of the fingerprint matching, as a local\nfeature for indexing and construct a fixed-length feature vector which will be\nused for searching from the minutia descriptors of the fingerprint image using\na clustering. And we propose a fingerprint searching approach that uses the\nEuclidean distance between two feature vectors as the similarity between two\nindexing features. Our indexing approach has several benefits. It reduces\nsearching time significantly and is irrespective of the existence of singular\npoints and robust even though the size of the fingerprint image is small or the\nquality is low. And the constructed indexing vector by this approach is\nindependent of the features which are used for indexing based on the\ngeometrical relations between the minutiae, like one based on the minutiae\ntriplets. Thus, the proposed approach could be combined with other indexing\napproaches to gain a better indexing performance.</p>\n", "tags": ["Evaluation", "Distance Metric Learning"], "tsne_embedding": [23.09636116027832, -5.581268310546875], "cluster": 7}, {"key": "riazi2016sub", "year": "2016", "citations": "11", "title": "Sub-linear Privacy-preserving Near-neighbor Search", "abstract": "<p>In Near-Neighbor Search (NNS), a new client queries a database (held by a\nserver) for the most similar data (near-neighbors) given a certain similarity\nmetric. The Privacy-Preserving variant (PP-NNS) requires that neither server\nnor the client shall learn information about the other party\u2019s data except what\ncan be inferred from the outcome of NNS. The overwhelming growth in the size of\ncurrent datasets and the lack of a truly secure server in the online world\nrender the existing solutions impractical; either due to their high\ncomputational requirements or non-realistic assumptions which potentially\ncompromise privacy. PP-NNS having query time {\\it sub-linear} in the size of\nthe database has been suggested as an open research direction by Li et al.\n(CCSW\u201915). In this paper, we provide the first such algorithm, called Secure\nLocality Sensitive Indexing (SLSI) which has a sub-linear query time and the\nability to handle honest-but-curious parties. At the heart of our proposal lies\na secure binary embedding scheme generated from a novel probabilistic\ntransformation over locality sensitive hashing family. We provide information\ntheoretic bound for the privacy guarantees and support our theoretical claims\nusing substantial empirical evidence on real-world datasets.</p>\n", "tags": ["Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Efficiency And Optimization"], "tsne_embedding": [1.7171885967254639, -23.212543487548828], "cluster": 5}, {"key": "riba2020learning", "year": "2020", "citations": "25", "title": "Learning Graph Edit Distance By Graph Neural Networks", "abstract": "<p>The emergence of geometric deep learning as a novel framework to deal with\ngraph-based representations has faded away traditional approaches in favor of\ncompletely new methodologies. In this paper, we propose a new framework able to\ncombine the advances on deep metric learning with traditional approximations of\nthe graph edit distance. Hence, we propose an efficient graph distance based on\nthe novel field of geometric deep learning. Our method employs a message\npassing neural network to capture the graph structure, and thus, leveraging\nthis information for its use on a distance computation. The performance of the\nproposed graph distance is validated on two different scenarios. On the one\nhand, in a graph retrieval of handwritten words~\\ie~keyword spotting, showing\nits superior performance when compared with (approximate) graph edit distance\nbenchmarks. On the other hand, demonstrating competitive results for graph\nsimilarity learning when compared with the current state-of-the-art on a recent\nbenchmark dataset.</p>\n", "tags": ["DATASETS", "Graph Based ANN", "Distance Metric Learning", "CVPR", "Tools & Libraries", "Evaluation"], "tsne_embedding": [20.755218505859375, 13.25826358795166], "cluster": 0}, {"key": "rippel2014learning", "year": "2014", "citations": "49", "title": "Learning Ordered Representations With Nested Dropout", "abstract": "<p>In this paper, we study ordered representations of data in which different\ndimensions have different degrees of importance. To learn these representations\nwe introduce nested dropout, a procedure for stochastically removing coherent\nnested sets of hidden units in a neural network. We first present a sequence of\ntheoretical results in the simple case of a semi-linear autoencoder. We\nrigorously show that the application of nested dropout enforces identifiability\nof the units, which leads to an exact equivalence with PCA. We then extend the\nalgorithm to deep models and demonstrate the relevance of ordered\nrepresentations to a number of applications. Specifically, we use the ordered\nproperty of the learned codes to construct hash-based data structures that\npermit very fast retrieval, achieving retrieval in time logarithmic in the\ndatabase size and independent of the dimensionality of the representation. This\nallows codes that are hundreds of times longer than currently feasible for\nretrieval. We therefore avoid the diminished quality associated with short\ncodes, while still performing retrieval that is competitive in speed with\nexisting methods. We also show that ordered representations are a promising way\nto learn adaptive compression for efficient online data reconstruction.</p>\n", "tags": ["Efficiency And Optimization"], "tsne_embedding": [-4.2366180419921875, -12.844953536987305], "cluster": 9}, {"key": "rodrigues2021combining", "year": "2021", "citations": "75", "title": "Combining Minkowski And Chebyshev: New Distance Proposal And Survey Of Distance Metrics Using K-nearest Neighbours Classifier", "abstract": "<p>This work proposes a distance that combines Minkowski and Chebyshev distances\nand can be seen as an intermediary distance. This combination not only achieves\nefficient run times in neighbourhood iteration tasks in Z^2, but also obtains\ngood accuracies when coupled with the k-Nearest Neighbours (k-NN) classifier.\nThe proposed distance is approximately 1.3 times faster than Manhattan distance\nand 329.5 times faster than Euclidean distance in discrete neighbourhood\niterations. An accuracy analysis of the k-NN classifier using a total of 33\ndatasets from the UCI repository, 15 distances and values assigned to k that\nvary from 1 to 200 is presented. In this experiment, the proposed distance\nobtained accuracies that were better than the average more often than its\ncounterparts (in 26 cases out of 33), and also obtained the best accuracy more\nfrequently (in 9 out of 33 cases).</p>\n", "tags": ["Survey Paper", "DATASETS", "Distance Metric Learning"], "tsne_embedding": [17.503292083740234, -2.1917362213134766], "cluster": 7}, {"key": "roller2021hash", "year": "2021", "citations": "47", "title": "Hash Layers For Large Sparse Models", "abstract": "<p>We investigate the training of sparse layers that use different parameters\nfor different inputs based on hashing in large Transformer models.\nSpecifically, we modify the feedforward layer to hash to different sets of\nweights depending on the current token, over all tokens in the sequence. We\nshow that this procedure either outperforms or is competitive with\nlearning-to-route mixture-of-expert methods such as Switch Transformers and\nBASE Layers, while requiring no routing parameters or extra terms in the\nobjective function such as a load balancing loss, and no sophisticated\nassignment algorithm. We study the performance of different hashing techniques,\nhash sizes and input features, and show that balanced and random hashes focused\non the most local features work best, compared to either learning clusters or\nusing longer-range context. We show our approach works well both on large\nlanguage modeling and dialogue tasks, and on downstream fine-tuning tasks.</p>\n", "tags": ["Hashing Methods", "Evaluation"], "tsne_embedding": [-5.011883735656738, -15.65262508392334], "cluster": 9}, {"key": "rong2025locality", "year": "2025", "citations": "6", "title": "Locality-sensitive Hashing For Earthquake Detection: A Case Study Of Scaling Data-driven Science", "abstract": "<p>In this work, we report on a novel application of Locality Sensitive\nHashing (LSH) to seismic data at scale. Based on the high waveform similarity between reoccurring earthquakes, our application\nidentifies potential earthquakes by searching for similar time series\nsegments via LSH. However, a straightforward implementation of\nthis LSH-enabled application has difficulty scaling beyond 3 months\nof continuous time series data measured at a single seismic station.\nAs a case study of a data-driven science workflow, we illustrate how\ndomain knowledge can be incorporated into the workload to improve\nboth the efficiency and result quality. We describe several end-toend optimizations of the analysis pipeline from pre-processing to\npost-processing, which allow the application to scale to time series data measured at multiple seismic stations. Our optimizations\nenable an over 100\u00d7 speedup in the end-to-end analysis pipeline.\nThis improved scalability enabled seismologists to perform seismic\nanalysis on more than ten years of continuous time series data from\nover ten seismic stations, and has directly enabled the discovery of\n597 new earthquakes near the Diablo Canyon nuclear power plant\nin California and 6123 new earthquakes in New Zealand.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Efficiency And Optimization"], "tsne_embedding": [-17.639516830444336, 19.67119598388672], "cluster": 3}, {"key": "roy2016representing", "year": "2016", "citations": "11", "title": "Representing Documents And Queries As Sets Of Word Embedded Vectors For Information Retrieval", "abstract": "<p>A major difficulty in applying word vector embeddings in IR is in devising an\neffective and efficient strategy for obtaining representations of compound\nunits of text, such as whole documents, (in comparison to the atomic words),\nfor the purpose of indexing and scoring documents. Instead of striving for a\nsuitable method for obtaining a single vector representation of a large\ndocument of text, we rather aim for developing a similarity metric that makes\nuse of the similarities between the individual embedded word vectors in a\ndocument and a query. More specifically, we represent a document and a query as\nsets of word vectors, and use a standard notion of similarity measure between\nthese sets, computed as a function of the similarities between each constituent\nword pair from these sets. We then make use of this similarity measure in\ncombination with standard IR based similarities for document ranking. The\nresults of our initial experimental investigations shows that our proposed\nmethod improves MAP by up to \\(5.77%\\), in comparison to standard text-based\nlanguage model similarity, on the TREC ad-hoc dataset.</p>\n", "tags": ["DATASETS", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [2.2882509231567383, 3.7314069271087646], "cluster": 4}, {"key": "roy2019metric", "year": "2019", "citations": "75", "title": "Metric-learning Based Deep Hashing Network For Content Based Retrieval Of Remote Sensing Images", "abstract": "<p>Hashing methods have been recently found very effective in retrieval of\nremote sensing (RS) images due to their computational efficiency and fast\nsearch speed. The traditional hashing methods in RS usually exploit\nhand-crafted features to learn hash functions to obtain binary codes, which can\nbe insufficient to optimally represent the information content of RS images. To\novercome this problem, in this paper we introduce a metric-learning based\nhashing network, which learns: 1) a semantic-based metric space for effective\nfeature representation; and 2) compact binary hash codes for fast archive\nsearch. Our network considers an interplay of multiple loss functions that\nallows to jointly learn a metric based semantic space facilitating similar\nimages to be clustered together in that target space and at the same time\nproducing compact final activations that lose negligible information when\nbinarized. Experiments carried out on two benchmark RS archives point out that\nthe proposed network significantly improves the retrieval performance under the\nsame retrieval time when compared to the state-of-the-art hashing methods in\nRS.</p>\n", "tags": ["Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Neural Hashing", "Evaluation"], "tsne_embedding": [-4.788322448730469, 3.3088932037353516], "cluster": 8}, {"key": "royoletelier2018disambiguating", "year": "2018", "citations": "5", "title": "Disambiguating Music Artists At Scale With Audio Metric Learning", "abstract": "<p>We address the problem of disambiguating large scale catalogs through the\ndefinition of an unknown artist clustering task. We explore the use of metric\nlearning techniques to learn artist embeddings directly from audio, and using a\ndedicated homonym artists dataset, we compare our method with a recent approach\nthat learn similar embeddings using artist classifiers. While both systems have\nthe ability to disambiguate unknown artists relying exclusively on audio, we\nshow that our system is more suitable in the case when enough audio data is\navailable for each artist in the train dataset. We also propose a new negative\nsampling method for metric learning that takes advantage of side information\nsuch as music genre during the learning phase and shows promising results for\nthe artist clustering task.</p>\n", "tags": ["DATASETS", "Distance Metric Learning"], "tsne_embedding": [-26.240610122680664, 8.818571090698242], "cluster": 3}, {"key": "rubinstein2018hardness", "year": "2018", "citations": "74", "title": "Hardness Of Approximate Nearest Neighbor Search", "abstract": "<p>We prove conditional near-quadratic running time lower bounds for approximate\nBichromatic Closest Pair with Euclidean, Manhattan, Hamming, or edit distance.\nSpecifically, unless the Strong Exponential Time Hypothesis (SETH) is false,\nfor every \\(\\delta&gt;0\\) there exists a constant \\(\\epsilon&gt;0\\) such that computing a\n\\((1+\\epsilon)\\)-approximation to the Bichromatic Closest Pair requires\n\\(n^{2-\\delta}\\) time. In particular, this implies a near-linear query time for\nApproximate Nearest Neighbor search with polynomial preprocessing time.\n  Our reduction uses the Distributed PCP framework of [ARW\u201917], but obtains\nimproved efficiency using Algebraic Geometry (AG) codes. Efficient PCPs from AG\ncodes have been constructed in other settings before [BKKMS\u201916, BCGRS\u201917], but\nour construction is the first to yield new hardness results.</p>\n", "tags": ["Tools & Libraries", "Efficiency And Optimization"], "tsne_embedding": [25.07964515686035, -2.082404375076294], "cluster": 7}, {"key": "ryali2020bio", "year": "2020", "citations": "45", "title": "Bio-inspired Hashing For Unsupervised Similarity Search", "abstract": "<p>The fruit fly Drosophila\u2019s olfactory circuit has inspired a new locality\nsensitive hashing (LSH) algorithm, FlyHash. In contrast with classical LSH\nalgorithms that produce low dimensional hash codes, FlyHash produces sparse\nhigh-dimensional hash codes and has also been shown to have superior empirical\nperformance compared to classical LSH algorithms in similarity search. However,\nFlyHash uses random projections and cannot learn from data. Building on\ninspiration from FlyHash and the ubiquity of sparse expansive representations\nin neurobiology, our work proposes a novel hashing algorithm BioHash that\nproduces sparse high dimensional hash codes in a data-driven manner. We show\nthat BioHash outperforms previously published benchmarks for various hashing\nmethods. Since our learning algorithm is based on a local and biologically\nplausible synaptic plasticity rule, our work provides evidence for the proposal\nthat LSH might be a computational reason for the abundance of sparse expansive\nmotifs in a variety of biological systems. We also propose a convolutional\nvariant BioConvHash that further improves performance. From the perspective of\ncomputer science, BioHash and BioConvHash are fast, scalable and yield\ncompressed binary representations that are useful for similarity search.</p>\n", "tags": ["Locality Sensitive Hashing", "Similarity Search", "Hashing Methods", "Evaluation"], "tsne_embedding": [11.394305229187012, -2.212254524230957], "cluster": 4}, {"key": "rygl2017semantic", "year": "2017", "citations": "12", "title": "Semantic Vector Encoding And Similarity Search Using Fulltext Search Engines", "abstract": "<p>Vector representations and vector space modeling (VSM) play a central role in\nmodern machine learning. We propose a novel approach to `vector similarity\nsearching\u2019 over dense semantic representations of words and documents that can\nbe deployed on top of traditional inverted-index-based fulltext engines, taking\nadvantage of their robustness, stability, scalability and ubiquity.\n  We show that this approach allows the indexing and querying of dense vectors\nin text domains. This opens up exciting avenues for major efficiency gains,\nalong with simpler deployment, scaling and monitoring.\n  The end result is a fast and scalable vector database with a tunable\ntrade-off between vector search performance and quality, backed by a standard\nfulltext engine such as Elasticsearch.\n  We empirically demonstrate its querying performance and quality by applying\nthis solution to the task of semantic searching over a dense vector\nrepresentation of the entire English Wikipedia.</p>\n", "tags": ["Efficiency And Optimization", "Text Retrieval", "Similarity Search", "Evaluation", "Robustness"], "tsne_embedding": [1.1314431428909302, -0.678554356098175], "cluster": 4}, {"key": "saberi2024drew", "year": "2024", "citations": "43", "title": "DREW : Towards Robust Data Provenance By Leveraging Error-controlled Watermarking", "abstract": "<p>Identifying the origin of data is crucial for data provenance, with\napplications including data ownership protection, media forensics, and\ndetecting AI-generated content. A standard approach involves embedding-based\nretrieval techniques that match query data with entries in a reference dataset.\nHowever, this method is not robust against benign and malicious edits. To\naddress this, we propose Data Retrieval with Error-corrected codes and\nWatermarking (DREW). DREW randomly clusters the reference dataset, injects\nunique error-controlled watermark keys into each cluster, and uses these keys\nat query time to identify the appropriate cluster for a given sample. After\nlocating the relevant cluster, embedding vector similarity retrieval is\nperformed within the cluster to find the most accurate matches. The integration\nof error control codes (ECC) ensures reliable cluster assignments, enabling the\nmethod to perform retrieval on the entire dataset in case the ECC algorithm\ncannot detect the correct cluster with high confidence. This makes DREW\nmaintain baseline performance, while also providing opportunities for\nperformance improvements due to the increased likelihood of correctly matching\nqueries to their origin when performing retrieval on a smaller subset of the\ndataset. Depending on the watermark technique used, DREW can provide\nsubstantial improvements in retrieval accuracy (up to 40% for some datasets\nand modification types) across multiple datasets and state-of-the-art embedding\nmodels (e.g., DinoV2, CLIP), making our method a promising solution for secure\nand reliable source identification. The code is available at\nhttps://github.com/mehrdadsaberi/DREW</p>\n", "tags": ["DATASETS", "Similarity Search", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [0.8475576639175415, 1.3576037883758545], "cluster": 4}, {"key": "sablayrolles2016how", "year": "2016", "citations": "97", "title": "How Should We Evaluate Supervised Hashing?", "abstract": "<p>Hashing produces compact representations for documents, to perform tasks like\nclassification or retrieval based on these short codes. When hashing is\nsupervised, the codes are trained using labels on the training data. This paper\nfirst shows that the evaluation protocols used in the literature for supervised\nhashing are not satisfactory: we show that a trivial solution that encodes the\noutput of a classifier significantly outperforms existing supervised or\nsemi-supervised methods, while using much shorter codes. We then propose two\nalternative protocols for supervised hashing: one based on retrieval on a\ndisjoint set of classes, and another based on transfer learning to new classes.\nWe provide two baseline methods for image-related tasks to assess the\nperformance of (semi-)supervised hashing: without coding and with unsupervised\ncodes. These baselines give a lower- and upper-bound on the performance of a\nsupervised hashing scheme.</p>\n", "tags": ["Hashing Methods", "Compact Codes", "Alt", "ICASSP", "Evaluation"], "tsne_embedding": [-18.85021209716797, -4.6807026863098145], "cluster": 1}, {"key": "salakhutdinov2025semantic", "year": "2025", "citations": "1272", "title": "Semantic Hashing", "abstract": "<p>We show how to learn a deep graphical model of the word-count\nvectors obtained from a large set of documents. The values of the\nlatent variables in the deepest layer are easy to infer and give a\nmuch better representation of each document than Latent Semantic\nAnalysis. When the deepest layer is forced to use a small number of\nbinary variables (e.g. 32), the graphical model performs \u201csemantic\nhashing\u201d: Documents are mapped to memory addresses in such a\nway that semantically similar documents are located at nearby addresses.\nDocuments similar to a query document can then be found\nby simply accessing all the addresses that differ by only a few bits\nfrom the address of the query document. This way of extending the\nefficiency of hash-coding to approximate matching is much faster\nthan locality sensitive hashing, which is the fastest current method.\nBy using semantic hashing to filter the documents given to TF-IDF,\nwe achieve higher accuracy than applying TF-IDF to the entire document\nset.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Efficiency And Optimization", "Text Retrieval", "Evaluation"], "tsne_embedding": [-7.921926975250244, -18.296724319458008], "cluster": 5}, {"key": "salvi2016bloom", "year": "2016", "citations": "5", "title": "Bloom Filters And Compact Hash Codes For Efficient And Distributed Image Retrieval", "abstract": "<p>This paper presents a novel method for efficient image retrieval, based on a\nsimple and effective hashing of CNN features and the use of an indexing\nstructure based on Bloom filters. These filters are used as gatekeepers for the\ndatabase of image features, allowing to avoid to perform a query if the query\nfeatures are not stored in the database and speeding up the query process,\nwithout affecting retrieval performance. Thanks to the limited memory\nrequirements the system is suitable for mobile applications and distributed\ndatabases, associating each filter to a distributed portion of the database.\nExperimental validation has been performed on three standard image retrieval\ndatasets, outperforming state-of-the-art hashing methods in terms of precision,\nwhile the proposed indexing method obtains a \\(2\\times\\) speedup.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Evaluation"], "tsne_embedding": [-14.158255577087402, 23.224931716918945], "cluster": 6}, {"key": "sanakoyeu2019divide", "year": "2019", "citations": "121", "title": "Divide And Conquer The Embedding Space For Metric Learning", "abstract": "<p>Learning the embedding space, where semantically similar objects are located\nclose together and dissimilar objects far apart, is a cornerstone of many\ncomputer vision applications. Existing approaches usually learn a single metric\nin the embedding space for all available data points, which may have a very\ncomplex non-uniform distribution with different notions of similarity between\nobjects, e.g. appearance, shape, color or semantic meaning. Approaches for\nlearning a single distance metric often struggle to encode all different types\nof relationships and do not generalize well. In this work, we propose a novel\neasy-to-implement divide and conquer approach for deep metric learning, which\nsignificantly improves the state-of-the-art performance of metric learning. Our\napproach utilizes the embedding space more efficiently by jointly splitting the\nembedding space and data into \\(K\\) smaller sub-problems. It divides both, the\ndata and the embedding space into \\(K\\) subsets and learns \\(K\\) separate distance\nmetrics in the non-overlapping subspaces of the embedding space, defined by\ngroups of neurons in the embedding layer of the neural network. The proposed\napproach increases the convergence speed and improves generalization since the\ncomplexity of each sub-problem is reduced compared to the original one. We show\nthat our approach outperforms the state-of-the-art by a large margin in\nretrieval, clustering and re-identification tasks on CUB200-2011, CARS196,\nStanford Online Products, In-shop Clothes and PKU VehicleID datasets.</p>\n", "tags": ["CVPR", "DATASETS", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [-17.776668548583984, 4.589823246002197], "cluster": 3}, {"key": "sanakoyeu2021improving", "year": "2021", "citations": "16", "title": "Improving Deep Metric Learning By Divide And Conquer", "abstract": "<p>Deep metric learning (DML) is a cornerstone of many computer vision\napplications. It aims at learning a mapping from the input domain to an\nembedding space, where semantically similar objects are located nearby and\ndissimilar objects far from another. The target similarity on the training data\nis defined by user in form of ground-truth class labels. However, while the\nembedding space learns to mimic the user-provided similarity on the training\ndata, it should also generalize to novel categories not seen during training.\nBesides user-provided groundtruth training labels, a lot of additional visual\nfactors (such as viewpoint changes or shape peculiarities) exist and imply\ndifferent notions of similarity between objects, affecting the generalization\non the images unseen during training. However, existing approaches usually\ndirectly learn a single embedding space on all available training data,\nstruggling to encode all different types of relationships, and do not\ngeneralize well. We propose to build a more expressive representation by\njointly splitting the embedding space and the data hierarchically into smaller\nsub-parts. We successively focus on smaller subsets of the training data,\nreducing its variance and learning a different embedding subspace for each data\nsubset. Moreover, the subspaces are learned jointly to cover not only the\nintricacies, but the breadth of the data as well. Only after that, we build the\nfinal embedding from the subspaces in the conquering stage. The proposed\nalgorithm acts as a transparent wrapper that can be placed around arbitrary\nexisting DML methods. Our approach significantly improves upon the\nstate-of-the-art on image retrieval, clustering, and re-identification tasks\nevaluated using CUB200-2011, CARS196, Stanford Online Products, In-shop\nClothes, and PKU VehicleID datasets.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [-16.109798431396484, 4.035655975341797], "cluster": 3}, {"key": "sankar2019transferable", "year": "2019", "citations": "7", "title": "Transferable Neural Projection Representations", "abstract": "<p>Neural word representations are at the core of many state-of-the-art natural\nlanguage processing models. A widely used approach is to pre-train, store and\nlook up word or character embedding matrices. While useful, such\nrepresentations occupy huge memory making it hard to deploy on-device and often\ndo not generalize to unknown words due to vocabulary pruning.\n  In this paper, we propose a skip-gram based architecture coupled with\nLocality-Sensitive Hashing (LSH) projections to learn efficient dynamically\ncomputable representations. Our model does not need to store lookup tables as\nrepresentations are computed on-the-fly and require low memory footprint. The\nrepresentations can be trained in an unsupervised fashion and can be easily\ntransferred to other NLP tasks. For qualitative evaluation, we analyze the\nnearest neighbors of the word representations and discover semantically similar\nwords even with misspellings. For quantitative evaluation, we plug our\ntransferable projections into a simple LSTM and run it on multiple NLP tasks\nand show how our transferable projections achieve better performance compared\nto prior work.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [-10.022906303405762, -16.41166114807129], "cluster": 1}, {"key": "sankaranarayanan2016triplet", "year": "2016", "citations": "47", "title": "Triplet Similarity Embedding For Face Verification", "abstract": "<p>In this work, we present an unconstrained face verification algorithm and\nevaluate it on the recently released IJB-A dataset that aims to push the\nboundaries of face verification methods. The proposed algorithm couples a deep\nCNN-based approach with a low-dimensional discriminative embedding learnt using\ntriplet similarity constraints in a large margin fashion. Aside from yielding\nperformance improvement, this embedding provides significant advantages in\nterms of memory and post-processing operations like hashing and visualization.\nExperiments on the IJB-A dataset show that the proposed algorithm outperforms\nstate of the art methods in verification and identification metrics, while\nrequiring less training time.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Evaluation"], "tsne_embedding": [4.4197797775268555, 12.913101196289062], "cluster": 6}, {"key": "sarafijanovicdjukic2020fast", "year": "2020", "citations": "32", "title": "Fast Distance-based Anomaly Detection In Images Using An Inception-like Autoencoder", "abstract": "<p>The goal of anomaly detection is to identify examples that deviate from\nnormal or expected behavior. We tackle this problem for images. We consider a\ntwo-phase approach. First, using normal examples, a convolutional autoencoder\n(CAE) is trained to extract a low-dimensional representation of the images.\nHere, we propose a novel architectural choice when designing the CAE, an\nInception-like CAE. It combines convolutional filters of different kernel sizes\nand it uses a Global Average Pooling (GAP) operation to extract the\nrepresentations from the CAE\u2019s bottleneck layer. Second, we employ a\ndistanced-based anomaly detector in the low-dimensional space of the learned\nrepresentation for the images. However, instead of computing the exact\ndistance, we compute an approximate distance using product quantization. This\nalleviates the high memory and prediction time costs of distance-based anomaly\ndetectors. We compare our proposed approach to a number of baselines and\nstate-of-the-art methods on four image datasets, and we find that our approach\nresulted in improved predictive performance.</p>\n", "tags": ["DATASETS", "Quantization", "Evaluation"], "tsne_embedding": [-10.399368286132812, 14.20527458190918], "cluster": 6}, {"key": "schlegel2018adding", "year": "2018", "citations": "6", "title": "Adding Cues To Binary Feature Descriptors For Visual Place Recognition", "abstract": "<p>In this paper we propose an approach to embed continuous and selector cues in\nbinary feature descriptors used for visual place recognition. The embedding is\nachieved by extending each feature descriptor with a binary string that encodes\na cue and supports the Hamming distance metric. Augmenting the descriptors in\nsuch a way has the advantage of being transparent to the procedure used to\ncompare them. We present two concrete applications of our methodology,\ndemonstrating the two considered types of cues. In addition to that, we\nconducted on these applications a broad quantitative and comparative evaluation\ncovering five benchmark datasets and several state-of-the-art image retrieval\napproaches in combination with various binary descriptor types.</p>\n", "tags": ["DATASETS", "Evaluation", "ICRA", "Distance Metric Learning", "Image Retrieval"], "tsne_embedding": [-0.9376533031463623, 11.980228424072266], "cluster": 6}, {"key": "schlegel2018hbst", "year": "2018", "citations": "52", "title": "HBST: A Hamming Distance Embedding Binary Search Tree For Visual Place Recognition", "abstract": "<p>Reliable and efficient Visual Place Recognition is a major building block of\nmodern SLAM systems. Leveraging on our prior work, in this paper we present a\nHamming Distance embedding Binary Search Tree (HBST) approach for binary\nDescriptor Matching and Image Retrieval. HBST allows for descriptor Search and\nInsertion in logarithmic time by exploiting particular properties of binary\nFeature descriptors. We support the idea behind our search structure with a\nthorough analysis on the exploited descriptor properties and their effects on\ncompleteness and complexity of search and insertion. To validate our claims we\nconducted comparative experiments for HBST and several state-of-the-art methods\non a broad range of publicly available datasets. HBST is available as a compact\nopen-source C++ header-only library.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Tools & Libraries"], "tsne_embedding": [-0.25717660784721375, 12.498003005981445], "cluster": 6}, {"key": "schroff2015facenet", "year": "2015", "citations": "8308", "title": "Facenet: A Unified Embedding For Face Recognition And Clustering", "abstract": "<p>Despite significant recent advances in the field of face recognition,\nimplementing face verification and recognition efficiently at scale presents\nserious challenges to current approaches. In this paper we present a system,\ncalled FaceNet, that directly learns a mapping from face images to a compact\nEuclidean space where distances directly correspond to a measure of face\nsimilarity. Once this space has been produced, tasks such as face recognition,\nverification and clustering can be easily implemented using standard techniques\nwith FaceNet embeddings as feature vectors.\n  Our method uses a deep convolutional network trained to directly optimize the\nembedding itself, rather than an intermediate bottleneck layer as in previous\ndeep learning approaches. To train, we use triplets of roughly aligned matching\n/ non-matching face patches generated using a novel online triplet mining\nmethod. The benefit of our approach is much greater representational\nefficiency: we achieve state-of-the-art face recognition performance using only\n128-bytes per face.\n  On the widely used Labeled Faces in the Wild (LFW) dataset, our system\nachieves a new record accuracy of 99.63%. On YouTube Faces DB it achieves\n95.12%. Our system cuts the error rate in comparison to the best published\nresult by 30% on both datasets.\n  We also introduce the concept of harmonic embeddings, and a harmonic triplet\nloss, which describe different versions of face embeddings (produced by\ndifferent networks) that are compatible to each other and allow for direct\ncomparison between each other.</p>\n", "tags": ["CVPR", "DATASETS", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [-14.240327835083008, 3.008632183074951], "cluster": 8}, {"key": "schubert2020graph", "year": "2020", "citations": "9", "title": "Graph-based Non-linear Least Squares Optimization For Visual Place Recognition In Changing Environments", "abstract": "<p>Visual place recognition is an important subproblem of mobile robot\nlocalization. Since it is a special case of image retrieval, the basic source\nof information is the pairwise similarity of image descriptors. However, the\nembedding of the image retrieval problem in this robotic task provides\nadditional structure that can be exploited, e.g. spatio-temporal consistency.\nSeveral algorithms exist to exploit this structure, e.g., sequence processing\napproaches or descriptor standardization approaches for changing environments.\nIn this paper, we propose a graph-based framework to systematically exploit\ndifferent types of additional structure and information. The graphical model is\nused to formulate a non-linear least squares problem that can be optimized with\nstandard tools. Beyond sequences and standardization, we propose the usage of\nintra-set similarities within the database and/or the query image set as\nadditional source of information. If available, our approach also allows to\nseamlessly integrate additional knowledge about poses of database images. We\nevaluate the system on a variety of standard place recognition datasets and\ndemonstrate performance improvements for a large number of different\nconfigurations including different sources of information, different types of\nconstraints, and online or offline place recognition setups.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Graph Based ANN", "Tools & Libraries", "Evaluation"], "tsne_embedding": [0.48933637142181396, 19.71196174621582], "cluster": 6}, {"key": "schubert2021beyond", "year": "2021", "citations": "7", "title": "Beyond ANN: Exploiting Structural Knowledge For Efficient Place Recognition", "abstract": "<p>Visual place recognition is the task of recognizing same places of query\nimages in a set of database images, despite potential condition changes due to\ntime of day, weather or seasons. It is important for loop closure detection in\nSLAM and candidate selection for global localization. Many approaches in the\nliterature perform computationally inefficient full image comparisons between\nqueries and all database images. There is still a lack of suited methods for\nefficient place recognition that allow a fast, sparse comparison of only the\nmost promising image pairs without any loss in performance. While this is\npartially given by ANN-based methods, they trade speed for precision and\nadditional memory consumption, and many cannot find arbitrary numbers of\nmatching database images in case of loops in the database. In this paper, we\npropose a novel fast sequence-based method for efficient place recognition that\ncan be applied online. It uses relocalization to recover from sequence losses,\nand exploits usually available but often unused intra-database similarities for\na potential detection of all matching database images for each query in case of\nloops or stops in the database. We performed extensive experimental evaluations\nover five datasets and 21 sequence combinations, and show that our method\noutperforms two state-of-the-art approaches and even full image comparisons in\nmany cases, while providing a good tradeoff between performance and percentage\nof evaluated image pairs. Source code for Matlab will be provided with\npublication of this paper.</p>\n", "tags": ["DATASETS", "ICRA", "Evaluation"], "tsne_embedding": [5.027884483337402, -9.609515190124512], "cluster": 2}, {"key": "schubert2021triangle", "year": "2021", "citations": "19", "title": "A Triangle Inequality For Cosine Similarity", "abstract": "<p>Similarity search is a fundamental problem for many data analysis techniques.\nMany efficient search techniques rely on the triangle inequality of metrics,\nwhich allows pruning parts of the search space based on transitive bounds on\ndistances. Recently, Cosine similarity has become a popular alternative choice\nto the standard Euclidean metric, in particular in the context of textual data\nand neural network embeddings. Unfortunately, Cosine similarity is not metric\nand does not satisfy the standard triangle inequality. Instead, many search\ntechniques for Cosine rely on approximation techniques such as locality\nsensitive hashing. In this paper, we derive a triangle inequality for Cosine\nsimilarity that is suitable for efficient similarity search with many standard\nsearch structures (such as the VP-tree, Cover-tree, and M-tree); show that this\nbound is tight and discuss fast approximations for it. We hope that this spurs\nnew research on accelerating exact similarity search for cosine similarity, and\npossible other similarity measures beyond the existing work for distance\nmetrics.</p>\n", "tags": ["Hashing Methods", "Distance Metric Learning", "Alt", "Similarity Search", "Tree Based ANN"], "tsne_embedding": [10.837748527526855, 4.431849002838135], "cluster": 4}, {"key": "schuhmann2021laion", "year": "2021", "citations": "312", "title": "LAION-400M: Open Dataset Of Clip-filtered 400 Million Image-text Pairs", "abstract": "<p>Multi-modal language-vision models trained on hundreds of millions of\nimage-text pairs (e.g. CLIP, DALL-E) gained a recent surge, showing remarkable\ncapability to perform zero- or few-shot learning and transfer even in absence\nof per-sample labels on target image data. Despite this trend, to date there\nhas been no publicly available datasets of sufficient scale for training such\nmodels from scratch. To address this issue, in a community effort we build and\nrelease for public LAION-400M, a dataset with CLIP-filtered 400 million\nimage-text pairs, their CLIP embeddings and kNN indices that allow efficient\nsimilarity search.</p>\n", "tags": ["DATASETS", "Similarity Search"], "tsne_embedding": [-7.149919033050537, 24.113264083862305], "cluster": 6}, {"key": "schulz2020can", "year": "2020", "citations": "8", "title": "Can Embeddings Adequately Represent Medical Terminology? New Large-scale Medical Term Similarity Datasets Have The Answer!", "abstract": "<p>A large number of embeddings trained on medical data have emerged, but it\nremains unclear how well they represent medical terminology, in particular\nwhether the close relationship of semantically similar medical terms is encoded\nin these embeddings. To date, only small datasets for testing medical term\nsimilarity are available, not allowing to draw conclusions about the\ngeneralisability of embeddings to the enormous amount of medical terms used by\ndoctors. We present multiple automatically created large-scale medical term\nsimilarity datasets and confirm their high quality in an annotation study with\ndoctors. We evaluate state-of-the-art word and contextual embeddings on our new\ndatasets, comparing multiple vector similarity metrics and word vector\naggregation techniques. Our results show that current embeddings are limited in\ntheir ability to adequately encode medical terms. The novel datasets thus form\na challenging new benchmark for the development of medical embeddings able to\naccurately represent the whole medical terminology.</p>\n", "tags": ["AAAI", "DATASETS", "Graph Based ANN", "Distance Metric Learning", "Evaluation"], "tsne_embedding": [-23.2263126373291, 19.911909103393555], "cluster": 3}, {"key": "seidenschwarz2021learning", "year": "2021", "citations": "23", "title": "Learning Intra-batch Connections For Deep Metric Learning", "abstract": "<p>The goal of metric learning is to learn a function that maps samples to a\nlower-dimensional space where similar samples lie closer than dissimilar ones.\nParticularly, deep metric learning utilizes neural networks to learn such a\nmapping. Most approaches rely on losses that only take the relations between\npairs or triplets of samples into account, which either belong to the same\nclass or two different classes. However, these methods do not explore the\nembedding space in its entirety. To this end, we propose an approach based on\nmessage passing networks that takes all the relations in a mini-batch into\naccount. We refine embedding vectors by exchanging messages among all samples\nin a given batch allowing the training process to be aware of its overall\nstructure. Since not all samples are equally important to predict a decision\nboundary, we use an attention mechanism during message passing to allow samples\nto weigh the importance of each neighbor accordingly. We achieve\nstate-of-the-art results on clustering and image retrieval on the CUB-200-2011,\nCars196, Stanford Online Products, and In-Shop Clothes datasets. To facilitate\nfurther research, we make available the code and the models at\nhttps://github.com/dvl-tum/intra_batch_connections.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [-21.464529037475586, 4.713202953338623], "cluster": 3}, {"key": "settle2017query", "year": "2017", "citations": "56", "title": "Query-by-example Search With Discriminative Neural Acoustic Word Embeddings", "abstract": "<p>Query-by-example search often uses dynamic time warping (DTW) for comparing\nqueries and proposed matching segments. Recent work has shown that comparing\nspeech segments by representing them as fixed-dimensional vectors \u2014 acoustic\nword embeddings \u2014 and measuring their vector distance (e.g., cosine distance)\ncan discriminate between words more accurately than DTW-based approaches. We\nconsider an approach to query-by-example search that embeds both the query and\ndatabase segments according to a neural model, followed by nearest-neighbor\nsearch to find the matching segments. Earlier work on embedding-based\nquery-by-example, using template-based acoustic word embeddings, achieved\ncompetitive performance. We find that our embeddings, based on recurrent neural\nnetworks trained to optimize word discrimination, achieve substantial\nimprovements in performance and run-time efficiency over the previous\napproaches.</p>\n", "tags": ["Efficiency And Optimization", "INTERSPEECH", "Evaluation"], "tsne_embedding": [6.700011253356934, 5.257706165313721], "cluster": 4}, {"key": "shahreza2022mlp", "year": "2022", "citations": "18", "title": "Mlp-hash: Protecting Face Templates Via Hashing Of Randomized Multi-layer Perceptron", "abstract": "<p>Applications of face recognition systems for authentication purposes are\ngrowing rapidly. Although state-of-the-art (SOTA) face recognition systems have\nhigh recognition accuracy, the features which are extracted for each user and\nare stored in the system\u2019s database contain privacy-sensitive information.\nAccordingly, compromising this data would jeopardize users\u2019 privacy. In this\npaper, we propose a new cancelable template protection method, dubbed MLP-hash,\nwhich generates protected templates by passing the extracted features through a\nuser-specific randomly-weighted multi-layer perceptron (MLP) and binarizing the\nMLP output. We evaluated the unlinkability, irreversibility, and recognition\naccuracy of our proposed biometric template protection method to fulfill the\nISO/IEC 30136 standard requirements. Our experiments with SOTA face recognition\nsystems on the MOBIO and LFW datasets show that our method has competitive\nperformance with the BioHashing and IoM Hashing (IoM-GRP and IoM-URP) template\nprotection algorithms. We provide an open-source implementation of all the\nexperiments presented in this paper so that other researchers can verify our\nfindings and build upon our work.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Alt", "Tools & Libraries", "Evaluation"], "tsne_embedding": [5.250802993774414, -26.529781341552734], "cluster": 5}, {"key": "shan2018recurrent", "year": "2018", "citations": "9", "title": "Recurrent Binary Embedding For Gpu-enabled Exhaustive Retrieval From Billion-scale Semantic Vectors", "abstract": "<p>Rapid advances in GPU hardware and multiple areas of Deep Learning open up a\nnew opportunity for billion-scale information retrieval with exhaustive search.\nBuilding on top of the powerful concept of semantic learning, this paper\nproposes a Recurrent Binary Embedding (RBE) model that learns compact\nrepresentations for real-time retrieval. The model has the unique ability to\nrefine a base binary vector by progressively adding binary residual vectors to\nmeet the desired accuracy. The refined vector enables efficient implementation\nof exhaustive similarity computation with bit-wise operations, followed by a\nnear- lossless k-NN selection algorithm, also proposed in this paper. The\nproposed algorithms are integrated into an end-to-end multi-GPU system that\nretrieves thousands of top items from over a billion candidates in real-time.\nThe RBE model and the retrieval system were evaluated with data from a major\npaid search engine. When measured against the state-of-the-art model for binary\nrepresentation and the full precision model for semantic embedding, RBE\nsignificantly outperformed the former, and filled in over 80% of the AUC gap\nin-between. Experiments comparing with our production retrieval system also\ndemonstrated superior performance. While the primary focus of this paper is to\nbuild RBE based on a particular class of semantic models, generalizing to other\ntypes is straightforward, as exemplified by two different models at the end of\nthe paper.</p>\n", "tags": ["KDD", "Hashing Methods", "Large Scale Search", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-7.132732391357422, -13.62851333618164], "cluster": 9}, {"key": "shand2020locality", "year": "2020", "citations": "15", "title": "Locality-sensitive Hashing In Function Spaces", "abstract": "<p>We discuss the problem of performing similarity search over function spaces.\nTo perform search over such spaces in a reasonable amount of time, we use {\\it\nlocality-sensitive hashing} (LSH). We present two methods that allow LSH\nfunctions on \\(\\mathbb{R}^N\\) to be extended to \\(L^p\\) spaces: one using function\napproximation in an orthonormal basis, and another using (quasi-)Monte\nCarlo-style techniques. We use the presented hashing schemes to construct an\nLSH family for Wasserstein distance over one-dimensional, continuous\nprobability distributions.</p>\n", "tags": ["Locality Sensitive Hashing", "Similarity Search", "Hashing Methods"], "tsne_embedding": [24.794403076171875, -0.31664690375328064], "cluster": 7}, {"key": "shao2018h", "year": "2018", "citations": "30", "title": "H-CNN: Spatial Hashing Based CNN For 3D Shape Analysis", "abstract": "<p>We present a novel spatial hashing based data structure to facilitate 3D\nshape analysis using convolutional neural networks (CNNs). Our method well\nutilizes the sparse occupancy of 3D shape boundary and builds hierarchical hash\ntables for an input model under different resolutions. Based on this data\nstructure, we design two efficient GPU algorithms namely hash2col and col2hash\nso that the CNN operations like convolution and pooling can be efficiently\nparallelized. The spatial hashing is nearly minimal, and our data structure is\nalmost of the same size as the raw input. Compared with state-of-the-art\noctree-based methods, our data structure significantly reduces the memory\nfootprint during the CNN training. As the input geometry features are more\ncompactly packed, CNN operations also run faster with our data structure. The\nexperiment shows that, under the same network structure, our method yields\ncomparable or better benchmarks compared to the state-of-the-art while it has\nonly one-third memory consumption. Such superior memory performance allows the\nCNN to handle high-resolution shape analysis.</p>\n", "tags": ["Tree Based ANN", "Hashing Methods", "Evaluation"], "tsne_embedding": [-14.405275344848633, 23.4244327545166], "cluster": 6}, {"key": "shao2022johnson", "year": "2022", "citations": "7", "title": "Johnson-lindenstrauss Embeddings For Noisy Vectors -- Taking Advantage Of The Noise", "abstract": "<p>This paper investigates theoretical properties of subsampling and hashing as\ntools for approximate Euclidean norm-preserving embeddings for vectors with\n(unknown) additive Gaussian noises. Such embeddings are sometimes called\nJohnson-lindenstrauss embeddings due to their celebrated lemma. Previous work\nshows that as sparse embeddings, the success of subsampling and hashing closely\ndepends on the \\(l_\\infty\\) to \\(l_2\\) ratios of the vector to be mapped. This\npaper shows that the presence of noise removes such constrain in\nhigh-dimensions, in other words, sparse embeddings such as subsampling and\nhashing with comparable embedding dimensions to dense embeddings have similar\napproximate norm-preserving dimensionality-reduction properties. The key is\nthat the noise should be treated as an information to be exploited, not simply\nsomething to be removed. Theoretical bounds for subsampling and hashing to\nrecover the approximate norm of a high dimension vector in the presence of\nnoise are derived, with numerical illustrations showing better performances are\nachieved in the presence of noise.</p>\n", "tags": ["Hashing Methods", "Evaluation"], "tsne_embedding": [25.495529174804688, 4.9705047607421875], "cluster": 7}, {"key": "sharma2016stacked", "year": "2016", "citations": "32", "title": "Stacked Autoencoders For Medical Image Search", "abstract": "<p>Medical images can be a valuable resource for reliable information to support\nmedical diagnosis. However, the large volume of medical images makes it\nchallenging to retrieve relevant information given a particular scenario. To\nsolve this challenge, content-based image retrieval (CBIR) attempts to\ncharacterize images (or image regions) with invariant content information in\norder to facilitate image search. This work presents a feature extraction\ntechnique for medical images using stacked autoencoders, which encode images to\nbinary vectors. The technique is applied to the IRMA dataset, a collection of\n14,410 x-ray images in order to demonstrate the ability of autoencoders to\nretrieve similar x-rays given test queries. Using IRMA dataset as a benchmark,\nit was found that stacked autoencoders gave excellent results with a retrieval\nerror of 376 for 1,733 test images with a compression of 74.61%.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Evaluation"], "tsne_embedding": [-23.37713050842285, 17.776836395263672], "cluster": 3}, {"key": "sharma2018improving", "year": "2018", "citations": "6", "title": "Improving Similarity Search With High-dimensional Locality-sensitive Hashing", "abstract": "<p>We propose a new class of data-independent locality-sensitive hashing (LSH)\nalgorithms based on the fruit fly olfactory circuit. The fundamental difference\nof this approach is that, instead of assigning hashes as dense points in a low\ndimensional space, hashes are assigned in a high dimensional space, which\nenhances their separability. We show theoretically and empirically that this\nnew family of hash functions is locality-sensitive and preserves rank\nsimilarity for inputs in any `p space. We then analyze different variations on\nthis strategy and show empirically that they outperform existing LSH methods\nfor nearest-neighbors search on six benchmark datasets. Finally, we propose a\nmulti-probe version of our algorithm that achieves higher performance for the\nsame query time, or conversely, that maintains performance of prior approaches\nwhile taking significantly less indexing time and memory. Overall, our approach\nleverages the advantages of separability provided by high-dimensional spaces,\nwhile still remaining computationally efficient</p>\n", "tags": ["Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Similarity Search", "Evaluation"], "tsne_embedding": [11.310002326965332, -1.9008921384811401], "cluster": 4}, {"key": "sharma2019retrieving", "year": "2019", "citations": "20", "title": "Retrieving Similar E-commerce Images Using Deep Learning", "abstract": "<p>In this paper, we propose a deep convolutional neural network for learning\nthe embeddings of images in order to capture the notion of visual similarity.\nWe present a deep siamese architecture that when trained on positive and\nnegative pairs of images learn an embedding that accurately approximates the\nranking of images in order of visual similarity notion. We also implement a\nnovel loss calculation method using an angular loss metrics based on the\nproblems requirement. The final embedding of the image is combined\nrepresentation of the lower and top-level embeddings. We used fractional\ndistance matrix to calculate the distance between the learned embeddings in\nn-dimensional space. In the end, we compare our architecture with other\nexisting deep architecture and go on to demonstrate the superiority of our\nsolution in terms of image retrieval by testing the architecture on four\ndatasets. We also show how our suggested network is better than the other\ntraditional deep CNNs used for capturing fine-grained image similarities by\nlearning an optimum embedding.</p>\n", "tags": ["Image Retrieval", "DATASETS"], "tsne_embedding": [-22.539159774780273, 4.7509541511535645], "cluster": 3}, {"key": "sharma2021learning", "year": "2021", "citations": "23", "title": "Learning Canonical Embedding For Non-rigid Shape Matching", "abstract": "<p>This paper provides a novel framework that learns canonical embeddings for\nnon-rigid shape matching. In contrast to prior work in this direction, our\nframework is trained end-to-end and thus avoids instabilities and constraints\nassociated with the commonly-used Laplace-Beltrami basis or sequential\noptimization schemes. On multiple datasets, we demonstrate that learning self\nsymmetry maps with a deep functional map projects 3D shapes into a low\ndimensional canonical embedding that facilitates non-rigid shape correspondence\nvia a simple nearest neighbor search. Our framework outperforms multiple recent\nlearning based methods on FAUST and SHREC benchmarks while being\ncomputationally cheaper, data-efficient, and robust.</p>\n", "tags": ["DATASETS", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-1.5581059455871582, 24.242839813232422], "cluster": 6}, {"key": "she2023image", "year": "2023", "citations": "7", "title": "Image Patch-matching With Graph-based Learning In Street Scenes", "abstract": "<p>Matching landmark patches from a real-time image captured by an on-vehicle\ncamera with landmark patches in an image database plays an important role in\nvarious computer perception tasks for autonomous driving. Current methods focus\non local matching for regions of interest and do not take into account spatial\nneighborhood relationships among the image patches, which typically correspond\nto objects in the environment. In this paper, we construct a spatial graph with\nthe graph vertices corresponding to patches and edges capturing the spatial\nneighborhood information. We propose a joint feature and metric learning model\nwith graph-based learning. We provide a theoretical basis for the graph-based\nloss by showing that the information distance between the distributions\nconditioned on matched and unmatched pairs is maximized under our framework. We\nevaluate our model using several street-scene datasets and demonstrate that our\napproach achieves state-of-the-art matching results.</p>\n", "tags": ["DATASETS", "Tools & Libraries", "Graph Based ANN", "Distance Metric Learning"], "tsne_embedding": [13.118768692016602, 8.491925239562988], "cluster": 0}, {"key": "shen2016learning", "year": "2016", "citations": "111", "title": "Learning Binary Codes And Binary Weights For Efficient Classification", "abstract": "<p>This paper proposes a generic formulation that significantly expedites the\ntraining and deployment of image classification models, particularly under the\nscenarios of many image categories and high feature dimensions. As a defining\nproperty, our method represents both the images and learned classifiers using\nbinary hash codes, which are simultaneously learned from the training data.\nClassifying an image thereby reduces to computing the Hamming distance between\nthe binary codes of the image and classifiers and selecting the class with\nminimal Hamming distance. Conventionally, compact hash codes are primarily used\nfor accelerating image search. Our work is first of its kind to represent\nclassifiers using binary codes. Specifically, we formulate multi-class image\nclassification as an optimization problem over binary variables. The\noptimization alternatively proceeds over the binary classifiers and image hash\ncodes. Profiting from the special property of binary codes, we show that the\nsub-problems can be efficiently solved through either a binary quadratic\nprogram (BQP) or linear program. In particular, for attacking the BQP problem,\nwe propose a novel bit-flipping procedure which enjoys high efficacy and local\noptimality guarantee. Our formulation supports a large family of empirical loss\nfunctions and is here instantiated by exponential / hinge losses. Comprehensive\nevaluations are conducted on several representative image benchmarks. The\nexperiments consistently observe reduced complexities of model training and\ndeployment, without sacrifice of accuracies.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Compact Codes", "Alt", "Evaluation"], "tsne_embedding": [-5.081813812255859, 9.07529354095459], "cluster": 8}, {"key": "shen2017deep", "year": "2017", "citations": "49", "title": "Deep Binaries: Encoding Semantic-rich Cues For Efficient Textual-visual Cross Retrieval", "abstract": "<p>Cross-modal hashing is usually regarded as an effective technique for\nlarge-scale textual-visual cross retrieval, where data from different\nmodalities are mapped into a shared Hamming space for matching. Most of the\ntraditional textual-visual binary encoding methods only consider holistic image\nrepresentations and fail to model descriptive sentences. This renders existing\nmethods inappropriate to handle the rich semantics of informative cross-modal\ndata for quality textual-visual search tasks. To address the problem of hashing\ncross-modal data with semantic-rich cues, in this paper, a novel integrated\ndeep architecture is developed to effectively encode the detailed semantics of\ninformative images and long descriptive sentences, named as Textual-Visual Deep\nBinaries (TVDB). In particular, region-based convolutional networks with long\nshort-term memory units are introduced to fully explore image regional details\nwhile semantic cues of sentences are modeled by a text convolutional network.\nAdditionally, we propose a stochastic batch-wise training routine, where\nhigh-quality binary codes and deep encoding functions are efficiently optimized\nin an alternating manner. Experiments are conducted on three multimedia\ndatasets, i.e. Microsoft COCO, IAPR TC-12, and INRIA Web Queries, where the\nproposed TVDB model significantly outperforms state-of-the-art binary coding\nmethods in the task of cross-modal retrieval.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Compact Codes", "Alt", "ICCV", "Multimodal Retrieval", "Evaluation"], "tsne_embedding": [-8.629171371459961, 2.2523608207702637], "cluster": 8}, {"key": "shen2018nash", "year": "2018", "citations": "65", "title": "NASH: Toward End-to-end Neural Architecture For Generative Semantic Hashing", "abstract": "<p>Semantic hashing has become a powerful paradigm for fast similarity search in\nmany information retrieval systems. While fairly successful, previous\ntechniques generally require two-stage training, and the binary constraints are\nhandled ad-hoc. In this paper, we present an end-to-end Neural Architecture for\nSemantic Hashing (NASH), where the binary hashing codes are treated as\nBernoulli latent variables. A neural variational inference framework is\nproposed for training, where gradients are directly back-propagated through the\ndiscrete latent variable to optimize the hash function. We also draw\nconnections between proposed method and rate-distortion theory, which provides\na theoretical foundation for the effectiveness of the proposed framework.\nExperimental results on three public datasets demonstrate that our method\nsignificantly outperforms several state-of-the-art models on both unsupervised\nand supervised scenarios.</p>\n", "tags": ["DATASETS", "Text Retrieval", "Hashing Methods", "ACL", "Similarity Search", "Tools & Libraries"], "tsne_embedding": [1.0563613176345825, -15.768194198608398], "cluster": 5}, {"key": "shen2018zero", "year": "2018", "citations": "154", "title": "Zero-shot Sketch-image Hashing", "abstract": "<p>Recent studies show that large-scale sketch-based image retrieval (SBIR) can\nbe efficiently tackled by cross-modal binary representation learning methods,\nwhere Hamming distance matching significantly speeds up the process of\nsimilarity search. Providing training and test data subjected to a fixed set of\npre-defined categories, the cutting-edge SBIR and cross-modal hashing works\nobtain acceptable retrieval performance. However, most of the existing methods\nfail when the categories of query sketches have never been seen during\ntraining. In this paper, the above problem is briefed as a novel but realistic\nzero-shot SBIR hashing task. We elaborate the challenges of this special task\nand accordingly propose a zero-shot sketch-image hashing (ZSIH) model. An\nend-to-end three-network architecture is built, two of which are treated as the\nbinary encoders. The third network mitigates the sketch-image heterogeneity and\nenhances the semantic relations among data by utilizing the Kronecker fusion\nlayer and graph convolution, respectively. As an important part of ZSIH, we\nformulate a generative hashing scheme in reconstructing semantic knowledge\nrepresentations for zero-shot retrieval. To the best of our knowledge, ZSIH is\nthe first zero-shot hashing work suitable for SBIR and cross-modal search.\nComprehensive experiments are conducted on two extended datasets, i.e., Sketchy\nand TU-Berlin with a novel zero-shot train-test split. The proposed model\nremarkably outperforms related works.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "CVPR", "Similarity Search", "Evaluation"], "tsne_embedding": [-6.809092998504639, 0.086558036506176], "cluster": 8}, {"key": "shen2019embarrassingly", "year": "2019", "citations": "20", "title": "Embarrassingly Simple Binary Representation Learning", "abstract": "<p>Recent binary representation learning models usually require sophisticated\nbinary optimization, similarity measure or even generative models as\nauxiliaries. However, one may wonder whether these non-trivial components are\nneeded to formulate practical and effective hashing models. In this paper, we\nanswer the above question by proposing an embarrassingly simple approach to\nbinary representation learning. With a simple classification objective, our\nmodel only incorporates two additional fully-connected layers onto the top of\nan arbitrary backbone network, whilst complying with the binary constraints\nduring training. The proposed model lower-bounds the Information Bottleneck\n(IB) between data samples and their semantics, and can be related to many\nrecent `learning to hash\u2019 paradigms. We show that, when properly designed, even\nsuch a simple network can generate effective binary codes, by fully exploring\ndata semantics without any held-out alternating updating steps or auxiliary\nmodels. Experiments are conducted on conventional large-scale benchmarks, i.e.,\nCIFAR-10, NUS-WIDE, and ImageNet, where the proposed simple model outperforms\nthe state-of-the-art methods.</p>\n", "tags": ["Hashing Methods", "Graph Based ANN", "Compact Codes", "Alt", "ICCV", "Evaluation"], "tsne_embedding": [-4.782401084899902, -15.409820556640625], "cluster": 9}, {"key": "shen2020auto", "year": "2020", "citations": "113", "title": "Auto-encoding Twin-bottleneck Hashing", "abstract": "<p>Conventional unsupervised hashing methods usually take advantage of\nsimilarity graphs, which are either pre-computed in the high-dimensional space\nor obtained from random anchor points. On the one hand, existing methods\nuncouple the procedures of hash function learning and graph construction. On\nthe other hand, graphs empirically built upon original data could introduce\nbiased prior knowledge of data relevance, leading to sub-optimal retrieval\nperformance. In this paper, we tackle the above problems by proposing an\nefficient and adaptive code-driven graph, which is updated by decoding in the\ncontext of an auto-encoder. Specifically, we introduce into our framework twin\nbottlenecks (i.e., latent variables) that exchange crucial information\ncollaboratively. One bottleneck (i.e., binary codes) conveys the high-level\nintrinsic data structure captured by the code-driven graph to the other (i.e.,\ncontinuous variables for low-level detail information), which in turn\npropagates the updated network feedback for the encoder to learn more\ndiscriminative binary codes. The auto-encoding learning objective literally\nrewards the code-driven graph to learn an optimal encoder. Moreover, the\nproposed model can be simply optimized by gradient descent without violating\nthe binary constraints. Experiments on benchmarked datasets clearly show the\nsuperiority of our framework over the state-of-the-art hashing methods. Our\nsource code can be found at https://github.com/ymcidence/TBH.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Graph Based ANN", "CVPR", "Compact Codes", "Tools & Libraries", "Evaluation"], "tsne_embedding": [13.68130111694336, 11.748727798461914], "cluster": 0}, {"key": "shen2022semicon", "year": "2022", "citations": "12", "title": "SEMICON: A Learning-to-hash Solution For Large-scale Fine-grained Image Retrieval", "abstract": "<p>In this paper, we propose Suppression-Enhancing Mask based attention and\nInteractive Channel transformatiON (SEMICON) to learn binary hash codes for\ndealing with large-scale fine-grained image retrieval tasks. In SEMICON, we\nfirst develop a suppression-enhancing mask (SEM) based attention to dynamically\nlocalize discriminative image regions. More importantly, different from\nexisting attention mechanism simply erasing previous discriminative regions,\nour SEM is developed to restrain such regions and then discover other\ncomplementary regions by considering the relation between activated regions in\na stage-by-stage fashion. In each stage, the interactive channel transformation\n(ICON) module is afterwards designed to exploit correlations across channels of\nattended activation tensors. Since channels could generally correspond to the\nparts of fine-grained objects, the part correlation can be also modeled\naccordingly, which further improves fine-grained retrieval accuracy. Moreover,\nto be computational economy, ICON is realized by an efficient two-step process.\nFinally, the hash learning of our SEMICON consists of both global- and\nlocal-level branches for better representing fine-grained objects and then\ngenerating binary hash codes explicitly corresponding to multiple levels.\nExperiments on five benchmark fine-grained datasets show our superiority over\ncompeting methods.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Evaluation"], "tsne_embedding": [-10.991101264953613, 11.373525619506836], "cluster": 6}, {"key": "shen2025unsupervised", "year": "2025", "citations": "377", "title": "Unsupervised Deep Hashing With Similarity-adaptive And Discrete Optimization", "abstract": "<p>Recent vision and learning studies show that learning compact hash codes can facilitate massive data processing\nwith significantly reduced storage and computation. Particularly, learning deep hash functions has greatly improved the retrieval\nperformance, typically under the semantic supervision. In contrast, current unsupervised deep hashing algorithms can hardly achieve\nsatisfactory performance due to either the relaxed optimization or absence of similarity-sensitive objective. In this work, we propose a\nsimple yet effective unsupervised hashing framework, named Similarity-Adaptive Deep Hashing (SADH), which alternatingly proceeds\nover three training modules: deep hash model training, similarity graph updating and binary code optimization. The key difference from\nthe widely-used two-step hashing method is that the output representations of the learned deep model help update the similarity graph\nmatrix, which is then used to improve the subsequent code optimization. In addition, for producing high-quality binary codes, we devise\nan effective discrete optimization algorithm which can directly handle the binary constraints with a general hashing loss. Extensive\nexperiments validate the efficacy of SADH, which consistently outperforms the state-of-the-arts by large gaps.</p>\n", "tags": ["Hashing Methods", "Compact Codes", "Alt", "Neural Hashing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-6.845515727996826, -9.072759628295898], "cluster": 9}, {"key": "shenoy2017deduplication", "year": "2017", "citations": "18", "title": "Deduplication In A Massive Clinical Note Dataset", "abstract": "<p>Duplication, whether exact or partial, is a common issue in many datasets. In\nclinical notes data, duplication (and near duplication) can arise for many\nreasons, such as the pervasive use of templates, copy-pasting, or notes being\ngenerated by automated procedures. A key challenge in removing such near\nduplicates is the size of such datasets; our own dataset consists of more than\n10 million notes. To detect and correct such duplicates requires algorithms\nthat both accurate and highly scalable. We describe a solution based on\nMinhashing with Locality Sensitive Hashing. In this paper, we present the\ntheory behind this method and present a database-inspired approach to make the\nmethod scalable. We also present a clustering technique using disjoint sets to\nproduce dense clusters, which speeds up our algorithm.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "DATASETS"], "tsne_embedding": [8.344998359680176, -16.906021118164062], "cluster": 2}, {"key": "sheynin2022knn", "year": "2022", "citations": "26", "title": "Knn-diffusion: Image Generation Via Large-scale Retrieval", "abstract": "<p>Recent text-to-image models have achieved impressive results. However, since\nthey require large-scale datasets of text-image pairs, it is impractical to\ntrain them on new domains where data is scarce or not labeled. In this work, we\npropose using large-scale retrieval methods, in particular, efficient\nk-Nearest-Neighbors (kNN), which offers novel capabilities: (1) training a\nsubstantially small and efficient text-to-image diffusion model without any\ntext, (2) generating out-of-distribution images by simply swapping the\nretrieval database at inference time, and (3) performing text-driven local\nsemantic manipulations while preserving object identity. To demonstrate the\nrobustness of our method, we apply our kNN approach on two state-of-the-art\ndiffusion backbones, and show results on several different datasets. As\nevaluated by human studies and automatic metrics, our method achieves\nstate-of-the-art results compared to existing approaches that train\ntext-to-image generation models using images only (without paired text data)</p>\n", "tags": ["DATASETS", "Robustness"], "tsne_embedding": [-10.656937599182129, 9.448224067687988], "cluster": 8}, {"key": "shi2017face", "year": "2017", "citations": "107", "title": "Face Clustering: Representation And Pairwise Constraints", "abstract": "<p>Clustering face images according to their identity has two important\napplications: (i) grouping a collection of face images when no external labels\nare associated with images, and (ii) indexing for efficient large scale face\nretrieval. The clustering problem is composed of two key parts: face\nrepresentation and choice of similarity for grouping faces. We first propose a\nrepresentation based on ResNet, which has been shown to perform very well in\nimage classification problems. Given this representation, we design a\nclustering algorithm, Conditional Pairwise Clustering (ConPaC), which directly\nestimates the adjacency matrix only based on the similarity between face\nimages. This allows a dynamic selection of number of clusters and retains\npairwise similarity between faces. ConPaC formulates the clustering problem as\na Conditional Random Field (CRF) model and uses Loopy Belief Propagation to\nfind an approximate solution for maximizing the posterior probability of the\nadjacency matrix. Experimental results on two benchmark face datasets (LFW and\nIJB-B) show that ConPaC outperforms well known clustering algorithms such as\nk-means, spectral clustering and approximate rank-order. Additionally, our\nalgorithm can naturally incorporate pairwise constraints to obtain a\nsemi-supervised version that leads to improved clustering performance. We also\npropose an k-NN variant of ConPaC, which has a linear time complexity given a\nk-NN graph, suitable for large datasets.</p>\n", "tags": ["DATASETS", "Evaluation"], "tsne_embedding": [7.844780921936035, 11.929594993591309], "cluster": 0}, {"key": "shi2018fast", "year": "2018", "citations": "9", "title": "Fast Locality Sensitive Hashing For Beam Search On GPU", "abstract": "<p>We present a GPU-based Locality Sensitive Hashing (LSH) algorithm to speed up\nbeam search for sequence models. We utilize the winner-take-all (WTA) hash,\nwhich is based on relative ranking order of hidden dimensions and thus\nresilient to perturbations in numerical values. Our algorithm is designed by\nfully considering the underling architecture of CUDA-enabled GPUs\n(Algorithm/Architecture Co-design): 1) A parallel Cuckoo hash table is applied\nfor LSH code lookup (guaranteed O(1) lookup time); 2) Candidate lists are\nshared across beams to maximize the parallelism; 3) Top frequent words are\nmerged into candidate lists to improve performance. Experiments on 4\nlarge-scale neural machine translation models demonstrate that our algorithm\ncan achieve up to 4x speedup on softmax module, and 2x overall speedup without\nhurting BLEU on GPU.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [0.42776960134506226, -13.203956604003906], "cluster": 9}, {"key": "shi2018scalable", "year": "2018", "citations": "11", "title": "A Scalable Optimization Mechanism For Pairwise Based Discrete Hashing", "abstract": "<p>Maintaining the pair similarity relationship among originally\nhigh-dimensional data into a low-dimensional binary space is a popular strategy\nto learn binary codes. One simiple and intutive method is to utilize two\nidentical code matrices produced by hash functions to approximate a pairwise\nreal label matrix. However, the resulting quartic problem is difficult to\ndirectly solve due to the non-convex and non-smooth nature of the objective. In\nthis paper, unlike previous optimization methods using various relaxation\nstrategies, we aim to directly solve the original quartic problem using a novel\nalternative optimization mechanism to linearize the quartic problem by\nintroducing a linear regression model. Additionally, we find that gradually\nlearning each batch of binary codes in a sequential mode, i.e. batch by batch,\nis greatly beneficial to the convergence of binary code learning. Based on this\nsignificant discovery and the proposed strategy, we introduce a scalable\nsymmetric discrete hashing algorithm that gradually and smoothly updates each\nbatch of binary codes. To further improve the smoothness, we also propose a\ngreedy symmetric discrete hashing algorithm to update each bit of batch binary\ncodes. Moreover, we extend the proposed optimization mechanism to solve the\nnon-convex optimization problems for binary code learning in many other\npairwise based hashing algorithms. Extensive experiments on benchmark\nsingle-label and multi-label databases demonstrate the superior performance of\nthe proposed mechanism over recent state-of-the-art methods.</p>\n", "tags": ["Compact Codes", "Alt", "Hashing Methods", "Evaluation"], "tsne_embedding": [-7.62977409362793, -9.72353744506836], "cluster": 9}, {"key": "shi2019compositional", "year": "2019", "citations": "39", "title": "Compositional Embeddings Using Complementary Partitions For Memory-efficient Recommendation Systems", "abstract": "<p>Modern deep learning-based recommendation systems exploit hundreds to\nthousands of different categorical features, each with millions of different\ncategories ranging from clicks to posts. To respect the natural diversity\nwithin the categorical data, embeddings map each category to a unique dense\nrepresentation within an embedded space. Since each categorical feature could\ntake on as many as tens of millions of different possible categories, the\nembedding tables form the primary memory bottleneck during both training and\ninference. We propose a novel approach for reducing the embedding size in an\nend-to-end fashion by exploiting complementary partitions of the category set\nto produce a unique embedding vector for each category without explicit\ndefinition. By storing multiple smaller embedding tables based on each\ncomplementary partition and combining embeddings from each table, we define a\nunique embedding for each category at smaller memory cost. This approach may be\ninterpreted as using a specific fixed codebook to ensure uniqueness of each\ncategory\u2019s representation. Our experimental results demonstrate the\neffectiveness of our approach over the hashing trick for reducing the size of\nthe embedding tables in terms of model loss and accuracy, while retaining a\nsimilar reduction in the number of parameters.</p>\n", "tags": ["KDD", "Recommender Systems", "Hashing Methods", "Evaluation"], "tsne_embedding": [6.11313009262085, -3.96978759765625], "cluster": 4}, {"key": "shi2022information", "year": "2022", "citations": "11", "title": "Information-theoretic Hashing For Zero-shot Cross-modal Retrieval", "abstract": "<p>Zero-shot cross-modal retrieval (ZS-CMR) deals with the retrieval problem\namong heterogenous data from unseen classes. Typically, to guarantee\ngeneralization, the pre-defined class embeddings from natural language\nprocessing (NLP) models are used to build a common space. In this paper,\ninstead of using an extra NLP model to define a common space beforehand, we\nconsider a totally different way to construct (or learn) a common hamming space\nfrom an information-theoretic perspective. We term our model the\nInformation-Theoretic Hashing (ITH), which is composed of two cascading\nmodules: an Adaptive Information Aggregation (AIA) module; and a Semantic\nPreserving Encoding (SPE) module. Specifically, our AIA module takes the\ninspiration from the Principle of Relevant Information (PRI) to construct a\ncommon space that adaptively aggregates the intrinsic semantics of different\nmodalities of data and filters out redundant or irrelevant information. On the\nother hand, our SPE module further generates the hashing codes of different\nmodalities by preserving the similarity of intrinsic semantics with the\nelement-wise Kullback-Leibler (KL) divergence. A total correlation\nregularization term is also imposed to reduce the redundancy amongst different\ndimensions of hash codes. Sufficient experiments on three benchmark datasets\ndemonstrate the superiority of the proposed ITH in ZS-CMR. Source code is\navailable in the supplementary material.</p>\n", "tags": ["Multimodal Retrieval", "DATASETS", "Hashing Methods", "Evaluation"], "tsne_embedding": [-10.282207489013672, 6.261745929718018], "cluster": 8}, {"key": "shi2022learning", "year": "2022", "citations": "19", "title": "Learning Similarity Preserving Binary Codes For Recommender Systems", "abstract": "<p>Hashing-based Recommender Systems (RSs) are widely studied to provide\nscalable services. The existing methods for the systems combine three modules\nto achieve efficiency: feature extraction, interaction modeling, and\nbinarization. In this paper, we study an unexplored module combination for the\nhashing-based recommender systems, namely Compact Cross-Similarity Recommender\n(CCSR). Inspired by cross-modal retrieval, CCSR utilizes Maximum a Posteriori\nsimilarity instead of matrix factorization and rating reconstruction to model\ninteractions between users and items. We conducted experiments on MovieLens1M,\nAmazon product review, Ichiba purchase dataset and confirmed CCSR outperformed\nthe existing matrix factorization-based methods. On the Movielens1M dataset,\nthe absolute performance improvements are up to 15.69% in NDCG and 4.29% in\nRecall. In addition, we extensively studied three binarization modules: \\(sign\\),\nscaled tanh, and sign-scaled tanh. The result demonstrated that although\ndifferentiable scaled tanh is popular in recent discrete feature learning\nliterature, a huge performance drop occurs when outputs of scaled \\(tanh\\) are\nforced to be binary.</p>\n", "tags": ["Survey Paper", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Alt", "Recommender Systems", "Multimodal Retrieval", "Evaluation"], "tsne_embedding": [1.6579197645187378, 9.226813316345215], "cluster": 4}, {"key": "shohoud2023quranic", "year": "2023", "citations": "8", "title": "Quranic Conversations: Developing A Semantic Search Tool For The Quran Using Arabic NLP Techniques", "abstract": "<p>The Holy Book of Quran is believed to be the literal word of God (Allah) as\nrevealed to the Prophet Muhammad (PBUH) over a period of approximately 23\nyears. It is the book where God provides guidance on how to live a righteous\nand just life, emphasizing principles like honesty, compassion, charity and\njustice, as well as providing rules for personal conduct, family matters,\nbusiness ethics and much more. However, due to constraints related to the\nlanguage and the Quran organization, it is challenging for Muslims to get all\nrelevant ayahs (verses) pertaining to a matter or inquiry of interest. Hence,\nwe developed a Quran semantic search tool which finds the verses pertaining to\nthe user inquiry or prompt. To achieve this, we trained several models on a\nlarge dataset of over 30 tafsirs, where typically each tafsir corresponds to\none verse in the Quran and, using cosine similarity, obtained the tafsir tensor\nwhich is most similar to the prompt tensor of interest, which was then used to\nindex for the corresponding ayah in the Quran. Using the SNxLM model, we were\nable to achieve a cosine similarity score as high as 0.97 which corresponds to\nthe abdu tafsir for a verse relating to financial matters.</p>\n", "tags": ["DATASETS", "Distance Metric Learning"], "tsne_embedding": [-19.52096176147461, -10.696883201599121], "cluster": 1}, {"key": "shrivastava2016exact", "year": "2016", "citations": "7", "title": "Exact Weighted Minwise Hashing In Constant Time", "abstract": "<p>Weighted minwise hashing (WMH) is one of the fundamental subroutine, required\nby many celebrated approximation algorithms, commonly adopted in industrial\npractice for large scale-search and learning. The resource bottleneck of the\nalgorithms is the computation of multiple (typically a few hundreds to\nthousands) independent hashes of the data. The fastest hashing algorithm is by\nIoffe \\cite{Proc:Ioffe_ICDM10}, which requires one pass over the entire data\nvector, \\(O(d)\\) (\\(d\\) is the number of non-zeros), for computing one hash.\nHowever, the requirement of multiple hashes demands hundreds or thousands\npasses over the data. This is very costly for modern massive dataset.\n  In this work, we break this expensive barrier and show an expected constant\namortized time algorithm which computes \\(k\\) independent and unbiased WMH in\ntime \\(O(k)\\) instead of \\(O(dk)\\) required by Ioffe\u2019s method. Moreover, our\nproposal only needs a few bits (5 - 9 bits) of storage per hash value compared\nto around \\(64\\) bits required by the state-of-art-methodologies. Experimental\nevaluations, on real datasets, show that for computing 500 WMH, our proposal\ncan be 60000x faster than the Ioffe\u2019s method without losing any accuracy. Our\nmethod is also around 100x faster than approximate heuristics capitalizing on\nthe efficient \u201cdensified\u201d one permutation hashing schemes\n\\cite{Proc:OneHashLSH_ICML14}. Given the simplicity of our approach and its\nsignificant advantages, we hope that it will replace existing implementations\nin practice.</p>\n", "tags": ["ICML", "Locality Sensitive Hashing", "Hashing Methods", "DATASETS", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-5.862420082092285, -24.644025802612305], "cluster": 5}, {"key": "shrivastava2017optimal", "year": "2017", "citations": "27", "title": "Optimal Densification For Fast And Accurate Minwise Hashing", "abstract": "<p>Minwise hashing is a fundamental and one of the most successful hashing\nalgorithm in the literature. Recent advances based on the idea of\ndensification~\\cite{Proc:OneHashLSH_ICML14,Proc:Shrivastava_UAI14} have shown\nthat it is possible to compute \\(k\\) minwise hashes, of a vector with \\(d\\)\nnonzeros, in mere \\((d + k)\\) computations, a significant improvement over the\nclassical \\(O(dk)\\). These advances have led to an algorithmic improvement in the\nquery complexity of traditional indexing algorithms based on minwise hashing.\nUnfortunately, the variance of the current densification techniques is\nunnecessarily high, which leads to significantly poor accuracy compared to\nvanilla minwise hashing, especially when the data is sparse. In this paper, we\nprovide a novel densification scheme which relies on carefully tailored\n2-universal hashes. We show that the proposed scheme is variance-optimal, and\nwithout losing the runtime efficiency, it is significantly more accurate than\nexisting densification techniques. As a result, we obtain a significantly\nefficient hashing scheme which has the same variance and collision probability\nas minwise hashing. Experimental evaluations on real sparse and\nhigh-dimensional datasets validate our claims. We believe that given the\nsignificant advantages, our method will replace minwise hashing implementations\nin practice.</p>\n", "tags": ["ICML", "Locality Sensitive Hashing", "Hashing Methods", "DATASETS", "Efficiency And Optimization", "Evaluation"], "tsne_embedding": [-2.5104281902313232, -24.76947021484375], "cluster": 5}, {"key": "shrivastava2025asymmetric", "year": "2025", "citations": "268", "title": "Asymmetric LSH (ALSH) For Sublinear Time Maximum Inner Product Search (MIPS).", "abstract": "<p>We present the first provably sublinear time hashing algorithm for approximate\nMaximum Inner Product Search (MIPS). Searching with (un-normalized) inner\nproduct as the underlying similarity measure is a known difficult problem and\nfinding hashing schemes for MIPS was considered hard. While the existing Locality\nSensitive Hashing (LSH) framework is insufficient for solving MIPS, in this\npaper we extend the LSH framework to allow asymmetric hashing schemes. Our\nproposal is based on a key observation that the problem of finding maximum inner\nproducts, after independent asymmetric transformations, can be converted into\nthe problem of approximate near neighbor search in classical settings. This key\nobservation makes efficient sublinear hashing scheme for MIPS possible. Under\nthe extended asymmetric LSH (ALSH) framework, this paper provides an example\nof explicit construction of provably fast hashing scheme for MIPS. Our proposed\nalgorithm is simple and easy to implement. The proposed hashing scheme\nleads to significant computational savings over the two popular conventional LSH\nschemes: (i) Sign Random Projection (SRP) and (ii) hashing based on p-stable\ndistributions for L2 norm (L2LSH), in the collaborative filtering task of item recommendations\non Netflix and Movielens (10M) datasets.</p>\n", "tags": ["Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Recommender Systems", "Tools & Libraries"], "tsne_embedding": [15.089421272277832, -0.358590304851532], "cluster": 4}, {"key": "shrivastava2025densifying", "year": "2025", "citations": "86", "title": "Densifying One Permutation Hashing Via Rotation For Fast Near Neighbor Search", "abstract": "<p>The query complexity of locality sensitive hashing\n(LSH) based similarity search is dominated\nby the number of hash evaluations, and this number\ngrows with the data size (Indyk &amp; Motwani,\n1998). In industrial applications such as search\nwhere the data are often high-dimensional and\nbinary (e.g., text n-grams), minwise hashing is\nwidely adopted, which requires applying a large\nnumber of permutations on the data. This is\ncostly in computation and energy-consumption.\nIn this paper, we propose a hashing technique\nwhich generates all the necessary hash evaluations\nneeded for similarity search, using one\nsingle permutation. The heart of the proposed\nhash function is a \u201crotation\u201d scheme which densifies\nthe sparse sketches of one permutation\nhashing (Li et al., 2012) in an unbiased fashion\nthereby maintaining the LSH property. This\nmakes the obtained sketches suitable for hash table\nconstruction. This idea of rotation presented\nin this paper could be of independent interest for\ndensifying other types of sparse sketches.\nUsing our proposed hashing method, the query\ntime of a (K, L)-parameterized LSH is reduced\nfrom the typical O(dKL) complexity to merely\nO(KL + dL), where d is the number of nonzeros\nof the data vector, K is the number of hashes\nin each hash table, and L is the number of hash\ntables. Our experimental evaluation on real data\nconfirms that the proposed scheme significantly\nreduces the query processing time over minwise\nhashing without loss in retrieval accuracies.</p>\n", "tags": ["Locality Sensitive Hashing", "Similarity Search", "Hashing Methods", "Evaluation"], "tsne_embedding": [9.32386589050293, -0.7823489308357239], "cluster": 4}, {"key": "shu2017compressing", "year": "2017", "citations": "95", "title": "Compressing Word Embeddings Via Deep Compositional Code Learning", "abstract": "<p>Natural language processing (NLP) models often require a massive number of\nparameters for word embeddings, resulting in a large storage or memory\nfootprint. Deploying neural NLP models to mobile devices requires compressing\nthe word embeddings without any significant sacrifices in performance. For this\npurpose, we propose to construct the embeddings with few basis vectors. For\neach word, the composition of basis vectors is determined by a hash code. To\nmaximize the compression rate, we adopt the multi-codebook quantization\napproach instead of binary coding scheme. Each code is composed of multiple\ndiscrete numbers, such as (3, 2, 1, 8), where the value of each component is\nlimited to a fixed range. We propose to directly learn the discrete codes in an\nend-to-end neural network by applying the Gumbel-softmax trick. Experiments\nshow the compression rate achieves 98% in a sentiment analysis task and 94% ~\n99% in machine translation tasks without performance loss. In both tasks, the\nproposed method can improve the model performance by slightly lowering the\ncompression rate. Compared to other approaches such as character-level\nsegmentation, the proposed method is language-independent and does not require\nmodifications to the network architecture.</p>\n", "tags": ["Quantization", "Hashing Methods", "Evaluation"], "tsne_embedding": [-11.37125015258789, -17.392822265625], "cluster": 1}, {"key": "sicre2017unsupervised", "year": "2017", "citations": "16", "title": "Unsupervised Part Learning For Visual Recognition", "abstract": "<p>Part-based image classification aims at representing categories by small sets\nof learned discriminative parts, upon which an image representation is built.\nConsidered as a promising avenue a decade ago, this direction has been\nneglected since the advent of deep neural networks. In this context, this paper\nbrings two contributions: first, it shows that despite the recent success of\nend-to-end holistic models, explicit part learning can boosts classification\nperformance. Second, this work proceeds one step further than recent part-based\nmodels (PBM), focusing on how to learn parts without using any labeled data.\nInstead of learning a set of parts per class, as generally done in the PBM\nliterature, the proposed approach both constructs a partition of a given set of\nimages into visually similar groups, and subsequently learn a set of\ndiscriminative parts per group in a fully unsupervised fashion. This strategy\nopens the door to the use of PBM in new applications for which the notion of\nimage categories is irrelevant, such as instance-based image retrieval, for\nexample. We experimentally show that our learned parts can help building\nefficient image representations, for classification as well as for indexing\ntasks, resulting in performance superior to holistic state-of-the art Deep\nConvolutional Neural Networks (DCNN) encoding.</p>\n", "tags": ["CVPR", "Image Retrieval", "Evaluation"], "tsne_embedding": [-24.63088607788086, 1.2684999704360962], "cluster": 3}, {"key": "silavong2025deskew", "year": "2025", "citations": "16", "title": "Deskew-lsh Based Code-to-code Recommendation Engine", "abstract": "<p>Machine learning on source code (MLOnCode) is a popular research field that has been driven by the availability of large-scale code repositories and the development of powerful probabilistic and deep learning models for mining source code. Code-to-code recommendation is a task in MLOnCode that aims to recommend relevant, diverse and concise code snippets that usefully extend the code currently being written by a developer in their development environment (IDE). Code-to-code recommendation engines hold the promise of increasing developer productivity by reducing context switching from the IDE and increasing code-reuse. Existing code-to-code recommendation engines do not scale gracefully to large codebases, exhibiting a linear growth in query time as the code repository increases in size. In addition, existing code-to-code recommendation engines fail to account for the global statistics of code repositories in the ranking function, such as the distribution of code snippet lengths, leading to sub-optimal retrieval results. We address both of these weaknesses with <em>Senatus</em>, a new code-to-code recommendation engine. At the core of Senatus is <em>De-Skew</em> LSH a new locality sensitive hashing (LSH) algorithm that indexes the data for fast (sub-linear time) retrieval while also counteracting the skewness in the snippet length distribution using novel abstract syntax tree-based feature scoring and selection algorithms. We evaluate Senatus via automatic evaluation and with an expert developer user study and find the recommendations to be of higher quality than competing baselines, while achieving faster search. For example, on the CodeSearchNet dataset we show that Senatus improves performance by 6.7% F1 and query time 16x is faster compared to Facebook Aroma on the task of code-to-code recommendation.</p>\n", "tags": ["Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Recommender Systems", "Tree Based ANN", "Evaluation"], "tsne_embedding": [-13.020054817199707, -10.418266296386719], "cluster": 1}, {"key": "singh2020ihashnet", "year": "2020", "citations": "5", "title": "Ihashnet: Iris Hashing Network Based On Efficient Multi-index Hashing", "abstract": "<p>Massive biometric deployments are pervasive in today\u2019s world. But despite the\nhigh accuracy of biometric systems, their computational efficiency degrades\ndrastically with an increase in the database size. Thus, it is essential to\nindex them. An ideal indexing scheme needs to generate codes that preserve the\nintra-subject similarity as well as inter-subject dissimilarity. Here, in this\npaper, we propose an iris indexing scheme using real-valued deep iris features\nbinarized to iris bar codes (IBC) compatible with the indexing structure.\nFirstly, for extracting robust iris features, we have designed a network\nutilizing the domain knowledge of ordinal filtering and learning their\nnonlinear combinations. Later these real-valued features are binarized.\nFinally, for indexing the iris dataset, we have proposed a loss that can\ntransform the binary feature into an improved feature compatible with the\nMulti-Index Hashing scheme. This loss function ensures the hamming distance\nequally distributed among all the contiguous disjoint sub-strings. To the best\nof our knowledge, this is the first work in the iris indexing domain that\npresents an end-to-end iris indexing structure. Experimental results on four\ndatasets are presented to depict the efficacy of the proposed approach.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "Neural Hashing", "Vector Indexing"], "tsne_embedding": [-5.713005065917969, 2.655843734741211], "cluster": 8}, {"key": "singh2021freshdiskann", "year": "2021", "citations": "10", "title": "Freshdiskann: A Fast And Accurate Graph-based ANN Index For Streaming Similarity Search", "abstract": "<p>Approximate nearest neighbor search (ANNS) is a fundamental building block in\ninformation retrieval with graph-based indices being the current\nstate-of-the-art and widely used in the industry. Recent advances in\ngraph-based indices have made it possible to index and search billion-point\ndatasets with high recall and millisecond-level latency on a single commodity\nmachine with an SSD.\n  However, existing graph algorithms for ANNS support only static indices that\ncannot reflect real-time changes to the corpus required by many key real-world\nscenarios (e.g. index of sentences in documents, email, or a news index). To\novercome this drawback, the current industry practice for manifesting updates\ninto such indices is to periodically re-build these indices, which can be\nprohibitively expensive.\n  In this paper, we present the first graph-based ANNS index that reflects\ncorpus updates into the index in real-time without compromising on search\nperformance. Using update rules for this index, we design FreshDiskANN, a\nsystem that can index over a billion points on a workstation with an SSD and\nlimited memory, and support thousands of concurrent real-time inserts, deletes\nand searches per second each, while retaining \\(&gt;95%\\) 5-recall@5. This\nrepresents a 5-10x reduction in the cost of maintaining freshness in indices\nwhen compared to existing methods.</p>\n", "tags": ["DATASETS", "Graph Based ANN", "Efficiency And Optimization", "Similarity Search", "Vector Indexing", "Evaluation"], "tsne_embedding": [15.410799026489258, 19.490692138671875], "cluster": 0}, {"key": "singhi2025provenance", "year": "2025", "citations": "35", "title": "Provenance Detection For Ai-generated Images: Combining Perceptual Hashing, Homomorphic Encryption, And AI Detection Models", "abstract": "<p>As AI-generated sensitive images become more prevalent, identifying their\nsource is crucial for distinguishing them from real images. Conventional image\nwatermarking methods are vulnerable to common transformations like filters,\nlossy compression, and screenshots, often applied during social media sharing.\nWatermarks can also be faked or removed if models are open-sourced or leaked\nsince images can be rewatermarked. We have developed a three-part framework for\nsecure, transformation-resilient AI content provenance detection, to address\nthese limitations. We develop an adversarially robust state-of-the-art\nperceptual hashing model, DinoHash, derived from DINOV2, which is robust to\ncommon transformations like filters, compression, and crops. Additionally, we\nintegrate a Multi-Party Fully Homomorphic Encryption~(MP-FHE) scheme into our\nproposed framework to ensure the protection of both user queries and registry\nprivacy. Furthermore, we improve previous work on AI-generated media detection.\nThis approach is useful in cases where the content is absent from our registry.\nDinoHash significantly improves average bit accuracy by 12% over\nstate-of-the-art watermarking and perceptual hashing methods while maintaining\nsuperior true positive rate (TPR) and false positive rate (FPR) tradeoffs\nacross various transformations. Our AI-generated media detection results show a\n25% improvement in classification accuracy on commonly used real-world AI image\ngenerators over existing algorithms. By combining perceptual hashing, MP-FHE,\nand an AI content detection model, our proposed framework provides better\nrobustness and privacy compared to previous work.</p>\n", "tags": ["ICCV", "Tools & Libraries", "Hashing Methods", "Robustness"], "tsne_embedding": [-13.737275123596191, 11.886247634887695], "cluster": 3}, {"key": "sinha2020neural", "year": "2020", "citations": "5", "title": "Neural Neighborhood Encoding For Classification", "abstract": "<p>Inspired by the fruit-fly olfactory circuit, the Fly Bloom Filter [Dasgupta\net al., 2018] is able to efficiently summarize the data with a single pass and\nhas been used for novelty detection. We propose a new classifier (for binary\nand multi-class classification) that effectively encodes the different local\nneighborhoods for each class with a per-class Fly Bloom Filter. The inference\non test data requires an efficient {\\tt FlyHash} [Dasgupta, et al., 2017]\noperation followed by a high-dimensional, but {\\em sparse}, dot product with\nthe per-class Bloom Filters. The learning is trivially parallelizable. On the\ntheoretical side, we establish conditions under which the prediction of our\nproposed classifier on any test example agrees with the prediction of the\nnearest neighbor classifier with high probability. We extensively evaluate our\nproposed scheme with over \\(50\\) data sets of varied data dimensionality to\ndemonstrate that the predictive performance of our proposed neuroscience\ninspired classifier is competitive the the nearest-neighbor classifiers and\nother single-pass classifiers.</p>\n", "tags": ["KDD", "Evaluation"], "tsne_embedding": [22.36942481994629, -10.872320175170898], "cluster": 2}, {"key": "sivertsen2017fast", "year": "2017", "citations": "62", "title": "Fast Nearest Neighbor Preserving Embeddings", "abstract": "<p>We show an analog to the Fast Johnson-Lindenstrauss Transform for Nearest\nNeighbor Preserving Embeddings in \\(\u2113\u2082\\). These are sparse, randomized\nembeddings that preserve the (approximate) nearest neighbors. The\ndimensionality of the embedding space is bounded not by the size of the\nembedded set n, but by its doubling dimension {\\lambda}. For most large\nreal-world datasets this will mean a considerably lower-dimensional embedding\nspace than possible when preserving all distances. The resulting embeddings can\nbe used with existing approximate nearest neighbor data structures to yield\nspeed improvements.</p>\n", "tags": ["DATASETS"], "tsne_embedding": [21.885093688964844, -1.7668052911758423], "cluster": 7}, {"key": "sivertsen2019similarity", "year": "2019", "citations": "7", "title": "Similarity Problems In High Dimensions", "abstract": "<p>The main contribution of this dissertation is the introduction of new or\nimproved approximation algorithms and data structures for several similarity\nsearch problems. We examine the furthest neighbor query, the annulus query,\ndistance sensitive membership, nearest neighbor preserving embeddings and set\nsimilarity queries in the large-scale, high-dimensional setting.</p>\n", "tags": ["AAAI"], "tsne_embedding": [8.641156196594238, 5.394769668579102], "cluster": 4}, {"key": "son2025fed", "year": "2025", "citations": "12", "title": "FED: Fast And Efficient Dataset Deduplication Framework With GPU Acceleration", "abstract": "<p>Dataset deduplication plays a crucial role in enhancing data quality,\nultimately improving the training performance and efficiency of large language\nmodels. A commonly used method for data deduplication is the MinHash LSH\nalgorithm. Recently, NVIDIA introduced a GPU-based MinHash LSH deduplication\nmethod, but it remains suboptimal, leaving room for further improvement in\nprocessing efficiency. This paper proposes a GPU-accelerated deduplication\nframework, FED, that optimizes MinHash LSH for GPU clusters and leverages\ncomputationally efficient, partially reusable non-cryptographic hash functions.\nFED significantly outperforms the CPU-based deduplication tool in SlimPajama\n(using 64 logical CPU cores) by up to 107.2 times and the GPU-based tool in\nNVIDIA NeMo Curator by up to 6.3 times when processing 30 million documents on\na node with four GPUs. Notably, our method dramatically accelerates the\npreviously time-consuming MinHash signature generation phase, achieving\nspeed-ups of up to 260 compared to the CPU baseline. Despite these gains in\nefficiency, FED maintains high deduplication quality, with the duplicate\ndocument sets reaching a Jaccard similarity of over 0.96 compared to those\nidentified by the standard MinHash algorithm. In large-scale experiments, the\ndeduplication of 1.2 trillion tokens is completed in just 6 hours in a\nfour-node, 16-GPU environment. The related code is publicly available on GitHub\n(\\href{https://github.com/mcrl/FED}{https://github.com/mcrl/FED}).</p>\n", "tags": ["Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-8.604190826416016, -21.1097469329834], "cluster": 5}, {"key": "song2015deep", "year": "2015", "citations": "1648", "title": "Deep Metric Learning Via Lifted Structured Feature Embedding", "abstract": "<p>Learning the distance metric between pairs of examples is of great importance\nfor learning and visual recognition. With the remarkable success from the state\nof the art convolutional neural networks, recent works have shown promising\nresults on discriminatively training the networks to learn semantic feature\nembeddings where similar examples are mapped close to each other and dissimilar\nexamples are mapped farther apart. In this paper, we describe an algorithm for\ntaking full advantage of the training batches in the neural network training by\nlifting the vector of pairwise distances within the batch to the matrix of\npairwise distances. This step enables the algorithm to learn the state of the\nart feature embedding by optimizing a novel structured prediction objective on\nthe lifted problem. Additionally, we collected Online Products dataset: 120k\nimages of 23k classes of online products for metric learning. Our experiments\non the CUB-200-2011, CARS196, and Online Products datasets demonstrate\nsignificant improvement over existing deep feature embedding methods on all\nexperimented embedding sizes with the GoogLeNet network.</p>\n", "tags": ["CVPR", "DATASETS", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [-22.227190017700195, 6.852035045623779], "cluster": 3}, {"key": "song2016deep", "year": "2016", "citations": "308", "title": "Deep Metric Learning Via Facility Location", "abstract": "<p>Learning the representation and the similarity metric in an end-to-end\nfashion with deep networks have demonstrated outstanding results for clustering\nand retrieval. However, these recent approaches still suffer from the\nperformance degradation stemming from the local metric training procedure which\nis unaware of the global structure of the embedding space.\n  We propose a global metric learning scheme for optimizing the deep metric\nembedding with the learnable clustering function and the clustering metric\n(NMI) in a novel structured prediction framework.\n  Our experiments on CUB200-2011, Cars196, and Stanford online products\ndatasets show state of the art performance both on the clustering and retrieval\ntasks measured in the NMI and Recall@K evaluation metrics.</p>\n", "tags": ["DATASETS", "Distance Metric Learning", "CVPR", "Tools & Libraries", "Evaluation"], "tsne_embedding": [14.886720657348633, -8.487196922302246], "cluster": 2}, {"key": "song2017binary", "year": "2017", "citations": "164", "title": "Binary Generative Adversarial Networks For Image Retrieval", "abstract": "<p>The most striking successes in image retrieval using deep hashing have mostly\ninvolved discriminative models, which require labels. In this paper, we use\nbinary generative adversarial networks (BGAN) to embed images to binary codes\nin an unsupervised way. By restricting the input noise variable of generative\nadversarial networks (GAN) to be binary and conditioned on the features of each\ninput image, BGAN can simultaneously learn a binary representation per image,\nand generate an image plausibly similar to the original one. In the proposed\nframework, we address two main problems: 1) how to directly generate binary\ncodes without relaxation? 2) how to equip the binary representation with the\nability of accurate image retrieval? We resolve these problems by proposing new\nsign-activation strategy and a loss function steering the learning process,\nwhich consists of new models for adversarial loss, a content loss, and a\nneighborhood structure loss. Experimental results on standard datasets\n(CIFAR-10, NUSWIDE, and Flickr) demonstrate that our BGAN significantly\noutperforms existing hashing methods by up to 107% in terms of~mAP (See Table\ntab.res.map.comp) Our anonymous code is available at:\nhttps://github.com/htconquer/BGAN.</p>\n", "tags": ["Image Retrieval", "AAAI", "DATASETS", "Hashing Methods", "Compact Codes", "Neural Hashing", "Tools & Libraries", "Evaluation", "Robustness"], "tsne_embedding": [-6.640341281890869, 8.245575904846191], "cluster": 8}, {"key": "song2017deep", "year": "2017", "citations": "11", "title": "Deep Discrete Hashing With Self-supervised Pairwise Labels", "abstract": "<p>Hashing methods have been widely used for applications of large-scale image\nretrieval and classification. Non-deep hashing methods using handcrafted\nfeatures have been significantly outperformed by deep hashing methods due to\ntheir better feature representation and end-to-end learning framework. However,\nthe most striking successes in deep hashing have mostly involved discriminative\nmodels, which require labels. In this paper, we propose a novel unsupervised\ndeep hashing method, named Deep Discrete Hashing (DDH), for large-scale image\nretrieval and classification. In the proposed framework, we address two main\nproblems: 1) how to directly learn discrete binary codes? 2) how to equip the\nbinary representation with the ability of accurate image retrieval and\nclassification in an unsupervised way? We resolve these problems by introducing\nan intermediate variable and a loss function steering the learning process,\nwhich is based on the neighborhood structure in the original space.\nExperimental results on standard datasets (CIFAR-10, NUS-WIDE, and Oxford-17)\ndemonstrate that our DDH significantly outperforms existing hashing methods by\nlarge margin in terms of~mAP for image retrieval and object recognition. Code\nis available at https://github.com/htconquer/ddh.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Compact Codes", "Neural Hashing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-6.783685207366943, 8.310686111450195], "cluster": 8}, {"key": "song2018self", "year": "2018", "citations": "165", "title": "Self-supervised Video Hashing With Hierarchical Binary Auto-encoder", "abstract": "<p>Existing video hash functions are built on three isolated stages: frame\npooling, relaxed learning, and binarization, which have not adequately explored\nthe temporal order of video frames in a joint binary optimization model,\nresulting in severe information loss. In this paper, we propose a novel\nunsupervised video hashing framework dubbed Self-Supervised Video Hashing\n(SSVH), that is able to capture the temporal nature of videos in an end-to-end\nlearning-to-hash fashion. We specifically address two central problems: 1) how\nto design an encoder-decoder architecture to generate binary codes for videos;\nand 2) how to equip the binary codes with the ability of accurate video\nretrieval. We design a hierarchical binary autoencoder to model the temporal\ndependencies in videos with multiple granularities, and embed the videos into\nbinary codes with less computations than the stacked architecture. Then, we\nencourage the binary codes to simultaneously reconstruct the visual content and\nneighborhood structure of the videos. Experiments on two real-world datasets\n(FCVID and YFCC) show that our SSVH method can significantly outperform the\nstate-of-the-art methods and achieve the currently best performance on the task\nof unsupervised video retrieval.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Compact Codes", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-7.40697717666626, 17.301830291748047], "cluster": 6}, {"key": "song2019deep", "year": "2019", "citations": "59", "title": "Deep Hashing Learning For Visual And Semantic Retrieval Of Remote Sensing Images", "abstract": "<p>Driven by the urgent demand for managing remote sensing big data, large-scale\nremote sensing image retrieval (RSIR) attracts increasing attention in the\nremote sensing field. In general, existing retrieval methods can be regarded as\nvisual-based retrieval approaches which search and return a set of similar\nimages from a database to a given query image. Although retrieval methods have\nachieved great success, there is still a question that needs to be responded\nto: Can we obtain the accurate semantic labels of the returned similar images\nto further help analyzing and processing imagery? Inspired by the above\nquestion, in this paper, we redefine the image retrieval problem as visual and\nsemantic retrieval of images. Specifically, we propose a novel deep hashing\nconvolutional neural network (DHCNN) to simultaneously retrieve the similar\nimages and classify their semantic labels in a unified framework. In more\ndetail, a convolutional neural network (CNN) is used to extract\nhigh-dimensional deep features. Then, a hash layer is perfectly inserted into\nthe network to transfer the deep features into compact hash codes. In addition,\na fully connected layer with a softmax function is performed on hash layer to\ngenerate class distribution. Finally, a loss function is elaborately designed\nto simultaneously consider the label loss of each image and similarity loss of\npairs of images. Experimental results on two remote sensing datasets\ndemonstrate that the proposed method achieves the state-of-art retrieval and\nclassification performance.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Alt", "Neural Hashing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-12.397756576538086, 0.00848009530454874], "cluster": 8}, {"key": "song2020deep", "year": "2020", "citations": "21", "title": "Deep Robust Multilevel Semantic Cross-modal Hashing", "abstract": "<p>Hashing based cross-modal retrieval has recently made significant progress.\nBut straightforward embedding data from different modalities into a joint\nHamming space will inevitably produce false codes due to the intrinsic modality\ndiscrepancy and noises. We present a novel Robust Multilevel Semantic Hashing\n(RMSH) for more accurate cross-modal retrieval. It seeks to preserve\nfine-grained similarity among data with rich semantics, while explicitly\nrequire distances between dissimilar points to be larger than a specific value\nfor strong robustness. For this, we give an effective bound of this value based\non the information coding-theoretic analysis, and the above goals are embodied\ninto a margin-adaptive triplet loss. Furthermore, we introduce pseudo-codes via\nfusing multiple hash codes to explore seldom-seen semantics, alleviating the\nsparsity problem of similarity information. Experiments on three benchmarks\nshow the validity of the derived bounds, and our method achieves\nstate-of-the-art performance.</p>\n", "tags": ["Hashing Methods", "Distance Metric Learning", "CVPR", "Text Retrieval", "Multimodal Retrieval", "Evaluation", "Robustness"], "tsne_embedding": [-0.9125478267669678, 0.722066342830658], "cluster": 8}, {"key": "song2022asymmetric", "year": "2022", "citations": "44", "title": "Asymmetric Hash Code Learning For Remote Sensing Image Retrieval", "abstract": "<p>Remote sensing image retrieval (RSIR), aiming at searching for a set of\nsimilar items to a given query image, is a very important task in remote\nsensing applications. Deep hashing learning as the current mainstream method\nhas achieved satisfactory retrieval performance. On one hand, various deep\nneural networks are used to extract semantic features of remote sensing images.\nOn the other hand, the hashing techniques are subsequently adopted to map the\nhigh-dimensional deep features to the low-dimensional binary codes. This kind\nof methods attempts to learn one hash function for both the query and database\nsamples in a symmetric way. However, with the number of database samples\nincreasing, it is typically time-consuming to generate the hash codes of\nlarge-scale database images. In this paper, we propose a novel deep hashing\nmethod, named asymmetric hash code learning (AHCL), for RSIR. The proposed AHCL\ngenerates the hash codes of query and database images in an asymmetric way. In\nmore detail, the hash codes of query images are obtained by binarizing the\noutput of the network, while the hash codes of database images are directly\nlearned by solving the designed objective function. In addition, we combine the\nsemantic information of each image and the similarity information of pairs of\nimages as supervised information to train a deep hashing network, which\nimproves the representation ability of deep features and hash codes. The\nexperimental results on three public datasets demonstrate that the proposed\nmethod outperforms symmetric methods in terms of retrieval accuracy and\nefficiency. The source code is available at\nhttps://github.com/weiweisong415/Demo AHCL for TGRS2022.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Neural Hashing", "Evaluation"], "tsne_embedding": [-12.366752624511719, -0.3572792708873749], "cluster": 8}, {"key": "song2025inter", "year": "2025", "citations": "619", "title": "Inter-media Hashing For Large-scale Retrieval From Heterogeneous Data Sources", "abstract": "<p>In this paper, we present a new multimedia retrieval paradigm to innovate large-scale search of heterogenous multimedia data. It is able to return results of different media types from heterogeneous data sources, e.g., using a query image to retrieve relevant text documents or images from different data sources. This utilizes the widely available data from different sources and caters for the current users\u2019 demand of receiving a result list simultaneously containing multiple types of data to obtain a comprehensive understanding of the query\u2019s results. To enable large-scale inter-media retrieval, we propose a novel inter-media hashing (IMH) model to explore the correlations among multiple media types from different data sources and tackle the scalability issue. To this end, multimedia data from heterogeneous data sources are transformed into a common Hamming space, in which fast search can be easily implemented by XOR and bit-count operations. Furthermore, we integrate a linear regression model to learn hashing functions so that the hash codes for new data points can be efficiently generated. Experiments conducted on real-world large-scale multimedia datasets demonstrate the superiority of our proposed method compared with state-of-the-art techniques.</p>\n", "tags": ["Large Scale Search", "DATASETS", "Hashing Methods"], "tsne_embedding": [-3.3307344913482666, 15.99903678894043], "cluster": 6}, {"key": "song2025top", "year": "2025", "citations": "76", "title": "Top Rank Supervised Binary Coding For Visual Search", "abstract": "<p>In recent years, binary coding techniques are becoming\nincreasingly popular because of their high efficiency in handling large-scale computer vision applications. It has been\ndemonstrated that supervised binary coding techniques that\nleverage supervised information can significantly enhance\nthe coding quality, and hence greatly benefit visual search\ntasks. Typically, a modern binary coding method seeks\nto learn a group of coding functions which compress data\nsamples into binary codes. However, few methods pursued\nthe coding functions such that the precision at the top of\na ranking list according to Hamming distances of the generated binary codes is optimized.\nIn this paper, we propose a novel supervised binary coding approach, namely\nTop Rank Supervised Binary Coding (Top-RSBC), which\nexplicitly focuses on optimizing the precision of top positions in a Hamming-distance ranking list towards preserving the supervision information. The core idea is to train\nthe disciplined coding functions, by which the mistakes at\nthe top of a Hamming-distance ranking list are penalized\nmore than those at the bottom. To solve such coding functions, we relax the original discrete optimization objective\nwith a continuous surrogate, and derive a stochastic gradient descent to optimize the surrogate objective. To further reduce the training time cost, we also design an online\nlearning algorithm to optimize the surrogate objective more\nefficiently. Empirical studies based upon three benchmark\nimage datasets demonstrate that the proposed binary coding approach achieves superior image search accuracy over\nthe state-of-the-arts.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Efficiency And Optimization", "Compact Codes", "ICCV", "Evaluation"], "tsne_embedding": [-8.730611801147461, -9.337529182434082], "cluster": 9}, {"key": "sonthalia2025rankability", "year": "2025", "citations": "22", "title": "On The Rankability Of Visual Embeddings", "abstract": "<p>We study whether visual embedding models capture continuous, ordinal attributes along linear directions, which we term <em>rank axes</em>. We define a model as <em>rankable</em> for an attribute if projecting embeddings onto such an axis preserves the attribute\u2019s order. Across 7 popular encoders and 9 datasets with attributes like age, crowd count, head pose, aesthetics, and recency, we find that many embeddings are inherently rankable. Surprisingly, a small number of samples, or even just two extreme examples, often suffice to recover meaningful rank axes, without full-scale supervision. These findings open up new use cases for image ranking in vector databases and motivate further study into the structure and learning of rankable embeddings. Our code is available at https://github.com/aktsonthalia/rankable-vision-embeddings.</p>\n", "tags": ["DATASETS"], "tsne_embedding": [-12.067694664001465, 9.122427940368652], "cluster": 8}, {"key": "spaldingjamieson2025scalable", "year": "2025", "citations": "6", "title": "Scalable K-means Clustering For Large K Via Seeded Approximate Nearest-neighbor Search", "abstract": "<p>For very large values of \\(k\\), we consider methods for fast \\(k\\)-means\nclustering of massive datasets with \\(10^7\\sim10^9\\) points in high-dimensions\n(\\(d\\geq100\\)). All current practical methods for this problem have runtimes at\nleast \\(\u03a9(k^2)\\). We find that initialization routines are not a bottleneck\nfor this case. Instead, it is critical to improve the speed of Lloyd\u2019s\nlocal-search algorithm, particularly the step that reassigns points to their\nclosest center. Attempting to improve this step naturally leads us to leverage\napproximate nearest-neighbor search methods, although this alone is not enough\nto be practical. Instead, we propose a family of problems we call \u201cSeeded\nApproximate Nearest-Neighbor Search\u201d, for which we propose \u201cSeeded\nSearch-Graph\u201d methods as a solution.</p>\n", "tags": ["Alt", "DATASETS"], "tsne_embedding": [16.328554153442383, -2.9755983352661133], "cluster": 2}, {"key": "spencer2016noisy", "year": "2016", "citations": "104", "title": "Noisy 1-bit Compressed Sensing Embeddings Enjoy A Restricted Isometry Property", "abstract": "<p>We investigate the sign-linear embeddings of 1-bit compressed sensing given\nby Gaussian measurements. One can give short arguments concerning a Restricted\nIsometry Property of such maps using Vapnik-Chervonenkis dimension of sparse\nhemispheres. This approach has a natural extension to the presence of additive\nwhite noise prior to quantization. Noisy one-bit mappings are shown to satisfy\nan RIP when the metric on the sphere is given by the noise.</p>\n", "tags": ["Survey Paper", "Quantization", "Evaluation"], "tsne_embedding": [25.503000259399414, -8.436287879943848], "cluster": 7}, {"key": "spring2016scalable", "year": "2016", "citations": "108", "title": "Scalable And Sustainable Deep Learning Via Randomized Hashing", "abstract": "<p>Current deep learning architectures are growing larger in order to learn from\ncomplex datasets. These architectures require giant matrix multiplication\noperations to train millions of parameters. Conversely, there is another\ngrowing trend to bring deep learning to low-power, embedded devices. The matrix\noperations, associated with both training and testing of deep networks, are\nvery expensive from a computational and energy standpoint. We present a novel\nhashing based technique to drastically reduce the amount of computation needed\nto train and test deep networks. Our approach combines recent ideas from\nadaptive dropouts and randomized hashing for maximum inner product search to\nselect the nodes with the highest activation efficiently. Our new algorithm for\ndeep learning reduces the overall computational cost of forward and\nback-propagation by operating on significantly fewer (sparse) nodes. As a\nconsequence, our algorithm uses only 5% of the total multiplications, while\nkeeping on average within 1% of the accuracy of the original model. A unique\nproperty of the proposed hashing based back-propagation is that the updates are\nalways sparse. Due to the sparse gradient updates, our algorithm is ideally\nsuited for asynchronous and parallel training leading to near linear speedup\nwith increasing number of cores. We demonstrate the scalability and\nsustainability (energy efficiency) of our proposed algorithm via rigorous\nexperimental evaluations on several real datasets.</p>\n", "tags": ["KDD", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Evaluation"], "tsne_embedding": [2.2799370288848877, -9.589615821838379], "cluster": 9}, {"key": "srijith2016sub", "year": "2016", "citations": "59", "title": "Sub-story Detection In Twitter With Hierarchical Dirichlet Processes", "abstract": "<p>Social media has now become the de facto information source on real world\nevents. The challenge, however, due to the high volume and velocity nature of\nsocial media streams, is in how to follow all posts pertaining to a given event\nover time, a task referred to as story detection. Moreover, there are often\nseveral different stories pertaining to a given event, which we refer to as\nsub-stories and the corresponding task of their automatic detection as\nsub-story detection. This paper proposes hierarchical Dirichlet processes\n(HDP), a probabilistic topic model, as an effective method for automatic\nsub-story detection. HDP can learn sub-topics associated with sub-stories which\nenables it to handle subtle variations in sub-stories. It is compared with\nstate- of-the-art story detection approaches based on locality sensitive\nhashing and spectral clustering. We demonstrate the superior performance of HDP\nfor sub-story detection on real world Twitter data sets using various\nevaluation measures. The ability of HDP to learn sub-topics helps it to recall\nthe sub- stories with high precision. Another contribution of this paper is in\ndemonstrating that the conversational structures within the Twitter stream can\nbe used to improve sub-story detection performance significantly.</p>\n", "tags": ["Hashing Methods", "Evaluation"], "tsne_embedding": [-20.175745010375977, -18.193336486816406], "cluster": 1}, {"key": "srinivas2018merging", "year": "2018", "citations": "7", "title": "Merging Datasets Through Deep Learning", "abstract": "<p>Merging datasets is a key operation for data analytics. A frequent\nrequirement for merging is joining across columns that have different surface\nforms for the same entity (e.g., the name of a person might be represented as\n\u201cDouglas Adams\u201d or \u201cAdams, Douglas\u201d). Similarly, ontology alignment can require\nrecognizing distinct surface forms of the same entity, especially when\nontologies are independently developed. However, data management systems are\ncurrently limited to performing merges based on string equality, or at best\nusing string similarity. We propose an approach to performing merges based on\ndeep learning models. Our approach depends on (a) creating a deep learning\nmodel that maps surface forms of an entity into a set of vectors such that\nalternate forms for the same entity are closest in vector space, (b) indexing\nthese vectors using a nearest neighbors algorithm to find the forms that can be\npotentially joined together. To build these models, we had to adapt techniques\nfrom metric learning due to the characteristics of the data; specifically we\ndescribe novel sample selection techniques and loss functions that work for\nthis problem. To evaluate our approach, we used Wikidata as ground truth and\nbuilt models from datasets with approximately 1.1M people\u2019s names (200K\nidentities) and 130K company names (70K identities). We developed models that\nallow for joins with precision@1 of .75-.81 and recall of .74-.81. We make the\nmodels available for aligning people or companies across multiple datasets.</p>\n", "tags": ["Alt", "DATASETS", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [6.609185218811035, 1.918368935585022], "cluster": 4}, {"key": "sriperumbudur2007metric", "year": "2007", "citations": "8", "title": "Metric Embedding For Nearest Neighbor Classification", "abstract": "<p>The distance metric plays an important role in nearest neighbor (NN)\nclassification. Usually the Euclidean distance metric is assumed or a\nMahalanobis distance metric is optimized to improve the NN performance. In this\npaper, we study the problem of embedding arbitrary metric spaces into a\nEuclidean space with the goal to improve the accuracy of the NN classifier. We\npropose a solution by appealing to the framework of regularization in a\nreproducing kernel Hilbert space and prove a representer-like theorem for NN\nclassification. The embedding function is then determined by solving a\nsemidefinite program which has an interesting connection to the soft-margin\nlinear binary support vector machine classifier. Although the main focus of\nthis paper is to present a general, theoretical framework for metric embedding\nin a NN setting, we demonstrate the performance of the proposed method on some\nbenchmark datasets and show that it performs better than the Mahalanobis metric\nlearning algorithm in terms of leave-one-out and generalization errors.</p>\n", "tags": ["DATASETS", "Distance Metric Learning", "CVPR", "Alt", "Tools & Libraries", "Evaluation"], "tsne_embedding": [23.765653610229492, 1.2109421491622925], "cluster": 7}, {"key": "srivastava20173d", "year": "2017", "citations": "8", "title": "3D Binary Signatures", "abstract": "<p>In this paper, we propose a novel binary descriptor for 3D point clouds. The\nproposed descriptor termed as 3D Binary Signature (3DBS) is motivated from the\nmatching efficiency of the binary descriptors for 2D images. 3DBS describes\nkeypoints from point clouds with a binary vector resulting in extremely fast\nmatching. The method uses keypoints from standard keypoint detectors. The\ndescriptor is built by constructing a Local Reference Frame and aligning a\nlocal surface patch accordingly. The local surface patch constitutes of\nidentifying nearest neighbours based upon an angular constraint among them. The\npoints are ordered with respect to the distance from the keypoints. The normals\nof the ordered pairs of these keypoints are projected on the axes and the\nrelative magnitude is used to assign a binary digit. The vector thus\nconstituted is used as a signature for representing the keypoints. The matching\nis done by using hamming distance. We show that 3DBS outperforms state of the\nart descriptors on various evaluation metrics.</p>\n", "tags": ["Evaluation", "Efficiency And Optimization"], "tsne_embedding": [23.554576873779297, -4.656014442443848], "cluster": 7}, {"key": "struppek2021learning", "year": "2021", "citations": "116", "title": "Learning To Break Deep Perceptual Hashing: The Use Case Neuralhash", "abstract": "<p>Apple recently revealed its deep perceptual hashing system NeuralHash to\ndetect child sexual abuse material (CSAM) on user devices before files are\nuploaded to its iCloud service. Public criticism quickly arose regarding the\nprotection of user privacy and the system\u2019s reliability. In this paper, we\npresent the first comprehensive empirical analysis of deep perceptual hashing\nbased on NeuralHash. Specifically, we show that current deep perceptual hashing\nmay not be robust. An adversary can manipulate the hash values by applying\nslight changes in images, either induced by gradient-based approaches or simply\nby performing standard image transformations, forcing or preventing hash\ncollisions. Such attacks permit malicious actors easily to exploit the\ndetection system: from hiding abusive material to framing innocent users,\neverything is possible. Moreover, using the hash values, inferences can still\nbe made about the data stored on user devices. In our view, based on our\nresults, deep perceptual hashing in its current form is generally not ready for\nrobust client-side scanning and should not be used from a privacy perspective.</p>\n", "tags": ["Tools & Libraries", "Hashing Methods"], "tsne_embedding": [-15.184640884399414, 16.003877639770508], "cluster": 3}, {"key": "stylianou2019visualizing", "year": "2019", "citations": "44", "title": "Visualizing Deep Similarity Networks", "abstract": "<p>For convolutional neural network models that optimize an image embedding, we\npropose a method to highlight the regions of images that contribute most to\npairwise similarity. This work is a corollary to the visualization tools\ndeveloped for classification networks, but applicable to the problem domains\nbetter suited to similarity learning. The visualization shows how similarity\nnetworks that are fine-tuned learn to focus on different features. We also\ngeneralize our approach to embedding networks that use different pooling\nstrategies and provide a simple mechanism to support image similarity searches\non objects or sub-regions in the query image.</p>\n", "tags": ["Similarity Search"], "tsne_embedding": [-0.9143334627151489, 16.525333404541016], "cluster": 6}, {"key": "su2022global", "year": "2022", "citations": "33", "title": "Global Learnable Attention For Single Image Super-resolution", "abstract": "<p>Self-similarity is valuable to the exploration of non-local textures in\nsingle image super-resolution (SISR). Researchers usually assume that the\nimportance of non-local textures is positively related to their similarity\nscores. In this paper, we surprisingly found that when repairing severely\ndamaged query textures, some non-local textures with low-similarity which are\ncloser to the target can provide more accurate and richer details than the\nhigh-similarity ones. In these cases, low-similarity does not mean inferior but\nis usually caused by different scales or orientations. Utilizing this finding,\nwe proposed a Global Learnable Attention (GLA) to adaptively modify similarity\nscores of non-local textures during training instead of only using a fixed\nsimilarity scoring function such as the dot product. The proposed GLA can\nexplore non-local textures with low-similarity but more accurate details to\nrepair severely damaged textures. Furthermore, we propose to adopt Super-Bit\nLocality-Sensitive Hashing (SB-LSH) as a preprocessing method for our GLA. With\nthe SB-LSH, the computational complexity of our GLA is reduced from quadratic\nto asymptotic linear with respect to the image size. In addition, the proposed\nGLA can be integrated into existing deep SISR models as an efficient general\nbuilding block. Based on the GLA, we constructed a Deep Learnable Similarity\nNetwork (DLSN), which achieves state-of-the-art performance for SISR tasks of\ndifferent degradation types (e.g. blur and noise). Our code and a pre-trained\nDLSN have been uploaded to GitHub{\\dag} for validation.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Evaluation"], "tsne_embedding": [-12.807441711425781, 5.602227687835693], "cluster": 8}, {"key": "su2025deep", "year": "2025", "citations": "255", "title": "Deep Joint-semantics Reconstructing Hashing For Large-scale Unsupervised Cross-modal Retrieval", "abstract": "<p><img src=\"https://github.com/zzs1994/DJSRH/blob/master/page_image/DJRSH.png?raw=true\" alt=\"Deep Joint-Semantics Reconstructing Hashing for Large-Scale Unsupervised Cross-Modal Retrieval\" title=\"Deep Joint-Semantics Reconstructing Hashing for Large-Scale Unsupervised Cross-Modal Retrieval\" /></p>\n\n<p>Cross-modal hashing encodes the multimedia data into a common binary hash space in which the correlations among the samples from different modalities can be effectively measured. Deep cross-modal hashing further improves the retrieval performance as the deep neural networks can generate more semantic relevant features and hash codes. In this paper, we study the unsupervised deep cross-modal hash coding and propose Deep Joint Semantics Reconstructing Hashing (DJSRH), which has the following two main advantages. First, to learn binary codes that preserve the neighborhood structure of the original data, DJSRH constructs a novel joint-semantics affinity matrix which elaborately integrates the original neighborhood information from different modalities and accordingly is capable to capture the latent intrinsic semantic affinity for the input multi-modal instances. Second, DJSRH later trains the networks to generate binary codes that maximally reconstruct above joint-semantics relations via the proposed reconstructing framework, which is more competent for the batch-wise training as it reconstructs the specific similarity value unlike the common Laplacian constraint merely preserving the similarity order. Extensive experiments demonstrate the significant improvement by DJSRH in various cross-modal retrieval tasks.</p>\n", "tags": ["Hashing Methods", "Compact Codes", "ICCV", "Multimodal Retrieval", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-10.837899208068848, 0.7340101003646851], "cluster": 8}, {"key": "su2025greedy", "year": "2025", "citations": "114", "title": "Greedy Hash: Towards Fast Optimization For Accurate Hash Coding In CNN", "abstract": "<p>To convert the input into binary code, hashing algorithm has been widely used for approximate nearest neighbor search on large-scale image sets due to its computation and storage efficiency. Deep hashing further improves the retrieval quality by combining the hash coding with deep neural network. However, a major difficulty in deep hashing lies in the discrete constraints imposed on the network output, which generally makes the optimization NP hard. In this work, we adopt the greedy principle to tackle this NP hard problem by iteratively updating the network toward the probable optimal discrete solution in each iteration. A hash coding layer is designed to implement our approach which strictly uses the sign function in forward propagation to maintain the discrete constraints, while in back propagation the gradients are transmitted intactly to the front layer to avoid the vanishing gradients. In addition to the theoretical derivation, we provide a new perspective to visualize and understand the effectiveness and efficiency of our algorithm. Experiments on benchmark datasets show that our scheme outperforms state-of-the-art hashing methods in both supervised and unsupervised tasks.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Neural Hashing", "Evaluation"], "tsne_embedding": [-4.4432692527771, -12.113931655883789], "cluster": 9}, {"key": "subramanya2025diskann", "year": "2025", "citations": "36", "title": "Diskann: Fast Accurate Billion-point Nearest Neighbor Search On A Single Node", "abstract": "<p>Current state-of-the-art approximate nearest neighbor search (ANNS) algorithms generate indices that must be stored in main memory for fast high-recall search. This makes them expensive and limits the size of the dataset. We present a new graph-based indexing and search system called DiskANN that can index, store, and search a billion point database on a single workstation with just 64GB RAM and an inexpensive solid-state drive (SSD). Contrary to current wisdom, we demonstrate that the SSD-based indices built by DiskANN can meet all three desiderata for large-scale ANNS: high-recall, low query latency and high density (points indexed per node). On the billion point SIFT1B bigann dataset, DiskANN serves &gt; 5000 queries a second with &lt; 3ms mean latency and 95%+ 1-recall@1 on a 16 core machine, where state-of-the-art billion-point ANNS algorithms with similar memory footprint like FAISS and IVFOADC+G+P plateau at around 50% 1-recall@1. Alternately, in the high recall regime, DiskANN can index and serve 5 \u2212 10x more points per node compared to state-of-the-art graph- based methods such as HNSW and NSG. Finally, as part of our overall DiskANN system, we introduce Vamana, a new graph-based ANNS index that is more versatile than the graph indices even for in-memory indices.</p>\n", "tags": ["DATASETS", "Graph Based ANN", "Efficiency And Optimization", "Alt", "Vector Indexing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-8.899210929870605, -20.773151397705078], "cluster": 5}, {"key": "sumbul2020deep", "year": "2020", "citations": "23", "title": "Deep Learning For Image Search And Retrieval In Large Remote Sensing Archives", "abstract": "<p>This chapter presents recent advances in content based image search and\nretrieval (CBIR) systems in remote sensing (RS) for fast and accurate\ninformation discovery from massive data archives. Initially, we analyze the\nlimitations of the traditional CBIR systems that rely on the hand-crafted RS\nimage descriptors. Then, we focus our attention on the advances in RS CBIR\nsystems for which deep learning (DL) models are at the forefront. In\nparticular, we present the theoretical properties of the most recent DL based\nCBIR systems for the characterization of the complex semantic content of RS\nimages. After discussing their strengths and limitations, we present the deep\nhashing based CBIR systems that have high time-efficient search capability\nwithin huge data archives. Finally, the most promising research directions in\nRS CBIR are discussed.</p>\n", "tags": ["Image Retrieval", "Hashing Methods"], "tsne_embedding": [-17.54555320739746, 11.863734245300293], "cluster": 3}, {"key": "sun2021real", "year": "2021", "citations": "15", "title": "Real-time Human Action Recognition Using Locally Aggregated Kinematic-guided Skeletonlet And Supervised Hashing-by-analysis Model", "abstract": "<p>3D action recognition is referred to as the classification of action\nsequences which consist of 3D skeleton joints. While many research work are\ndevoted to 3D action recognition, it mainly suffers from three problems: highly\ncomplicated articulation, a great amount of noise, and a low implementation\nefficiency. To tackle all these problems, we propose a real-time 3D action\nrecognition framework by integrating the locally aggregated kinematic-guided\nskeletonlet (LAKS) with a supervised hashing-by-analysis (SHA) model. We first\ndefine the skeletonlet as a few combinations of joint offsets grouped in terms\nof kinematic principle, and then represent an action sequence using LAKS, which\nconsists of a denoising phase and a locally aggregating phase. The denoising\nphase detects the noisy action data and adjust it by replacing all the features\nwithin it with the features of the corresponding previous frame, while the\nlocally aggregating phase sums the difference between an offset feature of the\nskeletonlet and its cluster center together over all the offset features of the\nsequence. Finally, the SHA model which combines sparse representation with a\nhashing model, aiming at promoting the recognition accuracy while maintaining a\nhigh efficiency. Experimental results on MSRAction3D, UTKinectAction3D and\nFlorence3DAction datasets demonstrate that the proposed method outperforms\nstate-of-the-art methods in both recognition accuracy and implementation\nefficiency.</p>\n", "tags": ["DATASETS", "Tools & Libraries", "Hashing Methods", "Efficiency And Optimization"], "tsne_embedding": [0.5693015456199646, 21.208415985107422], "cluster": 6}, {"key": "sun2025deep", "year": "2025", "citations": "26", "title": "Deep Normalized Cross-modal Hashing With Bi-direction Relation Reasoning", "abstract": "<p>Due to the continuous growth of large-scale multi-modal data and increasing requirements for retrieval speed, deep cross-modal hashing has gained increasing attention recently. Most of existing studies take a similarity matrix as supervision to optimize their models, and the inner product between continuous surrogates of hash codes is utilized to depict the similarity in the Hamming space. However, all of them merely consider the relevant information to build the similarity matrix, ignoring the contribution of the irrelevant one, i.e., the categories that samples do not belong to. Therefore, they cannot effectively alleviate the effect of dissimilar samples. Moreover, due to the modality distribution difference, directly utilizing continuous surrogates of hash codes to calculate similarity may induce suboptimal retrieval performance. To tackle these issues, in this paper, we propose a novel deep normalized cross-modal hashing scheme with bi-direction relation reasoning, named Bi_NCMH. Specifically, we build the multi-level semantic similarity matrix by considering bi-direction relation, i.e., consistent and inconsistent relation. It hence can holistically characterize relations among instances. Besides, we execute feature normalization on continuous surrogates of hash codes to eliminate the deviation caused by modality gap, which further reduces the negative impact of binarization on retrieval performance. Extensive experiments on two cross-modal benchmark datasets demonstrate the superiority of our model over several state-of-the-art baselines.</p>\n", "tags": ["CVPR", "DATASETS", "Hashing Methods", "Evaluation"], "tsne_embedding": [8.130095481872559, 1.6264630556106567], "cluster": 4}, {"key": "sun2025supervised", "year": "2025", "citations": "47", "title": "Supervised Hierarchical Cross-modal Hashing", "abstract": "<p>Recently, due to the unprecedented growth of multimedia data,\ncross-modal hashing has gained increasing attention for the\nefficient cross-media retrieval. Typically, existing methods on crossmodal hashing treat labels of one instance independently but\noverlook the correlations among labels. Indeed, in many real-world\nscenarios, like the online fashion domain, instances (items) are\nlabeled with a set of categories correlated by certain hierarchy. In\nthis paper, we propose a new end-to-end solution for supervised\ncross-modal hashing, named HiCHNet, which explicitly exploits the\nhierarchical labels of instances. In particular, by the pre-established\nlabel hierarchy, we comprehensively characterize each modality\nof the instance with a set of layer-wise hash representations. In\nessence, hash codes are encouraged to not only preserve the layerwise semantic similarities encoded by the label hierarchy, but also\nretain the hierarchical discriminative capabilities. Due to the lack\nof benchmark datasets, apart from adapting the existing dataset\nFashionVC from fashion domain, we create a dataset from the\nonline fashion platform Ssense consisting of 15, 696 image-text\npairs labeled by 32 hierarchical categories. Extensive experiments\non two real-world datasets demonstrate the superiority of our model\nover the state-of-the-art methods.</p>\n", "tags": ["SIGIR", "Hashing Methods", "Evaluation", "DATASETS"], "tsne_embedding": [-4.057109832763672, 15.085188865661621], "cluster": 6}, {"key": "sundaram2025streaming", "year": "2025", "citations": "105", "title": "Streaming Similarity Search Over One Billion Tweets Using Parallel Locality-sensitive Hashing", "abstract": "<p>Finding nearest neighbors has become an important operation on databases, with applications to text search, multimedia indexing,\nand many other areas. One popular algorithm for similarity search, especially for high dimensional data (where spatial indexes like kdtrees do not perform well) is Locality Sensitive Hashing (LSH), an\napproximation algorithm for finding similar objects. In this paper, we describe a new variant of LSH, called Parallel\nLSH (PLSH) designed to be extremely efficient, capable of scaling out on multiple nodes and multiple cores, and which supports highthroughput streaming of new data. Our approach employs several\nnovel ideas, including: cache-conscious hash table layout, using a 2-level merge algorithm for hash table construction; an efficient\nalgorithm for duplicate elimination during hash-table querying; an insert-optimized hash table structure and efficient data expiration\nalgorithm for streaming data; and a performance model that accurately estimates performance of the algorithm and can be used to\noptimize parameter settings. We show that on a workload where we perform similarity search on a dataset of &gt; 1 Billion tweets, with\nhundreds of millions of new tweets per day, we can achieve query times of 1\u20132.5 ms. We show that this is an order of magnitude faster\nthan existing indexing schemes, such as inverted indexes. To the best of our knowledge, this is the fastest implementation of LSH,\nwith table construction times up to 3.7x faster and query times that are 8.3x faster than a basic implementation.</p>\n", "tags": ["Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Text Retrieval", "Similarity Search", "Evaluation"], "tsne_embedding": [8.646451950073242, 0.2453455626964569], "cluster": 4}, {"key": "su\u00e1rez2021revisiting", "year": "2021", "citations": "10", "title": "Revisiting Binary Local Image Description For Resource Limited Devices", "abstract": "<p>The advent of a panoply of resource limited devices opens up new challenges\nin the design of computer vision algorithms with a clear compromise between\naccuracy and computational requirements. In this paper we present new binary\nimage descriptors that emerge from the application of triplet ranking loss,\nhard negative mining and anchor swapping to traditional features based on pixel\ndifferences and image gradients. These descriptors, BAD (Box Average\nDifference) and HashSIFT, establish new operating points in the\nstate-of-the-art\u2019s accuracy vs.\\ resources trade-off curve. In our experiments\nwe evaluate the accuracy, execution time and energy consumption of the proposed\ndescriptors. We show that BAD bears the fastest descriptor implementation in\nthe literature while HashSIFT approaches in accuracy that of the top deep\nlearning-based descriptors, being computationally more efficient. We have made\nthe source code public.</p>\n", "tags": [], "tsne_embedding": [-4.77734899520874, 5.508294582366943], "cluster": 8}, {"key": "su\u00e1rez2024beblid", "year": "2024", "citations": "87", "title": "BEBLID: Boosted Efficient Binary Local Image Descriptor", "abstract": "<p>Efficient matching of local image features is a fundamental task in many\ncomputer vision applications. However, the real-time performance of top\nmatching algorithms is compromised in computationally limited devices, such as\nmobile phones or drones, due to the simplicity of their hardware and their\nfinite energy supply. In this paper we introduce BEBLID, an efficient learned\nbinary image descriptor. It improves our previous real-valued descriptor,\nBELID, making it both more efficient for matching and more accurate. To this\nend we use AdaBoost with an improved weak-learner training scheme that produces\nbetter local descriptions. Further, we binarize our descriptor by forcing all\nweak-learners to have the same weight in the strong learner combination and\ntrain it in an unbalanced data set to address the asymmetries arising in\nmatching and retrieval tasks. In our experiments BEBLID achieves an accuracy\nclose to SIFT and better computational efficiency than ORB, the fastest\nalgorithm in the literature.</p>\n", "tags": ["Evaluation", "Efficiency And Optimization"], "tsne_embedding": [-16.01520538330078, 7.113483428955078], "cluster": 3}, {"key": "svenstrup2017hash", "year": "2017", "citations": "29", "title": "Hash Embeddings For Efficient Word Representations", "abstract": "<p>We present hash embeddings, an efficient method for representing words in a\ncontinuous vector form. A hash embedding may be seen as an interpolation\nbetween a standard word embedding and a word embedding created using a random\nhash function (the hashing trick). In hash embeddings each token is represented\nby \\(k\\) \\(d\\)-dimensional embeddings vectors and one \\(k\\) dimensional weight\nvector. The final \\(d\\) dimensional representation of the token is the product of\nthe two. Rather than fitting the embedding vectors for each token these are\nselected by the hashing trick from a shared pool of \\(B\\) embedding vectors. Our\nexperiments show that hash embeddings can easily deal with huge vocabularies\nconsisting of millions of tokens. When using a hash embedding there is no need\nto create a dictionary before training nor to perform any kind of vocabulary\npruning after training. We show that models trained using hash embeddings\nexhibit at least the same level of performance as models trained using regular\nembeddings across a wide range of tasks. Furthermore, the number of parameters\nneeded by such an embedding is only a fraction of what is required by a regular\nembedding. Since standard embeddings and embeddings constructed using the\nhashing trick are actually just special cases of a hash embedding, hash\nembeddings can be considered an extension and improvement over the existing\nregular embedding types.</p>\n", "tags": ["Hashing Methods", "Evaluation"], "tsne_embedding": [4.409185886383057, -18.88611602783203], "cluster": 5}, {"key": "szeto2016binary", "year": "2016", "citations": "11", "title": "Binary Codes For Tagging X-ray Images Via Deep De-noising Autoencoders", "abstract": "<p>A Content-Based Image Retrieval (CBIR) system which identifies similar\nmedical images based on a query image can assist clinicians for more accurate\ndiagnosis. The recent CBIR research trend favors the construction and use of\nbinary codes to represent images. Deep architectures could learn the non-linear\nrelationship among image pixels adaptively, allowing the automatic learning of\nhigh-level features from raw pixels. However, most of them require class\nlabels, which are expensive to obtain, particularly for medical images. The\nmethods which do not need class labels utilize a deep autoencoder for binary\nhashing, but the code construction involves a specific training algorithm and\nan ad-hoc regularization technique. In this study, we explored using a deep\nde-noising autoencoder (DDA), with a new unsupervised training scheme using\nonly backpropagation and dropout, to hash images into binary codes. We\nconducted experiments on more than 14,000 x-ray images. By using class labels\nonly for evaluating the retrieval results, we constructed a 16-bit DDA and a\n512-bit DDA independently. Comparing to other unsupervised methods, we\nsucceeded to obtain the lowest total error by using the 512-bit codes for\nretrieval via exhaustive search, and speed up 9.27 times with the use of the\n16-bit codes while keeping a comparable total error. We found that our new\ntraining scheme could reduce the total retrieval error significantly by 21.9%.\nTo further boost the image retrieval performance, we developed Radon\nAutoencoder Barcode (RABC) which are learned from the Radon projections of\nimages using a de-noising autoencoder. Experimental results demonstrated its\nsuperior performance in retrieval when it was combined with DDA binary codes.</p>\n", "tags": ["Compact Codes", "Image Retrieval", "Hashing Methods", "Evaluation"], "tsne_embedding": [-23.263134002685547, 15.885204315185547], "cluster": 3}, {"key": "tabei2016scalable", "year": "2016", "citations": "62", "title": "Scalable Similarity Search For Molecular Descriptors", "abstract": "<p>Similarity search over chemical compound databases is a fundamental task in\nthe discovery and design of novel drug-like molecules. Such databases often\nencode molecules as non-negative integer vectors, called molecular descriptors,\nwhich represent rich information on various molecular properties. While there\nexist efficient indexing structures for searching databases of binary vectors,\nsolutions for more general integer vectors are in their infancy. In this paper\nwe present a time- and space- efficient index for the problem that we call the\nsuccinct intervals-splitting tree algorithm for molecular descriptors (SITAd).\nOur approach extends efficient methods for binary-vector databases, and uses\nideas from succinct data structures. Our experiments, on a large database of\nover 40 million compounds, show SITAd significantly outperforms alternative\napproaches in practice.</p>\n", "tags": ["Alt", "Similarity Search"], "tsne_embedding": [10.693583488464355, -15.977619171142578], "cluster": 2}, {"key": "taheri2019similarity", "year": "2019", "citations": "192", "title": "Similarity-based Android Malware Detection Using Hamming Distance Of Static Binary Features", "abstract": "<p>In this paper, we develop four malware detection methods using Hamming\ndistance to find similarity between samples which are first nearest neighbors\n(FNN), all nearest neighbors (ANN), weighted all nearest neighbors (WANN), and\nk-medoid based nearest neighbors (KMNN). In our proposed methods, we can\ntrigger the alarm if we detect an Android app is malicious. Hence, our\nsolutions help us to avoid the spread of detected malware on a broader scale.\nWe provide a detailed description of the proposed detection methods and related\nalgorithms. We include an extensive analysis to asses the suitability of our\nproposed similarity-based detection methods. In this way, we perform our\nexperiments on three datasets, including benign and malware Android apps like\nDrebin, Contagio, and Genome. Thus, to corroborate the actual effectiveness of\nour classifier, we carry out performance comparisons with some state-of-the-art\nclassification and malware detection algorithms, namely Mixed and Separated\nsolutions, the program dissimilarity measure based on entropy (PDME) and the\nFalDroid algorithms. We test our experiments in a different type of features:\nAPI, intent, and permission features on these three datasets. The results\nconfirm that accuracy rates of proposed algorithms are more than 90% and in\nsome cases (i.e., considering API features) are more than 99%, and are\ncomparable with existing state-of-the-art solutions.</p>\n", "tags": ["DATASETS", "Tools & Libraries", "Evaluation"], "tsne_embedding": [12.184629440307617, -25.54060173034668], "cluster": 5}, {"key": "taherkhani2020error", "year": "2020", "citations": "14", "title": "Error-corrected Margin-based Deep Cross-modal Hashing For Facial Image Retrieval", "abstract": "<p>Cross-modal hashing facilitates mapping of heterogeneous multimedia data into\na common Hamming space, which can beutilized for fast and flexible retrieval\nacross different modalities. In this paper, we propose a novel cross-modal\nhashingarchitecture-deep neural decoder cross-modal hashing (DNDCMH), which\nuses a binary vector specifying the presence of certainfacial attributes as an\ninput query to retrieve relevant face images from a database. The DNDCMH\nnetwork consists of two separatecomponents: an attribute-based deep cross-modal\nhashing (ADCMH) module, which uses a margin (m)-based loss function\ntoefficiently learn compact binary codes to preserve similarity between\nmodalities in the Hamming space, and a neural error correctingdecoder (NECD),\nwhich is an error correcting decoder implemented with a neural network. The\ngoal of NECD network in DNDCMH isto error correct the hash codes generated by\nADCMH to improve the retrieval efficiency. The NECD network is trained such\nthat it hasan error correcting capability greater than or equal to the margin\n(m) of the margin-based loss function. This results in NECD cancorrect the\ncorrupted hash codes generated by ADCMH up to the Hamming distance of m. We\nhave evaluated and comparedDNDCMH with state-of-the-art cross-modal hashing\nmethods on standard datasets to demonstrate the superiority of our method.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Evaluation"], "tsne_embedding": [-10.210332870483398, 2.945404052734375], "cluster": 8}, {"key": "takeshita2020secure", "year": "2020", "citations": "14", "title": "Secure Single-server Nearly-identical Image Deduplication", "abstract": "<p>Cloud computing is often utilized for file storage. Clients of cloud storage\nservices want to ensure the privacy of their data, and both clients and servers\nwant to use as little storage as possible. Cross-user deduplication is one\nmethod to reduce the amount of storage a server uses. Deduplication and privacy\nare naturally conflicting goals, especially for nearly-identical (``fuzzy\u2019\u2019)\ndeduplication, as some information about the data must be used to perform\ndeduplication. Prior solutions thus utilize multiple servers, or only function\nfor exact deduplication. In this paper, we present a single-server protocol for\ncross-user nearly-identical deduplication based on secure locality-sensitive\nhashing (SLSH). We formally define our ideal security, and rigorously prove our\nprotocol secure against fully malicious, colluding adversaries with a proof by\nsimulation. We show experimentally that the individual parts of the protocol\nare computationally feasible, and further discuss practical issues of security\nand efficiency.</p>\n", "tags": ["Efficiency And Optimization", "ICCV", "Hashing Methods", "Locality Sensitive Hashing"], "tsne_embedding": [2.72068190574646, -23.872840881347656], "cluster": 5}, {"key": "takikawa2023compact", "year": "2023", "citations": "8", "title": "Compact Neural Graphics Primitives With Learned Hash Probing", "abstract": "<p>Neural graphics primitives are faster and achieve higher quality when their\nneural networks are augmented by spatial data structures that hold trainable\nfeatures arranged in a grid. However, existing feature grids either come with a\nlarge memory footprint (dense or factorized grids, trees, and hash tables) or\nslow performance (index learning and vector quantization). In this paper, we\nshow that a hash table with learned probes has neither disadvantage, resulting\nin a favorable combination of size and speed. Inference is faster than unprobed\nhash tables at equal quality while training is only 1.2-2.6x slower,\nsignificantly outperforming prior index learning approaches. We arrive at this\nformulation by casting all feature grids into a common framework: they each\ncorrespond to a lookup function that indexes into a table of feature vectors.\nIn this framework, the lookup functions of existing data structures can be\ncombined by simple arithmetic combinations of their indices, resulting in\nPareto optimal compression and speed.</p>\n", "tags": ["Quantization", "Tools & Libraries", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [-1.229831576347351, -15.347691535949707], "cluster": 9}, {"key": "talamantes2021instance", "year": "2021", "citations": "7", "title": "Instance-based Learning Using The Half-space Proximal Graph", "abstract": "<p>The primary example of instance-based learning is the \\(k\\)-nearest neighbor\nrule (kNN), praised for its simplicity and the capacity to adapt to new unseen\ndata and toss away old data. The main disadvantages often mentioned are the\nclassification complexity, which is \\(O(n)\\), and the estimation of the parameter\n\\(k\\), the number of nearest neighbors to be used. The use of indexes at\nclassification time lifts the former disadvantage, while there is no conclusive\nmethod for the latter.\n  This paper presents a parameter-free instance-based learning algorithm using\nthe {\\em Half-Space Proximal} (HSP) graph. The HSP neighbors simultaneously\npossess proximity and variety concerning the center node. To classify a given\nquery, we compute its HSP neighbors and apply a simple majority rule over them.\nIn our experiments, the resulting classifier bettered \\(KNN\\) for any \\(k\\) in a\nbattery of datasets. This improvement sticks even when applying weighted\nmajority rules to both kNN and HSP classifiers.\n  Surprisingly, when using a probabilistic index to approximate the HSP graph\nand consequently speeding-up the classification task, our method could {\\em\nimprove} its accuracy in stark contrast with the kNN classifier, which worsens\nwith a probabilistic index.</p>\n", "tags": ["DATASETS"], "tsne_embedding": [18.375553131103516, 6.657183647155762], "cluster": 0}, {"key": "talreja2019learning", "year": "2019", "citations": "19", "title": "Learning To Authenticate With Deep Multibiometric Hashing And Neural Network Decoding", "abstract": "<p>In this paper, we propose a novel multimodal deep hashing neural decoder\n(MDHND) architecture, which integrates a deep hashing framework with a neural\nnetwork decoder (NND) to create an effective multibiometric authentication\nsystem. The MDHND consists of two separate modules: a multimodal deep hashing\n(MDH) module, which is used for feature-level fusion and binarization of\nmultiple biometrics, and a neural network decoder (NND) module, which is used\nto refine the intermediate binary codes generated by the MDH and compensate for\nthe difference between enrollment and probe biometrics (variations in pose,\nillumination, etc.). Use of NND helps to improve the performance of the overall\nmultimodal authentication system. The MDHND framework is trained in 3 steps\nusing joint optimization of the two modules. In Step 1, the MDH parameters are\ntrained and learned to generate a shared multimodal latent code; in Step 2, the\nlatent codes from Step 1 are passed through a conventional error-correcting\ncode (ECC) decoder to generate the ground truth to train a neural network\ndecoder (NND); in Step 3, the NND decoder is trained using the ground truth\nfrom Step 2 and the MDH and NND are jointly optimized. Experimental results on\na standard multimodal dataset demonstrate the superiority of our method\nrelative to other current multimodal authentication systems</p>\n", "tags": ["DATASETS", "Hashing Methods", "Compact Codes", "Neural Hashing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [5.588866710662842, -27.796344757080078], "cluster": 5}, {"key": "talreja2019using", "year": "2019", "citations": "25", "title": "Using Deep Cross Modal Hashing And Error Correcting Codes For Improving The Efficiency Of Attribute Guided Facial Image Retrieval", "abstract": "<p>With benefits of fast query speed and low storage cost, hashing-based image\nretrieval approaches have garnered considerable attention from the research\ncommunity. In this paper, we propose a novel Error-Corrected Deep Cross Modal\nHashing (CMH-ECC) method which uses a bitmap specifying the presence of certain\nfacial attributes as an input query to retrieve relevant face images from the\ndatabase. In this architecture, we generate compact hash codes using an\nend-to-end deep learning module, which effectively captures the inherent\nrelationships between the face and attribute modality. We also integrate our\ndeep learning module with forward error correction codes to further reduce the\ndistance between different modalities of the same subject. Specifically, the\nproperties of deep hashing and forward error correction codes are exploited to\ndesign a cross modal hashing framework with high retrieval performance.\nExperimental results using two standard datasets with facial attributes-image\nmodalities indicate that our CMH-ECC face image retrieval model outperforms\nmost of the current attribute-based face image retrieval approaches.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Neural Hashing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-13.657207489013672, 3.8412892818450928], "cluster": 8}, {"key": "talreja2019zero", "year": "2019", "citations": "20", "title": "Zero-shot Deep Hashing And Neural Network Based Error Correction For Face Template Protection", "abstract": "<p>In this paper, we present a novel architecture that integrates a deep hashing\nframework with a neural network decoder (NND) for application to face template\nprotection. It improves upon existing face template protection techniques to\nprovide better matching performance with one-shot and multi-shot enrollment. A\nkey novelty of our proposed architecture is that the framework can also be used\nwith zero-shot enrollment. This implies that our architecture does not need to\nbe re-trained even if a new subject is to be enrolled into the system. The\nproposed architecture consists of two major components: a deep hashing (DH)\ncomponent, which is used for robust mapping of face images to their\ncorresponding intermediate binary codes, and a NND component, which corrects\nerrors in the intermediate binary codes that are caused by differences in the\nenrollment and probe biometrics due to factors such as variation in pose,\nillumination, and other factors. The final binary code generated by the NND is\nthen cryptographically hashed and stored as a secure face template in the\ndatabase. The efficacy of our approach with zero-shot, one-shot, and multi-shot\nenrollments is shown for CMU-PIE, Extended Yale B, WVU multimodal and Multi-PIE\nface databases. With zero-shot enrollment, the system achieves approximately\n85% genuine accept rates (GAR) at 0.01% false accept rate (FAR), and with\none-shot and multi-shot enrollments, it achieves approximately 99.95% GAR at\n0.01% FAR, while providing a high level of template security.</p>\n", "tags": ["Hashing Methods", "Compact Codes", "Neural Hashing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [5.63502311706543, -27.30565643310547], "cluster": 5}, {"key": "talreja2020deep", "year": "2020", "citations": "24", "title": "Deep Hashing For Secure Multimodal Biometrics", "abstract": "<p>When compared to unimodal systems, multimodal biometric systems have several\nadvantages, including lower error rate, higher accuracy, and larger population\ncoverage. However, multimodal systems have an increased demand for integrity\nand privacy because they must store multiple biometric traits associated with\neach user. In this paper, we present a deep learning framework for\nfeature-level fusion that generates a secure multimodal template from each\nuser\u2019s face and iris biometrics. We integrate a deep hashing (binarization)\ntechnique into the fusion architecture to generate a robust binary multimodal\nshared latent representation. Further, we employ a hybrid secure architecture\nby combining cancelable biometrics with secure sketch techniques and integrate\nit with a deep hashing framework, which makes it computationally prohibitive to\nforge a combination of multiple biometrics that pass the authentication. The\nefficacy of the proposed approach is shown using a multimodal database of face\nand iris and it is observed that the matching performance is improved due to\nthe fusion of multiple biometrics. Furthermore, the proposed approach also\nprovides cancelability and unlinkability of the templates along with improved\nprivacy of the biometric data. Additionally, we also test the proposed hashing\nfunction for an image retrieval application using a benchmark dataset. The main\ngoal of this paper is to develop a method for integrating multimodal fusion,\ndeep hashing, and biometric security, with an emphasis on structural data from\nmodalities like face and iris. The proposed approach is in no way a general\nbiometric security framework that can be applied to all biometric modalities,\nas further research is needed to extend the proposed framework to other\nunconstrained biometric modalities.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Neural Hashing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [5.94197416305542, -26.801651000976562], "cluster": 5}, {"key": "tan2020learning", "year": "2020", "citations": "76", "title": "Learning To Hash With Graph Neural Networks For Recommender Systems", "abstract": "<p>Graph representation learning has attracted much attention in supporting high\nquality candidate search at scale. Despite its effectiveness in learning\nembedding vectors for objects in the user-item interaction network, the\ncomputational costs to infer users\u2019 preferences in continuous embedding space\nare tremendous. In this work, we investigate the problem of hashing with graph\nneural networks (GNNs) for high quality retrieval, and propose a simple yet\neffective discrete representation learning framework to jointly learn\ncontinuous and discrete codes. Specifically, a deep hashing with GNNs (HashGNN)\nis presented, which consists of two components, a GNN encoder for learning node\nrepresentations, and a hash layer for encoding representations to hash codes.\nThe whole architecture is trained end-to-end by jointly optimizing two losses,\ni.e., reconstruction loss from reconstructing observed links, and ranking loss\nfrom preserving the relative ordering of hash codes. A novel discrete\noptimization strategy based on straight through estimator (STE) with guidance\nis proposed. The principal idea is to avoid gradient magnification in\nback-propagation of STE with continuous embedding guidance, in which we begin\nfrom learning an easier network that mimic the continuous embedding and let it\nevolve during the training until it finally goes back to STE. Comprehensive\nexperiments over three publicly available and one real-world Alibaba company\ndatasets demonstrate that our model not only can achieve comparable performance\ncompared with its continuous counterpart but also runs multiple times faster\nduring inference.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Recommender Systems", "Neural Hashing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [14.84371566772461, 13.288013458251953], "cluster": 0}, {"key": "tan2021fast", "year": "2021", "citations": "12", "title": "A Fast Partial Video Copy Detection Using KNN And Global Feature Database", "abstract": "<p>We propose a fast partial video copy detection framework in this paper. In\nthis framework all frame features of the reference videos are organized in a\nKNN searchable database. Instead of scanning all reference videos, the query\nvideo segment does a fast KNN search in the global feature database. The\nreturned results are used to generate a short list of candidate videos. A\nmodified temporal network is then used to localize the copy segment in the\ncandidate videos. We evaluate different choice of CNN features on the VCDB\ndataset. Our benchmark F1 score exceeds the state of the art by a big margin.</p>\n", "tags": ["DATASETS", "Similarity Search", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-10.308374404907227, 23.299392700195312], "cluster": 6}, {"key": "tan2023unfolded", "year": "2023", "citations": "5", "title": "Unfolded Self-reconstruction LSH: Towards Machine Unlearning In Approximate Nearest Neighbour Search", "abstract": "<p>Approximate nearest neighbour (ANN) search is an essential component of\nsearch engines, recommendation systems, etc. Many recent works focus on\nlearning-based data-distribution-dependent hashing and achieve good retrieval\nperformance. However, due to increasing demand for users\u2019 privacy and security,\nwe often need to remove users\u2019 data information from Machine Learning (ML)\nmodels to satisfy specific privacy and security requirements. This need\nrequires the ANN search algorithm to support fast online data deletion and\ninsertion. Current learning-based hashing methods need retraining the hash\nfunction, which is prohibitable due to the vast time-cost of large-scale data.\nTo address this problem, we propose a novel data-dependent hashing method named\nunfolded self-reconstruction locality-sensitive hashing (USR-LSH). Our USR-LSH\nunfolded the optimization update for instance-wise data reconstruction, which\nis better for preserving data information than data-independent LSH. Moreover,\nour USR-LSH supports fast online data deletion and insertion without\nretraining. To the best of our knowledge, we are the first to address the\nmachine unlearning of retrieval problems. Empirically, we demonstrate that\nUSR-LSH outperforms the state-of-the-art data-distribution-independent LSH in\nANN tasks in terms of precision and recall. We also show that USR-LSH has\nsignificantly faster data deletion and insertion time than learning-based\ndata-dependent hashing.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Recommender Systems", "Similarity Search", "Evaluation"], "tsne_embedding": [-11.798096656799316, -11.989023208618164], "cluster": 1}, {"key": "tanaka2021fake", "year": "2021", "citations": "10", "title": "Fake-image Detection With Robust Hashing", "abstract": "<p>In this paper, we investigate whether robust hashing has a possibility to\nrobustly detect fake-images even when multiple manipulation techniques such as\nJPEG compression are applied to images for the first time. In an experiment,\nthe proposed fake detection with robust hashing is demonstrated to outperform\nstate-of-the-art one under the use of various datasets including fake images\ngenerated with GANs.</p>\n", "tags": ["DATASETS", "Hashing Methods"], "tsne_embedding": [-12.591591835021973, 16.262510299682617], "cluster": 6}, {"key": "tang2016visualizing", "year": "2016", "citations": "215", "title": "Visualizing Large-scale And High-dimensional Data", "abstract": "<p>We study the problem of visualizing large-scale and high-dimensional data in\na low-dimensional (typically 2D or 3D) space. Much success has been reported\nrecently by techniques that first compute a similarity structure of the data\npoints and then project them into a low-dimensional space with the structure\npreserved. These two steps suffer from considerable computational costs,\npreventing the state-of-the-art methods such as the t-SNE from scaling to\nlarge-scale and high-dimensional data (e.g., millions of data points and\nhundreds of dimensions). We propose the LargeVis, a technique that first\nconstructs an accurately approximated K-nearest neighbor graph from the data\nand then layouts the graph in the low-dimensional space. Comparing to t-SNE,\nLargeVis significantly reduces the computational cost of the graph construction\nstep and employs a principled probabilistic model for the visualization step,\nthe objective of which can be effectively optimized through asynchronous\nstochastic gradient descent with a linear time complexity. The whole procedure\nthus easily scales to millions of high-dimensional data points. Experimental\nresults on real-world data sets demonstrate that the LargeVis outperforms the\nstate-of-the-art methods in both efficiency and effectiveness. The\nhyper-parameters of LargeVis are also much more stable over different data\nsets.</p>\n", "tags": ["Graph Based ANN", "Efficiency And Optimization"], "tsne_embedding": [21.104963302612305, 11.536518096923828], "cluster": 0}, {"key": "tang2021improving", "year": "2021", "citations": "23", "title": "Improving Document Representations By Generating Pseudo Query Embeddings For Dense Retrieval", "abstract": "<p>Recently, the retrieval models based on dense representations have been\ngradually applied in the first stage of the document retrieval tasks, showing\nbetter performance than traditional sparse vector space models. To obtain high\nefficiency, the basic structure of these models is Bi-encoder in most cases.\nHowever, this simple structure may cause serious information loss during the\nencoding of documents since the queries are agnostic. To address this problem,\nwe design a method to mimic the queries on each of the documents by an\niterative clustering process and represent the documents by multiple pseudo\nqueries (i.e., the cluster centroids). To boost the retrieval process using\napproximate nearest neighbor search library, we also optimize the matching\nfunction with a two-step score calculation procedure. Experimental results on\nseveral popular ranking and QA datasets show that our model can achieve\nstate-of-the-art results.</p>\n", "tags": ["DATASETS", "Text Retrieval", "Evaluation", "Efficiency And Optimization", "ACL", "Tools & Libraries"], "tsne_embedding": [10.789592742919922, -8.062644004821777], "cluster": 2}, {"key": "tang2021when", "year": "2021", "citations": "95", "title": "When Similarity Digest Meets Vector Management System: A Survey On Similarity Hash Function", "abstract": "<p>The booming vector manage system calls for feasible similarity hash function\nas a front-end to perform similarity analysis. In this paper, we make a\nsystematical survey on the existent well-known similarity hash functions to\ntease out the satisfied ones. We conclude that the similarity hash function\nMinHash and Nilsimsa can be directly marshaled into the pipeline of similarity\nanalysis using vector manage system. After that, we make a brief and empirical\ndiscussion on the performance, drawbacks of the these functions and highlight\nMinHash, the variant of SimHash and feature hashing are the best for vector\nmanagement system for large-scale similarity analysis.</p>\n", "tags": ["Survey Paper", "Locality Sensitive Hashing", "Hashing Methods", "Evaluation"], "tsne_embedding": [7.879389762878418, 4.709636688232422], "cluster": 4}, {"key": "tchayekondi2020new", "year": "2020", "citations": "5", "title": "A New Hashing Based Nearest Neighbors Selection Technique For Big Datasets", "abstract": "<p>KNN has the reputation to be the word simplest but efficient supervised\nlearning algorithm used for either classification or regression. KNN prediction\nefficiency highly depends on the size of its training data but when this\ntraining data grows KNN suffers from slowness in making decisions since it\nneeds to search nearest neighbors within the entire dataset at each decision\nmaking. This paper proposes a new technique that enables the selection of\nnearest neighbors directly in the neighborhood of a given observation. The\nproposed approach consists of dividing the data space into subcells of a\nvirtual grid built on top of data space. The mapping between the data points\nand subcells is performed using hashing. When it comes to select the nearest\nneighbors of a given observation, we firstly identify the cell the observation\nbelongs by using hashing, and then we look for nearest neighbors from that\ncentral cell and cells around it layer by layer. From our experiment\nperformance analysis on publicly available datasets, our algorithm outperforms\nthe original KNN in time efficiency with a prediction quality as good as that\nof KNN it also offers competitive performance with solutions like KDtree</p>\n", "tags": ["DATASETS", "Hashing Methods", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [17.089317321777344, 6.554999351501465], "cluster": 0}, {"key": "teofili2019lucene", "year": "2019", "citations": "7", "title": "Lucene For Approximate Nearest-neighbors Search On Arbitrary Dense Vectors", "abstract": "<p>We demonstrate three approaches for adapting the open-source Lucene search\nlibrary to perform approximate nearest-neighbor search on arbitrary dense\nvectors, using similarity search on word embeddings as a case study. At its\ncore, Lucene is built around inverted indexes of a document collection\u2019s\n(sparse) term-document matrix, which is incompatible with the lower-dimensional\ndense vectors that are common in deep learning applications. We evaluate three\ntechniques to overcome these challenges that can all be natively integrated\ninto Lucene: the creation of documents populated with fake words, LSH applied\nto lexical realizations of dense vectors, and k-d trees coupled with\ndimensionality reduction. Experiments show that the \u201cfake words\u201d approach\nrepresents the best balance between effectiveness and efficiency. These\ntechniques are integrated into the Anserini open-source toolkit and made\navailable to the community.</p>\n", "tags": ["Locality Sensitive Hashing", "Efficiency And Optimization", "Similarity Search", "Tree Based ANN", "Tools & Libraries"], "tsne_embedding": [10.323851585388184, -9.41447639465332], "cluster": 2}, {"key": "thakur2022injecting", "year": "2022", "citations": "6", "title": "Injecting Domain Adaptation With Learning-to-hash For Effective And Efficient Zero-shot Dense Retrieval", "abstract": "<p>Dense retrieval overcome the lexical gap and has shown great success in\nad-hoc information retrieval (IR). Despite their success, dense retrievers are\nexpensive to serve across practical use cases. For use cases requiring to\nsearch from millions of documents, the dense index becomes bulky and requires\nhigh memory usage for storing the index. More recently, learning-to-hash (LTH)\ntechniques, for e.g., BPR and JPQ, produce binary document vectors, thereby\nreducing the memory requirement to efficiently store the dense index. LTH\ntechniques are supervised and finetune the retriever using a ranking loss. They\noutperform their counterparts, i.e., traditional out-of-the-box vector\ncompression techniques such as PCA or PQ. A missing piece from prior work is\nthat existing techniques have been evaluated only in-domain, i.e., on a single\ndataset such as MS MARCO. In our work, we evaluate LTH and vector compression\ntechniques for improving the downstream zero-shot retrieval accuracy of the\nTAS-B dense retriever while maintaining efficiency at inference. Our results\ndemonstrate that, unlike prior work, LTH strategies when applied naively can\nunderperform the zero-shot TAS-B dense retriever on average by up to 14%\nnDCG@10 on the BEIR benchmark. To solve this limitation, in our work, we\npropose an easy yet effective solution of injecting domain adaptation with\nexisting supervised LTH techniques. We experiment with two well-known\nunsupervised domain adaptation techniques: GenQ and GPL. Our domain adaptation\ninjection technique can improve the downstream zero-shot retrieval\neffectiveness for both BPR and JPQ variants of the TAS-B model by on average\n11.5% and 8.2% nDCG@10 while both maintaining 32\\(\\times\\) memory efficiency and\n14\\(\\times\\) and 2\\(\\times\\) speedup respectively in CPU retrieval latency on BEIR.\nAll our code, models, and data are publicly available at\nhttps://github.com/thakur-nandan/income.</p>\n", "tags": ["DATASETS", "Quantization", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [-7.032993316650391, -21.019630432128906], "cluster": 5}, {"key": "tian2017semi", "year": "2017", "citations": "8", "title": "Semi-supervised Multimodal Hashing", "abstract": "<p>Retrieving nearest neighbors across correlated data in multiple modalities,\nsuch as image-text pairs on Facebook and video-tag pairs on YouTube, has become\na challenging task due to the huge amount of data. Multimodal hashing methods\nthat embed data into binary codes can boost the retrieving speed and reduce\nstorage requirement. As unsupervised multimodal hashing methods are usually\ninferior to supervised ones, while the supervised ones requires too much\nmanually labeled data, the proposed method in this paper utilizes a part of\nlabels to design a semi-supervised multimodal hashing method. It first computes\nthe transformation matrices for data matrices and label matrix. Then, with\nthese transformation matrices, fuzzy logic is introduced to estimate a label\nmatrix for unlabeled data. Finally, it uses the estimated label matrix to learn\nhashing functions for data in each modality to generate a unified binary code\nmatrix. Experiments show that the proposed semi-supervised method with 50%\nlabels can get a medium performance among the compared supervised ones and\nachieve an approximate performance to the best supervised method with 90%\nlabels. With only 10% labels, the proposed method can still compete with the\nworst compared supervised one.</p>\n", "tags": ["Compact Codes", "Hashing Methods", "Evaluation"], "tsne_embedding": [-0.4160749912261963, -2.7851758003234863], "cluster": 9}, {"key": "tian2018learning", "year": "2018", "citations": "5", "title": "Learning Decorrelated Hashing Codes For Multimodal Retrieval", "abstract": "<p>In social networks, heterogeneous multimedia data correlate to each other,\nsuch as videos and their corresponding tags in YouTube and image-text pairs in\nFacebook. Nearest neighbor retrieval across multiple modalities on large data\nsets becomes a hot yet challenging problem. Hashing is expected to be an\nefficient solution, since it represents data as binary codes. As the bit-wise\nXOR operations can be fast handled, the retrieval time is greatly reduced. Few\nexisting multimodal hashing methods consider the correlation among hashing\nbits. The correlation has negative impact on hashing codes. When the hashing\ncode length becomes longer, the retrieval performance improvement becomes\nslower. In this paper, we propose a minimum correlation regularization (MCR)\nfor multimodal hashing. First, the sigmoid function is used to embed the data\nmatrices. Then, the MCR is applied on the output of sigmoid function. As the\noutput of sigmoid function approximates a binary code matrix, the proposed MCR\ncan efficiently decorrelate the hashing codes. Experiments show the superiority\nof the proposed method becomes greater as the code length increases.</p>\n", "tags": ["Compact Codes", "Multimodal Retrieval", "Hashing Methods", "Evaluation"], "tsne_embedding": [-1.9367573261260986, 1.3954415321350098], "cluster": 8}, {"key": "tian2019global", "year": "2019", "citations": "14", "title": "Global Hashing System For Fast Image Search", "abstract": "<p>Hashing methods have been widely investigated for fast approximate nearest\nneighbor searching in large data sets. Most existing methods use binary vectors\nin lower dimensional spaces to represent data points that are usually real\nvectors of higher dimensionality. We divide the hashing process into two steps.\nData points are first embedded in a low-dimensional space, and the global\npositioning system method is subsequently introduced but modified for binary\nembedding. We devise dataindependent and data-dependent methods to distribute\nthe satellites at appropriate locations. Our methods are based on finding the\ntradeoff between the information losses in these two steps. Experiments show\nthat our data-dependent method outperforms other methods in different-sized\ndata sets from 100k to 10M. By incorporating the orthogonality of the code\nmatrix, both our data-independent and data-dependent methods are particularly\nimpressive in experiments on longer bits.</p>\n", "tags": ["Image Retrieval", "Hashing Methods"], "tsne_embedding": [24.911104202270508, -10.324145317077637], "cluster": 7}, {"key": "tian2022learned", "year": "2022", "citations": "12", "title": "A Learned Index For Exact Similarity Search In Metric Spaces", "abstract": "<p>Indexing is an effective way to support efficient query processing in large\ndatabases. Recently the concept of learned index, which replaces or complements\ntraditional index structures with machine learning models, has been actively\nexplored to reduce storage and search costs. However, accurate and efficient\nsimilarity query processing in high-dimensional metric spaces remains to be an\nopen challenge. In this paper, we propose a novel indexing approach called LIMS\nthat uses data clustering, pivot-based data transformation techniques and\nlearned indexes to support efficient similarity query processing in metric\nspaces. In LIMS, the underlying data is partitioned into clusters such that\neach cluster follows a relatively uniform data distribution. Data\nredistribution is achieved by utilizing a small number of pivots for each\ncluster. Similar data are mapped into compact regions and the mapped values are\ntotally ordinal. Machine learning models are developed to approximate the\nposition of each data record on disk. Efficient algorithms are designed for\nprocessing range queries and nearest neighbor queries based on LIMS, and for\nindex maintenance with dynamic updates. Extensive experiments on real-world and\nsynthetic datasets demonstrate the superiority of LIMS compared with\ntraditional indexes and state-of-the-art learned indexes.</p>\n", "tags": ["Vector Indexing", "Similarity Search", "Evaluation", "DATASETS"], "tsne_embedding": [7.104085922241211, -2.9344539642333984], "cluster": 4}, {"key": "tian2024fusionanns", "year": "2024", "citations": "7", "title": "Fusionanns: An Efficient CPU/GPU Cooperative Processing Architecture For Billion-scale Approximate Nearest Neighbor Search", "abstract": "<p>Approximate nearest neighbor search (ANNS) has emerged as a crucial component\nof database and AI infrastructure. Ever-increasing vector datasets pose\nsignificant challenges in terms of performance, cost, and accuracy for ANNS\nservices. None of modern ANNS systems can address these issues simultaneously.\nWe present FusionANNS, a high-throughput, low-latency, cost-efficient, and\nhigh-accuracy ANNS system for billion-scale datasets using SSDs and only one\nentry-level GPU. The key idea of FusionANNS lies in CPU/GPU collaborative\nfiltering and re-ranking mechanisms, which significantly reduce I/O operations\nacross CPUs, GPU, and SSDs to break through the I/O performance bottleneck.\nSpecifically, we propose three novel designs: (1) multi-tiered indexing to\navoid data swapping between CPUs and GPU, (2) heuristic re-ranking to eliminate\nunnecessary I/Os and computations while guaranteeing high accuracy, and (3)\nredundant-aware I/O deduplication to further improve I/O efficiency. We\nimplement FusionANNS and compare it with the state-of-the-art SSD-based ANNS\nsystem \u2013 SPANN and GPU-accelerated in-memory ANNS system \u2013 RUMMY.\nExperimental results show that FusionANNS achieves 1) 9.4-13.1X higher query\nper second (QPS) and 5.7-8.8X higher cost efficiency compared with SPANN; 2)\nand 2-4.9X higher QPS and 2.3-6.8X higher cost efficiency compared with RUMMY,\nwhile guaranteeing low latency and high accuracy.</p>\n", "tags": ["Large Scale Search", "DATASETS", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [13.480886459350586, 20.95754051208496], "cluster": 0}, {"key": "tissier2018near", "year": "2018", "citations": "43", "title": "Near-lossless Binarization Of Word Embeddings", "abstract": "<p>Word embeddings are commonly used as a starting point in many NLP models to\nachieve state-of-the-art performances. However, with a large vocabulary and\nmany dimensions, these floating-point representations are expensive both in\nterms of memory and calculations which makes them unsuitable for use on\nlow-resource devices. The method proposed in this paper transforms real-valued\nembeddings into binary embeddings while preserving semantic information,\nrequiring only 128 or 256 bits for each vector. This leads to a small memory\nfootprint and fast vector operations. The model is based on an autoencoder\narchitecture, which also allows to reconstruct original vectors from the binary\nones. Experimental results on semantic similarity, text classification and\nsentiment analysis tasks show that the binarization of word embeddings only\nleads to a loss of ~2% in accuracy while vector size is reduced by 97%.\nFurthermore, a top-k benchmark demonstrates that using these binary vectors is\n30 times faster than using real-valued vectors.</p>\n", "tags": ["AAAI", "Hashing Methods", "Evaluation"], "tsne_embedding": [-10.960943222045898, -18.494253158569336], "cluster": 1}, {"key": "titus2018sig", "year": "2018", "citations": "13", "title": "SIG-DB: Leveraging Homomorphic Encryption To Securely Interrogate Privately Held Genomic Databases", "abstract": "<p>Genomic data are becoming increasingly valuable as we develop methods to\nutilize the information at scale and gain a greater understanding of how\ngenetic information relates to biological function. Advances in synthetic\nbiology and the decreased cost of sequencing are increasing the amount of\nprivately held genomic data. As the quantity and value of private genomic data\ngrows, so does the incentive to acquire and protect such data, which creates a\nneed to store and process these data securely. We present an algorithm for the\nSecure Interrogation of Genomic DataBases (SIG-DB). The SIG-DB algorithm\nenables databases of genomic sequences to be searched with an encrypted query\nsequence without revealing the query sequence to the Database Owner or any of\nthe database sequences to the Querier. SIG-DB is the first application of its\nkind to take advantage of locality-sensitive hashing and homomorphic encryption\nto allow generalized sequence-to-sequence comparisons of genomic data.</p>\n", "tags": ["Hashing Methods", "Evaluation"], "tsne_embedding": [8.840470314025879, -26.136432647705078], "cluster": 5}, {"key": "tizhoosh2016barcodes", "year": "2016", "citations": "16", "title": "Barcodes For Medical Image Retrieval Using Autoencoded Radon Transform", "abstract": "<p>Using content-based binary codes to tag digital images has emerged as a\npromising retrieval technology. Recently, Radon barcodes (RBCs) have been\nintroduced as a new binary descriptor for image search. RBCs are generated by\nbinarization of Radon projections and by assembling them into a vector, namely\nthe barcode. A simple local thresholding has been suggested for binarization.\nIn this paper, we put forward the idea of \u201cautoencoded Radon barcodes\u201d. Using\nimages in a training dataset, we autoencode Radon projections to perform\nbinarization on outputs of hidden layers. We employed the mini-batch stochastic\ngradient descent approach for the training. Each hidden layer of the\nautoencoder can produce a barcode using a threshold determined based on the\nrange of the logistic function used. The compressing capability of autoencoders\napparently reduces the redundancies inherent in Radon projections leading to\nmore accurate retrieval results. The IRMA dataset with 14,410 x-ray images is\nused to validate the performance of the proposed method. The experimental\nresults, containing comparison with RBCs, SURF and BRISK, show that autoencoded\nRadon barcode (ARBC) has the capacity to capture important information and to\nlearn richer representations resulting in lower retrieval errors for image\nretrieval measured with the accuracy of the first hit only.</p>\n", "tags": ["Compact Codes", "Image Retrieval", "DATASETS", "Evaluation"], "tsne_embedding": [-23.7925968170166, 15.215087890625], "cluster": 3}, {"key": "tizhoosh2016minmax", "year": "2016", "citations": "38", "title": "Minmax Radon Barcodes For Medical Image Retrieval", "abstract": "<p>Content-based medical image retrieval can support diagnostic decisions by\nclinical experts. Examining similar images may provide clues to the expert to\nremove uncertainties in his/her final diagnosis. Beyond conventional feature\ndescriptors, binary features in different ways have been recently proposed to\nencode the image content. A recent proposal is \u201cRadon barcodes\u201d that employ\nbinarized Radon projections to tag/annotate medical images with content-based\nbinary vectors, called barcodes. In this paper, MinMax Radon barcodes are\nintroduced which are superior to \u201clocal thresholding\u201d scheme suggested in the\nliterature. Using IRMA dataset with 14,410 x-ray images from 193 different\nclasses, the advantage of using MinMax Radon barcodes over <em>thresholded</em>\nRadon barcodes are demonstrated. The retrieval error for direct search drops by\nmore than 15%. As well, SURF, as a well-established non-binary approach, and\nBRISK, as a recent binary method are examined to compare their results with\nMinMax Radon barcodes when retrieving images from IRMA dataset. The results\ndemonstrate that MinMax Radon barcodes are faster and more accurate when\napplied on IRMA images.</p>\n", "tags": ["Image Retrieval", "DATASETS"], "tsne_embedding": [-23.69892692565918, 17.360044479370117], "cluster": 3}, {"key": "tolias2017asymmetric", "year": "2017", "citations": "39", "title": "Asymmetric Feature Maps With Application To Sketch Based Retrieval", "abstract": "<p>We propose a novel concept of asymmetric feature maps (AFM), which allows to\nevaluate multiple kernels between a query and database entries without\nincreasing the memory requirements. To demonstrate the advantages of the AFM\nmethod, we derive a short vector image representation that, due to asymmetric\nfeature maps, supports efficient scale and translation invariant sketch-based\nimage retrieval. Unlike most of the short-code based retrieval systems, the\nproposed method provides the query localization in the retrieved image. The\nefficiency of the search is boosted by approximating a 2D translation search\nvia trigonometric polynomial of scores by 1D projections. The projections are a\nspecial case of AFM. An order of magnitude speed-up is achieved compared to\ntraditional trigonometric polynomials. The results are boosted by an\nimage-based average query expansion, exceeding significantly the state of the\nart on standard benchmarks.</p>\n", "tags": ["CVPR", "Image Retrieval", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [21.047040939331055, 0.6146120429039001], "cluster": 7}, {"key": "torres2021compact", "year": "2021", "citations": "12", "title": "Compact And Effective Representations For Sketch-based Image Retrieval", "abstract": "<p>Sketch-based image retrieval (SBIR) has undergone an increasing interest in\nthe community of computer vision bringing high impact in real applications. For\ninstance, SBIR brings an increased benefit to eCommerce search engines because\nit allows users to formulate a query just by drawing what they need to buy.\nHowever, current methods showing high precision in retrieval work in a high\ndimensional space, which negatively affects aspects like memory consumption and\ntime processing. Although some authors have also proposed compact\nrepresentations, these drastically degrade the performance in a low dimension.\nTherefore in this work, we present different results of evaluating methods for\nproducing compact embeddings in the context of sketch-based image retrieval.\nOur main interest is in strategies aiming to keep the local structure of the\noriginal space. The recent unsupervised local-topology preserving dimension\nreduction method UMAP fits our requirements and shows outstanding performance,\nimproving even the precision achieved by SOTA methods. We evaluate six methods\nin two different datasets. We use Flickr15K and eCommerce datasets; the latter\nis another contribution of this work. We show that UMAP allows us to have\nfeature vectors of 16 bytes improving precision by more than 35%.</p>\n", "tags": ["Image Retrieval", "DATASETS", "CVPR", "Alt", "Evaluation"], "tsne_embedding": [-8.84306526184082, 12.990803718566895], "cluster": 6}, {"key": "tran2018device", "year": "2018", "citations": "38", "title": "On-device Scalable Image-based Localization Via Prioritized Cascade Search And Fast One-many RANSAC", "abstract": "<p>We present the design of an entire on-device system for large-scale urban\nlocalization using images. The proposed design integrates compact image\nretrieval and 2D-3D correspondence search to estimate the location in extensive\ncity regions. Our design is GPS agnostic and does not require network\nconnection. In order to overcome the resource constraints of mobile devices, we\npropose a system design that leverages the scalability advantage of image\nretrieval and accuracy of 3D model-based localization. Furthermore, we propose\na new hashing-based cascade search for fast computation of 2D-3D\ncorrespondences. In addition, we propose a new one-many RANSAC for accurate\npose estimation. The new one-many RANSAC addresses the challenge of repetitive\nbuilding structures (e.g. windows, balconies) in urban localization. Extensive\nexperiments demonstrate that our 2D-3D correspondence search achieves\nstate-of-the-art localization accuracy on multiple benchmark datasets.\nFurthermore, our experiments on a large Google Street View (GSV) image dataset\nshow the potential of large-scale localization entirely on a typical mobile\ndevice.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Evaluation"], "tsne_embedding": [3.70049786567688, 20.91605567932129], "cluster": 6}, {"key": "tripathi2024honeybee", "year": "2024", "citations": "9", "title": "Honeybee: A Scalable Modular Framework For Creating Multimodal Oncology Datasets With Foundational Embedding Models", "abstract": "<p>Developing accurate machine learning models for oncology requires\nlarge-scale, high-quality multimodal datasets. However, creating such datasets\nremains challenging due to the complexity and heterogeneity of medical data. To\naddress this challenge, we introduce HoneyBee, a scalable modular framework for\nbuilding multimodal oncology datasets that leverages foundation models to\ngenerate representative embeddings. HoneyBee integrates various data\nmodalities, including clinical diagnostic and pathology imaging data, medical\nnotes, reports, records, and molecular data. It employs data preprocessing\ntechniques and foundation models to generate embeddings that capture the\nessential features and relationships within the raw medical data. The generated\nembeddings are stored in a structured format using Hugging Face datasets and\nPyTorch dataloaders for accessibility. Vector databases enable efficient\nquerying and retrieval for machine learning applications. We demonstrate the\neffectiveness of HoneyBee through experiments assessing the quality and\nrepresentativeness of these embeddings. The framework is designed to be\nextensible to other medical domains and aims to accelerate oncology research by\nproviding high-quality, machine learning-ready datasets. HoneyBee is an ongoing\nopen-source effort, and the code, datasets, and models are available at the\nproject repository.</p>\n", "tags": ["DATASETS", "Tools & Libraries"], "tsne_embedding": [-23.153385162353516, 20.087982177734375], "cluster": 3}, {"key": "trivigno2023divide", "year": "2023", "citations": "7", "title": "Divide&classify: Fine-grained Classification For City-wide Visual Place Recognition", "abstract": "<p>Visual Place recognition is commonly addressed as an image retrieval problem.\nHowever, retrieval methods are impractical to scale to large datasets, densely\nsampled from city-wide maps, since their dimension impact negatively on the\ninference time. Using approximate nearest neighbour search for retrieval helps\nto mitigate this issue, at the cost of a performance drop. In this paper we\ninvestigate whether we can effectively approach this task as a classification\nproblem, thus bypassing the need for a similarity search. We find that existing\nclassification methods for coarse, planet-wide localization are not suitable\nfor the fine-grained and city-wide setting. This is largely due to how the\ndataset is split into classes, because these methods are designed to handle a\nsparse distribution of photos and as such do not consider the visual aliasing\nproblem across neighbouring classes that naturally arises in dense scenarios.\nThus, we propose a partitioning scheme that enables a fast and accurate\ninference, preserving a simple learning procedure, and a novel inference\npipeline based on an ensemble of novel classifiers that uses the prototypes\nlearned via an angular margin loss. Our method, Divide&amp;Classify (D&amp;C), enjoys\nthe fast inference of classification solutions and an accuracy competitive with\nretrieval methods on the fine-grained, city-wide setting. Moreover, we show\nthat D&amp;C can be paired with existing retrieval pipelines to speed up\ncomputations by over 20 times while increasing their recall, leading to new\nstate-of-the-art results.</p>\n", "tags": ["Image Retrieval", "DATASETS", "ICCV", "Similarity Search", "Evaluation"], "tsne_embedding": [-8.4710054397583, 12.237503051757812], "cluster": 6}, {"key": "tseng2020parallel", "year": "2020", "citations": "14", "title": "Parallel Index-based Structural Graph Clustering And Its Approximation", "abstract": "<p>SCAN (Structural Clustering Algorithm for Networks) is a well-studied, widely\nused graph clustering algorithm. For large graphs, however, sequential SCAN\nvariants are prohibitively slow, and parallel SCAN variants do not effectively\nshare work among queries with different SCAN parameter settings. Since users of\nSCAN often explore many parameter settings to find good clusterings, it is\nworthwhile to precompute an index that speeds up queries.\n  This paper presents a practical and provably efficient parallel index-based\nSCAN algorithm based on GS<em>-Index, a recent sequential algorithm. Our parallel\nalgorithm improves upon the asymptotic work of the sequential algorithm by\nusing integer sorting. It is also highly parallel, achieving logarithmic span\n(parallel time) for both index construction and clustering queries.\nFurthermore, we apply locality-sensitive hashing (LSH) to design a novel\napproximate SCAN algorithm and prove guarantees for its clustering behavior.\n  We present an experimental evaluation of our algorithms on large real-world\ngraphs. On a 48-core machine with two-way hyper-threading, our parallel index\nconstruction achieves 50\u2013151\\(\\times\\) speedup over the construction of\nGS</em>-Index. In fact, even on a single thread, our index construction algorithm\nis faster than GS<em>-Index. Our parallel index query implementation achieves\n5\u201332\\(\\times\\) speedup over GS</em>-Index queries across a range of SCAN parameter\nvalues, and our implementation is always faster than ppSCAN, a state-of-the-art\nparallel SCAN algorithm. Moreover, our experiments show that applying LSH\nresults in faster index construction while maintaining good clustering quality.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [18.440195083618164, 14.961427688598633], "cluster": 0}, {"key": "tu2018object", "year": "2018", "citations": "10", "title": "Object Detection Based Deep Unsupervised Hashing", "abstract": "<p>Recently, similarity-preserving hashing methods have been extensively studied\nfor large-scale image retrieval. Compared with unsupervised hashing, supervised\nhashing methods for labeled data have usually better performance by utilizing\nsemantic label information. Intuitively, for unlabeled data, it will improve\nthe performance of unsupervised hashing methods if we can first mine some\nsupervised semantic \u2018label information\u2019 from unlabeled data and then\nincorporate the \u2018label information\u2019 into the training process. Thus, in this\npaper, we propose a novel Object Detection based Deep Unsupervised Hashing\nmethod (ODDUH). Specifically, a pre-trained object detection model is utilized\nto mining supervised \u2018label information\u2019, which is used to guide the learning\nprocess to generate high-quality hash codes.Extensive experiments on two public\ndatasets demonstrate that the proposed method outperforms the state-of-the-art\nunsupervised hashing methods in the image retrieval task.</p>\n", "tags": ["DATASETS", "Evaluation", "IJCAI", "Hashing Methods", "Image Retrieval", "AAAI"], "tsne_embedding": [-18.48244285583496, -2.013378620147705], "cluster": 1}, {"key": "tu2019deep", "year": "2019", "citations": "62", "title": "Deep Cross-modal Hashing With Hashing Functions And Unified Hash Codes Jointly Learning", "abstract": "<p>Due to their high retrieval efficiency and low storage cost, cross-modal\nhashing methods have attracted considerable attention. Generally, compared with\nshallow cross-modal hashing methods, deep cross-modal hashing methods can\nachieve a more satisfactory performance by integrating feature learning and\nhash codes optimizing into a same framework. However, most existing deep\ncross-modal hashing methods either cannot learn a unified hash code for the two\ncorrelated data-points of different modalities in a database instance or cannot\nguide the learning of unified hash codes by the feedback of hashing function\nlearning procedure, to enhance the retrieval accuracy. To address the issues\nabove, in this paper, we propose a novel end-to-end Deep Cross-Modal Hashing\nwith Hashing Functions and Unified Hash Codes Jointly Learning (DCHUC).\nSpecifically, by an iterative optimization algorithm, DCHUC jointly learns\nunified hash codes for image-text pairs in a database and a pair of hash\nfunctions for unseen query image-text pairs. With the iterative optimization\nalgorithm, the learned unified hash codes can be used to guide the hashing\nfunction learning procedure; Meanwhile, the learned hashing functions can\nfeedback to guide the unified hash codes optimizing procedure. Extensive\nexperiments on three public datasets demonstrate that the proposed method\noutperforms the state-of-the-art cross-modal hashing methods.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-6.080248832702637, -3.6165623664855957], "cluster": 9}, {"key": "tu2020deep", "year": "2020", "citations": "34", "title": "Deep Cross-modal Hashing Via Margin-dynamic-softmax Loss", "abstract": "<p>Due to their high retrieval efficiency and low storage cost for cross-modal\nsearch task, cross-modal hashing methods have attracted considerable attention.\nFor the supervised cross-modal hashing methods, how to make the learned hash\ncodes preserve semantic information sufficiently contained in the label of\ndatapoints is the key to further enhance the retrieval performance. Hence,\nalmost all supervised cross-modal hashing methods usually depends on defining a\nsimilarity between datapoints with the label information to guide the hashing\nmodel learning fully or partly. However, the defined similarity between\ndatapoints can only capture the label information of datapoints partially and\nmisses abundant semantic information, then hinders the further improvement of\nretrieval performance. Thus, in this paper, different from previous works, we\npropose a novel cross-modal hashing method without defining the similarity\nbetween datapoints, called Deep Cross-modal Hashing via\n\\textit{Margin-dynamic-softmax Loss} (DCHML). Specifically, DCHML first trains\na proxy hashing network to transform each category information of a dataset\ninto a semantic discriminative hash code, called proxy hash code. Each proxy\nhash code can preserve the semantic information of its corresponding category\nwell. Next, without defining the similarity between datapoints to supervise the\ntraining process of the modality-specific hashing networks , we propose a novel\n\\textit{margin-dynamic-softmax loss} to directly utilize the proxy hashing\ncodes as supervised information. Finally, by minimizing the novel\n\\textit{margin-dynamic-softmax loss}, the modality-specific hashing networks\ncan be trained to generate hash codes which can simultaneously preserve the\ncross-modal similarity and abundant semantic information well.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [-6.1021342277526855, -2.3078725337982178], "cluster": 8}, {"key": "tu2022unsupervised", "year": "2022", "citations": "6", "title": "Unsupervised Hashing With Semantic Concept Mining", "abstract": "<p>Recently, to improve the unsupervised image retrieval performance, plenty of\nunsupervised hashing methods have been proposed by designing a semantic\nsimilarity matrix, which is based on the similarities between image features\nextracted by a pre-trained CNN model. However, most of these methods tend to\nignore high-level abstract semantic concepts contained in images. Intuitively,\nconcepts play an important role in calculating the similarity among images. In\nreal-world scenarios, each image is associated with some concepts, and the\nsimilarity between two images will be larger if they share more identical\nconcepts. Inspired by the above intuition, in this work, we propose a novel\nUnsupervised Hashing with Semantic Concept Mining, called UHSCM, which\nleverages a VLP model to construct a high-quality similarity matrix.\nSpecifically, a set of randomly chosen concepts is first collected. Then, by\nemploying a vision-language pretraining (VLP) model with the prompt engineering\nwhich has shown strong power in visual representation learning, the set of\nconcepts is denoised according to the training images. Next, the proposed\nmethod UHSCM applies the VLP model with prompting again to mine the concept\ndistribution of each image and construct a high-quality semantic similarity\nmatrix based on the mined concept distributions. Finally, with the semantic\nsimilarity matrix as guiding information, a novel hashing loss with a modified\ncontrastive loss based regularization item is proposed to optimize the hashing\nnetwork. Extensive experiments on three benchmark datasets show that the\nproposed method outperforms the state-of-the-art baselines in the image\nretrieval task.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Distance Metric Learning", "Evaluation"], "tsne_embedding": [-8.278632164001465, -0.04973660781979561], "cluster": 8}, {"key": "turati2023locality", "year": "2023", "citations": "6", "title": "Locality-sensitive Hashing Does Not Guarantee Privacy! Attacks On Google's Floc And The Minhash Hierarchy System", "abstract": "<p>Recently proposed systems aim at achieving privacy using locality-sensitive\nhashing. We show how these approaches fail by presenting attacks against two\nsuch systems: Google\u2019s FLoC proposal for privacy-preserving targeted\nadvertising and the MinHash Hierarchy, a system for processing mobile users\u2019\ntraffic behavior in a privacy-preserving way. Our attacks refute the pre-image\nresistance, anonymity, and privacy guarantees claimed for these systems.\n  In the case of FLoC, we show how to deanonymize users using Sybil attacks and\nto reconstruct 10% or more of the browsing history for 30% of its users using\nGenerative Adversarial Networks. We achieve this only analyzing the hashes used\nby FLoC. For MinHash, we precisely identify the movement of a subset of\nindividuals and, on average, we can limit users\u2019 movement to just 10% of the\npossible geographic area, again using just the hashes. In addition, we refute\ntheir differential privacy claims.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Robustness"], "tsne_embedding": [-13.715544700622559, 18.16830825805664], "cluster": 6}, {"key": "t\u011btek2021edge", "year": "2021", "citations": "8", "title": "Edge Sampling And Graph Parameter Estimation Via Vertex Neighborhood Accesses", "abstract": "<p>In this paper, we consider the problems from the area of sublinear-time\nalgorithms of edge sampling, edge counting, and triangle counting. Part of our\ncontribution is that we consider three different settings, differing in the way\nin which one may access the neighborhood of a given vertex. In previous work,\npeople have considered indexed neighbor access, with a query returning the\n\\(i\\)-th neighbor of a given vertex. Full neighborhood access model, which has a\nquery that returns the entire neighborhood at a unit cost, has recently been\nconsidered in the applied community. Between these, we propose hash-ordered\nneighbor access, inspired by coordinated sampling, where we have a global fully\nrandom hash function, and can access neighbors in order of their hash values,\npaying a constant for each accessed neighbor.\n  For edge sampling and counting, our new lower bounds are in the most powerful\nfull neighborhood access model. We provide matching upper bounds in the weaker\nhash-ordered neighbor access model. Our new faster algorithms can be provably\nimplemented efficiently on massive graphs in external memory and with the\ncurrent APIs for, e.g., Twitter or Wikipedia. For triangle counting, we provide\na separation: a better upper bound with full neighborhood access than the known\nlower bounds with indexed neighbor access. The technical core of our paper is\nour edge-sampling algorithm on which the other results depend.</p>\n", "tags": ["Tools & Libraries", "Hashing Methods"], "tsne_embedding": [18.3779239654541, 8.751596450805664], "cluster": 0}, {"key": "uchida2016image", "year": "2016", "citations": "13", "title": "Image Retrieval With Fisher Vectors Of Binary Features", "abstract": "<p>Recently, the Fisher vector representation of local features has attracted\nmuch attention because of its effectiveness in both image classification and\nimage retrieval. Another trend in the area of image retrieval is the use of\nbinary features such as ORB, FREAK, and BRISK. Considering the significant\nperformance improvement for accuracy in both image classification and retrieval\nby the Fisher vector of continuous feature descriptors, if the Fisher vector\nwere also to be applied to binary features, we would receive similar benefits\nin binary feature based image retrieval and classification. In this paper, we\nderive the closed-form approximation of the Fisher vector of binary features\nmodeled by the Bernoulli mixture model. We also propose accelerating the Fisher\nvector by using the approximate value of posterior probability. Experiments\nshow that the Fisher vector representation significantly improves the accuracy\nof image retrieval compared with a bag of binary words approach.</p>\n", "tags": ["Image Retrieval", "Evaluation"], "tsne_embedding": [-2.984440326690674, 11.993154525756836], "cluster": 6}, {"key": "ufer2021object", "year": "2021", "citations": "8", "title": "Object Retrieval And Localization In Large Art Collections Using Deep Multi-style Feature Fusion And Iterative Voting", "abstract": "<p>The search for specific objects or motifs is essential to art history as both\nassist in decoding the meaning of artworks. Digitization has produced large art\ncollections, but manual methods prove to be insufficient to analyze them. In\nthe following, we introduce an algorithm that allows users to search for image\nregions containing specific motifs or objects and find similar regions in an\nextensive dataset, helping art historians to analyze large digitized art\ncollections. Computer vision has presented efficient methods for visual\ninstance retrieval across photographs. However, applied to art collections,\nthey reveal severe deficiencies because of diverse motifs and massive domain\nshifts induced by differences in techniques, materials, and styles. In this\npaper, we present a multi-style feature fusion approach that successfully\nreduces the domain gap and improves retrieval results without labelled data or\ncurated image collections. Our region-based voting with GPU-accelerated\napproximate nearest-neighbour search allows us to find and localize even small\nmotifs within an extensive dataset in a few seconds. We obtain state-of-the-art\nresults on the Brueghel dataset and demonstrate its generalization to\ninhomogeneous collections with a large number of distractors.</p>\n", "tags": ["DATASETS"], "tsne_embedding": [-26.385465621948242, 10.11547565460205], "cluster": 3}, {"key": "um2019active", "year": "2019", "citations": "13", "title": "Active Search For Nearest Neighbors", "abstract": "<p>In pattern recognition or machine learning, it is a very fundamental task to\nfind nearest neighbors of a given point. All the methods for the task work\nbasically by comparing the given point to all the points in the data set. That\nis why the computational cost increases with the number of data points.\nHowever, the human visual system seems to work in a different way. When the\nhuman visual system tries to find the neighbors of one point on a map, it\ndirectly focuses on the area around the point and actively searches the\nneighbors by looking or zooming in and out around the point. In this paper, we\npropose an innovative search method for nearest neighbors, which seems very\nsimilar to how human visual system works on the task.</p>\n", "tags": ["Evaluation"], "tsne_embedding": [12.466464042663574, 7.600219249725342], "cluster": 0}, {"key": "uno2009efficient", "year": "2009", "citations": "10", "title": "Efficient Construction Of Neighborhood Graphs By The Multiple Sorting Method", "abstract": "<p>Neighborhood graphs are gaining popularity as a concise data representation\nin machine learning. However, naive graph construction by pairwise distance\ncalculation takes \\(O(n^2)\\) runtime for \\(n\\) data points and this is\nprohibitively slow for millions of data points. For strings of equal length,\nthe multiple sorting method (Uno, 2008) can construct an \\(\\epsilon\\)-neighbor\ngraph in \\(O(n+m)\\) time, where \\(m\\) is the number of \\(\\epsilon\\)-neighbor pairs in\nthe data. To introduce this remarkably efficient algorithm to continuous\ndomains such as images, signals and texts, we employ a random projection method\nto convert vectors to strings. Theoretical results are presented to elucidate\nthe trade-off between approximation quality and computation time. Empirical\nresults show the efficiency of our method in comparison to fast nearest\nneighbor alternatives.</p>\n", "tags": ["Locality Sensitive Hashing", "Graph Based ANN", "Efficiency And Optimization", "Alt", "Evaluation"], "tsne_embedding": [18.936199188232422, 9.696088790893555], "cluster": 0}, {"key": "vaiwsri2021accurate", "year": "2021", "citations": "7", "title": "Accurate And Efficient Suffix Tree Based Privacy-preserving String Matching", "abstract": "<p>The task of calculating similarities between strings held by different\norganizations without revealing these strings is an increasingly important\nproblem in areas such as health informatics, national censuses, genomics, and\nfraud detection. Most existing privacy-preserving string comparison functions\nare either based on comparing sets of encoded character q-grams, allow only\nexact matching of encrypted strings, or they are aimed at long genomic\nsequences that have a small alphabet. The set-based privacy-preserving\nsimilarity functions commonly used to compare name and address strings in the\ncontext of privacy-preserving record linkage do not take the positions of\nsub-strings into account. As a result, two very different strings can\npotentially be considered as an exact match leading to wrongly linked records.\nExisting set-based techniques also cannot identify the length of the longest\ncommon sub-string across two strings. In this paper we propose a novel approach\nfor accurate and efficient privacy-preserving string matching based on suffix\ntrees that are encoded using chained hashing. We incorporate a hashing based\nencoding technique upon the encoded suffixes to improve privacy against\nfrequency attacks such as those exploiting Benford\u2019s law. Our approach allows\nvarious operations to be performed without the strings to be compared being\nrevealed: the length of the longest common sub-string, do two strings have the\nsame beginning, middle or end, and the longest common sub-string similarity\nbetween two strings. These functions allow a more accurate comparison of, for\nexample, bank account, credit card, or telephone numbers, which cannot be\ncompared appropriately with existing privacy-preserving string matching\ntechniques. Our evaluation on several data sets with different types of strings\nvalidates the privacy and accuracy of our proposed approach.</p>\n", "tags": ["Alt", "Hashing Methods", "Evaluation"], "tsne_embedding": [10.080044746398926, -21.923486709594727], "cluster": 5}, {"key": "valsesia2017binary", "year": "2017", "citations": "13", "title": "Binary Adaptive Embeddings From Order Statistics Of Random Projections", "abstract": "<p>We use some of the largest order statistics of the random projections of a\nreference signal to construct a binary embedding that is adapted to signals\ncorrelated with such signal. The embedding is characterized from the analytical\nstandpoint and shown to provide improved performance on tasks such as\nclassification in a reduced-dimensionality space.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Evaluation"], "tsne_embedding": [23.576078414916992, -8.859745979309082], "cluster": 7}, {"key": "vanblokland2020indexing", "year": "2020", "citations": "14", "title": "An Indexing Scheme And Descriptor For 3D Object Retrieval Based On Local Shape Querying", "abstract": "<p>A binary descriptor indexing scheme based on Hamming distance called the\nHamming tree for local shape queries is presented. A new binary clutter\nresistant descriptor named Quick Intersection Count Change Image (QUICCI) is\nalso introduced. This local shape descriptor is extremely small and fast to\ncompare. Additionally, a novel distance function called Weighted Hamming\napplicable to QUICCI images is proposed for retrieval applications. The\neffectiveness of the indexing scheme and QUICCI is demonstrated on 828 million\nQUICCI images derived from the SHREC2017 dataset, while the clutter resistance\nof QUICCI is shown using the clutterbox experiment.</p>\n", "tags": ["DATASETS"], "tsne_embedding": [1.8748527765274048, 11.166537284851074], "cluster": 6}, {"key": "vanblokland2021partial", "year": "2021", "citations": "6", "title": "Partial 3D Object Retrieval Using Local Binary QUICCI Descriptors And Dissimilarity Tree Indexing", "abstract": "<p>A complete pipeline is presented for accurate and efficient partial 3D object\nretrieval based on Quick Intersection Count Change Image (QUICCI) binary local\ndescriptors and a novel indexing tree. It is shown how a modification to the\nQUICCI query descriptor makes it ideal for partial retrieval. An indexing\nstructure called Dissimilarity Tree is proposed which can significantly\naccelerate searching the large space of local descriptors; this is applicable\nto QUICCI and other binary descriptors. The index exploits the distribution of\nbits within descriptors for efficient retrieval. The retrieval pipeline is\ntested on the artificial part of SHREC\u201916 dataset with near-ideal retrieval\nresults.</p>\n", "tags": ["DATASETS", "Similarity Search"], "tsne_embedding": [0.47723808884620667, 11.902300834655762], "cluster": 6}, {"key": "vasudeva2021loop", "year": "2021", "citations": "12", "title": "Loop: Looking For Optimal Hard Negative Embeddings For Deep Metric Learning", "abstract": "<p>Deep metric learning has been effectively used to learn distance metrics for\ndifferent visual tasks like image retrieval, clustering, etc. In order to aid\nthe training process, existing methods either use a hard mining strategy to\nextract the most informative samples or seek to generate hard synthetics using\nan additional network. Such approaches face different challenges and can lead\nto biased embeddings in the former case, and (i) harder optimization (ii)\nslower training speed (iii) higher model complexity in the latter case. In\norder to overcome these challenges, we propose a novel approach that looks for\noptimal hard negatives (LoOp) in the embedding space, taking full advantage of\neach tuple by calculating the minimum distance between a pair of positives and\na pair of negatives. Unlike mining-based methods, our approach considers the\nentire space between pairs of embeddings to calculate the optimal hard\nnegatives. Extensive experiments combining our approach and representative\nmetric learning losses reveal a significant boost in performance on three\nbenchmark datasets.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Distance Metric Learning", "ICCV", "Evaluation"], "tsne_embedding": [-19.728836059570312, 5.066900253295898], "cluster": 3}, {"key": "venkateswara2017deep", "year": "2017", "citations": "1690", "title": "Deep Hashing Network For Unsupervised Domain Adaptation", "abstract": "<p>In recent years, deep neural networks have emerged as a dominant machine\nlearning tool for a wide variety of application domains. However, training a\ndeep neural network requires a large amount of labeled data, which is an\nexpensive process in terms of time, labor and human expertise. Domain\nadaptation or transfer learning algorithms address this challenge by leveraging\nlabeled data in a different, but related source domain, to develop a model for\nthe target domain. Further, the explosive growth of digital data has posed a\nfundamental challenge concerning its storage and retrieval. Due to its storage\nand retrieval efficiency, recent years have witnessed a wide application of\nhashing in a variety of computer vision applications. In this paper, we first\nintroduce a new dataset, Office-Home, to evaluate domain adaptation algorithms.\nThe dataset contains images of a variety of everyday objects from multiple\ndomains. We then propose a novel deep learning framework that can exploit\nlabeled source data and unlabeled target data to learn informative hash codes,\nto accurately classify unseen target data. To the best of our knowledge, this\nis the first research effort to exploit the feature learning capabilities of\ndeep neural networks to learn representative hash codes to address the domain\nadaptation problem. Our extensive empirical studies on multiple transfer tasks\ncorroborate the usefulness of the framework in learning efficient hash codes\nwhich outperform existing competitive baselines for unsupervised domain\nadaptation.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "CVPR", "Neural Hashing", "Tools & Libraries"], "tsne_embedding": [-20.263099670410156, -6.382632255554199], "cluster": 1}, {"key": "verma2025faster", "year": "2025", "citations": "52", "title": "Faster And Space Efficient Indexing For Locality Sensitive Hashing", "abstract": "<p>This work suggests faster and space-efficient index construction algorithms\nfor LSH for Euclidean distance (\\textit{a.k.a.}~\\ELSH) and cosine similarity\n(\\textit{a.k.a.}~\\SRP). The index construction step of these LSHs relies on\ngrouping data points into several bins of hash tables based on their hashcode.\nTo generate an \\(m\\)-dimensional hashcode of the \\(d\\)-dimensional data point,\nthese LSHs first project the data point onto a \\(d\\)-dimensional random Gaussian\nvector and then discretise the resulting inner product. The time and space\ncomplexity of both \\ELSH~and \\SRP~for computing an \\(m\\)-sized hashcode of a\n\\(d\\)-dimensional vector is \\(O(md)\\), which becomes impractical for large values\nof \\(m\\) and \\(d\\). To overcome this problem, we propose two alternative LSH\nhashcode generation algorithms both for Euclidean distance and cosine\nsimilarity, namely, \\CSELSH, \\HCSELSH~and \\CSSRP, \\HCSSRP, respectively.\n\\CSELSH~and \\CSSRP~are based on count sketch \\cite{count_sketch} and\n\\HCSELSH~and \\HCSSRP~utilize higher-order count sketch \\cite{shi2019higher}.\nThese proposals significantly reduce the hashcode computation time from \\(O(md)\\)\nto \\(O(d)\\). Additionally, both \\CSELSH~and \\CSSRP~reduce the space complexity\nfrom \\(O(md)\\) to \\(O(d)\\); ~and \\HCSELSH, \\HCSSRP~ reduce the space complexity\nfrom \\(O(md)\\) to \\(O(N \\sqrt[N]{d})\\) respectively, where \\(N\\geq 1\\) denotes the\nsize of the input/reshaped tensor. Our proposals are backed by strong\nmathematical guarantees, and we validate their performance through simulations\non various real-world datasets.</p>\n", "tags": ["CIKM", "Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Distance Metric Learning", "Alt", "Evaluation"], "tsne_embedding": [30.0848445892334, -0.09624446928501129], "cluster": 7}, {"key": "wagner2023fast", "year": "2023", "citations": "1523", "title": "Fast Private Kernel Density Estimation Via Locality Sensitive Quantization", "abstract": "<p>We study efficient mechanisms for differentially private kernel density\nestimation (DP-KDE). Prior work for the Gaussian kernel described algorithms\nthat run in time exponential in the number of dimensions \\(d\\). This paper breaks\nthe exponential barrier, and shows how the KDE can privately be approximated in\ntime linear in \\(d\\), making it feasible for high-dimensional data. We also\npresent improved bounds for low-dimensional data.\n  Our results are obtained through a general framework, which we term Locality\nSensitive Quantization (LSQ), for constructing private KDE mechanisms where\nexisting KDE approximation techniques can be applied. It lets us leverage\nseveral efficient non-private KDE methods \u2013 like Random Fourier Features, the\nFast Gauss Transform, and Locality Sensitive Hashing \u2013 and ``privatize\u2019\u2019 them\nin a black-box manner. Our experiments demonstrate that our resulting DP-KDE\nmechanisms are fast and accurate on large datasets in both high and low\ndimensions.</p>\n", "tags": ["Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Quantization", "Tools & Libraries"], "tsne_embedding": [12.966836929321289, -20.017793655395508], "cluster": 2}, {"key": "wald2022gpu", "year": "2022", "citations": "18", "title": "Gpu-friendly, Parallel, And (almost-)in-place Construction Of Left-balanced K-d Trees", "abstract": "<p>We present an algorithm that allows for building left-balanced and complete\nk-d trees over k-dimensional points in a trivially parallel and GPU friendly\nway. Our algorithm requires exactly one int per data point as temporary\nstorage, and uses O(log N) iterations, each of which performs one parallel\nsort, and one trivially parallel CUDA per-node update kernel.</p>\n", "tags": ["Tree Based ANN"], "tsne_embedding": [23.02699089050293, -14.530623435974121], "cluster": 2}, {"key": "wang2010efficient", "year": "2010", "citations": "5", "title": "Efficient K-nearest Neighbor Join Algorithms For High Dimensional Sparse Data", "abstract": "<p>The K-Nearest Neighbor (KNN) join is an expensive but important operation in\nmany data mining algorithms. Several recent applications need to perform KNN\njoin for high dimensional sparse data. Unfortunately, all existing KNN join\nalgorithms are designed for low dimensional data. To fulfill this void, we\ninvestigate the KNN join problem for high dimensional sparse data.\n  In this paper, we propose three KNN join algorithms: a brute force (BF)\nalgorithm, an inverted index-based(IIB) algorithm and an improved inverted\nindex-based(IIIB) algorithm. Extensive experiments on both synthetic and\nreal-world datasets were conducted to demonstrate the effectiveness of our\nalgorithms for high dimensional sparse data.</p>\n", "tags": ["DATASETS"], "tsne_embedding": [14.243939399719238, -5.97430944442749], "cluster": 2}, {"key": "wang2016comprehensive", "year": "2016", "citations": "230", "title": "A Comprehensive Survey On Cross-modal Retrieval", "abstract": "<p>In recent years, cross-modal retrieval has drawn much attention due to the\nrapid growth of multimodal data. It takes one type of data as the query to\nretrieve relevant data of another type. For example, a user can use a text to\nretrieve relevant pictures or videos. Since the query and its retrieved results\ncan be of different modalities, how to measure the content similarity between\ndifferent modalities of data remains a challenge. Various methods have been\nproposed to deal with such a problem. In this paper, we first review a number\nof representative methods for cross-modal retrieval and classify them into two\nmain groups: 1) real-valued representation learning, and 2) binary\nrepresentation learning. Real-valued representation learning methods aim to\nlearn real-valued common representations for different modalities of data. To\nspeed up the cross-modal retrieval, a number of binary representation learning\nmethods are proposed to map different modalities of data into a common Hamming\nspace. Then, we introduce several multimodal datasets in the community, and\nshow the experimental results on two commonly used multimodal datasets. The\ncomparison reveals the characteristic of different kinds of cross-modal\nretrieval methods, which is expected to benefit both practical applications and\nfuture research. Finally, we discuss open problems and future research\ndirections.</p>\n", "tags": ["Survey Paper", "DATASETS", "Hashing Methods", "Multimodal Retrieval", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-26.717761993408203, 6.145975112915039], "cluster": 3}, {"key": "wang2016contextual", "year": "2016", "citations": "7", "title": "Contextual Visual Similarity", "abstract": "<p>Measuring visual similarity is critical for image understanding. But what\nmakes two images similar? Most existing work on visual similarity assumes that\nimages are similar because they contain the same object instance or category.\nHowever, the reason why images are similar is much more complex. For example,\nfrom the perspective of category, a black dog image is similar to a white dog\nimage. However, in terms of color, a black dog image is more similar to a black\nhorse image than the white dog image. This example serves to illustrate that\nvisual similarity is ambiguous but can be made precise when given an explicit\ncontextual perspective. Based on this observation, we propose the concept of\ncontextual visual similarity. To be concrete, we examine the concept of\ncontextual visual similarity in the application domain of image search. Instead\nof providing only a single image for image similarity search (\\eg, Google image\nsearch), we require three images. Given a query image, a second positive image\nand a third negative image, dissimilar to the first two images, we define a\ncontextualized similarity search criteria. In particular, we learn feature\nweights over all the feature dimensions of each image such that the distance\nbetween the query image and the positive image is small and their distances to\nthe negative image are large after reweighting their features. The learned\nfeature weights encode the contextualized visual similarity specified by the\nuser and can be used for attribute specific image search. We also show the\nusefulness of our contextualized similarity weighting scheme for different\ntasks, such as answering visual analogy questions and unsupervised attribute\ndiscovery.</p>\n", "tags": ["Image Retrieval", "Similarity Search", "Graph Based ANN"], "tsne_embedding": [6.406620025634766, 10.754572868347168], "cluster": 4}, {"key": "wang2016deep", "year": "2016", "citations": "191", "title": "Deep Supervised Hashing With Triplet Labels", "abstract": "<p>Hashing is one of the most popular and powerful approximate nearest neighbor\nsearch techniques for large-scale image retrieval. Most traditional hashing\nmethods first represent images as off-the-shelf visual features and then\nproduce hashing codes in a separate stage. However, off-the-shelf visual\nfeatures may not be optimally compatible with the hash code learning procedure,\nwhich may result in sub-optimal hash codes. Recently, deep hashing methods have\nbeen proposed to simultaneously learn image features and hash codes using deep\nneural networks and have shown superior performance over traditional hashing\nmethods. Most deep hashing methods are given supervised information in the form\nof pairwise labels or triplet labels. The current state-of-the-art deep hashing\nmethod DPSH~\\cite{li2015feature}, which is based on pairwise labels, performs\nimage feature learning and hash code learning simultaneously by maximizing the\nlikelihood of pairwise similarities. Inspired by DPSH~\\cite{li2015feature}, we\npropose a triplet label based deep hashing method which aims to maximize the\nlikelihood of the given triplet labels. Experimental results show that our\nmethod outperforms all the baselines on CIFAR-10 and NUS-WIDE datasets,\nincluding the state-of-the-art method DPSH~\\cite{li2015feature} and all the\nprevious triplet label based deep hashing methods.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Neural Hashing", "Evaluation"], "tsne_embedding": [-9.493325233459473, 4.6233601570129395], "cluster": 8}, {"key": "wang2016survey", "year": "2016", "citations": "920", "title": "A Survey On Learning To Hash", "abstract": "<p>Nearest neighbor search is a problem of finding the data points from the\ndatabase such that the distances from them to the query point are the smallest.\nLearning to hash is one of the major solutions to this problem and has been\nwidely studied recently. In this paper, we present a comprehensive survey of\nthe learning to hash algorithms, categorize them according to the manners of\npreserving the similarities into: pairwise similarity preserving, multiwise\nsimilarity preserving, implicit similarity preserving, as well as quantization,\nand discuss their relations. We separate quantization from pairwise similarity\npreserving as the objective function is very different though quantization, as\nwe show, can be derived from preserving the pairwise similarities. In addition,\nwe present the evaluation protocols, and the general performance analysis, and\npoint out that the quantization algorithms perform superiorly in terms of\nsearch accuracy, search time cost, and space cost. Finally, we introduce a few\nemerging topics.</p>\n", "tags": ["Survey Paper", "Quantization", "Hashing Methods", "Evaluation"], "tsne_embedding": [0.5672733783721924, -4.697884559631348], "cluster": 9}, {"key": "wang2016unsupervised", "year": "2016", "citations": "22", "title": "Unsupervised Cross-media Hashing With Structure Preservation", "abstract": "<p>Recent years have seen the exponential growth of heterogeneous multimedia\ndata. The need for effective and accurate data retrieval from heterogeneous\ndata sources has attracted much research interest in cross-media retrieval.\nHere, given a query of any media type, cross-media retrieval seeks to find\nrelevant results of different media types from heterogeneous data sources. To\nfacilitate large-scale cross-media retrieval, we propose a novel unsupervised\ncross-media hashing method. Our method incorporates local affinity and distance\nrepulsion constraints into a matrix factorization framework. Correspondingly,\nthe proposed method learns hash functions that generates unified hash codes\nfrom different media types, while ensuring intrinsic geometric structure of the\ndata distribution is preserved. These hash codes empower the similarity between\ndata of different media types to be evaluated directly. Experimental results on\ntwo large-scale multimedia datasets demonstrate the effectiveness of the\nproposed method, where we outperform the state-of-the-art methods.</p>\n", "tags": ["DATASETS", "Tools & Libraries", "Hashing Methods"], "tsne_embedding": [-3.527845859527588, 15.472312927246094], "cluster": 6}, {"key": "wang2017composite", "year": "2017", "citations": "197", "title": "Composite Quantization", "abstract": "<p>This paper studies the compact coding approach to approximate nearest\nneighbor search. We introduce a composite quantization framework. It uses the\ncomposition of several (\\(M\\)) elements, each of which is selected from a\ndifferent dictionary, to accurately approximate a \\(D\\)-dimensional vector, thus\nyielding accurate search, and represents the data vector by a short code\ncomposed of the indices of the selected elements in the corresponding\ndictionaries. Our key contribution lies in introducing a near-orthogonality\nconstraint, which makes the search efficiency is guaranteed as the cost of the\ndistance computation is reduced to \\(O(M)\\) from \\(O(D)\\) through a distance table\nlookup scheme. The resulting approach is called near-orthogonal composite\nquantization. We theoretically justify the equivalence between near-orthogonal\ncomposite quantization and minimizing an upper bound of a function formed by\njointly considering the quantization error and the search cost according to a\ngeneralized triangle inequality. We empirically show the efficacy of the\nproposed approach over several benchmark datasets. In addition, we demonstrate\nthe superior performances in other three applications: combination with\ninverted multi-index, quantizing the query for mobile search, and inner-product\nsimilarity search.</p>\n", "tags": ["DATASETS", "Efficiency And Optimization", "Similarity Search", "Quantization", "Vector Indexing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [23.38780403137207, -1.1898813247680664], "cluster": 7}, {"key": "wang2017flash", "year": "2017", "citations": "9", "title": "FLASH: Randomized Algorithms Accelerated Over CPU-GPU For Ultra-high Dimensional Similarity Search", "abstract": "<p>We present FLASH (\\textbf{F}ast \\textbf{L}SH \\textbf{A}lgorithm for\n\\textbf{S}imilarity search accelerated with \\textbf{H}PC), a similarity search\nsystem for ultra-high dimensional datasets on a single machine, that does not\nrequire similarity computations and is tailored for high-performance computing\nplatforms. By leveraging a LSH style randomized indexing procedure and\ncombining it with several principled techniques, such as reservoir sampling,\nrecent advances in one-pass minwise hashing, and count based estimations, we\nreduce the computational and parallelization costs of similarity search, while\nretaining sound theoretical guarantees.\n  We evaluate FLASH on several real, high-dimensional datasets from different\ndomains, including text, malicious URL, click-through prediction, social\nnetworks, etc. Our experiments shed new light on the difficulties associated\nwith datasets having several million dimensions. Current state-of-the-art\nimplementations either fail on the presented scale or are orders of magnitude\nslower than FLASH. FLASH is capable of computing an approximate k-NN graph,\nfrom scratch, over the full webspam dataset (1.3 billion nonzeros) in less than\n10 seconds. Computing a full k-NN graph in less than 10 seconds on the webspam\ndataset, using brute-force (\\(n^2D\\)), will require at least 20 teraflops. We\nprovide CPU and GPU implementations of FLASH for replicability of our results.</p>\n", "tags": ["Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Similarity Search", "Evaluation"], "tsne_embedding": [4.87056827545166, 14.749528884887695], "cluster": 6}, {"key": "wang2017subspace", "year": "2017", "citations": "56", "title": "Subspace Approximation For Approximate Nearest Neighbor Search In NLP", "abstract": "<p>Most natural language processing tasks can be formulated as the approximated\nnearest neighbor search problem, such as word analogy, document similarity,\nmachine translation. Take the question-answering task as an example, given a\nquestion as the query, the goal is to search its nearest neighbor in the\ntraining dataset as the answer. However, existing methods for approximate\nnearest neighbor search problem may not perform well owing to the following\npractical challenges: 1) there are noise in the data; 2) the large scale\ndataset yields a huge retrieval space and high search time complexity.\n  In order to solve these problems, we propose a novel approximate nearest\nneighbor search framework which i) projects the data to a subspace based\nspectral analysis which eliminates the influence of noise; ii) partitions the\ntraining dataset to different groups in order to reduce the search space.\nSpecifically, the retrieval space is reduced from \\(O(n)\\) to \\(O(log n)\\) (where\n\\(n\\) is the number of data points in the training dataset). We prove that the\nretrieved nearest neighbor in the projected subspace is the same as the one in\nthe original feature space. We demonstrate the outstanding performance of our\nframework on real-world natural language processing tasks.</p>\n", "tags": ["Graph Based ANN", "DATASETS", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-16.9802303314209, 2.4649100303649902], "cluster": 3}, {"key": "wang2017supervised", "year": "2017", "citations": "26", "title": "Supervised Deep Hashing For Hierarchical Labeled Data", "abstract": "<p>Recently, hashing methods have been widely used in large-scale image\nretrieval. However, most existing hashing methods did not consider the\nhierarchical relation of labels, which means that they ignored the rich\ninformation stored in the hierarchy. Moreover, most of previous works treat\neach bit in a hash code equally, which does not meet the scenario of\nhierarchical labeled data. In this paper, we propose a novel deep hashing\nmethod, called supervised hierarchical deep hashing (SHDH), to perform hash\ncode learning for hierarchical labeled data. Specifically, we define a novel\nsimilarity formula for hierarchical labeled data by weighting each layer, and\ndesign a deep convolutional neural network to obtain a hash code for each data\npoint. Extensive experiments on several real-world public datasets show that\nthe proposed method outperforms the state-of-the-art baselines in the image\nretrieval task.</p>\n", "tags": ["AAAI", "DATASETS", "Neural Hashing", "Hashing Methods"], "tsne_embedding": [-7.716341972351074, 5.35609769821167], "cluster": 8}, {"key": "wang2018deep", "year": "2018", "citations": "45", "title": "Deep Metric Learning By Online Soft Mining And Class-aware Attention", "abstract": "<p>Deep metric learning aims to learn a deep embedding that can capture the\nsemantic similarity of data points. Given the availability of massive training\nsamples, deep metric learning is known to suffer from slow convergence due to a\nlarge fraction of trivial samples. Therefore, most existing methods generally\nresort to sample mining strategies for selecting nontrivial samples to\naccelerate convergence and improve performance. In this work, we identify two\ncritical limitations of the sample mining methods, and provide solutions for\nboth of them. First, previous mining methods assign one binary score to each\nsample, i.e., dropping or keeping it, so they only selects a subset of relevant\nsamples in a mini-batch. Therefore, we propose a novel sample mining method,\ncalled Online Soft Mining (OSM), which assigns one continuous score to each\nsample to make use of all samples in the mini-batch. OSM learns extended\nmanifolds that preserve useful intraclass variances by focusing on more similar\npositives. Second, the existing methods are easily influenced by outliers as\nthey are generally included in the mined subset. To address this, we introduce\nClass-Aware Attention (CAA) that assigns little attention to abnormal data\nsamples. Furthermore, by combining OSM and CAA, we propose a novel weighted\ncontrastive loss to learn discriminative embeddings. Extensive experiments on\ntwo fine-grained visual categorisation datasets and two video-based person\nre-identification benchmarks show that our method significantly outperforms the\nstate-of-the-art.</p>\n", "tags": ["AAAI", "DATASETS", "Distance Metric Learning", "Evaluation"], "tsne_embedding": [-19.545320510864258, 3.2278332710266113], "cluster": 3}, {"key": "wang2019cluster", "year": "2019", "citations": "25", "title": "Cluster-wise Unsupervised Hashing For Cross-modal Similarity Search", "abstract": "<p>Large-scale cross-modal hashing similarity retrieval has attracted more and\nmore attention in modern search applications such as search engines and\nautopilot, showing great superiority in computation and storage. However,\ncurrent unsupervised cross-modal hashing methods still have some limitations:\n(1)many methods relax the discrete constraints to solve the optimization\nobjective which may significantly degrade the retrieval performance;(2)most\nexisting hashing model project heterogenous data into a common latent space,\nwhich may always lose sight of diversity in heterogenous data;(3)transforming\nreal-valued data point to binary codes always results in abundant loss of\ninformation, producing the suboptimal continuous latent space. To overcome\nabove problems, in this paper, a novel Cluster-wise Unsupervised Hashing (CUH)\nmethod is proposed. Specifically, CUH jointly performs the multi-view\nclustering that projects the original data points from different modalities\ninto its own low-dimensional latent semantic space and finds the cluster\ncentroid points and the common clustering indicators in its own low-dimensional\nspace, and learns the compact hash codes and the corresponding linear hash\nfunctions. An discrete optimization framework is developed to learn the unified\nbinary codes across modalities under the guidance cluster-wise code-prototypes.\nThe reasonableness and effectiveness of CUH is well demonstrated by\ncomprehensive experiments on diverse benchmark datasets.</p>\n", "tags": ["DATASETS", "Hashing Methods", "CVPR", "Compact Codes", "Similarity Search", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-4.93271541595459, -4.0947771072387695], "cluster": 9}, {"key": "wang2019cross", "year": "2019", "citations": "228", "title": "Cross-batch Memory For Embedding Learning", "abstract": "<p>Mining informative negative instances are of central importance to deep\nmetric learning (DML), however this task is intrinsically limited by mini-batch\ntraining, where only a mini-batch of instances is accessible at each iteration.\nIn this paper, we identify a \u201cslow drift\u201d phenomena by observing that the\nembedding features drift exceptionally slow even as the model parameters are\nupdating throughout the training process. This suggests that the features of\ninstances computed at preceding iterations can be used to considerably\napproximate their features extracted by the current model. We propose a\ncross-batch memory (XBM) mechanism that memorizes the embeddings of past\niterations, allowing the model to collect sufficient hard negative pairs across\nmultiple mini-batches - even over the whole dataset. Our XBM can be directly\nintegrated into a general pair-based DML framework, where the XBM augmented DML\ncan boost performance considerably. In particular, without bells and whistles,\na simple contrastive loss with our XBM can have large R@1 improvements of\n12%-22.5% on three large-scale image retrieval datasets, surpassing the most\nsophisticated state-of-the-art methods, by a large margin. Our XBM is\nconceptually simple, easy to implement - using several lines of codes, and is\nmemory efficient - with a negligible 0.2 GB extra GPU memory. Code is available\nat: https://github.com/MalongTech/research-xbm.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Distance Metric Learning", "CVPR", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-19.57188606262207, 3.02996826171875], "cluster": 3}, {"key": "wang2019deep", "year": "2019", "citations": "39", "title": "Deep Collaborative Discrete Hashing With Semantic-invariant Structure", "abstract": "<p>Existing deep hashing approaches fail to fully explore semantic correlations\nand neglect the effect of linguistic context on visual attention learning,\nleading to inferior performance. This paper proposes a dual-stream learning\nframework, dubbed Deep Collaborative Discrete Hashing (DCDH), which constructs\na discriminative common discrete space by collaboratively incorporating the\nshared and individual semantics deduced from visual features and semantic\nlabels. Specifically, the context-aware representations are generated by\nemploying the outer product of visual embeddings and semantic encodings.\nMoreover, we reconstruct the labels and introduce the focal loss to take\nadvantage of frequent and rare concepts. The common binary code space is built\non the joint learning of the visual representations attended by language, the\nsemantic-invariant structure construction and the label distribution\ncorrection. Extensive experiments demonstrate the superiority of our method.</p>\n", "tags": ["Hashing Methods", "Compact Codes", "Neural Hashing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-19.61517906188965, -2.975198984146118], "cluster": 1}, {"key": "wang2019fpscreen", "year": "2019", "citations": "647", "title": "Fpscreen: A Rapid Similarity Search Tool For Massive Molecular Library Based On Molecular Fingerprint Comparison", "abstract": "<p>We designed a fast similarity search engine for large molecular libraries:\nFPScreen. We downloaded 100 million molecules\u2019 structure files in PubChem with\nSDF extension, then applied a computational chemistry tool RDKit to convert\neach structure file into one line of text in MACCS format and stored them in a\ntext file as our molecule library. The similarity search engine compares the\nsimilarity while traversing the 166-bit strings in the library file line by\nline. FPScreen can complete similarity search through 100 million entries in\nour molecule library within one hour. That is very fast as a biology\ncomputation tool. Additionally, we divided our library into several strides for\nparallel processing. FPScreen was developed in WEB mode.</p>\n", "tags": ["Hashing Methods", "Similarity Search", "Tools & Libraries", "EMNLP", "Evaluation"], "tsne_embedding": [7.486940383911133, -17.659379959106445], "cluster": 2}, {"key": "wang2019fusion", "year": "2019", "citations": "15", "title": "Fusion-supervised Deep Cross-modal Hashing", "abstract": "<p>Deep hashing has recently received attention in cross-modal retrieval for its\nimpressive advantages. However, existing hashing methods for cross-modal\nretrieval cannot fully capture the heterogeneous multi-modal correlation and\nexploit the semantic information. In this paper, we propose a novel\n<em>Fusion-supervised Deep Cross-modal Hashing</em> (FDCH) approach. Firstly,\nFDCH learns unified binary codes through a fusion hash network with paired\nsamples as input, which effectively enhances the modeling of the correlation of\nheterogeneous multi-modal data. Then, these high-quality unified hash codes\nfurther supervise the training of the modality-specific hash networks for\nencoding out-of-sample queries. Meanwhile, both pair-wise similarity\ninformation and classification information are embedded in the hash networks\nunder one stream framework, which simultaneously preserves cross-modal\nsimilarity and keeps semantic consistency. Experimental results on two\nbenchmark datasets demonstrate the state-of-the-art performance of FDCH.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Compact Codes", "Neural Hashing", "Multimodal Retrieval", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-1.7151508331298828, -3.771376371383667], "cluster": 9}, {"key": "wang2019memory", "year": "2019", "citations": "33", "title": "A Memory-efficient Sketch Method For Estimating High Similarities In Streaming Sets", "abstract": "<p>Estimating set similarity and detecting highly similar sets are fundamental\nproblems in areas such as databases, machine learning, and information\nretrieval. MinHash is a well-known technique for approximating Jaccard\nsimilarity of sets and has been successfully used for many applications such as\nsimilarity search and large scale learning. Its two compressed versions, b-bit\nMinHash and Odd Sketch, can significantly reduce the memory usage of the\noriginal MinHash method, especially for estimating high similarities (i.e.,\nsimilarities around 1). Although MinHash can be applied to static sets as well\nas streaming sets, of which elements are given in a streaming fashion and\ncardinality is unknown or even infinite, unfortunately, b-bit MinHash and Odd\nSketch fail to deal with streaming data. To solve this problem, we design a\nmemory efficient sketch method, MaxLogHash, to accurately estimate Jaccard\nsimilarities in streaming sets. Compared to MinHash, our method uses smaller\nsized registers (each register consists of less than 7 bits) to build a compact\nsketch for each set. We also provide a simple yet accurate estimator for\ninferring Jaccard similarity from MaxLogHash sketches. In addition, we derive\nformulas for bounding the estimation error and determine the smallest necessary\nmemory usage (i.e., the number of registers used for a MaxLogHash sketch) for\nthe desired accuracy. We conduct experiments on a variety of datasets, and\nexperimental results show that our method MaxLogHash is about 5 times more\nmemory efficient than MinHash with the same accuracy and computational cost for\nestimating high similarities.</p>\n", "tags": ["KDD", "Locality Sensitive Hashing", "DATASETS", "Alt", "Similarity Search"], "tsne_embedding": [13.29238510131836, 2.4855732917785645], "cluster": 4}, {"key": "wang2019multi", "year": "2019", "citations": "736", "title": "Multi-similarity Loss With General Pair Weighting For Deep Metric Learning", "abstract": "<p>A family of loss functions built on pair-based computation have been proposed\nin the literature which provide a myriad of solutions for deep metric learning.\nIn this paper, we provide a general weighting framework for understanding\nrecent pair-based loss functions. Our contributions are three-fold: (1) we\nestablish a General Pair Weighting (GPW) framework, which casts the sampling\nproblem of deep metric learning into a unified view of pair weighting through\ngradient analysis, providing a powerful tool for understanding recent\npair-based loss functions; (2) we show that with GPW, various existing\npair-based methods can be compared and discussed comprehensively, with clear\ndifferences and key limitations identified; (3) we propose a new loss called\nmulti-similarity loss (MS loss) under the GPW, which is implemented in two\niterative steps (i.e., mining and weighting). This allows it to fully consider\nthree similarities for pair weighting, providing a more principled approach for\ncollecting and weighting informative pairs. Finally, the proposed MS loss\nobtains new state-of-the-art performance on four image retrieval benchmarks,\nwhere it outperforms the most recent approaches, such as\nABE\\cite{Kim_2018_ECCV} and HTL by a large margin: 60.6% to 65.7% on CUB200,\nand 80.9% to 88.0% on In-Shop Clothes Retrieval dataset at Recall@1. Code is\navailable at https://github.com/MalongTech/research-ms-loss.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Distance Metric Learning", "CVPR", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-17.059572219848633, 8.712587356567383], "cluster": 3}, {"key": "wang2019ranked", "year": "2019", "citations": "231", "title": "Ranked List Loss For Deep Metric Learning", "abstract": "<p>The objective of deep metric learning (DML) is to learn embeddings that can\ncapture semantic similarity and dissimilarity information among data points.\nExisting pairwise or tripletwise loss functions used in DML are known to suffer\nfrom slow convergence due to a large proportion of trivial pairs or triplets as\nthe model improves. To improve this, ranking-motivated structured losses are\nproposed recently to incorporate multiple examples and exploit the structured\ninformation among them. They converge faster and achieve state-of-the-art\nperformance. In this work, we unveil two limitations of existing\nranking-motivated structured losses and propose a novel ranked list loss to\nsolve both of them. First, given a query, only a fraction of data points is\nincorporated to build the similarity structure. Consequently, some useful\nexamples are ignored and the structure is less informative. To address this, we\npropose to build a set-based similarity structure by exploiting all instances\nin the gallery. The learning setting can be interpreted as few-shot retrieval:\ngiven a mini-batch, every example is iteratively used as a query, and the rest\nones compose the gallery to search, i.e., the support set in few-shot setting.\nThe rest examples are split into a positive set and a negative set. For every\nmini-batch, the learning objective of ranked list loss is to make the query\ncloser to the positive set than to the negative set by a margin. Second,\nprevious methods aim to pull positive pairs as close as possible in the\nembedding space. As a result, the intraclass data distribution tends to be\nextremely compressed. In contrast, we propose to learn a hypersphere for each\nclass in order to preserve useful similarity structure inside it, which\nfunctions as regularisation. Extensive experiments demonstrate the superiority\nof our proposal by comparing with the state-of-the-art methods.</p>\n", "tags": ["CVPR", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [-17.29349136352539, 4.430202484130859], "cluster": 3}, {"key": "wang2019supervised", "year": "2019", "citations": "82", "title": "Supervised Quantization For Similarity Search", "abstract": "<p>In this paper, we address the problem of searching for semantically similar\nimages from a large database. We present a compact coding approach, supervised\nquantization. Our approach simultaneously learns feature selection that\nlinearly transforms the database points into a low-dimensional discriminative\nsubspace, and quantizes the data points in the transformed space. The\noptimization criterion is that the quantized points not only approximate the\ntransformed points accurately, but also are semantically separable: the points\nbelonging to a class lie in a cluster that is not overlapped with other\nclusters corresponding to other classes, which is formulated as a\nclassification problem. The experiments on several standard datasets show the\nsuperiority of our approach over the state-of-the art supervised hashing and\nunsupervised quantization algorithms.</p>\n", "tags": ["DATASETS", "Hashing Methods", "CVPR", "Similarity Search", "Quantization"], "tsne_embedding": [7.8488945960998535, -2.9503982067108154], "cluster": 4}, {"key": "wang2020asymmetric", "year": "2020", "citations": "21", "title": "Asymmetric Correlation Quantization Hashing For Cross-modal Retrieval", "abstract": "<p>Due to the superiority in similarity computation and database storage for\nlarge-scale multiple modalities data, cross-modal hashing methods have\nattracted extensive attention in similarity retrieval across the heterogeneous\nmodalities. However, there are still some limitations to be further taken into\naccount: (1) most current CMH methods transform real-valued data points into\ndiscrete compact binary codes under the binary constraints, limiting the\ncapability of representation for original data on account of abundant loss of\ninformation and producing suboptimal hash codes; (2) the discrete binary\nconstraint learning model is hard to solve, where the retrieval performance may\ngreatly reduce by relaxing the binary constraints for large quantization error;\n(3) handling the learning problem of CMH in a symmetric framework, leading to\ndifficult and complex optimization objective. To address above challenges, in\nthis paper, a novel Asymmetric Correlation Quantization Hashing (ACQH) method\nis proposed. Specifically, ACQH learns the projection matrixs of heterogeneous\nmodalities data points for transforming query into a low-dimensional\nreal-valued vector in latent semantic space and constructs the stacked\ncompositional quantization embedding in a coarse-to-fine manner for indicating\ndatabase points by a series of learnt real-valued codeword in the codebook with\nthe help of pointwise label information regression simultaneously. Besides, the\nunified hash codes across modalities can be directly obtained by the discrete\niterative optimization framework devised in the paper. Comprehensive\nexperiments on diverse three benchmark datasets have shown the effectiveness\nand rationality of ACQH.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Compact Codes", "Multimodal Retrieval", "Similarity Search", "Quantization", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-3.8828766345977783, -4.55719518661499], "cluster": 9}, {"key": "wang2020deep", "year": "2020", "citations": "214", "title": "Deep Reinforcement Learning With Label Embedding Reward For Supervised Image Hashing", "abstract": "<p>Deep hashing has shown promising results in image retrieval and recognition.\nDespite its success, most existing deep hashing approaches are rather similar:\neither multi-layer perceptron or CNN is applied to extract image feature,\nfollowed by different binarization activation functions such as sigmoid, tanh\nor autoencoder to generate binary code. In this work, we introduce a novel\ndecision-making approach for deep supervised hashing. We formulate the hashing\nproblem as travelling across the vertices in the binary code space, and learn a\ndeep Q-network with a novel label embedding reward defined by\nBose-Chaudhuri-Hocquenghem (BCH) codes to explore the best path. Extensive\nexperiments and analysis on the CIFAR-10 and NUS-WIDE dataset show that our\napproach outperforms state-of-the-art supervised hashing methods under various\ncode lengths.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "CVPR", "Compact Codes", "Neural Hashing"], "tsne_embedding": [-6.819868087768555, 6.647888660430908], "cluster": 8}, {"key": "wang2020distilling", "year": "2020", "citations": "20", "title": "Distilling Knowledge By Mimicking Features", "abstract": "<p>Knowledge distillation (KD) is a popular method to train efficient networks\n(\u201cstudent\u201d) with the help of high-capacity networks (\u201cteacher\u201d). Traditional\nmethods use the teacher\u2019s soft logits as extra supervision to train the student\nnetwork. In this paper, we argue that it is more advantageous to make the\nstudent mimic the teacher\u2019s features in the penultimate layer. Not only the\nstudent can directly learn more effective information from the teacher feature,\nfeature mimicking can also be applied for teachers trained without a softmax\nlayer. Experiments show that it can achieve higher accuracy than traditional\nKD. To further facilitate feature mimicking, we decompose a feature vector into\nthe magnitude and the direction. We argue that the teacher should give more\nfreedom to the student feature\u2019s magnitude, and let the student pay more\nattention on mimicking the feature direction. To meet this requirement, we\npropose a loss term based on locality-sensitive hashing (LSH). With the help of\nthis new loss, our method indeed mimics feature directions more accurately,\nrelaxes constraints on feature magnitudes, and achieves state-of-the-art\ndistillation accuracy. We provide theoretical analyses of how LSH facilitates\nfeature direction mimicking, and further extend feature mimicking to\nmulti-label recognition and object detection.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods"], "tsne_embedding": [-23.73862648010254, -5.454217433929443], "cluster": 1}, {"key": "wang2020faster", "year": "2020", "citations": "54", "title": "Faster Person Re-identification", "abstract": "<p>Fast person re-identification (ReID) aims to search person images quickly and\naccurately. The main idea of recent fast ReID methods is the hashing algorithm,\nwhich learns compact binary codes and performs fast Hamming distance and\ncounting sort. However, a very long code is needed for high accuracy (e.g.\n2048), which compromises search speed. In this work, we introduce a new\nsolution for fast ReID by formulating a novel Coarse-to-Fine (CtF) hashing code\nsearch strategy, which complementarily uses short and long codes, achieving\nboth faster speed and better accuracy. It uses shorter codes to coarsely rank\nbroad matching similarities and longer codes to refine only a few top\ncandidates for more accurate instance ReID. Specifically, we design an\nAll-in-One (AiO) framework together with a Distance Threshold Optimization\n(DTO) algorithm. In AiO, we simultaneously learn and enhance multiple codes of\ndifferent lengths in a single model. It learns multiple codes in a pyramid\nstructure, and encourage shorter codes to mimic longer codes by\nself-distillation. DTO solves a complex threshold search problem by a simple\noptimization process, and the balance between accuracy and speed is easily\ncontrolled by a single parameter. It formulates the optimization target as a\n\\(F_{\\beta}\\) score that can be optimised by Gaussian cumulative distribution\nfunctions. Experimental results on 2 datasets show that our proposed method\n(CtF) is not only 8% more accurate but also 5x faster than contemporary hashing\nReID methods. Compared with non-hashing ReID methods, CtF is \\(50\\times\\) faster\nwith comparable accuracy. Code is available at\nhttps://github.com/wangguanan/light-reid.</p>\n", "tags": ["Compact Codes", "DATASETS", "Tools & Libraries", "Hashing Methods"], "tsne_embedding": [-14.858774185180664, -19.785398483276367], "cluster": 1}, {"key": "wang2021comprehensive", "year": "2021", "citations": "119", "title": "A Comprehensive Survey And Experimental Comparison Of Graph-based Approximate Nearest Neighbor Search", "abstract": "<p>Approximate nearest neighbor search (ANNS) constitutes an important operation\nin a multitude of applications, including recommendation systems, information\nretrieval, and pattern recognition. In the past decade, graph-based ANNS\nalgorithms have been the leading paradigm in this domain, with dozens of\ngraph-based ANNS algorithms proposed. Such algorithms aim to provide effective,\nefficient solutions for retrieving the nearest neighbors for a given query.\nNevertheless, these efforts focus on developing and optimizing algorithms with\ndifferent approaches, so there is a real need for a comprehensive survey about\nthe approaches\u2019 relative performance, strengths, and pitfalls. Thus here we\nprovide a thorough comparative analysis and experimental evaluation of 13\nrepresentative graph-based ANNS algorithms via a new taxonomy and fine-grained\npipeline. We compared each algorithm in a uniform test environment on eight\nreal-world datasets and 12 synthetic datasets with varying sizes and\ncharacteristics. Our study yields novel discoveries, offerings several useful\nprinciples to improve algorithms, thus designing an optimized method that\noutperforms the state-of-the-art algorithms. This effort also helped us\npinpoint algorithms\u2019 working portions, along with rule-of-thumb recommendations\nabout promising research directions and suitable algorithms for practitioners\nin different fields.</p>\n", "tags": ["Survey Paper", "DATASETS", "Graph Based ANN", "Recommender Systems", "Evaluation"], "tsne_embedding": [19.994165420532227, 16.81891632080078], "cluster": 0}, {"key": "wang2021contrastive", "year": "2021", "citations": "23", "title": "Contrastive Quantization With Code Memory For Unsupervised Image Retrieval", "abstract": "<p>The high efficiency in computation and storage makes hashing (including\nbinary hashing and quantization) a common strategy in large-scale retrieval\nsystems. To alleviate the reliance on expensive annotations, unsupervised deep\nhashing becomes an important research problem. This paper provides a novel\nsolution to unsupervised deep quantization, namely Contrastive Quantization\nwith Code Memory (MeCoQ). Different from existing reconstruction-based\nstrategies, we learn unsupervised binary descriptors by contrastive learning,\nwhich can better capture discriminative visual semantics. Besides, we uncover\nthat codeword diversity regularization is critical to prevent contrastive\nlearning-based quantization from model degeneration. Moreover, we introduce a\nnovel quantization code memory module that boosts contrastive learning with\nlower feature drift than conventional feature memories. Extensive experiments\non benchmark datasets show that MeCoQ outperforms state-of-the-art methods.\nCode and configurations are publicly available at\nhttps://github.com/gimpong/AAAI22-MeCoQ.</p>\n", "tags": ["Image Retrieval", "AAAI", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Quantization", "Evaluation"], "tsne_embedding": [-7.52971887588501, -12.850019454956055], "cluster": 9}, {"key": "wang2021cross", "year": "2021", "citations": "5", "title": "Cross-modal Zero-shot Hashing By Label Attributes Embedding", "abstract": "<p>Cross-modal hashing (CMH) is one of the most promising methods in cross-modal\napproximate nearest neighbor search. Most CMH solutions ideally assume the\nlabels of training and testing set are identical. However, the assumption is\noften violated, causing a zero-shot CMH problem. Recent efforts to address this\nissue focus on transferring knowledge from the seen classes to the unseen ones\nusing label attributes. However, the attributes are isolated from the features\nof multi-modal data. To reduce the information gap, we introduce an approach\ncalled LAEH (Label Attributes Embedding for zero-shot cross-modal Hashing).\nLAEH first gets the initial semantic attribute vectors of labels by word2vec\nmodel and then uses a transformation network to transform them into a common\nsubspace. Next, it leverages the hash vectors and the feature similarity matrix\nto guide the feature extraction network of different modalities. At the same\ntime, LAEH uses the attribute similarity as the supplement of label similarity\nto rectify the label embedding and common subspace. Experiments show that LAEH\noutperforms related representative zero-shot and cross-modal hashing methods.</p>\n", "tags": ["Hashing Methods"], "tsne_embedding": [-17.85927963256836, -2.7980589866638184], "cluster": 1}, {"key": "wang2021meta", "year": "2021", "citations": "7", "title": "Meta Cross-modal Hashing On Long-tailed Data", "abstract": "<p>Due to the advantage of reducing storage while speeding up query time on big\nheterogeneous data, cross-modal hashing has been extensively studied for\napproximate nearest neighbor search of multi-modal data. Most hashing methods\nassume that training data is class-balanced.However, in practice, real world\ndata often have a long-tailed distribution. In this paper, we introduce a\nmeta-learning based cross-modal hashing method (MetaCMH) to handle long-tailed\ndata. Due to the lack of training samples in the tail classes, MetaCMH first\nlearns direct features from data in different modalities, and then introduces\nan associative memory module to learn the memory features of samples of the\ntail classes. It then combines the direct and memory features to obtain meta\nfeatures for each sample. For samples of the head classes of the long tail\ndistribution, the weight of the direct features is larger, because there are\nenough training data to learn them well; while for rare classes, the weight of\nthe memory features is larger. Finally, MetaCMH uses a likelihood loss function\nto preserve the similarity in different modalities and learns hash functions in\nan end-to-end fashion. Experiments on long-tailed datasets show that MetaCMH\nperforms significantly better than state-of-the-art methods, especially on the\ntail classes.</p>\n", "tags": ["AAAI", "DATASETS", "Hashing Methods", "Efficiency And Optimization"], "tsne_embedding": [-11.245379447937012, -8.840829849243164], "cluster": 1}, {"key": "wang2021prototype", "year": "2021", "citations": "41", "title": "Prototype-supervised Adversarial Network For Targeted Attack Of Deep Hashing", "abstract": "<p>Due to its powerful capability of representation learning and high-efficiency\ncomputation, deep hashing has made significant progress in large-scale image\nretrieval. However, deep hashing networks are vulnerable to adversarial\nexamples, which is a practical secure problem but seldom studied in\nhashing-based retrieval field. In this paper, we propose a novel\nprototype-supervised adversarial network (ProS-GAN), which formulates a\nflexible generative architecture for efficient and effective targeted hashing\nattack. To the best of our knowledge, this is the first generation-based method\nto attack deep hashing networks. Generally, our proposed framework consists of\nthree parts, i.e., a PrototypeNet, a generator, and a discriminator.\nSpecifically, the designed PrototypeNet embeds the target label into the\nsemantic representation and learns the prototype code as the category-level\nrepresentative of the target label. Moreover, the semantic representation and\nthe original image are jointly fed into the generator for a flexible targeted\nattack. Particularly, the prototype code is adopted to supervise the generator\nto construct the targeted adversarial example by minimizing the Hamming\ndistance between the hash code of the adversarial example and the prototype\ncode. Furthermore, the generator is against the discriminator to simultaneously\nencourage the adversarial examples visually realistic and the semantic\nrepresentation informative. Extensive experiments verify that the proposed\nframework can efficiently produce adversarial examples with better targeted\nattack performance and transferability over state-of-the-art targeted attack\nmethods of deep hashing. The related codes could be available at\nhttps://github.com/xunguangwang/ProS-GAN .</p>\n", "tags": ["Hashing Methods", "Efficiency And Optimization", "CVPR", "Neural Hashing", "Tools & Libraries", "Evaluation", "Robustness"], "tsne_embedding": [-12.344075202941895, -4.202545166015625], "cluster": 1}, {"key": "wang2021towards", "year": "2021", "citations": "19", "title": "Towards A Model For LSH", "abstract": "<p>As data volumes continue to grow, clustering and outlier detection algorithms\nare becoming increasingly time-consuming. Classical index structures for\nneighbor search are no longer sustainable due to the \u201ccurse of dimensionality\u201d.\nInstead, approximated index structures offer a good opportunity to\nsignificantly accelerate the neighbor search for clustering and outlier\ndetection and to have the lowest possible error rate in the results of the\nalgorithms. Locality-sensitive hashing is one of those. We indicate directions\nto model the properties of LSH.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Vector Indexing"], "tsne_embedding": [15.38937759399414, 6.144707202911377], "cluster": 0}, {"key": "wang2022binary", "year": "2022", "citations": "18", "title": "Binary Representation Via Jointly Personalized Sparse Hashing", "abstract": "<p>Unsupervised hashing has attracted much attention for binary representation\nlearning due to the requirement of economical storage and efficiency of binary\ncodes. It aims to encode high-dimensional features in the Hamming space with\nsimilarity preservation between instances. However, most existing methods learn\nhash functions in manifold-based approaches. Those methods capture the local\ngeometric structures (i.e., pairwise relationships) of data, and lack\nsatisfactory performance in dealing with real-world scenarios that produce\nsimilar features (e.g. color and shape) with different semantic information. To\naddress this challenge, in this work, we propose an effective unsupervised\nmethod, namely Jointly Personalized Sparse Hashing (JPSH), for binary\nrepresentation learning. To be specific, firstly, we propose a novel\npersonalized hashing module, i.e., Personalized Sparse Hashing (PSH). Different\npersonalized subspaces are constructed to reflect category-specific attributes\nfor different clusters, adaptively mapping instances within the same cluster to\nthe same Hamming space. In addition, we deploy sparse constraints for different\npersonalized subspaces to select important features. We also collect the\nstrengths of the other clusters to build the PSH module with avoiding\nover-fitting. Then, to simultaneously preserve semantic and pairwise\nsimilarities in our JPSH, we incorporate the PSH and manifold-based hash\nlearning into the seamless formulation. As such, JPSH not only distinguishes\nthe instances from different clusters, but also preserves local neighborhood\nstructures within the cluster. Finally, an alternating optimization algorithm\nis adopted to iteratively capture analytical solutions of the JPSH model.\nExtensive experiments on four benchmark datasets verify that the JPSH\noutperforms several hashing algorithms on the similarity search task.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "Alt", "Similarity Search", "Evaluation"], "tsne_embedding": [-4.807494163513184, -3.18038272857666], "cluster": 9}, {"key": "wang2022cgat", "year": "2022", "citations": "5", "title": "Cgat: Center-guided Adversarial Training For Deep Hashing-based Retrieval", "abstract": "<p>Deep hashing has been extensively utilized in massive image retrieval because\nof its efficiency and effectiveness. However, deep hashing models are\nvulnerable to adversarial examples, making it essential to develop adversarial\ndefense methods for image retrieval. Existing solutions achieved limited\ndefense performance because of using weak adversarial samples for training and\nlacking discriminative optimization objectives to learn robust features. In\nthis paper, we present a min-max based Center-guided Adversarial Training,\nnamely CgAT, to improve the robustness of deep hashing networks through worst\nadversarial examples. Specifically, we first formulate the center code as a\nsemantically-discriminative representative of the input image content, which\npreserves the semantic similarity with positive samples and dissimilarity with\nnegative examples. We prove that a mathematical formula can calculate the\ncenter code immediately. After obtaining the center codes in each optimization\niteration of the deep hashing network, they are adopted to guide the\nadversarial training process. On the one hand, CgAT generates the worst\nadversarial examples as augmented data by maximizing the Hamming distance\nbetween the hash codes of the adversarial examples and the center codes. On the\nother hand, CgAT learns to mitigate the effects of adversarial samples by\nminimizing the Hamming distance to the center codes. Extensive experiments on\nthe benchmark datasets demonstrate the effectiveness of our adversarial\ntraining algorithm in defending against adversarial attacks for deep\nhashing-based retrieval. Compared with the current state-of-the-art defense\nmethod, we significantly improve the defense performance by an average of\n18.61%, 12.35%, and 11.56% on FLICKR-25K, NUS-WIDE, and MS-COCO,\nrespectively. The code is available at https://github.com/xunguangwang/CgAT.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Neural Hashing", "Evaluation", "Robustness"], "tsne_embedding": [-15.741683959960938, -6.030963897705078], "cluster": 1}, {"key": "wang2022contrastive", "year": "2022", "citations": "17", "title": "Contrastive Masked Autoencoders For Self-supervised Video Hashing", "abstract": "<p>Self-Supervised Video Hashing (SSVH) models learn to generate short binary\nrepresentations for videos without ground-truth supervision, facilitating\nlarge-scale video retrieval efficiency and attracting increasing research\nattention. The success of SSVH lies in the understanding of video content and\nthe ability to capture the semantic relation among unlabeled videos. Typically,\nstate-of-the-art SSVH methods consider these two points in a two-stage training\npipeline, where they firstly train an auxiliary network by instance-wise\nmask-and-predict tasks and secondly train a hashing model to preserve the\npseudo-neighborhood structure transferred from the auxiliary network. This\nconsecutive training strategy is inflexible and also unnecessary. In this\npaper, we propose a simple yet effective one-stage SSVH method called ConMH,\nwhich incorporates video semantic information and video similarity relationship\nunderstanding in a single stage. To capture video semantic information for\nbetter hashing learning, we adopt an encoder-decoder structure to reconstruct\nthe video from its temporal-masked frames. Particularly, we find that a higher\nmasking ratio helps video understanding. Besides, we fully exploit the\nsimilarity relationship between videos by maximizing agreement between two\naugmented views of a video, which contributes to more discriminative and robust\nhash codes. Extensive experiments on three large-scale video datasets (i.e.,\nFCVID, ActivityNet and YFCC) indicate that ConMH achieves state-of-the-art\nresults. Code is available at https://github.com/huangmozhi9527/ConMH.</p>\n", "tags": ["AAAI", "DATASETS", "Hashing Methods", "Efficiency And Optimization"], "tsne_embedding": [-7.176370620727539, 16.882614135742188], "cluster": 6}, {"key": "wang2022hybrid", "year": "2022", "citations": "5", "title": "Hybrid Contrastive Quantization For Efficient Cross-view Video Retrieval", "abstract": "<p>With the recent boom of video-based social platforms (e.g., YouTube and\nTikTok), video retrieval using sentence queries has become an important demand\nand attracts increasing research attention. Despite the decent performance,\nexisting text-video retrieval models in vision and language communities are\nimpractical for large-scale Web search because they adopt brute-force search\nbased on high-dimensional embeddings. To improve efficiency, Web search engines\nwidely apply vector compression libraries (e.g., FAISS) to post-process the\nlearned embeddings. Unfortunately, separate compression from feature encoding\ndegrades the robustness of representations and incurs performance decay. To\npursue a better balance between performance and efficiency, we propose the\nfirst quantized representation learning method for cross-view video retrieval,\nnamely Hybrid Contrastive Quantization (HCQ). Specifically, HCQ learns both\ncoarse-grained and fine-grained quantizations with transformers, which provide\ncomplementary understandings for texts and videos and preserve comprehensive\nsemantic information. By performing Asymmetric-Quantized Contrastive Learning\n(AQ-CL) across views, HCQ aligns texts and videos at coarse-grained and\nmultiple fine-grained levels. This hybrid-grained learning strategy serves as\nstrong supervision on the cross-view video quantization model, where\ncontrastive learning at different levels can be mutually promoted. Extensive\nexperiments on three Web video benchmark datasets demonstrate that HCQ achieves\ncompetitive performance with state-of-the-art non-compressed retrieval methods\nwhile showing high efficiency in storage and computation. Code and\nconfigurations are available at https://github.com/gimpong/WWW22-HCQ.</p>\n", "tags": ["DATASETS", "Efficiency And Optimization", "Quantization", "Tools & Libraries", "Evaluation", "Robustness"], "tsne_embedding": [-10.939947128295898, -3.5378432273864746], "cluster": 8}, {"key": "wang2022inverted", "year": "2022", "citations": "14", "title": "Inverted Semantic-index For Image Retrieval", "abstract": "<p>This paper addresses the construction of inverted index for large-scale image\nretrieval. The inverted index proposed by J. Sivic brings a significant\nacceleration by reducing distance computations with only a small fraction of\nthe database. The state-of-the-art inverted indices aim to build finer\npartitions that produce a concise and accurate candidate list. However,\npartitioning in these frameworks is generally achieved by unsupervised\nclustering methods which ignore the semantic information of images. In this\npaper, we replace the clustering method with image classification, during the\nconstruction of codebook. We then propose a merging and splitting method to\nsolve the problem that the number of partitions is unchangeable in the inverted\nsemantic-index. Next, we combine our semantic-index with the product\nquantization (PQ) so as to alleviate the accuracy loss caused by PQ\ncompression. Finally, we evaluate our model on large-scale image retrieval\nbenchmarks. Experiment results demonstrate that our model can significantly\nimprove the retrieval accuracy by generating high-quality candidate lists.</p>\n", "tags": ["Image Retrieval", "Quantization", "Tools & Libraries", "Evaluation"], "tsne_embedding": [1.592745065689087, 7.728562355041504], "cluster": 4}, {"key": "wang2022navigable", "year": "2022", "citations": "7", "title": "Navigable Proximity Graph-driven Native Hybrid Queries With Structured And Unstructured Constraints", "abstract": "<p>As research interest surges, vector similarity search is applied in multiple\nfields, including data mining, computer vision, and information retrieval.\n{Given a set of objects (e.g., a set of images) and a query object, we can\neasily transform each object into a feature vector and apply the vector\nsimilarity search to retrieve the most similar objects. However, the original\nvector similarity search cannot well support \\textit{hybrid queries}, where\nusers not only input unstructured query constraint (i.e., the feature vector of\nquery object) but also structured query constraint (i.e., the desired\nattributes of interest). Hybrid query processing aims at identifying these\nobjects with similar feature vectors to query object and satisfying the given\nattribute constraints. Recent efforts have attempted to answer a hybrid query\nby performing attribute filtering and vector similarity search separately and\nthen merging the results later, which limits efficiency and accuracy because\nthey are not purpose-built for hybrid queries.} In this paper, we propose a\nnative hybrid query (NHQ) framework based on proximity graph (PG), which\nprovides the specialized \\textit{composite index and joint pruning} modules for\nhybrid queries. We easily deploy existing various PGs on this framework to\nprocess hybrid queries efficiently. Moreover, we present two novel navigable\nPGs (NPGs) with optimized edge selection and routing strategies, which obtain\nbetter overall performance than existing PGs. After that, we deploy the\nproposed NPGs in NHQ to form two hybrid query methods, which significantly\noutperform the state-of-the-art competitors on all experimental datasets\n(10\\(\\times\\) faster under the same \\textit{Recall}), including eight public and\none in-house real-world datasets. Our code and datasets have been released at\nhttps://github.com/AshenOn3/NHQ.</p>\n", "tags": ["DATASETS", "Evaluation", "Efficiency And Optimization", "Graph Based ANN", "CIKM", "Similarity Search", "Tools & Libraries"], "tsne_embedding": [8.130845069885254, 2.369338035583496], "cluster": 4}, {"key": "wang2023graph", "year": "2023", "citations": "56", "title": "Graph-collaborated Auto-encoder Hashing For Multi-view Binary Clustering", "abstract": "<p>Unsupervised hashing methods have attracted widespread attention with the\nexplosive growth of large-scale data, which can greatly reduce storage and\ncomputation by learning compact binary codes. Existing unsupervised hashing\nmethods attempt to exploit the valuable information from samples, which fails\nto take the local geometric structure of unlabeled samples into consideration.\nMoreover, hashing based on auto-encoders aims to minimize the reconstruction\nloss between the input data and binary codes, which ignores the potential\nconsistency and complementarity of multiple sources data. To address the above\nissues, we propose a hashing algorithm based on auto-encoders for multi-view\nbinary clustering, which dynamically learns affinity graphs with low-rank\nconstraints and adopts collaboratively learning between auto-encoders and\naffinity graphs to learn a unified binary code, called Graph-Collaborated\nAuto-Encoder Hashing for Multi-view Binary Clustering (GCAE). Specifically, we\npropose a multi-view affinity graphs learning model with low-rank constraint,\nwhich can mine the underlying geometric information from multi-view data. Then,\nwe design an encoder-decoder paradigm to collaborate the multiple affinity\ngraphs, which can learn a unified binary code effectively. Notably, we impose\nthe decorrelation and code balance constraints on binary codes to reduce the\nquantization errors. Finally, we utilize an alternating iterative optimization\nscheme to obtain the multi-view clustering results. Extensive experimental\nresults on \\(5\\) public datasets are provided to reveal the effectiveness of the\nalgorithm and its superior performance over other state-of-the-art\nalternatives.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Compact Codes", "Alt", "Quantization", "Evaluation"], "tsne_embedding": [14.696345329284668, 12.354233741760254], "cluster": 0}, {"key": "wang2023note", "year": "2023", "citations": "98", "title": "A Note On \"efficient Task-specific Data Valuation For Nearest Neighbor Algorithms\"", "abstract": "<p>Data valuation is a growing research field that studies the influence of\nindividual data points for machine learning (ML) models. Data Shapley, inspired\nby cooperative game theory and economics, is an effective method for data\nvaluation. However, it is well-known that the Shapley value (SV) can be\ncomputationally expensive. Fortunately, Jia et al. (2019) showed that for\nK-Nearest Neighbors (KNN) models, the computation of Data Shapley is\nsurprisingly simple and efficient.\n  In this note, we revisit the work of Jia et al. (2019) and propose a more\nnatural and interpretable utility function that better reflects the performance\nof KNN models. We derive the corresponding calculation procedure for the Data\nShapley of KNN classifiers/regressors with the new utility functions. Our new\napproach, dubbed soft-label KNN-SV, achieves the same time complexity as the\noriginal method. We further provide an efficient approximation algorithm for\nsoft-label KNN-SV based on locality sensitive hashing (LSH). Our experimental\nresults demonstrate that Soft-label KNN-SV outperforms the original method on\nmost datasets in the task of mislabeled data detection, making it a better\nbaseline for future work on data valuation.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Evaluation", "DATASETS"], "tsne_embedding": [-0.40845638513565063, -7.492292881011963], "cluster": 9}, {"key": "wang2023reliable", "year": "2023", "citations": "21", "title": "Reliable And Efficient Evaluation Of Adversarial Robustness For Deep Hashing-based Retrieval", "abstract": "<p>Deep hashing has been extensively applied to massive image retrieval due to\nits efficiency and effectiveness. Recently, several adversarial attacks have\nbeen presented to reveal the vulnerability of deep hashing models against\nadversarial examples. However, existing attack methods suffer from degraded\nperformance or inefficiency because they underutilize the semantic relations\nbetween original samples or spend a lot of time learning these relations with a\ndeep neural network. In this paper, we propose a novel Pharos-guided Attack,\ndubbed PgA, to evaluate the adversarial robustness of deep hashing networks\nreliably and efficiently. Specifically, we design pharos code to represent the\nsemantics of the benign image, which preserves the similarity to semantically\nrelevant samples and dissimilarity to irrelevant ones. It is proven that we can\nquickly calculate the pharos code via a simple math formula. Accordingly, PgA\ncan directly conduct a reliable and efficient attack on deep hashing-based\nretrieval by maximizing the similarity between the hash code of the adversarial\nexample and the pharos code. Extensive experiments on the benchmark datasets\nverify that the proposed algorithm outperforms the prior state-of-the-arts in\nboth attack strength and speed.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Neural Hashing", "Evaluation", "Robustness"], "tsne_embedding": [-16.007360458374023, -5.382983684539795], "cluster": 1}, {"key": "wang2024weakly", "year": "2024", "citations": "9", "title": "Weakly Supervised Deep Hyperspherical Quantization For Image Retrieval", "abstract": "<p>Deep quantization methods have shown high efficiency on large-scale image\nretrieval. However, current models heavily rely on ground-truth information,\nhindering the application of quantization in label-hungry scenarios. A more\nrealistic demand is to learn from inexhaustible uploaded images that are\nassociated with informal tags provided by amateur users. Though such sketchy\ntags do not obviously reveal the labels, they actually contain useful semantic\ninformation for supervising deep quantization. To this end, we propose\nWeakly-Supervised Deep Hyperspherical Quantization (WSDHQ), which is the first\nwork to learn deep quantization from weakly tagged images. Specifically, 1) we\nuse word embeddings to represent the tags and enhance their semantic\ninformation based on a tag correlation graph. 2) To better preserve semantic\ninformation in quantization codes and reduce quantization error, we jointly\nlearn semantics-preserving embeddings and supervised quantizer on hypersphere\nby employing a well-designed fusion layer and tailor-made loss functions.\nExtensive experiments show that WSDHQ can achieve state-of-art performance on\nweakly-supervised compact coding. Code is available at\nhttps://github.com/gimpong/AAAI21-WSDHQ.</p>\n", "tags": ["Image Retrieval", "AAAI", "Efficiency And Optimization", "Quantization", "Evaluation"], "tsne_embedding": [-9.11484146118164, -3.852802038192749], "cluster": 8}, {"key": "wang2025affinity", "year": "2025", "citations": "11", "title": "Affinity Preserving Quantization For Hashing: A Vector Quantization Approach To Learning Compact Binary Codes", "abstract": "<p>Hashing techniques are powerful for approximate nearest\nneighbour (ANN) search. Existing quantization methods in\nhashing are all focused on scalar quantization (SQ) which\nis inferior in utilizing the inherent data distribution. In this\npaper, we propose a novel vector quantization (VQ) method\nnamed affinity preserving quantization (APQ) to improve the\nquantization quality of projection values, which has significantly\nboosted the performance of state-of-the-art hashing\ntechniques. In particular, our method incorporates the neighbourhood\nstructure in the pre- and post-projection data space\ninto vector quantization. APQ minimizes the quantization errors\nof projection values as well as the loss of affinity property\nof original space. An effective algorithm has been proposed\nto solve the joint optimization problem in APQ, and\nthe extension to larger binary codes has been resolved by applying\nproduct quantization to APQ. Extensive experiments\nhave shown that APQ consistently outperforms the state-of-the-art\nquantization methods, and has significantly improved\nthe performance of various hashing techniques.</p>\n", "tags": ["AAAI", "Hashing Methods", "Compact Codes", "Quantization", "Evaluation"], "tsne_embedding": [20.893938064575195, -0.17653413116931915], "cluster": 7}, {"key": "wang2025hamming", "year": "2025", "citations": "20", "title": "Hamming Compatible Quantization For Hashing", "abstract": "<p>Hashing is one of the effective techniques for fast\nApproximate Nearest Neighbour (ANN) search.\nTraditional single-bit quantization (SBQ) in most\nhashing methods incurs lots of quantization error\nwhich seriously degrades the search performance.\nTo address the limitation of SBQ, researchers have\nproposed promising multi-bit quantization (MBQ)\nmethods to quantize each projection dimension\nwith multiple bits. However, some MBQ methods\nneed to adopt specific distance for binary code\nmatching instead of the original Hamming distance,\nwhich would significantly decrease the retrieval\nspeed. Two typical MBQ methods Hierarchical\nQuantization and Double Bit Quantization\nretain the Hamming distance, but both of them only\nconsider the projection dimensions during quantization,\nignoring the neighborhood structure of raw\ndata inherent in Euclidean space. In this paper,\nwe propose a multi-bit quantization method named\nHamming Compatible Quantization (HCQ) to preserve\nthe capability of similarity metric between\nEuclidean space and Hamming space by utilizing\nthe neighborhood structure of raw data. Extensive\nexperiment results have shown our approach significantly\nimproves the performance of various stateof-the-art\nhashing methods while maintaining fast\nretrieval speed.</p>\n", "tags": ["Hashing Methods", "Distance Metric Learning", "Compact Codes", "Similarity Search", "Quantization", "Evaluation"], "tsne_embedding": [19.005935668945312, -13.035066604614258], "cluster": 2}, {"key": "wang2025online", "year": "2025", "citations": "47", "title": "Online Collective Matrix Factorization Hashing For Large-scale Cross-media Retrieval", "abstract": "<p>Cross-modal hashing has been widely investigated recently for its efficiency in large-scale cross-media retrieval. However, most existing cross-modal hashing methods learn hash functions in a batch-based learning mode. Such mode is not suitable for large-scale data sets due to the large memory consumption and loses its efficiency when training streaming data. Online cross-modal hashing can deal with the above problems by learning hash model in an online learning process. However, existing online cross-modal hashing methods cannot update hash codes of old data by the newly learned model. In this paper, we propose Online Collective Matrix Factorization Hashing (OCMFH) based on collective matrix factorization hashing (CMFH), which can adaptively update hash codes of old data according to dynamic changes of hash model without accessing to old data. Specifically, it learns discriminative hash codes for streaming data by collective matrix factorization in an online optimization scheme. Unlike conventional CMFH which needs to load the entire data points into memory, the proposed OCMFH retrains hash functions only by newly arriving data points. Meanwhile, it generates hash codes of new data and updates hash codes of old data by the latest updated hash model. In such way, hash codes of new data and old data are well-matched. Furthermore, a zero mean strategy is developed to solve the mean-varying problem in the online hash learning process. Extensive experiments on three benchmark data sets demonstrate the effectiveness and efficiency of OCMFH on online cross-media retrieval.</p>\n", "tags": ["SIGIR", "Hashing Methods", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [-12.400311470031738, -11.814644813537598], "cluster": 1}, {"key": "wang2025semantic", "year": "2025", "citations": "149", "title": "Semantic Topic Multimodal Hashing For Cross-media Retrieval", "abstract": "<p>Multimodal hashing is essential to cross-media\nsimilarity search for its low storage cost and fast\nquery speed. Most existing multimodal hashing\nmethods embedded heterogeneous data into a common low-dimensional Hamming space, and then\nrounded the continuous embeddings to obtain the\nbinary codes. Yet they usually neglect the inherent discrete nature of hashing for relaxing the discrete constraints, which will cause degraded retrieval performance especially for long codes. For\nthis purpose, a novel Semantic Topic Multimodal\nHashing (STMH) is developed by considering latent semantic information in coding procedure.\nIt\nfirst discovers clustering patterns of texts and robust factorizes the matrix of images to obtain multiple semantic topics of texts and concepts of images.\nThen the learned multimodal semantic features are\ntransformed into a common subspace by their correlations. Finally, each bit of unified hash code\ncan be generated directly by figuring out whether a\ntopic or concept is contained in a text or an image.\nTherefore, the obtained model by STMH is more\nsuitable for hashing scheme as it directly learns discrete hash codes in the coding process. Experimental results demonstrate that the proposed method\noutperforms several state-of-the-art methods.</p>\n", "tags": ["Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Similarity Search", "Evaluation"], "tsne_embedding": [-3.303797483444214, -0.49383053183555603], "cluster": 8}, {"key": "wang2025semi", "year": "2025", "citations": "12", "title": "Semi-supervised Deep Quantization For Cross-modal Search", "abstract": "<p>The problem of cross-modal similarity search, which aims at making efficient and accurate queries across multiple domains, has become a significant and important research topic. Composite quantization, a compact coding solution superior to hashing techniques, has shown its effectiveness for similarity search. However, most existing works utilizing composite quantization to search multi-domain content only consider either pairwise similarity information or class label information across different domains, which fails to tackle the semi-supervised problem in composite quantization. In this paper, we address the semi-supervised quantization problem by considering: (i) pairwise similarity information (without class label information) across different domains, which captures the intra-document relation, (ii) cross-domain data with class label which can help capture inter-document relation, and (iii) cross-domain data with neither pairwise similarity nor class label which enables the full use of abundant unlabelled information. To the best of our knowledge, we are the first to consider both supervised information (pairwise similarity + class label) and unsupervised information (neither pairwise similarity nor class label) simultaneously in composite quantization. A challenging problem arises: how can we jointly handle these three sorts of information across multiple domains in an efficient way? To tackle this challenge, we propose a novel semi-supervised deep quantization (SSDQ) model that takes both supervised and unsupervised information into account. The proposed SSDQ model is capable of incorporating the above three kinds of information into one single framework when utilizing composite quantization for accurate and efficient queries across different domains. More specifically, we employ a modified deep autoencoder for better latent representation and formulate pairwise similarity loss, supervised quantization loss as well as unsupervised distribution match loss to handle all three types of information. The extensive experiments demonstrate the significant improvement of SSDQ over several state-of-the-art methods on various datasets.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Similarity Search", "Quantization", "Tools & Libraries"], "tsne_embedding": [-2.461867094039917, -2.2061100006103516], "cluster": 9}, {"key": "wang2025sequential", "year": "2025", "citations": "328", "title": "Sequential Projection Learning For Hashing With Compact Codes", "abstract": "<p>Hashing based Approximate Nearest Neighbor\n(ANN) search has attracted much attention\ndue to its fast query time and drastically\nreduced storage. However, most of the hashing\nmethods either use random projections or\nextract principal directions from the data to\nderive hash functions. The resulting embedding\nsuffers from poor discrimination when\ncompact codes are used. In this paper, we\npropose a novel data-dependent projection\nlearning method such that each hash function\nis designed to correct the errors made by\nthe previous one sequentially. The proposed\nmethod easily adapts to both unsupervised\nand semi-supervised scenarios and shows significant\nperformance gains over the state-ofthe-art\nmethods on two large datasets containing\nup to 1 million points.</p>\n", "tags": ["Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Evaluation"], "tsne_embedding": [11.576281547546387, -4.1832170486450195], "cluster": 2}, {"key": "wang2025uncertainty", "year": "2025", "citations": "48", "title": "Uncertainty-aware Unsupervised Video Hashing", "abstract": "<p>Learning to hash has become popular for video retrieval due to its fast speed and low storage consumption. Previous efforts formulate video hashing as training a binary auto-encoder, for which noncontinuous latent representations are optimized by the biased straight-through (ST) back-propagation heuristic. We propose to formulate video hashing as learning a discrete variational auto-encoder with the factorized Bernoulli latent distribution, termed as Bernoulli variational auto-encoder (BerVAE). The corresponding evidence lower bound (ELBO) in our BerVAE implementation leads to closed-form gradient expression, which can be applied to achieve principled training along with some other unbiased gradient estimators. BerVAE enables uncertainty-aware video hashing by predicting the probability distribution of video hash code-words, thus providing reliable uncertainty quantification. Experiments on both simulated and real-world large-scale video data demonstrate that our BerVAE trained with unbiased gradient estimators can achieve the state-of-the-art retrieval performance. Furthermore, we show that quantified uncertainty is highly correlated to video retrieval performance, which can be leveraged to further improve the retrieval accuracy. Our code is available at https://github.com/wangyucheng1234/BerVAE</p>\n", "tags": ["Hashing Methods", "Evaluation"], "tsne_embedding": [-2.2665445804595947, 2.7548341751098633], "cluster": 8}, {"key": "wei2021pp", "year": "2021", "citations": "6", "title": "Pp-shitu: A Practical Lightweight Image Recognition System", "abstract": "<p>In recent years, image recognition applications have developed rapidly. A\nlarge number of studies and techniques have emerged in different fields, such\nas face recognition, pedestrian and vehicle re-identification, landmark\nretrieval, and product recognition. In this paper, we propose a practical\nlightweight image recognition system, named PP-ShiTu, consisting of the\nfollowing 3 modules, mainbody detection, feature extraction and vector search.\nWe introduce popular strategies including metric learning, deep hash, knowledge\ndistillation and model quantization to improve accuracy and inference speed.\nWith strategies above, PP-ShiTu works well in different scenarios with a set of\nmodels trained on a mixed dataset. Experiments on different datasets and\nbenchmarks show that the system is widely effective in different domains of\nimage recognition. All the above mentioned models are open-sourced and the code\nis available in the GitHub repository PaddleClas on PaddlePaddle.</p>\n", "tags": ["DATASETS", "Distance Metric Learning", "Neural Hashing", "Quantization", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-0.32754993438720703, 12.909296989440918], "cluster": 6}, {"key": "wei2022accurate", "year": "2022", "citations": "5", "title": "Accurate Instance-level CAD Model Retrieval In A Large-scale Database", "abstract": "<p>We present a new solution to the fine-grained retrieval of clean CAD models\nfrom a large-scale database in order to recover detailed object shape\ngeometries for RGBD scans. Unlike previous work simply indexing into a\nmoderately small database using an object shape descriptor and accepting the\ntop retrieval result, we argue that in the case of a large-scale database a\nmore accurate model may be found within a neighborhood of the descriptor. More\nimportantly, we propose that the distinctiveness deficiency of shape\ndescriptors at the instance level can be compensated by a geometry-based\nre-ranking of its neighborhood. Our approach first leverages the discriminative\npower of learned representations to distinguish between different categories of\nmodels and then uses a novel robust point set distance metric to re-rank the\nCAD neighborhood, enabling fine-grained retrieval in a large shape database.\nEvaluation on a real-world dataset shows that our geometry-based re-ranking is\na conceptually simple but highly effective method that can lead to a\nsignificant improvement in retrieval accuracy compared to the state-of-the-art.</p>\n", "tags": ["DATASETS", "IROS", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [-1.9565609693527222, 19.422922134399414], "cluster": 6}, {"key": "wei2022hyperbolic", "year": "2022", "citations": "19", "title": "Hyperbolic Hierarchical Contrastive Hashing", "abstract": "<p>Hierarchical semantic structures, naturally existing in real-world datasets,\ncan assist in capturing the latent distribution of data to learn robust hash\ncodes for retrieval systems. Although hierarchical semantic structures can be\nsimply expressed by integrating semantically relevant data into a high-level\ntaxon with coarser-grained semantics, the construction, embedding, and\nexploitation of the structures remain tricky for unsupervised hash learning. To\ntackle these problems, we propose a novel unsupervised hashing method named\nHyperbolic Hierarchical Contrastive Hashing (HHCH). We propose to embed\ncontinuous hash codes into hyperbolic space for accurate semantic expression\nsince embedding hierarchies in hyperbolic space generates less distortion than\nin hyper-sphere space and Euclidean space. In addition, we extend the K-Means\nalgorithm to hyperbolic space and perform the proposed hierarchical hyperbolic\nK-Means algorithm to construct hierarchical semantic structures adaptively. To\nexploit the hierarchical semantic structures in hyperbolic space, we designed\nthe hierarchical contrastive learning algorithm, including hierarchical\ninstance-wise and hierarchical prototype-wise contrastive learning. Extensive\nexperiments on four benchmark datasets demonstrate that the proposed method\noutperforms the state-of-the-art unsupervised hashing methods. Codes will be\nreleased.</p>\n", "tags": ["DATASETS", "Evaluation", "IJCAI", "Hashing Methods", "AAAI", "Alt"], "tsne_embedding": [-4.220245838165283, -0.5443851351737976], "cluster": 8}, {"key": "wei2023attribute", "year": "2023", "citations": "16", "title": "Attribute-aware Deep Hashing With Self-consistency For Large-scale Fine-grained Image Retrieval", "abstract": "<p>Our work focuses on tackling large-scale fine-grained image retrieval as\nranking the images depicting the concept of interests (i.e., the same\nsub-category labels) highest based on the fine-grained details in the query. It\nis desirable to alleviate the challenges of both fine-grained nature of small\ninter-class variations with large intra-class variations and explosive growth\nof fine-grained data for such a practical task. In this paper, we propose\nattribute-aware hashing networks with self-consistency for generating\nattribute-aware hash codes to not only make the retrieval process efficient,\nbut also establish explicit correspondences between hash codes and visual\nattributes. Specifically, based on the captured visual representations by\nattention, we develop an encoder-decoder structure network of a reconstruction\ntask to unsupervisedly distill high-level attribute-specific vectors from the\nappearance-specific visual representations without attribute annotations. Our\nmodels are also equipped with a feature decorrelation constraint upon these\nattribute vectors to strengthen their representative abilities. Then, driven by\npreserving original entities\u2019 similarity, the required hash codes can be\ngenerated from these attribute-specific vectors and thus become\nattribute-aware. Furthermore, to combat simplicity bias in deep hashing, we\nconsider the model design from the perspective of the self-consistency\nprinciple and propose to further enhance models\u2019 self-consistency by equipping\nan additional image reconstruction path. Comprehensive quantitative experiments\nunder diverse empirical settings on six fine-grained retrieval datasets and two\ngeneric retrieval datasets show the superiority of our models over competing\nmethods.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Neural Hashing", "Hashing Methods"], "tsne_embedding": [-10.343912124633789, 7.73794412612915], "cluster": 8}, {"key": "wei2023chain", "year": "2023", "citations": "5", "title": "CHAIN: Exploring Global-local Spatio-temporal Information For Improved Self-supervised Video Hashing", "abstract": "<p>Compressing videos into binary codes can improve retrieval speed and reduce\nstorage overhead. However, learning accurate hash codes for video retrieval can\nbe challenging due to high local redundancy and complex global dependencies\nbetween video frames, especially in the absence of labels. Existing\nself-supervised video hashing methods have been effective in designing\nexpressive temporal encoders, but have not fully utilized the temporal dynamics\nand spatial appearance of videos due to less challenging and unreliable\nlearning tasks. To address these challenges, we begin by utilizing the\ncontrastive learning task to capture global spatio-temporal information of\nvideos for hashing. With the aid of our designed augmentation strategies, which\nfocus on spatial and temporal variations to create positive pairs, the learning\nframework can generate hash codes that are invariant to motion, scale, and\nviewpoint. Furthermore, we incorporate two collaborative learning tasks, i.e.,\nframe order verification and scene change regularization, to capture local\nspatio-temporal details within video frames, thereby enhancing the perception\nof temporal structure and the modeling of spatio-temporal relationships. Our\nproposed Contrastive Hashing with Global-Local Spatio-temporal Information\n(CHAIN) outperforms state-of-the-art self-supervised video hashing methods on\nfour video benchmark datasets. Our codes will be released.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Compact Codes", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-6.86371374130249, 17.095232009887695], "cluster": 6}, {"key": "wei2025net", "year": "2025", "citations": "7", "title": "A-net: Learning Attribute-aware Hash Codes For Large-scale Fine-grained Image Retrieval", "abstract": "<p>Our work focuses on tackling large-scale fine-grained image retrieval as ranking the images depicting the concept of interests (i.e., the same sub-category labels) highest based on the fine-grained details in the query. It is desirable to alleviate the challenges of both fine-grained nature of small inter-class variations with large intra-class variations and explosive growth of fine-grained data for such a practical task. In this paper, we propose an Attribute-Aware hashing Network (A-Net) for generating attribute-aware hash codes to not only make the retrieval process efficient, but also establish explicit correspondences between hash codes and visual attributes. Specifically, based on the captured visual representations by attention, we develop an encoder-decoder structure network of a reconstruction task to unsupervisedly distill high-level attribute-specific vectors from the appearance-specific visual representations without attribute annotations. A-Net is also equipped with a feature decorrelation constraint upon these attribute vectors to enhance their representation abilities. Finally, the required hash codes are generated by the attribute vectors driven by preserving original similarities. Qualitative experiments on five benchmark fine-grained datasets show our superiority over competing methods. More importantly, quantitative results demonstrate the obtained hash codes can strongly correspond to certain kinds of crucial properties of fine-grained objects.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Evaluation"], "tsne_embedding": [-10.337796211242676, 7.756667137145996], "cluster": 8}, {"key": "weiss2025multidimensional", "year": "2025", "citations": "161", "title": "Multidimensional Spectral Hashing", "abstract": "<p>en a surge of interest in methods based on \u201csemantic hashing\u201d,\ni.e. compact binary codes of data-points so that the Hamming distance\nbetween codewords correlates with similarity. In reviewing and\ncomparing existing methods, we show that their relative performance can\nchange drastically depending on the definition of ground-truth neighbors.\nMotivated by this finding, we propose a new formulation for learning binary\ncodes which seeks to reconstruct the affinity between datapoints,\nrather than their distances. We show that this criterion is intractable\nto solve exactly, but a spectral relaxation gives an algorithm where the\nbits correspond to thresholded eigenvectors of the affinity matrix, and\nas the number of datapoints goes to infinity these eigenvectors converge\nto eigenfunctions of Laplace-Beltrami operators, similar to the recently\nproposed Spectral Hashing (SH) method. Unlike SH whose performance\nmay degrade as the number of bits increases, the optimal code using\nour formulation is guaranteed to faithfully reproduce the affinities as\nthe number of bits increases. We show that the number of eigenfunctions\nneeded may increase exponentially with dimension, but introduce a \u201ckernel\ntrick\u201d to allow us to compute with an exponentially large number of\nbits but using only memory and computation that grows linearly with\ndimension. Experiments shows that MDSH outperforms the state-of-the\nart, especially in the challenging regime of small distance thresholds.</p>\n", "tags": ["Survey Paper", "Hashing Methods", "Compact Codes", "Text Retrieval", "Evaluation"], "tsne_embedding": [15.074047088623047, -0.04480686038732529], "cluster": 4}, {"key": "weiss2025spectral", "year": "2025", "citations": "2154", "title": "Spectral Hashing", "abstract": "<p>Semantic hashing seeks compact binary codes of data-points so that the\nHamming distance between codewords correlates with semantic similarity.\nIn this paper, we show that the problem of finding a best code for a given\ndataset is closely related to the problem of graph partitioning and can\nbe shown to be NP hard. By relaxing the original problem, we obtain a\nspectral method whose solutions are simply a subset of thresholded eigenvectors\nof the graph Laplacian. By utilizing recent results on convergence\nof graph Laplacian eigenvectors to the Laplace-Beltrami eigenfunctions of\nmanifolds, we show how to efficiently calculate the code of a novel datapoint.\nTaken together, both learning the code and applying it to a novel\npoint are extremely simple. Our experiments show that our codes outperform\nthe state-of-the art.</p>\n", "tags": ["Compact Codes", "Text Retrieval", "Hashing Methods", "DATASETS"], "tsne_embedding": [16.615093231201172, 10.713802337646484], "cluster": 0}, {"key": "weissman2014identifying", "year": "2014", "citations": "10", "title": "Identifying Duplicate And Contradictory Information In Wikipedia", "abstract": "<p>Our study identifies sentences in Wikipedia articles that are either\nidentical or highly similar by applying techniques for near-duplicate detection\nof web pages. This is accomplished with a MapReduce implementation of minhash\nto identify clusters of sentences with high Jaccard similarity. We show that\nthese clusters can be categorized into six different types, two of which are\nparticularly interesting: identical sentences quantify the extent to which\ncontent in Wikipedia is copied and pasted, and near-duplicate sentences that\nstate contradictory facts point to quality issues in Wikipedia.</p>\n", "tags": ["Locality Sensitive Hashing", "Evaluation"], "tsne_embedding": [10.594842910766602, -11.666690826416016], "cluster": 2}, {"key": "weng2019online", "year": "2019", "citations": "15", "title": "Online Hashing With Efficient Updating Of Binary Codes", "abstract": "<p>Online hashing methods are efficient in learning the hash functions from the\nstreaming data. However, when the hash functions change, the binary codes for\nthe database have to be recomputed to guarantee the retrieval accuracy.\nRecomputing the binary codes by accumulating the whole database brings a\ntimeliness challenge to the online retrieval process. In this paper, we propose\na novel online hashing framework to update the binary codes efficiently without\naccumulating the whole database. In our framework, the hash functions are fixed\nand the projection functions are introduced to learn online from the streaming\ndata. Therefore, inefficient updating of the binary codes by accumulating the\nwhole database can be transformed to efficient updating of the binary codes by\nprojecting the binary codes into another binary space. The queries and the\nbinary code database are projected asymmetrically to further improve the\nretrieval accuracy. The experiments on two multi-label image databases\ndemonstrate the effectiveness and the efficiency of our method for multi-label\nimage retrieval.</p>\n", "tags": ["Image Retrieval", "AAAI", "Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Tools & Libraries"], "tsne_embedding": [4.530609607696533, -8.55497932434082], "cluster": 2}, {"key": "weng2020fast", "year": "2020", "citations": "11", "title": "Fast Search On Binary Codes By Weighted Hamming Distance", "abstract": "<p>Weighted Hamming distance, as a similarity measure between binary codes and\nbinary queries, provides superior accuracy in search tasks than Hamming\ndistance. However, how to efficiently and accurately find \\(K\\) binary codes that\nhave the smallest weighted Hamming distance to the query remains an open issue.\nIn this paper, a fast search algorithm is proposed to perform the\nnon-exhaustive search for \\(K\\) nearest binary codes by weighted Hamming\ndistance. By using binary codes as direct bucket indices in a hash table, the\nsearch algorithm generates a sequence to probe the buckets based on the\nindependence characteristic of the weights for each bit. Furthermore, a fast\nsearch framework based on the proposed search algorithm is designed to solve\nthe problem of long binary codes. Specifically, long binary codes are split\ninto substrings and multiple hash tables are built on them. Then, the search\nalgorithm probes the buckets to obtain candidates according to the generated\nsubstring indices, and a merging algorithm is proposed to find the nearest\nbinary codes by merging the candidates. Theoretical analysis and experimental\nresults demonstrate that the search algorithm improves the search accuracy\ncompared to other non-exhaustive algorithms and provides orders-of-magnitude\nfaster search than the linear scan baseline.</p>\n", "tags": ["ICASSP", "Tools & Libraries", "Compact Codes"], "tsne_embedding": [15.761588096618652, -11.426973342895508], "cluster": 2}, {"key": "weng2020random", "year": "2020", "citations": "9", "title": "Random VLAD Based Deep Hashing For Efficient Image Retrieval", "abstract": "<p>Image hash algorithms generate compact binary representations that can be\nquickly matched by Hamming distance, thus become an efficient solution for\nlarge-scale image retrieval. This paper proposes RV-SSDH, a deep image hash\nalgorithm that incorporates the classical VLAD (vector of locally aggregated\ndescriptors) architecture into neural networks. Specifically, a novel neural\nnetwork component is formed by coupling a random VLAD layer with a latent hash\nlayer through a transform layer. This component can be combined with\nconvolutional layers to realize a hash algorithm. We implement RV-SSDH as a\npoint-wise algorithm that can be efficiently trained by minimizing\nclassification error and quantization loss. Comprehensive experiments show this\nnew architecture significantly outperforms baselines such as NetVLAD and SSDH,\nand offers a cost-effective trade-off in the state-of-the-art. In addition, the\nproposed random VLAD layer leads to satisfactory accuracy with low complexity,\nthus shows promising potentials as an alternative to NetVLAD.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Alt", "Neural Hashing", "Quantization"], "tsne_embedding": [-4.2313666343688965, 4.3715009689331055], "cluster": 8}, {"key": "weng2023constant", "year": "2023", "citations": "8", "title": "Constant Sequence Extension For Fast Search Using Weighted Hamming Distance", "abstract": "<p>Representing visual data using compact binary codes is attracting increasing\nattention as binary codes are used as direct indices into hash table(s) for\nfast non-exhaustive search. Recent methods show that ranking binary codes using\nweighted Hamming distance (WHD) rather than Hamming distance (HD) by generating\nquery-adaptive weights for each bit can better retrieve query-related items.\nHowever, search using WHD is slower than that using HD. One main challenge is\nthat the complexity of extending a monotone increasing sequence using WHD to\nprobe buckets in hash table(s) for existing methods is at least proportional to\nthe square of the sequence length, while that using HD is proportional to the\nsequence length. To overcome this challenge, we propose a novel fast\nnon-exhaustive search method using WHD. The key idea is to design a constant\nsequence extension algorithm to perform each sequence extension in constant\ncomputational complexity and the total complexity is proportional to the\nsequence length, which is justified by theoretical analysis. Experimental\nresults show that our method is faster than other WHD-based search methods.\nAlso, compared with the HD-based non-exhaustive search method, our method has\ncomparable efficiency but retrieves more query-related items for the dataset of\nup to one billion items.</p>\n", "tags": ["Compact Codes", "DATASETS", "Efficiency And Optimization"], "tsne_embedding": [-15.199532508850098, -20.703081130981445], "cluster": 1}, {"key": "westermann2021sentence", "year": "2021", "citations": "22", "title": "Sentence Embeddings And High-speed Similarity Search For Fast Computer Assisted Annotation Of Legal Documents", "abstract": "<p>Human-performed annotation of sentences in legal documents is an important\nprerequisite to many machine learning based systems supporting legal tasks.\nTypically, the annotation is done sequentially, sentence by sentence, which is\noften time consuming and, hence, expensive. In this paper, we introduce a\nproof-of-concept system for annotating sentences \u201claterally.\u201d The approach is\nbased on the observation that sentences that are similar in meaning often have\nthe same label in terms of a particular type system. We use this observation in\nallowing annotators to quickly view and annotate sentences that are\nsemantically similar to a given sentence, across an entire corpus of documents.\nHere, we present the interface of the system and empirically evaluate the\napproach. The experiments show that lateral annotation has the potential to\nmake the annotation process quicker and more consistent.</p>\n", "tags": ["Similarity Search"], "tsne_embedding": [12.031928062438965, -12.040565490722656], "cluster": 2}, {"key": "wieczorek2021unreasonable", "year": "2021", "citations": "84", "title": "On The Unreasonable Effectiveness Of Centroids In Image Retrieval", "abstract": "<p>Image retrieval task consists of finding similar images to a query image from\na set of gallery (database) images. Such systems are used in various\napplications e.g. person re-identification (ReID) or visual product search.\nDespite active development of retrieval models it still remains a challenging\ntask mainly due to large intra-class variance caused by changes in view angle,\nlighting, background clutter or occlusion, while inter-class variance may be\nrelatively low. A large portion of current research focuses on creating more\nrobust features and modifying objective functions, usually based on Triplet\nLoss. Some works experiment with using centroid/proxy representation of a class\nto alleviate problems with computing speed and hard samples mining used with\nTriplet Loss. However, these approaches are used for training alone and\ndiscarded during the retrieval stage. In this paper we propose to use the mean\ncentroid representation both during training and retrieval. Such an aggregated\nrepresentation is more robust to outliers and assures more stable features. As\neach class is represented by a single embedding - the class centroid - both\nretrieval time and storage requirements are reduced significantly. Aggregating\nmultiple embeddings results in a significant reduction of the search space due\nto lowering the number of candidate target vectors, which makes the method\nespecially suitable for production deployments. Comprehensive experiments\nconducted on two ReID and Fashion Retrieval datasets demonstrate effectiveness\nof our method, which outperforms the current state-of-the-art. We propose\ncentroid training and retrieval as a viable method for both Fashion Retrieval\nand ReID applications.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Distance Metric Learning"], "tsne_embedding": [-19.49336051940918, 2.596238374710083], "cluster": 3}, {"key": "wieder2018another", "year": "2018", "citations": "120", "title": "Another Proof Of Cuckoo Hashing With New Variants", "abstract": "<p>We show a new proof for the load of obtained by a Cuckoo Hashing data\nstructure. Our proof is arguably simpler than previous proofs and allows for\nnew generalizations. The proof first appeared in Pinkas et. al. \\cite{PSWW19}\nin the context of a protocol for private set intersection. We present it here\nseparately to improve its readability.</p>\n", "tags": ["Hashing Methods"], "tsne_embedding": [1.833267331123352, -14.040422439575195], "cluster": 9}, {"key": "wieschollek2017efficient", "year": "2017", "citations": "54", "title": "Efficient Large-scale Approximate Nearest Neighbor Search On The GPU", "abstract": "<p>We present a new approach for efficient approximate nearest neighbor (ANN)\nsearch in high dimensional spaces, extending the idea of Product Quantization.\nWe propose a two-level product and vector quantization tree that reduces the\nnumber of vector comparisons required during tree traversal. Our approach also\nincludes a novel highly parallelizable re-ranking method for candidate vectors\nby efficiently reusing already computed intermediate values. Due to its small\nmemory footprint during traversal, the method lends itself to an efficient,\nparallel GPU implementation. This Product Quantization Tree (PQT) approach\nsignificantly outperforms recent state of the art methods for high dimensional\nnearest neighbor queries on standard reference datasets. Ours is the first work\nthat demonstrates GPU performance superior to CPU performance on high\ndimensional, large scale ANN problems in time-critical real-world applications,\nlike loop-closing in videos.</p>\n", "tags": ["DATASETS", "Efficiency And Optimization", "CVPR", "Quantization", "Evaluation"], "tsne_embedding": [17.510284423828125, 20.836977005004883], "cluster": 0}, {"key": "wong2024shotit", "year": "2024", "citations": "15", "title": "Shotit: Compute-efficient Image-to-video Search Engine For The Cloud", "abstract": "<p>With the rapid growth of information technology, users are exposed to a\nmassive amount of data online, including image, music, and video. This has led\nto strong needs to provide effective corresponsive search services such as\nimage, music, and video search services. Most of them are operated based on\nkeywords, namely using keywords to find related image, music, and video.\nAdditionally, there are image-to-image search services that enable users to\nfind similar images using one input image. Given that videos are essentially\ncomposed of image frames, then similar videos can be searched by one input\nimage or screenshot. We want to target this scenario and provide an efficient\nmethod and implementation in this paper.\n  We present Shotit, a cloud-native image-to-video search engine that tailors\nthis search scenario in a compute-efficient approach. One main limitation faced\nin this scenario is the scale of its dataset. A typical image-to-image search\nengine only handles one-to-one relationships, colloquially, one image\ncorresponds to another single image. But image-to-video proliferates. Take a\n24-min length video as an example, it will generate roughly 20,000 image\nframes. As the number of videos grows, the scale of the dataset explodes\nexponentially. In this case, a compute-efficient approach ought to be\nconsidered, and the system design should cater to the cloud-native trend.\nChoosing an emerging technology - vector database as its backbone, Shotit fits\nthese two metrics performantly. Experiments for two different datasets, a 50\nthousand-scale Blender Open Movie dataset, and a 50 million-scale proprietary\nTV genre dataset at a 4 Core 32GB RAM Intel Xeon Gold 6271C cloud machine with\nobject storage reveal the effectiveness of Shotit. A demo regarding the Blender\nOpen Movie dataset is illustrated within this paper.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Tools & Libraries"], "tsne_embedding": [-5.1276984214782715, 22.667606353759766], "cluster": 6}, {"key": "woodbridge2018detecting", "year": "2018", "citations": "34", "title": "Detecting Homoglyph Attacks With A Siamese Neural Network", "abstract": "<p>A homoglyph (name spoofing) attack is a common technique used by adversaries\nto obfuscate file and domain names. This technique creates process or domain\nnames that are visually similar to legitimate and recognized names. For\ninstance, an attacker may create malware with the name svch0st.exe so that in a\nvisual inspection of running processes or a directory listing, the process or\nfile name might be mistaken as the Windows system process svchost.exe. There\nhas been limited published research on detecting homoglyph attacks. Current\napproaches rely on string comparison algorithms (such as Levenshtein distance)\nthat result in computationally heavy solutions with a high number of false\npositives. In addition, there is a deficiency in the number of publicly\navailable datasets for reproducible research, with most datasets focused on\nphishing attacks, in which homoglyphs are not always used. This paper presents\na fundamentally different solution to this problem using a Siamese\nconvolutional neural network (CNN). Rather than leveraging similarity based on\ncharacter swaps and deletions, this technique uses a learned metric on strings\nrendered as images: a CNN learns features that are optimized to detect visual\nsimilarity of the rendered strings. The trained model is used to convert\nthousands of potentially targeted process or domain names to feature vectors.\nThese feature vectors are indexed using randomized KD-Trees to make similarity\nsearches extremely fast with minimal computational processing. This technique\nshows a considerable 13% to 45% improvement over baseline techniques in terms\nof area under the receiver operating characteristic curve (ROC AUC). In\naddition, we provide both code and data to further future research.</p>\n", "tags": ["Tree Based ANN", "DATASETS", "Evaluation"], "tsne_embedding": [-9.178013801574707, -1.5522176027297974], "cluster": 8}, {"key": "wu2016robust", "year": "2016", "citations": "49", "title": "Robust Hashing For Multi-view Data: Jointly Learning Low-rank Kernelized Similarity Consensus And Hash Functions", "abstract": "<p>Learning hash functions/codes for similarity search over multi-view data is\nattracting increasing attention, where similar hash codes are assigned to the\ndata objects characterizing consistently neighborhood relationship across\nviews. Traditional methods in this category inherently suffer three\nlimitations: 1) they commonly adopt a two-stage scheme where similarity matrix\nis first constructed, followed by a subsequent hash function learning; 2) these\nmethods are commonly developed on the assumption that data samples with\nmultiple representations are noise-free,which is not practical in real-life\napplications; 3) they often incur cumbersome training model caused by the\nneighborhood graph construction using all \\(N\\) points in the database (\\(O(N)\\)).\nIn this paper, we motivate the problem of jointly and efficiently training the\nrobust hash functions over data objects with multi-feature representations\nwhich may be noise corrupted. To achieve both the robustness and training\nefficiency, we propose an approach to effectively and efficiently learning\nlow-rank kernelized \\footnote{We use kernelized similarity rather than kernel,\nas it is not a squared symmetric matrix for data-landmark affinity matrix.}\nhash functions shared across views. Specifically, we utilize landmark graphs to\nconstruct tractable similarity matrices in multi-views to automatically\ndiscover neighborhood structure in the data. To learn robust hash functions, a\nlatent low-rank kernel function is used to construct hash functions in order to\naccommodate linearly inseparable data. In particular, a latent kernelized\nsimilarity matrix is recovered by rank minimization on multiple kernel-based\nsimilarity matrices. Extensive experiments on real-world multi-view datasets\nvalidate the efficacy of our method in the presence of error corruptions.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Graph Based ANN", "Efficiency And Optimization", "Similarity Search", "Robustness"], "tsne_embedding": [12.060782432556152, 13.568511962890625], "cluster": 0}, {"key": "wu2017improved", "year": "2017", "citations": "19", "title": "Improved Consistent Weighted Sampling Revisited", "abstract": "<p>Min-Hash is a popular technique for efficiently estimating the Jaccard\nsimilarity of binary sets. Consistent Weighted Sampling (CWS) generalizes the\nMin-Hash scheme to sketch weighted sets and has drawn increasing interest from\nthe community. Due to its constant-time complexity independent of the values of\nthe weights, Improved CWS (ICWS) is considered as the state-of-the-art CWS\nalgorithm. In this paper, we revisit ICWS and analyze its underlying mechanism\nto show that there actually exists dependence between the two components of the\nhash-code produced by ICWS, which violates the condition of independence. To\nremedy the problem, we propose an Improved ICWS (I\\(^2\\)CWS) algorithm which not\nonly shares the same theoretical computational complexity as ICWS but also\nabides by the required conditions of the CWS scheme. The experimental results\non a number of synthetic data sets and real-world text data sets demonstrate\nthat our I\\(^2\\)CWS algorithm can estimate the Jaccard similarity more\naccurately, and also compete with or outperform the compared methods, including\nICWS, in classification and top-\\(K\\) retrieval, after relieving the underlying\ndependence.</p>\n", "tags": [], "tsne_embedding": [-1.697603702545166, 7.112185955047607], "cluster": 8}, {"key": "wu2017sampling", "year": "2017", "citations": "863", "title": "Sampling Matters In Deep Embedding Learning", "abstract": "<p>Deep embeddings answer one simple question: How similar are two images?\nLearning these embeddings is the bedrock of verification, zero-shot learning,\nand visual search. The most prominent approaches optimize a deep convolutional\nnetwork with a suitable loss function, such as contrastive loss or triplet\nloss. While a rich line of work focuses solely on the loss functions, we show\nin this paper that selecting training examples plays an equally important role.\nWe propose distance weighted sampling, which selects more informative and\nstable examples than traditional approaches. In addition, we show that a simple\nmargin based loss is sufficient to outperform all other loss functions. We\nevaluate our approach on the Stanford Online Products, CAR196, and the\nCUB200-2011 datasets for image retrieval and clustering, and on the LFW dataset\nfor face verification. Our method achieves state-of-the-art performance on all\nof them.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Graph Based ANN", "Distance Metric Learning", "ICCV", "Evaluation"], "tsne_embedding": [-21.775911331176758, 8.742642402648926], "cluster": 3}, {"key": "wu2017structured", "year": "2017", "citations": "71", "title": "Structured Deep Hashing With Convolutional Neural Networks For Fast Person Re-identification", "abstract": "<p>Given a pedestrian image as a query, the purpose of person re-identification\nis to identify the correct match from a large collection of gallery images\ndepicting the same person captured by disjoint camera views. The critical\nchallenge is how to construct a robust yet discriminative feature\nrepresentation to capture the compounded variations in pedestrian appearance.\nTo this end, deep learning methods have been proposed to extract hierarchical\nfeatures against extreme variability of appearance. However, existing methods\nin this category generally neglect the efficiency in the matching stage whereas\nthe searching speed of a re-identification system is crucial in real-world\napplications. In this paper, we present a novel deep hashing framework with\nConvolutional Neural Networks (CNNs) for fast person re-identification.\nTechnically, we simultaneously learn both CNN features and hash functions/codes\nto get robust yet discriminative features and similarity-preserving hash codes.\nThereby, person re-identification can be resolved by efficiently computing and\nranking the Hamming distances between images. A structured loss function\ndefined over positive pairs and hard negatives is proposed to formulate a novel\noptimization problem so that fast convergence and more stable optimized\nsolution can be obtained. Extensive experiments on two benchmarks CUHK03\n\\cite{FPNN} and Market-1501 \\cite{Market1501} show that the proposed deep\narchitecture is efficacy over state-of-the-arts.</p>\n", "tags": ["Hashing Methods", "Efficiency And Optimization", "Neural Hashing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [4.154658317565918, 23.309173583984375], "cluster": 6}, {"key": "wu2018cycle", "year": "2018", "citations": "189", "title": "Cycle-consistent Deep Generative Hashing For Cross-modal Retrieval", "abstract": "<p>In this paper, we propose a novel deep generative approach to cross-modal\nretrieval to learn hash functions in the absence of paired training samples\nthrough the cycle consistency loss. Our proposed approach employs adversarial\ntraining scheme to lean a couple of hash functions enabling translation between\nmodalities while assuming the underlying semantic relationship. To induce the\nhash codes with semantics to the input-output pair, cycle consistency loss is\nfurther proposed upon the adversarial training to strengthen the correlations\nbetween inputs and corresponding outputs. Our approach is generative to learn\nhash functions such that the learned hash codes can maximally correlate each\ninput-output correspondence, meanwhile can also regenerate the inputs so as to\nminimize the information loss. The learning to hash embedding is thus performed\nto jointly optimize the parameters of the hash functions across modalities as\nwell as the associated generative models. Extensive experiments on a variety of\nlarge-scale cross-modal data sets demonstrate that our proposed method achieves\nbetter retrieval results than the state-of-the-arts.</p>\n", "tags": ["Multimodal Retrieval", "Hashing Methods", "Robustness"], "tsne_embedding": [-7.587344646453857, -8.258445739746094], "cluster": 9}, {"key": "wu2018learning", "year": "2018", "citations": "15", "title": "Learning Product Codebooks Using Vector Quantized Autoencoders For Image Retrieval", "abstract": "<p>Vector-Quantized Variational Autoencoders (VQ-VAE)[1] provide an unsupervised\nmodel for learning discrete representations by combining vector quantization\nand autoencoders. In this paper, we study the use of VQ-VAE for representation\nlearning for downstream tasks, such as image retrieval. We first describe the\nVQ-VAE in the context of an information-theoretic framework. We show that the\nregularization term on the learned representation is determined by the size of\nthe embedded codebook before the training and it affects the generalization\nability of the model. As a result, we introduce a hyperparameter to balance the\nstrength of the vector quantizer and the reconstruction error. By tuning the\nhyperparameter, the embedded bottleneck quantizer is used as a regularizer that\nforces the output of the encoder to share a constrained coding space such that\nlearned latent features preserve the similarity relations of the data space. In\naddition, we provide a search range for finding the best hyperparameter.\nFinally, we incorporate the product quantization into the bottleneck stage of\nVQ-VAE and propose an end-to-end unsupervised learning model for the image\nretrieval task. The product quantizer has the advantage of generating\nlarge-size codebooks. Fast retrieval can be achieved by using the lookup tables\nthat store the distance between any pair of sub-codewords. State-of-the-art\nretrieval results are achieved by the learned codebooks.</p>\n", "tags": ["Image Retrieval", "Tools & Libraries", "Quantization", "Efficiency And Optimization"], "tsne_embedding": [-19.406553268432617, 0.5742141604423523], "cluster": 3}, {"key": "wu2018local", "year": "2018", "citations": "7", "title": "Local Density Estimation In High Dimensions", "abstract": "<p>An important question that arises in the study of high dimensional vector\nrepresentations learned from data is: given a set \\(\\mathcal{D}\\) of vectors and\na query \\(q\\), estimate the number of points within a specified distance\nthreshold of \\(q\\). We develop two estimators, LSH Count and Multi-Probe Count\nthat use locality sensitive hashing to preprocess the data to accurately and\nefficiently estimate the answers to such questions via importance sampling. A\nkey innovation is the ability to maintain a small number of hash tables via\npreprocessing data structures and algorithms that sample from multiple buckets\nin each hash table. We give bounds on the space requirements and sample\ncomplexity of our schemes, and demonstrate their effectiveness in experiments\non a standard word embedding dataset.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "Graph Based ANN", "DATASETS"], "tsne_embedding": [7.843616962432861, -5.730136871337891], "cluster": 2}, {"key": "wu2018review", "year": "2018", "citations": "30", "title": "A Review For Weighted Minhash Algorithms", "abstract": "<p>Data similarity (or distance) computation is a fundamental research topic\nwhich underpins many high-level applications based on similarity measures in\nmachine learning and data mining. However, in large-scale real-world scenarios,\nthe exact similarity computation has become daunting due to \u201c3V\u201d nature\n(volume, velocity and variety) of big data. In such cases, the hashing\ntechniques have been verified to efficiently conduct similarity estimation in\nterms of both theory and practice. Currently, MinHash is a popular technique\nfor efficiently estimating the Jaccard similarity of binary sets and\nfurthermore, weighted MinHash is generalized to estimate the generalized\nJaccard similarity of weighted sets. This review focuses on categorizing and\ndiscussing the existing works of weighted MinHash algorithms. In this review,\nwe mainly categorize the Weighted MinHash algorithms into quantization-based\napproaches, \u201cactive index\u201d-based ones and others, and show the evolution and\ninherent connection of the weighted MinHash algorithms, from the integer\nweighted MinHash algorithms to real-valued weighted MinHash ones (particularly\nthe Consistent Weighted Sampling scheme). Also, we have developed a python\ntoolbox for the algorithms, and released it in our github. Based on the\ntoolbox, we experimentally conduct a comprehensive comparative study of the\nstandard MinHash algorithm and the weighted MinHash ones.</p>\n", "tags": ["Survey Paper", "Locality Sensitive Hashing", "Hashing Methods", "Quantization"], "tsne_embedding": [7.074583530426025, 3.2010762691497803], "cluster": 4}, {"key": "wu2018unsupervised", "year": "2018", "citations": "175", "title": "Unsupervised Feature Learning Via Non-parametric Instance-level Discrimination", "abstract": "<p>Neural net classifiers trained on data with annotated class labels can also\ncapture apparent visual similarity among categories without being directed to\ndo so. We study whether this observation can be extended beyond the\nconventional domain of supervised learning: Can we learn a good feature\nrepresentation that captures apparent similarity among instances, instead of\nclasses, by merely asking the feature to be discriminative of individual\ninstances? We formulate this intuition as a non-parametric classification\nproblem at the instance-level, and use noise-contrastive estimation to tackle\nthe computational challenges imposed by the large number of instance classes.\nOur experimental results demonstrate that, under unsupervised learning\nsettings, our method surpasses the state-of-the-art on ImageNet classification\nby a large margin. Our method is also remarkable for consistently improving\ntest performance with more training data and better network architectures. By\nfine-tuning the learned feature, we further obtain competitive results for\nsemi-supervised learning and object detection tasks. Our non-parametric model\nis highly compact: With 128 features per image, our method requires only 600MB\nstorage for a million images, enabling fast nearest neighbour retrieval at the\nrun time.</p>\n", "tags": ["Evaluation"], "tsne_embedding": [-3.349174737930298, 3.803922653198242], "cluster": 8}, {"key": "wu2019efficient", "year": "2019", "citations": "7", "title": "Efficient Inner Product Approximation In Hybrid Spaces", "abstract": "<p>Many emerging use cases of data mining and machine learning operate on large\ndatasets with data from heterogeneous sources, specifically with both sparse\nand dense components. For example, dense deep neural network embedding vectors\nare often used in conjunction with sparse textual features to provide high\ndimensional hybrid representation of documents. Efficient search in such hybrid\nspaces is very challenging as the techniques that perform well for sparse\nvectors have little overlap with those that work well for dense vectors.\nPopular techniques like Locality Sensitive Hashing (LSH) and its data-dependent\nvariants also do not give good accuracy in high dimensional hybrid spaces. Even\nthough hybrid scenarios are becoming more prevalent, currently there exist no\nefficient techniques in literature that are both fast and accurate. In this\npaper, we propose a technique that approximates the inner product computation\nin hybrid vectors, leading to substantial speedup in search while maintaining\nhigh accuracy. We also propose efficient data structures that exploit modern\ncomputer architectures, resulting in orders of magnitude faster search than the\nexisting baselines. The performance of the proposed method is demonstrated on\nseveral datasets including a very large scale industrial dataset containing one\nbillion vectors in a billion dimensional space, achieving over 10x speedup and\nhigher accuracy against competitive baselines.</p>\n", "tags": ["Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Evaluation"], "tsne_embedding": [9.107219696044922, -16.117225646972656], "cluster": 2}, {"key": "wu2020nearest", "year": "2020", "citations": "6", "title": "Nearest Neighbor Search For Hyperbolic Embeddings", "abstract": "<p>Embedding into hyperbolic space is emerging as an effective representation\ntechnique for datasets that exhibit hierarchical structure. This development\nmotivates the need for algorithms that are able to effectively extract\nknowledge and insights from datapoints embedded in negatively curved spaces. We\nfocus on the problem of nearest neighbor search, a fundamental problem in data\nanalysis. We present efficient algorithmic solutions that build upon\nestablished methods for nearest neighbor search in Euclidean space, allowing\nfor easy adoption and integration with existing systems. We prove theoretical\nguarantees for our techniques and our experiments demonstrate the effectiveness\nof our approach on real datasets over competing algorithms.</p>\n", "tags": ["DATASETS"], "tsne_embedding": [1.9134429693222046, 15.93476390838623], "cluster": 6}, {"key": "wu2021hashing", "year": "2021", "citations": "30", "title": "Hashing-accelerated Graph Neural Networks For Link Prediction", "abstract": "<p>Networks are ubiquitous in the real world. Link prediction, as one of the key\nproblems for network-structured data, aims to predict whether there exists a\nlink between two nodes. The traditional approaches are based on the explicit\nsimilarity computation between the compact node representation by embedding\neach node into a low-dimensional space. In order to efficiently handle the\nintensive similarity computation in link prediction, the hashing technique has\nbeen successfully used to produce the node representation in the Hamming space.\nHowever, the hashing-based link prediction algorithms face accuracy loss from\nthe randomized hashing techniques or inefficiency from the learning to hash\ntechniques in the embedding process. Currently, the Graph Neural Network (GNN)\nframework has been widely applied to the graph-related tasks in an end-to-end\nmanner, but it commonly requires substantial computational resources and memory\ncosts due to massive parameter learning, which makes the GNN-based algorithms\nimpractical without the help of a powerful workhorse. In this paper, we propose\na simple and effective model called #GNN, which balances the trade-off between\naccuracy and efficiency. #GNN is able to efficiently acquire node\nrepresentation in the Hamming space for link prediction by exploiting the\nrandomized hashing technique to implement message passing and capture\nhigh-order proximity in the GNN framework. Furthermore, we characterize the\ndiscriminative power of #GNN in probability. The extensive experimental results\ndemonstrate that the proposed #GNN algorithm achieves accuracy comparable to\nthe learning-based algorithms and outperforms the randomized algorithm, while\nrunning significantly faster than the learning-based algorithms. Also, the\nproposed algorithm shows excellent scalability on a large-scale network with\nthe limited resources.</p>\n", "tags": ["Tools & Libraries", "Hashing Methods", "Efficiency And Optimization"], "tsne_embedding": [17.355737686157227, 14.792891502380371], "cluster": 0}, {"key": "wu2021linear", "year": "2021", "citations": "15", "title": "Linear-time Self Attention With Codeword Histogram For Efficient Recommendation", "abstract": "<p>Self-attention has become increasingly popular in a variety of sequence\nmodeling tasks from natural language processing to recommendation, due to its\neffectiveness. However, self-attention suffers from quadratic computational and\nmemory complexities, prohibiting its applications on long sequences. Existing\napproaches that address this issue mainly rely on a sparse attention context,\neither using a local window, or a permuted bucket obtained by\nlocality-sensitive hashing (LSH) or sorting, while crucial information may be\nlost. Inspired by the idea of vector quantization that uses cluster centroids\nto approximate items, we propose LISA (LInear-time Self Attention), which\nenjoys both the effectiveness of vanilla self-attention and the efficiency of\nsparse attention. LISA scales linearly with the sequence length, while enabling\nfull contextual attention via computing differentiable histograms of codeword\ndistributions. Meanwhile, unlike some efficient attention methods, our method\nposes no restriction on casual masking or sequence length. We evaluate our\nmethod on four real-world datasets for sequential recommendation. The results\nshow that LISA outperforms the state-of-the-art efficient attention methods in\nboth performance and speed; and it is up to 57x faster and 78x more memory\nefficient than vanilla self-attention.</p>\n", "tags": ["Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Recommender Systems", "Quantization", "Evaluation"], "tsne_embedding": [2.7201571464538574, -7.215692520141602], "cluster": 9}, {"key": "wu2021online", "year": "2021", "citations": "5", "title": "Online Enhanced Semantic Hashing: Towards Effective And Efficient Retrieval For Streaming Multi-modal Data", "abstract": "<p>With the vigorous development of multimedia equipment and applications,\nefficient retrieval of large-scale multi-modal data has become a trendy\nresearch topic. Thereinto, hashing has become a prevalent choice due to its\nretrieval efficiency and low storage cost. Although multi-modal hashing has\ndrawn lots of attention in recent years, there still remain some problems. The\nfirst point is that existing methods are mainly designed in batch mode and not\nable to efficiently handle streaming multi-modal data. The second point is that\nall existing online multi-modal hashing methods fail to effectively handle\nunseen new classes which come continuously with streaming data chunks. In this\npaper, we propose a new model, termed Online enhAnced SemantIc haShing (OASIS).\nWe design novel semantic-enhanced representation for data, which could help\nhandle the new coming classes, and thereby construct the enhanced semantic\nobjective function. An efficient and effective discrete online optimization\nalgorithm is further proposed for OASIS. Extensive experiments show that our\nmethod can exceed the state-of-the-art models. For good reproducibility and\nbenefiting the community, our code and data are already available in\nsupplementary material and will be made publicly available.</p>\n", "tags": ["AAAI", "Hashing Methods", "Efficiency And Optimization", "Alt", "Text Retrieval", "Similarity Search"], "tsne_embedding": [-20.816743850708008, -13.743351936340332], "cluster": 1}, {"key": "wu2022hqann", "year": "2022", "citations": "8", "title": "HQANN: Efficient And Robust Similarity Search For Hybrid Queries With Structured And Unstructured Constraints", "abstract": "<p>The in-memory approximate nearest neighbor search (ANNS) algorithms have\nachieved great success for fast high-recall query processing, but are extremely\ninefficient when handling hybrid queries with unstructured (i.e., feature\nvectors) and structured (i.e., related attributes) constraints. In this paper,\nwe present HQANN, a simple yet highly efficient hybrid query processing\nframework which can be easily embedded into existing proximity graph-based ANNS\nalgorithms. We guarantee both low latency and high recall by leveraging\nnavigation sense among attributes and fusing vector similarity search with\nattribute filtering. Experimental results on both public and in-house datasets\ndemonstrate that HQANN is 10x faster than the state-of-the-art hybrid ANNS\nsolutions to reach the same recall quality and its performance is hardly\naffected by the complexity of attributes. It can reach 99% recall@10 in just\naround 50 microseconds On GLOVE-1.2M with thousands of attribute constraints.</p>\n", "tags": ["DATASETS", "Evaluation", "Efficiency And Optimization", "Graph Based ANN", "CIKM", "Similarity Search", "Tools & Libraries"], "tsne_embedding": [13.893112182617188, -3.2903287410736084], "cluster": 2}, {"key": "wu2022self", "year": "2022", "citations": "51", "title": "Self-supervised Consistent Quantization For Fully Unsupervised Image Retrieval", "abstract": "<p>Unsupervised image retrieval aims to learn an efficient retrieval system\nwithout expensive data annotations, but most existing methods rely heavily on\nhandcrafted feature descriptors or pre-trained feature extractors. To minimize\nhuman supervision, recent advance proposes deep fully unsupervised image\nretrieval aiming at training a deep model from scratch to jointly optimize\nvisual features and quantization codes. However, existing approach mainly\nfocuses on instance contrastive learning without considering underlying\nsemantic structure information, resulting in sub-optimal performance. In this\nwork, we propose a novel self-supervised consistent quantization approach to\ndeep fully unsupervised image retrieval, which consists of part consistent\nquantization and global consistent quantization. In part consistent\nquantization, we devise part neighbor semantic consistency learning with\ncodeword diversity regularization. This allows to discover underlying neighbor\nstructure information of sub-quantized representations as self-supervision. In\nglobal consistent quantization, we employ contrastive learning for both\nembedding and quantized representations and fuses these representations for\nconsistent contrastive regularization between instances. This can make up for\nthe loss of useful representation information during quantization and\nregularize consistency between instances. With a unified learning objective of\npart and global consistent quantization, our approach exploits richer\nself-supervision cues to facilitate model learning. Extensive experiments on\nthree benchmark datasets show the superiority of our approach over the\nstate-of-the-art methods.</p>\n", "tags": ["Image Retrieval", "DATASETS", "ICCV", "Similarity Search", "Quantization", "Evaluation"], "tsne_embedding": [-14.69489574432373, 6.86997652053833], "cluster": 3}, {"key": "wu2024sign", "year": "2024", "citations": "10", "title": "Sign-guided Bipartite Graph Hashing For Hamming Space Search", "abstract": "<p>Bipartite graph hashing (BGH) is extensively used for Top-K search in Hamming\nspace at low storage and inference costs. Recent research adopts graph\nconvolutional hashing for BGH and has achieved the state-of-the-art\nperformance. However, the contributions of its various influencing factors to\nhashing performance have not been explored in-depth, including the\nsame/different sign count between two binary embeddings during Hamming space\nsearch (sign property), the contribution of sub-embeddings at each layer (model\nproperty), the contribution of different node types in the bipartite graph\n(node property), and the combination of augmentation methods. In this work, we\nbuild a lightweight graph convolutional hashing model named LightGCH by mainly\nremoving the augmentation methods of the state-of-the-art model BGCH. By\nanalyzing the contributions of each layer and node type to performance, as well\nas analyzing the Hamming similarity statistics at each layer, we find that the\nactual neighbors in the bipartite graph tend to have low Hamming similarity at\nthe shallow layer, and all nodes tend to have high Hamming similarity at the\ndeep layers in LightGCH. To tackle these problems, we propose a novel\nsign-guided framework SGBGH to make improvement, which uses sign-guided\nnegative sampling to improve the Hamming similarity of neighbors, and uses\nsign-aware contrastive learning to help nodes learn more uniform\nrepresentations. Experimental results show that SGBGH outperforms BGCH and\nLightGCH significantly in embedding quality.</p>\n", "tags": ["Similarity Search", "Tools & Libraries", "Hashing Methods", "Evaluation"], "tsne_embedding": [14.226252555847168, 10.754524230957031], "cluster": 0}, {"key": "wu2025deep", "year": "2025", "citations": "99", "title": "Deep Incremental Hashing Network For Efficient Image Retrieval", "abstract": "<p>Hashing has shown great potential in large-scale image retrieval due to its storage and computation efficiency, especially the recent deep supervised hashing methods. To achieve promising performance, deep supervised hashing methods require a large amount of training data from different classes. However, when images of new categories emerge, existing deep hashing methods have to retrain the CNN model and generate hash codes for all the database images again, which is impractical for large-scale retrieval system.\nIn this paper, we propose a novel deep hashing framework, called Deep Incremental Hashing Network (DIHN), for learning hash codes in an incremental manner. DIHN learns the hash codes for the new coming images directly, while keeping the old ones unchanged. Simultaneously, a deep hash function for query set is learned by preserving the similarities between training points. Extensive experiments on two widely used image retrieval benchmarks demonstrate that the proposed DIHN framework can significantly decrease the training time while keeping the state-of-the-art retrieval accuracy.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Efficiency And Optimization", "CVPR", "Neural Hashing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-13.453996658325195, -5.6283955574035645], "cluster": 1}, {"key": "wurzer2016randomised", "year": "2016", "citations": "81", "title": "Randomised Relevance Model", "abstract": "<p>Relevance Models are well-known retrieval models and capable of producing\ncompetitive results. However, because they use query expansion they can be very\nslow. We address this slowness by incorporating two variants of locality\nsensitive hashing (LSH) into the query expansion process. Results on two\ndocument collections suggest that we can obtain large reductions in the amount\nof work, with a small reduction in effectiveness. Our approach is shown to be\nadditive when pruning query terms.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods"], "tsne_embedding": [11.588408470153809, -7.214119911193848], "cluster": 2}, {"key": "wygocki2017fast", "year": "2017", "citations": "85", "title": "On Fast Bounded Locality Sensitive Hashing", "abstract": "<p>In this paper, we examine the hash functions expressed as scalar products,\ni.e., \\(f(x)=&lt;v,x&gt;\\), for some bounded random vector \\(v\\). Such hash functions\nhave numerous applications, but often there is a need to optimize the choice of\nthe distribution of \\(v\\). In the present work, we focus on so-called\nanti-concentration bounds, i.e. the upper bounds of \\(\\mathbb{P}\\left[|&lt;v,x&gt;| &lt;\n\\alpha \\right]\\). In many applications, \\(v\\) is a vector of independent random\nvariables with standard normal distribution. In such case, the distribution of\n\\(&lt;v,x&gt;\\) is also normal and it is easy to approximate \\(\\mathbb{P}\\left[|&lt;v,x&gt;| &lt;\n\\alpha \\right]\\). Here, we consider two bounded distributions in the context of\nthe anti-concentration bounds. Particularly, we analyze \\(v\\) being a random\nvector from the unit ball in \\(l_{\\infty}\\) and \\(v\\) being a random vector from\nthe unit sphere in \\(l_{2}\\). We show optimal up to a constant anti-concentration\nmeasures for functions \\(f(x)=&lt;v,x&gt;\\).\n  As a consequence of our research, we obtain new best results for \\newline\n\\textit{\\(c\\)-approximate nearest neighbors without false negatives} for \\(l_p\\) in\nhigh dimensional space for all \\(p\\in[1,\\infty]\\), for\n\\(c=\u03a9(\\max\\{\\sqrt{d},d^{1/p}\\})\\). These results improve over those\npresented in [16]. Finally, our paper reports progress on answering the open\nproblem by Pagh~[17], who considered the nearest neighbor search without false\nnegatives for the Hamming distance.</p>\n", "tags": ["KDD", "Locality Sensitive Hashing", "Hashing Methods", "Graph Based ANN"], "tsne_embedding": [32.05592727661133, 0.0007028840482234955], "cluster": 7}, {"key": "xia2016unsupervised", "year": "2016", "citations": "17", "title": "Unsupervised Deep Hashing For Large-scale Visual Search", "abstract": "<p>Learning based hashing plays a pivotal role in large-scale visual search.\nHowever, most existing hashing algorithms tend to learn shallow models that do\nnot seek representative binary codes. In this paper, we propose a novel hashing\napproach based on unsupervised deep learning to hierarchically transform\nfeatures into hash codes. Within the heterogeneous deep hashing framework, the\nautoencoder layers with specific constraints are considered to model the\nnonlinear mapping between features and binary codes. Then, a Restricted\nBoltzmann Machine (RBM) layer with constraints is utilized to reduce the\ndimension in the hamming space. Extensive experiments on the problem of visual\nsearch demonstrate the competitiveness of our proposed approach compared to\nstate-of-the-art.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Compact Codes", "Neural Hashing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-5.875067710876465, 5.852921009063721], "cluster": 8}, {"key": "xia2025supervised", "year": "2025", "citations": "978", "title": "Supervised Hashing Via Image Representation Learning", "abstract": "<p>Hashing is a popular approximate nearest neighbor\nsearch approach for large-scale image retrieval.\nSupervised hashing, which incorporates similarity/dissimilarity\ninformation on entity pairs to improve\nthe quality of hashing function learning, has recently\nreceived increasing attention. However, in the existing\nsupervised hashing methods for images, an input\nimage is usually encoded by a vector of hand-crafted\nvisual features. Such hand-crafted feature vectors\ndo not necessarily preserve the accurate semantic\nsimilarities of images pairs, which may often degrade\nthe performance of hashing function learning. In this\npaper, we propose a supervised hashing method for\nimage retrieval, in which we automatically learn a good\nimage representation tailored to hashing as well as a\nset of hash functions. The proposed method has two\nstages. In the first stage, given the pairwise similarity\nmatrix S over training images, we propose a scalable\ncoordinate descent method to decompose S into a\nproduct of HHT where H is a matrix with each of its\nrows being the approximate hash code associated to\na training image. In the second stage, we propose to\nsimultaneously learn a good feature representation for\nthe input images as well as a set of hash functions, via\na deep convolutional network tailored to the learned\nhash codes in H and optionally the discrete class labels\nof the images. Extensive empirical evaluations on three\nbenchmark datasets with different kinds of images\nshow that the proposed method has superior performance\ngains over several state-of-the-art supervised\nand unsupervised hashing methods.</p>\n", "tags": ["Image Retrieval", "AAAI", "DATASETS", "Hashing Methods", "Evaluation"], "tsne_embedding": [-11.530832290649414, 3.2418291568756104], "cluster": 8}, {"key": "xiao2021neural", "year": "2021", "citations": "7", "title": "Neural Pathsim For Inductive Similarity Search In Heterogeneous Information Networks", "abstract": "<p>PathSim is a widely used meta-path-based similarity in heterogeneous\ninformation networks. Numerous applications rely on the computation of PathSim,\nincluding similarity search and clustering. Computing PathSim scores on large\ngraphs is computationally challenging due to its high time and storage\ncomplexity. In this paper, we propose to transform the problem of approximating\nthe ground truth PathSim scores into a learning problem. We design an\nencoder-decoder based framework, NeuPath, where the algorithmic structure of\nPathSim is considered. Specifically, the encoder module identifies Top T\noptimized path instances, which can approximate the ground truth PathSim, and\nmaps each path instance to an embedding vector. The decoder transforms each\nembedding vector into a scalar respectively, which identifies the similarity\nscore. We perform extensive experiments on two real-world datasets in different\ndomains, ACM and IMDB. Our results demonstrate that NeuPath performs better\nthan state-of-the-art baselines in the PathSim approximation task and\nsimilarity search task.</p>\n", "tags": ["DATASETS", "Evaluation", "CIKM", "Similarity Search", "Tools & Libraries"], "tsne_embedding": [11.087198257446289, 10.273743629455566], "cluster": 0}, {"key": "xiao2022progressively", "year": "2022", "citations": "13", "title": "Progressively Optimized Bi-granular Document Representation For Scalable Embedding Based Retrieval", "abstract": "<p>Ad-hoc search calls for the selection of appropriate answers from a\nmassive-scale corpus. Nowadays, the embedding-based retrieval (EBR) becomes a\npromising solution, where deep learning based document representation and ANN\nsearch techniques are allied to handle this task. However, a major challenge is\nthat the ANN index can be too large to fit into memory, given the considerable\nsize of answer corpus. In this work, we tackle this problem with Bi-Granular\nDocument Representation, where the lightweight sparse embeddings are indexed\nand standby in memory for coarse-grained candidate search, and the heavyweight\ndense embeddings are hosted in disk for fine-grained post verification. For the\nbest of retrieval accuracy, a Progressive Optimization framework is designed.\nThe sparse embeddings are learned ahead for high-quality search of candidates.\nConditioned on the candidate distribution induced by the sparse embeddings, the\ndense embeddings are continuously learned to optimize the discrimination of\nground-truth from the shortlisted candidates. Besides, two techniques: the\ncontrastive quantization and the locality-centric sampling are introduced for\nthe learning of sparse and dense embeddings, which substantially contribute to\ntheir performances. Thanks to the above features, our method effectively\nhandles massive-scale EBR with strong advantages in accuracy: with up to +4.3%\nrecall gain on million-scale corpus, and up to +17.5% recall gain on\nbillion-scale corpus. Besides, Our method is applied to a major sponsored\nsearch platform with substantial gains on revenue (+1.95%), Recall (+1.01%) and\nCTR (+0.49%). Our code is available at https://github.com/microsoft/BiDR.</p>\n", "tags": ["Graph Based ANN", "Large Scale Search", "Quantization", "Vector Indexing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-15.728961944580078, -10.777976989746094], "cluster": 1}, {"key": "xiong2020approximate", "year": "2020", "citations": "356", "title": "Approximate Nearest Neighbor Negative Contrastive Learning For Dense Text Retrieval", "abstract": "<p>Conducting text retrieval in a dense learned representation space has many\nintriguing advantages over sparse retrieval. Yet the effectiveness of dense\nretrieval (DR) often requires combination with sparse retrieval. In this paper,\nwe identify that the main bottleneck is in the training mechanisms, where the\nnegative instances used in training are not representative of the irrelevant\ndocuments in testing. This paper presents Approximate nearest neighbor Negative\nContrastive Estimation (ANCE), a training mechanism that constructs negatives\nfrom an Approximate Nearest Neighbor (ANN) index of the corpus, which is\nparallelly updated with the learning process to select more realistic negative\ntraining instances. This fundamentally resolves the discrepancy between the\ndata distribution used in the training and testing of DR. In our experiments,\nANCE boosts the BERT-Siamese DR model to outperform all competitive dense and\nsparse retrieval baselines. It nearly matches the accuracy of\nsparse-retrieval-and-BERT-reranking using dot-product in the ANCE-learned\nrepresentation space and provides almost 100x speed-up.</p>\n", "tags": ["Text Retrieval"], "tsne_embedding": [-17.46844482421875, -13.576292037963867], "cluster": 1}, {"key": "xiong2025adaptive", "year": "2025", "citations": "13", "title": "Adaptive Quantization For Hashing: An Information-based Approach To Learning Binary Codes", "abstract": "<p>Large-scale data mining and retrieval applications have\nincreasingly turned to compact binary data representations\nas a way to achieve both fast queries and efficient\ndata storage; many algorithms have been proposed for\nlearning effective binary encodings. Most of these algorithms\nfocus on learning a set of projection hyperplanes\nfor the data and simply binarizing the result from each\nhyperplane, but this neglects the fact that informativeness\nmay not be uniformly distributed across the projections.\nIn this paper, we address this issue by proposing\na novel adaptive quantization (AQ) strategy that\nadaptively assigns varying numbers of bits to different\nhyperplanes based on their information content. Our\nmethod provides an information-based schema that preserves\nthe neighborhood structure of data points, and\nwe jointly find the globally optimal bit-allocation for\nall hyperplanes. In our experiments, we compare with\nstate-of-the-art methods on four large-scale datasets\nand find that our adaptive quantization approach significantly\nimproves on traditional hashing methods.</p>\n", "tags": ["Compact Codes", "DATASETS", "Hashing Methods", "Quantization"], "tsne_embedding": [-2.705944776535034, 8.216954231262207], "cluster": 8}, {"key": "xu2012distance", "year": "2012", "citations": "44", "title": "Distance Metric Learning For Kernel Machines", "abstract": "<p>Recent work in metric learning has significantly improved the\nstate-of-the-art in k-nearest neighbor classification. Support vector machines\n(SVM), particularly with RBF kernels, are amongst the most popular\nclassification algorithms that uses distance metrics to compare examples. This\npaper provides an empirical analysis of the efficacy of three of the most\npopular Mahalanobis metric learning algorithms as pre-processing for SVM\ntraining. We show that none of these algorithms generate metrics that lead to\nparticularly satisfying improvements for SVM-RBF classification. As a remedy we\nintroduce support vector metric learning (SVML), a novel algorithm that\nseamlessly combines the learning of a Mahalanobis metric with the training of\nthe RBF-SVM parameters. We demonstrate the capabilities of SVML on nine\nbenchmark data sets of varying sizes and difficulties. In our study, SVML\noutperforms all alternative state-of-the-art metric learning algorithms in\nterms of accuracy and establishes itself as a serious alternative to the\nstandard Euclidean metric with model selection by cross validation.</p>\n", "tags": ["Alt", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [-22.67737579345703, -1.513862133026123], "cluster": 1}, {"key": "xu2016binary", "year": "2016", "citations": "7", "title": "Binary Subspace Coding For Query-by-image Video Retrieval", "abstract": "<p>The query-by-image video retrieval (QBIVR) task has been attracting\nconsiderable research attention recently. However, most existing methods\nrepresent a video by either aggregating or projecting all its frames into a\nsingle datum point, which may easily cause severe information loss. In this\npaper, we propose an efficient QBIVR framework to enable an effective and\nefficient video search with image query. We first define a\nsimilarity-preserving distance metric between an image and its orthogonal\nprojection in the subspace of the video, which can be equivalently transformed\nto a Maximum Inner Product Search (MIPS) problem.\n  Besides, to boost the efficiency of solving the MIPS problem, we propose two\nasymmetric hashing schemes, which bridge the domain gap of images and videos.\nThe first approach, termed Inner-product Binary Coding (IBC), preserves the\ninner relationships of images and videos in a common Hamming space. To further\nimprove the retrieval efficiency, we devise a Bilinear Binary Coding (BBC)\napproach, which employs compact bilinear projections instead of a single large\nprojection matrix. Extensive experiments have been conducted on four real-world\nvideo datasets to verify the effectiveness of our proposed approaches as\ncompared to the state-of-the-arts.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Distance Metric Learning", "Efficiency And Optimization", "Tools & Libraries"], "tsne_embedding": [-9.141748428344727, 16.585237503051758], "cluster": 6}, {"key": "xu2017neural", "year": "2017", "citations": "545", "title": "Neural Network-based Graph Embedding For Cross-platform Binary Code Similarity Detection", "abstract": "<p>The problem of cross-platform binary code similarity detection aims at\ndetecting whether two binary functions coming from different platforms are\nsimilar or not. It has many security applications, including plagiarism\ndetection, malware detection, vulnerability search, etc. Existing approaches\nrely on approximate graph matching algorithms, which are inevitably slow and\nsometimes inaccurate, and hard to adapt to a new task. To address these issues,\nin this work, we propose a novel neural network-based approach to compute the\nembedding, i.e., a numeric vector, based on the control flow graph of each\nbinary function, then the similarity detection can be done efficiently by\nmeasuring the distance between the embeddings for two functions. We implement a\nprototype called Gemini. Our extensive evaluation shows that Gemini outperforms\nthe state-of-the-art approaches by large margins with respect to similarity\ndetection accuracy. Further, Gemini can speed up prior art\u2019s embedding\ngeneration time by 3 to 4 orders of magnitude and reduce the required training\ntime from more than 1 week down to 30 minutes to 10 hours. Our real world case\nstudies demonstrate that Gemini can identify significantly more vulnerable\nfirmware images than the state-of-the-art, i.e., Genius. Our research showcases\na successful application of deep learning on computer security problems.</p>\n", "tags": ["Compact Codes", "Evaluation"], "tsne_embedding": [5.133626461029053, 17.142560958862305], "cluster": 6}, {"key": "xu2017non", "year": "2017", "citations": "5", "title": "Non-iterative Label Propagation In Optimal Leading Forest", "abstract": "<p>Graph based semi-supervised learning (GSSL) has intuitive representation and\ncan be improved by exploiting the matrix calculation. However, it has to\nperform iterative optimization to achieve a preset objective, which usually\nleads to low efficiency. Another inconvenience lying in GSSL is that when new\ndata come, the graph construction and the optimization have to be conducted all\nover again. We propose a sound assumption, arguing that: the neighboring data\npoints are not in peer-to-peer relation, but in a partial-ordered relation\ninduced by the local density and distance between the data; and the label of a\ncenter can be regarded as the contribution of its followers. Starting from the\nassumption, we develop a highly efficient non-iterative label propagation\nalgorithm based on a novel data structure named as optimal leading forest\n(LaPOLeaF). The major weaknesses of the traditional GSSL are addressed by this\nstudy. We further scale LaPOLeaF to accommodate big data by utilizing block\ndistance matrix technique, parallel computing, and Locality-Sensitive Hashing\n(LSH). Experiments on large datasets have shown the promising results of the\nproposed methods.</p>\n", "tags": ["Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Graph Based ANN", "Efficiency And Optimization"], "tsne_embedding": [15.685669898986816, 13.654033660888672], "cluster": 0}, {"key": "xu2017self", "year": "2017", "citations": "208", "title": "Self-taught Convolutional Neural Networks For Short Text Clustering", "abstract": "<p>Short text clustering is a challenging problem due to its sparseness of text\nrepresentation. Here we propose a flexible Self-Taught Convolutional neural\nnetwork framework for Short Text Clustering (dubbed STC^2), which can flexibly\nand successfully incorporate more useful semantic features and learn non-biased\ndeep text representation in an unsupervised manner. In our framework, the\noriginal raw text features are firstly embedded into compact binary codes by\nusing one existing unsupervised dimensionality reduction methods. Then, word\nembeddings are explored and fed into convolutional neural networks to learn\ndeep feature representations, meanwhile the output units are used to fit the\npre-trained binary codes in the training process. Finally, we get the optimal\nclusters by employing K-means to cluster the learned representations. Extensive\nexperimental results demonstrate that the proposed framework is effective,\nflexible and outperform several popular clustering methods when tested on three\npublic short text datasets.</p>\n", "tags": ["DATASETS", "Tools & Libraries", "ICANN", "Compact Codes"], "tsne_embedding": [-11.101978302001953, -14.884859085083008], "cluster": 1}, {"key": "xu2018sketchmate", "year": "2018", "citations": "127", "title": "Sketchmate: Deep Hashing For Million-scale Human Sketch Retrieval", "abstract": "<p>We propose a deep hashing framework for sketch retrieval that, for the first\ntime, works on a multi-million scale human sketch dataset. Leveraging on this\nlarge dataset, we explore a few sketch-specific traits that were otherwise\nunder-studied in prior literature. Instead of following the conventional sketch\nrecognition task, we introduce the novel problem of sketch hashing retrieval\nwhich is not only more challenging, but also offers a better testbed for\nlarge-scale sketch analysis, since: (i) more fine-grained sketch feature\nlearning is required to accommodate the large variations in style and\nabstraction, and (ii) a compact binary code needs to be learned at the same\ntime to enable efficient retrieval. Key to our network design is the embedding\nof unique characteristics of human sketch, where (i) a two-branch CNN-RNN\narchitecture is adapted to explore the temporal ordering of strokes, and (ii) a\nnovel hashing loss is specifically designed to accommodate both the temporal\nand abstract traits of sketches. By working with a 3.8M sketch dataset, we show\nthat state-of-the-art hashing models specifically engineered for static images\nfail to perform well on temporal sketch data. Our network on the other hand not\nonly offers the best retrieval performance on various code sizes, but also\nyields the best generalization performance under a zero-shot setting and when\nre-purposed for sketch recognition. Such superior performances effectively\ndemonstrate the benefit of our sketch-specific design.</p>\n", "tags": ["DATASETS", "Hashing Methods", "CVPR", "Compact Codes", "Neural Hashing", "Similarity Search", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-7.028247356414795, 1.4957716464996338], "cluster": 8}, {"key": "xu2019hashing", "year": "2019", "citations": "8", "title": "Hashing Based Answer Selection", "abstract": "<p>Answer selection is an important subtask of question answering (QA), where\ndeep models usually achieve better performance. Most deep models adopt\nquestion-answer interaction mechanisms, such as attention, to get vector\nrepresentations for answers. When these interaction based deep models are\ndeployed for online prediction, the representations of all answers need to be\nrecalculated for each question. This procedure is time-consuming for deep\nmodels with complex encoders like BERT which usually have better accuracy than\nsimple encoders. One possible solution is to store the matrix representation\n(encoder output) of each answer in memory to avoid recalculation. But this will\nbring large memory cost. In this paper, we propose a novel method, called\nhashing based answer selection (HAS), to tackle this problem. HAS adopts a\nhashing strategy to learn a binary matrix representation for each answer, which\ncan dramatically reduce the memory cost for storing the matrix representations\nof answers. Hence, HAS can adopt complex encoders like BERT in the model, but\nthe online prediction of HAS is still fast with a low memory cost. Experimental\nresults on three popular answer selection datasets show that HAS can outperform\nexisting models to achieve state-of-the-art performance.</p>\n", "tags": ["AAAI", "DATASETS", "Hashing Methods", "Graph Based ANN", "Evaluation"], "tsne_embedding": [-10.900833129882812, -12.273520469665527], "cluster": 1}, {"key": "xu2020learning", "year": "2020", "citations": "10", "title": "On Learning Semantic Representations For Million-scale Free-hand Sketches", "abstract": "<p>In this paper, we study learning semantic representations for million-scale\nfree-hand sketches. This is highly challenging due to the domain-unique traits\nof sketches, e.g., diverse, sparse, abstract, noisy. We propose a dual-branch\nCNNRNN network architecture to represent sketches, which simultaneously encodes\nboth the static and temporal patterns of sketch strokes. Based on this\narchitecture, we further explore learning the sketch-oriented semantic\nrepresentations in two challenging yet practical settings, i.e., hashing\nretrieval and zero-shot recognition on million-scale sketches. Specifically, we\nuse our dual-branch architecture as a universal representation framework to\ndesign two sketch-specific deep models: (i) We propose a deep hashing model for\nsketch retrieval, where a novel hashing loss is specifically designed to\naccommodate both the abstract and messy traits of sketches. (ii) We propose a\ndeep embedding model for sketch zero-shot recognition, via collecting a\nlarge-scale edge-map dataset and proposing to extract a set of semantic vectors\nfrom edge-maps as the semantic knowledge for sketch zero-shot domain alignment.\nBoth deep models are evaluated by comprehensive experiments on million-scale\nsketches and outperform the state-of-the-art competitors.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Neural Hashing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-7.021242141723633, 1.4651157855987549], "cluster": 8}, {"key": "xu2020multi", "year": "2020", "citations": "21", "title": "Multi-feature Discrete Collaborative Filtering For Fast Cold-start Recommendation", "abstract": "<p>Hashing is an effective technique to address the large-scale recommendation\nproblem, due to its high computation and storage efficiency on calculating the\nuser preferences on items. However, existing hashing-based recommendation\nmethods still suffer from two important problems: 1) Their recommendation\nprocess mainly relies on the user-item interactions and single specific content\nfeature. When the interaction history or the content feature is unavailable\n(the cold-start problem), their performance will be seriously deteriorated. 2)\nExisting methods learn the hash codes with relaxed optimization or adopt\ndiscrete coordinate descent to directly solve binary hash codes, which results\nin significant quantization loss or consumes considerable computation time. In\nthis paper, we propose a fast cold-start recommendation method, called\nMulti-Feature Discrete Collaborative Filtering (MFDCF), to solve these\nproblems. Specifically, a low-rank self-weighted multi-feature fusion module is\ndesigned to adaptively project the multiple content features into binary yet\ninformative hash codes by fully exploiting their complementarity. Additionally,\nwe develop a fast discrete optimization algorithm to directly compute the\nbinary hash codes with simple operations. Experiments on two public\nrecommendation datasets demonstrate that MFDCF outperforms the\nstate-of-the-arts on various aspects.</p>\n", "tags": ["AAAI", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Recommender Systems", "Quantization", "Evaluation"], "tsne_embedding": [2.932373046875, -3.7931995391845703], "cluster": 4}, {"key": "xu2021hhf", "year": "2021", "citations": "13", "title": "HHF: Hashing-guided Hinge Function For Deep Hashing Retrieval", "abstract": "<p>Deep hashing has shown promising performance in large-scale image retrieval.\nHowever, latent codes extracted by Deep Neural Networks (DNNs) will inevitably\nlose semantic information during the binarization process, which damages the\nretrieval accuracy and makes it challenging. Although many existing approaches\nperform regularization to alleviate quantization errors, we figure out an\nincompatible conflict between metric learning and quantization learning. The\nmetric loss penalizes the inter-class distances to push different classes\nunconstrained far away. Worse still, it tends to map the latent code deviate\nfrom ideal binarization point and generate severe ambiguity in the binarization\nprocess. Based on the minimum distance of the binary linear code, we creatively\npropose Hashing-guided Hinge Function (HHF) to avoid such conflict. In detail,\nthe carefully-designed inflection point, which relies on the hash bit length\nand category numbers, is explicitly adopted to balance the metric term and\nquantization term. Such a modification prevents the network from falling into\nlocal metric optimal minima in deep hashing. Extensive experiments in CIFAR-10,\nCIFAR-100, ImageNet, and MS-COCO show that HHF consistently outperforms\nexisting techniques, and is robust and flexible to transplant into other\nmethods. Code is available at https://github.com/JerryXu0129/HHF.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Distance Metric Learning", "Alt", "Neural Hashing", "Quantization", "Evaluation"], "tsne_embedding": [-2.818135976791382, 5.348747730255127], "cluster": 8}, {"key": "xu2022hyp", "year": "2022", "citations": "15", "title": "Hyp\\(^2\\) Loss: Beyond Hypersphere Metric Space For Multi-label Image Retrieval", "abstract": "<p>Image retrieval has become an increasingly appealing technique with broad\nmultimedia application prospects, where deep hashing serves as the dominant\nbranch towards low storage and efficient retrieval. In this paper, we carried\nout in-depth investigations on metric learning in deep hashing for establishing\na powerful metric space in multi-label scenarios, where the pair loss suffers\nhigh computational overhead and converge difficulty, while the proxy loss is\ntheoretically incapable of expressing the profound label dependencies and\nexhibits conflicts in the constructed hypersphere space. To address the\nproblems, we propose a novel metric learning framework with Hybrid Proxy-Pair\nLoss (HyP\\(^2\\) Loss) that constructs an expressive metric space with efficient\ntraining complexity w.r.t. the whole dataset. The proposed HyP\\(^2\\) Loss focuses\non optimizing the hypersphere space by learnable proxies and excavating\ndata-to-data correlations of irrelevant pairs, which integrates sufficient data\ncorrespondence of pair-based methods and high-efficiency of proxy-based\nmethods. Extensive experiments on four standard multi-label benchmarks justify\nthe proposed method outperforms the state-of-the-art, is robust among different\nhash bits and achieves significant performance gains with a faster, more stable\nconvergence speed. Our code is available at\nhttps://github.com/JerryXu0129/HyP2-Loss.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Distance Metric Learning", "Neural Hashing", "Similarity Search", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-13.203207015991211, 7.90037202835083], "cluster": 3}, {"key": "xu2024bi", "year": "2024", "citations": "39", "title": "A Bi-metric Framework For Fast Similarity Search", "abstract": "<p>We propose a new \u201cbi-metric\u201d framework for designing nearest neighbor data\nstructures. Our framework assumes two dissimilarity functions: a ground-truth\nmetric that is accurate but expensive to compute, and a proxy metric that is\ncheaper but less accurate. In both theory and practice, we show how to\nconstruct data structures using only the proxy metric such that the query\nprocedure achieves the accuracy of the expensive metric, while only using a\nlimited number of calls to both metrics. Our theoretical results instantiate\nthis framework for two popular nearest neighbor search algorithms: DiskANN and\nCover Tree. In both cases we show that, as long as the proxy metric used to\nconstruct the data structure approximates the ground-truth metric up to a\nbounded factor, our data structure achieves arbitrarily good approximation\nguarantees with respect to the ground-truth metric. On the empirical side, we\napply the framework to the text retrieval problem with two dissimilarity\nfunctions evaluated by ML models with vastly different computational costs. We\nobserve that for almost all data sets in the MTEB benchmark, our approach\nachieves a considerably better accuracy-efficiency tradeoff than the\nalternatives, such as re-ranking.</p>\n", "tags": ["Efficiency And Optimization", "Alt", "Text Retrieval", "Similarity Search", "Tree Based ANN", "Tools & Libraries", "Evaluation"], "tsne_embedding": [16.286672592163086, 0.8905935287475586], "cluster": 7}, {"key": "xu2025convolutional", "year": "2025", "citations": "33", "title": "Convolutional Neural Networks For Text Hashing", "abstract": "<p>Hashing, as a popular approximate nearest neighbor\nsearch, has been widely used for large-scale similarity search. Recently, a spectrum of machine learning\nmethods are utilized to learn similarity-preserving\nbinary codes. However, most of them directly encode the explicit features, keywords, which fail to\npreserve the accurate semantic similarities in binary code beyond keyword matching, especially on\nshort texts. Here we propose a novel text hashing\nframework with convolutional neural networks. In\nparticular, we first embed the keyword features into\ncompact binary code with a locality preserving constraint. Meanwhile word features and position features are together fed into a convolutional network to\nlearn the implicit features which are further incorporated with the explicit features to fit the pre-trained\nbinary code. Such base method can be successfully\naccomplished without any external tags/labels, and\nother three model variations are designed to integrate tags/labels. Experimental results show the\nsuperiority of our proposed approach over several\nstate-of-the-art hashing methods when tested on one\nshort text dataset as well as one normal text dataset.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Compact Codes", "Similarity Search", "Tools & Libraries"], "tsne_embedding": [-11.076133728027344, -14.21273422241211], "cluster": 1}, {"key": "xu2025harmonious", "year": "2025", "citations": "49", "title": "Harmonious Hashing", "abstract": "<p>Hashing-based fast nearest neighbor search technique\nhas attracted great attention in both research\nand industry areas recently. Many existing hashing\napproaches encode data with projection-based hash\nfunctions and represent each projected dimension\nby 1-bit. However, the dimensions with high variance\nhold large energy or information of data but\ntreated equivalently as dimensions with low variance,\nwhich leads to a serious information loss. In\nthis paper, we introduce a novel hashing algorithm\ncalled Harmonious Hashing which aims at learning\nhash functions with low information loss. Specifically,\nwe learn a set of optimized projections to\npreserve the maximum cumulative energy and meet\nthe constraint of equivalent variance on each dimension\nas much as possible. In this way, we could\nminimize the information loss after binarization.\nDespite the extreme simplicity, our method outperforms\nsuperiorly to many state-of-the-art hashing\nmethods in large-scale and high-dimensional nearest\nneighbor search experiments.</p>\n", "tags": ["Hashing Methods"], "tsne_embedding": [17.669483184814453, -0.522374153137207], "cluster": 7}, {"key": "xuan2018deep", "year": "2018", "citations": "124", "title": "Deep Randomized Ensembles For Metric Learning", "abstract": "<p>Learning embedding functions, which map semantically related inputs to nearby\nlocations in a feature space supports a variety of classification and\ninformation retrieval tasks. In this work, we propose a novel, generalizable\nand fast method to define a family of embedding functions that can be used as\nan ensemble to give improved results. Each embedding function is learned by\nrandomly bagging the training labels into small subsets. We show experimentally\nthat these embedding ensembles create effective embedding functions. The\nensemble output defines a metric space that improves state of the art\nperformance for image retrieval on CUB-200-2011, Cars-196, In-Shop Clothes\nRetrieval and VehicleID.</p>\n", "tags": ["Image Retrieval", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [-23.930164337158203, 8.001739501953125], "cluster": 3}, {"key": "xuan2019improved", "year": "2019", "citations": "131", "title": "Improved Embeddings With Easy Positive Triplet Mining", "abstract": "<p>Deep metric learning seeks to define an embedding where semantically similar\nimages are embedded to nearby locations, and semantically dissimilar images are\nembedded to distant locations. Substantial work has focused on loss functions\nand strategies to learn these embeddings by pushing images from the same class\nas close together in the embedding space as possible. In this paper, we propose\nan alternative, loosened embedding strategy that requires the embedding\nfunction only map each training image to the most similar examples from the\nsame class, an approach we call \u201cEasy Positive\u201d mining. We provide a collection\nof experiments and visualizations that highlight that this Easy Positive mining\nleads to embeddings that are more flexible and generalize better to new unseen\ndata. This simple mining strategy yields recall performance that exceeds state\nof the art approaches (including those with complicated loss functions and\nensemble methods) on image retrieval datasets including CUB, Stanford Online\nProducts, In-Shop Clothes and Hotels-50K.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Distance Metric Learning", "Alt", "Evaluation"], "tsne_embedding": [-20.094711303710938, 3.9534196853637695], "cluster": 3}, {"key": "xue2022cross", "year": "2022", "citations": "5", "title": "Cross-scale Context Extracted Hashing For Fine-grained Image Binary Encoding", "abstract": "<p>Deep hashing has been widely applied to large-scale image retrieval tasks\nowing to efficient computation and low storage cost by encoding\nhigh-dimensional image data into binary codes. Since binary codes do not\ncontain as much information as float features, the essence of binary encoding\nis preserving the main context to guarantee retrieval quality. However, the\nexisting hashing methods have great limitations on suppressing redundant\nbackground information and accurately encoding from Euclidean space to Hamming\nspace by a simple sign function. In order to solve these problems, a\nCross-Scale Context Extracted Hashing Network (CSCE-Net) is proposed in this\npaper. Firstly, we design a two-branch framework to capture fine-grained local\ninformation while maintaining high-level global semantic information. Besides,\nAttention guided Information Extraction module (AIE) is introduced between two\nbranches, which suppresses areas of low context information cooperated with\nglobal sliding windows. Unlike previous methods, our CSCE-Net learns a\ncontent-related Dynamic Sign Function (DSF) to replace the original simple sign\nfunction. Therefore, the proposed CSCE-Net is context-sensitive and able to\nperform well on accurate image binary encoding. We further demonstrate that our\nCSCE-Net is superior to the existing hashing methods, which improves retrieval\nperformance on standard benchmarks.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Neural Hashing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-9.73425579071045, 10.189509391784668], "cluster": 8}, {"key": "yamada2021efficient", "year": "2021", "citations": "46", "title": "Efficient Passage Retrieval With Hashing For Open-domain Question Answering", "abstract": "<p>Most state-of-the-art open-domain question answering systems use a neural\nretrieval model to encode passages into continuous vectors and extract them\nfrom a knowledge source. However, such retrieval models often require large\nmemory to run because of the massive size of their passage index. In this\npaper, we introduce Binary Passage Retriever (BPR), a memory-efficient neural\nretrieval model that integrates a learning-to-hash technique into the\nstate-of-the-art Dense Passage Retriever (DPR) to represent the passage index\nusing compact binary codes rather than continuous vectors. BPR is trained with\na multi-task objective over two tasks: efficient candidate generation based on\nbinary codes and accurate reranking based on continuous vectors. Compared with\nDPR, BPR substantially reduces the memory cost from 65GB to 2GB without a loss\nof accuracy on two standard open-domain question answering benchmarks: Natural\nQuestions and TriviaQA. Our code and trained models are available at\nhttps://github.com/studio-ousia/bpr.</p>\n", "tags": ["Evaluation", "Hashing Methods", "ACL", "Graph Based ANN", "Compact Codes"], "tsne_embedding": [-9.525599479675293, -15.835768699645996], "cluster": 1}, {"key": "yan2017privmin", "year": "2017", "citations": "7", "title": "Privmin: Differentially Private Minhash For Jaccard Similarity Computation", "abstract": "<p>In many industrial applications of big data, the Jaccard Similarity\nComputation has been widely used to measure the distance between two profiles\nor sets respectively owned by two users. Yet, one semi-honest user with\nunpredictable knowledge may also deduce the private or sensitive information\n(e.g., the existence of a single element in the original sets) of the other\nuser via the shared similarity. In this paper, we aim at solving the privacy\nissues in Jaccard similarity computation with strict differential privacy\nguarantees. To achieve this, we first define the Conditional \\(\\epsilon\\)-DPSO, a\nrelaxed differential privacy definition regarding set operations, and prove\nthat the MinHash-based Jaccard Similarity Computation (MH-JSC) satisfies this\ndefinition. Then for achieving strict differential privacy in MH-JSC, we\npropose the PrivMin algorithm, which consists of two private operations: 1) the\nPrivate MinHash Value Generation that works by introducing the Exponential\nnoise to the generation of MinHash signature. 2) the Randomized MinHashing\nSteps Selection that works by adopting Randomized Response technique to\nprivately select several steps within the MinHashing phase that are deployed\nwith the Exponential mechanism. Experiments on real datasets demonstrate that\nthe proposed PrivMin algorithm can successfully retain the utility of the\ncomputed similarity while preserving privacy.</p>\n", "tags": ["Locality Sensitive Hashing", "Hashing Methods", "DATASETS"], "tsne_embedding": [7.486756801605225, -23.602375030517578], "cluster": 5}, {"key": "yan2018norm", "year": "2018", "citations": "15", "title": "Norm-range Partition: A Universal Catalyst For LSH Based Maximum Inner Product Search (MIPS)", "abstract": "<p>Recently, locality sensitive hashing (LSH) was shown to be effective for MIPS\nand several algorithms including \\(L_2\\)-ALSH, Sign-ALSH and Simple-LSH have been\nproposed. In this paper, we introduce the norm-range partition technique, which\npartitions the original dataset into sub-datasets containing items with similar\n2-norms and builds hash index independently for each sub-dataset. We prove that\nnorm-range partition reduces the query processing complexity for all existing\nLSH based MIPS algorithms under mild conditions. The key to performance\nimprovement is that norm-range partition allows to use smaller normalization\nfactor most sub-datasets. For efficient query processing, we also formulate a\nunified framework to rank the buckets from the hash indexes of different\nsub-datasets. Experiments on real datasets show that norm-range partition\nsignificantly reduces the number of probed for LSH based MIPS algorithms when\nachieving the same recall.</p>\n", "tags": ["AAAI", "Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Tools & Libraries", "Evaluation"], "tsne_embedding": [10.448881149291992, -2.7388722896575928], "cluster": 4}, {"key": "yan2020deep", "year": "2020", "citations": "413", "title": "Deep Multi-view Enhancement Hashing For Image Retrieval", "abstract": "<p>Hashing is an efficient method for nearest neighbor search in large-scale\ndata space by embedding high-dimensional feature descriptors into a similarity\npreserving Hamming space with a low dimension. However, large-scale high-speed\nretrieval through binary code has a certain degree of reduction in retrieval\naccuracy compared to traditional retrieval methods. We have noticed that\nmulti-view methods can well preserve the diverse characteristics of data.\nTherefore, we try to introduce the multi-view deep neural network into the hash\nlearning field, and design an efficient and innovative retrieval model, which\nhas achieved a significant improvement in retrieval performance. In this paper,\nwe propose a supervised multi-view hash model which can enhance the multi-view\ninformation through neural networks. This is a completely new hash learning\nmethod that combines multi-view and deep learning methods. The proposed method\nutilizes an effective view stability evaluation method to actively explore the\nrelationship among views, which will affect the optimization direction of the\nentire network. We have also designed a variety of multi-data fusion methods in\nthe Hamming space to preserve the advantages of both convolution and\nmulti-view. In order to avoid excessive computing resources on the enhancement\nprocedure during retrieval, we set up a separate structure called memory\nnetwork which participates in training together. The proposed method is\nsystematically evaluated on the CIFAR-10, NUS-WIDE and MS-COCO datasets, and\nthe results show that our method significantly outperforms the state-of-the-art\nsingle-view and multi-view hashing methods.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Compact Codes", "Evaluation"], "tsne_embedding": [-12.813824653625488, -2.501323699951172], "cluster": 8}, {"key": "yan2021binary", "year": "2021", "citations": "10", "title": "Binary Code Based Hash Embedding For Web-scale Applications", "abstract": "<p>Nowadays, deep learning models are widely adopted in web-scale applications\nsuch as recommender systems, and online advertising. In these applications,\nembedding learning of categorical features is crucial to the success of deep\nlearning models. In these models, a standard method is that each categorical\nfeature value is assigned a unique embedding vector which can be learned and\noptimized. Although this method can well capture the characteristics of the\ncategorical features and promise good performance, it can incur a huge memory\ncost to store the embedding table, especially for those web-scale applications.\nSuch a huge memory cost significantly holds back the effectiveness and\nusability of EDRMs. In this paper, we propose a binary code based hash\nembedding method which allows the size of the embedding table to be reduced in\narbitrary scale without compromising too much performance. Experimental\nevaluation results show that one can still achieve 99% performance even if the\nembedding table size is reduced 1000\\(\\times\\) smaller than the original one with\nour proposed method.</p>\n", "tags": ["Evaluation", "Recommender Systems", "Large Scale Search", "Compact Codes", "CIKM", "Alt"], "tsne_embedding": [-2.8083930015563965, -13.016740798950195], "cluster": 9}, {"key": "yan2025deep", "year": "2025", "citations": "27", "title": "Deep Hashing By Discriminating Hard Examples", "abstract": "<p>This paper tackles a rarely explored but critical problem within learning to hash, i.e., to learn hash codes that effectively discriminate hard similar and dissimilar examples, to empower large-scale image retrieval. Hard similar examples refer to image pairs from the same semantic class that demonstrate some shared appearance but have different fine-grained appearance. Hard dissimilar examples are image pairs that come from different semantic classes but exhibit similar appearance. These hard examples generally have a small distance due to the shared appearance. Therefore, effective encoding of the hard examples can well discriminate the relevant images within a small Hamming distance, enabling more accurate retrieval in the top-ranked returned images. However, most existing hashing methods cannot capture this key information as their optimization is dominated byeasy examples, i.e., distant similar/dissimilar pairs that share no or limited appearance. To address this problem, we introduce a novel Gamma distribution-enabled and symmetric Kullback-Leibler divergence-based loss, which is dubbed dual hinge loss because it works similarly as imposing two smoothed hinge losses on the respective similar and dissimilar pairs. Specifically, the loss enforces exponentially variant penalization on the hard similar (dissimilar) examples to emphasize and learn their fine-grained difference. It meanwhile imposes a bounding penalization on easy similar (dissimilar) examples to prevent the dominance of the easy examples in the optimization while preserving the high-level similarity (dissimilarity). This enables our model to well encode the key information carried by both easy and hard examples. Extensive empirical results on three widely-used image retrieval datasets show that (i) our method consistently and substantially outperforms state-of-the-art competing methods using hash codes of the same length and (ii) our method can use significantly (e.g., 50%-75%) shorter hash codes to perform substantially better than, or comparably well to, the competing methods.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Neural Hashing", "Hashing Methods"], "tsne_embedding": [-7.896799564361572, -2.445040464401245], "cluster": 8}, {"key": "yang2015beyond", "year": "2015", "citations": "22", "title": "Beyond Classification: Latent User Interests Profiling From Visual Contents Analysis", "abstract": "<p>User preference profiling is an important task in modern online social\nnetworks (OSN). With the proliferation of image-centric social platforms, such\nas Pinterest, visual contents have become one of the most informative data\nstreams for understanding user preferences. Traditional approaches usually\ntreat visual content analysis as a general classification problem where one or\nmore labels are assigned to each image. Although such an approach simplifies\nthe process of image analysis, it misses the rich context and visual cues that\nplay an important role in people\u2019s perception of images. In this paper, we\nexplore the possibilities of learning a user\u2019s latent visual preferences\ndirectly from image contents. We propose a distance metric learning method\nbased on Deep Convolutional Neural Networks (CNN) to directly extract\nsimilarity information from visual contents and use the derived distance metric\nto mine individual users\u2019 fine-grained visual preferences. Through our\npreliminary experiments using data from 5,790 Pinterest users, we show that\neven for the images within the same category, each user possesses distinct and\nindividually-identifiable visual preferences that are consistent over their\nlifetime. Our results underscore the untapped potential of finer-grained visual\npreference profiling in understanding users\u2019 preferences.</p>\n", "tags": ["Alt", "Distance Metric Learning"], "tsne_embedding": [-12.325034141540527, 20.19554901123047], "cluster": 6}, {"key": "yang2016zero", "year": "2016", "citations": "138", "title": "Zero-shot Hashing Via Transferring Supervised Knowledge", "abstract": "<p>Hashing has shown its efficiency and effectiveness in facilitating\nlarge-scale multimedia applications. Supervised knowledge e.g. semantic labels\nor pair-wise relationship) associated to data is capable of significantly\nimproving the quality of hash codes and hash functions. However, confronted\nwith the rapid growth of newly-emerging concepts and multimedia data on the\nWeb, existing supervised hashing approaches may easily suffer from the scarcity\nand validity of supervised information due to the expensive cost of manual\nlabelling. In this paper, we propose a novel hashing scheme, termed\n<em>zero-shot hashing</em> (ZSH), which compresses images of \u201cunseen\u201d categories\nto binary codes with hash functions learned from limited training data of\n\u201cseen\u201d categories. Specifically, we project independent data labels i.e.\n0/1-form label vectors) into semantic embedding space, where semantic\nrelationships among all the labels can be precisely characterized and thus seen\nsupervised knowledge can be transferred to unseen classes. Moreover, in order\nto cope with the semantic shift problem, we rotate the embedded space to more\nsuitably align the embedded semantics with the low-level visual feature space,\nthereby alleviating the influence of semantic gap. In the meantime, to exert\npositive effects on learning high-quality hash functions, we further propose to\npreserve local structural property and discrete nature in binary codes.\nBesides, we develop an efficient alternating algorithm to solve the ZSH model.\nExtensive experiments conducted on various real-life datasets show the superior\nzero-shot image retrieval performance of ZSH as compared to several\nstate-of-the-art hashing methods.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Alt", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-8.254545211791992, -4.842406749725342], "cluster": 9}, {"key": "yang2018deep", "year": "2018", "citations": "29", "title": "Deep Attention-guided Hashing", "abstract": "<p>With the rapid growth of multimedia data (e.g., image, audio and video etc.)\non the web, learning-based hashing techniques such as Deep Supervised Hashing\n(DSH) have proven to be very efficient for large-scale multimedia search. The\nrecent successes seen in Learning-based hashing methods are largely due to the\nsuccess of deep learning-based hashing methods. However, there are some\nlimitations to previous learning-based hashing methods (e.g., the learned hash\ncodes containing repetitive and highly correlated information). In this paper,\nwe propose a novel learning-based hashing method, named Deep Attention-guided\nHashing (DAgH). DAgH is implemented using two stream frameworks. The core idea\nis to use guided hash codes which are generated by the hashing network of the\nfirst stream framework (called first hashing network) to guide the training of\nthe hashing network of the second stream framework (called second hashing\nnetwork). Specifically, in the first network, it leverages an attention network\nand hashing network to generate the attention-guided hash codes from the\noriginal images. The loss function we propose contains two components: the\nsemantic loss and the attention loss. The attention loss is used to punish the\nattention network to obtain the salient region from pairs of images; in the\nsecond network, these attention-guided hash codes are used to guide the\ntraining of the second hashing network (i.e., these codes are treated as\nsupervised labels to train the second network). By doing this, DAgH can make\nfull use of the most critical information contained in images to guide the\nsecond hashing network in order to learn efficient hash codes in a true\nend-to-end fashion. Results from our experiments demonstrate that DAgH can\ngenerate high quality hash codes and it outperforms current state-of-the-art\nmethods on three benchmark datasets, CIFAR-10, NUS-WIDE, and ImageNet.</p>\n", "tags": ["DATASETS", "Tools & Libraries", "Hashing Methods", "Evaluation"], "tsne_embedding": [-13.282487869262695, -2.97007417678833], "cluster": 1}, {"key": "yang2018efficient", "year": "2018", "citations": "49", "title": "Efficient Image Retrieval Via Decoupling Diffusion Into Online And Offline Processing", "abstract": "<p>Diffusion is commonly used as a ranking or re-ranking method in retrieval\ntasks to achieve higher retrieval performance, and has attracted lots of\nattention in recent years. A downside to diffusion is that it performs slowly\nin comparison to the naive k-NN search, which causes a non-trivial online\ncomputational cost on large datasets. To overcome this weakness, we propose a\nnovel diffusion technique in this paper. In our work, instead of applying\ndiffusion to the query, we pre-compute the diffusion results of each element in\nthe database, making the online search a simple linear combination on top of\nthe k-NN search process. Our proposed method becomes 10~ times faster in terms\nof online search speed. Moreover, we propose to use late truncation instead of\nearly truncation in previous works to achieve better retrieval performance.</p>\n", "tags": ["Image Retrieval", "AAAI", "DATASETS", "Evaluation"], "tsne_embedding": [12.566163063049316, -6.368869304656982], "cluster": 2}, {"key": "yang2018gb", "year": "2018", "citations": "18", "title": "GB-KMV: An Augmented KMV Sketch For Approximate Containment Similarity Search", "abstract": "<p>In this paper, we study the problem of approximate containment similarity\nsearch. Given two records Q and X, the containment similarity between Q and X\nwith respect to Q is |Q intersect X|/ |Q|. Given a query record Q and a set of\nrecords S, the containment similarity search finds a set of records from S\nwhose containment similarity regarding Q are not less than the given threshold.\nThis problem has many important applications in commercial and scientific\nfields such as record matching and domain search. Existing solution relies on\nthe asymmetric LSH method by transforming the containment similarity to\nwell-studied Jaccard similarity. In this paper, we use a different framework by\ntransforming the containment similarity to set intersection. We propose a novel\naugmented KMV sketch technique, namely GB-KMV, which is data-dependent and can\nachieve a good trade-off between the sketch size and the accuracy. We provide a\nset of theoretical analysis to underpin the proposed augmented KMV sketch\ntechnique, and show that it outperforms the state-of-the-art technique LSH-E in\nterms of estimation accuracy under practical assumption. Our comprehensive\nexperiments on real-life datasets verify that GB-KMV is superior to LSH-E in\nterms of the space-accuracy trade-off, time-accuracy trade-off, and the sketch\nconstruction time. For instance, with similar estimation accuracy (F-1 score),\nGB-KMV is over 100 times faster than LSH-E on some real-life dataset.</p>\n", "tags": ["Locality Sensitive Hashing", "Similarity Search", "Tools & Libraries", "DATASETS"], "tsne_embedding": [22.868038177490234, 6.177221775054932], "cluster": 7}, {"key": "yang2019asymmetric", "year": "2019", "citations": "5", "title": "Asymmetric Deep Semantic Quantization For Image Retrieval", "abstract": "<p>Due to its fast retrieval and storage efficiency capabilities, hashing has\nbeen widely used in nearest neighbor retrieval tasks. By using deep learning\nbased techniques, hashing can outperform non-learning based hashing technique\nin many applications. However, we argue that the current deep learning based\nhashing methods ignore some critical problems (e.g., the learned hash codes are\nnot discriminative due to the hashing methods being unable to discover rich\nsemantic information and the training strategy having difficulty optimizing the\ndiscrete binary codes). In this paper, we propose a novel image hashing method,\ntermed as \\textbf{\\underline{A}}symmetric \\textbf{\\underline{D}}eep\n\\textbf{\\underline{S}}emantic \\textbf{\\underline{Q}}uantization\n(\\textbf{ADSQ}). \\textbf{ADSQ} is implemented using three stream frameworks,\nwhich consist of one <em>LabelNet</em> and two <em>ImgNets</em>. The\n<em>LabelNet</em> leverages the power of three fully-connected layers, which are\nused to capture rich semantic information between image pairs. For the two\n<em>ImgNets</em>, they each adopt the same convolutional neural network\nstructure, but with different weights (i.e., asymmetric convolutional neural\nnetworks). The two <em>ImgNets</em> are used to generate discriminative compact\nhash codes. Specifically, the function of the <em>LabelNet</em> is to capture\nrich semantic information that is used to guide the two <em>ImgNets</em> in\nminimizing the gap between the real-continuous features and the discrete binary\ncodes. Furthermore, \\textbf{ADSQ} can utilize the most critical semantic\ninformation to guide the feature learning process and consider the consistency\nof the common semantic space and Hamming space. Experimental results on three\nbenchmarks (i.e., CIFAR-10, NUS-WIDE, and ImageNet) demonstrate that the\nproposed \\textbf{ADSQ} can outperforms current state-of-the-art methods.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Quantization", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-10.588757514953613, -1.8970677852630615], "cluster": 8}, {"key": "yang2019distillhash", "year": "2019", "citations": "149", "title": "Distillhash: Unsupervised Deep Hashing By Distilling Data Pairs", "abstract": "<p>Due to the high storage and search efficiency, hashing has become prevalent\nfor large-scale similarity search. Particularly, deep hashing methods have\ngreatly improved the search performance under supervised scenarios. In\ncontrast, unsupervised deep hashing models can hardly achieve satisfactory\nperformance due to the lack of reliable supervisory similarity signals. To\naddress this issue, we propose a novel deep unsupervised hashing model, dubbed\nDistillHash, which can learn a distilled data set consisted of data pairs,\nwhich have confidence similarity signals. Specifically, we investigate the\nrelationship between the initial noisy similarity signals learned from local\nstructures and the semantic similarity labels assigned by a Bayes optimal\nclassifier. We show that under a mild assumption, some data pairs, of which\nlabels are consistent with those assigned by the Bayes optimal classifier, can\nbe potentially distilled. Inspired by this fact, we design a simple yet\neffective strategy to distill data pairs automatically and further adopt a\nBayesian learning framework to learn hash functions from the distilled data\nset. Extensive experimental results on three widely used benchmark datasets\nshow that the proposed DistillHash consistently accomplishes the\nstate-of-the-art search performance.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "CVPR", "Neural Hashing", "Similarity Search", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-1.5477045774459839, -0.7597009539604187], "cluster": 8}, {"key": "yang2019feature", "year": "2019", "citations": "22", "title": "Feature Pyramid Hashing", "abstract": "<p>In recent years, deep-networks-based hashing has become a leading approach\nfor large-scale image retrieval. Most deep hashing approaches use the high\nlayer to extract the powerful semantic representations. However, these methods\nhave limited ability for fine-grained image retrieval because the semantic\nfeatures extracted from the high layer are difficult in capturing the subtle\ndifferences. To this end, we propose a novel two-pyramid hashing architecture\nto learn both the semantic information and the subtle appearance details for\nfine-grained image search. Inspired by the feature pyramids of convolutional\nneural network, a vertical pyramid is proposed to capture the high-layer\nfeatures and a horizontal pyramid combines multiple low-layer features with\nstructural information to capture the subtle differences. To fuse the low-level\nfeatures, a novel combination strategy, called consensus fusion, is proposed to\ncapture all subtle information from several low-layers for finer retrieval.\nExtensive evaluation on two fine-grained datasets CUB-200-2011 and Stanford\nDogs demonstrate that the proposed method achieves significant performance\ncompared with the state-of-art baselines.</p>\n", "tags": ["DATASETS", "Evaluation", "Neural Hashing", "Hashing Methods", "Image Retrieval", "Multimodal Retrieval"], "tsne_embedding": [-8.398786544799805, 2.9816269874572754], "cluster": 8}, {"key": "yang2019shared", "year": "2019", "citations": "150", "title": "Shared Predictive Cross-modal Deep Quantization", "abstract": "<p>With explosive growth of data volume and ever-increasing diversity of data\nmodalities, cross-modal similarity search, which conducts nearest neighbor\nsearch across different modalities, has been attracting increasing interest.\nThis paper presents a deep compact code learning solution for efficient\ncross-modal similarity search. Many recent studies have proven that\nquantization-based approaches perform generally better than hashing-based\napproaches on single-modal similarity search. In this paper, we propose a deep\nquantization approach, which is among the early attempts of leveraging deep\nneural networks into quantization-based cross-modal similarity search. Our\napproach, dubbed shared predictive deep quantization (SPDQ), explicitly\nformulates a shared subspace across different modalities and two private\nsubspaces for individual modalities, and representations in the shared subspace\nand the private subspaces are learned simultaneously by embedding them to a\nreproducing kernel Hilbert space, where the mean embedding of different\nmodality distributions can be explicitly compared. In addition, in the shared\nsubspace, a quantizer is learned to produce the semantics preserving compact\ncodes with the help of label alignment. Thanks to this novel network\narchitecture in cooperation with supervised quantization training, SPDQ can\npreserve intramodal and intermodal similarities as much as possible and greatly\nreduce quantization error. Experiments on two popular benchmarks corroborate\nthat our approach outperforms state-of-the-art methods.</p>\n", "tags": ["Hashing Methods", "Compact Codes", "Similarity Search", "Quantization", "Evaluation"], "tsne_embedding": [-13.734004974365234, -1.3494795560836792], "cluster": 8}, {"key": "yang2023efficient", "year": "2023", "citations": "9", "title": "Efficient And Effective Similarity Search Over Bipartite Graphs", "abstract": "<p>Similarity search over a bipartite graph aims to retrieve from the graph the\nnodes that are similar to each other, which finds applications in various\nfields such as online advertising, recommender systems etc. Existing similarity\nmeasures either (i) overlook the unique properties of bipartite graphs, or (ii)\nfail to capture high-order information between nodes accurately, leading to\nsuboptimal result quality. Recently, Hidden Personalized PageRank (HPP) is\napplied to this problem and found to be more effective compared with prior\nsimilarity measures. However, existing solutions for HPP computation incur\nsignificant computational costs, rendering it inefficient especially on large\ngraphs.\n  In this paper, we first identify an inherent drawback of HPP and overcome it\nby proposing bidirectional HPP (BHPP). Then, we formulate similarity search\nover bipartite graphs as the problem of approximate BHPP computation, and\npresent an efficient solution Approx-BHPP. Specifically, Approx-BHPP offers\nrigorous theoretical accuracy guarantees with optimal computational complexity\nby combining deterministic graph traversal with matrix operations in an\noptimized and non-trivial way. Moreover, our solution achieves significant gain\nin practical efficiency due to several carefully-designed optimizations.\nExtensive experiments, comparing BHPP against 8 existing similarity measures\nover 7 real bipartite graphs, demonstrate the effectiveness of BHPP on query\nrewriting and item recommendation. Moreover, Approx-BHPP outperforms baseline\nsolutions often by up to orders of magnitude in terms of computational time on\nboth small and large datasets.</p>\n", "tags": ["Efficiency And Optimization", "DATASETS", "Similarity Search", "Recommender Systems"], "tsne_embedding": [17.222991943359375, 13.617785453796387], "cluster": 0}, {"key": "yang2025adaptive", "year": "2025", "citations": "8", "title": "Adaptive Labeling For Deep Learning To Hash", "abstract": "<p>Hash function learning has been widely used for largescale image retrieval because of the efficiency of computation and storage. We introduce AdaLabelHash, a binary\nhash function learning approach via deep neural networks\nin this paper. In AdaLabelHash, class label representations are variables that are adapted during the backward\nnetwork training procedure. We express the labels as hypercube vertices in a K-dimensional space, and the class\nlabel representations together with the network weights are\nupdated in the learning process. As the label representations (or referred to as codewords in this work), are learned\nfrom data, semantically similar classes will be assigned\nwith the codewords that are close to each other in terms\nof Hamming distance in the label space. The codewords\nthen serve as the desired output of the hash function learning, and yield compact and discriminating binary hash representations. AdaLabelHash is easy to implement, which\ncan jointly learn label representations and infer compact\nbinary codes from data. It is applicable to both supervised\nand semi-supervised hash. Experimental results on standard benchmarks demonstrate the satisfactory performance\nof AdaLabelHash.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Efficiency And Optimization", "CVPR", "Compact Codes", "Evaluation"], "tsne_embedding": [-5.508813858032227, 1.2851389646530151], "cluster": 8}, {"key": "yang2025nonlinear", "year": "2025", "citations": "21", "title": "Nonlinear Robust Discrete Hashing For Cross-modal Retrieval", "abstract": "<p>Hashing techniques have recently been successfully applied to solve similarity search problems in the information retrieval field because of their significantly reduced storage and high-speed search capabilities. However, the hash codes learned from most recent cross-modal hashing methods lack the ability to comprehensively preserve adequate information, resulting in a less than desirable performance. To solve this limitation, we propose a novel method termed Nonlinear Robust Discrete Hashing (NRDH), for cross-modal retrieval. The main idea behind NRDH is motivated by the success of neural networks, i.e., nonlinear descriptors, in the field of representation learning, and the use of nonlinear descriptors instead of simple linear transformations is more in line with the complex relationships that exist between common latent representation and heterogeneous multimedia data in the real world. In NRDH, we first learn a common latent representation through nonlinear descriptors to encode complementary and consistent information from the features of the heterogeneous multimedia data. Moreover, an asymmetric learning scheme is proposed to correlate the learned hash codes with the common latent representation. Empirically, we demonstrate that NRDH is able to successfully generate a comprehensive common latent representation that significantly improves the quality of the learned hash codes. Then, NRDH adopts a linear learning strategy to fast learn the hash function with the learned hash codes. Extensive experiments performed on two benchmark datasets highlight the superiority of NRDH over several state-of-the-art methods.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Distance Metric Learning", "Multimodal Retrieval", "SIGIR", "Similarity Search", "Evaluation"], "tsne_embedding": [-4.252213478088379, -5.691240310668945], "cluster": 9}, {"key": "yao2019efficient", "year": "2019", "citations": "29", "title": "Efficient Discrete Supervised Hashing For Large-scale Cross-modal Retrieval", "abstract": "<p>Supervised cross-modal hashing has gained increasing research interest on\nlarge-scale retrieval task owning to its satisfactory performance and\nefficiency. However, it still has some challenging issues to be further\nstudied: 1) most of them fail to well preserve the semantic correlations in\nhash codes because of the large heterogenous gap; 2) most of them relax the\ndiscrete constraint on hash codes, leading to large quantization error and\nconsequent low performance; 3) most of them suffer from relatively high memory\ncost and computational complexity during training procedure, which makes them\nunscalable. In this paper, to address above issues, we propose a supervised\ncross-modal hashing method based on matrix factorization dubbed Efficient\nDiscrete Supervised Hashing (EDSH). Specifically, collective matrix\nfactorization on heterogenous features and semantic embedding with class labels\nare seamlessly integrated to learn hash codes. Therefore, the feature based\nsimilarities and semantic correlations can be both preserved in hash codes,\nwhich makes the learned hash codes more discriminative. Then an efficient\ndiscrete optimal algorithm is proposed to handle the scalable issue. Instead of\nlearning hash codes bit-by-bit, hash codes matrix can be obtained directly\nwhich is more efficient. Extensive experimental results on three public\nreal-world datasets demonstrate that EDSH produces a superior performance in\nboth accuracy and scalability over some existing cross-modal hashing methods.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "Multimodal Retrieval", "Quantization", "Evaluation"], "tsne_embedding": [-7.513736724853516, -6.009213447570801], "cluster": 9}, {"key": "yeh2022embedding", "year": "2022", "citations": "13", "title": "Embedding Compression With Hashing For Efficient Representation Learning In Large-scale Graph", "abstract": "<p>Graph neural networks (GNNs) are deep learning models designed specifically\nfor graph data, and they typically rely on node features as the input to the\nfirst layer. When applying such a type of network on the graph without node\nfeatures, one can extract simple graph-based node features (e.g., number of\ndegrees) or learn the input node representations (i.e., embeddings) when\ntraining the network. While the latter approach, which trains node embeddings,\nmore likely leads to better performance, the number of parameters associated\nwith the embeddings grows linearly with the number of nodes. It is therefore\nimpractical to train the input node embeddings together with GNNs within\ngraphics processing unit (GPU) memory in an end-to-end fashion when dealing\nwith industrial-scale graph data. Inspired by the embedding compression methods\ndeveloped for natural language processing (NLP) tasks, we develop a node\nembedding compression method where each node is compactly represented with a\nbit vector instead of a floating-point vector. The parameters utilized in the\ncompression method can be trained together with GNNs. We show that the proposed\nnode embedding compression method achieves superior performance compared to the\nalternatives.</p>\n", "tags": ["KDD", "Hashing Methods", "Graph Based ANN", "Alt", "Evaluation"], "tsne_embedding": [16.512725830078125, 15.254288673400879], "cluster": 0}, {"key": "yi2015binary", "year": "2015", "citations": "19", "title": "Binary Embedding: Fundamental Limits And Fast Algorithm", "abstract": "<p>Binary embedding is a nonlinear dimension reduction methodology where high\ndimensional data are embedded into the Hamming cube while preserving the\nstructure of the original space. Specifically, for an arbitrary \\(N\\) distinct\npoints in \\(\\mathbb{S}^{p-1}\\), our goal is to encode each point using\n\\(m\\)-dimensional binary strings such that we can reconstruct their geodesic\ndistance up to \\(\\delta\\) uniform distortion. Existing binary embedding\nalgorithms either lack theoretical guarantees or suffer from running time\n\\(O\\big(mp\\big)\\). We make three contributions: (1) we establish a lower bound\nthat shows any binary embedding oblivious to the set of points requires \\(m =\n\u03a9(\\frac{1}{\\delta^2}log{N})\\) bits and a similar lower bound for\nnon-oblivious embeddings into Hamming distance; (2) [DELETED, see comment]; (3)\nwe also provide an analytic result about embedding a general set of points \\(K\n\\subseteq \\mathbb{S}^{p-1}\\) with even infinite size. Our theoretical findings\nare supported through experiments on both synthetic and real data sets.</p>\n", "tags": ["Hashing Methods"], "tsne_embedding": [35.00735092163086, 0.08709648996591568], "cluster": 7}, {"key": "yu2016variable", "year": "2016", "citations": "29", "title": "Variable-length Hashing", "abstract": "<p>Hashing has emerged as a popular technique for large-scale similarity search.\nMost learning-based hashing methods generate compact yet correlated hash codes.\nHowever, this redundancy is storage-inefficient. Hence we propose a lossless\nvariable-length hashing (VLH) method that is both storage- and\nsearch-efficient. Storage efficiency is achieved by converting the fixed-length\nhash code into a variable-length code. Search efficiency is obtained by using a\nmultiple hash table structure. With VLH, we are able to deliberately add\nredundancy into hash codes to improve retrieval performance with little\nsacrifice in storage efficiency or search complexity. In particular, we propose\na block K-means hashing (B-KMH) method to obtain significantly improved\nretrieval performance with no increase in storage and marginal increase in\ncomputational cost.</p>\n", "tags": ["Hashing Methods", "Efficiency And Optimization", "CVPR", "Similarity Search", "Evaluation"], "tsne_embedding": [-2.891144037246704, -7.922818660736084], "cluster": 9}, {"key": "yu2017hyperminhash", "year": "2017", "citations": "16", "title": "Hyperminhash: Minhash In Loglog Space", "abstract": "<p>In this extended abstract, we describe and analyze a lossy compression of\nMinHash from buckets of size \\(O(log n)\\) to buckets of size \\(O(loglog n)\\) by\nencoding using floating-point notation. This new compressed sketch, which we\ncall HyperMinHash, as we build off a HyperLogLog scaffold, can be used as a\ndrop-in replacement of MinHash. Unlike comparable Jaccard index fingerprinting\nalgorithms in sub-logarithmic space (such as b-bit MinHash), HyperMinHash\nretains MinHash\u2019s features of streaming updates, unions, and cardinality\nestimation. For a multiplicative approximation error \\(1+ \\epsilon\\) on a Jaccard\nindex \\( t \\), given a random oracle, HyperMinHash needs \\(O\\left(\\epsilon^{-2}\n\\left( loglog n + log \\frac{1}{ t \\epsilon} \\right)\\right)\\) space.\nHyperMinHash allows estimating Jaccard indices of 0.01 for set cardinalities on\nthe order of \\(10^{19}\\) with relative error of around 10% using 64KiB of\nmemory; MinHash can only estimate Jaccard indices for cardinalities of\n\\(10^{10}\\) with the same memory consumption.</p>\n", "tags": ["Locality Sensitive Hashing"], "tsne_embedding": [28.102083206176758, -1.2415716648101807], "cluster": 7}, {"key": "yu2018discriminative", "year": "2018", "citations": "15", "title": "Discriminative Supervised Hashing For Cross-modal Similarity Search", "abstract": "<p>With the advantage of low storage cost and high retrieval efficiency, hashing\ntechniques have recently been an emerging topic in cross-modal similarity\nsearch. As multiple modal data reflect similar semantic content, many\nresearches aim at learning unified binary codes. However, discriminative\nhashing features learned by these methods are not adequate. This results in\nlower accuracy and robustness. We propose a novel hashing learning framework\nwhich jointly performs classifier learning, subspace learning and matrix\nfactorization to preserve class-specific semantic content, termed\nDiscriminative Supervised Hashing (DSH), to learn the discrimative unified\nbinary codes for multi-modal data. Besides, reducing the loss of information\nand preserving the non-linear structure of data, DSH non-linearly projects\ndifferent modalities into the common space in which the similarity among\nheterogeneous data points can be measured. Extensive experiments conducted on\nthe three publicly available datasets demonstrate that the framework proposed\nin this paper outperforms several state-of -the-art methods.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Similarity Search", "Tools & Libraries", "Robustness"], "tsne_embedding": [-1.7187916040420532, -1.6497596502304077], "cluster": 8}, {"key": "yu2018semi", "year": "2018", "citations": "10", "title": "Semi-supervised Hashing For Semi-paired Cross-view Retrieval", "abstract": "<p>Recently, hashing techniques have gained importance in large-scale retrieval\ntasks because of their retrieval speed. Most of the existing cross-view\nframeworks assume that data are well paired. However, the fully-paired\nmultiview situation is not universal in real applications. The aim of the\nmethod proposed in this paper is to learn the hashing function for semi-paired\ncross-view retrieval tasks. To utilize the label information of partial data,\nwe propose a semi-supervised hashing learning framework which jointly performs\nfeature extraction and classifier learning. The experimental results on two\ndatasets show that our method outperforms several state-of-the-art methods in\nterms of retrieval accuracy.</p>\n", "tags": ["DATASETS", "Tools & Libraries", "Hashing Methods"], "tsne_embedding": [3.2659926414489746, -14.177602767944336], "cluster": 9}, {"key": "yu2019unsupervised", "year": "2019", "citations": "9", "title": "Unsupervised Multi-modal Hashing For Cross-modal Retrieval", "abstract": "<p>With the advantage of low storage cost and high efficiency, hashing learning\nhas received much attention in the domain of Big Data. In this paper, we\npropose a novel unsupervised hashing learning method to cope with this open\nproblem to directly preserve the manifold structure by hashing. To address this\nproblem, both the semantic correlation in textual space and the locally\ngeometric structure in the visual space are explored simultaneously in our\nframework. Besides, the `2;1-norm constraint is imposed on the projection\nmatrices to learn the discriminative hash function for each modality. Extensive\nexperiments are performed to evaluate the proposed method on the three publicly\navailable datasets and the experimental results show that our method can\nachieve superior performance over the state-of-the-art methods.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "Multimodal Retrieval", "Tools & Libraries", "Evaluation"], "tsne_embedding": [1.2311660051345825, -15.504408836364746], "cluster": 5}, {"key": "yu2020comprehensive", "year": "2020", "citations": "18", "title": "Comprehensive Graph-conditional Similarity Preserving Network For Unsupervised Cross-modal Hashing", "abstract": "<p>Unsupervised cross-modal hashing (UCMH) has become a hot topic recently.\nCurrent UCMH focuses on exploring data similarities. However, current UCMH\nmethods calculate the similarity between two data, mainly relying on the two\ndata\u2019s cross-modal features. These methods suffer from inaccurate similarity\nproblems that result in a suboptimal retrieval Hamming space, because the\ncross-modal features between the data are not sufficient to describe the\ncomplex data relationships, such as situations where two data have different\nfeature representations but share the inherent concepts. In this paper, we\ndevise a deep graph-neighbor coherence preserving network (DGCPN).\nSpecifically, DGCPN stems from graph models and explores graph-neighbor\ncoherence by consolidating the information between data and their neighbors.\nDGCPN regulates comprehensive similarity preserving losses by exploiting three\ntypes of data similarities (i.e., the graph-neighbor coherence, the coexistent\nsimilarity, and the intra- and inter-modality consistency) and designs a\nhalf-real and half-binary optimization strategy to reduce the quantization\nerrors during hashing. Essentially, DGCPN addresses the inaccurate similarity\nproblem by exploring and exploiting the data\u2019s intrinsic relationships in a\ngraph. We conduct extensive experiments on three public UCMH datasets. The\nexperimental results demonstrate the superiority of DGCPN, e.g., by improving\nthe mean average precision from 0.722 to 0.751 on MIRFlickr-25K using 64-bit\nhashing codes to retrieve texts from images. We will release the source code\npackage and the trained model on https://github.com/Atmegal/DGCPN.</p>\n", "tags": ["DATASETS", "Quantization", "Hashing Methods", "Evaluation"], "tsne_embedding": [12.913130760192871, 11.413816452026367], "cluster": 0}, {"key": "yu2020self", "year": "2020", "citations": "5", "title": "Self-supervised Asymmetric Deep Hashing With Margin-scalable Constraint", "abstract": "<p>Due to its effectivity and efficiency, deep hashing approaches are widely\nused for large-scale visual search. However, it is still challenging to produce\ncompact and discriminative hash codes for images associated with multiple\nsemantics for two main reasons, 1) similarity constraints designed in most of\nthe existing methods are based upon an oversimplified similarity\nassignment(i.e., 0 for instance pairs sharing no label, 1 for instance pairs\nsharing at least 1 label), 2) the exploration in multi-semantic relevance are\ninsufficient or even neglected in many of the existing methods. These problems\nsignificantly limit the discrimination of generated hash codes. In this paper,\nwe propose a novel self-supervised asymmetric deep hashing method with a\nmargin-scalable constraint(SADH) approach to cope with these problems. SADH\nimplements a self-supervised network to sufficiently preserve semantic\ninformation in a semantic feature dictionary and a semantic code dictionary for\nthe semantics of the given dataset, which efficiently and precisely guides a\nfeature learning network to preserve multilabel semantic information using an\nasymmetric learning strategy. By further exploiting semantic dictionaries, a\nnew margin-scalable constraint is employed for both precise similarity\nsearching and robust hash code generation. Extensive empirical research on four\npopular benchmarks validates the proposed method and shows it outperforms\nseveral state-of-the-art approaches.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Distance Metric Learning", "Efficiency And Optimization", "Neural Hashing", "Evaluation"], "tsne_embedding": [-6.700540065765381, -1.4454500675201416], "cluster": 8}, {"key": "yu2022learning", "year": "2022", "citations": "11", "title": "Learning To Hash Naturally Sorts", "abstract": "<p>Learning to hash pictures a list-wise sorting problem. Its testing metrics,\ne.g., mean-average precision, count on a sorted candidate list ordered by\npair-wise code similarity. However, scarcely does one train a deep hashing\nmodel with the sorted results end-to-end because of the non-differentiable\nnature of the sorting operation. This inconsistency in the objectives of\ntraining and test may lead to sub-optimal performance since the training loss\noften fails to reflect the actual retrieval metric. In this paper, we tackle\nthis problem by introducing Naturally-Sorted Hashing (NSH). We sort the Hamming\ndistances of samples\u2019 hash codes and accordingly gather their latent\nrepresentations for self-supervised training. Thanks to the recent advances in\ndifferentiable sorting approximations, the hash head receives gradients from\nthe sorter so that the hash encoder can be optimized along with the training\nprocedure. Additionally, we describe a novel Sorted Noise-Contrastive\nEstimation (SortedNCE) loss that selectively picks positive and negative\nsamples for contrastive learning, which allows NSH to mine data semantic\nrelations during training in an unsupervised manner. Our extensive experiments\nshow the proposed NSH model significantly outperforms the existing unsupervised\nhashing methods on three benchmarked datasets.</p>\n", "tags": ["DATASETS", "Evaluation", "IJCAI", "Neural Hashing", "Hashing Methods", "AAAI"], "tsne_embedding": [-10.32675838470459, -7.680972576141357], "cluster": 1}, {"key": "yu2022live", "year": "2022", "citations": "5", "title": "Live Laparoscopic Video Retrieval With Compressed Uncertainty", "abstract": "<p>Searching through large volumes of medical data to retrieve relevant\ninformation is a challenging yet crucial task for clinical care. However the\nprimitive and most common approach to retrieval, involving text in the form of\nkeywords, is severely limited when dealing with complex media formats.\nContent-based retrieval offers a way to overcome this limitation, by using rich\nmedia as the query itself. Surgical video-to-video retrieval in particular is a\nnew and largely unexplored research problem with high clinical value,\nespecially in the real-time case: using real-time video hashing, search can be\nachieved directly inside of the operating room. Indeed, the process of hashing\nconverts large data entries into compact binary arrays or hashes, enabling\nlarge-scale search operations at a very fast rate. However, due to fluctuations\nover the course of a video, not all bits in a given hash are equally reliable.\nIn this work, we propose a method capable of mitigating this uncertainty while\nmaintaining a light computational footprint. We present superior retrieval\nresults (3-4 % top 10 mean average precision) on a multi-task evaluation\nprotocol for surgery, using cholecystectomy phases, bypass phases, and coming\nfrom an entirely new dataset introduced here, critical events across six\ndifferent surgery types. Success on this multi-task benchmark shows the\ngeneralizability of our approach for surgical video retrieval.</p>\n", "tags": ["Large Scale Search", "DATASETS", "Hashing Methods", "Evaluation"], "tsne_embedding": [-20.01197052001953, 15.708733558654785], "cluster": 3}, {"key": "yu2025circulant", "year": "2025", "citations": "132", "title": "Circulant Binary Embedding", "abstract": "<p>Binary embedding of high-dimensional data requires\nlong codes to preserve the discriminative\npower of the input space. Traditional binary coding\nmethods often suffer from very high computation\nand storage costs in such a scenario. To\naddress this problem, we propose Circulant Binary\nEmbedding (CBE) which generates binary\ncodes by projecting the data with a circulant matrix.\nThe circulant structure enables the use of\nFast Fourier Transformation to speed up the computation.\nCompared to methods that use unstructured\nmatrices, the proposed method improves\nthe time complexity from O(d^2\n) to O(d log d),\nand the space complexity from O(d^2) to O(d)\nwhere d is the input dimensionality. We also\npropose a novel time-frequency alternating optimization\nto learn data-dependent circulant projections,\nwhich alternatively minimizes the objective\nin original and Fourier domains. We show\nby extensive experiments that the proposed approach\ngives much better performance than the\nstate-of-the-art approaches for fixed time, and\nprovides much faster computation with no performance\ndegradation for fixed number of bits.</p>\n", "tags": ["Alt", "Hashing Methods", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [-15.240137100219727, -20.831092834472656], "cluster": 1}, {"key": "yu2025deep", "year": "2025", "citations": "136", "title": "Deep Graph-neighbor Coherence Preserving Network For Unsupervised Cross-modal Hashing", "abstract": "<p>Unsupervised cross-modal hashing (UCMH) has become a hot topic recently. Current UCMH focuses on exploring data similarities. However, current UCMH methods calculate the similarity between two data, mainly relying on the two data\u2019s cross-modal features. These methods suffer from inaccurate similarity problems that result in a suboptimal retrieval Hamming space, because the cross-modal features between the data are not sufficient to describe the complex data relationships, such as situations where two data have different feature representations but share the inherent concepts. In this paper, we devise a deep graph-neighbor coherence preserving network (DGCPN). Specifically, DGCPN stems from graph models and explores graph-neighbor coherence by consolidating the information between data and their neighbors. DGCPN regulates comprehensive similarity preserving losses by exploiting three types of data similarities (i.e., the graph-neighbor coherence, the coexistent similarity, and the intra- and inter-modality consistency) and designs a half-real and half-binary optimization strategy to reduce the quantization errors during hashing. Essentially, DGCPN addresses the inaccurate similarity problem by exploring and exploiting the data\u2019s intrinsic relationships in a graph. We conduct extensive experiments on three public UCMH datasets. The experimental results demonstrate the superiority of DGCPN, e.g., by improving the mean average precision from 0.722 to 0.751 on MIRFlickr-25K using 64-bit hashing codes to retrieval texts from images. We will release the source code package and the trained model on https://github.com/Atmegal/DGCPN.</p>\n", "tags": ["AAAI", "DATASETS", "Hashing Methods", "Quantization", "Evaluation"], "tsne_embedding": [12.9557466506958, 11.420636177062988], "cluster": 0}, {"key": "yuan2019central", "year": "2019", "citations": "288", "title": "Central Similarity Quantization For Efficient Image And Video Retrieval", "abstract": "<p>Existing data-dependent hashing methods usually learn hash functions from\npairwise or triplet data relationships, which only capture the data similarity\nlocally, and often suffer from low learning efficiency and low collision rate.\nIn this work, we propose a new <em>global</em> similarity metric, termed as\n<em>central similarity</em>, with which the hash codes of similar data pairs are\nencouraged to approach a common center and those for dissimilar pairs to\nconverge to different centers, to improve hash learning efficiency and\nretrieval accuracy. We principally formulate the computation of the proposed\ncentral similarity metric by introducing a new concept, i.e., <em>hash\ncenter</em> that refers to a set of data points scattered in the Hamming space with\na sufficient mutual distance between each other. We then provide an efficient\nmethod to construct well separated hash centers by leveraging the Hadamard\nmatrix and Bernoulli distributions. Finally, we propose the Central Similarity\nQuantization (CSQ) that optimizes the central similarity between data points\nw.r.t.\\ their hash centers instead of optimizing the local similarity. CSQ is\ngeneric and applicable to both image and video hashing scenarios. Extensive\nexperiments on large-scale image and video retrieval tasks demonstrate that CSQ\ncan generate cohesive hash codes for similar data pairs and dispersed hash\ncodes for dissimilar pairs, achieving a noticeable boost in retrieval\nperformance, i.e. 3%-20% in mAP over the previous state-of-the-arts. The code\nis at: https://github.com/yuanli2333/Hadamard-Matrix-for-hashing</p>\n", "tags": ["Hashing Methods", "Distance Metric Learning", "Efficiency And Optimization", "CVPR", "Quantization", "Evaluation"], "tsne_embedding": [2.5667483806610107, 5.855221271514893], "cluster": 4}, {"key": "yuan2019signal", "year": "2019", "citations": "81", "title": "Signal-to-noise Ratio: A Robust Distance Metric For Deep Metric Learning", "abstract": "<p>Deep metric learning, which learns discriminative features to process image\nclustering and retrieval tasks, has attracted extensive attention in recent\nyears. A number of deep metric learning methods, which ensure that similar\nexamples are mapped close to each other and dissimilar examples are mapped\nfarther apart, have been proposed to construct effective structures for loss\nfunctions and have shown promising results. In this paper, different from the\napproaches on learning the loss structures, we propose a robust SNR distance\nmetric based on Signal-to-Noise Ratio (SNR) for measuring the similarity of\nimage pairs for deep metric learning. By exploring the properties of our SNR\ndistance metric from the view of geometry space and statistical theory, we\nanalyze the properties of our metric and show that it can preserve the semantic\nsimilarity between image pairs, which well justify its suitability for deep\nmetric learning. Compared with Euclidean distance metric, our SNR distance\nmetric can further jointly reduce the intra-class distances and enlarge the\ninter-class distances for learned features. Leveraging our SNR distance metric,\nwe propose Deep SNR-based Metric Learning (DSML) to generate discriminative\nfeature embeddings. By extensive experiments on three widely adopted\nbenchmarks, including CARS196, CUB200-2011 and CIFAR10, our DSML has shown its\nsuperiority over other state-of-the-art methods. Additionally, we extend our\nSNR distance metric to deep hashing learning, and conduct experiments on two\nbenchmarks, including CIFAR10 and NUS-WIDE, to demonstrate the effectiveness\nand generality of our SNR distance metric.</p>\n", "tags": ["Hashing Methods", "Distance Metric Learning", "CVPR", "Neural Hashing", "Evaluation"], "tsne_embedding": [-20.716848373413086, 6.201559066772461], "cluster": 3}, {"key": "yuan2023semantic", "year": "2023", "citations": "12", "title": "Semantic-aware Adversarial Training For Reliable Deep Hashing Retrieval", "abstract": "<p>Deep hashing has been intensively studied and successfully applied in\nlarge-scale image retrieval systems due to its efficiency and effectiveness.\nRecent studies have recognized that the existence of adversarial examples poses\na security threat to deep hashing models, that is, adversarial vulnerability.\nNotably, it is challenging to efficiently distill reliable semantic\nrepresentatives for deep hashing to guide adversarial learning, and thereby it\nhinders the enhancement of adversarial robustness of deep hashing-based\nretrieval models. Moreover, current researches on adversarial training for deep\nhashing are hard to be formalized into a unified minimax structure. In this\npaper, we explore Semantic-Aware Adversarial Training (SAAT) for improving the\nadversarial robustness of deep hashing models. Specifically, we conceive a\ndiscriminative mainstay features learning (DMFL) scheme to construct semantic\nrepresentatives for guiding adversarial learning in deep hashing. Particularly,\nour DMFL with the strict theoretical guarantee is adaptively optimized in a\ndiscriminative learning manner, where both discriminative and semantic\nproperties are jointly considered. Moreover, adversarial examples are\nfabricated by maximizing the Hamming distance between the hash codes of\nadversarial samples and mainstay features, the efficacy of which is validated\nin the adversarial attack trials. Further, we, for the first time, formulate\nthe formalized adversarial training of deep hashing into a unified minimax\noptimization under the guidance of the generated mainstay codes. Extensive\nexperiments on benchmark datasets show superb attack performance against the\nstate-of-the-art algorithms, meanwhile, the proposed adversarial training can\neffectively eliminate adversarial perturbations for trustworthy deep\nhashing-based retrieval. Our code is available at\nhttps://github.com/xandery-geek/SAAT.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Neural Hashing", "Evaluation", "Robustness"], "tsne_embedding": [-15.630739212036133, -6.114100456237793], "cluster": 1}, {"key": "yuan2025central", "year": "2025", "citations": "264", "title": "Central Similarity Hashing For Efficient Image And Video Retrieval", "abstract": "<p>Existing data-dependent hashing methods usually learn\nhash functions from the pairwise or triplet data relationships, which only capture the data similarity locally, and\noften suffer low learning efficiency and low collision rate.\nIn this work, we propose a new global similarity metric,\ntermed as central similarity, with which the hash codes for\nsimilar data pairs are encouraged to approach a common\ncenter and those for dissimilar pairs to converge to different centers, to improve hash learning efficiency and retrieval accuracy. We principally formulate the computation of the proposed central similarity metric by introducing a new concept, i.e. hash center that refers to a set\nof data points scattered in the Hamming space with sufficient mutual distance between each other. We then provide an efficient method to construct well separated hash\ncenters by leveraging the Hadamard matrix and Bernoulli\ndistributions. Finally, we propose the Central Similarity\nHashing (CSH) that optimizes the central similarity between data points w.r.t. their hash centers instead of optimizing the local similarity. The CSH is generic and applicable to both image and video hashing. Extensive experiments on large-scale image and video retrieval demonstrate CSH can generate cohesive hash codes for similar\ndata pairs and dispersed hash codes for dissimilar pairs,\nand achieve noticeable boost in retrieval performance, i.e.\n3%-20% in mAP over the previous state-of-the-art. The\ncodes are in: https://github.com/yuanli2333/\nHadamard-Matrix-for-hashing</p>\n", "tags": ["Hashing Methods", "Distance Metric Learning", "Efficiency And Optimization", "CVPR", "Evaluation"], "tsne_embedding": [2.492230176925659, 5.880343437194824], "cluster": 4}, {"key": "yuan2025neighbor", "year": "2025", "citations": "28", "title": "Neighbor-based Feature And Index Enhancement For Person Re-identification", "abstract": "<p>Person re-identification (Re-ID) aims to match the same pedestrian in a large\ngallery with different cameras and views. Enhancing the robustness of the\nextracted feature representations is a main challenge in Re-ID. Existing\nmethods usually improve feature representation by improving model architecture,\nbut most methods ignore the potential contextual information, which limits the\neffectiveness of feature representation and retrieval performance. Neighborhood\ninformation, especially the potential information of multi-order neighborhoods,\ncan effectively enrich feature expression and improve retrieval accuracy, but\nthis has not been fully explored in existing research. Therefore, we propose a\nnovel model DMON-ARO that leverages latent neighborhood information to enhance\nboth feature representation and index performance. Our approach is built on two\ncomplementary modules: Dynamic Multi-Order Neighbor Modeling (DMON) and\nAsymmetric Relationship Optimization (ARO). The DMON module dynamically\naggregates multi-order neighbor relationships, allowing it to capture richer\ncontextual information and enhance feature representation through adaptive\nneighborhood modeling. Meanwhile, ARO refines the distance matrix by optimizing\nquery-to-gallery relationships, improving the index accuracy. Extensive\nexperiments on three benchmark datasets demonstrate that our approach achieves\nperformance improvements against baseline models, which illustrate the\neffectiveness of our model. Specifically, our model demonstrates improvements\nin Rank-1 accuracy and mAP. Moreover, this method can also be directly extended\nto other re-identification tasks.</p>\n", "tags": ["DATASETS", "Evaluation", "Robustness"], "tsne_embedding": [4.539769172668457, 22.15747833251953], "cluster": 6}, {"key": "yuan2025towards", "year": "2025", "citations": "27", "title": "Towards Optimal Deep Hashing Via Policy Gradient", "abstract": "<p>In this paper, we propose a simple yet effective relaxation free method to learn more effective binary codes via policy gradient for\nscalable image search. While a variety of deep hashing methods have been\nproposed in recent years, most of them are confronted by the dilemma\nto obtain optimal binary codes in a truly end-to-end manner with nonsmooth sign activations. Unlike existing methods which usually employ a\ngeneral relaxation framework to adapt to the gradient-based algorithms,\nour approach formulates the non-smooth part of the hashing network\nas sampling with a stochastic policy, so that the retrieval performance\ndegradation caused by the relaxation can be avoided. Specifically, our\nmethod directly generates the binary codes and maximizes the expectation of rewards for similarity preservation, where the network can be\ntrained directly via policy gradient. Hence, the differentiation challenge\nfor discrete optimization can be naturally addressed, which leads to effective gradients and binary codes. Extensive experimental results on three\nbenchmark datasets validate the effectiveness of the proposed method.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Compact Codes", "Neural Hashing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-5.543924808502197, 9.356626510620117], "cluster": 8}, {"key": "yun2024neurohash", "year": "2024", "citations": "10", "title": "Neurohash: A Hyperdimensional Neuro-symbolic Framework For Spatially-aware Image Hashing And Retrieval", "abstract": "<p>Customizable image retrieval from large datasets remains a critical\nchallenge, particularly when preserving spatial relationships within images.\nTraditional hashing methods, primarily based on deep learning, often fail to\ncapture spatial information adequately and lack transparency. In this paper, we\nintroduce NeuroHash, a novel neuro-symbolic framework leveraging\nHyperdimensional Computing (HDC) to enable highly customizable, spatially-aware\nimage retrieval. NeuroHash combines pre-trained deep neural network models with\nHDC-based symbolic models, allowing for flexible manipulation of hash values to\nsupport conditional image retrieval. Our method includes a self-supervised\ncontext-aware HDC encoder and novel loss terms for optimizing lower-dimensional\nbipolar hashing using multilinear hyperplanes. We evaluate NeuroHash on two\nbenchmark datasets, demonstrating superior performance compared to\nstate-of-the-art hashing methods, as measured by mAP@5K scores and our newly\nintroduced metric, mAP@5Kr, which assesses spatial alignment. The results\nhighlight NeuroHash\u2019s ability to achieve competitive performance while offering\nsignificant advantages in flexibility and customization, paving the way for\nmore advanced and versatile image retrieval systems.</p>\n", "tags": ["DATASETS", "Evaluation", "Hashing Methods", "Image Retrieval", "Tools & Libraries", "Multimodal Retrieval"], "tsne_embedding": [-12.851018905639648, 8.205069541931152], "cluster": 3}, {"key": "zadeh2012dimension", "year": "2012", "citations": "53", "title": "Dimension Independent Similarity Computation", "abstract": "<p>We present a suite of algorithms for Dimension Independent Similarity\nComputation (DISCO) to compute all pairwise similarities between very high\ndimensional sparse vectors. All of our results are provably independent of\ndimension, meaning apart from the initial cost of trivially reading in the\ndata, all subsequent operations are independent of the dimension, thus the\ndimension can be very large. We study Cosine, Dice, Overlap, and the Jaccard\nsimilarity measures. For Jaccard similiarity we include an improved version of\nMinHash. Our results are geared toward the MapReduce framework. We empirically\nvalidate our theorems at large scale using data from the social networking site\nTwitter. At time of writing, our algorithms are live in production at\ntwitter.com.</p>\n", "tags": ["Locality Sensitive Hashing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [7.307204723358154, -14.035813331604004], "cluster": 2}, {"key": "zeighami2024nudge", "year": "2024", "citations": "5", "title": "NUDGE: Lightweight Non-parametric Fine-tuning Of Embeddings For Retrieval", "abstract": "<p>\\(k\\)-Nearest Neighbor search on dense vector embeddings (\\(k\\)-NN retrieval)\nfrom pre-trained embedding models is the predominant retrieval method for text\nand images, as well as Retrieval-Augmented Generation (RAG) pipelines. In\npractice, application developers often fine-tune the embeddings to improve\ntheir accuracy on the dataset and query workload in hand. Existing approaches\neither fine-tune the pre-trained model itself or, more efficiently, but at the\ncost of accuracy, train adaptor models to transform the output of the\npre-trained model. We present NUDGE, a family of novel non-parametric embedding\nfine-tuning approaches that are significantly more accurate and efficient than\nboth sets of existing approaches. NUDGE directly modifies the embeddings of\ndata records to maximize the accuracy of \\(k\\)-NN retrieval. We present a\nthorough theoretical and experimental study of NUDGE\u2019s non-parametric approach.\nWe show that even though the underlying problem is NP-Hard, constrained\nvariations can be solved efficiently. These constraints additionally ensure\nthat the changes to the embeddings are modest, avoiding large distortions to\nthe semantics learned during pre-training. In experiments across five\npre-trained models and nine standard text and image retrieval datasets, NUDGE\nruns in minutes and often improves NDCG@10 by more than 10% over existing\nfine-tuning methods. On average, NUDGE provides 3.3x and 4.3x higher increase\nin accuracy and runs 200x and 3x faster, respectively, over fine-tuning the\npre-trained model and training adaptors.</p>\n", "tags": ["Image Retrieval", "SIGIR", "DATASETS"], "tsne_embedding": [-14.270185470581055, -14.88520336151123], "cluster": 1}, {"key": "zemene2017large", "year": "2017", "citations": "38", "title": "Large-scale Image Geo-localization Using Dominant Sets", "abstract": "<p>This paper presents a new approach for the challenging problem of\ngeo-locating an image using image matching in a structured database of\ncity-wide reference images with known GPS coordinates. We cast the\ngeo-localization as a clustering problem on local image features. Akin to\nexisting approaches on the problem, our framework builds on low-level features\nwhich allow partial matching between images. For each local feature in the\nquery image, we find its approximate nearest neighbors in the reference set.\nNext, we cluster the features from reference images using Dominant Set\nclustering, which affords several advantages over existing approaches. First,\nit permits variable number of nodes in the cluster which we use to dynamically\nselect the number of nearest neighbors (typically coming from multiple\nreference images) for each query feature based on its discrimination value.\nSecond, as we also quantify in our experiments, this approach is several orders\nof magnitude faster than existing approaches. Thus, we obtain multiple clusters\n(different local maximizers) and obtain a robust final solution to the problem\nusing multiple weak solutions through constrained Dominant Set clustering on\nglobal image features, where we enforce the constraint that the query image\nmust be included in the cluster. This second level of clustering also bypasses\nheuristic approaches to voting and selecting the reference image that matches\nto the query. We evaluated the proposed framework on an existing dataset of\n102k street view images as well as a new dataset of 300k images, and show that\nit outperforms the state-of-the-art by 20% and 7%, respectively, on the two\ndatasets.</p>\n", "tags": ["DATASETS", "Tools & Libraries"], "tsne_embedding": [4.563214302062988, 21.657854080200195], "cluster": 6}, {"key": "zeng2019simultaneous", "year": "2019", "citations": "5", "title": "Simultaneous Region Localization And Hash Coding For Fine-grained Image Retrieval", "abstract": "<p>Fine-grained image hashing is a challenging problem due to the difficulties\nof discriminative region localization and hash code generation. Most existing\ndeep hashing approaches solve the two tasks independently. While these two\ntasks are correlated and can reinforce each other. In this paper, we propose a\ndeep fine-grained hashing to simultaneously localize the discriminative regions\nand generate the efficient binary codes. The proposed approach consists of a\nregion localization module and a hash coding module. The region localization\nmodule aims to provide informative regions to the hash coding module. The hash\ncoding module aims to generate effective binary codes and give feedback for\nlearning better localizer. Moreover, to better capture subtle differences,\nmulti-scale regions at different layers are learned without the need of\nbounding-box/part annotations. Extensive experiments are conducted on two\npublic benchmark fine-grained datasets. The results demonstrate significant\nimprovements in the performance of our method relative to other fine-grained\nhashing algorithms.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Compact Codes", "Neural Hashing", "Evaluation"], "tsne_embedding": [-4.7470808029174805, 6.867189407348633], "cluster": 8}, {"key": "zeng2021phpq", "year": "2021", "citations": "9", "title": "PHPQ: Pyramid Hybrid Pooling Quantization For Efficient Fine-grained Image Retrieval", "abstract": "<p>Deep hashing approaches, including deep quantization and deep binary hashing,\nhave become a common solution to large-scale image retrieval due to their high\ncomputation and storage efficiency. Most existing hashing methods cannot\nproduce satisfactory results for fine-grained retrieval, because they usually\nadopt the outputs of the last CNN layer to generate binary codes. Since deeper\nlayers tend to summarize visual clues, e.g., texture, into abstract semantics,\ne.g., dogs and cats, the feature produced by the last CNN layer is less\neffective in capturing subtle but discriminative visual details that mostly\nexist in shallow layers. To improve fine-grained image hashing, we propose\nPyramid Hybrid Pooling Quantization (PHPQ). Specifically, we propose a Pyramid\nHybrid Pooling (PHP) module to capture and preserve fine-grained semantic\ninformation from multi-level features, which emphasizes the subtle\ndiscrimination of different sub-categories. Besides, we propose a learnable\nquantization module with a partial codebook attention mechanism, which helps to\noptimize the most relevant codewords and improves the quantization.\nComprehensive experiments on two widely-used public benchmarks, i.e.,\nCUB-200-2011 and Stanford Dogs, demonstrate that PHPQ outperforms\nstate-of-the-art methods.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Neural Hashing", "Quantization", "Evaluation"], "tsne_embedding": [-8.544020652770996, 0.942395806312561], "cluster": 8}, {"key": "zhai2018classification", "year": "2018", "citations": "132", "title": "Classification Is A Strong Baseline For Deep Metric Learning", "abstract": "<p>Deep metric learning aims to learn a function mapping image pixels to\nembedding feature vectors that model the similarity between images. Two major\napplications of metric learning are content-based image retrieval and face\nverification. For the retrieval tasks, the majority of current state-of-the-art\n(SOTA) approaches are triplet-based non-parametric training. For the face\nverification tasks, however, recent SOTA approaches have adopted\nclassification-based parametric training. In this paper, we look into the\neffectiveness of classification based approaches on image retrieval datasets.\nWe evaluate on several standard retrieval datasets such as CAR-196,\nCUB-200-2011, Stanford Online Product, and In-Shop datasets for image retrieval\nand clustering, and establish that our classification-based approach is\ncompetitive across different feature dimensions and base feature networks. We\nfurther provide insights into the performance effects of subsampling classes\nfor scalable classification-based training, and the effects of binarization,\nenabling efficient storage and computation for practical applications.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Distance Metric Learning", "Compact Codes", "Evaluation"], "tsne_embedding": [-22.225452423095703, 9.213159561157227], "cluster": 3}, {"key": "zhai2019learning", "year": "2019", "citations": "33", "title": "Learning A Unified Embedding For Visual Search At Pinterest", "abstract": "<p>At Pinterest, we utilize image embeddings throughout our search and\nrecommendation systems to help our users navigate through visual content by\npowering experiences like browsing of related content and searching for exact\nproducts for shopping. In this work we describe a multi-task deep metric\nlearning system to learn a single unified image embedding which can be used to\npower our multiple visual search products. The solution we present not only\nallows us to train for multiple application objectives in a single deep neural\nnetwork architecture, but takes advantage of correlated information in the\ncombination of all training data from each application to generate a unified\nembedding that outperforms all specialized embeddings previously deployed for\neach product. We discuss the challenges of handling images from different\ndomains such as camera photos, high quality web images, and clean product\ncatalog images. We also detail how to jointly train for multiple product\nobjectives and how to leverage both engagement data and human labeled data. In\naddition, our trained embeddings can also be binarized for efficient storage\nand retrieval without compromising precision and recall. Through comprehensive\nevaluations on offline metrics, user studies, and online A/B experiments, we\ndemonstrate that our proposed unified embedding improves both relevance and\nengagement of our visual search products for both browsing and searching\npurposes when compared to existing specialized embeddings. Finally, the\ndeployment of the unified embedding at Pinterest has drastically reduced the\noperation and engineering cost of maintaining multiple embeddings while\nimproving quality.</p>\n", "tags": ["KDD", "Image Retrieval", "Compact Codes", "Recommender Systems", "Evaluation"], "tsne_embedding": [-21.923885345458984, 9.737418174743652], "cluster": 3}, {"key": "zhan2020weakly", "year": "2020", "citations": "8", "title": "Weakly-supervised Online Hashing", "abstract": "<p>With the rapid development of social websites, recent years have witnessed an\nexplosive growth of social images with user-provided tags which continuously\narrive in a streaming fashion. Due to the fast query speed and low storage\ncost, hashing-based methods for image search have attracted increasing\nattention. However, existing hashing methods for social image retrieval are\nbased on batch mode which violates the nature of social images, i.e., social\nimages are usually generated periodically or collected in a stream fashion.\nAlthough there exist many online image hashing methods, they either adopt\nunsupervised learning which ignore the relevant tags, or are designed in the\nsupervised manner which needs high-quality labels. In this paper, to overcome\nthe above limitations, we propose a new method named Weakly-supervised Online\nHashing (WOH). In order to learn high-quality hash codes, WOH exploits the weak\nsupervision by considering the semantics of tags and removing the noise.\nBesides, We develop a discrete online optimization algorithm for WOH, which is\nefficient and scalable. Extensive experiments conducted on two real-world\ndatasets demonstrate the superiority of WOH compared with several\nstate-of-the-art hashing baselines.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Alt", "Tools & Libraries"], "tsne_embedding": [-8.31378173828125, -4.303539752960205], "cluster": 9}, {"key": "zhan2021jointly", "year": "2021", "citations": "58", "title": "Jointly Optimizing Query Encoder And Product Quantization To Improve Retrieval Performance", "abstract": "<p>Recently, Information Retrieval community has witnessed fast-paced advances\nin Dense Retrieval (DR), which performs first-stage retrieval with\nembedding-based search. Despite the impressive ranking performance, previous\nstudies usually adopt brute-force search to acquire candidates, which is\nprohibitive in practical Web search scenarios due to its tremendous memory\nusage and time cost. To overcome these problems, vector compression methods\nhave been adopted in many practical embedding-based retrieval applications. One\nof the most popular methods is Product Quantization (PQ). However, although\nexisting vector compression methods including PQ can help improve the\nefficiency of DR, they incur severely decayed retrieval performance due to the\nseparation between encoding and compression. To tackle this problem, we present\nJPQ, which stands for Joint optimization of query encoding and Product\nQuantization. It trains the query encoder and PQ index jointly in an end-to-end\nmanner based on three optimization strategies, namely ranking-oriented loss, PQ\ncentroid optimization, and end-to-end negative sampling. We evaluate JPQ on two\npublicly available retrieval benchmarks. Experimental results show that JPQ\nsignificantly outperforms popular vector compression methods. Compared with\nprevious DR models that use brute-force search, JPQ almost matches the best\nretrieval performance with 30x compression on index size. The compressed index\nfurther brings 10x speedup on CPU and 2x speedup on GPU in query latency.</p>\n", "tags": ["Evaluation", "Quantization", "Efficiency And Optimization", "CIKM", "Alt"], "tsne_embedding": [-16.604312896728516, -13.47344970703125], "cluster": 1}, {"key": "zhan2021learning", "year": "2021", "citations": "32", "title": "Learning Discrete Representations Via Constrained Clustering For Effective And Efficient Dense Retrieval", "abstract": "<p>Dense Retrieval (DR) has achieved state-of-the-art first-stage ranking\neffectiveness. However, the efficiency of most existing DR models is limited by\nthe large memory cost of storing dense vectors and the time-consuming nearest\nneighbor search (NNS) in vector space. Therefore, we present RepCONC, a novel\nretrieval model that learns discrete Representations via CONstrained\nClustering. RepCONC jointly trains dual-encoders and the Product Quantization\n(PQ) method to learn discrete document representations and enables fast\napproximate NNS with compact indexes. It models quantization as a constrained\nclustering process, which requires the document embeddings to be uniformly\nclustered around the quantization centroids and supports end-to-end\noptimization of the quantization method and dual-encoders. We theoretically\ndemonstrate the importance of the uniform clustering constraint in RepCONC and\nderive an efficient approximate solution for constrained clustering by reducing\nit to an instance of the optimal transport problem. Besides constrained\nclustering, RepCONC further adopts a vector-based inverted file system (IVF) to\nsupport highly efficient vector search on CPUs. Extensive experiments on two\npopular ad-hoc retrieval benchmarks show that RepCONC achieves better ranking\neffectiveness than competitive vector quantization baselines under different\ncompression ratio settings. It also substantially outperforms a wide range of\nexisting retrieval models in terms of retrieval effectiveness, memory\nefficiency, and time efficiency.</p>\n", "tags": ["Vector Indexing", "Quantization", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [4.169703483581543, -0.4760567843914032], "cluster": 4}, {"key": "zhang2016query", "year": "2016", "citations": "55", "title": "Query-adaptive Image Retrieval By Deep Weighted Hashing", "abstract": "<p>Hashing methods have attracted much attention for large scale image\nretrieval. Some deep hashing methods have achieved promising results by taking\nadvantage of the strong representation power of deep networks recently.\nHowever, existing deep hashing methods treat all hash bits equally. On one\nhand, a large number of images share the same distance to a query image due to\nthe discrete Hamming distance, which raises a critical issue of image retrieval\nwhere fine-grained rankings are very important. On the other hand, different\nhash bits actually contribute to the image retrieval differently, and treating\nthem equally greatly affects the retrieval accuracy of image. To address the\nabove two problems, we propose the query-adaptive deep weighted hashing (QaDWH)\napproach, which can perform fine-grained ranking for different queries by\nweighted Hamming distance. First, a novel deep hashing network is proposed to\nlearn the hash codes and corresponding class-wise weights jointly, so that the\nlearned weights can reflect the importance of different hash bits for different\nimage classes. Second, a query-adaptive image retrieval method is proposed,\nwhich rapidly generates hash bit weights for different query images by fusing\nits semantic probability and the learned class-wise weights. Fine-grained image\nretrieval is then performed by the weighted Hamming distance, which can provide\nmore accurate ranking than the traditional Hamming distance. Experiments on\nfour widely used datasets show that the proposed approach outperforms eight\nstate-of-the-art hashing methods.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Neural Hashing", "Tools & Libraries"], "tsne_embedding": [-9.488343238830566, 4.906548023223877], "cluster": 8}, {"key": "zhang2016ssdh", "year": "2016", "citations": "150", "title": "SSDH: Semi-supervised Deep Hashing For Large Scale Image Retrieval", "abstract": "<p>Hashing methods have been widely used for efficient similarity retrieval on\nlarge scale image database. Traditional hashing methods learn hash functions to\ngenerate binary codes from hand-crafted features, which achieve limited\naccuracy since the hand-crafted features cannot optimally represent the image\ncontent and preserve the semantic similarity. Recently, several deep hashing\nmethods have shown better performance because the deep architectures generate\nmore discriminative feature representations. However, these deep hashing\nmethods are mainly designed for supervised scenarios, which only exploit the\nsemantic similarity information, but ignore the underlying data structures. In\nthis paper, we propose the semi-supervised deep hashing (SSDH) approach, to\nperform more effective hash function learning by simultaneously preserving\nsemantic similarity and underlying data structures. The main contributions are\nas follows: (1) We propose a semi-supervised loss to jointly minimize the\nempirical error on labeled data, as well as the embedding error on both labeled\nand unlabeled data, which can preserve the semantic similarity and capture the\nmeaningful neighbors on the underlying data structures for effective hashing.\n(2) A semi-supervised deep hashing network is designed to extensively exploit\nboth labeled and unlabeled data, in which we propose an online graph\nconstruction method to benefit from the evolving deep features during training\nto better capture semantic neighbors. To the best of our knowledge, the\nproposed deep network is the first deep hashing method that can perform hash\ncode learning and feature learning simultaneously in a semi-supervised fashion.\nExperimental results on 5 widely-used datasets show that our proposed approach\noutperforms the state-of-the-art hashing methods.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Compact Codes", "Neural Hashing", "Similarity Search", "Evaluation"], "tsne_embedding": [-6.299128532409668, -1.4941434860229492], "cluster": 8}, {"key": "zhang2017effective", "year": "2017", "citations": "24", "title": "Effective Image Retrieval Via Multilinear Multi-index Fusion", "abstract": "<p>Multi-index fusion has demonstrated impressive performances in retrieval task\nby integrating different visual representations in a unified framework.\nHowever, previous works mainly consider propagating similarities via neighbor\nstructure, ignoring the high order information among different visual\nrepresentations. In this paper, we propose a new multi-index fusion scheme for\nimage retrieval. By formulating this procedure as a multilinear based\noptimization problem, the complementary information hidden in different indexes\ncan be explored more thoroughly. Specially, we first build our multiple indexes\nfrom various visual representations. Then a so-called index-specific functional\nmatrix, which aims to propagate similarities, is introduced for updating the\noriginal index. The functional matrices are then optimized in a unified tensor\nspace to achieve a refinement, such that the relevant images can be pushed more\ncloser. The optimization problem can be efficiently solved by the augmented\nLagrangian method with theoretical convergence guarantee. Unlike the\ntraditional multi-index fusion scheme, our approach embeds the multi-index\nsubspace structure into the new indexes with sparse constraint, thus it has\nlittle additional memory consumption in online query stage. Experimental\nevaluation on three benchmark datasets reveals that the proposed approach\nachieves the state-of-the-art performance, i.e., N-score 3.94 on UKBench, mAP\n94.1% on Holiday and 62.39% on Market-1501.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Vector Indexing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [23.057170867919922, 6.861196994781494], "cluster": 7}, {"key": "zhang2017hashgan", "year": "2017", "citations": "16", "title": "Hashgan:attention-aware Deep Adversarial Hashing For Cross Modal Retrieval", "abstract": "<p>As the rapid growth of multi-modal data, hashing methods for cross-modal\nretrieval have received considerable attention. Deep-networks-based cross-modal\nhashing methods are appealing as they can integrate feature learning and hash\ncoding into end-to-end trainable frameworks. However, it is still challenging\nto find content similarities between different modalities of data due to the\nheterogeneity gap. To further address this problem, we propose an adversarial\nhashing network with attention mechanism to enhance the measurement of content\nsimilarities by selectively focusing on informative parts of multi-modal data.\nThe proposed new adversarial network, HashGAN, consists of three building\nblocks: 1) the feature learning module to obtain feature representations, 2)\nthe generative attention module to generate an attention mask, which is used to\nobtain the attended (foreground) and the unattended (background) feature\nrepresentations, 3) the discriminative hash coding module to learn hash\nfunctions that preserve the similarities between different modalities. In our\nframework, the generative module and the discriminative module are trained in\nan adversarial way: the generator is learned to make the discriminator cannot\npreserve the similarities of multi-modal data w.r.t. the background feature\nrepresentations, while the discriminator aims to preserve the similarities of\nmulti-modal data w.r.t. both the foreground and the background feature\nrepresentations. Extensive evaluations on several benchmark datasets\ndemonstrate that the proposed HashGAN brings substantial improvements over\nother state-of-the-art cross-modal hashing methods.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Tools & Libraries", "Evaluation", "Robustness"], "tsne_embedding": [-14.099994659423828, -0.5614169836044312], "cluster": 8}, {"key": "zhang2017unsupervised", "year": "2017", "citations": "203", "title": "Unsupervised Generative Adversarial Cross-modal Hashing", "abstract": "<p>Cross-modal hashing aims to map heterogeneous multimedia data into a common\nHamming space, which can realize fast and flexible retrieval across different\nmodalities. Unsupervised cross-modal hashing is more flexible and applicable\nthan supervised methods, since no intensive labeling work is involved. However,\nexisting unsupervised methods learn hashing functions by preserving inter and\nintra correlations, while ignoring the underlying manifold structure across\ndifferent modalities, which is extremely helpful to capture meaningful nearest\nneighbors of different modalities for cross-modal retrieval. To address the\nabove problem, in this paper we propose an Unsupervised Generative Adversarial\nCross-modal Hashing approach (UGACH), which makes full use of GAN\u2019s ability for\nunsupervised representation learning to exploit the underlying manifold\nstructure of cross-modal data. The main contributions can be summarized as\nfollows: (1) We propose a generative adversarial network to model cross-modal\nhashing in an unsupervised fashion. In the proposed UGACH, given a data of one\nmodality, the generative model tries to fit the distribution over the manifold\nstructure, and select informative data of another modality to challenge the\ndiscriminative model. The discriminative model learns to distinguish the\ngenerated data and the true positive data sampled from correlation graph to\nachieve better retrieval accuracy. These two models are trained in an\nadversarial way to improve each other and promote hashing function learning.\n(2) We propose a correlation graph based approach to capture the underlying\nmanifold structure across different modalities, so that data of different\nmodalities but within the same manifold can have smaller Hamming distance and\npromote retrieval accuracy. Extensive experiments compared with 6\nstate-of-the-art methods verify the effectiveness of our proposed approach.</p>\n", "tags": ["AAAI", "Hashing Methods", "Multimodal Retrieval", "Evaluation", "Robustness"], "tsne_embedding": [-11.347373962402344, -2.6368863582611084], "cluster": 8}, {"key": "zhang2018hierarchical", "year": "2018", "citations": "21", "title": "Hierarchical Information Quadtree: Efficient Spatial Temporal Image Search For Multimedia Stream", "abstract": "<p>Massive amount of multimedia data that contain times- tamps and geographical\ninformation are being generated at an unprecedented scale in many emerging\napplications such as photo sharing web site and social networks applications.\nDue to their importance, a large body of work has focused on efficiently\ncomputing various spatial image queries. In this paper,we study the spatial\ntemporal image query which considers three important constraints during the\nsearch including time recency, spatial proximity and visual relevance. A novel\nindex structure, namely Hierarchical Information Quadtree(\\hiq), to efficiently\ninsert/delete spatial temporal images with high arrive rates. Base on \\hiq an\nefficient algorithm is developed to support spatial temporal image query. We\nshow via extensive experimentation with real spatial databases clearly\ndemonstrate the efficiency of our methods.</p>\n", "tags": ["Image Retrieval", "Vector Indexing", "Efficiency And Optimization"], "tsne_embedding": [-18.437837600708008, 12.122328758239746], "cluster": 3}, {"key": "zhang2018highly", "year": "2018", "citations": "49", "title": "Highly-economized Multi-view Binary Compression For Scalable Image Clustering", "abstract": "<p>How to economically cluster large-scale multi-view images is a long-standing\nproblem in computer vision. To tackle this challenge, we introduce a novel\napproach named Highly-economized Scalable Image Clustering (HSIC) that\nradically surpasses conventional image clustering methods via binary\ncompression. We intuitively unify the binary representation learning and\nefficient binary cluster structure learning into a joint framework. In\nparticular, common binary representations are learned by exploiting both\nsharable and individual information across multiple views to capture their\nunderlying correlations. Meanwhile, cluster assignment with robust binary\ncentroids is also performed via effective discrete optimization under L21-norm\nconstraint. By this means, heavy continuous-valued Euclidean distance\ncomputations can be successfully reduced by efficient binary XOR operations\nduring the clustering procedure. To our best knowledge, HSIC is the first\nbinary clustering work specifically designed for scalable multi-view image\nclustering. Extensive experimental results on four large-scale image datasets\nshow that HSIC consistently outperforms the state-of-the-art approaches, whilst\nsignificantly reducing computational time and memory footprint.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Distance Metric Learning", "Efficiency And Optimization", "Tools & Libraries"], "tsne_embedding": [-1.3117239475250244, 9.090841293334961], "cluster": 8}, {"key": "zhang2018improved", "year": "2018", "citations": "144", "title": "Improved Deep Hashing With Soft Pairwise Similarity For Multi-label Image Retrieval", "abstract": "<p>Hash coding has been widely used in the approximate nearest neighbor search\nfor large-scale image retrieval. Recently, many deep hashing methods have been\nproposed and shown largely improved performance over traditional\nfeature-learning-based methods. Most of these methods examine the pairwise\nsimilarity on the semantic-level labels, where the pairwise similarity is\ngenerally defined in a hard-assignment way. That is, the pairwise similarity is\n\u20181\u2019 if they share no less than one class label and \u20180\u2019 if they do not share\nany. However, such similarity definition cannot reflect the similarity ranking\nfor pairwise images that hold multiple labels. In this paper, a new deep\nhashing method is proposed for multi-label image retrieval by re-defining the\npairwise similarity into an instance similarity, where the instance similarity\nis quantified into a percentage based on the normalized semantic labels. Based\non the instance similarity, a weighted cross-entropy loss and a minimum mean\nsquare error loss are tailored for loss-function construction, and are\nefficiently used for simultaneous feature learning and hash coding. Experiments\non three popular datasets demonstrate that, the proposed method outperforms the\ncompeting methods and achieves the state-of-the-art performance in multi-label\nimage retrieval.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Neural Hashing", "Evaluation"], "tsne_embedding": [0.9287919998168945, 5.410706996917725], "cluster": 4}, {"key": "zhang2018relationnet2", "year": "2018", "citations": "17", "title": "Relationnet2: Deep Comparison Columns For Few-shot Learning", "abstract": "<p>Few-shot deep learning is a topical challenge area for scaling visual\nrecognition to open ended growth of unseen new classes with limited labeled\nexamples. A promising approach is based on metric learning, which trains a deep\nembedding to support image similarity matching. Our insight is that effective\ngeneral purpose matching requires non-linear comparison of features at multiple\nabstraction levels. We thus propose a new deep comparison network comprised of\nembedding and relation modules that learn multiple non-linear distance metrics\nbased on different levels of features simultaneously. Furthermore, to reduce\nover-fitting and enable the use of deeper embeddings, we represent images as\ndistributions rather than vectors via learning parameterized Gaussian noise\nregularization. The resulting network achieves excellent performance on both\nminiImageNet and tieredImageNet.</p>\n", "tags": ["Evaluation", "Distance Metric Learning"], "tsne_embedding": [-23.276248931884766, 5.331361293792725], "cluster": 3}, {"key": "zhang2018sch", "year": "2018", "citations": "124", "title": "SCH-GAN: Semi-supervised Cross-modal Hashing By Generative Adversarial Network", "abstract": "<p>Cross-modal hashing aims to map heterogeneous multimedia data into a common\nHamming space, which can realize fast and flexible retrieval across different\nmodalities. Supervised cross-modal hashing methods have achieved considerable\nprogress by incorporating semantic side information. However, they mainly have\ntwo limitations: (1) Heavily rely on large-scale labeled cross-modal training\ndata which are labor intensive and hard to obtain. (2) Ignore the rich\ninformation contained in the large amount of unlabeled data across different\nmodalities, especially the margin examples that are easily to be incorrectly\nretrieved, which can help to model the correlations. To address these problems,\nin this paper we propose a novel Semi-supervised Cross-Modal Hashing approach\nby Generative Adversarial Network (SCH-GAN). We aim to take advantage of GAN\u2019s\nability for modeling data distributions to promote cross-modal hashing learning\nin an adversarial way. The main contributions can be summarized as follows: (1)\nWe propose a novel generative adversarial network for cross-modal hashing. In\nour proposed SCH-GAN, the generative model tries to select margin examples of\none modality from unlabeled data when giving a query of another modality. While\nthe discriminative model tries to distinguish the selected examples and true\npositive examples of the query. These two models play a minimax game so that\nthe generative model can promote the hashing performance of discriminative\nmodel. (2) We propose a reinforcement learning based algorithm to drive the\ntraining of proposed SCH-GAN. The generative model takes the correlation score\npredicted by discriminative model as a reward, and tries to select the examples\nclose to the margin to promote discriminative model by maximizing the margin\nbetween positive and negative data. Experiments on 3 widely-used datasets\nverify the effectiveness of our proposed approach.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Evaluation", "Robustness"], "tsne_embedding": [-11.73537826538086, -2.61639404296875], "cluster": 8}, {"key": "zhang2018semantic", "year": "2018", "citations": "13", "title": "Semantic Cluster Unary Loss For Efficient Deep Hashing", "abstract": "<p>Hashing method maps similar data to binary hashcodes with smaller hamming\ndistance, which has received a broad attention due to its low storage cost and\nfast retrieval speed. With the rapid development of deep learning, deep hashing\nmethods have achieved promising results in efficient information retrieval.\nMost of the existing deep hashing methods adopt pairwise or triplet losses to\ndeal with similarities underlying the data, but the training is difficult and\nless efficient because \\(O(n^2)\\) data pairs and \\(O(n^3)\\) triplets are involved.\nTo address these issues, we propose a novel deep hashing algorithm with unary\nloss which can be trained very efficiently. We first of all introduce a Unary\nUpper Bound of the traditional triplet loss, thus reducing the complexity to\n\\(O(n)\\) and bridging the classification-based unary loss and the triplet loss.\nSecond, we propose a novel Semantic Cluster Deep Hashing (SCDH) algorithm by\nintroducing a modified Unary Upper Bound loss, named Semantic Cluster Unary\nLoss (SCUL). The resultant hashcodes form several compact clusters, which means\nhashcodes in the same cluster have similar semantic information. We also\ndemonstrate that the proposed SCDH is easy to be extended to semi-supervised\nsettings by incorporating the state-of-the-art semi-supervised learning\nalgorithms. Experiments on large-scale datasets show that the proposed method\nis superior to state-of-the-art hashing algorithms.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Distance Metric Learning", "Efficiency And Optimization", "Neural Hashing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-3.6174607276916504, -8.072847366333008], "cluster": 9}, {"key": "zhang2018zoom", "year": "2018", "citations": "33", "title": "Zoom: Ssd-based Vector Search For Optimizing Accuracy, Latency And Memory", "abstract": "<p>With the advancement of machine learning and deep learning, vector search\nbecomes instrumental to many information retrieval systems, to search and find\nbest matches to user queries based on their semantic similarities.These online\nservices require the search architecture to be both effective with high\naccuracy and efficient with low latency and memory footprint, which existing\nwork fails to offer. We develop, Zoom, a new vector search solution that\ncollaboratively optimizes accuracy, latency and memory based on a multiview\napproach. (1) A \u201cpreview\u201d step generates a small set of good candidates,\nleveraging compressed vectors in memory for reduced footprint and fast lookup.\n(2) A \u201cfullview\u201d step on SSDs reranks those candidates with their full-length\nvector, striking high accuracy. Our evaluation shows that, Zoom achieves an\norder of magnitude improvements on efficiency while attaining equal or higher\naccuracy, comparing with the state-of-the-art.</p>\n", "tags": ["Survey Paper", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [2.42118501663208, 8.518460273742676], "cluster": 4}, {"key": "zhang2019collaborative", "year": "2019", "citations": "62", "title": "Collaborative Quantization For Cross-modal Similarity Search", "abstract": "<p>Cross-modal similarity search is a problem about designing a search system\nsupporting querying across content modalities, e.g., using an image to search\nfor texts or using a text to search for images. This paper presents a compact\ncoding solution for efficient search, with a focus on the quantization approach\nwhich has already shown the superior performance over the hashing solutions in\nthe single-modal similarity search. We propose a cross-modal quantization\napproach, which is among the early attempts to introduce quantization into\ncross-modal search. The major contribution lies in jointly learning the\nquantizers for both modalities through aligning the quantized representations\nfor each pair of image and text belonging to a document. In addition, our\napproach simultaneously learns the common space for both modalities in which\nquantization is conducted to enable efficient and effective search using the\nEuclidean distance computed in the common space with fast distance table\nlookup. Experimental results compared with several competitive algorithms over\nthree benchmark datasets demonstrate that the proposed approach achieves the\nstate-of-the-art performance.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Distance Metric Learning", "CVPR", "Similarity Search", "Quantization", "Evaluation"], "tsne_embedding": [1.5873963832855225, 3.335200071334839], "cluster": 4}, {"key": "zhang2019generic", "year": "2019", "citations": "33", "title": "Generic Intent Representation In Web Search", "abstract": "<p>This paper presents GEneric iNtent Encoder (GEN Encoder) which learns a\ndistributed representation space for user intent in search. Leveraging large\nscale user clicks from Bing search logs as weak supervision of user intent, GEN\nEncoder learns to map queries with shared clicks into similar embeddings\nend-to-end and then finetunes on multiple paraphrase tasks. Experimental\nresults on an intrinsic evaluation task - query intent similarity modeling -\ndemonstrate GEN Encoder\u2019s robust and significant advantages over previous\nrepresentation methods. Ablation studies reveal the crucial role of learning\nfrom implicit user feedback in representing user intent and the contributions\nof multi-task learning in representation generality. We also demonstrate that\nGEN Encoder alleviates the sparsity of tail search traffic and cuts down half\nof the unseen queries by using an efficient approximate nearest neighbor search\nto effectively identify previous queries with the same search intent. Finally,\nwe demonstrate distances between GEN encodings reflect certain information\nseeking behaviors in search sessions.</p>\n", "tags": ["SIGIR", "Evaluation"], "tsne_embedding": [3.255722999572754, -5.323615550994873], "cluster": 9}, {"key": "zhang2019pairwise", "year": "2019", "citations": "7", "title": "Pairwise Teacher-student Network For Semi-supervised Hashing", "abstract": "<p>Hashing method maps similar high-dimensional data to binary hashcodes with\nsmaller hamming distance, and it has received broad attention due to its low\nstorage cost and fast retrieval speed. Pairwise similarity is easily obtained\nand widely used for retrieval, and most supervised hashing algorithms are\ncarefully designed for the pairwise supervisions. As labeling all data pairs is\ndifficult, semi-supervised hashing is proposed which aims at learning efficient\ncodes with limited labeled pairs and abundant unlabeled ones. Existing methods\nbuild graphs to capture the structure of dataset, but they are not working well\nfor complex data as the graph is built based on the data representations and\ndetermining the representations of complex data is difficult. In this paper, we\npropose a novel teacher-student semi-supervised hashing framework in which the\nstudent is trained with the pairwise information produced by the teacher\nnetwork. The network follows the smoothness assumption, which achieves\nconsistent distances for similar data pairs so that the retrieval results are\nsimilar for neighborhood queries. Experiments on large-scale datasets show that\nthe proposed method reaches impressive gain over the supervised baselines and\nis superior to state-of-the-art semi-supervised hashing methods.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "CVPR", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-23.47193145751953, -6.793050289154053], "cluster": 1}, {"key": "zhang2019sadih", "year": "2019", "citations": "17", "title": "SADIH: Semantic-aware Discrete Hashing", "abstract": "<p>Due to its low storage cost and fast query speed, hashing has been recognized\nto accomplish similarity search in large-scale multimedia retrieval\napplications. Particularly supervised hashing has recently received\nconsiderable research attention by leveraging the label information to preserve\nthe pairwise similarities of data points in the Hamming space. However, there\nstill remain two crucial bottlenecks: 1) the learning process of the full\npairwise similarity preservation is computationally unaffordable and unscalable\nto deal with big data; 2) the available category information of data are not\nwell-explored to learn discriminative hash functions. To overcome these\nchallenges, we propose a unified Semantic-Aware DIscrete Hashing (SADIH)\nframework, which aims to directly embed the transformed semantic information\ninto the asymmetric similarity approximation and discriminative hashing\nfunction learning. Specifically, a semantic-aware latent embedding is\nintroduced to asymmetrically preserve the full pairwise similarities while\nskillfully handle the cumbersome n times n pairwise similarity matrix.\nMeanwhile, a semantic-aware autoencoder is developed to jointly preserve the\ndata structures in the discriminative latent semantic space and perform data\nreconstruction. Moreover, an efficient alternating optimization algorithm is\nproposed to solve the resulting discrete optimization problem. Extensive\nexperimental results on multiple large-scale datasets demonstrate that our\nSADIH can clearly outperform the state-of-the-art baselines with the additional\nbenefit of lower computational costs.</p>\n", "tags": ["AAAI", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Alt", "Similarity Search", "Tools & Libraries"], "tsne_embedding": [-5.279002666473389, -2.3522562980651855], "cluster": 8}, {"key": "zhang2020collaborative", "year": "2020", "citations": "6", "title": "Collaborative Generative Hashing For Marketing And Fast Cold-start Recommendation", "abstract": "<p>Cold-start has being a critical issue in recommender systems with the\nexplosion of data in e-commerce. Most existing studies proposed to alleviate\nthe cold-start problem are also known as hybrid recommender systems that learn\nrepresentations of users and items by combining user-item interactive and\nuser/item content information. However, previous hybrid methods regularly\nsuffered poor efficiency bottlenecking in online recommendations with\nlarge-scale items, because they were designed to project users and items into\ncontinuous latent space where the online recommendation is expensive. To this\nend, we propose a collaborative generated hashing (CGH) framework to improve\nthe efficiency by denoting users and items as binary codes, then fast hashing\nsearch techniques can be used to speed up the online recommendation. In\naddition, the proposed CGH can generate potential users or items for marketing\napplication where the generative network is designed with the principle of\nMinimum Description Length (MDL), which is used to learn compact and\ninformative binary codes. Extensive experiments on two public datasets show the\nadvantages for recommendations in various settings over competing baselines and\nanalyze its feasibility in marketing application.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Recommender Systems", "Tools & Libraries"], "tsne_embedding": [3.9822075366973877, -3.395411491394043], "cluster": 4}, {"key": "zhang2020deep", "year": "2020", "citations": "9", "title": "Deep Pairwise Hashing For Cold-start Recommendation", "abstract": "<p>Recommendation efficiency and data sparsity problems have been regarded as\ntwo challenges of improving performance for online recommendation. Most of the\nprevious related work focus on improving recommendation accuracy instead of\nefficiency. In this paper, we propose a Deep Pairwise Hashing (DPH) to map\nusers and items to binary vectors in Hamming space, where a user\u2019s preference\nfor an item can be efficiently calculated by Hamming distance, which\nsignificantly improves the efficiency of online recommendation. To alleviate\ndata sparsity and cold-start problems, the user-item interactive information\nand item content information are unified to learn effective representations of\nitems and users. Specifically, we first pre-train robust item representation\nfrom item content data by a Denoising Auto-encoder instead of other\ndeterministic deep learning frameworks; then we finetune the entire framework\nby adding a pairwise loss objective with discrete constraints; moreover, DPH\naims to minimize a pairwise ranking loss that is consistent with the ultimate\ngoal of recommendation. Finally, we adopt the alternating optimization method\nto optimize the proposed model with discrete constraints. Extensive experiments\non three different datasets show that DPH can significantly advance the\nstate-of-the-art frameworks regarding data sparsity and item cold-start\nrecommendation.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "Recommender Systems", "Alt", "Tools & Libraries", "Evaluation"], "tsne_embedding": [2.650587320327759, -3.2761588096618652], "cluster": 4}, {"key": "zhang2020faster", "year": "2020", "citations": "31", "title": "Faster Binary Embeddings For Preserving Euclidean Distances", "abstract": "<p>We propose a fast, distance-preserving, binary embedding algorithm to\ntransform a high-dimensional dataset \\(\\mathcal{T}\\subseteq\\mathbb{R}^n\\) into\nbinary sequences in the cube \\(\\{\\pm 1\\}^m\\). When \\(\\mathcal{T}\\) consists of\nwell-spread (i.e., non-sparse) vectors, our embedding method applies a stable\nnoise-shaping quantization scheme to \\(A x\\) where \\(A\\in\\mathbb{R}^{m\\times n}\\)\nis a sparse Gaussian random matrix. This contrasts with most binary embedding\nmethods, which usually use \\(x\\mapsto \\mathrm{sign}(Ax)\\) for the embedding.\nMoreover, we show that Euclidean distances among the elements of \\(\\mathcal{T}\\)\nare approximated by the \\(\\ell_1\\) norm on the images of \\(\\{\\pm 1\\}^m\\) under a\nfast linear transformation. This again contrasts with standard methods, where\nthe Hamming distance is used instead. Our method is both fast and memory\nefficient, with time complexity \\(O(m)\\) and space complexity \\(O(m)\\). Further, we\nprove that the method is accurate and its associated error is comparable to\nthat of a continuous valued Johnson-Lindenstrauss embedding plus a quantization\nerror that admits a polynomial decay as the embedding dimension \\(m\\) increases.\nThus the length of the binary codes required to achieve a desired accuracy is\nquite small, and we show it can even be compressed further without compromising\nthe accuracy. To illustrate our results, we test the proposed method on natural\nimages and show that it achieves strong performance.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Distance Metric Learning", "CVPR", "Compact Codes", "Quantization", "Tools & Libraries", "Evaluation"], "tsne_embedding": [34.23032760620117, 0.786247193813324], "cluster": 7}, {"key": "zhang2020fedocr", "year": "2020", "citations": "24", "title": "Fedocr: Communication-efficient Federated Learning For Scene Text Recognition", "abstract": "<p>While scene text recognition techniques have been widely used in commercial\napplications, data privacy has rarely been taken into account by this research\ncommunity. Most existing algorithms have assumed a set of shared or centralized\ntraining data. However, in practice, data may be distributed on different local\ndevices that can not be centralized to share due to the privacy restrictions.\nIn this paper, we study how to make use of decentralized datasets for training\na robust scene text recognizer while keeping them stay on local devices. To the\nbest of our knowledge, we propose the first framework leveraging federated\nlearning for scene text recognition, which is trained with decentralized\ndatasets collaboratively. Hence we name it FedOCR. To make FedCOR fairly\nsuitable to be deployed on end devices, we make two improvements including\nusing lightweight models and hashing techniques. We argue that both are crucial\nfor FedOCR in terms of the communication efficiency of federated learning. The\nsimulations on decentralized datasets show that the proposed FedOCR achieves\ncompetitive results to the models that are trained with centralized data, with\nfewer communication costs and higher-level privacy-preserving.</p>\n", "tags": ["DATASETS", "Tools & Libraries", "Hashing Methods", "Efficiency And Optimization"], "tsne_embedding": [0.13467563688755035, -20.538129806518555], "cluster": 5}, {"key": "zhang2020leveraging", "year": "2020", "citations": "13", "title": "Leveraging Local And Global Descriptors In Parallel To Search Correspondences For Visual Localization", "abstract": "<p>Visual localization to compute 6DoF camera pose from a given image has wide\napplications such as in robotics, virtual reality, augmented reality, etc. Two\nkinds of descriptors are important for the visual localization. One is global\ndescriptors that extract the whole feature from each image. The other is local\ndescriptors that extract the local feature from each image patch usually\nenclosing a key point. More and more methods of the visual localization have\ntwo stages: at first to perform image retrieval by global descriptors and then\nfrom the retrieval feedback to make 2D-3D point correspondences by local\ndescriptors. The two stages are in serial for most of the methods. This simple\ncombination has not achieved superiority of fusing local and global\ndescriptors. The 3D points obtained from the retrieval feedback are as the\nnearest neighbor candidates of the 2D image points only by global descriptors.\nEach of the 2D image points is also called a query local feature when\nperforming the 2D-3D point correspondences. In this paper, we propose a novel\nparallel search framework, which leverages advantages of both local and global\ndescriptors to get nearest neighbor candidates of a query local feature.\nSpecifically, besides using deep learning based global descriptors, we also\nutilize local descriptors to construct random tree structures for obtaining\nnearest neighbor candidates of the query local feature. We propose a new\nprobabilistic model and a new deep learning based local descriptor when\nconstructing the random trees. A weighted Hamming regularization term to keep\ndiscriminativeness after binarization is given in the loss function for the\nproposed local descriptor. The loss function co-trains both real and binary\ndescriptors of which the results are integrated into the random trees.</p>\n", "tags": ["CVPR", "Image Retrieval", "Tools & Libraries"], "tsne_embedding": [-8.30693531036377, 8.88310718536377], "cluster": 8}, {"key": "zhang2020model", "year": "2020", "citations": "31", "title": "Model Size Reduction Using Frequency Based Double Hashing For Recommender Systems", "abstract": "<p>Deep Neural Networks (DNNs) with sparse input features have been widely used\nin recommender systems in industry. These models have large memory requirements\nand need a huge amount of training data. The large model size usually entails a\ncost, in the range of millions of dollars, for storage and communication with\nthe inference services. In this paper, we propose a hybrid hashing method to\ncombine frequency hashing and double hashing techniques for model size\nreduction, without compromising performance. We evaluate the proposed models on\ntwo product surfaces. In both cases, experiment results demonstrated that we\ncan reduce the model size by around 90 % while keeping the performance on par\nwith the original baselines.</p>\n", "tags": ["Recommender Systems", "RecSys", "Evaluation", "Hashing Methods"], "tsne_embedding": [-6.931334495544434, -16.3804988861084], "cluster": 9}, {"key": "zhang2020survey", "year": "2020", "citations": "40", "title": "A Survey On Deep Hashing For Image Retrieval", "abstract": "<p>Hashing has been widely used in approximate nearest search for large-scale\ndatabase retrieval for its computation and storage efficiency. Deep hashing,\nwhich devises convolutional neural network architecture to exploit and extract\nthe semantic information or feature of images, has received increasing\nattention recently. In this survey, several deep supervised hashing methods for\nimage retrieval are evaluated and I conclude three main different directions\nfor deep supervised hashing methods. Several comments are made at the end.\nMoreover, to break through the bottleneck of the existing hashing methods, I\npropose a Shadow Recurrent Hashing(SRH) method as a try. Specifically, I devise\na CNN architecture to extract the semantic features of images and design a loss\nfunction to encourage similar images projected close. To this end, I propose a\nconcept: shadow of the CNN output. During optimization process, the CNN output\nand its shadow are guiding each other so as to achieve the optimal solution as\nmuch as possible. Several experiments on dataset CIFAR-10 show the satisfying\nperformance of SRH.</p>\n", "tags": ["Survey Paper", "Image Retrieval", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Neural Hashing", "Evaluation"], "tsne_embedding": [-11.879780769348145, 23.65677833557129], "cluster": 6}, {"key": "zhang2021finger", "year": "2021", "citations": "84", "title": "Finger Vein Recognition By Generating Code", "abstract": "<p>Finger vein recognition has drawn increasing attention as one of the most\npopular and promising biometrics due to its high distinguishes ability,\nsecurity and non-invasive procedure. The main idea of traditional schemes is to\ndirectly extract features from finger vein images or patterns and then compare\nfeatures to find the best match. However, the features extracted from images\ncontain much redundant data, while the features extracted from patterns are\ngreatly influenced by image segmentation methods. To tack these problems, this\npaper proposes a new finger vein recognition by generating code. The proposed\nmethod does not require an image segmentation algorithm, is simple to calculate\nand has a small amount of data. Firstly, the finger vein images were divided\ninto blocks to calculate the mean value. Then the centrosymmetric coding is\nperformed by using the generated eigenmatrix. The obtained codewords are\nconcatenated as the feature codewords of the image. The similarity between vein\ncodes is measured by the ratio of minimum Hamming distance to codeword length.\nExtensive experiments on two public finger vein databases verify the\neffectiveness of the proposed method. The results indicate that our method\noutperforms the state-of-theart methods and has competitive potential in\nperforming the matching task.</p>\n", "tags": [], "tsne_embedding": [-14.229639053344727, 4.623093605041504], "cluster": 8}, {"key": "zhang2021graph", "year": "2021", "citations": "13", "title": "Graph Convolution For Re-ranking In Person Re-identification", "abstract": "<p>Nowadays, deep learning is widely applied to extract features for similarity\ncomputation in person re-identification (re-ID) and have achieved great\nsuccess. However, due to the non-overlapping between training and testing IDs,\nthe difference between the data used for model training and the testing data\nmakes the performance of learned feature degraded during testing. Hence,\nre-ranking is proposed to mitigate this issue and various algorithms have been\ndeveloped. However, most of existing re-ranking methods focus on replacing the\nEuclidean distance with sophisticated distance metrics, which are not friendly\nto downstream tasks and hard to be used for fast retrieval of massive data in\nreal applications. In this work, we propose a graph-based re-ranking method to\nimprove learned features while still keeping Euclidean distance as the\nsimilarity metric. Inspired by graph convolution networks, we develop an\noperator to propagate features over an appropriate graph. Since graph is the\nessential key for the propagation, two important criteria are considered for\ndesigning the graph, and three different graphs are explored accordingly.\nFurthermore, a simple yet effective method is proposed to generate a profile\nvector for each tracklet in videos, which helps extend our method to video\nre-ID. Extensive experiments on three benchmark data sets, e.g., Market-1501,\nDuke, and MARS, demonstrate the effectiveness of our proposed approach.</p>\n", "tags": ["Graph Based ANN", "Distance Metric Learning", "Efficiency And Optimization", "ICASSP", "Evaluation"], "tsne_embedding": [15.37608814239502, 13.91582202911377], "cluster": 0}, {"key": "zhang2021improved", "year": "2021", "citations": "8", "title": "Improved Deep Classwise Hashing With Centers Similarity Learning For Image Retrieval", "abstract": "<p>Deep supervised hashing for image retrieval has attracted researchers\u2019\nattention due to its high efficiency and superior retrieval performance. Most\nexisting deep supervised hashing works, which are based on pairwise/triplet\nlabels, suffer from the expensive computational cost and insufficient\nutilization of the semantics information. Recently, deep classwise hashing\nintroduced a classwise loss supervised by class labels information\nalternatively; however, we find it still has its drawback. In this paper, we\npropose an improved deep classwise hashing, which enables hashing learning and\nclass centers learning simultaneously. Specifically, we design a two-step\nstrategy on center similarity learning. It interacts with the classwise loss to\nattract the class center to concentrate on the intra-class samples while\npushing other class centers as far as possible. The centers similarity learning\ncontributes to generating more compact and discriminative hashing codes. We\nconduct experiments on three benchmark datasets. It shows that the proposed\nmethod effectively surpasses the original method and outperforms\nstate-of-the-art baselines under various commonly-used evaluation metrics for\nimage retrieval.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Alt", "Evaluation"], "tsne_embedding": [-6.354246139526367, 4.514583110809326], "cluster": 8}, {"key": "zhang2021joint", "year": "2021", "citations": "6", "title": "Joint Learning Of Deep Retrieval Model And Product Quantization Based Embedding Index", "abstract": "<p>Embedding index that enables fast approximate nearest neighbor(ANN) search,\nserves as an indispensable component for state-of-the-art deep retrieval\nsystems. Traditional approaches, often separating the two steps of embedding\nlearning and index building, incur additional indexing time and decayed\nretrieval accuracy. In this paper, we propose a novel method called Poeem,\nwhich stands for product quantization based embedding index jointly trained\nwith deep retrieval model, to unify the two separate steps within an end-to-end\ntraining, by utilizing a few techniques including the gradient straight-through\nestimator, warm start strategy, optimal space decomposition and Givens\nrotation. Extensive experimental results show that the proposed method not only\nimproves retrieval accuracy significantly but also reduces the indexing time to\nalmost none. We have open sourced our approach for the sake of comparison and\nreproducibility.</p>\n", "tags": ["Vector Indexing", "Quantization", "SIGIR", "Evaluation"], "tsne_embedding": [5.929083824157715, -7.694668292999268], "cluster": 2}, {"key": "zhang2021moon", "year": "2021", "citations": "10", "title": "MOON: Multi-hash Codes Joint Learning For Cross-media Retrieval", "abstract": "<p>In recent years, cross-media hashing technique has attracted increasing\nattention for its high computation efficiency and low storage cost. However,\nthe existing approaches still have some limitations, which need to be explored.\n1) A fixed hash length (e.g., 16bits or 32bits) is predefined before learning\nthe binary codes. Therefore, these models need to be retrained when the hash\nlength changes, that consumes additional computation power, reducing the\nscalability in practical applications. 2) Existing cross-modal approaches only\nexplore the information in the original multimedia data to perform the hash\nlearning, without exploiting the semantic information contained in the learned\nhash codes. To this end, we develop a novel Multiple hash cOdes jOint learNing\nmethod (MOON) for cross-media retrieval. Specifically, the developed MOON\nsynchronously learns the hash codes with multiple lengths in a unified\nframework. Besides, to enhance the underlying discrimination, we combine the\nclues from the multimodal data, semantic labels and learned hash codes for hash\nlearning. As far as we know, the proposed MOON is the first work to\nsimultaneously learn different length hash codes without retraining in\ncross-media retrieval. Experiments on several databases show that our MOON can\nachieve promising performance, outperforming some recent competitive shallow\nand deep methods.</p>\n", "tags": ["Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-11.689213752746582, -7.575626373291016], "cluster": 1}, {"key": "zhang2021orthonormal", "year": "2021", "citations": "9", "title": "Orthonormal Product Quantization Network For Scalable Face Image Retrieval", "abstract": "<p>Existing deep quantization methods provided an efficient solution for\nlarge-scale image retrieval. However, the significant intra-class variations\nlike pose, illumination, and expressions in face images, still pose a challenge\nfor face image retrieval. In light of this, face image retrieval requires\nsufficiently powerful learning metrics, which are absent in current deep\nquantization works. Moreover, to tackle the growing unseen identities in the\nquery stage, face image retrieval drives more demands regarding model\ngeneralization and system scalability than general image retrieval tasks. This\npaper integrates product quantization with orthonormal constraints into an\nend-to-end deep learning framework to effectively retrieve face images.\nSpecifically, a novel scheme that uses predefined orthonormal vectors as\ncodewords is proposed to enhance the quantization informativeness and reduce\ncodewords\u2019 redundancy. A tailored loss function maximizes discriminability\namong identities in each quantization subspace for both the quantized and\noriginal features. An entropy-based regularization term is imposed to reduce\nthe quantization error. Experiments are conducted on four commonly-used face\ndatasets under both seen and unseen identities retrieval settings. Our method\noutperforms all the compared deep hashing/quantization state-of-the-arts under\nboth settings. Results validate the effectiveness of the proposed orthonormal\ncodewords in improving models\u2019 standard retrieval performance and\ngeneralization ability. Combing with further experiments on two general image\ndatasets, it demonstrates the broad superiority of our method for scalable\nimage retrieval.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "CVPR", "Neural Hashing", "Quantization", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-12.395390510559082, 10.807195663452148], "cluster": 3}, {"key": "zhang2021visual", "year": "2021", "citations": "58", "title": "Visual Search At Alibaba", "abstract": "<p>This paper introduces the large scale visual search algorithm and system\ninfrastructure at Alibaba. The following challenges are discussed under the\nE-commercial circumstance at Alibaba (a) how to handle heterogeneous image data\nand bridge the gap between real-shot images from user query and the online\nimages. (b) how to deal with large scale indexing for massive updating data.\n(c) how to train deep models for effective feature representation without huge\nhuman annotations. (d) how to improve the user engagement by considering the\nquality of the content. We take advantage of large image collection of Alibaba\nand state-of-the-art deep learning techniques to perform visual search at\nscale. We present solutions and implementation details to overcome those\nproblems and also share our learnings from building such a large scale\ncommercial visual search engine. Specifically, model and search-based fusion\napproach is introduced to effectively predict categories. Also, we propose a\ndeep CNN model for joint detection and feature learning by mining user click\nbehavior. The binary index engine is designed to scale up indexing without\ncompromising recall and precision. Finally, we apply all the stages into an\nend-to-end system architecture, which can simultaneously achieve highly\nefficient and scalable performance adapting to real-shot images. Extensive\nexperiments demonstrate the advancement of each module in our system. We hope\nvisual search at Alibaba becomes more widely incorporated into today\u2019s\ncommercial applications.</p>\n", "tags": ["KDD", "Image Retrieval", "Evaluation"], "tsne_embedding": [-20.63092803955078, 10.95482349395752], "cluster": 3}, {"key": "zhang2022hashing", "year": "2022", "citations": "26", "title": "Hashing Learning With Hyper-class Representation", "abstract": "<p>Existing unsupervised hash learning is a kind of attribute-centered\ncalculation. It may not accurately preserve the similarity between data. This\nleads to low down the performance of hash function learning. In this paper, a\nhash algorithm is proposed with a hyper-class representation. It is a two-steps\napproach. The first step finds potential decision features and establish\nhyper-class. The second step constructs hash learning based on the hyper-class\ninformation in the first step, so that the hash codes of the data within the\nhyper-class are as similar as possible, as well as the hash codes of the data\nbetween the hyper-classes are as different as possible. To evaluate the\nefficiency, a series of experiments are conducted on four public datasets. The\nexperimental results show that the proposed hash algorithm is more efficient\nthan the compared algorithms, in terms of mean average precision (MAP), average\nprecision (AP) and Hamming radius 2 (HAM2)</p>\n", "tags": ["DATASETS", "Hashing Methods", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [-3.0957679748535156, -19.3431396484375], "cluster": 5}, {"key": "zhang2022lightfr", "year": "2022", "citations": "43", "title": "Lightfr: Lightweight Federated Recommendation With Privacy-preserving Matrix Factorization", "abstract": "<p>Federated recommender system (FRS), which enables many local devices to train\na shared model jointly without transmitting local raw data, has become a\nprevalent recommendation paradigm with privacy-preserving advantages. However,\nprevious work on FRS performs similarity search via inner product in continuous\nembedding space, which causes an efficiency bottleneck when the scale of items\nis extremely large. We argue that such a scheme in federated settings ignores\nthe limited capacities in resource-constrained user devices (i.e., storage\nspace, computational overhead, and communication bandwidth), and makes it\nharder to be deployed in large-scale recommender systems. Besides, it has been\nshown that transmitting local gradients in real-valued form between server and\nclients may leak users\u2019 private information. To this end, we propose a\nlightweight federated recommendation framework with privacy-preserving matrix\nfactorization, LightFR, that is able to generate high-quality binary codes by\nexploiting learning to hash technique under federated settings, and thus enjoys\nboth fast online inference and economic memory consumption. Moreover, we devise\nan efficient federated discrete optimization algorithm to collaboratively train\nmodel parameters between the server and clients, which can effectively prevent\nreal-valued gradient attacks from malicious parties. Through extensive\nexperiments on four real-world datasets, we show that our LightFR model\noutperforms several state-of-the-art FRS methods in terms of recommendation\naccuracy, inference efficiency and data privacy.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Recommender Systems", "Similarity Search", "Tools & Libraries"], "tsne_embedding": [1.7715028524398804, -22.38104820251465], "cluster": 5}, {"key": "zhang2023cafe", "year": "2023", "citations": "8", "title": "CAFE: Towards Compact, Adaptive, And Fast Embedding For Large-scale Recommendation Models", "abstract": "<p>Recently, the growing memory demands of embedding tables in Deep Learning\nRecommendation Models (DLRMs) pose great challenges for model training and\ndeployment. Existing embedding compression solutions cannot simultaneously meet\nthree key design requirements: memory efficiency, low latency, and adaptability\nto dynamic data distribution. This paper presents CAFE, a Compact, Adaptive,\nand Fast Embedding compression framework that addresses the above requirements.\nThe design philosophy of CAFE is to dynamically allocate more memory resources\nto important features (called hot features), and allocate less memory to\nunimportant ones. In CAFE, we propose a fast and lightweight sketch data\nstructure, named HotSketch, to capture feature importance and report hot\nfeatures in real time. For each reported hot feature, we assign it a unique\nembedding. For the non-hot features, we allow multiple features to share one\nembedding by using hash embedding technique. Guided by our design philosophy,\nwe further propose a multi-level hash embedding framework to optimize the\nembedding tables of non-hot features. We theoretically analyze the accuracy of\nHotSketch, and analyze the model convergence against deviation. Extensive\nexperiments show that CAFE significantly outperforms existing embedding\ncompression methods, yielding 3.92% and 3.68% superior testing AUC on Criteo\nKaggle dataset and CriteoTB dataset at a compression ratio of 10000x. The\nsource codes of CAFE are available at GitHub.</p>\n", "tags": ["Efficiency And Optimization", "DATASETS", "Tools & Libraries", "Recommender Systems"], "tsne_embedding": [4.857329845428467, -6.064474582672119], "cluster": 4}, {"key": "zhang2023model", "year": "2023", "citations": "17", "title": "Model-enhanced Vector Index", "abstract": "<p>Embedding-based retrieval methods construct vector indices to search for\ndocument representations that are most similar to the query representations.\nThey are widely used in document retrieval due to low latency and decent recall\nperformance. Recent research indicates that deep retrieval solutions offer\nbetter model quality, but are hindered by unacceptable serving latency and the\ninability to support document updates. In this paper, we aim to enhance the\nvector index with end-to-end deep generative models, leveraging the\ndifferentiable advantages of deep retrieval models while maintaining desirable\nserving efficiency. We propose Model-enhanced Vector Index (MEVI), a\ndifferentiable model-enhanced index empowered by a twin-tower representation\nmodel. MEVI leverages a Residual Quantization (RQ) codebook to bridge the\nsequence-to-sequence deep retrieval and embedding-based models. To\nsubstantially reduce the inference time, instead of decoding the unique\ndocument ids in long sequential steps, we first generate some semantic virtual\ncluster ids of candidate documents in a small number of steps, and then\nleverage the well-adapted embedding vectors to further perform a fine-grained\nsearch for the relevant documents in the candidate virtual clusters. We\nempirically show that our model achieves better performance on the commonly\nused academic benchmarks MSMARCO Passage and Natural Questions, with comparable\nserving latency to dense retrieval solutions.</p>\n", "tags": ["Efficiency And Optimization", "Text Retrieval", "Quantization", "Vector Indexing", "Evaluation"], "tsne_embedding": [3.40195894241333, 0.3345946669578552], "cluster": 4}, {"key": "zhang2025binary", "year": "2025", "citations": "98", "title": "Binary Code Ranking With Weighted Hamming Distance", "abstract": "<p>Binary hashing has been widely used for efficient similarity search due to its query and storage efficiency. In most\nexisting binary hashing methods, the high-dimensional data are embedded into Hamming space and the distance or\nsimilarity of two points are approximated by the Hamming\ndistance between their binary codes. The Hamming distance calculation is efficient, however, in practice, there are\noften lots of results sharing the same Hamming distance to\na query, which makes this distance measure ambiguous and\nposes a critical issue for similarity search where ranking is\nimportant. In this paper, we propose a weighted Hamming\ndistance ranking algorithm (WhRank) to rank the binary\ncodes of hashing methods. By assigning different bit-level\nweights to different hash bits, the returned binary codes\nare ranked at a finer-grained binary code level. We give\nan algorithm to learn the data-adaptive and query-sensitive\nweight for each hash bit. Evaluations on two large-scale\nimage data sets demonstrate the efficacy of our weighted\nHamming distance for binary code ranking.</p>\n", "tags": ["Hashing Methods", "Efficiency And Optimization", "CVPR", "Compact Codes", "Similarity Search", "Evaluation"], "tsne_embedding": [15.683568000793457, -10.469115257263184], "cluster": 2}, {"key": "zhang2025bit", "year": "2025", "citations": "418", "title": "Bit-scalable Deep Hashing With Regularized Similarity Learning For Image Retrieval And Person Re-identification", "abstract": "<p>Extracting informative image features and learning\neffective approximate hashing functions are two crucial steps in\nimage retrieval . Conventional methods often study these two\nsteps separately, e.g., learning hash functions from a predefined\nhand-crafted feature space. Meanwhile, the bit lengths of output\nhashing codes are preset in most previous methods, neglecting the\nsignificance level of different bits and restricting their practical\nflexibility. To address these issues, we propose a supervised\nlearning framework to generate compact and bit-scalable hashing\ncodes directly from raw images. We pose hashing learning as\na problem of regularized similarity learning. Specifically, we\norganize the training images into a batch of triplet samples,\neach sample containing two images with the same label and one\nwith a different label. With these triplet samples, we maximize\nthe margin between matched pairs and mismatched pairs in the\nHamming space. In addition, a regularization term is introduced\nto enforce the adjacency consistency, i.e., images of similar\nappearances should have similar codes. The deep convolutional\nneural network is utilized to train the model in an end-to-end\nfashion, where discriminative image features and hash functions\nare simultaneously optimized. Furthermore, each bit of our\nhashing codes is unequally weighted so that we can manipulate\nthe code lengths by truncating the insignificant bits. Our\nframework outperforms state-of-the-arts on public benchmarks\nof similar image search and also achieves promising results in\nthe application of person re-identification in surveillance. It is\nalso shown that the generated bit-scalable hashing codes well\npreserve the discriminative powers with shorter code lengths.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Neural Hashing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-11.59602165222168, 3.3454177379608154], "cluster": 8}, {"key": "zhang2025composite", "year": "2025", "citations": "221", "title": "Composite Hashing With Multiple Information Sources", "abstract": "<p>Similarity search applications with a large amount of text\nand image data demands an efficient and effective solution.\nOne useful strategy is to represent the examples in databases\nas compact binary codes through semantic hashing, which\nhas attracted much attention due to its fast query/search\nspeed and drastically reduced storage requirement. All of\nthe current semantic hashing methods only deal with the\ncase when each example is represented by one type of features.\nHowever, examples are often described from several\ndifferent information sources in many real world applications.\nFor example, the characteristics of a webpage can be\nderived from both its content part and its associated links.\nTo address the problem of learning good hashing codes in\nthis scenario, we propose a novel research problem \u2013 Composite\nHashing with Multiple Information Sources (CHMIS).\nThe focus of the new research problem is to design an algorithm\nfor incorporating the features from different information\nsources into the binary hashing codes efficiently and\neffectively. In particular, we propose an algorithm CHMISAW\n(CHMIS with Adjusted Weights) for learning the codes.\nThe proposed algorithm integrates information from several\ndifferent sources into the binary hashing codes by adjusting\nthe weights on each individual source for maximizing\nthe coding performance, and enables fast conversion from\nquery examples to their binary hashing codes. Experimental\nresults on five different datasets demonstrate the superior\nperformance of the proposed method against several other\nstate-of-the-art semantic hashing techniques.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Compact Codes", "Text Retrieval", "SIGIR", "Similarity Search", "Evaluation"], "tsne_embedding": [-0.2381458729505539, -1.3736552000045776], "cluster": 4}, {"key": "zhang2025deep", "year": "2025", "citations": "21", "title": "Deep Center-based Dual-constrained Hashing For Discriminative Face Image Retrieval", "abstract": "<p>With the advantages of low storage cost and extremely fast retrieval speed, deep hashing methods have attracted much attention for image retrieval recently. However, large-scale face image retrieval with significant intra-class variations is still challenging. Neither existing pairwise/triplet labels-based nor softmax classification loss-based deep hashing works can generate compact and discriminative binary codes. Considering these issues, we propose a center-based framework integrating end-to-end hashing learning and class centers learning simultaneously. The framework minimizes the intra-class variance by clustering intra-class samples into a learnable class center. To strengthen inter-class separability, it additionally imposes a novel regularization term to enlarge the Hamming distance between pairwise class centers. Moreover, a simple yet effective regression matrix is introduced to encourage intra-class samples to generate the same binary codes, which further enhances the hashing codes compactness. Experiments on four large-scale datasets show the proposed method outperforms state-of-the-art baselines under various code lengths and commonly-used evaluation metrics.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "CVPR", "Compact Codes", "Neural Hashing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-5.959359645843506, 4.489740371704102], "cluster": 8}, {"key": "zhang2025discrete", "year": "2025", "citations": "32", "title": "Discrete Scale-invariant Metric Learning For Efficient Collaborative Filtering", "abstract": "<p>Metric learning has attracted extensive interest for its ability to provide personalized recommendations based on the importance of observed user-item interactions. Current metric learning methods aim to push negative items away from the corresponding users and positive items by an absolute geometrical distance margin. However, items may come from imbalanced categories with different intra-class variations. Thus, the absolute distance margin may not be ideal for estimating the difference between user preferences over imbalanced items. To this end, we propose a new method, named discrete scale-invariant metric learning (DSIML), by adding binary constraints to users and items, which maps users and items into binary codes of a shared Hamming subspace to speed up the online recommendation. Specifically, we firstly propose a scale-invariant margin based on angles at the negative item points in the shared Hamming subspace. Then, we derive a scale-invariant triple hinge loss based on the margin. To capture more preference difference information, we integrate a pairwise ranking loss into the scale-invariant loss in the proposed model. Due to the difficulty of directly optimizing the mixed integer optimization problem formulated with \\textit{log-sum-exp} functions, we seek to optimize its variational quadratic upper bound and learn hash codes with an alternating optimization strategy. Experiments on benchmark datasets clearly show that our proposed method is superior to competitive metric learning and hashing-based baselines for recommender systems. The implementation code is available at https://github.com/AnonyFeb/dsml.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Distance Metric Learning", "Compact Codes", "Alt", "Recommender Systems", "SIGIR", "Evaluation"], "tsne_embedding": [-0.5252572894096375, 3.782620906829834], "cluster": 4}, {"key": "zhang2025efficient", "year": "2025", "citations": "111", "title": "Efficient Training Of Very Deep Neural Networks For Supervised Hashing", "abstract": "<p>In this paper, we propose training very deep neural networks (DNNs) for supervised learning of hash codes. Existing methods in this context train relatively \u201cshallow\u201d networks limited by the issues arising in back propagation (e.e. vanishing gradients) as well as computational efficiency. We propose a novel and efficient training algorithm inspired by alternating direction method of multipliers (ADMM) that overcomes some of these limitations. Our method decomposes the training process into independent layer-wise local updates through auxiliary variables. Empirically we observe that our training algorithm always converges and its computational complexity is linearly proportional to the number of edges in the networks. Empirically we manage to train DNNs with 64 hidden layers and 1024 nodes per layer for supervised hashing in about 3 hours using a single GPU. Our proposed very deep supervised hashing (VDSH) method significantly outperforms the state-of-the-art on several benchmark datasets.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Efficiency And Optimization", "CVPR", "Alt", "Evaluation"], "tsne_embedding": [-2.6868462562561035, -14.722426414489746], "cluster": 9}, {"key": "zhang2025fast", "year": "2025", "citations": "9", "title": "Fast Discrete Cross-modal Hashing Based On Label Relaxation And Matrix Factorization", "abstract": "<p>In recent years, cross-media retrieval has drawn considerable attention due to the exponential growth of multimedia data. Many hashing approaches have been proposed for the cross-media search task. However, there are still open problems that warrant investigation. For example, most existing supervised hashing approaches employ a binary label matrix, which achieves small margins between wrong labels (0) and true labels (1). This may affect the retrieval performance by generating many false negatives and false positives. In addition, some methods adopt a relaxation scheme to solve the binary constraints, which may cause large quantization errors. There are also some discrete hashing methods that have been presented, but most of them are time-consuming. To conquer these problems, we present a label relaxation and discrete matrix factorization method (LRMF) for cross-modal retrieval. It offers a number of innovations. First of all, the proposed approach employs a novel label relaxation scheme to control the margins adaptively, which has the benefit of reducing the quantization error. Second, by virtue of the proposed discrete matrix factorization method designed to learn the binary codes, large quantization errors caused by relaxation can be avoided. The experimental results obtained on two widely-used databases demonstrate that LRMF outperforms state-of-the-art cross-media methods.</p>\n", "tags": ["Hashing Methods", "Compact Codes", "Multimodal Retrieval", "Quantization", "Evaluation"], "tsne_embedding": [-4.753290176391602, -6.559948921203613], "cluster": 9}, {"key": "zhang2025high", "year": "2025", "citations": "60", "title": "High-order Nonlocal Hashing For Unsupervised Cross-modal Retrieval", "abstract": "<p>In light of the ability to enable efficient storage and fast query for big data, hashing techniques for cross-modal search have aroused extensive attention. Despite the great success achieved, unsupervised cross-modal hashing still suffers from lacking reliable similarity supervision and struggles with handling the heterogeneity issue between different modalities. To cope with these, in this paper, we devise a new deep hashing model, termed as High-order Nonlocal Hashing (HNH) to facilitate cross-modal retrieval with the following advantages. First, different from existing methods that mainly leverage low-level local-view similarity as the guidance for hashing learning, we propose a high-order affinity measure that considers the multi-modal neighbourhood structures from a nonlocal perspective, thereby comprehensively capturing the similarity relationships between data items. Second, a common representation is introduced to correlate different modalities. By enforcing the modal-specific descriptors and the common representation to be aligned with each other, the proposed HNH significantly bridges the modality gap and maintains the intra-consistency. Third, an effective affinity preserving objective function is delicately designed to generate high-quality binary codes. Extensive experiments evidence the superiority of the proposed HNH in unsupervised cross-modal retrieval tasks over the state-of-the-art baselines.</p>\n", "tags": ["Compact Codes", "Multimodal Retrieval", "Neural Hashing", "Hashing Methods"], "tsne_embedding": [-1.7857418060302734, -2.6951732635498047], "cluster": 9}, {"key": "zhang2025large", "year": "2025", "citations": "619", "title": "Large-scale Supervised Multimodal Hashing With Semantic Correlation Maximization", "abstract": "<p>Due to its low storage cost and fast query speed, hashing\nhas been widely adopted for similarity search in multimedia\ndata. In particular, more and more attentions\nhave been payed to multimodal hashing for search in\nmultimedia data with multiple modalities, such as images\nwith tags. Typically, supervised information of semantic\nlabels is also available for the data points in\nmany real applications. Hence, many supervised multimodal\nhashing (SMH) methods have been proposed\nto utilize such semantic labels to further improve the\nsearch accuracy. However, the training time complexity\nof most existing SMH methods is too high, which\nmakes them unscalable to large-scale datasets. In this\npaper, a novel SMH method, called semantic correlation\nmaximization (SCM), is proposed to seamlessly integrate\nsemantic labels into the hashing learning procedure\nfor large-scale data modeling. Experimental results\non two real-world datasets show that SCM can signifi-\ncantly outperform the state-of-the-art SMH methods, in\nterms of both accuracy and scalability.</p>\n", "tags": ["AAAI", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Similarity Search"], "tsne_embedding": [-3.8550641536712646, -2.2257771492004395], "cluster": 8}, {"key": "zhang2025self", "year": "2025", "citations": "352", "title": "Self-taught Hashing For Fast Similarity Search", "abstract": "<p>The ability of fast similarity search at large scale is of great\nimportance to many Information Retrieval (IR) applications.\nA promising way to accelerate similarity search is semantic\nhashing which designs compact binary codes for a large number\nof documents so that semantically similar documents\nare mapped to similar codes (within a short Hamming distance).\nAlthough some recently proposed techniques are\nable to generate high-quality codes for documents known\nin advance, obtaining the codes for previously unseen documents\nremains to be a very challenging problem. In this\npaper, we emphasise this issue and propose a novel SelfTaught\nHashing (STH) approach to semantic hashing: we\nfirst find the optimal l-bit binary codes for all documents in\nthe given corpus via unsupervised learning, and then train\nl classifiers via supervised learning to predict the l-bit code\nfor any query document unseen before. Our experiments on\nthree real-world text datasets show that the proposed approach\nusing binarised Laplacian Eigenmap (LapEig) and\nlinear Support Vector Machine (SVM) outperforms stateof-the-art\ntechniques significantly.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Compact Codes", "Alt", "Text Retrieval", "SIGIR", "Similarity Search", "Evaluation"], "tsne_embedding": [-14.101847648620605, -9.184962272644043], "cluster": 1}, {"key": "zhang2025supervised", "year": "2025", "citations": "285", "title": "Supervised Hashing With Latent Factor Models", "abstract": "<p>Due to its low storage cost and fast query speed, hashing\nhas been widely adopted for approximate nearest neighbor\nsearch in large-scale datasets. Traditional hashing methods\ntry to learn the hash codes in an unsupervised way where\nthe metric (Euclidean) structure of the training data is preserved.\nVery recently, supervised hashing methods, which\ntry to preserve the semantic structure constructed from the\nsemantic labels of the training points, have exhibited higher\naccuracy than unsupervised methods. In this paper, we\npropose a novel supervised hashing method, called latent\nfactor hashing (LFH), to learn similarity-preserving binary\ncodes based on latent factor models. An algorithm with\nconvergence guarantee is proposed to learn the parameters\nof LFH. Furthermore, a linear-time variant with stochastic\nlearning is proposed for training LFH on large-scale datasets.\nExperimental results on two large datasets with semantic\nlabels show that LFH can achieve superior accuracy than\nstate-of-the-art methods with comparable training time.</p>\n", "tags": ["Efficiency And Optimization", "DATASETS", "SIGIR", "Hashing Methods"], "tsne_embedding": [-3.0736989974975586, -9.954702377319336], "cluster": 9}, {"key": "zhao2017scalable", "year": "2017", "citations": "7", "title": "Scalable Nearest Neighbor Search Based On Knn Graph", "abstract": "<p>Nearest neighbor search is known as a challenging issue that has been studied\nfor several decades. Recently, this issue becomes more and more imminent in\nviewing that the big data problem arises from various fields. In this paper, a\nscalable solution based on hill-climbing strategy with the support of k-nearest\nneighbor graph (kNN) is presented. Two major issues have been considered in the\npaper. Firstly, an efficient kNN graph construction method based on two means\ntree is presented. For the nearest neighbor search, an enhanced hill-climbing\nprocedure is proposed, which sees considerable performance boost over original\nprocedure. Furthermore, with the support of inverted indexing derived from\nresidue vector quantization, our method achieves close to 100% recall with high\nspeed efficiency in two state-of-the-art evaluation benchmarks. In addition, a\ncomparative study on both the compressional and traditional nearest neighbor\nsearch methods is presented. We show that our method achieves the best\ntrade-off between search quality, efficiency and memory complexity.</p>\n", "tags": ["Survey Paper", "Graph Based ANN", "Efficiency And Optimization", "Quantization", "Evaluation"], "tsne_embedding": [12.217616081237793, -0.46400517225265503], "cluster": 4}, {"key": "zhao2018approximate", "year": "2018", "citations": "20", "title": "Approximate K-nn Graph Construction: A Generic Online Approach", "abstract": "<p>Nearest neighbor search and k-nearest neighbor graph construction are two\nfundamental issues arise from many disciplines such as multimedia information\nretrieval, data-mining and machine learning. They become more and more imminent\ngiven the big data emerge in various fields in recent years. In this paper, a\nsimple but effective solution both for approximate k-nearest neighbor search\nand approximate k-nearest neighbor graph construction is presented. These two\nissues are addressed jointly in our solution. On the one hand, the approximate\nk-nearest neighbor graph construction is treated as a search task. Each sample\nalong with its k-nearest neighbors are joined into the k-nearest neighbor graph\nby performing the nearest neighbor search sequentially on the graph under\nconstruction. On the other hand, the built k-nearest neighbor graph is used to\nsupport k-nearest neighbor search. Since the graph is built online, the dynamic\nupdate on the graph, which is not possible from most of the existing solutions,\nis supported. This solution is feasible for various distance measures. Its\neffectiveness both as k-nearest neighbor construction and k-nearest neighbor\nsearch approaches is verified across different types of data in different\nscales, various dimensions and under different metrics.</p>\n", "tags": ["Graph Based ANN"], "tsne_embedding": [21.04802131652832, 14.024334907531738], "cluster": 0}, {"key": "zhao2019weakly", "year": "2019", "citations": "22", "title": "A Weakly Supervised Adaptive Triplet Loss For Deep Metric Learning", "abstract": "<p>We address the problem of distance metric learning in visual similarity\nsearch, defined as learning an image embedding model which projects images into\nEuclidean space where semantically and visually similar images are closer and\ndissimilar images are further from one another. We present a weakly supervised\nadaptive triplet loss (ATL) capable of capturing fine-grained semantic\nsimilarity that encourages the learned image embedding models to generalize\nwell on cross-domain data. The method uses weakly labeled product description\ndata to implicitly determine fine grained semantic classes, avoiding the need\nto annotate large amounts of training data. We evaluate on the Amazon fashion\nretrieval benchmark and DeepFashion in-shop retrieval data. The method boosts\nthe performance of triplet loss baseline by 10.6% on cross-domain data and\nout-performs the state-of-art model on all evaluation metrics.</p>\n", "tags": ["ICCV", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [-22.79018783569336, 9.538477897644043], "cluster": 3}, {"key": "zhao2021feature", "year": "2021", "citations": "20", "title": "A Feature Consistency Driven Attention Erasing Network For Fine-grained Image Retrieval", "abstract": "<p>Large-scale fine-grained image retrieval has two main problems. First, low\ndimensional feature embedding can fasten the retrieval process but bring\naccuracy reduce due to overlooking the feature of significant attention regions\nof images in fine-grained datasets. Second, fine-grained images lead to the\nsame category query hash codes mapping into the different cluster in database\nhash latent space. To handle these two issues, we propose a feature consistency\ndriven attention erasing network (FCAENet) for fine-grained image retrieval.\nFor the first issue, we propose an adaptive augmentation module in FCAENet,\nwhich is selective region erasing module (SREM). SREM makes the network more\nrobust on subtle differences of fine-grained task by adaptively covering some\nregions of raw images. The feature extractor and hash layer can learn more\nrepresentative hash code for fine-grained images by SREM. With regard to the\nsecond issue, we fully exploit the pair-wise similarity information and add the\nenhancing space relation loss (ESRL) in FCAENet to make the vulnerable relation\nstabler between the query hash code and database hash code. We conduct\nextensive experiments on five fine-grained benchmark datasets (CUB2011,\nAircraft, NABirds, VegFru, Food101) for 12bits, 24bits, 32bits, 48bits hash\ncode. The results show that FCAENet achieves the state-of-the-art (SOTA)\nfine-grained retrieval performance compared with other methods.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "CVPR", "Evaluation"], "tsne_embedding": [-10.141213417053223, 10.508365631103516], "cluster": 8}, {"key": "zhao2021large", "year": "2021", "citations": "10", "title": "Large-scale Visual Search With Binary Distributed Graph At Alibaba", "abstract": "<p>Graph-based approximate nearest neighbor search has attracted more and more\nattentions due to its online search advantages. Numbers of methods studying the\nenhancement of speed and recall have been put forward. However, few of them\nfocus on the efficiency and scale of offline graph-construction. For a deployed\nvisual search system with several billions of online images in total, building\na billion-scale offline graph in hours is essential, which is almost\nunachievable by most existing methods. In this paper, we propose a novel\nalgorithm called Binary Distributed Graph to solve this problem. Specifically,\nwe combine binary codes with graph structure to speedup online and offline\nprocedures, and achieve comparable performance with the ones in real-value\nbased scenarios by recalling more binary candidates. Furthermore, the\ngraph-construction is optimized to completely distributed implementation, which\nsignificantly accelerates the offline process and gets rid of the limitation of\nmemory and disk within a single machine. Experimental comparisons on Alibaba\nCommodity Data Set (more than three billion images) show that the proposed\nmethod outperforms the state-of-the-art with respect to the online/offline\ntrade-off.</p>\n", "tags": ["CIKM", "Image Retrieval", "Graph Based ANN", "Efficiency And Optimization", "Compact Codes", "Large Scale Search", "Evaluation"], "tsne_embedding": [16.676979064941406, 18.651473999023438], "cluster": 0}, {"key": "zhao2022constrained", "year": "2022", "citations": "19", "title": "Constrained Approximate Similarity Search On Proximity Graph", "abstract": "<p>Search engines and recommendation systems are built to efficiently display\nrelevant information from those massive amounts of candidates. Typically a\nthree-stage mechanism is employed in those systems: (i) a small collection of\nitems are first retrieved by (e.g.,) approximate near neighbor search\nalgorithms; (ii) then a collection of constraints are applied on the retrieved\nitems; (iii) a fine-grained ranking neural network is employed to determine the\nfinal recommendation. We observe a major defect of the original three-stage\npipeline: Although we only target to retrieve \\(k\\) vectors in the final\nrecommendation, we have to preset a sufficiently large \\(s\\) (\\(s &gt; k\\)) for each\nquery, and ``hope\u2019\u2019 the number of survived vectors after the filtering is not\nsmaller than \\(k\\). That is, at least \\(k\\) vectors in the \\(s\\) similar candidates\nsatisfy the query constraints.\n  In this paper, we investigate this constrained similarity search problem and\nattempt to merge the similarity search stage and the filtering stage into one\nsingle search operation. We introduce AIRSHIP, a system that integrates a\nuser-defined function filtering into the similarity search framework. The\nproposed system does not need to build extra indices nor require prior\nknowledge of the query constraints. We propose three optimization strategies:\n(1) starting point selection, (2) multi-direction search, and (3) biased\npriority queue selection. Experimental evaluations on both synthetic and real\ndata confirm the effectiveness of the proposed AIRSHIP algorithm. We focus on\nconstrained graph-based approximate near neighbor (ANN) search in this study,\nin part because graph-based ANN is known to achieve excellent performance. We\nbelieve it is also possible to develop constrained hashing-based ANN or\nconstrained quantization-based ANN.</p>\n", "tags": ["KDD", "Hashing Methods", "Graph Based ANN", "Alt", "Recommender Systems", "Similarity Search", "Quantization", "Tools & Libraries", "Evaluation"], "tsne_embedding": [11.394463539123535, 13.59005069732666], "cluster": 0}, {"key": "zhao2023embedding", "year": "2023", "citations": "8", "title": "Embedding In Recommender Systems: A Survey", "abstract": "<p>Recommender systems have become an essential component of many online\nplatforms, providing personalized recommendations to users. A crucial aspect is\nembedding techniques that coverts the high-dimensional discrete features, such\nas user and item IDs, into low-dimensional continuous vectors and can enhance\nthe recommendation performance. Applying embedding techniques captures complex\nentity relationships and has spurred substantial research. In this survey, we\nprovide an overview of the recent literature on embedding techniques in\nrecommender systems. This survey covers embedding methods like collaborative\nfiltering, self-supervised learning, and graph-based techniques. Collaborative\nfiltering generates embeddings capturing user-item preferences, excelling in\nsparse data. Self-supervised methods leverage contrastive or generative\nlearning for various tasks. Graph-based techniques like node2vec exploit\ncomplex relationships in network-rich environments. Addressing the scalability\nchallenges inherent to embedding methods, our survey delves into innovative\ndirections within the field of recommendation systems. These directions aim to\nenhance performance and reduce computational complexity, paving the way for\nimproved recommender systems. Among these innovative approaches, we will\nintroduce Auto Machine Learning (AutoML), hash techniques, and quantization\ntechniques in this survey. We discuss various architectures and techniques and\nhighlight the challenges and future directions in these aspects. This survey\naims to provide a comprehensive overview of the state-of-the-art in this\nrapidly evolving field and serve as a useful resource for researchers and\npractitioners working in the area of recommender systems.</p>\n", "tags": ["Survey Paper", "Graph Based ANN", "Recommender Systems", "Quantization", "Tools & Libraries", "Evaluation"], "tsne_embedding": [10.747207641601562, 12.179378509521484], "cluster": 0}, {"key": "zhao2025deep", "year": "2025", "citations": "463", "title": "Deep Semantic Ranking Based Hashing For Multi-label Image Retrieval", "abstract": "<p>With the rapid growth of web images, hashing has received\nincreasing interests in large scale image retrieval.\nResearch efforts have been devoted to learning compact binary\ncodes that preserve semantic similarity based on labels.\nHowever, most of these hashing methods are designed\nto handle simple binary similarity. The complex multilevel\nsemantic structure of images associated with multiple labels\nhave not yet been well explored. Here we propose a deep\nsemantic ranking based method for learning hash functions\nthat preserve multilevel semantic similarity between multilabel\nimages. In our approach, deep convolutional neural\nnetwork is incorporated into hash functions to jointly\nlearn feature representations and mappings from them to\nhash codes, which avoids the limitation of semantic representation\npower of hand-crafted features. Meanwhile, a\nranking list that encodes the multilevel similarity information\nis employed to guide the learning of such deep hash\nfunctions. An effective scheme based on surrogate loss is\nused to solve the intractable optimization problem of nonsmooth\nand multivariate ranking measures involved in the\nlearning procedure. Experimental results show the superiority\nof our proposed approach over several state-of-theart\nhashing methods in term of ranking evaluation metrics\nwhen tested on multi-label image datasets.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "CVPR", "Neural Hashing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-5.504199504852295, 0.4085915684700012], "cluster": 8}, {"key": "zhao2025note", "year": "2025", "citations": "26", "title": "A Note On Efficient Privacy-preserving Similarity Search For Encrypted Vectors", "abstract": "<p>Traditional approaches to vector similarity search over encrypted data rely\non fully homomorphic encryption (FHE) to enable computation without decryption.\nHowever, the substantial computational overhead of FHE makes it impractical for\nlarge-scale real-time applications. This work explores a more efficient\nalternative: using additively homomorphic encryption (AHE) for\nprivacy-preserving similarity search. We consider scenarios where either the\nquery vector or the database vectors remain encrypted, a setting that\nfrequently arises in applications such as confidential recommender systems and\nsecure federated learning. While AHE only supports addition and scalar\nmultiplication, we show that it is sufficient to compute inner product\nsimilarity\u2013one of the most widely used similarity measures in vector\nretrieval. Compared to FHE-based solutions, our approach significantly reduces\ncomputational overhead by avoiding ciphertext-ciphertext multiplications and\nbootstrapping, while still preserving correctness and privacy. We present an\nefficient algorithm for encrypted similarity search under AHE and analyze its\nerror growth and security implications. Our method provides a scalable and\npractical solution for privacy-preserving vector search in real-world machine\nlearning applications.</p>\n", "tags": ["Alt", "Similarity Search", "Recommender Systems"], "tsne_embedding": [5.21260929107666, -22.01321792602539], "cluster": 5}, {"key": "zhe2018deep", "year": "2018", "citations": "36", "title": "Deep Class-wise Hashing: Semantics-preserving Hashing Via Class-wise Loss", "abstract": "<p>Deep supervised hashing has emerged as an influential solution to large-scale\nsemantic image retrieval problems in computer vision. In the light of recent\nprogress, convolutional neural network based hashing methods typically seek\npair-wise or triplet labels to conduct the similarity preserving learning.\nHowever, complex semantic concepts of visual contents are hard to capture by\nsimilar/dissimilar labels, which limits the retrieval performance. Generally,\npair-wise or triplet losses not only suffer from expensive training costs but\nalso lack in extracting sufficient semantic information. In this regard, we\npropose a novel deep supervised hashing model to learn more compact class-level\nsimilarity preserving binary codes. Our deep learning based model is motivated\nby deep metric learning that directly takes semantic labels as supervised\ninformation in training and generates corresponding discriminant hashing code.\nSpecifically, a novel cubic constraint loss function based on Gaussian\ndistribution is proposed, which preserves semantic variations while penalizes\nthe overlap part of different classes in the embedding space. To address the\ndiscrete optimization problem introduced by binary codes, a two-step\noptimization strategy is proposed to provide efficient training and avoid the\nproblem of gradient vanishing. Extensive experiments on four large-scale\nbenchmark databases show that our model can achieve the state-of-the-art\nretrieval performance. Moreover, when training samples are limited, our method\nsurpasses other supervised deep hashing methods with non-negligible margins.</p>\n", "tags": ["Image Retrieval", "Hashing Methods", "Distance Metric Learning", "Compact Codes", "Neural Hashing", "Evaluation"], "tsne_embedding": [-9.11210823059082, -5.756503582000732], "cluster": 9}, {"key": "zhe2018directional", "year": "2018", "citations": "72", "title": "Directional Statistics-based Deep Metric Learning For Image Classification And Retrieval", "abstract": "<p>Deep distance metric learning (DDML), which is proposed to learn image\nsimilarity metrics in an end-to-end manner based on the convolution neural\nnetwork, has achieved encouraging results in many computer vision\ntasks.\\(L2\\)-normalization in the embedding space has been used to improve the\nperformance of several DDML methods. However, the commonly used Euclidean\ndistance is no longer an accurate metric for \\(L2\\)-normalized embedding space,\ni.e., a hyper-sphere. Another challenge of current DDML methods is that their\nloss functions are usually based on rigid data formats, such as the triplet\ntuple. Thus, an extra process is needed to prepare data in specific formats. In\naddition, their losses are obtained from a limited number of samples, which\nleads to a lack of the global view of the embedding space. In this paper, we\nreplace the Euclidean distance with the cosine similarity to better utilize the\n\\(L2\\)-normalization, which is able to attenuate the curse of dimensionality.\nMore specifically, a novel loss function based on the von Mises-Fisher\ndistribution is proposed to learn a compact hyper-spherical embedding space.\nMoreover, a new efficient learning algorithm is developed to better capture the\nglobal structure of the embedding space. Experiments for both classification\nand retrieval tasks on several standard datasets show that our method achieves\nstate-of-the-art performance with a simpler training procedure. Furthermore, we\ndemonstrate that, even with a small number of convolutional layers, our model\ncan still obtain significantly better classification performance than the\nwidely used softmax loss.</p>\n", "tags": ["CVPR", "DATASETS", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [-16.528522491455078, 3.5647339820861816], "cluster": 3}, {"key": "zhen2025co", "year": "2025", "citations": "195", "title": "Co-regularized Hashing For Multimodal Data", "abstract": "<p>Hashing-based methods provide a very promising approach to large-scale similarity\nsearch. To obtain compact hash codes, a recent trend seeks to learn the hash\nfunctions from data automatically. In this paper, we study hash function learning\nin the context of multimodal data. We propose a novel multimodal hash function\nlearning method, called Co-Regularized Hashing (CRH), based on a boosted coregularization\nframework. The hash functions for each bit of the hash codes are\nlearned by solving DC (difference of convex functions) programs, while the learning\nfor multiple bits proceeds via a boosting procedure so that the bias introduced\nby the hash functions can be sequentially minimized. We empirically compare\nCRH with two state-of-the-art multimodal hash function learning methods on two\npublicly available data sets.</p>\n", "tags": ["Tools & Libraries", "Hashing Methods"], "tsne_embedding": [0.04609240964055061, -11.637922286987305], "cluster": 9}, {"key": "zheng2020generative", "year": "2020", "citations": "10", "title": "Generative Semantic Hashing Enhanced Via Boltzmann Machines", "abstract": "<p>Generative semantic hashing is a promising technique for large-scale\ninformation retrieval thanks to its fast retrieval speed and small memory\nfootprint. For the tractability of training, existing generative-hashing\nmethods mostly assume a factorized form for the posterior distribution,\nenforcing independence among the bits of hash codes. From the perspectives of\nboth model representation and code space size, independence is always not the\nbest assumption. In this paper, to introduce correlations among the bits of\nhash codes, we propose to employ the distribution of Boltzmann machine as the\nvariational posterior. To address the intractability issue of training, we\nfirst develop an approximate method to reparameterize the distribution of a\nBoltzmann machine by augmenting it as a hierarchical concatenation of a\nGaussian-like distribution and a Bernoulli distribution. Based on that, an\nasymptotically-exact lower bound is further derived for the evidence lower\nbound (ELBO). With these novel techniques, the entire model can be optimized\nefficiently. Extensive experimental results demonstrate that by effectively\nmodeling correlations among different bits within a hash code, our model can\nachieve significant performance gains.</p>\n", "tags": ["Text Retrieval", "Evaluation", "Hashing Methods", "Efficiency And Optimization", "ACL"], "tsne_embedding": [-1.9824800491333008, -9.812458038330078], "cluster": 9}, {"key": "zheng2025enhancing", "year": "2025", "citations": "16", "title": "Enhancing Embedding Representation Stability In Recommendation Systems With Semantic ID", "abstract": "<p>The exponential growth of online content has posed significant challenges to\nID-based models in industrial recommendation systems, ranging from extremely\nhigh cardinality and dynamically growing ID space, to highly skewed engagement\ndistributions, to prediction instability as a result of natural id life cycles\n(e.g, the birth of new IDs and retirement of old IDs). To address these issues,\nmany systems rely on random hashing to handle the id space and control the\ncorresponding model parameters (i.e embedding table). However, this approach\nintroduces data pollution from multiple ids sharing the same embedding, leading\nto degraded model performance and embedding representation instability.\n  This paper examines these challenges and introduces Semantic ID prefix ngram,\na novel token parameterization technique that significantly improves the\nperformance of the original Semantic ID. Semantic ID prefix ngram creates\nsemantically meaningful collisions by hierarchically clustering items based on\ntheir content embeddings, as opposed to random assignments. Through extensive\nexperimentation, we demonstrate that Semantic ID prefix ngram not only\naddresses embedding instability but also significantly improves tail id\nmodeling, reduces overfitting, and mitigates representation shifts. We further\nhighlight the advantages of Semantic ID prefix ngram in attention-based models\nthat contextualize user histories, showing substantial performance\nimprovements. We also report our experience of integrating Semantic ID into\nMeta production Ads Ranking system, leading to notable performance gains and\nenhanced prediction stability in live deployments.</p>\n", "tags": ["Recommender Systems", "Hashing Methods", "Evaluation"], "tsne_embedding": [4.314262390136719, -3.0458920001983643], "cluster": 4}, {"key": "zhong2020compact", "year": "2020", "citations": "8", "title": "Compact Deep Aggregation For Set Retrieval", "abstract": "<p>The objective of this work is to learn a compact embedding of a set of\ndescriptors that is suitable for efficient retrieval and ranking, whilst\nmaintaining discriminability of the individual descriptors. We focus on a\nspecific example of this general problem \u2013 that of retrieving images\ncontaining multiple faces from a large scale dataset of images. Here the set\nconsists of the face descriptors in each image, and given a query for multiple\nidentities, the goal is then to retrieve, in order, images which contain all\nthe identities, all but one, \\etc\n  To this end, we make the following contributions: first, we propose a CNN\narchitecture \u2013 {\\em SetNet} \u2013 to achieve the objective: it learns face\ndescriptors and their aggregation over a set to produce a compact fixed length\ndescriptor designed for set retrieval, and the score of an image is a count of\nthe number of identities that match the query; second, we show that this\ncompact descriptor has minimal loss of discriminability up to two faces per\nimage, and degrades slowly after that \u2013 far exceeding a number of baselines;\nthird, we explore the speed vs.\\ retrieval quality trade-off for set retrieval\nusing this compact descriptor; and, finally, we collect and annotate a large\ndataset of images containing various number of celebrities, which we use for\nevaluation and is publicly released.</p>\n", "tags": ["DATASETS", "Similarity Search", "Evaluation"], "tsne_embedding": [-11.29144287109375, 23.30733871459961], "cluster": 6}, {"key": "zhou2011hamming", "year": "2011", "citations": "7", "title": "Hamming Compressed Sensing", "abstract": "<p>Compressed sensing (CS) and 1-bit CS cannot directly recover quantized\nsignals and require time consuming recovery. In this paper, we introduce\n\\textit{Hamming compressed sensing} (HCS) that directly recovers a k-bit\nquantized signal of dimensional \\(n\\) from its 1-bit measurements via invoking\n\\(n\\) times of Kullback-Leibler divergence based nearest neighbor search.\nCompared with CS and 1-bit CS, HCS allows the signal to be dense, takes\nconsiderably less (linear) recovery time and requires substantially less\nmeasurements (\\(\\mathcal O(log n)\\)). Moreover, HCS recovery can accelerate the\nsubsequent 1-bit CS dequantizer. We study a quantized recovery error bound of\nHCS for general signals and \u201cHCS+dequantizer\u201d recovery error bound for sparse\nsignals. Extensive numerical simulations verify the appealing accuracy,\nrobustness, efficiency and consistency of HCS.</p>\n", "tags": ["Efficiency And Optimization", "Robustness"], "tsne_embedding": [16.087547302246094, -5.227503299713135], "cluster": 2}, {"key": "zhou2016generic", "year": "2016", "citations": "11", "title": "A Generic Inverted Index Framework For Similarity Search On The GPU - Technical Report", "abstract": "<p>We propose a novel generic inverted index framework on the GPU (called\nGENIE), aiming to reduce the programming complexity of the GPU for parallel\nsimilarity search of different data types. Not every data type and similarity\nmeasure are supported by GENIE, but many popular ones are. We present the\nsystem design of GENIE, and demonstrate similarity search with GENIE on several\ndata types along with a theoretical analysis of search results. A new concept\nof locality sensitive hashing (LSH) named \\(\\tau\\)-ANN search, and a novel data\nstructure c-PQ on the GPU are also proposed for achieving this purpose.\nExtensive experiments on different real-life datasets demonstrate the\nefficiency and effectiveness of our framework. The implemented system has been\nreleased as open source.</p>\n", "tags": ["Locality Sensitive Hashing", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Similarity Search", "Quantization", "Tools & Libraries"], "tsne_embedding": [6.466015815734863, -8.414981842041016], "cluster": 2}, {"key": "zhou2016transfer", "year": "2016", "citations": "25", "title": "Transfer Hashing With Privileged Information", "abstract": "<p>Most existing learning to hash methods assume that there are sufficient data,\neither labeled or unlabeled, on the domain of interest (i.e., the target\ndomain) for training. However, this assumption cannot be satisfied in some\nreal-world applications. To address this data sparsity issue in hashing,\ninspired by transfer learning, we propose a new framework named Transfer\nHashing with Privileged Information (THPI). Specifically, we extend the\nstandard learning to hash method, Iterative Quantization (ITQ), in a transfer\nlearning manner, namely ITQ+. In ITQ+, a new slack function is learned from\nauxiliary data to approximate the quantization error in ITQ. We developed an\nalternating optimization approach to solve the resultant optimization problem\nfor ITQ+. We further extend ITQ+ to LapITQ+ by utilizing the geometry structure\namong the auxiliary data for learning more precise binary codes in the target\ndomain. Extensive experiments on several benchmark datasets verify the\neffectiveness of our proposed approaches through comparisons with several\nstate-of-the-art baselines.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Compact Codes", "Alt", "Quantization", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-9.467556953430176, -6.8879170417785645], "cluster": 9}, {"key": "zhou2019ladder", "year": "2019", "citations": "27", "title": "Ladder Loss For Coherent Visual-semantic Embedding", "abstract": "<p>For visual-semantic embedding, the existing methods normally treat the\nrelevance between queries and candidates in a bipolar way \u2013 relevant or\nirrelevant, and all \u201cirrelevant\u201d candidates are uniformly pushed away from the\nquery by an equal margin in the embedding space, regardless of their various\nproximity to the query. This practice disregards relatively discriminative\ninformation and could lead to suboptimal ranking in the retrieval results and\npoorer user experience, especially in the long-tail query scenario where a\nmatching candidate may not necessarily exist. In this paper, we introduce a\ncontinuous variable to model the relevance degree between queries and multiple\ncandidates, and propose to learn a coherent embedding space, where candidates\nwith higher relevance degrees are mapped closer to the query than those with\nlower relevance degrees. In particular, the new ladder loss is proposed by\nextending the triplet loss inequality to a more general inequality chain, which\nimplements variable push-away margins according to respective relevance\ndegrees. In addition, a proper Coherent Score metric is proposed to better\nmeasure the ranking results including those \u201cirrelevant\u201d candidates. Extensive\nexperiments on multiple datasets validate the efficacy of our proposed method,\nwhich achieves significant improvement over existing state-of-the-art methods.</p>\n", "tags": ["AAAI", "DATASETS", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [3.785081386566162, 5.007698059082031], "cluster": 4}, {"key": "zhu2016radon", "year": "2016", "citations": "12", "title": "Radon Features And Barcodes For Medical Image Retrieval Via SVM", "abstract": "<p>For more than two decades, research has been performed on content-based image\nretrieval (CBIR). By combining Radon projections and the support vector\nmachines (SVM), a content-based medical image retrieval method is presented in\nthis work. The proposed approach employs the normalized Radon projections with\ncorresponding image category labels to build an SVM classifier, and the Radon\nbarcode database which encodes every image in a binary format is also generated\nsimultaneously to tag all images. To retrieve similar images when a query image\nis given, Radon projections and the barcode of the query image are generated.\nSubsequently, the k-nearest neighbor search method is applied to find the\nimages with minimum Hamming distance of the Radon barcode within the same class\npredicted by the trained SVM classifier that uses Radon features. The\nperformance of the proposed method is validated by using the IRMA 2009 dataset\nwith 14,410 x-ray images in 57 categories. The results demonstrate that our\nmethod has the capacity to retrieve similar responses for the correctly\nidentified query image and even for those mistakenly classified by SVM. The\napproach further is very fast and has low memory requirement.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Evaluation"], "tsne_embedding": [-23.93551254272461, 16.324726104736328], "cluster": 3}, {"key": "zhu2017discrete", "year": "2017", "citations": "9", "title": "Discrete Multi-modal Hashing With Canonical Views For Robust Mobile Landmark Search", "abstract": "<p>Mobile landmark search (MLS) recently receives increasing attention for its\ngreat practical values. However, it still remains unsolved due to two important\nchallenges. One is high bandwidth consumption of query transmission, and the\nother is the huge visual variations of query images sent from mobile devices.\nIn this paper, we propose a novel hashing scheme, named as canonical view based\ndiscrete multi-modal hashing (CV-DMH), to handle these problems via a novel\nthree-stage learning procedure. First, a submodular function is designed to\nmeasure visual representativeness and redundancy of a view set. With it,\ncanonical views, which capture key visual appearances of landmark with limited\nredundancy, are efficiently discovered with an iterative mining strategy.\nSecond, multi-modal sparse coding is applied to transform visual features from\nmultiple modalities into an intermediate representation. It can robustly and\nadaptively characterize visual contents of varied landmark images with certain\ncanonical views. Finally, compact binary codes are learned on intermediate\nrepresentation within a tailored discrete binary embedding model which\npreserves visual relations of images measured with canonical views and removes\nthe involved noises. In this part, we develop a new augmented Lagrangian\nmultiplier (ALM) based optimization method to directly solve the discrete\nbinary codes. We can not only explicitly deal with the discrete constraint, but\nalso consider the bit-uncorrelated constraint and balance constraint together.\nExperiments on real world landmark datasets demonstrate the superior\nperformance of CV-DMH over several state-of-the-art methods.</p>\n", "tags": ["Compact Codes", "DATASETS", "Hashing Methods", "Evaluation"], "tsne_embedding": [-15.062520027160645, 10.587788581848145], "cluster": 3}, {"key": "zhu2017part", "year": "2017", "citations": "70", "title": "Part-based Deep Hashing For Large-scale Person Re-identification", "abstract": "<p>Large-scale is a trend in person re-identification (re-id). It is important\nthat real-time search be performed in a large gallery. While previous methods\nmostly focus on discriminative learning, this paper makes the attempt in\nintegrating deep learning and hashing into one framework to evaluate the\nefficiency and accuracy for large-scale person re-id. We integrate spatial\ninformation for discriminative visual representation by partitioning the\npedestrian image into horizontal parts. Specifically, Part-based Deep Hashing\n(PDH) is proposed, in which batches of triplet samples are employed as the\ninput of the deep hashing architecture. Each triplet sample contains two\npedestrian images (or parts) with the same identity and one pedestrian image\n(or part) of the different identity. A triplet loss function is employed with a\nconstraint that the Hamming distance of pedestrian images (or parts) with the\nsame identity is smaller than ones with the different identity. In the\nexperiment, we show that the proposed Part-based Deep Hashing method yields\nvery competitive re-id accuracy on the large-scale Market-1501 and\nMarket-1501+500K datasets.</p>\n", "tags": ["DATASETS", "Hashing Methods", "Distance Metric Learning", "Efficiency And Optimization", "Neural Hashing", "Tools & Libraries"], "tsne_embedding": [4.180166244506836, 23.374998092651367], "cluster": 6}, {"key": "zhu2019exploring", "year": "2019", "citations": "154", "title": "Exploring Auxiliary Context: Discrete Semantic Transfer Hashing For Scalable Image Retrieval", "abstract": "<p>Unsupervised hashing can desirably support scalable content-based image\nretrieval (SCBIR) for its appealing advantages of semantic label independence,\nmemory and search efficiency. However, the learned hash codes are embedded with\nlimited discriminative semantics due to the intrinsic limitation of image\nrepresentation. To address the problem, in this paper, we propose a novel\nhashing approach, dubbed as <em>Discrete Semantic Transfer Hashing</em> (DSTH).\nThe key idea is to <em>directly</em> augment the semantics of discrete image hash\ncodes by exploring auxiliary contextual modalities. To this end, a unified\nhashing framework is formulated to simultaneously preserve visual similarities\nof images and perform semantic transfer from contextual modalities. Further, to\nguarantee direct semantic transfer and avoid information loss, we explicitly\nimpose the discrete constraint, bit\u2013uncorrelation constraint and bit-balance\nconstraint on hash codes. A novel and effective discrete optimization method\nbased on augmented Lagrangian multiplier is developed to iteratively solve the\noptimization problem. The whole learning process has linear computation\ncomplexity and desirable scalability. Experiments on three benchmark datasets\ndemonstrate the superiority of DSTH compared with several state-of-the-art\napproaches.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-10.066308975219727, 6.939972877502441], "cluster": 8}, {"key": "zhu2019visual", "year": "2019", "citations": "25", "title": "Visual Explanation For Deep Metric Learning", "abstract": "<p>This work explores the visual explanation for deep metric learning and its\napplications. As an important problem for learning representation, metric\nlearning has attracted much attention recently, while the interpretation of\nsuch model is not as well studied as classification. To this end, we propose an\nintuitive idea to show where contributes the most to the overall similarity of\ntwo input images by decomposing the final activation. Instead of only providing\nthe overall activation map of each image, we propose to generate point-to-point\nactivation intensity between two images so that the relationship between\ndifferent regions is uncovered. We show that the proposed framework can be\ndirectly deployed to a large range of metric learning applications and provides\nvaluable information for understanding the model. Furthermore, our experiments\nshow its effectiveness on two potential applications, i.e. cross-view pattern\ndiscovery and interactive retrieval. The source code is available at\nhttps://github.com/Jeff-Zilence/Explain_Metric_Learning.</p>\n", "tags": ["Tools & Libraries", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [-23.586177825927734, 7.060507297515869], "cluster": 3}, {"key": "zhu2020dual", "year": "2020", "citations": "38", "title": "Dual-level Semantic Transfer Deep Hashing For Efficient Social Image Retrieval", "abstract": "<p>Social network stores and disseminates a tremendous amount of user shared\nimages. Deep hashing is an efficient indexing technique to support large-scale\nsocial image retrieval, due to its deep representation capability, fast\nretrieval speed and low storage cost. Particularly, unsupervised deep hashing\nhas well scalability as it does not require any manually labelled data for\ntraining. However, owing to the lacking of label guidance, existing methods\nsuffer from severe semantic shortage when optimizing a large amount of deep\nneural network parameters. Differently, in this paper, we propose a Dual-level\nSemantic Transfer Deep Hashing (DSTDH) method to alleviate this problem with a\nunified deep hash learning framework. Our model targets at learning the\nsemantically enhanced deep hash codes by specially exploiting the\nuser-generated tags associated with the social images. Specifically, we design\na complementary dual-level semantic transfer mechanism to efficiently discover\nthe potential semantics of tags and seamlessly transfer them into binary hash\ncodes. On the one hand, instance-level semantics are directly preserved into\nhash codes from the associated tags with adverse noise removing. Besides, an\nimage-concept hypergraph is constructed for indirectly transferring the latent\nhigh-order semantic correlations of images and tags into hash codes. Moreover,\nthe hash codes are obtained simultaneously with the deep representation\nlearning by the discrete hash optimization strategy. Extensive experiments on\ntwo public social image retrieval datasets validate the superior performance of\nour method compared with state-of-the-art hashing methods. The source codes of\nour method can be obtained at https://github.com/research2020-1/DSTDH</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Neural Hashing", "Tools & Libraries", "Evaluation"], "tsne_embedding": [-8.258734703063965, -3.659114122390747], "cluster": 8}, {"key": "zhu2022lower", "year": "2022", "citations": "9", "title": "A Lower Bound Of Hash Codes' Performance", "abstract": "<p>As a crucial approach for compact representation learning, hashing has\nachieved great success in effectiveness and efficiency. Numerous heuristic\nHamming space metric learning objectives are designed to obtain high-quality\nhash codes. Nevertheless, a theoretical analysis of criteria for learning good\nhash codes remains largely unexploited. In this paper, we prove that\ninter-class distinctiveness and intra-class compactness among hash codes\ndetermine the lower bound of hash codes\u2019 performance. Promoting these two\ncharacteristics could lift the bound and improve hash learning. We then propose\na surrogate model to fully exploit the above objective by estimating the\nposterior of hash codes and controlling it, which results in a low-bias\noptimization. Extensive experiments reveal the effectiveness of the proposed\nmethod. By testing on a series of hash-models, we obtain performance\nimprovements among all of them, with an up to \\(26.5%\\) increase in mean Average\nPrecision and an up to \\(20.5%\\) increase in accuracy. Our code is publicly\navailable at https://github.com/VL-Group/LBHash.</p>\n", "tags": ["Distance Metric Learning", "Hashing Methods", "Evaluation", "Efficiency And Optimization"], "tsne_embedding": [-1.3008102178573608, -11.371238708496094], "cluster": 9}, {"key": "zhu2023clip", "year": "2023", "citations": "37", "title": "CLIP Multi-modal Hashing: A New Baseline CLIPMH", "abstract": "<p>The multi-modal hashing method is widely used in multimedia retrieval. It can\nfuse multi-source data to generate binary hash code. However, the current\nmulti-modal methods have the problem of low retrieval accuracy. The reason is\nthat the individual backbone networks have limited feature expression\ncapabilities and are not jointly pre-trained on large-scale unsupervised\nmulti-modal data. To solve this problem, we propose a new baseline CLIP\nMulti-modal Hashing (CLIPMH) method. It uses CLIP model to extract text and\nimage features, and then fuse to generate hash code. CLIP improves the\nexpressiveness of each modal feature. In this way, it can greatly improve the\nretrieval performance of multi-modal hashing methods. In comparison to\nstate-of-the-art unsupervised and supervised multi-modal hashing methods,\nexperiments reveal that the proposed CLIPMH can significantly enhance\nperformance (Maximum increase of 8.38%). CLIP also has great advantages over\nthe text and visual backbone networks commonly used before.</p>\n", "tags": ["Hashing Methods", "Evaluation"], "tsne_embedding": [-5.641382217407227, 17.474624633789062], "cluster": 6}, {"key": "zhu2023deep", "year": "2023", "citations": "7", "title": "Deep Metric Multi-view Hashing For Multimedia Retrieval", "abstract": "<p>Learning the hash representation of multi-view heterogeneous data is an\nimportant task in multimedia retrieval. However, existing methods fail to\neffectively fuse the multi-view features and utilize the metric information\nprovided by the dissimilar samples, leading to limited retrieval precision.\nCurrent methods utilize weighted sum or concatenation to fuse the multi-view\nfeatures. We argue that these fusion methods cannot capture the interaction\namong different views. Furthermore, these methods ignored the information\nprovided by the dissimilar samples. We propose a novel deep metric multi-view\nhashing (DMMVH) method to address the mentioned problems. Extensive empirical\nevidence is presented to show that gate-based fusion is better than typical\nmethods. We introduce deep metric learning to the multi-view hashing problems,\nwhich can utilize metric information of dissimilar samples. On the\nMIR-Flickr25K, MS COCO, and NUS-WIDE, our method outperforms the current\nstate-of-the-art methods by a large margin (up to 15.28 mean Average Precision\n(mAP) improvement).</p>\n", "tags": ["Hashing Methods", "Evaluation", "Distance Metric Learning"], "tsne_embedding": [-6.022714614868164, -4.823675155639648], "cluster": 9}, {"key": "zhu2025deep", "year": "2025", "citations": "636", "title": "Deep Hashing Network For Efficient Similarity Retrieval", "abstract": "<p>Due to the storage and retrieval efficiency, hashing has been widely deployed to approximate nearest neighbor search for large-scale multimedia retrieval. Supervised hashing, which improves the quality of hash coding by exploiting the semantic similarity on data pairs, has received increasing attention recently. For most existing supervised hashing methods for image retrieval, an image is first represented as a vector of hand-crafted or machine-learned features, followed by another separate quantization step that generates binary codes.\nHowever, suboptimal hash coding may be produced, because the quantization error is not statistically minimized and the feature representation is not optimally compatible with the binary coding. In this paper, we propose a novel Deep Hashing Network (DHN) architecture for supervised hashing, in which we jointly learn good image representation tailored to hash coding and formally control the quantization error.\nThe DHN model constitutes four key components: (1) a sub-network with multiple convolution-pooling layers to capture image representations; (2) a fully-connected hashing layer to generate compact binary hash codes; (3) a pairwise cross-entropy loss layer for similarity-preserving learning; and (4) a pairwise quantization loss for controlling hashing quality. Extensive experiments on standard image retrieval datasets show the proposed DHN model yields substantial boosts over latest state-of-the-art hashing methods.</p>\n", "tags": ["Image Retrieval", "AAAI", "DATASETS", "Hashing Methods", "Efficiency And Optimization", "Compact Codes", "Neural Hashing", "Similarity Search", "Quantization"], "tsne_embedding": [-9.364781379699707, 3.315455198287964], "cluster": 8}, {"key": "zhu2025linear", "year": "2025", "citations": "278", "title": "Linear Cross-modal Hashing For Efficient Multimedia Search", "abstract": "<p>Most existing cross-modal hashing methods suffer from the scalability issue in the training phase. In this paper, we propose a novel \ncross-modal hashing approach with a linear time complexity to the training data size, to enable scalable indexing for multimedia \nsearch across multiple modals. Taking both the intra-similarity in each modal and the inter-similarity across different modals \ninto consideration, the proposed approach aims at effectively learning hash functions from large-scale training datasets. \nMore specifically, for each modal, we first partition the training data into \\(k\\) clusters and then represent each training data \npoint with its distances to \\(k\\) centroids of the clusters. Interestingly, such a k-dimensional data representation can reduce \nthe time complexity of the training phase from traditional O(n2) or higher to O(n), where \\(n\\) is the training data size, leading to \npractical learning on large-scale datasets. We further prove that this new representation preserves the intra-similarity in each modal. \nTo preserve the inter-similarity among data points across different modals, we transform the derived data representations into a \ncommon binary subspace in which binary codes from all the modals are \u201cconsistent\u201d and comparable. The transformation simultaneously \noutputs the hash functions for all modals, which are used to convert unseen data into binary codes. Given a query of one modal, \nit is first mapped into the binary codes using the modal\u2019s hash functions, followed by matching the database binary codes of any other \nmodals. Experimental results on two benchmark datasets confirm the scalability and the effectiveness of the proposed approach in \ncomparison with the state of the art.</p>\n", "tags": ["Compact Codes", "DATASETS", "Hashing Methods", "Evaluation"], "tsne_embedding": [-21.921995162963867, -2.8655343055725098], "cluster": 1}, {"key": "zhuang2016fast", "year": "2016", "citations": "136", "title": "Fast Training Of Triplet-based Deep Binary Embedding Networks", "abstract": "<p>In this paper, we aim to learn a mapping (or embedding) from images to a\ncompact binary space in which Hamming distances correspond to a ranking measure\nfor the image retrieval task.\n  We make use of a triplet loss because this has been shown to be most\neffective for ranking problems.\n  However, training in previous works can be prohibitively expensive due to the\nfact that optimization is directly performed on the triplet space, where the\nnumber of possible triplets for training is cubic in the number of training\nexamples.\n  To address this issue, we propose to formulate high-order binary codes\nlearning as a multi-label classification problem by explicitly separating\nlearning into two interleaved stages.\n  To solve the first stage, we design a large-scale high-order binary codes\ninference algorithm to reduce the high-order objective to a standard binary\nquadratic problem such that graph cuts can be used to efficiently infer the\nbinary code which serve as the label of each training datum.\n  In the second stage we propose to map the original image to compact binary\ncodes via carefully designed deep convolutional neural networks (CNNs) and the\nhashing function fitting can be solved by training binary CNN classifiers.\n  An incremental/interleaved optimization strategy is proffered to ensure that\nthese two steps are interactive with each other during training for better\naccuracy.\n  We conduct experiments on several benchmark datasets, which demonstrate both\nimproved training time (by as much as two orders of magnitude) as well as\nproducing state-of-the-art hashing for various retrieval tasks.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Distance Metric Learning", "CVPR", "Compact Codes", "Evaluation"], "tsne_embedding": [-9.722267150878906, -7.445636749267578], "cluster": 1}, {"key": "zieba2018bingan", "year": "2018", "citations": "36", "title": "Bingan: Learning Compact Binary Descriptors With A Regularized GAN", "abstract": "<p>In this paper, we propose a novel regularization method for Generative\nAdversarial Networks, which allows the model to learn discriminative yet\ncompact binary representations of image patches (image descriptors). We employ\nthe dimensionality reduction that takes place in the intermediate layers of the\ndiscriminator network and train binarized low-dimensional representation of the\npenultimate layer to mimic the distribution of the higher-dimensional preceding\nlayers. To achieve this, we introduce two loss terms that aim at: (i) reducing\nthe correlation between the dimensions of the binarized low-dimensional\nrepresentation of the penultimate layer i. e. maximizing joint entropy) and\n(ii) propagating the relations between the dimensions in the high-dimensional\nspace to the low-dimensional space. We evaluate the resulting binary image\ndescriptors on two challenging applications, image matching and retrieval, and\nachieve state-of-the-art results.</p>\n", "tags": ["Hashing Methods", "Robustness"], "tsne_embedding": [-0.530029296875, 7.6113505363464355], "cluster": 8}, {"key": "zoran2017learning", "year": "2017", "citations": "9", "title": "Learning Deep Nearest Neighbor Representations Using Differentiable Boundary Trees", "abstract": "<p>Nearest neighbor (kNN) methods have been gaining popularity in recent years\nin light of advances in hardware and efficiency of algorithms. There is a\nplethora of methods to choose from today, each with their own advantages and\ndisadvantages. One requirement shared between all kNN based methods is the need\nfor a good representation and distance measure between samples.\n  We introduce a new method called differentiable boundary tree which allows\nfor learning deep kNN representations. We build on the recently proposed\nboundary tree algorithm which allows for efficient nearest neighbor\nclassification, regression and retrieval. By modelling traversals in the tree\nas stochastic events, we are able to form a differentiable cost function which\nis associated with the tree\u2019s predictions. Using a deep neural network to\ntransform the data and back-propagating through the tree allows us to learn\ngood representations for kNN methods.\n  We demonstrate that our method is able to learn suitable representations\nallowing for very efficient trees with a clearly interpretable structure.</p>\n", "tags": ["Efficiency And Optimization"], "tsne_embedding": [12.673197746276855, 0.4257916212081909], "cluster": 4}, {"key": "zou2019transductive", "year": "2019", "citations": "14", "title": "Transductive Zero-shot Hashing For Multilabel Image Retrieval", "abstract": "<p>Hash coding has been widely used in approximate nearest neighbor search for\nlarge-scale image retrieval. Given semantic annotations such as class labels\nand pairwise similarities of the training data, hashing methods can learn and\ngenerate effective and compact binary codes. While some newly introduced images\nmay contain undefined semantic labels, which we call unseen images, zeor-shot\nhashing techniques have been studied. However, existing zeor-shot hashing\nmethods focus on the retrieval of single-label images, and cannot handle\nmulti-label images. In this paper, for the first time, a novel transductive\nzero-shot hashing method is proposed for multi-label unseen image retrieval. In\norder to predict the labels of the unseen/target data, a visual-semantic bridge\nis built via instance-concept coherence ranking on the seen/source data. Then,\npairwise similarity loss and focal quantization loss are constructed for\ntraining a hashing model using both the seen/source and unseen/target data.\nExtensive evaluations on three popular multi-label datasets demonstrate that,\nthe proposed hashing method achieves significantly better results than the\ncompeting methods.</p>\n", "tags": ["Image Retrieval", "DATASETS", "Hashing Methods", "Compact Codes", "Quantization", "Evaluation"], "tsne_embedding": [-18.008878707885742, -2.7872626781463623], "cluster": 1}, {"key": "zou2025prompthash", "year": "2025", "citations": "7", "title": "Prompthash: Affinity-prompted Collaborative Cross-modal Learning For Adaptive Hashing Retrieval", "abstract": "<p>Cross-modal hashing is a promising approach for efficient data retrieval and\nstorage optimization. However, contemporary methods exhibit significant\nlimitations in semantic preservation, contextual integrity, and information\nredundancy, which constrains retrieval efficacy. We present PromptHash, an\ninnovative framework leveraging affinity prompt-aware collaborative learning\nfor adaptive cross-modal hashing. We propose an end-to-end framework for\naffinity-prompted collaborative hashing, with the following fundamental\ntechnical contributions: (i) a text affinity prompt learning mechanism that\npreserves contextual information while maintaining parameter efficiency, (ii)\nan adaptive gated selection fusion architecture that synthesizes State Space\nModel with Transformer network for precise cross-modal feature integration, and\n(iii) a prompt affinity alignment strategy that bridges modal heterogeneity\nthrough hierarchical contrastive learning. To the best of our knowledge, this\nstudy presents the first investigation into affinity prompt awareness within\ncollaborative cross-modal adaptive hash learning, establishing a paradigm for\nenhanced semantic consistency across modalities. Through comprehensive\nevaluation on three benchmark multi-label datasets, PromptHash demonstrates\nsubstantial performance improvements over existing approaches. Notably, on the\nNUS-WIDE dataset, our method achieves significant gains of 18.22% and 18.65% in\nimage-to-text and text-to-image retrieval tasks, respectively. The code is\npublicly available at https://github.com/ShiShuMo/PromptHash.</p>\n", "tags": ["DATASETS", "Evaluation", "Hashing Methods", "Efficiency And Optimization", "Image Retrieval", "Tools & Libraries", "Multimodal Retrieval"], "tsne_embedding": [-14.394095420837402, -0.6991795897483826], "cluster": 8}, {"key": "zvedeniouk2010angle", "year": "2010", "citations": "14", "title": "Angle Tree: Nearest Neighbor Search In High Dimensions With Low Intrinsic Dimensionality", "abstract": "<p>We propose an extension of tree-based space-partitioning indexing structures\nfor data with low intrinsic dimensionality embedded in a high dimensional\nspace. We call this extension an Angle Tree. Our extension can be applied to\nboth classical kd-trees as well as the more recent rp-trees. The key idea of\nour approach is to store the angle (the \u201cdihedral angle\u201d) between the data\nregion (which is a low dimensional manifold) and the random hyperplane that\nsplits the region (the \u201csplitter\u201d). We show that the dihedral angle can be used\nto obtain a tight lower bound on the distance between the query point and any\npoint on the opposite side of the splitter. This in turn can be used to\nefficiently prune the search space. We introduce a novel randomized strategy to\nefficiently calculate the dihedral angle with a high degree of accuracy.\nExperiments and analysis on real and synthetic data sets shows that the Angle\nTree is the most efficient known indexing structure for nearest neighbor\nqueries in terms of preprocessing and space usage while achieving high accuracy\nand fast search time.</p>\n", "tags": ["Tree Based ANN"], "tsne_embedding": [23.253795623779297, 2.2842204570770264], "cluster": 7}, {"key": "\u00f1anculef2020self", "year": "2020", "citations": "5", "title": "Self-supervised Bernoulli Autoencoders For Semi-supervised Hashing", "abstract": "<p>Semantic hashing is an emerging technique for large-scale similarity search\nbased on representing high-dimensional data using similarity-preserving binary\ncodes used for efficient indexing and search. It has recently been shown that\nvariational autoencoders, with Bernoulli latent representations parametrized by\nneural nets, can be successfully trained to learn such codes in supervised and\nunsupervised scenarios, improving on more traditional methods thanks to their\nability to handle the binary constraints architecturally. However, the scenario\nwhere labels are scarce has not been studied yet.\n  This paper investigates the robustness of hashing methods based on\nvariational autoencoders to the lack of supervision, focusing on two\nsemi-supervised approaches currently in use. The first augments the variational\nautoencoder\u2019s training objective to jointly model the distribution over the\ndata and the class labels. The second approach exploits the annotations to\ndefine an additional pairwise loss that enforces consistency between the\nsimilarity in the code (Hamming) space and the similarity in the label space.\nOur experiments show that both methods can significantly increase the hash\ncodes\u2019 quality. The pairwise approach can exhibit an advantage when the number\nof labelled points is large. However, we found that this method degrades\nquickly and loses its advantage when labelled samples decrease. To circumvent\nthis problem, we propose a novel supervision method in which the model uses its\nlabel distribution predictions to implement the pairwise objective. Compared to\nthe best baseline, this procedure yields similar performance in fully\nsupervised settings but improves the results significantly when labelled data\nis scarce. Our code is made publicly available at\nhttps://github.com/amacaluso/SSB-VAE.</p>\n", "tags": ["Hashing Methods", "Text Retrieval", "Similarity Search", "Evaluation", "Robustness"], "tsne_embedding": [-7.893698215484619, -5.259082794189453], "cluster": 9}]