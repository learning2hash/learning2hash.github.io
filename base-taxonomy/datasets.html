---
layout: default
title: Datasets
---
<h2>Unimodal and Cross-Modal Hashing Datasets</h2>

<b>Unimodal Datasets:</b>
For <i>unimodal</i> experiments (query and database are in the same feature space e.g. images), there are six popular and freely available image datasets: LabelMe, CIFAR-10, NUS-WIDE, MNIST, SIFT1M and ImageNet. The datasets are of
widely varying size (22,019-1.3 million images), are represented by an array of different
feature descriptors (from GIST, SIFT, RGB pixels to bag of visual words) and cover a diverse
range of different image topics from natural scenes to personal photos, logos and drawings.
<p></p>

<b>Cross-modal Datasets:</b>

<i>Cross-modal</i> retrieval experiments (query and database can be in different feature spaces e.g. image and text) are typically conducted on the `Wiki' dataset, Microsoft COCO and NUSWIDE datasets. All datasets come with images and associated
paired textual descriptors, a key requirement for training and evaluating a cross-modal
retrieval model.

{% assign publicationsList = site.data.morantaxonomy | sort: "bibkey" %}
<table id="reprModelTable">
<thead><th>Name</th><th>Dataset</th><th>Modality</th><th>Size</th><th>Features</th></thead><tbody>
{% for publication in publicationsList %}{% if publication.categories contains "dataset" %}
    {% assign pubDetails = site.publications | where:"bibkey", publication.bibkey %}  
      <tr>
          <td data-order="{{publication.bibkey}}"><a href="/publications/{{publication.bibkey}}">{{pubDetails[0].authors}}, {{pubDetails[0].year}}.</a>{{pubDetails[0].title}}</td>
          <td>{{publication.name}}</td>
          <td>{{publication.modality}}</td>
          <td>{{publication.size}}</td>
          <td>{{publication.features}}</td>
      </tr>
{% endif %}{% endfor %}
</tbody></table>

<script>
$(document).ready( function () {
    $('#reprModelTable').DataTable({paging: false,});
} );
</script>
