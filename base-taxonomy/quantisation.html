---
layout: default
title: Quantization Models
---

## Binary Quantization Models

**Quantization Models** play a crucial role in nearest neighbor search by converting real-valued data into binary hashcodes, making it easier and faster to retrieve similar items. Two primary types of quantization have been developed: *scalar* and *vector* quantization. The difference lies in whether the input and output are treated as a single scalar or as a vector. This page focuses on **scalar quantization**, a widely-used method in hashing.

### How Scalar Quantization Works:
In scalar quantization, the real-valued projections (resulting from the dot product between a data-pointâ€™s feature vector and the normal vectors of hyperplanes partitioning the feature space) are transformed into binary values. Each dot product produces a scalar value, which is then **quantized** into binary (0/1) through a thresholding process. The sequence of these binary values is concatenated to form a unique hashcode for each data point.

Below is a list of key publications on quantization models, ordered by their bibliographic key:

{% assign publicationsList = site.data.morantaxonomy | sort: "bibkey" %}
<table id="reprModelTable">
  <thead>
    <tr>
      <th>Paper</th>
      <th>Learning Type</th>
    </tr>
  </thead>
  <tbody>
    {% for publication in publicationsList %}{% if publication.categories contains "quantisation" %}
      {% assign pubDetails = site.publications | where:"bibkey", publication.bibkey %}
        <tr>
          <td data-order="{{publication.bibkey}}"><a href="/publications/{{publication.bibkey}}">{{pubDetails[0].authors}}, {{pubDetails[0].year}}.</a> {{pubDetails[0].title}}</td>
          <td>{{publication.type}}</td>
        </tr>
    {% endif %}{% endfor %}
  </tbody>
</table>

<script>
  $(document).ready( function () {
      $('#reprModelTable').DataTable({paging: false});
  });
</script>
