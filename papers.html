<!DOCTYPE html>
<html lang="en-us">

  <head>
<!-- Begin Web-Stat code v 7.0 -->
<span id="wts2185304"></span>
<script>var wts=document.createElement('script');wts.async=true;
wts.src='https://app.ardalio.com/log7.js';document.head.appendChild(wts);
wts.onload = function(){ wtslog7(2185304,4); };
</script><noscript><a href="https://www.web-stat.com">
<img src="https://app.ardalio.com/7/4/2185304.png" 
alt="Web-Stat web statistics"></a></noscript>
<!-- End Web-Stat code v 7.0 -->
  <!-- Hotjar Tracking Code for https://learning2hash.github.io/ -->
<script>
    (function(h,o,t,j,a,r){
        h.hj=h.hj||function(){(h.hj.q=h.hj.q||[]).push(arguments)};
        h._hjSettings={hjid:1843243,hjsv:6};
        a=o.getElementsByTagName('head')[0];
        r=o.createElement('script');r.async=1;
        r.src=t+h._hjSettings.hjid+j+h._hjSettings.hjsv;
        a.appendChild(r);
    })(window,document,'https://static.hotjar.com/c/hotjar-','.js?sv=');
</script><!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-109544763-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-109544763-1');
</script>
<script>
    window.MathJax = {
      tex: {
        inlineMath: [["\\(","\\)"]],
        displayMath: [["\\[","\\]"]],
      },
      options: {
        processHtmlClass: "mathjax-content",
        processEscapes: true,
      }
    };
  </script>
  <script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="keywords" content="machine learning, hashing, approximate nearest neighbour search, lsh, learning-to-hash">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Search all Publications on Machine Learning for Hashing | Awesome Learning to Hash</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="Search all Publications on Machine Learning for Hashing" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A list of research papers for machine learning models for hashing." />
<meta property="og:description" content="A list of research papers for machine learning models for hashing." />
<link rel="canonical" href="https://learning2hash.github.io/papers.html" />
<meta property="og:url" content="https://learning2hash.github.io/papers.html" />
<meta property="og:site_name" content="Awesome Learning to Hash" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Search all Publications on Machine Learning for Hashing" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"A list of research papers for machine learning models for hashing.","headline":"Search all Publications on Machine Learning for Hashing","url":"https://learning2hash.github.io/papers.html"}</script>
<!-- End Jekyll SEO tag -->


  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="shortcut icon" href="/public/favicon.svg">
  <link rel="search" href="/public/opensearchdescription.xml" 
      type="application/opensearchdescription+xml" 
      title="learning2hash" />

  <script src="https://code.jquery.com/jquery-3.2.1.min.js"
  integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
  crossorigin="anonymous"></script>
  
  <link rel="stylesheet" type="text/css" href="//cdn.datatables.net/1.10.16/css/jquery.dataTables.min.css">
  <script type="text/javascript" charset="utf8" src="//cdn.datatables.net/1.10.16/js/jquery.dataTables.min.js"></script>
</head>


  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

  <body class="theme-base-0c layout-reverse">

    <a href='/contributing.html' class='ribbon'>Add your paper to Learning2Hash</a>
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Awesome Learning to Hash
        </a>
      </h1>
      <p class="lead">A Webpage dedicated to the latest research on Hash Function Learning. Maintained by <a href="http://sjmoran.github.io/">Sean Moran</a>.</p>
    </div>

    <nav class="sidebar-nav">
      <div class="sidebar-item">
        <p style="font-size: 12px">
          Search related work 
          <input type='text' id='searchTarget' size="16"/> 
          <button onClick="search();">Go</button>
        </p>
      </div>
      <a class="sidebar-nav-item" href="/papers.html">All Papers</a>
      <a class="sidebar-nav-item" href="/tags.html">Papers by Tag</a>
      <a class="sidebar-nav-item" href="/tsne-viz.html">2D Map of Papers</a>
      <a class="sidebar-nav-item" href="/topic-viz.html">Topic-based Explorer</a>
      <a class="sidebar-nav-item" href="/tutorial.html">Tutorial</a>
      <a class="sidebar-nav-item" href="/resources.html">Resources, Courses &#38; Events</a>
      <a class="sidebar-nav-item" href="/contributing.html">Contributing</a>
    </nav>

    <div class="sidebar-item">
      <p style="font-size: 12px">
        Contact <a href="http://www.seanjmoran.com">Sean Moran</a> about this survey or website.
        <span style="font-size: 9px">
          Made with <a href="https://jekyllrb.com">Jekyll</a> and <a href="https://github.com/poole/hyde">Hyde</a>.
        </span>
      </p>
    </div>
  </div>
</div>

<script>
$("#searchTarget").keydown(function (e) {	
  if (e.keyCode == 13) {
    search();
  }
});

function search() {
  try {
    ga('send', 'event', 'search', 'search', $("#searchTarget").val());
  } finally {
    window.location = "/papers.html#" + $("#searchTarget").val();
  }
}
</script>


    <div class="content container">
      Search across all paper titles, abstracts, and authors by using the search field.
Please consider <a href="/contributing.html">contributing</a> by updating
the information of existing papers or adding new work.

<!-- Loading Indicator -->
<div id="loading">
  <p>Loading...</p>
</div>

<!-- Data Table -->
<table id="allPapers">
<thead>
  <tr>
    <th>Year</th>
    <th>Title</th>
    <th>Authors</th>
    <th>Venue</th>
    <th>Citations</th>
    <th>Abstract</th>
    <th>Tags</th>
  </tr>
  </thead>
  <tbody>
    
    
      
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/raginsky2025locality/">Locality-sensitive Binary Codes From Shift-invariant Kernels</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Locality-sensitive Binary Codes From Shift-invariant Kernels' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Locality-sensitive Binary Codes From Shift-invariant Kernels' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Raginsky M., Lazebnik</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>633</td>
    <td><p>This paper addresses the problem of designing binary codes for high-dimensional
data such that vectors that are similar in the original space map to similar binary
strings. We introduce a simple distribution-free encoding scheme based on
random projections, such that the expected Hamming distance between the binary
codes of two vectors is related to the value of a shift-invariant kernel (e.g., a
Gaussian kernel) between the vectors. We present a full theoretical analysis of the
convergence properties of the proposed scheme, and report favorable experimental
performance as compared to a recent state-of-the-art method, spectral hashing.</p>
</td>
    <td>
      
        Compact Codes 
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/ramos2025blockboost/">Blockboost: Scalable And Efficient Blocking Through Boosting</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Blockboost: Scalable And Efficient Blocking Through Boosting' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Blockboost: Scalable And Efficient Blocking Through Boosting' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ramos et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the fifth international conference on Architectural support for programming languages and operating systems</td>
    <td>61</td>
    <td><p>As datasets grow larger, matching and merging entries from different databases has become a costly task in modern data pipelines. To avoid expensive comparisons between entries, blocking similar items is a popular preprocessing step. In this paper, we introduce BlockBoost, a novel boosting-based method that generates compact binary hash codes for database entries, through which blocking can be performed efficiently. The algorithm is fast and scalable, resulting in computational costs that are orders of magnitude lower than current benchmarks. Unlike existing alternatives, BlockBoost comes with associated feature importance measures for interpretability, and possesses strong theoretical guarantees, including lower bounds on critical performance metrics like recall and reduction ratio. Finally, we show that BlockBoost delivers great empirical results, outperforming state-of-the-art blocking benchmarks in terms of both performance metrics and computational cost.</p>
</td>
    <td>
      
        Alt 
      
        Hashing Methods 
      
        Evaluation 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/rong2025locality/">Locality-sensitive Hashing For Earthquake Detection: A Case Study Of Scaling Data-driven Science</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Locality-sensitive Hashing For Earthquake Detection: A Case Study Of Scaling Data-driven Science' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Locality-sensitive Hashing For Earthquake Detection: A Case Study Of Scaling Data-driven Science' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Rong et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>6</td>
    <td><p>In this work, we report on a novel application of Locality Sensitive
Hashing (LSH) to seismic data at scale. Based on the high waveform similarity between reoccurring earthquakes, our application
identifies potential earthquakes by searching for similar time series
segments via LSH. However, a straightforward implementation of
this LSH-enabled application has difficulty scaling beyond 3 months
of continuous time series data measured at a single seismic station.
As a case study of a data-driven science workflow, we illustrate how
domain knowledge can be incorporated into the workload to improve
both the efficiency and result quality. We describe several end-toend optimizations of the analysis pipeline from pre-processing to
post-processing, which allow the application to scale to time series data measured at multiple seismic stations. Our optimizations
enable an over 100Ã— speedup in the end-to-end analysis pipeline.
This improved scalability enabled seismologists to perform seismic
analysis on more than ten years of continuous time series data from
over ten seismic stations, and has directly enabled the discovery of
597 new earthquakes near the Diablo Canyon nuclear power plant
in California and 6123 new earthquakes in New Zealand.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/pauleve2025locality/">Locality Sensitive Hashing: A Comparison Of Hash Function Types And Querying Mechanisms</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Locality Sensitive Hashing: A Comparison Of Hash Function Types And Querying Mechanisms' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Locality Sensitive Hashing: A Comparison Of Hash Function Types And Querying Mechanisms' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Pauleve Loic, Jegou, Amsaleg</td> <!-- ðŸ”§ You were missing this -->
    <td>Pattern Recognition Letters</td>
    <td>299</td>
    <td><p>It is well known that high-dimensional nearest-neighbor retrieval is very expensive. Dramatic performance gains are obtained using
approximate search schemes, such as the popular Locality-Sensitive Hashing (LSH). Several extensions have been proposed to
address the limitations of this algorithm, in particular, by choosing more appropriate hash functions to better partition the vector
space. All the proposed extensions, however, rely on a structured quantizer for hashing, poorly fitting real data sets, limiting
its performance in practice. In this paper, we compare several families of space hashing functions in a real setup, namely when
searching for high-dimension SIFT descriptors. The comparison of random projections, lattice quantizers, k-means and hierarchical
k-means reveal that unstructured quantizer significantly improves the accuracy of LSH, as it closely fits the data in the feature space.
We then compare two querying mechanisms introduced in the literature with the one originally proposed in LSH, and discuss their
respective merits and limitations.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/petrovic2025streaming/">Streaming First Story Detection With Application To Twitter</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Streaming First Story Detection With Application To Twitter' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Streaming First Story Detection With Application To Twitter' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Petrovic S., Osborne, Lavrenko</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>565</td>
    <td><p>With the recent rise in popularity and size of
social media, there is a growing need for systems
that can extract useful information from
this amount of data. We address the problem
of detecting new events from a stream of
Twitter posts. To make event detection feasible
on web-scale corpora, we present an algorithm
based on locality-sensitive hashing which
is able overcome the limitations of traditional
approaches, while maintaining competitive results.
In particular, a comparison with a stateof-the-art
system on the first story detection
task shows that we achieve over an order of
magnitude speedup in processing time, while
retaining comparable performance. Event detection
experiments on a collection of 160 million
Twitter posts show that celebrity deaths
are the fastest spreading news on Twitter.</p>
</td>
    <td>
      
        Large Scale Search 
      
        Hashing Methods 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/pariente2025infinity/">Infinity Search: Approximate Vector Search With Projections On Q-metric Spaces</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Infinity Search: Approximate Vector Search With Projections On Q-metric Spaces' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Infinity Search: Approximate Vector Search With Projections On Q-metric Spaces' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Pariente et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Pattern Recognition Letters</td>
    <td>8</td>
    <td><p>Despite the ubiquity of vector search applications, prevailing search algorithms overlook the metric structure of vector embeddings, treating it as a constraint rather than exploiting its underlying properties. In this paper, we demonstrate that in \(q\)-metric spaces, metric trees can leverage a stronger version of the triangle inequality to reduce comparisons for exact search. Notably, as \(q\) approaches infinity, the search complexity becomes logarithmic. Therefore, we propose a novel projection method that embeds vector datasets with arbitrary dissimilarity measures into \(q\)-metric spaces while preserving the nearest neighbor. We propose to learn an approximation of this projection to efficiently transform query points to a space where euclidean distances satisfy the desired properties. Our experimental results with text and image vector embeddings show that learning \(q\)-metric approximations enables classic metric tree algorithms â€“ which typically underperform with high-dimensional data â€“ to achieve competitive performance against state-of-the-art search methods.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/petrovic2025using/">Using Paraphrases For Improving First Story Detection In News And Twitter</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Using Paraphrases For Improving First Story Detection In News And Twitter' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Using Paraphrases For Improving First Story Detection In News And Twitter' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Petrovic S., Osborne, Lavrenko</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>91</td>
    <td><p>First story detection (FSD) involves identifying
first stories about events from a continuous
stream of documents. A major problem in this
task is the high degree of lexical variation in
documents which makes it very difficult to detect
stories that talk about the same event but
expressed using different words. We suggest
using paraphrases to alleviate this problem,
making this the first work to use paraphrases
for FSD. We show a novel way of integrating
paraphrases with locality sensitive hashing
(LSH) in order to obtain an efficient FSD system
that can scale to very large datasets. Our
system achieves state-of-the-art results on the
first story detection task, beating both the best
supervised and unsupervised systems. To test
our approach on large data, we construct a corpus
of events for Twitter, consisting of 50 million
documents, and show that paraphrasing is
also beneficial in this domain.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/norouzi2025hamming/">Hamming Distance Metric Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hamming Distance Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hamming Distance Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Norouzi M., Fleet, Salakhutdinov</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>540</td>
    <td><p>Motivated by large-scale multimedia applications we propose to learn mappings
from high-dimensional data to binary codes that preserve semantic similarity.
Binary codes are well suited to large-scale applications as they are storage efficient and permit exact sub-linear kNN search. The framework is applicable
to broad families of mappings, and uses a flexible form of triplet ranking loss.
We overcome discontinuous optimization of the discrete mappings by minimizing
a piecewise-smooth upper bound on empirical loss, inspired by latent structural
SVMs. We develop a new loss-augmented inference algorithm that is quadratic in
the code length. We show strong retrieval performance on CIFAR-10 and MNIST,
with promising classification results using no more than kNN on the binary codes.</p>
</td>
    <td>
      
        Distance Metric Learning 
      
        Compact Codes 
      
        Similarity Search 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/neyshabur2025power/">The Power Of Asymmetry In Binary Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=The Power Of Asymmetry In Binary Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=The Power Of Asymmetry In Binary Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Neyshabur B., Salakhutdinov, Srebro</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>57</td>
    <td><p>When approximating binary similarity using the hamming distance between short
binary hashes, we show that even if the similarity is symmetric, we can have
shorter and more accurate hashes by using two distinct code maps. I.e. by approximating the similarity between x and x
0
as the hamming distance between f(x)
and g(x0), for two distinct binary codes f, g, rather than as the hamming distance
between f(x) and f(x0).</p>
</td>
    <td>
      
        Compact Codes 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/nguyennhu2025lightweight/">A Lightweight Moment Retrieval System With Global Re-ranking And Robust Adaptive Bidirectional Temporal Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Lightweight Moment Retrieval System With Global Re-ranking And Robust Adaptive Bidirectional Temporal Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Lightweight Moment Retrieval System With Global Re-ranking And Robust Adaptive Bidirectional Temporal Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Nguyen-nhu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining</td>
    <td>6</td>
    <td><p>The exponential growth of digital video content has posed critical challenges
in moment-level video retrieval, where existing methodologies struggle to
efficiently localize specific segments within an expansive video corpus.
Current retrieval systems are constrained by computational inefficiencies,
temporal context limitations, and the intrinsic complexity of navigating video
content. In this paper, we address these limitations through a novel
Interactive Video Corpus Moment Retrieval framework that integrates a
SuperGlobal Reranking mechanism and Adaptive Bidirectional Temporal Search
(ABTS), strategically optimizing query similarity, temporal stability, and
computational resources. By preprocessing a large corpus of videos using a
keyframe extraction model and deduplication technique through image hashing,
our approach provides a scalable solution that significantly reduces storage
requirements while maintaining high localization precision across diverse video
repositories.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Tools & Libraries 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/norouzi2025minimal/">Minimal Loss Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Minimal Loss Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Minimal Loss Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Norouzi M., Fleet</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>730</td>
    <td><p>We propose a method for learning similaritypreserving
hash functions that map highdimensional
data onto binary codes. The
formulation is based on structured prediction
with latent variables and a hinge-like
loss function. It is efficient to train for large
datasets, scales well to large code lengths,
and outperforms state-of-the-art methods.</p>
</td>
    <td>
      
        Compact Codes 
      
        DATASETS 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/mukherjee2025nmf/">An NMF Perspective On Binary Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=An NMF Perspective On Binary Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=An NMF Perspective On Binary Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Mukherjee et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2015 IEEE International Conference on Computer Vision (ICCV)</td>
    <td>14</td>
    <td><p>The pervasiveness of massive data repositories has led
to much interest in efficient methods for indexing, search,
and retrieval. For image data, a rapidly developing body of
work for these applications shows impressive performance
with methods that broadly fall under the umbrella term of
Binary Hashing. Given a distance matrix, a binary hashing
algorithm solves for a binary code for the given set of examples, whose Hamming distance nicely approximates the
original distances. The formulation is non-convex â€” so existing solutions adopt spectral relaxations or perform coordinate descent (or quantization) on a surrogate objective
that is numerically more tractable. In this paper, we first
derive an Augmented Lagrangian approach to optimize the
standard binary Hashing objective (i.e., maintain fidelity
with a given distance matrix). With appropriate step sizes,
we find that this scheme already yields results that match or
substantially outperform state of the art methods on most
benchmarks used in the literature. Then, to allow the model
to scale to large datasets, we obtain an interesting reformulation of the binary hashing objective as a non-negative matrix factorization. Later, this leads to a simple multiplicative updates algorithm â€” whose parallelization properties
are exploited to obtain a fast GPU based implementation.
We give a probabilistic analysis of our initialization scheme
and present a range of experiments to show that the method
is simple to implement and competes favorably with available methods (both for optimization and generalization).</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        ICCV 
      
        Quantization 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/moran2025variable/">Variable Bit Quantisation For LSH</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Variable Bit Quantisation For LSH' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Variable Bit Quantisation For LSH' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Moran S., Lavrenko, Osborne</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>21</td>
    <td><p>We introduce a scheme for optimally allocating
a variable number of bits per
LSH hyperplane. Previous approaches assign
a constant number of bits per hyperplane.
This neglects the fact that a subset
of hyperplanes may be more informative
than others. Our method, dubbed Variable
Bit Quantisation (VBQ), provides a datadriven
non-uniform bit allocation across
hyperplanes. Despite only using a fraction
of the available hyperplanes, VBQ outperforms
uniform quantisation by up to 168%
for retrieval across standard text and image
datasets.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/moran2025neighbourhood/">Neighbourhood Preserving Quantisation For LSH</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Neighbourhood Preserving Quantisation For LSH' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Neighbourhood Preserving Quantisation For LSH' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Moran S., Lavrenko, Osborne</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval</td>
    <td>22</td>
    <td><p>We introduce a scheme for optimally allocating multiple bits per hyperplane for Locality Sensitive Hashing (LSH). Existing approaches binarise LSH projections by thresholding at zero yielding a single bit per dimension. We demonstrate that this is a sub-optimal bit allocation approach that can easily destroy the neighbourhood structure in the original feature space. Our proposed method, dubbed Neighbourhood Preserving Quantization (NPQ), assigns multiple bits per hyperplane based upon adaptively learned thresholds. NPQ exploits a pairwise affinity matrix to discretise each dimension such that nearest neighbours in the original feature space fall within the same quantisation thresholds and are therefore assigned identical bits. NPQ is not only applicable to LSH, but can also be applied to any low-dimensional projection scheme. Despite using half the number of hyperplanes, NPQ is shown to improve LSH-based retrieval accuracy by up to 65% compared to the state-of-the-art.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        SIGIR 
      
        Quantization 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/moran2025enhancing/">Enhancing First Story Detection Using Word Embeddings</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Enhancing First Story Detection Using Word Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Enhancing First Story Detection Using Word Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Moran et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval</td>
    <td>29</td>
    <td><p>In this paper we show how word embeddings can be used to increase the effectiveness of a state-of-the art Locality Sensitive Hashing (LSH) based first story detection (FSD) system over a standard tweet corpus. Vocabulary mismatch, in which related tweets use different words, is a serious hindrance to the effectiveness of a modern FSD system. In this case, a tweet could be flagged as a first story even if a related tweet, which uses different but synonymous words, was already returned as a first story. In this work, we propose a novel approach to mitigate this problem of lexical variation, based on tweet expansion. In particular, we propose to expand tweets with semantically related paraphrases identified via automatically mined word embeddings over a background tweet corpus. Through experimentation on a large data stream comprised of 50 million tweets, we show that FSD effectiveness can be improved by 9.5% over a state-of-the-art FSD system.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        SIGIR 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/moran2025regularised/">Regularised Cross-modal Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Regularised Cross-modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Regularised Cross-modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Moran S., Lavrenko</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval</td>
    <td>18</td>
    <td><p>In this paper we propose Regularised Cross-Modal Hashing (RCMH) a new cross-modal hashing scheme that projects annotation and visual feature descriptors into a common Hamming space. RCMH optimises the intra-modality similarity of data-points in the annotation modality using an iterative three-step hashing algorithm: in the first step each training image is assigned a K-bit hashcode based on hyperplanes learnt at the previous iteration; in the second step the binary bits are smoothed by a formulation of graph regularisation so that similar data-points have similar bits; in the third step a set of binary classifiers are trained to predict the regularised bits with maximum margin. Visual descriptors are projected into the annotation Hamming space by a set of binary classifiers learnt using the bits of the corresponding annotations as labels. RCMH is shown to consistently improve retrieval effectiveness over state-of-the-art baselines.</p>
</td>
    <td>
      
        SIGIR 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/mohoney2025quake/">Quake: Adaptive Indexing For Vector Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Quake: Adaptive Indexing For Vector Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Quake: Adaptive Indexing For Vector Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Mohoney et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>ACM Transactions on Intelligent Systems and Technology</td>
    <td>21</td>
    <td><p>Vector search, the task of finding the k-nearest neighbors of a query vector against a database of high-dimensional vectors, underpins many machine learning applications, including retrieval-augmented generation, recommendation systems, and information retrieval. However, existing approximate nearest neighbor (ANN) methods perform poorly under dynamic and skewed workloads where data distributions evolve. We introduce Quake, an adaptive indexing system that maintains low latency and high recall in such environments. Quake employs a multi-level partitioning scheme that adjusts to updates and changing access patterns, guided by a cost model that predicts query latency based on partition sizes and access frequencies. Quake also dynamically sets query execution parameters to meet recall targets using a novel recall estimation model. Furthermore, Quake utilizes NUMA-aware intra-query parallelism for improved memory bandwidth utilization during search. To evaluate Quake, we prepare a Wikipedia vector search workload and develop a workload generator to create vector search workloads with configurable access patterns. Our evaluation shows that on dynamic workloads, Quake achieves query latency reductions of 1.5-38x and update latency reductions of 4.5-126x compared to state-of-the-art indexes such as SVS, DiskANN, HNSW, and SCANN.</p>
</td>
    <td>
      
        Graph Based ANN 
      
        Efficiency And Optimization 
      
        Recommender Systems 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/mei2025temporal/">Temporal-aware Spiking Transformer Hashing Based On 3D-DWT</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Temporal-aware Spiking Transformer Hashing Based On 3D-DWT' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Temporal-aware Spiking Transformer Hashing Based On 3D-DWT' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Mei et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2015 International Conference on Green Computing and Internet of Things (ICGCIoT)</td>
    <td>8</td>
    <td><p>With the rapid growth of dynamic vision sensor (DVS) data, constructing a
low-energy, efficient data retrieval system has become an urgent task. Hash
learning is one of the most important retrieval technologies which can keep the
distance between hash codes consistent with the distance between DVS data. As
spiking neural networks (SNNs) can encode information through spikes, they
demonstrate great potential in promoting energy efficiency. Based on the binary
characteristics of SNNs, we first propose a novel supervised hashing method
named Spikinghash with a hierarchical lightweight structure. Spiking WaveMixer
(SWM) is deployed in shallow layers, utilizing a multilevel 3D discrete wavelet
transform (3D-DWT) to decouple spatiotemporal features into various
low-frequency and high frequency components, and then employing efficient
spectral feature fusion. SWM can effectively capture the temporal dependencies
and local spatial features. Spiking Self-Attention (SSA) is deployed in deeper
layers to further extract global spatiotemporal information. We also design a
hash layer utilizing binary characteristic of SNNs, which integrates
information over multiple time steps to generate final hash codes. Furthermore,
we propose a new dynamic soft similarity loss for SNNs, which utilizes membrane
potentials to construct a learnable similarity matrix as soft labels to fully
capture the similarity differences between classes and compensate information
loss in SNNs, thereby improving retrieval performance. Experiments on multiple
datasets demonstrate that Spikinghash can achieve state-of-the-art results with
low energy consumption and fewer parameters.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Neural Hashing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/ma2025harr/">HARR: Learning Discriminative And High-quality Hash Codes For Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=HARR: Learning Discriminative And High-quality Hash Codes For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=HARR: Learning Discriminative And High-quality Hash Codes For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ma et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>ACM Transactions on Multimedia Computing, Communications, and Applications</td>
    <td>5</td>
    <td><p>This article studies deep unsupervised hashing, which has attracted increasing attention in large-scale image retrieval. The majority of recent approaches usually reconstruct semantic similarity information, which then guides the hash code learning. However, they still fail to achieve satisfactory performance in reality for two reasons. On the one hand, without accurate supervised information, these methods usually fail to produce independent and robust hash codes with semantics information well preserved, which may hinder effective image retrieval. On the other hand, due to discrete constraints, how to effectively optimize the hashing network in an end-to-end manner with small quantization errors remains a problem. To address these difficulties, we propose a novel unsupervised hashing method called HARR to learn discriminative and high-quality hash codes. To comprehensively explore semantic similarity structure, HARR adopts the Winner-Take-All hash to model the similarity structure. Then similarity-preserving hash codes are learned under the reliable guidance of the reconstructed similarity structure. Additionally, we improve the quality of hash codes by a bit correlation reduction module, which forces the cross-correlation matrix between a batch of hash codes under different augmentations to approach the identity matrix. In this way, the generated hash bits are expected to be invariant to disturbances with minimal redundancy, which can be further interpreted as an instantiation of the information bottleneck principle. Finally, for effective hashing network training, we minimize the cosine distances between real-value network outputs and their binary codes for small quantization errors. Extensive experiments demonstrate the effectiveness of our proposed HARR.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Compact Codes 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/ma2025progressive/">Progressive Generative Hashing For Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Progressive Generative Hashing For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Progressive Generative Hashing For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ma et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence</td>
    <td>18</td>
    <td><p>Recent years have witnessed the success of the emerging hashing techniques in large-scale image
retrieval. Owing to the great learning capacity,
deep hashing has become one of the most promising solutions, and achieved attractive performance
in practice. However, without semantic label information, the unsupervised deep hashing still remains
an open question. In this paper, we propose a novel
progressive generative hashing (PGH) framework
to help learn a discriminative hashing network in an
unsupervised way. Different from existing studies,
it first treats the hash codes as a kind of semantic
condition for the similar image generation, and simultaneously feeds the original image and its codes
into the generative adversarial networks (GANs).
The real images together with the synthetic ones
can further help train a discriminative hashing network based on a triplet loss. By iteratively inputting
the learnt codes into the hash conditioned GANs, we can progressively enable the hashing network
to discover the semantic relations. Extensive experiments on the widely-used image datasets demonstrate that PGH can significantly outperform stateof-the-art unsupervised hashing methods.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        IJCAI 
      
        Robustness 
      
        Neural Hashing 
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        Image Retrieval 
      
        Tools & Libraries 
      
        AAAI 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/luo2025fast/">Fast Scalable Supervised Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fast Scalable Supervised Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fast Scalable Supervised Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Luo et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval</td>
    <td>89</td>
    <td><p>Despite significant progress in supervised hashing, there are three
common limitations of existing methods. First, most pioneer methods discretely learn hash codes bit by bit, making the learning
procedure rather time-consuming. Second, to reduce the large complexity of the n by n pairwise similarity matrix, most methods apply
sampling strategies during training, which inevitably results in information loss and suboptimal performance; some recent methods
try to replace the large matrix with a smaller one, but the size is
still large. Third, among the methods that leverage the pairwise
similarity matrix, most of them only encode the semantic label
information in learning the hash codes, failing to fully capture
the characteristics of data. In this paper, we present a novel supervised hashing method, called Fast Scalable Supervised Hashing
(FSSH), which circumvents the use of the large similarity matrix by
introducing a pre-computed intermediate term whose size is independent with the size of training data. Moreover, FSSH can learn
the hash codes with not only the semantic information but also
the features of data. Extensive experiments on three widely used
datasets demonstrate its superiority over several state-of-the-art
methods in both accuracy and scalability. Our experiment codes
are available at: https://lcbwlx.wixsite.com/fssh.</p>
</td>
    <td>
      
        SIGIR 
      
        Hashing Methods 
      
        Evaluation 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/lv2025multi/">Multi-probe LSH: Efficient Indexing For High-dimensional Similarity Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Multi-probe LSH: Efficient Indexing For High-dimensional Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Multi-probe LSH: Efficient Indexing For High-dimensional Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lv et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>620</td>
    <td><p>Similarity indices for high-dimensional data are very desirable for building content-based search systems for featurerich data such as audio, images, videos, and other sensor
data. Recently, locality sensitive hashing (LSH) and its
variations have been proposed as indexing techniques for
approximate similarity search. A significant drawback of
these approaches is the requirement for a large number of
hash tables in order to achieve good search quality. This paper proposes a new indexing scheme called multi-probe LSH
that overcomes this drawback. Multi-probe LSH is built on
the well-known LSH technique, but it intelligently probes
multiple buckets that are likely to contain query results in
a hash table. Our method is inspired by and improves upon
recent theoretical work on entropy-based LSH designed to
reduce the space requirement of the basic LSH method. We
have implemented the multi-probe LSH method and evaluated the implementation with two different high-dimensional
datasets. Our evaluation shows that the multi-probe LSH
method substantially improves upon previously proposed
methods in both space and time efficiency. To achieve the
same search quality, multi-probe LSH has a similar timeefficiency as the basic LSH method while reducing the number of hash tables by an order of magnitude. In comparison
with the entropy-based LSH method, to achieve the same
search quality, multi-probe LSH uses less query time and 5
to 8 times fewer number of hash tables.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/lu2025online/">Online Multi-modal Hashing With Dynamic Query-adaption</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Online Multi-modal Hashing With Dynamic Query-adaption' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Online Multi-modal Hashing With Dynamic Query-adaption' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</td>
    <td>128</td>
    <td><p>Multi-modal hashing is an effective technique to support large-scale multimedia retrieval, due to its capability of encoding heterogeneous multi-modal features into compact and similarity-preserving binary codes. Although great progress has been achieved so far, existing methods still suffer from several problems, including: 1) All existing methods simply adopt fixed modality combination weights in online hashing process to generate the query hash codes. This strategy cannot adaptively capture the variations of different queries. 2) They either suffer from insufficient semantics (for unsupervised methods) or require high computation and storage cost (for the supervised methods, which rely on pair-wise semantic matrix). 3) They solve the hash codes with relaxed optimization strategy or bit-by-bit discrete optimization, which results in significant quantization loss or consumes considerable computation time. To address the above limitations, in this paper, we propose an Online Multi-modal Hashing with Dynamic Query-adaption (OMH-DQ) method in a novel fashion. Specifically, a self-weighted fusion strategy is designed to adaptively preserve the multi-modal feature information into hash codes by exploiting their complementarity. The hash codes are learned with the supervision of pair-wise semantic labels to enhance their discriminative capability, while avoiding the challenging symmetric similarity matrix factorization. Under such learning framework, the binary hash codes can be directly obtained with efficient operations and without quantization errors. Accordingly, our method can benefit from the semantic labels, and simultaneously, avoid the high computation complexity. Moreover, to accurately capture the query variations, at the online retrieval stage, we design a parameter-free online hashing module which can adaptively learn the query hash codes according to the dynamic query contents. Extensive experiments demonstrate the state-of-the-art performance of the proposed approach from various aspects.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Alt 
      
        SIGIR 
      
        Quantization 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/long2025deep/">Deep Domain Adaptation Hashing With Adversarial Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Domain Adaptation Hashing With Adversarial Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Domain Adaptation Hashing With Adversarial Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Long et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval</td>
    <td>21</td>
    <td><p>The recent advances in deep neural networks have demonstrated high capability in a wide variety of scenarios. Nevertheless, fine-tuning deep models in a new domain still requires a significant amount of labeled data despite expensive labeling efforts. A valid question is how to leverage the source knowledge plus unlabeled or only sparsely labeled target data for learning a new model in target domain. The core problem is to bring the source and target distributions closer in the feature space. In the paper, we facilitate this issue in an adversarial learning framework, in which a domain discriminator is devised to handle domain shift. Particularly, we explore the learning in the context of hashing problem, which has been studied extensively due to its great efficiency in gigantic data. Specifically, a novel Deep Domain Adaptation Hashing with Adversarial learning (DeDAHA) architecture is presented, which mainly consists of three components: a deep convolutional neural networks (CNN) for learning basic image/frame representation followed by an adversary stream on one hand to optimize the domain discriminator, and on the other, to interact with each domain-specific hashing stream for encoding image representation to hash codes. The whole architecture is trained end-to-end by jointly optimizing two types of losses, i.e., triplet ranking loss to preserve the relative similarity ordering in the input triplets and adversarial loss to maximally fool the domain discriminator with the learnt source and target feature distributions. Extensive experiments are conducted on three domain transfer tasks, including cross-domain digits retrieval, image to image and image to video transfers, on several benchmarks. Our DeDAHA framework achieves superior results when compared to the state-of-the-art techniques.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        SIGIR 
      
        Tools & Libraries 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/liu2025multi/">Multi-view Complementary Hash Tables For Nearest Neighbor Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Multi-view Complementary Hash Tables For Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Multi-view Complementary Hash Tables For Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2015 IEEE International Conference on Computer Vision (ICCV)</td>
    <td>57</td>
    <td><p>Recent years have witnessed the success of hashing techniques in fast nearest neighbor search. In practice many
applications (e.g., visual search, object detection, image
matching, etc.) have enjoyed the benefits of complementary hash tables and information fusion over multiple views.
However, most of prior research mainly focused on compact hash code cleaning, and rare work studies how to build
multiple complementary hash tables, much less to adaptively integrate information stemming from multiple views.
In
this paper we first present a novel multi-view complementary hash table method that learns complementary hash tables from the data with multiple views. For single multiview table, using exemplar based feature fusion, we approximate the inherent data similarities with a low-rank matrix,
and learn discriminative hash functions in an efficient way.
To build complementary tables and meanwhile maintain scalable training and fast out-of-sample extension, an exemplar reweighting scheme is introduced to update the induced low-rank similarity in the sequential table construction framework, which indeed brings mutual benefits between tables by placing greater importance on exemplars
shared by mis-separated neighbors. Extensive experiments
on three large-scale image datasets demonstrate that the
proposed method significantly outperforms various naive
solutions and state-of-the-art multi-table methods.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        ICCV 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/liu2025moboost/">Moboost: A Self-improvement Framework For Linear-based Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Moboost: A Self-improvement Framework For Linear-based Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Moboost: A Self-improvement Framework For Linear-based Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Knowledge and Data Engineering</td>
    <td>5</td>
    <td><p>The linear model is commonly utilized in hashing methods owing to its efficiency. To obtain better accuracy, linear-based hashing methods focus on designing a generalized linear objective function with different constraints or penalty terms that consider neighborhood information. In this study, we propose a novel generalized framework called Model Boost (MoBoost), which can achieve the self-improvement of the linear-based hashing. The proposed MoBoost is used to improve model parameter optimization for linear-based hashing methods without adding new constraints or penalty terms. In the proposed MoBoost, given a linear-based hashing method, we first execute the method several times to get several different hash codes for training samples, and then combine these different hash codes into one set utilizing one novel fusion strategy. Based on this set of hash codes, we learn some new parameters for the linear hash function that can significantly improve accuracy. The proposed MoBoost can be generally adopted in existing linear-based hashing methods, achieving more precise and stable performance compared to the original methods while imposing negligible added expenditure in terms of time and space. Extensive experiments are performed based on three benchmark datasets, and the results demonstrate the superior performance of the proposed framework.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Alt 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/liu2025joint/">Joint-modal Distribution-based Similarity Hashing For Large-scale Unsupervised Deep Cross-modal Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Joint-modal Distribution-based Similarity Hashing For Large-scale Unsupervised Deep Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Joint-modal Distribution-based Similarity Hashing For Large-scale Unsupervised Deep Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</td>
    <td>148</td>
    <td><p>Hashing-based cross-modal search which aims to map multiple modality features into binary codes has attracted increasingly attention due to its storage and search efficiency especially in large-scale database retrieval. Recent unsupervised deep cross-modal hashing methods have shown promising results. However, existing approaches typically suffer from two limitations: (1) They usually learn cross-modal similarity information separately or in a redundant fusion manner, which may fail to capture semantic correlations among instances from different modalities sufficiently and effectively. (2) They seldom consider the sampling and weighting schemes for unsupervised cross-modal hashing, resulting in the lack of satisfactory discriminative ability in hash codes. To overcome these limitations, we propose a novel unsupervised deep cross-modal hashing method called Joint-modal Distribution-based Similarity Hashing (JDSH) for large-scale cross-modal retrieval. Firstly, we propose a novel cross-modal joint-training method by constructing a joint-modal similarity matrix to fully preserve the cross-modal semantic correlations among instances. Secondly, we propose a sampling and weighting scheme termed the Distribution-based Similarity Decision and Weighting (DSDW) method for unsupervised cross-modal hashing, which is able to generate more discriminative hash codes by pushing semantic similar instance pairs closer and pulling semantic dissimilar instance pairs apart. The experimental results demonstrate the superiority of JDSH compared with several unsupervised cross-modal hashing methods on two public datasets NUS-WIDE and MIRFlickr.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Multimodal Retrieval 
      
        SIGIR 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/liu2025model/">Model Optimization Boosting Framework For Linear Model Hash Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Model Optimization Boosting Framework For Linear Model Hash Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Model Optimization Boosting Framework For Linear Model Hash Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Image Processing</td>
    <td>22</td>
    <td><p>Efficient hashing techniques have attracted extensive research interests in both storage and retrieval of high dimensional data, such as images and videos. In existing hashing methods, a linear model is commonly utilized owing to its efficiency. To obtain better accuracy, linear-based hashing methods focus on designing a generalized linear objective function with different constraints or penalty terms that consider the inherent characteristics and neighborhood information of samples. Differing from existing hashing methods, in this study, we propose a self-improvement framework called Model Boost (MoBoost) to improve model parameter optimization for linear-based hashing methods without adding new constraints or penalty terms. In the proposed MoBoost, for a linear-based hashing method, we first repeatedly execute the hashing method to obtain several hash codes to training samples. Then, utilizing two novel fusion strategies, these codes are fused into a single set. We also propose two new criteria to evaluate the goodness of hash bits during the fusion process. Based on the fused set of hash codes, we learn new parameters for the linear hash function that can significantly improve the accuracy. In general, the proposed MoBoost can be adopted by existing linear-based hashing methods, achieving more precise and stable performance compared to the original methods, and adopting the proposed MoBoost will incur negligible time and space costs. To evaluate the proposed MoBoost, we performed extensive experiments on four benchmark datasets, and the results demonstrate superior performance.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Alt 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/liu2025supervised/">Supervised Hashing With Kernels</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Supervised Hashing With Kernels' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Supervised Hashing With Kernels' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2012 IEEE Conference on Computer Vision and Pattern Recognition</td>
    <td>1447</td>
    <td><p>Recent years have witnessed the growing popularity of
hashing in large-scale vision problems. It has been shown
that the hashing quality could be boosted by leveraging supervised
information into hash function learning. However,
the existing supervised methods either lack adequate performance
or often incur cumbersome model training. In this
paper, we propose a novel kernel-based supervised hashing
model which requires a limited amount of supervised information,
i.e., similar and dissimilar data pairs, and a feasible
training cost in achieving high quality hashing. The idea
is to map the data to compact binary codes whose Hamming
distances are minimized on similar pairs and simultaneously
maximized on dissimilar pairs. Our approach is
distinct from prior works by utilizing the equivalence between
optimizing the code inner products and the Hamming
distances. This enables us to sequentially and efficiently
train the hash functions one bit at a time, yielding very
short yet discriminative codes. We carry out extensive experiments
on two image benchmarks with up to one million
samples, demonstrating that our approach significantly outperforms
the state-of-the-arts in searching both metric distance
neighbors and semantically similar neighbors, with
accuracy gains ranging from 13% to 46%.</p>
</td>
    <td>
      
        CVPR 
      
        Compact Codes 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/liu2025discretely/">Discretely Coding Semantic Rank Orders For Supervised Image Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Discretely Coding Semantic Rank Orders For Supervised Image Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Discretely Coding Semantic Rank Orders For Supervised Image Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>49</td>
    <td><p>Learning to hash has been recognized to accomplish highly efficient storage and retrieval for large-scale visual data. Particularly, ranking-based hashing techniques have recently attracted broad research attention because ranking accuracy among the retrieved data is well explored and their objective is more applicable to realistic search tasks. However, directly optimizing discrete hash codes without continuous-relaxations on a nonlinear ranking objective is infeasible by either traditional optimization methods or even recent discrete hashing algorithms. To address this challenging issue, in this paper, we introduce a novel supervised hashing method, dubbed Discrete Semantic Ranking Hashing (DSeRH), which aims to directly embed semantic rank orders into binary codes. In DSeRH, a generalized Adaptive Discrete Minimization (ADM) approach is proposed to discretely optimize binary codes with the quadratic nonlinear ranking objective in an iterative manner and is guaranteed to converge quickly. Additionally, instead of using 0/1 independent labels to form rank orders as in previous works, we generate the listwise rank orders from the high-level semantic word embeddings which can quantitatively capture the intrinsic correlation between different categories. We evaluate our DSeRH, coupled with both linear and deep convolutional neural network (CNN) hash functions, on three image datasets, i.e., CIFAR-10, SUN397 and ImageNet100, and the results manifest that DSeRH can outperform the state-of-the-art ranking-based hashing methods.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        CVPR 
      
        Compact Codes 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/liu2025discrete/">Discrete Graph Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Discrete Graph Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Discrete Graph Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>496</td>
    <td><p>Hashing has emerged as a popular technique for fast nearest neighbor search in gigantic
databases. In particular, learning based hashing has received considerable
attention due to its appealing storage and search efficiency. However, the performance
of most unsupervised learning based hashing methods deteriorates rapidly
as the hash code length increases. We argue that the degraded performance is due
to inferior optimization procedures used to achieve discrete binary codes. This
paper presents a graph-based unsupervised hashing model to preserve the neighborhood
structure of massive data in a discrete code space. We cast the graph
hashing problem into a discrete optimization framework which directly learns the
binary codes. A tractable alternating maximization algorithm is then proposed to
explicitly deal with the discrete constraints, yielding high-quality codes to well
capture the local neighborhoods. Extensive experiments performed on four large
datasets with up to one million samples show that our discrete optimization based
graph hashing method obtains superior search accuracy over state-of-the-art unsupervised
hashing methods, especially for longer codes.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Graph Based ANN 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Alt 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/liu2025hash/">Hash Bit Selection: A Unified Solution For Selection Problems In Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hash Bit Selection: A Unified Solution For Selection Problems In Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hash Bit Selection: A Unified Solution For Selection Problems In Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2013 IEEE Conference on Computer Vision and Pattern Recognition</td>
    <td>91</td>
    <td><p>Hashing based methods recently have been shown promising for large-scale nearest neighbor search. However, good designs involve difficult decisions of many unknowns â€“ data features, hashing algorithms, parameter settings, kernels, etc. In this paper, we provide a unified solution as hash bit selection, i.e., selecting the most informative hash bits from a pool of candidates that may have been generated under various conditions mentioned above. We represent the candidate bit pool as a vertex- and edge-weighted graph with the pooled bits as vertices. Then we formulate the bit selection problem as quadratic programming over the graph, and solve it efficiently by replicator dynamics. Extensive experiments show that our bit selection approach can achieve superior performance over both naive selection methods and state-of-the-art methods under each scenario, usually with significant accuracy gains from 10% to 50% relatively.</p>
</td>
    <td>
      
        CVPR 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/liu2025collaborative/">Collaborative Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Collaborative Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Collaborative Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2014 IEEE Conference on Computer Vision and Pattern Recognition</td>
    <td>130</td>
    <td><p>Hashing technique has become a promising approach for
fast similarity search. Most of existing hashing research
pursue the binary codes for the same type of entities by
preserving their similarities. In practice, there are many
scenarios involving nearest neighbor search on the data
given in matrix form, where two different types of, yet
naturally associated entities respectively correspond to its
two dimensions or views. To fully explore the duality
between the two views, we propose a collaborative hashing
scheme for the data in matrix form to enable fast search
in various applications such as image search using bag of
words and recommendation using user-item ratings. By
simultaneously preserving both the entity similarities in
each view and the interrelationship between views, our
collaborative hashing effectively learns the compact binary
codes and the explicit hash functions for out-of-sample
extension in an alternating optimization way. Extensive
evaluations are conducted on three well-known datasets
for search inside a single view and search across different
views, demonstrating that our proposed method outperforms
state-of-the-art baselines, with significant accuracy
gains ranging from 7.67% to 45.87% relatively.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        CVPR 
      
        Compact Codes 
      
        Alt 
      
        Recommender Systems 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/liu2025hashing/">Hashing With Graphs</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hashing With Graphs' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hashing With Graphs' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>861</td>
    <td><p>Hashing is becoming increasingly popular for
efficient nearest neighbor search in massive
databases. However, learning short codes
that yield good search performance is still
a challenge. Moreover, in many cases realworld
data lives on a low-dimensional manifold,
which should be taken into account
to capture meaningful nearest neighbors. In
this paper, we propose a novel graph-based
hashing method which automatically discovers
the neighborhood structure inherent in
the data to learn appropriate compact codes.
To make such an approach computationally
feasible, we utilize Anchor Graphs to obtain
tractable low-rank adjacency matrices. Our
formulation allows constant time hashing of a
new data point by extrapolating graph Laplacian
eigenvectors to eigenfunctions. Finally,
we describe a hierarchical threshold learning
procedure in which each eigenfunction yields
multiple bits, leading to higher search accuracy.
Experimental comparison with the
other state-of-the-art methods on two large
datasets demonstrates the efficacy of the proposed
method.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Graph Based ANN 
      
        Compact Codes 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/liong2025deep/">Deep Variational And Structural Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Variational And Structural Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Variational And Structural Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liong et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Pattern Analysis and Machine Intelligence</td>
    <td>56</td>
    <td><p>In this paper, we propose a deep variational and structural hashing (DVStH) method to learn compact binary codes for multimedia retrieval. Unlike most existing deep hashing methods which use a series of convolution and fully-connected layers to learn binary features, we develop a probabilistic framework to infer latent feature representation inside the network. Then, we design a struct layer rather than a bottleneck hash layer, to obtain binary codes through a simple encoding procedure. By doing these, we are able to obtain binary codes discriminatively and generatively. To make it applicable to cross-modal scalable multimedia retrieval, we extend our method to a cross-modal deep variational and structural hashing (CM-DVStH). We design a deep fusion network with a struct layer to maximize the correlation between image-text input pairs during the training stage so that a unified binary vector can be obtained. We then design modality-specific hashing networks to handle the out-of-sample extension scenario. Specifically, we train a network for each modality which outputs a latent representation that is as close as possible to the binary codes which are inferred from the fusion network. Experimental results on five benchmark datasets are presented to show the efficacy of the proposed approach.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Neural Hashing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/liong2025cross/">Cross-modal Deep Variational Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Cross-modal Deep Variational Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Cross-modal Deep Variational Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liong et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 IEEE International Conference on Computer Vision (ICCV)</td>
    <td>98</td>
    <td><p>In this paper, we propose a cross-modal deep variational hashing (CMDVH) method for cross-modality multimedia retrieval. Unlike existing cross-modal hashing methods
which learn a single pair of projections to map each example as a binary vector, we design a couple of deep neural
network to learn non-linear transformations from imagetext input pairs, so that unified binary codes can be obtained. We then design the modality-specific neural networks in a probabilistic manner where we model a latent
variable as close as possible from the inferred binary codes,
which is approximated by a posterior distribution regularized by a known prior. Experimental results on three benchmark datasets show the efficacy of the proposed approach.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        ICCV 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/lin2025optimizing/">Optimizing Ranking Measures For Compact Binary Code Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Optimizing Ranking Measures For Compact Binary Code Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Optimizing Ranking Measures For Compact Binary Code Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lin Guosheng, Shen, Wu.</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>23</td>
    <td><p>Hashing has proven a valuable tool for large-scale information retrieval. Despite much success, existing hashing methods optimize over simple objectives such as the reconstruction error or graph Laplacian related loss functions, instead of the performance evaluation criteria of interestâ€”multivariate performance measures such as the AUC and NDCG. Here we present a general framework (termed StructHash) that allows one to directly optimize multivariate performance measures.
The resulting optimization problem can involve exponentially or infinitely many variables and constraints, which is more challenging than standard structured output learning. To solve the StructHash optimization problem, we use a combination of column generation and cutting-plane techniques. We demonstrate the generality of StructHash by applying it to ranking prediction and image retrieval, and show that it outperforms a few state-of-the-art hashing methods.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Compact Codes 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/lin2025fast/">Fast Supervised Hashing With Decision Trees For High-dimensional Data</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fast Supervised Hashing With Decision Trees For High-dimensional Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fast Supervised Hashing With Decision Trees For High-dimensional Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lin et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2014 IEEE Conference on Computer Vision and Pattern Recognition</td>
    <td>453</td>
    <td><p>Supervised hashing aims to map the original features to
compact binary codes that are able to preserve label based
similarity in the Hamming space. Non-linear hash functions
have demonstrated their advantage over linear ones due to
their powerful generalization capability. In the literature,
kernel functions are typically used to achieve non-linearity
in hashing, which achieve encouraging retrieval performance at the price of slow evaluation and training time.
Here we propose to use boosted decision trees for achieving
non-linearity in hashing, which are fast to train and evaluate, hence more suitable for hashing with high dimensional
data. In our approach, we first propose sub-modular formulations for the hashing binary code inference problem
and an efficient GraphCut based block search method for
solving large-scale inference.
Then we learn hash functions by training boosted decision trees to fit the binary
codes. Experiments demonstrate that our proposed method
significantly outperforms most state-of-the-art methods in
retrieval precision and training time. Especially for highdimensional data, our method is orders of magnitude faster
than many methods in terms of training time.</p>
</td>
    <td>
      
        CVPR 
      
        Compact Codes 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/lin2025deep/">Deep Learning Of Binary Hash Codes For Fast Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Learning Of Binary Hash Codes For Fast Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Learning Of Binary Hash Codes For Fast Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lin et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</td>
    <td>626</td>
    <td><p>Approximate nearest neighbor search is an efficient strategy for large-scale image retrieval. Encouraged by the recent advances in convolutional neural networks (CNNs), we propose an effective deep learning framework to generate binary hash codes for fast image retrieval. Our idea is that when the data labels are available, binary codes can be learned by employing a hidden layer for representing the latent concepts that dominate the class labels.
he utilization of the CNN also allows for learning image representations. Unlike other supervised methods that require pair-wised inputs for binary code learning, our method learns hash codes and image representations in a point-wised manner, making it suitable for large-scale datasets. Experimental results show that our method outperforms several state-of-the-art hashing algorithms on the CIFAR-10 and MNIST datasets. We further demonstrate its scalability and efficacy on a large-scale dataset of 1 million clothing images.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        CVPR 
      
        Compact Codes 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/lin2025general/">A General Two-step Approach To Learning-based Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A General Two-step Approach To Learning-based Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A General Two-step Approach To Learning-based Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lin et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2013 IEEE International Conference on Computer Vision</td>
    <td>199</td>
    <td><p>Most existing approaches to hashing apply a single form of hash function, and an optimization process which
is typically deeply coupled to this specific form. This tight coupling restricts the flexibility of the method to
respond to the data, and can result in complex optimization problems that are difficult to solve. Here we propose
a flexible yet simple framework that is able to accommodate different types of loss functions and hash functions.
This framework allows a number of existing approaches to hashing to be placed in context, and simplifies the
development of new problem-specific hashing methods. Our framework decomposes hashing learning problem
into two steps: hash bit learning and hash function learning based on the learned bits. The first step can typically
be formulated as binary quadratic problems, and the second step can be accomplished by training standard binary
classifiers. Both problems have been extensively studied in the literature. Our extensive experiments demonstrate
that the proposed framework is effective, flexible and outperforms the state-of-the-art.</p>
</td>
    <td>
      
        ICCV 
      
        Tools & Libraries 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/lin2025semantics/">Semantics-preserving Hashing For Cross-view Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Semantics-preserving Hashing For Cross-view Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Semantics-preserving Hashing For Cross-view Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lin Zijia, Ding, Wang</td> <!-- ðŸ”§ You were missing this -->
    <td>2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>540</td>
    <td><p>With benefits of low storage costs and high query speeds,
hashing methods are widely researched for efficiently retrieving large-scale data, which commonly contains multiple views, e.g. a news report with images, videos and texts.
In this paper, we study the problem of cross-view retrieval
and propose an effective Semantics-Preserving Hashing
method, termed SePH. Given semantic affinities of training data as supervised information, SePH transforms them
into a probability distribution and approximates it with tobe-learnt hash codes in Hamming space via minimizing the
Kullback-Leibler divergence. Then kernel logistic regression with a sampling strategy is utilized to learn the nonlinear projections from features in each view to the learnt
hash codes. And for any unseen instance, predicted hash
codes and their corresponding output probabilities from observed views are utilized to determine its unified hash code,
using a novel probabilistic approach. Extensive experiments conducted on three benchmark datasets well demonstrate the effectiveness and reasonableness of SePH.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        CVPR 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/li2025two/">Two Birds, One Stone: Jointly Learning Binary Code For Large-scale Face Image Retrieval And Attributes Prediction</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Two Birds, One Stone: Jointly Learning Binary Code For Large-scale Face Image Retrieval And Attributes Prediction' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Two Birds, One Stone: Jointly Learning Binary Code For Large-scale Face Image Retrieval And Attributes Prediction' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2015 IEEE International Conference on Computer Vision (ICCV)</td>
    <td>31</td>
    <td><p>We address the challenging large-scale content-based
face image retrieval problem, intended as searching images
based on the presence of specific subject, given one face
image of him/her. To this end, one natural demand is a supervised binary code learning method. While the learned
codes might be discriminating, people often have a further
expectation that whether some semantic message (e.g., visual attributes) can be read from the human-incomprehensible
codes. For this purpose, we propose a novel binary code
learning framework by jointly encoding identity discriminability and a number of facial attributes into unified binary code. In this way, the learned binary codes can be applied to not only fine-grained face image retrieval, but also
facial attributes prediction, which is the very innovation of
this work, just like killing two birds with one stone. To evaluate the effectiveness of the proposed method, extensive experiments are conducted on a new purified large-scale web
celebrity database, named CFW 60K, with abundant manual identity and attributes annotation, and experimental results exhibit the superiority of our method over state-of-the-art.</p>
</td>
    <td>
      
        ICCV 
      
        Compact Codes 
      
        Image Retrieval 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/li2025neighborhood/">Neighborhood Preserving Hashing For Scalable Video Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Neighborhood Preserving Hashing For Scalable Video Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Neighborhood Preserving Hashing For Scalable Video Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE/CVF International Conference on Computer Vision (ICCV)</td>
    <td>40</td>
    <td><p>In this paper, we propose a Neighborhood Preserving
Hashing (NPH) method for scalable video retrieval in an
unsupervised manner. Unlike most existing deep video
hashing methods which indiscriminately compress an entire video into a binary code, we embed the spatial-temporal
neighborhood information into the encoding network such
that the neighborhood-relevant visual content of a video can
be preferentially encoded into a binary code under the guidance of the neighborhood information. Specifically, we propose a neighborhood attention mechanism which focuses
on partial useful content of each input frame conditioned
on the neighborhood information. We then integrate the
neighborhood attention mechanism into an RNN-based reconstruction scheme to encourage the binary codes to capture the spatial-temporal structure in a video which is consistent with that in the neighborhood. As a consequence, the
learned hashing functions can map similar videos to similar
binary codes. Extensive experiments on three widely-used
benchmark datasets validate the effectiveness of our proposed approach.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        ICCV 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/li2025learning/">Learning Hash Functions Using Column Generation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning Hash Functions Using Column Generation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning Hash Functions Using Column Generation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>93</td>
    <td><p>Fast nearest neighbor searching is becoming
an increasingly important tool in solving
many large-scale problems. Recently
a number of approaches to learning datadependent
hash functions have been developed.
In this work, we propose a column
generation based method for learning datadependent
hash functions on the basis of
proximity comparison information. Given a
set of triplets that encode the pairwise proximity
comparison information, our method
learns hash functions that preserve the relative
comparison relationships in the data
as well as possible within the large-margin
learning framework. The learning procedure
is implemented using column generation and
hence is named CGHash. At each iteration
of the column generation procedure, the best
hash function is selected. Unlike most other
hashing methods, our method generalizes to
new data points naturally; and has a training
objective which is convex, thus ensuring
that the global optimum can be identi-
fied. Experiments demonstrate that the proposed
method learns compact binary codes
and that its retrieval performance compares
favorably with state-of-the-art methods when
tested on a few benchmark datasets.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/li2025self/">Self-supervised Video Hashing Via Bidirectional Transformers</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Self-supervised Video Hashing Via Bidirectional Transformers' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Self-supervised Video Hashing Via Bidirectional Transformers' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>38</td>
    <td><p>Most existing unsupervised video hashing methods are built on unidirectional models with less reliable training objectives, which underuse the correlations among frames and the similarity structure between videos. To enable efficient scalable video retrieval, we propose a self-supervised video Hashing method based on Bidirectional Transformers (BTH). Based on the encoder-decoder structure of transformers, we design a visual cloze task to fully exploit the bidirectional correlations between frames. To unveil the similarity structure between unlabeled video data, we further develop a similarity reconstruction task by establishing reliable and effective similarity connections in the video space. Furthermore, we develop a cluster assignment task to exploit the structural statistics of the whole dataset such that more discriminative binary codes can be learned. Extensive experiments implemented on three public benchmark datasets, FCVID, ActivityNet and YFCC, demonstrate the superiority of our proposed approach.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        CVPR 
      
        Compact Codes 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/li2025very/">Very Sparse Random Projections</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Very Sparse Random Projections' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Very Sparse Random Projections' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li Ping, Hastie, Church</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining</td>
    <td>632</td>
    <td><p>There has been considerable interest in random projections, an approximate algorithm for estimating distances between pairs of points in a high-dimensional vector space. Let A in Rn x D be our n points in D dimensions. The method multiplies A by a random matrix R in RD x k, reducing the D dimensions down to just k for speeding up the computation. R typically consists of entries of standard normal N(0,1). It is well known that random projections preserve pairwise distances (in the expectation). Achlioptas proposed sparse random projections by replacing the N(0,1) entries in R with entries in -1,0,1 with probabilities 1/6, 2/3, 1/6, achieving a threefold speedup in processing time.We recommend using R of entries in -1,0,1 with probabilities 1/2âˆšD, 1-1âˆšD, 1/2âˆšD for achieving a significant âˆšD-fold speedup, with little loss in accuracy.</p>
</td>
    <td>
      
        KDD 
      
        Locality Sensitive Hashing 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/li20250/">0-bit Consistent Weighted Sampling</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=0-bit Consistent Weighted Sampling' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=0-bit Consistent Weighted Sampling' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li P.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</td>
    <td>58</td>
    <td><p>We develop 0-bit consistent weighted sampling (CWS) for efficiently estimating min-max kernel, which is a generalization of the resemblance kernel originally designed for binary data. Because the estimator of 0-bit CWS constitutes a positive definite kernel, this method can be naturally applied to large-scale data mining problems. Basically, if we feed the sampled data from 0-bit CWS to a highly efficient linear classifier (e.g., linear SVM), we effectively (and approximately) train a nonlinear classifier based on the min-max kernel. The accuracy improves as we increase the sample size.</p>

<p>In this paper, we first demonstrate, through an extensive classification study using kernel machines, that the min-max kernel often provides an effective measure of similarity for nonnegative data. This helps justify the use of min-max kernel. However, as the min-max kernel is nonlinear and might be difficult to be used for industrial applications with massive data, we propose to linearize the min-max kernel via 0-bit CWS, a simplification of the original CWS method.</p>

<p>The previous remarkable work on consistent weighted sampling (CWS) produces samples in the form of (i<em>, t</em>) where the i* records the location (and in fact also the weights) information analogous to the samples produced by classical minwise hashing on binary data. Because the t* is theoretically unbounded, it was not immediately clear how to effectively implement CWS for building large-scale linear classifiers. We provide a simple solution by discarding t* (which we refer to as the â€œ0-bitâ€ scheme). Via an extensive empirical study, we show that this 0-bit scheme does not lose essential information. We then apply 0-bit CWS for building linear classifiers to approximate min-max kernel classifiers, as extensively validated on a wide range of public datasets.</p>

<p>We expect this work will generate interests among data mining practitioners who would like to efficiently utilize the nonlinear information of non-binary and nonnegative data.</p>
</td>
    <td>
      
        KDD 
      
        DATASETS 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/li2025clean/">Clean Image May Be Dangerous: Data Poisoning Attacks Against Deep Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Clean Image May Be Dangerous: Data Poisoning Attacks Against Deep Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Clean Image May Be Dangerous: Data Poisoning Attacks Against Deep Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>61</td>
    <td><p>Large-scale image retrieval using deep hashing has become increasingly
popular due to the exponential growth of image data and the remarkable feature
extraction capabilities of deep neural networks (DNNs). However, deep hashing
methods are vulnerable to malicious attacks, including adversarial and backdoor
attacks. It is worth noting that these attacks typically involve altering the
query images, which is not a practical concern in real-world scenarios. In this
paper, we point out that even clean query images can be dangerous, inducing
malicious target retrieval results, like undesired or illegal images. To the
best of our knowledge, we are the first to study data \textbf{p}oisoning
\textbf{a}ttacks against \textbf{d}eep \textbf{hash}ing
\textbf{(\textit{PADHASH})}. Specifically, we first train a surrogate model to
simulate the behavior of the target deep hashing model. Then, a strict gradient
matching strategy is proposed to generate the poisoned images. Extensive
experiments on different models, datasets, hash methods, and hash code lengths
demonstrate the effectiveness and generality of our attack method.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Alt 
      
        Neural Hashing 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/li2025feature/">Feature Learning Based Deep Supervised Hashing With Pairwise Labels</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Feature Learning Based Deep Supervised Hashing With Pairwise Labels' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Feature Learning Based Deep Supervised Hashing With Pairwise Labels' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li Wu-jun, Kang</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>509</td>
    <td><p>Recent years have witnessed wide application of
hashing for large-scale image retrieval. However,
most existing hashing methods are based on handcrafted features which might not be optimally compatible with the hashing procedure. Recently, deep
hashing methods have been proposed to perform simultaneous feature learning and hash-code learning with deep neural networks, which have shown
better performance than traditional hashing methods with hand-crafted features. Most of these deep
hashing methods are supervised whose supervised
information is given with triplet labels. For another common application scenario with pairwise labels, there have not existed methods for simultaneous feature learning and hash-code learning. In this
paper, we propose a novel deep hashing method,
called deep pairwise-supervised hashing (DPSH),
to perform simultaneous feature learning and hashcode learning for applications with pairwise labels.
Experiments on real datasets show that our DPSH
method can outperform other methods to achieve
the state-of-the-art performance in image retrieval
applications.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Neural Hashing 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/leng2025hashing/">Hashing For Distributed Data</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hashing For Distributed Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hashing For Distributed Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Leng et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>30</td>
    <td><p>Recently, hashing based approximate nearest
neighbors search has attracted much attention.
Extensive centralized hashing algorithms have
been proposed and achieved promising performance. However, due to the large scale of many
applications, the data is often stored or even collected in a distributed manner. Learning hash
functions by aggregating all the data into a fusion
center is infeasible because of the prohibitively
expensive communication and computation overhead.
In this paper, we develop a novel hashing
model to learn hash functions in a distributed setting. We cast a centralized hashing model as a
set of subproblems with consensus constraints.
We find these subproblems can be analytically
solved in parallel on the distributed compute nodes. Since no training data is transmitted across
the nodes in the learning process, the communication cost of our model is independent to the data size. Extensive experiments on several large
scale datasets containing up to 100 million samples demonstrate the efficacy of our method.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/lehmann2025combined/">Combined Search And Encoding For Seeds, With An Application To Minimal Perfect Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Combined Search And Encoding For Seeds, With An Application To Minimal Perfect Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Combined Search And Encoding For Seeds, With An Application To Minimal Perfect Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lehmann et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE GLOBECOM 2008 - 2008 IEEE Global Telecommunications Conference</td>
    <td>5</td>
    <td><p>Randomised algorithms often employ methods that can fail and that are retried with independent randomness until they succeed. Randomised data structures therefore often store indices of successful attempts, called seeds. If \(n\) such seeds are required (e.g., for independent substructures) the standard approach is to compute for each \(i \in [n]\) the smallest successful seed \(S_i\) and store \(\vec{S} = (S_1, \ldots, S_n)\).
  The central observation of this paper is that this is not space-optimal. We present a different algorithm that computes a sequence \(\vec{S}â€™ = (S_1â€™, \ldots, S_nâ€™)\) of successful seeds such that the entropy of \(\vec{Sâ€™}\) undercuts the entropy of \(\vec{S}\) by \(Î©(n)\) bits in most cases. To achieve a memory consumption of \(\mathrm{OPT}+\epsilon n\), the expected number of inspected seeds increases by a factor of \(O(1/\epsilon)\).
  We demonstrate the usefulness of our findings with a novel construction for minimal perfect hash functions that, for \(n\) keys and any \(\epsilon \in [n^{-3/7}, 1]\), has space requirement \((1+\epsilon)\mathrm{OPT}\) and construction time \(O(n/\epsilon)\). All previous approaches only support \(\epsilon = \omega(1 / log n)\) or have construction times that increase exponentially with \(1/\epsilon\). Our implementation beats the construction throughput of the state of the art by more than two orders of magnitude for \(\epsilon \leq 3%\).</p>
</td>
    <td>
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/lai2025simultaneous/">Simultaneous Feature Learning And Hash Coding With Deep Neural Networks</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Simultaneous Feature Learning And Hash Coding With Deep Neural Networks' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Simultaneous Feature Learning And Hash Coding With Deep Neural Networks' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lai et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>916</td>
    <td><p>Similarity-preserving hashing is a widely-used method
for nearest neighbour search in large-scale image retrieval
tasks. For most existing hashing methods, an image is
first encoded as a vector of hand-engineering visual features,
followed by another separate projection or quantization
step that generates binary codes. However, such visual
feature vectors may not be optimally compatible with the
coding process, thus producing sub-optimal hashing codes.
In this paper, we propose a deep architecture for supervised
hashing, in which images are mapped into binary codes via
carefully designed deep neural networks. The pipeline of
the proposed deep architecture consists of three building
blocks: 1) a sub-network with a stack of convolution layers
to produce the effective intermediate image features; 2)
a divide-and-encode module to divide the intermediate image
features into multiple branches, each encoded into one
hash bit; and 3) a triplet ranking loss designed to characterize
that one image is more similar to the second image than
to the third one. Extensive evaluations on several benchmark
image datasets show that the proposed simultaneous
feature learning and hash coding pipeline brings substantial
improvements over other state-of-the-art supervised or
unsupervised hashing methods.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        CVPR 
      
        Compact Codes 
      
        Similarity Search 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/lehmann2025modern/">Modern Minimal Perfect Hashing: A Survey</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Modern Minimal Perfect Hashing: A Survey' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Modern Minimal Perfect Hashing: A Survey' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lehmann et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE GLOBECOM 2008 - 2008 IEEE Global Telecommunications Conference</td>
    <td>5</td>
    <td><p>Given a set \(S\) of \(n\) keys, a perfect hash function for \(S\) maps the keys in \(S\) to the first \(m \geq n\) integers without collisions. It may return an arbitrary result for any key not in \(S\) and is called minimal if \(m = n\). The most important parameters are its space consumption, construction time, and query time. Years of research now enable modern perfect hash functions to be extremely fast to query, very space-efficient, and scale to billions of keys. Different approaches give different trade-offs between these aspects. For example, the smallest constructions get within 0.1% of the space lower bound of \(log_2(e)\) bits per key. Others are particularly fast to query, requiring only one memory access. Perfect hashing has many applications, for example to avoid collision resolution in static hash tables, and is used in databases, bioinformatics, and stringology.
  Since the last comprehensive survey in 1997, significant progress has been made. This survey covers the latest developments and provides a starting point for getting familiar with the topic. Additionally, our extensive experimental evaluation can serve as a guide to select a perfect hash function for use in applications.</p>
</td>
    <td>
      
        Survey Paper 
      
        Hashing Methods 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/kumar2025learning/">Learning Hash Functions For Cross-view Similarity Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning Hash Functions For Cross-view Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning Hash Functions For Cross-view Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Kumar S., Udupa</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>438</td>
    <td><p>Many applications in Multilingual and Multimodal
Information Access involve searching large
databases of high dimensional data objects with
multiple (conditionally independent) views. In this
work we consider the problem of learning hash
functions for similarity search across the views
for such applications. We propose a principled
method for learning a hash function for each view
given a set of multiview training data objects. The
hash functions map similar objects to similar codes
across the views thus enabling cross-view similarity
search. We present results from an extensive
empirical study of the proposed approach
which demonstrate its effectiveness on Japanese
language People Search and Multilingual People
Search problems.</p>
</td>
    <td>
      
        Similarity Search 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/kwok2025learning/">Learning To Hash With A Dimension Analysis-based Quantizer For Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning To Hash With A Dimension Analysis-based Quantizer For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning To Hash With A Dimension Analysis-based Quantizer For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Kwok Yuan</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Multimedia</td>
    <td>10</td>
    <td><p>The last few years have witnessed the rise of the big data era in which approximate nearest neighbor search is a fundamental problem in many applications, such as large-scale image retrieval. Recently, many research results have demonstrated that hashing can achieve promising performance due to its appealing storage and search efficiency. Since complex optimization problems for loss functions are difficult to solve, most hashing methods decompose the hash code learning problem into two steps: projection and quantization. In the quantization step, binary codes are widely used because ranking them by the Hamming distance is very efficient. However, the massive information loss produced by the quantization step should be reduced in applications where high search accuracy is required, such as in image retrieval. Since many two-step hashing methods produce uneven projected dimensions in the projection step, in this paper, we propose a novel dimension analysis-based quantization (DAQ) on two-step hashing methods for image retrieval. We first perform an importance analysis of the projected dimensions and select a subset of them that are more informative than others, and then we divide the selected projected dimensions into several regions with our quantizer. Every region is quantized with its corresponding codebook. Finally, the similarity between two hash codes is estimated by the Manhattan distance between their corresponding codebooks, which is also efficient. We conduct experiments on three public benchmarks containing up to one million descriptors and show that the proposed DAQ method consistently leads to significant accuracy improvements over state-of-the-art quantization methods.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/kulis2025kernelized/">Kernelized Locality-sensitive Hashing For Scalable Image Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Kernelized Locality-sensitive Hashing For Scalable Image Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Kernelized Locality-sensitive Hashing For Scalable Image Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Kulis B., Grauman</td> <!-- ðŸ”§ You were missing this -->
    <td>2009 IEEE 12th International Conference on Computer Vision</td>
    <td>907</td>
    <td><p>Fast retrieval methods are critical for large-scale and
data-driven vision applications. Recent work has explored
ways to embed high-dimensional features or complex distance
functions into a low-dimensional Hamming space
where items can be efficiently searched. However, existing
methods do not apply for high-dimensional kernelized
data when the underlying feature embedding for the kernel
is unknown. We show how to generalize locality-sensitive
hashing to accommodate arbitrary kernel functions, making
it possible to preserve the algorithmâ€™s sub-linear time similarity
search guarantees for a wide class of useful similarity
functions. Since a number of successful image-based kernels
have unknown or incomputable embeddings, this is especially
valuable for image retrieval tasks. We validate our
technique on several large-scale datasets, and show that it
enables accurate and fast performance for example-based
object classification, feature matching, and content-based
retrieval.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        ICCV 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/krauthgamer2025power/">The Power Of Recursive Embeddings For \(\ell_p\) Metrics</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=The Power Of Recursive Embeddings For \(\ell_p\) Metrics' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=The Power Of Recursive Embeddings For \(\ell_p\) Metrics' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Krauthgamer Robert, Petruschka Nir, Sapir Shay</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the American Mathematical Society</td>
    <td>7</td>
    <td><p>Metric embedding is a powerful tool used extensively in mathematics and
computer science. We devise a new method of using metric embeddings
recursively, which turns out to be particularly effective in \(\ell_p\) spaces,
\(p&gt;2\), yielding state-of-the-art results for Lipschitz decomposition, for
Nearest Neighbor Search, and for embedding into \(â„“â‚‚\). In a nutshell, our
method composes metric embeddings by viewing them as reductions between
problems, and thereby obtains a new reduction that is substantially more
effective than the known reduction that employs a single embedding. We in fact
apply this method recursively, oftentimes using double recursion, which further
amplifies the gap from a single embedding.</p>
</td>
    <td>
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/kulis2025learning/">Learning To Hash With Binary Reconstructive Embeddings</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning To Hash With Binary Reconstructive Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning To Hash With Binary Reconstructive Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Kulis B., Darrell</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>841</td>
    <td><p>Fast retrieval methods are increasingly critical for many large-scale analysis tasks, and there have been
several recent methods that attempt to learn hash functions for fast and accurate nearest neighbor searches.
In this paper, we develop an algorithm for learning hash functions based on explicitly minimizing the
reconstruction error between the original distances and the Hamming distances of the corresponding binary
embeddings. We develop a scalable coordinate-descent algorithm for our proposed hashing objective that
is able to efficiently learn hash functions in a variety of settings. Unlike existing methods such as semantic
hashing and spectral hashing, our method is easily kernelized and does not require restrictive assumptions
about the underlying distribution of the data. We present results over several domains to demonstrate that
our method outperforms existing state-of-the-art techniques.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/kong2025isotropic/">Isotropic Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Isotropic Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Isotropic Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Kong W., Li</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>260</td>
    <td><p>Most existing hashing methods adopt some projection functions to project the original data into several dimensions of real values, and then each of these projected dimensions is quantized into one bit (zero or one) by thresholding. Typically, the variances of different projected dimensions are different for existing projection functions such as principal component analysis (PCA). Using the same number of bits for different projected dimensions is unreasonable because larger-variance dimensions will carry more information. Although this viewpoint has been widely accepted by many researchers, it is still not verified by either theory or experiment because no methods have been proposed to find a projection with equal variances for different dimensions. In this paper, we propose a novel method, called isotropic hashing (IsoHash), to learn projection functions which can produce projected dimensions with isotropic variances (equal variances). Experimental results on real data sets show that IsoHash can outperform its counterpart with different variances for different dimensions, which verifies the viewpoint that projections with isotropic variances will be better than those with anisotropic variances.</p>
</td>
    <td>
      
        Alt 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/kong2025manhattan/">Manhattan Hashing For Large-scale Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Manhattan Hashing For Large-scale Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Manhattan Hashing For Large-scale Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Kong W., Li, Guo</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval</td>
    <td>105</td>
    <td><p>Hashing is used to learn binary-code representation for data with
expectation of preserving the neighborhood structure in the original
feature space. Due to its fast query speed and reduced storage
cost, hashing has been widely used for efficient nearest neighbor
search in a large variety of applications like text and image retrieval.
Most existing hashing methods adopt Hamming distance to
measure the similarity (neighborhood) between points in the hashcode
space. However, one problem with Hamming distance is that
it may destroy the neighborhood structure in the original feature
space, which violates the essential goal of hashing. In this paper,
Manhattan hashing (MH), which is based on Manhattan distance, is
proposed to solve the problem of Hamming distance based hashing.
The basic idea of MH is to encode each projected dimension with
multiple bits of natural binary code (NBC), based on which the
Manhattan distance between points in the hashcode space is calculated
for nearest neighbor search. MH can effectively preserve the
neighborhood structure in the data to achieve the goal of hashing.
To the best of our knowledge, this is the first work to adopt Manhattan
distance with NBC for hashing. Experiments on several largescale
image data sets containing up to one million points show that
our MH method can significantly outperform other state-of-the-art
methods.</p>
</td>
    <td>
      
        Compact Codes 
      
        Image Retrieval 
      
        SIGIR 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/kim2025rt/">RT-HDIST: Ray-tracing Core-based Hausdorff Distance Computation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=RT-HDIST: Ray-tracing Core-based Hausdorff Distance Computation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=RT-HDIST: Ray-tracing Core-based Hausdorff Distance Computation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Kim Youngwoo, Lee Jaehong, Kim Duksu</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Access</td>
    <td>10</td>
    <td><p>The Hausdorff distance is a fundamental metric with widespread applications
across various fields. However, its computation remains computationally
expensive, especially for large-scale datasets. In this work, we present
RT-HDIST, the first Hausdorff distance algorithm accelerated by ray-tracing
cores (RT-cores). By reformulating the Hausdorff distance problem as a series
of nearest-neighbor searches and introducing a novel quantized index space,
RT-HDIST achieves significant reductions in computational overhead while
maintaining exact results. Extensive benchmarks demonstrate up to a
two-order-of-magnitude speedup over prior state-of-the-art methods,
underscoring RT-HDISTâ€™s potential for real-time and large-scale applications.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/koerkamp2025ptrhash/">Ptrhash: Minimal Perfect Hashing At RAM Throughput</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Ptrhash: Minimal Perfect Hashing At RAM Throughput' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Ptrhash: Minimal Perfect Hashing At RAM Throughput' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Koerkamp Ragnar Groot</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE GLOBECOM 2008 - 2008 IEEE Global Telecommunications Conference</td>
    <td>5</td>
    <td><p>Given a set \(K\) of \(n\) keys, a minimal perfect hash function (MPHF) is a collision-free bijective map \(\mathsf{H_{mphf}}\) from \(K\) to \(\{0, \dots, n-1\}\). This work presents a (minimal) perfect hash function that first prioritizes query throughput, while also allowing efficient construction for \(10^9\) or more elements using 2.4 bits of memory per key.
  Both PTHash and PHOBIC first map all \(n\) keys to \(n/\lambda &lt; n\) buckets. Then, each bucket stores a pilot that controls the final hash value of the keys mapping to it. PtrHash builds on this by using 1) fixed-width (uncompressed) 8-bit pilots, 2) a construction algorithm similar to cuckoo-hashing to find suitable pilot values. Further, it 3) uses the same number of buckets and slots for each part, with 4) a single remap table to map intermediate positions \(\geq n\) to \(&lt;n\), 5) encoded using per-cacheline Elias-Fano coding. Lastly, 6) PtrHash support streaming queries, where we use prefetching to answer a stream of multiple queries more efficiently than one-by-one processing.
  With default parameters, PtrHash takes 2.0 bits per key. On 300 million string keys, PtrHash is as fast or faster to build than other MPHFs, and at least \(2.1\times\) faster to query. When streaming multiple queries, this improves to \(3.3\times\) speedup over the fastest alternative, while also being significantly faster to construct. When using \(10^9\) integer keys instead, query times are as low as 12 ns/key when iterating in a for loop, or even down to 8 ns/key when using the streaming approach, just short of the 7.4 ns inverse throughput of random memory accesses.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Graph Based ANN 
      
        Efficiency And Optimization 
      
        Alt 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/kang2025column/">Column Sampling Based Discrete Supervised Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Column Sampling Based Discrete Supervised Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Column Sampling Based Discrete Supervised Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Kang Wang-cheng, Li, Zhou</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>299</td>
    <td><p>By leveraging semantic (label) information, supervised hashing has demonstrated better accuracy than unsupervised hashing in many real applications. Because the hashing-code learning problem is essentially a discrete optimization problem which is hard to solve, most existing supervised hashing methods try to solve a relaxed continuous optimization problem by dropping the discrete constraints.
However, these methods typically suffer from poor performance due to the errors caused by the relaxation. Some other methods try to directly solve the discrete optimization problem. However, they are typically time-consuming and unscalable. In this paper, we propose a novel method, called column sampling based discrete supervised hashing (COSDISH), to directly learn the discrete hashing code from semantic information.
COSDISH is an iterative method, in each iteration of which several columns are sampled from the semantic similarity matrix and then the hashing code is decomposed into two parts which can be alternately optimized in a discrete way. Theoretical analysis shows that the learning (optimization) algorithm of COSDISH has a constant-approximation bound in each step of the alternating optimization procedure. Empirical results on datasets with semantic labels illustrate that COSDISH can outperform the state-of-the-art methods in real applications like image retrieval.</p>
</td>
    <td>
      
        Image Retrieval 
      
        AAAI 
      
        DATASETS 
      
        Hashing Methods 
      
        Alt 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/j%C3%A4%C3%A4saari2025vibe/">VIBE: Vector Index Benchmark For Embeddings</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=VIBE: Vector Index Benchmark For Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=VIBE: Vector Index Benchmark For Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>JÃ¤Ã¤saari et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2023 International Workshop on Artificial Intelligence and Image Processing (IWAIIP)</td>
    <td>6</td>
    <td><p>Approximate nearest neighbor (ANN) search is a performance-critical component of many machine learning pipelines. Rigorous benchmarking is essential for evaluating the performance of vector indexes for ANN search. However, the datasets of the existing benchmarks are no longer representative of the current applications of ANN search. Hence, there is an urgent need for an up-to-date set of benchmarks. To this end, we introduce Vector Index Benchmark for Embeddings (VIBE), an open source project for benchmarking ANN algorithms. VIBE contains a pipeline for creating benchmark datasets using dense embedding models characteristic of modern applications, such as retrieval-augmented generation (RAG). To replicate real-world workloads, we also include out-of-distribution (OOD) datasets where the queries and the corpus are drawn from different distributions. We use VIBE to conduct a comprehensive evaluation of SOTA vector indexes, benchmarking 21 implementations on 12 in-distribution and 6 out-of-distribution datasets.</p>
</td>
    <td>
      
        Vector Indexing 
      
        Similarity Search 
      
        Evaluation 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/kang2025maximum/">Maximum-margin Hamming Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Maximum-margin Hamming Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Maximum-margin Hamming Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Kang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE/CVF International Conference on Computer Vision (ICCV)</td>
    <td>37</td>
    <td><p>Deep hashing enables computation and memory efficient
image search through end-to-end learning of feature representations and binary codes. While linear scan over binary
hash codes is more efficient than over the high-dimensional
representations, its linear-time complexity is still unacceptable for very large databases. Hamming space retrieval enables constant-time search through hash lookups, where for
each query, there is a Hamming ball centered at the query
and the data points within the ball are returned as relevant.
Since inside the Hamming ball implies retrievable while
outside irretrievable, it is crucial to explicitly characterize
the Hamming ball. The main idea of this work is to directly
embody the Hamming radius into the loss functions, leading
to Maximum-Margin Hamming Hashing (MMHH), a new
model specifically optimized for Hamming space retrieval.
We introduce a max-margin t-distribution loss, where the
t-distribution concentrates more similar data points to be
within the Hamming ball, and the margin characterizes the
Hamming radius such that less penalization is applied to
similar data points within the Hamming ball. The loss function also introduces robustness to data noise, where the similarity supervision may be inaccurate in practical problems.
The model is trained end-to-end using a new semi-batch optimization algorithm tailored to extremely imbalanced data.
Our method yields state-of-the-art results on four datasets
and shows superior performance on noisy data.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Neural Hashing 
      
        ICCV 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/joly2025random/">Random Maximum Margin Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Random Maximum Margin Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Random Maximum Margin Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Joly A., Buisson</td> <!-- ðŸ”§ You were missing this -->
    <td>CVPR 2011</td>
    <td>150</td>
    <td><p>Following the success of hashing methods for multidimensional
indexing, more and more works are interested
in embedding visual feature space in compact hash codes.
Such approaches are not an alternative to using index structures
but a complementary way to reduce both the memory
usage and the distance computation cost. Several data
dependent hash functions have notably been proposed to
closely fit data distribution and provide better selectivity
than usual random projections such as LSH. However, improvements
occur only for relatively small hash code sizes
up to 64 or 128 bits. As discussed in the paper, this is mainly
due to the lack of independence between the produced hash
functions. We introduce a new hash function family that
attempts to solve this issue in any kernel space. Rather
than boosting the collision probability of close points, our
method focus on data scattering. By training purely random
splits of the data, regardless the closeness of the training
samples, it is indeed possible to generate consistently
more independent hash functions. On the other side, the
use of large margin classifiers allows to maintain good generalization
performances. Experiments show that our new
Random Maximum Margin Hashing scheme (RMMH) outperforms
four state-of-the-art hashing methods, notably in
kernel spaces.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        CVPR 
      
        Alt 
      
        Vector Indexing 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/jin2025deep/">Deep Saliency Hashing For Fine-grained Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Saliency Hashing For Fine-grained Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Saliency Hashing For Fine-grained Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jin et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Image Processing</td>
    <td>57</td>
    <td><p>In recent years, hashing methods have been proved to be
effective and efficient for the large-scale Web media search.
However, the existing general hashing methods have limited discriminative power for describing fine-grained objects that share similar overall appearance but have subtle
difference. To solve this problem, we for the first time introduce the attention mechanism to the learning of fine-grained
hashing codes. Specifically, we propose a novel deep hashing model, named deep saliency hashing (DSaH), which
automatically mines salient regions and learns semanticpreserving hashing codes simultaneously. DSaH is a twostep end-to-end model consisting of an attention network
and a hashing network. Our loss function contains three
basic components, including the semantic loss, the saliency
loss, and the quantization loss. As the core of DSaH, the
saliency loss guides the attention network to mine discriminative regions from pairs of images. We conduct extensive experiments on both fine-grained and general retrieval
datasets for performance evaluation. Experimental results
on fine grained dataset, including Oxford Flowers-17, Stanford Dogs-120 and CUB Bird demonstrate that our DSaH
performs the best for fine-grained retrieval task and beats
strongest competitor (DTQ) by approximately 10% on both
Stanford Dogs-120 and CUB Bird. DSaH is also comparable to several state-of-the-art hashing methods on general
datasets, including CIFAR-10 and NUS-WIDE.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Neural Hashing 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/jin2025complementary/">Complementary Projection Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Complementary Projection Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Complementary Projection Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jin et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2013 IEEE International Conference on Computer Vision</td>
    <td>59</td>
    <td><p>Recently, hashing techniques have been widely applied
to solve the approximate nearest neighbors search problem
in many vision applications. Generally, these hashing
approaches generate 2^c buckets, where c is the length
of the hash code. A good hashing method should satisfy
the following two requirements: 1) mapping the nearby
data points into the same bucket or nearby (measured by
the Hamming distance) buckets. 2) all the data points are
evenly distributed among all the buckets. In this paper,
we propose a novel algorithm named Complementary Projection
Hashing (CPH) to find the optimal hashing functions
which explicitly considers the above two requirements.
Specifically, CPH aims at sequentially finding a series of hyperplanes
(hashing functions) which cross the sparse region
of the data. At the same time, the data points are evenly distributed
in the hypercubes generated by these hyperplanes.
The experiments comparing with the state-of-the-art hashing
methods demonstrate the effectiveness of the proposed
method.</p>
</td>
    <td>
      
        ICCV 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/jin2025unsupervised/">Unsupervised Discrete Hashing With Affinity Similarity</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Unsupervised Discrete Hashing With Affinity Similarity' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Unsupervised Discrete Hashing With Affinity Similarity' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jin et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Image Processing</td>
    <td>14</td>
    <td><p>In recent years, supervised hashing has been validated to greatly boost the performance of image retrieval. However, the label-hungry property requires massive label collection, making it intractable in practical scenarios. To liberate the model training procedure from laborious manual annotations, some unsupervised methods are proposed. However, the following two factors make unsupervised algorithms inferior to their supervised counterparts: (1) Without manually-defined labels, it is difficult to capture the semantic information across data, which is of crucial importance to guide robust binary code learning. (2) The widely adopted relaxation on binary constraints results in quantization error accumulation in the optimization procedure. To address the above-mentioned problems, in this paper, we propose a novel Unsupervised Discrete Hashing method (UDH). Specifically, to capture the semantic information, we propose a balanced graph-based semantic loss which explores the affinity priors in the original feature space. Then, we propose a novel self-supervised loss, termed orthogonal consistent loss, which can leverage semantic loss of instance and impose independence of codes. Moreover, by integrating the discrete optimization into the proposed unsupervised framework, the binary constraints are consistently preserved, alleviating the influence of quantization errors. Extensive experiments demonstrate that UDH outperforms state-of-the-art unsupervised methods for image retrieval.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Graph Based ANN 
      
        Compact Codes 
      
        Quantization 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/jegou2025searching/">Searching With Quantization: Approximate Nearest Neighbor Search Using Short Codes And Distance Estimators</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Searching With Quantization: Approximate Nearest Neighbor Search Using Short Codes And Distance Estimators' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Searching With Quantization: Approximate Nearest Neighbor Search Using Short Codes And Distance Estimators' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jegou H., Douze, Schmid</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>17</td>
    <td><p>We propose an approximate nearest neighbor search method based
on quantization. It uses, in particular, product quantizer to produce short codes
and corresponding distance estimators approximating the Euclidean distance
between the orginal vectors. The method is advantageously used in an asymmetric
manner, by computing the distance between a vector and code, unlike
competing techniques such as spectral hashing that only compare codes.
Our approach approximates the Euclidean distance based on memory efficient codes and, thus, permits efficient nearest neighbor search. Experiments
performed on SIFT and GIST image descriptors show excellent search accuracy.
The method is shown to outperform two state-of-the-art approaches of the literature.
Timings measured when searching a vector set of 2 billion vectors are
shown to be excellent given the high accuracy of the method.</p>
</td>
    <td>
      
        Compact Codes 
      
        Hashing Methods 
      
        Quantization 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/jain2025hashing/">Hashing Hyperplane Queries To Near Points With Applications To Large-scale Active Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hashing Hyperplane Queries To Near Points With Applications To Large-scale Active Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hashing Hyperplane Queries To Near Points With Applications To Large-scale Active Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jain P., Vijayanarasimhan, Grauman</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>69</td>
    <td><p>We consider the problem of retrieving the database points nearest to a given hyperplane query without exhaustively scanning the 
database. We propose two hashing-based solutions. Our first approach maps the data to two-bit binary keys that are locality-sensitive for the angle between the hyperplane normal and a database point. Our second approach embeds the data into a vector space where the Euclidean norm reflects the desired distance between the original points and hyperplane query. Both use hashing to retrieve near points in sub-linear time. Our first methodâ€™s preprocessing stage is more efficient, while the second has stronger accuracy guarantees. We apply both to pool-based active learning: taking the current hyperplane classifier as a query, our algorithm identifies those points (approximately) satisfying the well-known minimal distance-to-hyperplane selection criterion. We empirically demonstrate our methodsâ€™ tradeoffs, and show that they make it practical to perform active selection with millions 
of unlabeled points.</p>
</td>
    <td>
      
        Tools & Libraries 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/jain2025fast/">Fast Similarity Search For Learned Metrics</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fast Similarity Search For Learned Metrics' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fast Similarity Search For Learned Metrics' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jain P., Kulis, Grauman</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Pattern Analysis and Machine Intelligence</td>
    <td>264</td>
    <td><p>We propose a method to efficiently index into a large database of examples according to a learned metric.
Given a collection of examples, we learn a Mahalanobis distance using an information-theoretic metric
learning technique that adapts prior knowledge about pairwise distances to incorporate similarity and dissimilarity
constraints. To enable sub-linear time similarity search under the learned metric, we show how
to encode a learned Mahalanobis parameterization into randomized locality-sensitive hash functions. We
further formulate an indirect solution that enables metric learning and hashing for sparse input vector spaces
whose high dimensionality make it infeasible to learn an explicit weighting over the feature dimensions.
We demonstrate the approach applied to systems and image datasets, and show that our learned metrics
improve accuracy relative to commonly-used metric baselines, while our hashing construction permits effi-
cient indexing with a learned distance and very large databases.</p>
</td>
    <td>
      
        DATASETS 
      
        Similarity Search 
      
        Hashing Methods 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/jaber2025linear/">Linear Hashing Is Optimal</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Linear Hashing Is Optimal' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Linear Hashing Is Optimal' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jaber Michael, Kumar Vinayak M., Zuckerman David</td> <!-- ðŸ”§ You were missing this -->
    <td>Journal of Combinatorial Theory, Series A</td>
    <td>54</td>
    <td><p>We prove that hashing \(n\) balls into \(n\) bins via a random matrix over \(\mathbf{F}_2\) yields expected maximum load \(O(log n / log log n)\). This matches the expected maximum load of a fully random function and resolves an open question posed by Alon, Dietzfelbinger, Miltersen, Petrank, and Tardos (STOC â€˜97, JACM â€˜99). More generally, we show that the maximum load exceeds \(r\cdotlog n/loglog n\) with probability at most \(O(1/r^2)\).</p>
</td>
    <td>
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/irie2025locally/">Locally Linear Hashing For Extracting Non-linear Manifolds</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Locally Linear Hashing For Extracting Non-linear Manifolds' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Locally Linear Hashing For Extracting Non-linear Manifolds' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Irie et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2014 IEEE Conference on Computer Vision and Pattern Recognition</td>
    <td>94</td>
    <td><p>Previous efforts in hashing intend to preserve data variance
or pairwise affinity, but neither is adequate in capturing
the manifold structures hidden in most visual data. In
this paper, we tackle this problem by reconstructing the locally
linear structures of manifolds in the binary Hamming
space, which can be learned by locality-sensitive sparse
coding. We cast the problem as a joint minimization of
reconstruction error and quantization loss, and show that,
despite its NP-hardness, a local optimum can be obtained
efficiently via alternative optimization. Our method distinguishes
itself from existing methods in its remarkable ability
to extract the nearest neighbors of the query from the
same manifold, instead of from the ambient space. On extensive
experiments on various image benchmarks, our results
improve previous state-of-the-art by 28-74% typically,
and 627% on the Yale face data.</p>
</td>
    <td>
      
        Hashing Methods 
      
        CVPR 
      
        Alt 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/jiang2025scalable/">Scalable Graph Hashing With Feature Transformation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Scalable Graph Hashing With Feature Transformation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Scalable Graph Hashing With Feature Transformation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jiang Q., Li</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>208</td>
    <td><p>Hashing has been widely used for approximate nearest
neighbor (ANN) search in big data applications
because of its low storage cost and fast retrieval
speed. The goal of hashing is to map the data
points from the original space into a binary-code
space where the similarity (neighborhood structure)
in the original space is preserved. By directly
exploiting the similarity to guide the hashing
code learning procedure, graph hashing has attracted
much attention. However, most existing graph
hashing methods cannot achieve satisfactory performance
in real applications due to the high complexity
for graph modeling. In this paper, we propose
a novel method, called scalable graph hashing
with feature transformation (SGH), for large-scale
graph hashing. Through feature transformation, we
can effectively approximate the whole graph without
explicitly computing the similarity graph matrix,
based on which a sequential learning method
is proposed to learn the hash functions in a bit-wise
manner. Experiments on two datasets with one million
data points show that our SGH method can
outperform the state-of-the-art methods in terms of
both accuracy and scalability.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/hu2025separated/">Separated Variational Hashing Networks For Cross-modal Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Separated Variational Hashing Networks For Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Separated Variational Hashing Networks For Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Hu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 27th ACM International Conference on Multimedia</td>
    <td>30</td>
    <td><p>Cross-modal hashing, due to its low storage cost and high query speed, has been successfully used for similarity search in multimedia retrieval applications. It projects high-dimensional data into a shared isomorphic Hamming space with similar binary codes for semantically-similar data. In some applications, all modalities may not be obtained or trained simultaneously for some reasons, such as privacy, secret, storage limitation, and computational resource limitation. However, most existing cross-modal hashing methods need all modalities to jointly learn the common Hamming space, thus hindering them from handling these problems. In this paper, we propose a novel approach called Separated Variational Hashing Networks (SVHNs) to overcome the above challenge. Firstly, it adopts a label network (LabNet) to exploit available and nonspecific label annotations to learn a latent common Hamming space by projecting each semantic label into a common binary representation. Then, each modality-specific network can separately map the samples of the corresponding modality into their binary semantic codes learned by LabNet. We achieve it by conducting variational inference to match the aggregated posterior of the hashing code of LabNet with an arbitrary prior distribution. The effectiveness and efficiency of our SVHNs are verified by extensive experiments carried out on four widely-used multimedia databases, in comparison with 11 state-of-the-art approaches.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Multimodal Retrieval 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/heo2025spherical/">Spherical Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Spherical Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Spherical Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Heo et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2012 IEEE Conference on Computer Vision and Pattern Recognition</td>
    <td>380</td>
    <td><p>Many binary code encoding schemes based on hashing
have been actively studied recently, since they can provide
efficient similarity search, especially nearest neighbor
search, and compact data representations suitable for handling
large scale image databases in many computer vision
problems. Existing hashing techniques encode highdimensional
data points by using hyperplane-based hashing
functions. In this paper we propose a novel hyperspherebased
hashing function, spherical hashing, to map more
spatially coherent data points into a binary code compared
to hyperplane-based hashing functions. Furthermore, we
propose a new binary code distance function, spherical
Hamming distance, that is tailored to our hyperspherebased
binary coding scheme, and design an efficient iterative
optimization process to achieve balanced partitioning
of data points for each hash function and independence between
hashing functions. Our extensive experiments show
that our spherical hashing technique significantly outperforms
six state-of-the-art hashing techniques based on hyperplanes
across various image benchmarks of sizes ranging
from one to 75 million of GIST descriptors. The performance
gains are consistent and large, up to 100% improvements.
The excellent results confirm the unique merits of
the proposed idea in using hyperspheres to encode proximity
regions in high-dimensional spaces. Finally, our method
is intuitive and easy to implement.</p>
</td>
    <td>
      
        Hashing Methods 
      
        CVPR 
      
        Compact Codes 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/he2025k/">K-nearest Neighbors Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=K-nearest Neighbors Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=K-nearest Neighbors Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>He Xiangyu, Wang, Cheng</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>31</td>
    <td><p>Hashing based approximate nearest neighbor search embeds high dimensional data to compact binary codes, which
enables efficient similarity search and storage. However,
the non-isometry sign(Â·) function makes it hard to project
the nearest neighbors in continuous data space into the
closest codewords in discrete Hamming space. In this work,
we revisit the sign(Â·) function from the perspective of space partitioning.
In specific, we bridge the gap between
k-nearest neighbors and binary hashing codes with Shannon entropy. We further propose a novel K-Nearest Neighbors Hashing (KNNH) method to learn binary representations from KNN within the subspaces generated by sign(Â·).
Theoretical and experimental results show that the KNN relation is of central importance to neighbor preserving embeddings, and the proposed method outperforms the state-of-the-arts on benchmark datasets.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        CVPR 
      
        Compact Codes 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/guo2025gpu/">Gpu-accelerated Multi-relational Parallel Graph Retrieval For Web-scale Recommendations</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Gpu-accelerated Multi-relational Parallel Graph Retrieval For Web-scale Recommendations' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Gpu-accelerated Multi-relational Parallel Graph Retrieval For Web-scale Recommendations' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Guo et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</td>
    <td>6</td>
    <td><p>Web recommendations provide personalized items from massive catalogs for
users, which rely heavily on retrieval stages to trade off the effectiveness
and efficiency of selecting a small relevant set from billion-scale candidates
in online digital platforms. As one of the largest Chinese search engine and
news feed providers, Baidu resorts to Deep Neural Network (DNN) and graph-based
Approximate Nearest Neighbor Search (ANNS) algorithms for accurate relevance
estimation and efficient search for relevant items. However, current retrieval
at Baidu fails in comprehensive user-item relational understanding due to
dissected interaction modeling, and performs inefficiently in large-scale
graph-based ANNS because of suboptimal traversal navigation and the GPU
computational bottleneck under high concurrency. To this end, we propose a
GPU-accelerated Multi-relational Parallel Graph Retrieval (GMP-GR) framework to
achieve effective yet efficient retrieval in web-scale recommendations. First,
we propose a multi-relational user-item relevance metric learning method that
unifies diverse user behaviors through multi-objective optimization and employs
a self-covariant loss to enhance pathfinding performance. Second, we develop a
hierarchical parallel graph-based ANNS to boost graph retrieval throughput,
which conducts breadth-depth-balanced searches on a large-scale item graph and
cost-effectively handles irregular neural computation via adaptive aggregation
on GPUs. In addition, we integrate system optimization strategies in the
deployment of GMP-GR in Baidu. Extensive experiments demonstrate the
superiority of GMP-GR in retrieval accuracy and efficiency. Deployed across
more than twenty applications at Baidu, GMP-GR serves hundreds of millions of
users with a throughput exceeding one hundred million requests per second.</p>
</td>
    <td>
      
        KDD 
      
        Graph Based ANN 
      
        Efficiency And Optimization 
      
        Distance Metric Learning 
      
        Large Scale Search 
      
        Recommender Systems 
      
        Similarity Search 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/gritta2025dresd/">Dresd: Dense Retrieval For Speculative Decoding</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Dresd: Dense Retrieval For Speculative Decoding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Dresd: Dense Retrieval For Speculative Decoding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Gritta Milan, Xue Huiyin, Lampouras Gerasimos</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)</td>
    <td>6</td>
    <td><p>Speculative decoding (SD) accelerates Large Language Model (LLM) generation by using an efficient draft model to propose the next few tokens, which are verified by the LLM in a single forward call, reducing latency while preserving its outputs. We focus on retrieval-based SD where the draft model retrieves the next tokens from a non-parametric datastore. Sparse retrieval (REST), which operates on the surface form of strings, is currently the dominant paradigm due to its simplicity and scalability. However, its effectiveness is limited due to the usage of short contexts and exact string matching. Instead, we introduce Dense Retrieval for Speculative Decoding (DReSD), a novel framework that uses approximate nearest neighbour search with contextualised token embeddings to retrieve the most semantically relevant token sequences for SD. Extensive experiments show that DReSD achieves (on average) 87% higher acceptance rates, 65% longer accepted tokens and 19% faster generation speeds compared to sparse retrieval (REST).</p>
</td>
    <td>
      
        NAACL 
      
        Efficiency And Optimization 
      
        ACL 
      
        Similarity Search 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/grauman2025learning/">Learning Binary Hash Codes For Large-scale Image Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning Binary Hash Codes For Large-scale Image Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning Binary Hash Codes For Large-scale Image Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Grauman Kristen, Fergus</td> <!-- ðŸ”§ You were missing this -->
    <td>Studies in Computational Intelligence</td>
    <td>102</td>
    <td><p>Algorithms to rapidly search massive image or video collections are critical for many vision applications, including visual search, content-based retrieval, and non-parametric models for object recognition. Recent work shows that learned binary projections are a powerful way to index large collections according to their content. The basic idea is to formulate the projections so as to approximately preserve a given similarity function of interest. Having done so, one can then search the data efficiently using hash tables, or by exploring the Hamming ball volume around a novel query. Both enable sub-linear time retrieval with respect to the database size. Further, depending on the design of the projections, in some cases it is possible to bound the number of database examples that must be searched in order to achieve a given level of accuracy.</p>

<p>This chapter overviews data structures for fast search with binary codes, and then describes several supervised and unsupervised strategies for generating the codes. In particular, we review supervised methods that integrate metric learning, boosting, and neural networks into the hash key construction, and unsupervised methods based on spectral analysis or kernelized random projections that compute affinity-preserving binary codes.Whether learning from explicit semantic supervision or exploiting the structure among unlabeled data, these methods make scalable retrieval possible for a variety of robust visual similarity measures.We focus on defining the algorithms, and illustrate the main points with results using millions of images.</p>
</td>
    <td>
      
        Survey Paper 
      
        Image Retrieval 
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        Compact Codes 
      
        Large Scale Search 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/gong2025learning/">Learning Binary Codes For High-dimensional Data Using Bilinear Projections</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning Binary Codes For High-dimensional Data Using Bilinear Projections' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning Binary Codes For High-dimensional Data Using Bilinear Projections' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Gong et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2013 IEEE Conference on Computer Vision and Pattern Recognition</td>
    <td>183</td>
    <td><p>Recent advances in visual recognition indicate that to
achieve good retrieval and classification accuracy on largescale
datasets like ImageNet, extremely high-dimensional
visual descriptors, e.g., Fisher Vectors, are needed. We
present a novel method for converting such descriptors to
compact similarity-preserving binary codes that exploits
their natural matrix structure to reduce their dimensionality
using compact bilinear projections instead of a single
large projection matrix. This method achieves comparable
retrieval and classification accuracy to the original descriptors
and to the state-of-the-art Product Quantization
approach while having orders of magnitude faster code generation
time and smaller memory footprint.</p>
</td>
    <td>
      
        DATASETS 
      
        Efficiency And Optimization 
      
        CVPR 
      
        Compact Codes 
      
        Quantization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/gupta2025retreever/">Retreever: Tree-based Coarse-to-fine Representations For Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Retreever: Tree-based Coarse-to-fine Representations For Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Retreever: Tree-based Coarse-to-fine Representations For Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Gupta et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings. International Conference on Image Processing</td>
    <td>6</td>
    <td><p>Document retrieval is a core component of question-answering systems, as it
enables conditioning answer generation on new and large-scale corpora. While
effective, the standard practice of encoding documents into high-dimensional
embeddings for similarity search entails large memory and compute footprints,
and also makes it hard to inspect the inner workings of the system. In this
paper, we propose a tree-based method for organizing and representing reference
documents at various granular levels, which offers the flexibility to balance
cost and utility, and eases the inspection of the corpus content and retrieval
operations. Our method, called ReTreever, jointly learns a routing function per
internal node of a binary tree such that query and reference documents are
assigned to similar tree branches, hence directly optimizing for retrieval
performance. Our evaluations show that ReTreever generally preserves full
representation accuracy. Its hierarchical structure further provides strong
coarse representations and enhances transparency by indirectly learning
meaningful semantic groupings. Among hierarchical retrieval methods, ReTreever
achieves the best retrieval accuracy at the lowest latency, proving that this
family of techniques can be viable in practical applications.</p>
</td>
    <td>
      
        Graph Based ANN 
      
        Efficiency And Optimization 
      
        Text Retrieval 
      
        Similarity Search 
      
        Tree Based ANN 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/huang2025accelerate/">Accelerate Learning Of Deep Hashing With Gradient Attention</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Accelerate Learning Of Deep Hashing With Gradient Attention' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Accelerate Learning Of Deep Hashing With Gradient Attention' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Huang Long-kai, Chen, Pan</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE/CVF International Conference on Computer Vision (ICCV)</td>
    <td>23</td>
    <td><p>Recent years have witnessed the success of learning to hash in fast large-scale image retrieval. As deep learning has shown its superior performance on many computer vision applications, recent designs of learning-based hashing models have been moving from shallow ones to deep architectures. However, based on our analysis, we find that gradient descent based algorithms used in deep hashing models would potentially cause hash codes of a pair of training instances to be updated towards the directions of each other simultaneously during optimization. In the worst case, the paired hash codes switch their directions after update, and consequently, their corresponding distance in the Hamming space remain unchanged. This makes the overall learning process highly inefficient. To address this issue, we propose a new deep hashing model integrated with a novel gradient attention mechanism. Extensive experimental results on three benchmark datasets show that our proposed algorithm is able to accelerate the learning process and obtain competitive retrieval performance compared with state-of-the-art deep hashing models.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Neural Hashing 
      
        ICCV 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/gionis2025similarity/">Similarity Search In High Dimensions Via Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Similarity Search In High Dimensions Via Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Similarity Search In High Dimensions Via Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Gionis A., Indyk, Motwani</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>3205</td>
    <td><p>The nearest- or near-neighbor query problems arise in a large variety of database applications, usually in the context of similarity searching. Of late, there has been increasing interest in building search/index structures for performing similarity search over high-dimensional data, e.g., image databases, document collections, time-series databases, and genome databases. Unfortunately,
all known techniques for solving this problem fall prey to the curse of dimensionality. That is, the data structures scale poorly with data dimensionality;
in fact, if the number of dimensions exceeds 10 to 20, searching in k-d trees and related structures involves the inspection of a large fraction of the database, thereby doing no better than brute-force linear search. It has been suggested that since the selection of features and the choice of a distance metric in typical applications is rather heuristic, determining an approximate nearest neighbor should suffice for most practical purposes. In this paper, we examine a novel scheme for approximate similarity search based on hashing. The basic idea is to hash the points from the database so as to ensure that the probability of collision is much higher for objects that are close to each other than for those that are far apart. We provide experimental evidence that our
method gives significant improvement in running time over other methods for searching in highdimensional spaces based on hierarchical tree decomposition.
Experimental results also indicate that our scheme scales well even for a relatively large number of dimensions (more than 50).</p>
</td>
    <td>
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        Similarity Search 
      
        Tree Based ANN 
      
        Vector Indexing 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/ge2025graph/">Graph Cuts For Supervised Binary Coding</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Graph Cuts For Supervised Binary Coding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Graph Cuts For Supervised Binary Coding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ge T., He, Sun</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>69</td>
    <td><p>Learning short binary codes is challenged by the inherent discrete
nature of the problem. The graph cuts algorithm is a well-studied
discrete label assignment solution in computer vision, but has not yet
been applied to solve the binary coding problems. This is partially because
it was unclear how to use it to learn the encoding (hashing) functions
for out-of-sample generalization. In this paper, we formulate supervised
binary coding as a single optimization problem that involves both
the encoding functions and the binary label assignment. Then we apply
the graph cuts algorithm to address the discrete optimization problem
involved, with no continuous relaxation. This method, named as Graph
Cuts Coding (GCC), shows competitive results in various datasets.</p>
</td>
    <td>
      
        Compact Codes 
      
        DATASETS 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/firtina2025enabling/">Enabling Fast, Accurate, And Efficient Real-time Genome Analysis Via New Algorithms And Techniques</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Enabling Fast, Accurate, And Efficient Real-time Genome Analysis Via New Algorithms And Techniques' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Enabling Fast, Accurate, And Efficient Real-time Genome Analysis Via New Algorithms And Techniques' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Firtina Can</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Computers</td>
    <td>8</td>
    <td><p>The advent of high-throughput sequencing technologies has revolutionized
genome analysis by enabling the rapid and cost-effective sequencing of large
genomes. Despite these advancements, the increasing complexity and volume of
genomic data present significant challenges related to accuracy, scalability,
and computational efficiency. These challenges are mainly due to various forms
of unwanted and unhandled variations in sequencing data, collectively referred
to as noise. In this dissertation, we address these challenges by providing a
deep understanding of different types of noise in genomic data and developing
techniques to mitigate the impact of noise on genome analysis.
  First, we introduce BLEND, a noise-tolerant hashing mechanism that quickly
identifies both exactly matching and highly similar sequences with arbitrary
differences using a single lookup of their hash values. Second, to enable
scalable and accurate analysis of noisy raw nanopore signals, we propose
RawHash, a novel mechanism that effectively reduces noise in raw nanopore
signals and enables accurate, real-time analysis by proposing the first
hash-based similarity search technique for raw nanopore signals. Third, we
extend the capabilities of RawHash with RawHash2, an improved mechanism that 1)
provides a better understanding of noise in raw nanopore signals to reduce it
more effectively and 2) improves the robustness of mapping decisions. Fourth,
we explore the broader implications and new applications of raw nanopore signal
analysis by introducing Rawsamble, the first mechanism for all-vs-all
overlapping of raw signals using hash-based search. Rawsamble enables the
construction of de novo assemblies directly from raw signals without
basecalling, which opens up new directions and uses for raw nanopore signal
analysis.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Similarity Search 
      
        Tools & Libraries 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/fan2025supervised/">Supervised Binary Hash Code Learning With Jensen Shannon Divergence</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Supervised Binary Hash Code Learning With Jensen Shannon Divergence' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Supervised Binary Hash Code Learning With Jensen Shannon Divergence' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Fan Lixin</td> <!-- ðŸ”§ You were missing this -->
    <td>2013 IEEE International Conference on Computer Vision</td>
    <td>15</td>
    <td><p>This paper proposes to learn binary hash codes within
a statistical learning framework, in which an upper bound
of the probability of Bayes decision errors is derived for
different forms of hash functions and a rigorous proof of
the convergence of the upper bound is presented. Consequently, minimizing such an upper bound leads to consistent
performance improvements of existing hash code learning
algorithms, regardless of whether original algorithms are
unsupervised or supervised. This paper also illustrates a
fast hash coding method that exploits simple binary tests to
achieve orders of magnitude improvement in coding speed
as compared to projection based methods.</p>
</td>
    <td>
      
        ICCV 
      
        Tools & Libraries 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/fan2025deep/">Deep Polarized Network For Supervised Learning Of Accurate Binary Hashing Codes</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Polarized Network For Supervised Learning Of Accurate Binary Hashing Codes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Polarized Network For Supervised Learning Of Accurate Binary Hashing Codes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Fan et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence</td>
    <td>81</td>
    <td><p>This paper proposes a novel deep polarized network (DPN) for learning to hash, in which each channel in the network outputs is pushed far away
from zero by employing a differentiable bit-wise hinge-like loss which is dubbed as polarization loss. Reformulated within a generic Hamming Distance Metric Learning framework [Norouzi et al.,
2012], the proposed polarization loss bypasses the requirement to prepare pairwise labels for (dis-)similar items and, yet, the proposed loss strictly bounds from above the pairwise Hamming Distance based losses. The intrinsic connection between pairwise and pointwise label information, as
disclosed in this paper, brings about the following methodological improvements: (a) we may directly employ the proposed differentiable polarization loss with no large deviations incurred from
the target Hamming distance based loss; and (b) the subtask of assigning binary codes becomes extremely simple â€” even random codes assigned to each class suffice to result in state-of-the-art performances, as demonstrated in CIFAR10, NUS-WIDE and ImageNet100 datasets.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        IJCAI 
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        Compact Codes 
      
        Tools & Libraries 
      
        AAAI 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/duan2025enhancing/">Enhancing Subsequent Video Retrieval Via Vision-language Models (vlms)</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Enhancing Subsequent Video Retrieval Via Vision-language Models (vlms)' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Enhancing Subsequent Video Retrieval Via Vision-language Models (vlms)' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Duan Yicheng, Huang Xi, Chen Duo</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>71</td>
    <td><p>The rapid growth of video content demands efficient and precise retrieval
systems. While vision-language models (VLMs) excel in representation learning,
they often struggle with adaptive, time-sensitive video retrieval. This paper
introduces a novel framework that combines vector similarity search with
graph-based data structures. By leveraging VLM embeddings for initial retrieval
and modeling contextual relationships among video segments, our approach
enables adaptive query refinement and improves retrieval accuracy. Experiments
demonstrate its precision, scalability, and robustness, offering an effective
solution for interactive video retrieval in dynamic environments.</p>
</td>
    <td>
      
        Graph Based ANN 
      
        CVPR 
      
        Similarity Search 
      
        Tools & Libraries 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/ding2025collective/">Collective Matrix Factorization Hashing For Multimodal Data</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Collective Matrix Factorization Hashing For Multimodal Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Collective Matrix Factorization Hashing For Multimodal Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ding G., Guo, Zhou</td> <!-- ðŸ”§ You were missing this -->
    <td>2014 IEEE Conference on Computer Vision and Pattern Recognition</td>
    <td>638</td>
    <td><p>Nearest neighbor search methods based on hashing have
attracted considerable attention for effective and efficient
large-scale similarity search in computer vision and information
retrieval community. In this paper, we study the
problems of learning hash functions in the context of multimodal
data for cross-view similarity search. We put forward
a novel hashing method, which is referred to Collective
Matrix Factorization Hashing (CMFH). CMFH learns unified
hash codes by collective matrix factorization with latent
factor model from different modalities of one instance,
which can not only supports cross-view search but also increases
the search accuracy by merging multiple view information
sources. We also prove that CMFH, a similaritypreserving
hashing learning method, has upper and lower
boundaries. Extensive experiments verify that CMFH significantly
outperforms several state-of-the-art methods on
three different datasets.</p>
</td>
    <td>
      
        CVPR 
      
        DATASETS 
      
        Similarity Search 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/ding2025knn/">Knn Hashing With Factorized Neighborhood Representation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Knn Hashing With Factorized Neighborhood Representation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Knn Hashing With Factorized Neighborhood Representation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ding et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2015 IEEE International Conference on Computer Vision (ICCV)</td>
    <td>14</td>
    <td><p>Hashing is very effective for many tasks in reducing the
processing time and in compressing massive databases. Although lots of approaches have been developed to learn
data-dependent hash functions in recent years, how to learn
hash functions to yield good performance with acceptable
computational and memory cost is still a challenging problem. Based on the observation that retrieval precision is
highly related to the kNN classification accuracy, this paper
proposes a novel kNN-based supervised hashing method,
which learns hash functions by directly maximizing the kNN
accuracy of the Hamming-embedded training data. To make
it scalable well to large problem, we propose a factorized
neighborhood representation to parsimoniously model the
neighborhood relationships inherent in training data. Considering that real-world data are often linearly inseparable,
we further kernelize this basic model to improve its performance. As a result, the proposed method is able to learn
accurate hashing functions with tolerable computation and
storage cost. Experiments on four benchmarks demonstrate
that our method outperforms the state-of-the-arts.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Alt 
      
        ICCV 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/datar2025locality/">Locality-sensitive Hashing Scheme Based On P-stable Distributions</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Locality-sensitive Hashing Scheme Based On P-stable Distributions' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Locality-sensitive Hashing Scheme Based On P-stable Distributions' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Datar et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the twentieth annual symposium on Computational geometry</td>
    <td>2874</td>
    <td><p>We present a novel Locality-Sensitive Hashing scheme for the Approximate Nearest Neighbor Problem under lp norm, based on p-stable distributions.Our scheme improves the running time of the earlier algorithm for the case of the lp norm. It also yields the first known provably efficient approximate NN algorithm for the case p&lt;1. We also show that the algorithm finds the exact near neigbhor in O(log n) time for data satisfying certain â€œbounded growthâ€ condition.Unlike earlier schemes, our LSH scheme works directly on points in the Euclidean space without embeddings. Consequently, the resulting query time bound is free of large factors and is simple and easy to implement. Our experiments (on synthetic data sets) show that the our data structure is up to 40 times faster than kd-tree.</p>
</td>
    <td>
      
        Tree Based ANN 
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/deng2025two/">Two-stream Deep Hashing With Class-specific Centers For Supervised Image Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Two-stream Deep Hashing With Class-specific Centers For Supervised Image Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Two-stream Deep Hashing With Class-specific Centers For Supervised Image Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Deng et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Neural Networks and Learning Systems</td>
    <td>75</td>
    <td><p>Hashing has been widely used for large-scale approximate nearest neighbor search due to its storage and search efficiency. Recent supervised hashing research has shown that deep learning-based methods can significantly outperform nondeep methods. Most existing supervised deep hashing methods exploit supervisory signals to generate similar and dissimilar image pairs for training. However, natural images can have large intraclass and small interclass variations, which may degrade the accuracy of hash codes. To address this problem, we propose a novel two-stream ConvNet architecture, which learns hash codes with class-specific representation centers. Our basic idea is that if we can learn a unified binary representation for each class as a center and encourage hash codes of images to be close to the corresponding centers, the intraclass variation will be greatly reduced. Accordingly, we design a neural network that leverages label information and outputs a unified binary representation for each class. Moreover, we also design an image network to learn hash codes from images and force these hash codes to be close to the corresponding class-specific centers. These two neural networks are then seamlessly incorporated to create a unified, end-to-end trainable framework. Extensive experiments on three popular benchmarks corroborate that our proposed method outperforms current state-of-the-art methods.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Neural Hashing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/cheng2025robust/">Robust Unsupervised Cross-modal Hashing For Multimedia Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Robust Unsupervised Cross-modal Hashing For Multimedia Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Robust Unsupervised Cross-modal Hashing For Multimedia Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Cheng Miaomiao, Jing, Ng</td> <!-- ðŸ”§ You were missing this -->
    <td>ACM Transactions on Information Systems</td>
    <td>46</td>
    <td><p>With the quick development of social websites, there are more opportunities to have different media types (such as text, image, video, etc.) describing the same topic from large-scale heterogeneous data sources. To efficiently identify the inter-media correlations for multimedia retrieval, unsupervised cross-modal hashing (UCMH) has gained increased interest due to the significant reduction in computation and storage. However, most UCMH methods assume that the data from different modalities are well paired. As a result, existing UCMH methods may not achieve satisfactory performance when partially paired data are given only. In this article, we propose a new-type of UCMH method called robust unsupervised cross-modal hashing (RUCMH). The major contribution lies in jointly learning modal-specific hash function, exploring the correlations among modalities with partial or even without any pairwise correspondence, and preserving the information of original features as much as possible. The learning process can be modeled via a joint minimization problem, and the corresponding optimization algorithm is presented. A series of experiments is conducted on four real-world datasets (Wiki, MIRFlickr, NUS-WIDE, and MS-COCO). The results demonstrate that RUCMH can significantly outperform the state-of-the-art unsupervised cross-modal hashing methods, especially for the partially paired case, which validates the effectiveness of RUCMH.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/chen2025enhanced/">Enhanced Discrete Multi-modal Hashing: More Constraints Yet Less Time To Learn</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Enhanced Discrete Multi-modal Hashing: More Constraints Yet Less Time To Learn' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Enhanced Discrete Multi-modal Hashing: More Constraints Yet Less Time To Learn' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Chen et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Knowledge and Data Engineering</td>
    <td>27</td>
    <td><p>Due to the exponential growth of multimedia data, multi-modal hashing as a promising technique to make cross-view retrieval scalable is attracting more and more attention. However, most of the existing multi-modal hashing methods either divide the learning process unnaturally into two separate stages or treat the discrete optimization problem simplistically as a continuous one, which leads to suboptimal results. Recently, a few discrete multi-modal hashing methods that try to address such issues have emerged, but they still ignore several important discrete constraints (such as the balance and decorrelation of hash bits). In this paper, we overcome those limitations by proposing a novel method named â€œEnhanced Discrete Multi-modal Hashing (EDMH)â€ which learns binary codes and hashing functions simultaneously from the pairwise similarity matrix of data, under the aforementioned discrete constraints. Although the model of EDMH looks a lot more complex than the other models for multi-modal hashing, we are actually able to develop a fast iterative learning algorithm for it, since the subproblems of its optimization all have closed-form solutions after introducing two auxiliary variables. Our experimental results on three real-world datasets have demonstrated that EDMH not only performs much better than state-of-the-art competitors but also runs much faster than them.</p>
</td>
    <td>
      
        Compact Codes 
      
        Alt 
      
        Hashing Methods 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/chen2025deep/">Deep Supervised Hashing With Anchor Graph</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Supervised Hashing With Anchor Graph' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Supervised Hashing With Anchor Graph' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Chen et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE/CVF International Conference on Computer Vision (ICCV)</td>
    <td>52</td>
    <td><p>Recently, a series of deep supervised hashing methods were proposed for binary code learning. However, due to the high computation cost and the limited hardwareâ€™s memory, these methods will first select a subset from the training set, and then form a mini-batch data to update the network in each iteration. Therefore, the remaining labeled data cannot be fully utilized and the model cannot directly obtain the binary codes of the entire training set for retrieval. To address these problems, this paper proposes an interesting regularized deep model to seamlessly integrate the advantages of deep hashing and efficient binary code learning by using the anchor graph. As such, the deep features and label matrix can be jointly used to optimize the binary codes, and the network can obtain more discriminative feedback from the linear combinations of the learned bits. Moreover, we also reveal the algorithm mechanism and its computation essence. Experiments on three large-scale datasets indicate that the proposed method achieves better retrieval performance with less training time compared to previous deep hashing methods.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Neural Hashing 
      
        ICCV 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/chen2025long/">Long-tail Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Long-tail Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Long-tail Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Chen et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</td>
    <td>9</td>
    <td><p>Hashing, which represents data items as compact binary codes, has
been becoming a more and more popular technique, e.g., for large-scale image retrieval, owing to its super fast search speed as well
as its extremely economical memory consumption. However, existing hashing methods all try to learn binary codes from artificially
balanced datasets which are not commonly available in real-world
scenarios. In this paper, we propose Long-Tail Hashing Network
(LTHNet), a novel two-stage deep hashing approach that addresses
the problem of learning to hash for more realistic datasets where
the data labels roughly exhibit a long-tail distribution. Specifically,
the first stage is to learn relaxed embeddings of the given dataset
with its long-tail characteristic taken into account via an end-to-end deep neural network; the second stage is to binarize those
obtained embeddings. A critical part of LTHNet is its extended dynamic meta-embedding module which can adaptively realize visual
knowledge transfer between head and tail classes, and thus enrich
image representations for hashing. Our experiments have shown
that LTHNet achieves dramatic performance improvements over all
state-of-the-art competitors on long-tail datasets, with no or little
sacrifice on balanced datasets. Further analyses reveal that while to
our surprise directly manipulating class weights in the loss function
has little effect, the extended dynamic meta-embedding module, the
usage of cross-entropy loss instead of square loss, and the relatively
small batch-size for training all contribute to LTHNetâ€™s success.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Neural Hashing 
      
        SIGIR 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/chen2025strongly/">Strongly Constrained Discrete Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Strongly Constrained Discrete Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Strongly Constrained Discrete Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Chen et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Image Processing</td>
    <td>50</td>
    <td><p>Learning to hash is a fundamental technique widely used in large-scale image retrieval. Most existing methods for learning to hash address the involved discrete optimization problem by the continuous relaxation of the binary constraint, which usually leads to large quantization errors and consequently suboptimal binary codes. A few discrete hashing methods have emerged recently. However, they either completely ignore some useful constraints (specifically the balance and decorrelation of hash bits) or just turn those constraints into regularizers that would make the optimization easier but less accurate. In this paper, we propose a novel supervised hashing method named Strongly Constrained Discrete Hashing (SCDH) which overcomes such limitations. It can learn the binary codes for all examples in the training set, and meanwhile obtain a hash function for unseen samples with the above mentioned constraints preserved. Although the model of SCDH is fairly sophisticated, we are able to find closed-form solutions to all of its optimization subproblems and thus design an efficient algorithm that converges quickly. In addition, we extend SCDH to a kernelized version SCDH K . Our experiments on three large benchmark datasets have demonstrated that not only can SCDH and SCDH K achieve substantially higher MAP scores than state-of-the-art baselines, but they train much faster than those that are also supervised as well.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Alt 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/chen2025two/">A Two-step Cross-modal Hashing By Exploiting Label Correlations And Preserving Similarity In Both Steps</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Two-step Cross-modal Hashing By Exploiting Label Correlations And Preserving Similarity In Both Steps' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Two-step Cross-modal Hashing By Exploiting Label Correlations And Preserving Similarity In Both Steps' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Chen et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 27th ACM International Conference on Multimedia</td>
    <td>45</td>
    <td><p>In this paper, we present a novel Two-stEp Cross-modal Hashing method, TECH for short, for cross-modal retrieval tasks. As a two-step method, it first learns hash codes based on semantic labels, while preserving the similarity in the original space and exploiting the label correlations in the label space. In the light of this, it is able to make better use of label information and generate better binary codes. In addition, different from other two-step methods that mainly focus on the hash codes learning, TECH adopts a new hash function learning strategy in the second step, which also preserves the similarity in the original space. Moreover, with the help of well designed objective function and optimization scheme, it is able to generate hash codes discretely and scalable for large scale data. To the best of our knowledge, it is the first cross-modal hashing method exploiting label correlations, and also the first two-step hashing model preserving the similarity while leaning hash function. Extensive experiments demonstrate that the proposed approach outperforms some state-of-the-art cross-modal hashing methods.</p>
</td>
    <td>
      
        Compact Codes 
      
        Multimodal Retrieval 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/chaidaroon2025deep/">Deep Semantic Text Hashing With Weak Supervision</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Semantic Text Hashing With Weak Supervision' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Semantic Text Hashing With Weak Supervision' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Chaidaroon Suthee, Ebesu, Fang</td> <!-- ðŸ”§ You were missing this -->
    <td>The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval</td>
    <td>29</td>
    <td><p>With an ever increasing amount of data available on the web, fast similarity search has become the critical component for large-scale information retrieval systems. One solution is semantic hashing which designs binary codes to accelerate similarity search. Recently, deep learning has been successfully applied to the semantic hashing problem and produces high-quality compact binary codes compared to traditional methods. However, most state-of-the-art semantic hashing approaches require large amounts of hand-labeled training data which are often expensive and time consuming to collect. The cost of getting labeled data is the key bottleneck in deploying these hashing methods. Motivated by the recent success in machine learning that makes use of weak supervision, we employ unsupervised ranking methods such as BM25 to extract weak signals from training data. We further introduce two deep generative semantic hashing models to leverage weak signals for text hashing. The experimental results on four public datasets show that our models can generate high-quality binary codes without using hand-labeled training data and significantly outperform the competitive unsupervised semantic hashing baselines.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Text Retrieval 
      
        SIGIR 
      
        Similarity Search 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/carreiraperpinan2025hashing/">Hashing With Binary Autoencoders</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hashing With Binary Autoencoders' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hashing With Binary Autoencoders' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Carreira-perpinan M., Raziperchikolaei</td> <!-- ðŸ”§ You were missing this -->
    <td>2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>142</td>
    <td><p>An attractive approach for fast search in image
databases is binary hashing, where each high-dimensional,
real-valued image is mapped onto a low-dimensional, binary
vector and the search is done in this binary space.
Finding the optimal hash function is difficult because it involves
binary constraints, and most approaches approximate
the optimization by relaxing the constraints and then
binarizing the result. Here, we focus on the binary autoencoder
model, which seeks to reconstruct an image from the
binary code produced by the hash function. We show that
the optimization can be simplified with the method of auxiliary
coordinates. This reformulates the optimization as
alternating two easier steps: one that learns the encoder
and decoder separately, and one that optimizes the code for
each image. Image retrieval experiments show the resulting
hash function outperforms or is competitive with state-ofthe-art
methods for binary hashing.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        CVPR 
      
        Compact Codes 
      
        Alt 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/cao2025hashgan/">Hashgan: Deep Learning To Hash With Pair Conditional Wasserstein GAN</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hashgan: Deep Learning To Hash With Pair Conditional Wasserstein GAN' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hashgan: Deep Learning To Hash With Pair Conditional Wasserstein GAN' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Cao et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</td>
    <td>117</td>
    <td><p>Deep learning to hash improves image retrieval performance by end-to-end representation learning and hash coding from training data with pairwise similarity information.
Subject to the scarcity of similarity information that is often
expensive to collect for many application domains, existing
deep learning to hash methods may overfit the training data
and result in substantial loss of retrieval quality. This paper
presents HashGAN, a novel architecture for deep learning
to hash, which learns compact binary hash codes from both
real images and diverse images synthesized by generative
models. The main idea is to augment the training data with
nearly real images synthesized from a new Pair Conditional
Wasserstein GAN (PC-WGAN) conditioned on the pairwise
similarity information. Extensive experiments demonstrate
that HashGAN can generate high-quality binary hash codes
and yield state-of-the-art image retrieval performance on
three benchmarks, NUS-WIDE, CIFAR-10, and MS-COCO.</p>
</td>
    <td>
      
        CVPR 
      
        Image Retrieval 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/cao2025correlation/">Correlation Autoencoder Hashing For Supervised Cross-modal Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Correlation Autoencoder Hashing For Supervised Cross-modal Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Correlation Autoencoder Hashing For Supervised Cross-modal Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Cao et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval</td>
    <td>98</td>
    <td><p>Due to its storage and query efficiency, hashing has been widely
applied to approximate nearest neighbor search from large-scale
datasets. While there is increasing interest in cross-modal hashing
which facilitates cross-media retrieval by embedding data from different modalities into a common Hamming space, how to distill the
cross-modal correlation structure effectively remains a challenging
problem. In this paper, we propose a novel supervised cross-modal
hashing method, Correlation Autoencoder Hashing (CAH), to learn
discriminative and compact binary codes based on deep autoencoders. Specifically, CAH jointly maximizes the feature correlation
revealed by bimodal data and the semantic correlation conveyed in
similarity labels, while embeds them into hash codes by nonlinear
deep autoencoders. Extensive experiments clearly show the superior effectiveness and efficiency of CAH against the state-of-the-art
hashing methods on standard cross-modal retrieval benchmarks.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Multimodal Retrieval 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/cao2025collective/">Collective Deep Quantization For Efficient Cross-modal Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Collective Deep Quantization For Efficient Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Collective Deep Quantization For Efficient Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Cao et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>97</td>
    <td><p>Cross-modal similarity retrieval is a problem about designing a retrieval system that supports querying across
content modalities, e.g., using an image to retrieve for
texts. This paper presents a compact coding solution for
efficient cross-modal retrieval, with a focus on the quantization approach which has already shown the superior
performance over the hashing solutions in single-modal
similarity retrieval. We propose a collective deep quantization (CDQ) approach, which is the first attempt to
introduce quantization in end-to-end deep architecture
for cross-modal retrieval. The major contribution lies in
jointly learning deep representations and the quantizers
for both modalities using carefully-crafted hybrid networks and well-specified loss functions. In addition, our
approach simultaneously learns the common quantizer
codebook for both modalities through which the crossmodal correlation can be substantially enhanced. CDQ
enables efficient and effective cross-modal retrieval using inner product distance computed based on the common codebook with fast distance table lookup. Extensive experiments show that CDQ yields state of the art
cross-modal retrieval results on standard benchmarks.</p>
</td>
    <td>
      
        AAAI 
      
        Hashing Methods 
      
        Multimodal Retrieval 
      
        Similarity Search 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/cao2025deep/">Deep Cauchy Hashing For Hamming Space Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Cauchy Hashing For Hamming Space Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Cauchy Hashing For Hamming Space Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Cao et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</td>
    <td>358</td>
    <td><p>Due to its computation efficiency and retrieval quality,
hashing has been widely applied to approximate nearest
neighbor search for large-scale image retrieval, while deep
hashing further improves the retrieval quality by end-toend representation learning and hash coding. With compact
hash codes, Hamming space retrieval enables the most efficient constant-time search that returns data points within a
given Hamming radius to each query, by hash table lookups
instead of linear scan. However, subject to the weak capability of concentrating relevant images to be within a small
Hamming ball due to mis-specified loss functions, existing deep hashing methods may underperform for Hamming
space retrieval.  This work presents Deep Cauchy Hashing
(DCH), a novel deep hashing model that generates compact
and concentrated binary hash codes to enable efficient and
effective Hamming space retrieval. The main idea is to design a pairwise cross-entropy loss based on Cauchy distribution, which penalizes significantly on similar image pairs
with Hamming distance larger than the given Hamming radius threshold. Comprehensive experiments demonstrate
that DCH can generate highly concentrated hash codes and
yield state-of-the-art Hamming space retrieval performance
on three datasets, NUS-WIDE, CIFAR-10, and MS-COCO.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        CVPR 
      
        Neural Hashing 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/cakir2025adaptive/">Adaptive Hashing For Fast Similarity Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Adaptive Hashing For Fast Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Adaptive Hashing For Fast Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Cakir F., Sclaroff</td> <!-- ðŸ”§ You were missing this -->
    <td>2015 IEEE International Conference on Computer Vision (ICCV)</td>
    <td>88</td>
    <td><p>With the staggering growth in image and video datasets,
algorithms that provide fast similarity search and compact
storage are crucial. Hashing methods that map the
data into Hamming space have shown promise; however,
many of these methods employ a batch-learning strategy
in which the computational cost and memory requirements
may become intractable and infeasible with larger and
larger datasets. To overcome these challenges, we propose
an online learning algorithm based on stochastic gradient
descent in which the hash functions are updated iteratively
with streaming data. In experiments with three image retrieval
benchmarks, our online algorithm attains retrieval
accuracy that is comparable to competing state-of-the-art
batch-learning solutions, while our formulation is orders
of magnitude faster and being online it is adaptable to the
variations of the data. Moreover, our formulation yields improved
retrieval performance over a recently reported online
hashing technique, Online Kernel Hashing.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        ICCV 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/bawa2025lsh/">LSH Forest: Self-tuning Indexes For Similarity Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=LSH Forest: Self-tuning Indexes For Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=LSH Forest: Self-tuning Indexes For Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Bawa M., Condie, Ganesan</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>5</td>
    <td><p>We consider the problem of indexing high-dimensional data for answering (approximate) similarity-search queries. Similarity indexes prove to be important in a wide variety of settings: Web search
engines desire fast, parallel, main-memory-based indexes for similarity search on text data; database systems desire disk-based similarity indexes for high-dimensional data, including text and images;
peer-to-peer systems desire distributed similarity indexes with low
communication cost. We propose an indexing scheme called LSH
Forest which is applicable in all the above contexts. Our index uses the well-known technique of locality-sensitive hashing (LSH),
but improves upon previous designs by (a) eliminating the different data-dependent parameters for which LSH must be constantly hand-tuned, and (b) improving on LSHâ€™s performance guarantees for skewed data distributions while retaining the same storage
and query overhead. We show how to construct this index in main
memory, on disk, in parallel systems, and in peer-to-peer systems.
We evaluate the design with experiments on multiple text corpora
and demonstrate both the self-tuning nature and the superior performance of LSH Forest.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Graph Based ANN 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/beling2025phast/">Phast -- Perfect Hashing With Fast Evaluation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Phast -- Perfect Hashing With Fast Evaluation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Phast -- Perfect Hashing With Fast Evaluation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Beling Piotr, Sanders Peter</td> <!-- ðŸ”§ You were missing this -->
    <td>Theoretical Computer Science</td>
    <td>93</td>
    <td><p>Perfect hash functions give unique â€œnamesâ€ to arbitrary keys requiring only a few bits per key. This is an essential building block in applications like static hash tables, databases, or bioinformatics. This paper introduces the PHast approach that has the currently fastest query time with competitive construction time and space consumption. PHast improves bucket-placement which first hashes each key k to a bucket, and then looks for the bucket seed s such that a secondary hash function maps pairs (s,k) in a collision-free way. PHast can use small-range primary hash functions with linear mapping, fixed-width encoding of seeds, and parallel construction. This is achieved using small overlapping slices of allowed values and bumping to handle unsuccessful seed assignment.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/bach2025hierarchical/">Hierarchical Patch Compression For Colpali: Efficient Multi-vector Document Retrieval With Dynamic Pruning And Quantization</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hierarchical Patch Compression For Colpali: Efficient Multi-vector Document Retrieval With Dynamic Pruning And Quantization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hierarchical Patch Compression For Colpali: Efficient Multi-vector Document Retrieval With Dynamic Pruning And Quantization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Bach Duong</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 9th annual international ACM SIGIR conference on Research and development in information retrieval  - SIGIR '86</td>
    <td>16</td>
    <td><p>Multi-vector document retrieval systems, such as ColPali, excel in fine-grained matching for complex queries but incur significant storage and computational costs due to their reliance on high-dimensional patch embeddings and late-interaction scoring. To address these challenges, we propose HPC-ColPali, a Hierarchical Patch Compression framework that enhances the efficiency of ColPali while preserving its retrieval accuracy. Our approach integrates three innovative techniques: (1) K-Means quantization, which compresses patch embeddings into 1-byte centroid indices, achieving up to 32\(\times\) storage reduction; (2) attention-guided dynamic pruning, utilizing Vision-Language Model attention weights to retain only the top-\(p%\) most salient patches, reducing late-interaction computation by up to 60% with less than 2% nDCG@10 loss; and (3) optional binary encoding of centroid indices into \(b\)-bit strings (\(b=\lceillog_2 K\rceil\)), enabling rapid Hamming distance-based similarity search for resource-constrained environments. Evaluated on the ViDoRe and SEC-Filings datasets, HPC-ColPali achieves 30â€“50% lower query latency under HNSW indexing while maintaining high retrieval precision. When integrated into a Retrieval-Augmented Generation pipeline for legal summarization, it reduces hallucination rates by 30% and halves end-to-end latency. These advancements establish HPC-ColPali as a scalable and efficient solution for multi-vector document retrieval across diverse applications. Code is available at https://github.com/DngBack/HPC-ColPali.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Graph Based ANN 
      
        Efficiency And Optimization 
      
        Text Retrieval 
      
        SIGIR 
      
        Similarity Search 
      
        Quantization 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/andoni2025practical/">Practical And Optimal LSH For Angular Distance</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Practical And Optimal LSH For Angular Distance' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Practical And Optimal LSH For Angular Distance' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Andoni A., Indyk, Laarhoven</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>238</td>
    <td><p>We show the existence of a Locality-Sensitive Hashing (LSH) family for the angular
distance that yields an approximate Near Neighbor Search algorithm with the
asymptotically optimal running time exponent. Unlike earlier algorithms with this
property (e.g., Spherical LSH [1, 2]), our algorithm is also practical, improving
upon the well-studied hyperplane LSH [3] in practice. We also introduce a multiprobe
version of this algorithm and conduct an experimental evaluation on real
and synthetic data sets.
We complement the above positive results with a fine-grained lower bound for the
quality of any LSH family for angular distance. Our lower bound implies that the
above LSH family exhibits a trade-off between evaluation time and quality that is
close to optimal for a natural class of LSH functions.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/andoni2025near/">Near-optimal Hashing Algorithms For Approximate Nearest Neighbor In High Dimensions</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Near-optimal Hashing Algorithms For Approximate Nearest Neighbor In High Dimensions' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Near-optimal Hashing Algorithms For Approximate Nearest Neighbor In High Dimensions' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Andoni A., Indyk</td> <!-- ðŸ”§ You were missing this -->
    <td>Communications of the ACM</td>
    <td>1420</td>
    <td><p>We present an algorithm for the c-approximate nearest neighbor problem in a d-dimensional Euclidean space, achieving query time of O(dn 1c2/+o(1)) and space O(dn + n1+1c2/+o(1)). This almost matches the lower bound for hashing-based algorithm recently obtained in (R. Motwani et al., 2006). We also obtain a space-efficient version of the algorithm, which uses dn+n logO(1) n space, with a query time of dnO(1/c2). Finally, we discuss practical variants of the algorithms that utilize fast bounded-distance decoders for the Leech lattice</p>
</td>
    <td>
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/2025scratch/">SCRATCH: A Scalable Discrete Matrix Factorization Hashing For Cross-modal Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=SCRATCH: A Scalable Discrete Matrix Factorization Hashing For Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=SCRATCH: A Scalable Discrete Matrix Factorization Hashing For Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Chuan-xiang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Circuits and Systems for Video Technology</td>
    <td>110</td>
    <td><p>In recent years, many hashing methods have been proposed for the cross-modal retrieval task. However, there are still some issues that need to be further explored. For example, some of them relax the binary constraints to generate the hash codes, which may generate large quantization error. Although some discrete schemes have been proposed, most of them are time-consuming. In addition, most of the existing supervised hashing methods use an n x n similarity matrix during the optimization, making them unscalable. To address these issues, in this paper, we present a novel supervised cross-modal hashing methodâ€”Scalable disCRete mATrix faCtorization Hashing, SCRATCH for short. It leverages the collective matrix factorization on the kernelized features and the semantic embedding with labels to find a latent semantic space to preserve the intra- and inter-modality similarities. In addition, it incorporates the label matrix instead of the similarity matrix into the loss function. Based on the proposed loss function and the iterative optimization algorithm, it can learn the hash functions and binary codes simultaneously. Moreover, the binary codes can be generated discretely, reducing the quantization error generated by the relaxation scheme. Its time complexity is linear to the size of the dataset, making it scalable to large-scale datasets. Extensive experiments on three benchmark datasets, namely, Wiki, MIRFlickr-25K, and NUS-WIDE, have verified that our proposed SCRATCH model outperforms several state-of-the-art unsupervised and supervised hashing methods for cross-modal retrieval.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Alt 
      
        Multimodal Retrieval 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/gong2025iterative/">Iterative Quantization: A Procrustean Approach To Learning Binary Codes</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Iterative Quantization: A Procrustean Approach To Learning Binary Codes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Iterative Quantization: A Procrustean Approach To Learning Binary Codes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Gong Y., Lazebnik</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Pattern Analysis and Machine Intelligence</td>
    <td>1834</td>
    <td><p>This paper addresses the problem of learning similarity preserving binary codes for efficient retrieval in large-scale image collections. We propose a simple and efficient alternating minimization scheme for finding a rotation of zerocentered data so as to minimize the quantization error of
mapping this data to the vertices of a zero-centered binary
hypercube. This method, dubbed iterative quantization
(ITQ), has connections to multi-class spectral clustering
and to the orthogonal Procrustes problem, and it can be
used both with unsupervised data embeddings such as PCA
and supervised embeddings such as canonical correlation
analysis (CCA). Our experiments show that the resulting
binary coding schemes decisively outperform several other
state-of-the-art methods.</p>
</td>
    <td>
      
        Compact Codes 
      
        Alt 
      
        Similarity Search 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/yang2025nonlinear/">Nonlinear Robust Discrete Hashing For Cross-modal Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Nonlinear Robust Discrete Hashing For Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Nonlinear Robust Discrete Hashing For Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</td>
    <td>21</td>
    <td><p>Hashing techniques have recently been successfully applied to solve similarity search problems in the information retrieval field because of their significantly reduced storage and high-speed search capabilities. However, the hash codes learned from most recent cross-modal hashing methods lack the ability to comprehensively preserve adequate information, resulting in a less than desirable performance. To solve this limitation, we propose a novel method termed Nonlinear Robust Discrete Hashing (NRDH), for cross-modal retrieval. The main idea behind NRDH is motivated by the success of neural networks, i.e., nonlinear descriptors, in the field of representation learning, and the use of nonlinear descriptors instead of simple linear transformations is more in line with the complex relationships that exist between common latent representation and heterogeneous multimedia data in the real world. In NRDH, we first learn a common latent representation through nonlinear descriptors to encode complementary and consistent information from the features of the heterogeneous multimedia data. Moreover, an asymmetric learning scheme is proposed to correlate the learned hash codes with the common latent representation. Empirically, we demonstrate that NRDH is able to successfully generate a comprehensive common latent representation that significantly improves the quality of the learned hash codes. Then, NRDH adopts a linear learning strategy to fast learn the hash function with the learned hash codes. Extensive experiments performed on two benchmark datasets highlight the superiority of NRDH over several state-of-the-art methods.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        Multimodal Retrieval 
      
        SIGIR 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/yang2025adaptive/">Adaptive Labeling For Deep Learning To Hash</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Adaptive Labeling For Deep Learning To Hash' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Adaptive Labeling For Deep Learning To Hash' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yang Huei-fang, Tu, Chen</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</td>
    <td>8</td>
    <td><p>Hash function learning has been widely used for largescale image retrieval because of the efficiency of computation and storage. We introduce AdaLabelHash, a binary
hash function learning approach via deep neural networks
in this paper. In AdaLabelHash, class label representations are variables that are adapted during the backward
network training procedure. We express the labels as hypercube vertices in a K-dimensional space, and the class
label representations together with the network weights are
updated in the learning process. As the label representations (or referred to as codewords in this work), are learned
from data, semantically similar classes will be assigned
with the codewords that are close to each other in terms
of Hamming distance in the label space. The codewords
then serve as the desired output of the hash function learning, and yield compact and discriminating binary hash representations. AdaLabelHash is easy to implement, which
can jointly learn label representations and infer compact
binary codes from data. It is applicable to both supervised
and semi-supervised hash. Experimental results on standard benchmarks demonstrate the satisfactory performance
of AdaLabelHash.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        CVPR 
      
        Compact Codes 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/yan2025deep/">Deep Hashing By Discriminating Hard Examples</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Hashing By Discriminating Hard Examples' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Hashing By Discriminating Hard Examples' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yan et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 27th ACM International Conference on Multimedia</td>
    <td>27</td>
    <td><p>This paper tackles a rarely explored but critical problem within learning to hash, i.e., to learn hash codes that effectively discriminate hard similar and dissimilar examples, to empower large-scale image retrieval. Hard similar examples refer to image pairs from the same semantic class that demonstrate some shared appearance but have different fine-grained appearance. Hard dissimilar examples are image pairs that come from different semantic classes but exhibit similar appearance. These hard examples generally have a small distance due to the shared appearance. Therefore, effective encoding of the hard examples can well discriminate the relevant images within a small Hamming distance, enabling more accurate retrieval in the top-ranked returned images. However, most existing hashing methods cannot capture this key information as their optimization is dominated byeasy examples, i.e., distant similar/dissimilar pairs that share no or limited appearance. To address this problem, we introduce a novel Gamma distribution-enabled and symmetric Kullback-Leibler divergence-based loss, which is dubbed dual hinge loss because it works similarly as imposing two smoothed hinge losses on the respective similar and dissimilar pairs. Specifically, the loss enforces exponentially variant penalization on the hard similar (dissimilar) examples to emphasize and learn their fine-grained difference. It meanwhile imposes a bounding penalization on easy similar (dissimilar) examples to prevent the dominance of the easy examples in the optimization while preserving the high-level similarity (dissimilarity). This enables our model to well encode the key information carried by both easy and hard examples. Extensive empirical results on three widely-used image retrieval datasets show that (i) our method consistently and substantially outperforms state-of-the-art competing methods using hash codes of the same length and (ii) our method can use significantly (e.g., 50%-75%) shorter hash codes to perform substantially better than, or comparably well to, the competing methods.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Neural Hashing 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/xu2025harmonious/">Harmonious Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Harmonious Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Harmonious Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Xu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>49</td>
    <td><p>Hashing-based fast nearest neighbor search technique
has attracted great attention in both research
and industry areas recently. Many existing hashing
approaches encode data with projection-based hash
functions and represent each projected dimension
by 1-bit. However, the dimensions with high variance
hold large energy or information of data but
treated equivalently as dimensions with low variance,
which leads to a serious information loss. In
this paper, we introduce a novel hashing algorithm
called Harmonious Hashing which aims at learning
hash functions with low information loss. Specifically,
we learn a set of optimized projections to
preserve the maximum cumulative energy and meet
the constraint of equivalent variance on each dimension
as much as possible. In this way, we could
minimize the information loss after binarization.
Despite the extreme simplicity, our method outperforms
superiorly to many state-of-the-art hashing
methods in large-scale and high-dimensional nearest
neighbor search experiments.</p>
</td>
    <td>
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/xu2025convolutional/">Convolutional Neural Networks For Text Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Convolutional Neural Networks For Text Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Convolutional Neural Networks For Text Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Xu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>33</td>
    <td><p>Hashing, as a popular approximate nearest neighbor
search, has been widely used for large-scale similarity search. Recently, a spectrum of machine learning
methods are utilized to learn similarity-preserving
binary codes. However, most of them directly encode the explicit features, keywords, which fail to
preserve the accurate semantic similarities in binary code beyond keyword matching, especially on
short texts. Here we propose a novel text hashing
framework with convolutional neural networks. In
particular, we first embed the keyword features into
compact binary code with a locality preserving constraint. Meanwhile word features and position features are together fed into a convolutional network to
learn the implicit features which are further incorporated with the explicit features to fit the pre-trained
binary code. Such base method can be successfully
accomplished without any external tags/labels, and
other three model variations are designed to integrate tags/labels. Experimental results show the
superiority of our proposed approach over several
state-of-the-art hashing methods when tested on one
short text dataset as well as one normal text dataset.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Similarity Search 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/xiong2025adaptive/">Adaptive Quantization For Hashing: An Information-based Approach To Learning Binary Codes</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Adaptive Quantization For Hashing: An Information-based Approach To Learning Binary Codes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Adaptive Quantization For Hashing: An Information-based Approach To Learning Binary Codes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Xiong et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 2014 SIAM International Conference on Data Mining</td>
    <td>13</td>
    <td><p>Large-scale data mining and retrieval applications have
increasingly turned to compact binary data representations
as a way to achieve both fast queries and efficient
data storage; many algorithms have been proposed for
learning effective binary encodings. Most of these algorithms
focus on learning a set of projection hyperplanes
for the data and simply binarizing the result from each
hyperplane, but this neglects the fact that informativeness
may not be uniformly distributed across the projections.
In this paper, we address this issue by proposing
a novel adaptive quantization (AQ) strategy that
adaptively assigns varying numbers of bits to different
hyperplanes based on their information content. Our
method provides an information-based schema that preserves
the neighborhood structure of data points, and
we jointly find the globally optimal bit-allocation for
all hyperplanes. In our experiments, we compare with
state-of-the-art methods on four large-scale datasets
and find that our adaptive quantization approach significantly
improves on traditional hashing methods.</p>
</td>
    <td>
      
        Compact Codes 
      
        DATASETS 
      
        Hashing Methods 
      
        Quantization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/xia2025supervised/">Supervised Hashing Via Image Representation Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Supervised Hashing Via Image Representation Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Supervised Hashing Via Image Representation Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Xia et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>978</td>
    <td><p>Hashing is a popular approximate nearest neighbor
search approach for large-scale image retrieval.
Supervised hashing, which incorporates similarity/dissimilarity
information on entity pairs to improve
the quality of hashing function learning, has recently
received increasing attention. However, in the existing
supervised hashing methods for images, an input
image is usually encoded by a vector of hand-crafted
visual features. Such hand-crafted feature vectors
do not necessarily preserve the accurate semantic
similarities of images pairs, which may often degrade
the performance of hashing function learning. In this
paper, we propose a supervised hashing method for
image retrieval, in which we automatically learn a good
image representation tailored to hashing as well as a
set of hash functions. The proposed method has two
stages. In the first stage, given the pairwise similarity
matrix S over training images, we propose a scalable
coordinate descent method to decompose S into a
product of HHT where H is a matrix with each of its
rows being the approximate hash code associated to
a training image. In the second stage, we propose to
simultaneously learn a good feature representation for
the input images as well as a set of hash functions, via
a deep convolutional network tailored to the learned
hash codes in H and optionally the discrete class labels
of the images. Extensive empirical evaluations on three
benchmark datasets with different kinds of images
show that the proposed method has superior performance
gains over several state-of-the-art supervised
and unsupervised hashing methods.</p>
</td>
    <td>
      
        Image Retrieval 
      
        AAAI 
      
        DATASETS 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/wu2025deep/">Deep Incremental Hashing Network For Efficient Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Incremental Hashing Network For Efficient Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Incremental Hashing Network For Efficient Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>99</td>
    <td><p>Hashing has shown great potential in large-scale image retrieval due to its storage and computation efficiency, especially the recent deep supervised hashing methods. To achieve promising performance, deep supervised hashing methods require a large amount of training data from different classes. However, when images of new categories emerge, existing deep hashing methods have to retrain the CNN model and generate hash codes for all the database images again, which is impractical for large-scale retrieval system.
In this paper, we propose a novel deep hashing framework, called Deep Incremental Hashing Network (DIHN), for learning hash codes in an incremental manner. DIHN learns the hash codes for the new coming images directly, while keeping the old ones unchanged. Simultaneously, a deep hash function for query set is learned by preserving the similarities between training points. Extensive experiments on two widely used image retrieval benchmarks demonstrate that the proposed DIHN framework can significantly decrease the training time while keeping the state-of-the-art retrieval accuracy.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        CVPR 
      
        Neural Hashing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/weiss2025spectral/">Spectral Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Spectral Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Spectral Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Weiss Y., Torralba, Fergus</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>2154</td>
    <td><p>Semantic hashing seeks compact binary codes of data-points so that the
Hamming distance between codewords correlates with semantic similarity.
In this paper, we show that the problem of finding a best code for a given
dataset is closely related to the problem of graph partitioning and can
be shown to be NP hard. By relaxing the original problem, we obtain a
spectral method whose solutions are simply a subset of thresholded eigenvectors
of the graph Laplacian. By utilizing recent results on convergence
of graph Laplacian eigenvectors to the Laplace-Beltrami eigenfunctions of
manifolds, we show how to efficiently calculate the code of a novel datapoint.
Taken together, both learning the code and applying it to a novel
point are extremely simple. Our experiments show that our codes outperform
the state-of-the art.</p>
</td>
    <td>
      
        Compact Codes 
      
        Text Retrieval 
      
        Hashing Methods 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/weiss2025multidimensional/">Multidimensional Spectral Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Multidimensional Spectral Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Multidimensional Spectral Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Weiss Y., Fergus, Torralba</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>161</td>
    <td><p>en a surge of interest in methods based on â€œsemantic hashingâ€,
i.e. compact binary codes of data-points so that the Hamming distance
between codewords correlates with similarity. In reviewing and
comparing existing methods, we show that their relative performance can
change drastically depending on the definition of ground-truth neighbors.
Motivated by this finding, we propose a new formulation for learning binary
codes which seeks to reconstruct the affinity between datapoints,
rather than their distances. We show that this criterion is intractable
to solve exactly, but a spectral relaxation gives an algorithm where the
bits correspond to thresholded eigenvectors of the affinity matrix, and
as the number of datapoints goes to infinity these eigenvectors converge
to eigenfunctions of Laplace-Beltrami operators, similar to the recently
proposed Spectral Hashing (SH) method. Unlike SH whose performance
may degrade as the number of bits increases, the optimal code using
our formulation is guaranteed to faithfully reproduce the affinities as
the number of bits increases. We show that the number of eigenfunctions
needed may increase exponentially with dimension, but introduce a â€œkernel
trickâ€ to allow us to compute with an exponentially large number of
bits but using only memory and computation that grows linearly with
dimension. Experiments shows that MDSH outperforms the state-of-the
art, especially in the challenging regime of small distance thresholds.</p>
</td>
    <td>
      
        Survey Paper 
      
        Hashing Methods 
      
        Compact Codes 
      
        Text Retrieval 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/wang2025uncertainty/">Uncertainty-aware Unsupervised Video Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Uncertainty-aware Unsupervised Video Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Uncertainty-aware Unsupervised Video Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Image Processing</td>
    <td>48</td>
    <td><p>Learning to hash has become popular for video retrieval due to its fast speed and low storage consumption. Previous efforts formulate video hashing as training a binary auto-encoder, for which noncontinuous latent representations are optimized by the biased straight-through (ST) back-propagation heuristic. We propose to formulate video hashing as learning a discrete variational auto-encoder with the factorized Bernoulli latent distribution, termed as Bernoulli variational auto-encoder (BerVAE). The corresponding evidence lower bound (ELBO) in our BerVAE implementation leads to closed-form gradient expression, which can be applied to achieve principled training along with some other unbiased gradient estimators. BerVAE enables uncertainty-aware video hashing by predicting the probability distribution of video hash code-words, thus providing reliable uncertainty quantification. Experiments on both simulated and real-world large-scale video data demonstrate that our BerVAE trained with unbiased gradient estimators can achieve the state-of-the-art retrieval performance. Furthermore, we show that quantified uncertainty is highly correlated to video retrieval performance, which can be leveraged to further improve the retrieval accuracy. Our code is available at https://github.com/wangyucheng1234/BerVAE</p>
</td>
    <td>
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/wang2025semi/">Semi-supervised Deep Quantization For Cross-modal Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Semi-supervised Deep Quantization For Cross-modal Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Semi-supervised Deep Quantization For Cross-modal Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang Xin, Zhu, Liu</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 27th ACM International Conference on Multimedia</td>
    <td>12</td>
    <td><p>The problem of cross-modal similarity search, which aims at making efficient and accurate queries across multiple domains, has become a significant and important research topic. Composite quantization, a compact coding solution superior to hashing techniques, has shown its effectiveness for similarity search. However, most existing works utilizing composite quantization to search multi-domain content only consider either pairwise similarity information or class label information across different domains, which fails to tackle the semi-supervised problem in composite quantization. In this paper, we address the semi-supervised quantization problem by considering: (i) pairwise similarity information (without class label information) across different domains, which captures the intra-document relation, (ii) cross-domain data with class label which can help capture inter-document relation, and (iii) cross-domain data with neither pairwise similarity nor class label which enables the full use of abundant unlabelled information. To the best of our knowledge, we are the first to consider both supervised information (pairwise similarity + class label) and unsupervised information (neither pairwise similarity nor class label) simultaneously in composite quantization. A challenging problem arises: how can we jointly handle these three sorts of information across multiple domains in an efficient way? To tackle this challenge, we propose a novel semi-supervised deep quantization (SSDQ) model that takes both supervised and unsupervised information into account. The proposed SSDQ model is capable of incorporating the above three kinds of information into one single framework when utilizing composite quantization for accurate and efficient queries across different domains. More specifically, we employ a modified deep autoencoder for better latent representation and formulate pairwise similarity loss, supervised quantization loss as well as unsupervised distribution match loss to handle all three types of information. The extensive experiments demonstrate the significant improvement of SSDQ over several state-of-the-art methods on various datasets.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Similarity Search 
      
        Quantization 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/wang2025semantic/">Semantic Topic Multimodal Hashing For Cross-media Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Semantic Topic Multimodal Hashing For Cross-media Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Semantic Topic Multimodal Hashing For Cross-media Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang di, Gao, He</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>149</td>
    <td><p>Multimodal hashing is essential to cross-media
similarity search for its low storage cost and fast
query speed. Most existing multimodal hashing
methods embedded heterogeneous data into a common low-dimensional Hamming space, and then
rounded the continuous embeddings to obtain the
binary codes. Yet they usually neglect the inherent discrete nature of hashing for relaxing the discrete constraints, which will cause degraded retrieval performance especially for long codes. For
this purpose, a novel Semantic Topic Multimodal
Hashing (STMH) is developed by considering latent semantic information in coding procedure.
It
first discovers clustering patterns of texts and robust factorizes the matrix of images to obtain multiple semantic topics of texts and concepts of images.
Then the learned multimodal semantic features are
transformed into a common subspace by their correlations. Finally, each bit of unified hash code
can be generated directly by figuring out whether a
topic or concept is contained in a text or an image.
Therefore, the obtained model by STMH is more
suitable for hashing scheme as it directly learns discrete hash codes in the coding process. Experimental results demonstrate that the proposed method
outperforms several state-of-the-art methods.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/wang2025sequential/">Sequential Projection Learning For Hashing With Compact Codes</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Sequential Projection Learning For Hashing With Compact Codes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Sequential Projection Learning For Hashing With Compact Codes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang J., Kumar, Chang</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>328</td>
    <td><p>Hashing based Approximate Nearest Neighbor
(ANN) search has attracted much attention
due to its fast query time and drastically
reduced storage. However, most of the hashing
methods either use random projections or
extract principal directions from the data to
derive hash functions. The resulting embedding
suffers from poor discrimination when
compact codes are used. In this paper, we
propose a novel data-dependent projection
learning method such that each hash function
is designed to correct the errors made by
the previous one sequentially. The proposed
method easily adapts to both unsupervised
and semi-supervised scenarios and shows significant
performance gains over the state-ofthe-art
methods on two large datasets containing
up to 1 million points.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/wang2025affinity/">Affinity Preserving Quantization For Hashing: A Vector Quantization Approach To Learning Compact Binary Codes</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Affinity Preserving Quantization For Hashing: A Vector Quantization Approach To Learning Compact Binary Codes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Affinity Preserving Quantization For Hashing: A Vector Quantization Approach To Learning Compact Binary Codes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>11</td>
    <td><p>Hashing techniques are powerful for approximate nearest
neighbour (ANN) search. Existing quantization methods in
hashing are all focused on scalar quantization (SQ) which
is inferior in utilizing the inherent data distribution. In this
paper, we propose a novel vector quantization (VQ) method
named affinity preserving quantization (APQ) to improve the
quantization quality of projection values, which has significantly
boosted the performance of state-of-the-art hashing
techniques. In particular, our method incorporates the neighbourhood
structure in the pre- and post-projection data space
into vector quantization. APQ minimizes the quantization errors
of projection values as well as the loss of affinity property
of original space. An effective algorithm has been proposed
to solve the joint optimization problem in APQ, and
the extension to larger binary codes has been resolved by applying
product quantization to APQ. Extensive experiments
have shown that APQ consistently outperforms the state-of-the-art
quantization methods, and has significantly improved
the performance of various hashing techniques.</p>
</td>
    <td>
      
        AAAI 
      
        Hashing Methods 
      
        Compact Codes 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/wang2025hamming/">Hamming Compatible Quantization For Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hamming Compatible Quantization For Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hamming Compatible Quantization For Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>20</td>
    <td><p>Hashing is one of the effective techniques for fast
Approximate Nearest Neighbour (ANN) search.
Traditional single-bit quantization (SBQ) in most
hashing methods incurs lots of quantization error
which seriously degrades the search performance.
To address the limitation of SBQ, researchers have
proposed promising multi-bit quantization (MBQ)
methods to quantize each projection dimension
with multiple bits. However, some MBQ methods
need to adopt specific distance for binary code
matching instead of the original Hamming distance,
which would significantly decrease the retrieval
speed. Two typical MBQ methods Hierarchical
Quantization and Double Bit Quantization
retain the Hamming distance, but both of them only
consider the projection dimensions during quantization,
ignoring the neighborhood structure of raw
data inherent in Euclidean space. In this paper,
we propose a multi-bit quantization method named
Hamming Compatible Quantization (HCQ) to preserve
the capability of similarity metric between
Euclidean space and Hamming space by utilizing
the neighborhood structure of raw data. Extensive
experiment results have shown our approach significantly
improves the performance of various stateof-the-art
hashing methods while maintaining fast
retrieval speed.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        Compact Codes 
      
        Similarity Search 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/wang2025online/">Online Collective Matrix Factorization Hashing For Large-scale Cross-media Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Online Collective Matrix Factorization Hashing For Large-scale Cross-media Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Online Collective Matrix Factorization Hashing For Large-scale Cross-media Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</td>
    <td>47</td>
    <td><p>Cross-modal hashing has been widely investigated recently for its efficiency in large-scale cross-media retrieval. However, most existing cross-modal hashing methods learn hash functions in a batch-based learning mode. Such mode is not suitable for large-scale data sets due to the large memory consumption and loses its efficiency when training streaming data. Online cross-modal hashing can deal with the above problems by learning hash model in an online learning process. However, existing online cross-modal hashing methods cannot update hash codes of old data by the newly learned model. In this paper, we propose Online Collective Matrix Factorization Hashing (OCMFH) based on collective matrix factorization hashing (CMFH), which can adaptively update hash codes of old data according to dynamic changes of hash model without accessing to old data. Specifically, it learns discriminative hash codes for streaming data by collective matrix factorization in an online optimization scheme. Unlike conventional CMFH which needs to load the entire data points into memory, the proposed OCMFH retrains hash functions only by newly arriving data points. Meanwhile, it generates hash codes of new data and updates hash codes of old data by the latest updated hash model. In such way, hash codes of new data and old data are well-matched. Furthermore, a zero mean strategy is developed to solve the mean-varying problem in the online hash learning process. Extensive experiments on three benchmark data sets demonstrate the effectiveness and efficiency of OCMFH on online cross-media retrieval.</p>
</td>
    <td>
      
        SIGIR 
      
        Hashing Methods 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/wei2025net/">A-net: Learning Attribute-aware Hash Codes For Large-scale Fine-grained Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A-net: Learning Attribute-aware Hash Codes For Large-scale Fine-grained Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A-net: Learning Attribute-aware Hash Codes For Large-scale Fine-grained Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wei et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>7</td>
    <td><p>Our work focuses on tackling large-scale fine-grained image retrieval as ranking the images depicting the concept of interests (i.e., the same sub-category labels) highest based on the fine-grained details in the query. It is desirable to alleviate the challenges of both fine-grained nature of small inter-class variations with large intra-class variations and explosive growth of fine-grained data for such a practical task. In this paper, we propose an Attribute-Aware hashing Network (A-Net) for generating attribute-aware hash codes to not only make the retrieval process efficient, but also establish explicit correspondences between hash codes and visual attributes. Specifically, based on the captured visual representations by attention, we develop an encoder-decoder structure network of a reconstruction task to unsupervisedly distill high-level attribute-specific vectors from the appearance-specific visual representations without attribute annotations. A-Net is also equipped with a feature decorrelation constraint upon these attribute vectors to enhance their representation abilities. Finally, the required hash codes are generated by the attribute vectors driven by preserving original similarities. Qualitative experiments on five benchmark fine-grained datasets show our superiority over competing methods. More importantly, quantitative results demonstrate the obtained hash codes can strongly correspond to certain kinds of crucial properties of fine-grained objects.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/verma2025faster/">Faster And Space Efficient Indexing For Locality Sensitive Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Faster And Space Efficient Indexing For Locality Sensitive Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Faster And Space Efficient Indexing For Locality Sensitive Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Verma Bhisham Dev, Pratap Rameshwar</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 21st ACM international conference on Information and knowledge management</td>
    <td>52</td>
    <td><p>This work suggests faster and space-efficient index construction algorithms
for LSH for Euclidean distance (\textit{a.k.a.}~\ELSH) and cosine similarity
(\textit{a.k.a.}~\SRP). The index construction step of these LSHs relies on
grouping data points into several bins of hash tables based on their hashcode.
To generate an \(m\)-dimensional hashcode of the \(d\)-dimensional data point,
these LSHs first project the data point onto a \(d\)-dimensional random Gaussian
vector and then discretise the resulting inner product. The time and space
complexity of both \ELSH~and \SRP~for computing an \(m\)-sized hashcode of a
\(d\)-dimensional vector is \(O(md)\), which becomes impractical for large values
of \(m\) and \(d\). To overcome this problem, we propose two alternative LSH
hashcode generation algorithms both for Euclidean distance and cosine
similarity, namely, \CSELSH, \HCSELSH~and \CSSRP, \HCSSRP, respectively.
\CSELSH~and \CSSRP~are based on count sketch \cite{count_sketch} and
\HCSELSH~and \HCSSRP~utilize higher-order count sketch \cite{shi2019higher}.
These proposals significantly reduce the hashcode computation time from \(O(md)\)
to \(O(d)\). Additionally, both \CSELSH~and \CSSRP~reduce the space complexity
from \(O(md)\) to \(O(d)\); ~and \HCSELSH, \HCSSRP~ reduce the space complexity
from \(O(md)\) to \(O(N \sqrt[N]{d})\) respectively, where \(N\geq 1\) denotes the
size of the input/reshaped tensor. Our proposals are backed by strong
mathematical guarantees, and we validate their performance through simulations
on various real-world datasets.</p>
</td>
    <td>
      
        CIKM 
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        Alt 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/sun2025deep/">Deep Normalized Cross-modal Hashing With Bi-direction Relation Reasoning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Normalized Cross-modal Hashing With Bi-direction Relation Reasoning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Normalized Cross-modal Hashing With Bi-direction Relation Reasoning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Sun et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</td>
    <td>26</td>
    <td><p>Due to the continuous growth of large-scale multi-modal data and increasing requirements for retrieval speed, deep cross-modal hashing has gained increasing attention recently. Most of existing studies take a similarity matrix as supervision to optimize their models, and the inner product between continuous surrogates of hash codes is utilized to depict the similarity in the Hamming space. However, all of them merely consider the relevant information to build the similarity matrix, ignoring the contribution of the irrelevant one, i.e., the categories that samples do not belong to. Therefore, they cannot effectively alleviate the effect of dissimilar samples. Moreover, due to the modality distribution difference, directly utilizing continuous surrogates of hash codes to calculate similarity may induce suboptimal retrieval performance. To tackle these issues, in this paper, we propose a novel deep normalized cross-modal hashing scheme with bi-direction relation reasoning, named Bi_NCMH. Specifically, we build the multi-level semantic similarity matrix by considering bi-direction relation, i.e., consistent and inconsistent relation. It hence can holistically characterize relations among instances. Besides, we execute feature normalization on continuous surrogates of hash codes to eliminate the deviation caused by modality gap, which further reduces the negative impact of binarization on retrieval performance. Extensive experiments on two cross-modal benchmark datasets demonstrate the superiority of our model over several state-of-the-art baselines.</p>
</td>
    <td>
      
        CVPR 
      
        DATASETS 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/sun2025supervised/">Supervised Hierarchical Cross-modal Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Supervised Hierarchical Cross-modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Supervised Hierarchical Cross-modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Sun et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</td>
    <td>47</td>
    <td><p>Recently, due to the unprecedented growth of multimedia data,
cross-modal hashing has gained increasing attention for the
efficient cross-media retrieval. Typically, existing methods on crossmodal hashing treat labels of one instance independently but
overlook the correlations among labels. Indeed, in many real-world
scenarios, like the online fashion domain, instances (items) are
labeled with a set of categories correlated by certain hierarchy. In
this paper, we propose a new end-to-end solution for supervised
cross-modal hashing, named HiCHNet, which explicitly exploits the
hierarchical labels of instances. In particular, by the pre-established
label hierarchy, we comprehensively characterize each modality
of the instance with a set of layer-wise hash representations. In
essence, hash codes are encouraged to not only preserve the layerwise semantic similarities encoded by the label hierarchy, but also
retain the hierarchical discriminative capabilities. Due to the lack
of benchmark datasets, apart from adapting the existing dataset
FashionVC from fashion domain, we create a dataset from the
online fashion platform Ssense consisting of 15, 696 image-text
pairs labeled by 32 hierarchical categories. Extensive experiments
on two real-world datasets demonstrate the superiority of our model
over the state-of-the-art methods.</p>
</td>
    <td>
      
        SIGIR 
      
        Hashing Methods 
      
        Evaluation 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/subramanya2025diskann/">Diskann: Fast Accurate Billion-point Nearest Neighbor Search On A Single Node</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Diskann: Fast Accurate Billion-point Nearest Neighbor Search On A Single Node' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Diskann: Fast Accurate Billion-point Nearest Neighbor Search On A Single Node' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Subramanya et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>36</td>
    <td><p>Current state-of-the-art approximate nearest neighbor search (ANNS) algorithms generate indices that must be stored in main memory for fast high-recall search. This makes them expensive and limits the size of the dataset. We present a new graph-based indexing and search system called DiskANN that can index, store, and search a billion point database on a single workstation with just 64GB RAM and an inexpensive solid-state drive (SSD). Contrary to current wisdom, we demonstrate that the SSD-based indices built by DiskANN can meet all three desiderata for large-scale ANNS: high-recall, low query latency and high density (points indexed per node). On the billion point SIFT1B bigann dataset, DiskANN serves &gt; 5000 queries a second with &lt; 3ms mean latency and 95%+ 1-recall@1 on a 16 core machine, where state-of-the-art billion-point ANNS algorithms with similar memory footprint like FAISS and IVFOADC+G+P plateau at around 50% 1-recall@1. Alternately, in the high recall regime, DiskANN can index and serve 5 âˆ’ 10x more points per node compared to state-of-the-art graph- based methods such as HNSW and NSG. Finally, as part of our overall DiskANN system, we introduce Vamana, a new graph-based ANNS index that is more versatile than the graph indices even for in-memory indices.</p>
</td>
    <td>
      
        DATASETS 
      
        Graph Based ANN 
      
        Efficiency And Optimization 
      
        Alt 
      
        Vector Indexing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/su2025deep/">Deep Joint-semantics Reconstructing Hashing For Large-scale Unsupervised Cross-modal Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Joint-semantics Reconstructing Hashing For Large-scale Unsupervised Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Joint-semantics Reconstructing Hashing For Large-scale Unsupervised Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Su Shupeng, Zhong, Zhang</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE/CVF International Conference on Computer Vision (ICCV)</td>
    <td>255</td>
    <td><p><img src="https://github.com/zzs1994/DJSRH/blob/master/page_image/DJRSH.png?raw=true" alt="Deep Joint-Semantics Reconstructing Hashing for Large-Scale Unsupervised Cross-Modal Retrieval" title="Deep Joint-Semantics Reconstructing Hashing for Large-Scale Unsupervised Cross-Modal Retrieval" /></p>

<p>Cross-modal hashing encodes the multimedia data into a common binary hash space in which the correlations among the samples from different modalities can be effectively measured. Deep cross-modal hashing further improves the retrieval performance as the deep neural networks can generate more semantic relevant features and hash codes. In this paper, we study the unsupervised deep cross-modal hash coding and propose Deep Joint Semantics Reconstructing Hashing (DJSRH), which has the following two main advantages. First, to learn binary codes that preserve the neighborhood structure of the original data, DJSRH constructs a novel joint-semantics affinity matrix which elaborately integrates the original neighborhood information from different modalities and accordingly is capable to capture the latent intrinsic semantic affinity for the input multi-modal instances. Second, DJSRH later trains the networks to generate binary codes that maximally reconstruct above joint-semantics relations via the proposed reconstructing framework, which is more competent for the batch-wise training as it reconstructs the specific similarity value unlike the common Laplacian constraint merely preserving the similarity order. Extensive experiments demonstrate the significant improvement by DJSRH in various cross-modal retrieval tasks.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Compact Codes 
      
        ICCV 
      
        Multimodal Retrieval 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/su2025greedy/">Greedy Hash: Towards Fast Optimization For Accurate Hash Coding In CNN</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Greedy Hash: Towards Fast Optimization For Accurate Hash Coding In CNN' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Greedy Hash: Towards Fast Optimization For Accurate Hash Coding In CNN' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Su et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>114</td>
    <td><p>To convert the input into binary code, hashing algorithm has been widely used for approximate nearest neighbor search on large-scale image sets due to its computation and storage efficiency. Deep hashing further improves the retrieval quality by combining the hash coding with deep neural network. However, a major difficulty in deep hashing lies in the discrete constraints imposed on the network output, which generally makes the optimization NP hard. In this work, we adopt the greedy principle to tackle this NP hard problem by iteratively updating the network toward the probable optimal discrete solution in each iteration. A hash coding layer is designed to implement our approach which strictly uses the sign function in forward propagation to maintain the discrete constraints, while in back propagation the gradients are transmitted intactly to the front layer to avoid the vanishing gradients. In addition to the theoretical derivation, we provide a new perspective to visualize and understand the effectiveness and efficiency of our algorithm. Experiments on benchmark datasets show that our scheme outperforms state-of-the-art hashing methods in both supervised and unsupervised tasks.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Neural Hashing 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/sundaram2025streaming/">Streaming Similarity Search Over One Billion Tweets Using Parallel Locality-sensitive Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Streaming Similarity Search Over One Billion Tweets Using Parallel Locality-sensitive Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Streaming Similarity Search Over One Billion Tweets Using Parallel Locality-sensitive Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Sundaram et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the VLDB Endowment</td>
    <td>105</td>
    <td><p>Finding nearest neighbors has become an important operation on databases, with applications to text search, multimedia indexing,
and many other areas. One popular algorithm for similarity search, especially for high dimensional data (where spatial indexes like kdtrees do not perform well) is Locality Sensitive Hashing (LSH), an
approximation algorithm for finding similar objects. In this paper, we describe a new variant of LSH, called Parallel
LSH (PLSH) designed to be extremely efficient, capable of scaling out on multiple nodes and multiple cores, and which supports highthroughput streaming of new data. Our approach employs several
novel ideas, including: cache-conscious hash table layout, using a 2-level merge algorithm for hash table construction; an efficient
algorithm for duplicate elimination during hash-table querying; an insert-optimized hash table structure and efficient data expiration
algorithm for streaming data; and a performance model that accurately estimates performance of the algorithm and can be used to
optimize parameter settings. We show that on a workload where we perform similarity search on a dataset of &gt; 1 Billion tweets, with
hundreds of millions of new tweets per day, we can achieve query times of 1â€“2.5 ms. We show that this is an order of magnitude faster
than existing indexing schemes, such as inverted indexes. To the best of our knowledge, this is the fastest implementation of LSH,
with table construction times up to 3.7x faster and query times that are 8.3x faster than a basic implementation.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Text Retrieval 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/spaldingjamieson2025scalable/">Scalable K-means Clustering For Large K Via Seeded Approximate Nearest-neighbor Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Scalable K-means Clustering For Large K Via Seeded Approximate Nearest-neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Scalable K-means Clustering For Large K Via Seeded Approximate Nearest-neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Spalding-jamieson Jack, Robson Eliot Wong, Zheng da Wei</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Image Processing</td>
    <td>6</td>
    <td><p>For very large values of \(k\), we consider methods for fast \(k\)-means
clustering of massive datasets with \(10^7\sim10^9\) points in high-dimensions
(\(d\geq100\)). All current practical methods for this problem have runtimes at
least \(Î©(k^2)\). We find that initialization routines are not a bottleneck
for this case. Instead, it is critical to improve the speed of Lloydâ€™s
local-search algorithm, particularly the step that reassigns points to their
closest center. Attempting to improve this step naturally leads us to leverage
approximate nearest-neighbor search methods, although this alone is not enough
to be practical. Instead, we propose a family of problems we call â€œSeeded
Approximate Nearest-Neighbor Searchâ€, for which we propose â€œSeeded
Search-Graphâ€ methods as a solution.</p>
</td>
    <td>
      
        Alt 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/sonthalia2025rankability/">On The Rankability Of Visual Embeddings</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=On The Rankability Of Visual Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=On The Rankability Of Visual Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Sonthalia Ankit, Uselis Arnas, Oh Seong Joon</td> <!-- ðŸ”§ You were missing this -->
    <td>Neurocomputing</td>
    <td>22</td>
    <td><p>We study whether visual embedding models capture continuous, ordinal attributes along linear directions, which we term <em>rank axes</em>. We define a model as <em>rankable</em> for an attribute if projecting embeddings onto such an axis preserves the attributeâ€™s order. Across 7 popular encoders and 9 datasets with attributes like age, crowd count, head pose, aesthetics, and recency, we find that many embeddings are inherently rankable. Surprisingly, a small number of samples, or even just two extreme examples, often suffice to recover meaningful rank axes, without full-scale supervision. These findings open up new use cases for image ranking in vector databases and motivate further study into the structure and learning of rankable embeddings. Our code is available at https://github.com/aktsonthalia/rankable-vision-embeddings.</p>
</td>
    <td>
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/song2025inter/">Inter-media Hashing For Large-scale Retrieval From Heterogeneous Data Sources</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Inter-media Hashing For Large-scale Retrieval From Heterogeneous Data Sources' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Inter-media Hashing For Large-scale Retrieval From Heterogeneous Data Sources' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Song et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data</td>
    <td>619</td>
    <td><p>In this paper, we present a new multimedia retrieval paradigm to innovate large-scale search of heterogenous multimedia data. It is able to return results of different media types from heterogeneous data sources, e.g., using a query image to retrieve relevant text documents or images from different data sources. This utilizes the widely available data from different sources and caters for the current usersâ€™ demand of receiving a result list simultaneously containing multiple types of data to obtain a comprehensive understanding of the queryâ€™s results. To enable large-scale inter-media retrieval, we propose a novel inter-media hashing (IMH) model to explore the correlations among multiple media types from different data sources and tackle the scalability issue. To this end, multimedia data from heterogeneous data sources are transformed into a common Hamming space, in which fast search can be easily implemented by XOR and bit-count operations. Furthermore, we integrate a linear regression model to learn hashing functions so that the hash codes for new data points can be efficiently generated. Experiments conducted on real-world large-scale multimedia datasets demonstrate the superiority of our proposed method compared with state-of-the-art techniques.</p>
</td>
    <td>
      
        Large Scale Search 
      
        DATASETS 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/song2025top/">Top Rank Supervised Binary Coding For Visual Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Top Rank Supervised Binary Coding For Visual Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Top Rank Supervised Binary Coding For Visual Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Song et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2015 IEEE International Conference on Computer Vision (ICCV)</td>
    <td>76</td>
    <td><p>In recent years, binary coding techniques are becoming
increasingly popular because of their high efficiency in handling large-scale computer vision applications. It has been
demonstrated that supervised binary coding techniques that
leverage supervised information can significantly enhance
the coding quality, and hence greatly benefit visual search
tasks. Typically, a modern binary coding method seeks
to learn a group of coding functions which compress data
samples into binary codes. However, few methods pursued
the coding functions such that the precision at the top of
a ranking list according to Hamming distances of the generated binary codes is optimized.
In this paper, we propose a novel supervised binary coding approach, namely
Top Rank Supervised Binary Coding (Top-RSBC), which
explicitly focuses on optimizing the precision of top positions in a Hamming-distance ranking list towards preserving the supervision information. The core idea is to train
the disciplined coding functions, by which the mistakes at
the top of a Hamming-distance ranking list are penalized
more than those at the bottom. To solve such coding functions, we relax the original discrete optimization objective
with a continuous surrogate, and derive a stochastic gradient descent to optimize the surrogate objective. To further reduce the training time cost, we also design an online
learning algorithm to optimize the surrogate objective more
efficiently. Empirical studies based upon three benchmark
image datasets demonstrate that the proposed binary coding approach achieves superior image search accuracy over
the state-of-the-arts.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        ICCV 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/son2025fed/">FED: Fast And Efficient Dataset Deduplication Framework With GPU Acceleration</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=FED: Fast And Efficient Dataset Deduplication Framework With GPU Acceleration' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=FED: Fast And Efficient Dataset Deduplication Framework With GPU Acceleration' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Son Youngjun, Kim Chaewon, Lee Jaejin</td> <!-- ðŸ”§ You were missing this -->
    <td>2023 Design, Automation &amp; Test in Europe Conference &amp; Exhibition (DATE)</td>
    <td>12</td>
    <td><p>Dataset deduplication plays a crucial role in enhancing data quality,
ultimately improving the training performance and efficiency of large language
models. A commonly used method for data deduplication is the MinHash LSH
algorithm. Recently, NVIDIA introduced a GPU-based MinHash LSH deduplication
method, but it remains suboptimal, leaving room for further improvement in
processing efficiency. This paper proposes a GPU-accelerated deduplication
framework, FED, that optimizes MinHash LSH for GPU clusters and leverages
computationally efficient, partially reusable non-cryptographic hash functions.
FED significantly outperforms the CPU-based deduplication tool in SlimPajama
(using 64 logical CPU cores) by up to 107.2 times and the GPU-based tool in
NVIDIA NeMo Curator by up to 6.3 times when processing 30 million documents on
a node with four GPUs. Notably, our method dramatically accelerates the
previously time-consuming MinHash signature generation phase, achieving
speed-ups of up to 260 compared to the CPU baseline. Despite these gains in
efficiency, FED maintains high deduplication quality, with the duplicate
document sets reaching a Jaccard similarity of over 0.96 compared to those
identified by the standard MinHash algorithm. In large-scale experiments, the
deduplication of 1.2 trillion tokens is completed in just 6 hours in a
four-node, 16-GPU environment. The related code is publicly available on GitHub
(\href{https://github.com/mcrl/FED}{https://github.com/mcrl/FED}).</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/singhi2025provenance/">Provenance Detection For Ai-generated Images: Combining Perceptual Hashing, Homomorphic Encryption, And AI Detection Models</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Provenance Detection For Ai-generated Images: Combining Perceptual Hashing, Homomorphic Encryption, And AI Detection Models' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Provenance Detection For Ai-generated Images: Combining Perceptual Hashing, Homomorphic Encryption, And AI Detection Models' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Singhi et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2023 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)</td>
    <td>35</td>
    <td><p>As AI-generated sensitive images become more prevalent, identifying their
source is crucial for distinguishing them from real images. Conventional image
watermarking methods are vulnerable to common transformations like filters,
lossy compression, and screenshots, often applied during social media sharing.
Watermarks can also be faked or removed if models are open-sourced or leaked
since images can be rewatermarked. We have developed a three-part framework for
secure, transformation-resilient AI content provenance detection, to address
these limitations. We develop an adversarially robust state-of-the-art
perceptual hashing model, DinoHash, derived from DINOV2, which is robust to
common transformations like filters, compression, and crops. Additionally, we
integrate a Multi-Party Fully Homomorphic Encryption~(MP-FHE) scheme into our
proposed framework to ensure the protection of both user queries and registry
privacy. Furthermore, we improve previous work on AI-generated media detection.
This approach is useful in cases where the content is absent from our registry.
DinoHash significantly improves average bit accuracy by 12% over
state-of-the-art watermarking and perceptual hashing methods while maintaining
superior true positive rate (TPR) and false positive rate (FPR) tradeoffs
across various transformations. Our AI-generated media detection results show a
25% improvement in classification accuracy on commonly used real-world AI image
generators over existing algorithms. By combining perceptual hashing, MP-FHE,
and an AI content detection model, our proposed framework provides better
robustness and privacy compared to previous work.</p>
</td>
    <td>
      
        ICCV 
      
        Tools & Libraries 
      
        Hashing Methods 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/shrivastava2025densifying/">Densifying One Permutation Hashing Via Rotation For Fast Near Neighbor Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Densifying One Permutation Hashing Via Rotation For Fast Near Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Densifying One Permutation Hashing Via Rotation For Fast Near Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Shrivastava A., Li</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>86</td>
    <td><p>The query complexity of locality sensitive hashing
(LSH) based similarity search is dominated
by the number of hash evaluations, and this number
grows with the data size (Indyk &amp; Motwani,
1998). In industrial applications such as search
where the data are often high-dimensional and
binary (e.g., text n-grams), minwise hashing is
widely adopted, which requires applying a large
number of permutations on the data. This is
costly in computation and energy-consumption.
In this paper, we propose a hashing technique
which generates all the necessary hash evaluations
needed for similarity search, using one
single permutation. The heart of the proposed
hash function is a â€œrotationâ€ scheme which densifies
the sparse sketches of one permutation
hashing (Li et al., 2012) in an unbiased fashion
thereby maintaining the LSH property. This
makes the obtained sketches suitable for hash table
construction. This idea of rotation presented
in this paper could be of independent interest for
densifying other types of sparse sketches.
Using our proposed hashing method, the query
time of a (K, L)-parameterized LSH is reduced
from the typical O(dKL) complexity to merely
O(KL + dL), where d is the number of nonzeros
of the data vector, K is the number of hashes
in each hash table, and L is the number of hash
tables. Our experimental evaluation on real data
confirms that the proposed scheme significantly
reduces the query processing time over minwise
hashing without loss in retrieval accuracies.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Similarity Search 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/shrivastava2025asymmetric/">Asymmetric LSH (ALSH) For Sublinear Time Maximum Inner Product Search (MIPS).</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Asymmetric LSH (ALSH) For Sublinear Time Maximum Inner Product Search (MIPS).' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Asymmetric LSH (ALSH) For Sublinear Time Maximum Inner Product Search (MIPS).' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Shrivastava A., Li</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>268</td>
    <td><p>We present the first provably sublinear time hashing algorithm for approximate
Maximum Inner Product Search (MIPS). Searching with (un-normalized) inner
product as the underlying similarity measure is a known difficult problem and
finding hashing schemes for MIPS was considered hard. While the existing Locality
Sensitive Hashing (LSH) framework is insufficient for solving MIPS, in this
paper we extend the LSH framework to allow asymmetric hashing schemes. Our
proposal is based on a key observation that the problem of finding maximum inner
products, after independent asymmetric transformations, can be converted into
the problem of approximate near neighbor search in classical settings. This key
observation makes efficient sublinear hashing scheme for MIPS possible. Under
the extended asymmetric LSH (ALSH) framework, this paper provides an example
of explicit construction of provably fast hashing scheme for MIPS. Our proposed
algorithm is simple and easy to implement. The proposed hashing scheme
leads to significant computational savings over the two popular conventional LSH
schemes: (i) Sign Random Projection (SRP) and (ii) hashing based on p-stable
distributions for L2 norm (L2LSH), in the collaborative filtering task of item recommendations
on Netflix and Movielens (10M) datasets.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Recommender Systems 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/silavong2025deskew/">Deskew-lsh Based Code-to-code Recommendation Engine</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deskew-lsh Based Code-to-code Recommendation Engine' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deskew-lsh Based Code-to-code Recommendation Engine' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Silavong et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Recommendation Systems in Software Engineering</td>
    <td>16</td>
    <td><p>Machine learning on source code (MLOnCode) is a popular research field that has been driven by the availability of large-scale code repositories and the development of powerful probabilistic and deep learning models for mining source code. Code-to-code recommendation is a task in MLOnCode that aims to recommend relevant, diverse and concise code snippets that usefully extend the code currently being written by a developer in their development environment (IDE). Code-to-code recommendation engines hold the promise of increasing developer productivity by reducing context switching from the IDE and increasing code-reuse. Existing code-to-code recommendation engines do not scale gracefully to large codebases, exhibiting a linear growth in query time as the code repository increases in size. In addition, existing code-to-code recommendation engines fail to account for the global statistics of code repositories in the ranking function, such as the distribution of code snippet lengths, leading to sub-optimal retrieval results. We address both of these weaknesses with <em>Senatus</em>, a new code-to-code recommendation engine. At the core of Senatus is <em>De-Skew</em> LSH a new locality sensitive hashing (LSH) algorithm that indexes the data for fast (sub-linear time) retrieval while also counteracting the skewness in the snippet length distribution using novel abstract syntax tree-based feature scoring and selection algorithms. We evaluate Senatus via automatic evaluation and with an expert developer user study and find the recommendations to be of higher quality than competing baselines, while achieving faster search. For example, on the CodeSearchNet dataset we show that Senatus improves performance by 6.7% F1 and query time 16x is faster compared to Facebook Aroma on the task of code-to-code recommendation.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Recommender Systems 
      
        Tree Based ANN 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/shen2025unsupervised/">Unsupervised Deep Hashing With Similarity-adaptive And Discrete Optimization</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Unsupervised Deep Hashing With Similarity-adaptive And Discrete Optimization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Unsupervised Deep Hashing With Similarity-adaptive And Discrete Optimization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Shen et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Pattern Analysis and Machine Intelligence</td>
    <td>377</td>
    <td><p>Recent vision and learning studies show that learning compact hash codes can facilitate massive data processing
with significantly reduced storage and computation. Particularly, learning deep hash functions has greatly improved the retrieval
performance, typically under the semantic supervision. In contrast, current unsupervised deep hashing algorithms can hardly achieve
satisfactory performance due to either the relaxed optimization or absence of similarity-sensitive objective. In this work, we propose a
simple yet effective unsupervised hashing framework, named Similarity-Adaptive Deep Hashing (SADH), which alternatingly proceeds
over three training modules: deep hash model training, similarity graph updating and binary code optimization. The key difference from
the widely-used two-step hashing method is that the output representations of the learned deep model help update the similarity graph
matrix, which is then used to improve the subsequent code optimization. In addition, for producing high-quality binary codes, we devise
an effective discrete optimization algorithm which can directly handle the binary constraints with a general hashing loss. Extensive
experiments validate the efficacy of SADH, which consistently outperforms the state-of-the-arts by large gaps.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Compact Codes 
      
        Alt 
      
        Neural Hashing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/salakhutdinov2025semantic/">Semantic Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Semantic Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Semantic Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Salakhutdinov R., Hinton</td> <!-- ðŸ”§ You were missing this -->
    <td>International Journal of Approximate Reasoning</td>
    <td>1272</td>
    <td><p>We show how to learn a deep graphical model of the word-count
vectors obtained from a large set of documents. The values of the
latent variables in the deepest layer are easy to infer and give a
much better representation of each document than Latent Semantic
Analysis. When the deepest layer is forced to use a small number of
binary variables (e.g. 32), the graphical model performs â€œsemantic
hashingâ€: Documents are mapped to memory addresses in such a
way that semantically similar documents are located at nearby addresses.
Documents similar to a query document can then be found
by simply accessing all the addresses that differ by only a few bits
from the address of the query document. This way of extending the
efficiency of hash-coding to approximate matching is much faster
than locality sensitive hashing, which is the fastest current method.
By using semantic hashing to filter the documents given to TF-IDF,
we achieve higher accuracy than applying TF-IDF to the entire document
set.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Text Retrieval 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/zhang2025large/">Large-scale Supervised Multimodal Hashing With Semantic Correlation Maximization</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Large-scale Supervised Multimodal Hashing With Semantic Correlation Maximization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Large-scale Supervised Multimodal Hashing With Semantic Correlation Maximization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang D., Li</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>619</td>
    <td><p>Due to its low storage cost and fast query speed, hashing
has been widely adopted for similarity search in multimedia
data. In particular, more and more attentions
have been payed to multimodal hashing for search in
multimedia data with multiple modalities, such as images
with tags. Typically, supervised information of semantic
labels is also available for the data points in
many real applications. Hence, many supervised multimodal
hashing (SMH) methods have been proposed
to utilize such semantic labels to further improve the
search accuracy. However, the training time complexity
of most existing SMH methods is too high, which
makes them unscalable to large-scale datasets. In this
paper, a novel SMH method, called semantic correlation
maximization (SCM), is proposed to seamlessly integrate
semantic labels into the hashing learning procedure
for large-scale data modeling. Experimental results
on two real-world datasets show that SCM can signifi-
cantly outperform the state-of-the-art SMH methods, in
terms of both accuracy and scalability.</p>
</td>
    <td>
      
        AAAI 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Similarity Search 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/zhang2025high/">High-order Nonlocal Hashing For Unsupervised Cross-modal Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=High-order Nonlocal Hashing For Unsupervised Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=High-order Nonlocal Hashing For Unsupervised Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>World Wide Web</td>
    <td>60</td>
    <td><p>In light of the ability to enable efficient storage and fast query for big data, hashing techniques for cross-modal search have aroused extensive attention. Despite the great success achieved, unsupervised cross-modal hashing still suffers from lacking reliable similarity supervision and struggles with handling the heterogeneity issue between different modalities. To cope with these, in this paper, we devise a new deep hashing model, termed as High-order Nonlocal Hashing (HNH) to facilitate cross-modal retrieval with the following advantages. First, different from existing methods that mainly leverage low-level local-view similarity as the guidance for hashing learning, we propose a high-order affinity measure that considers the multi-modal neighbourhood structures from a nonlocal perspective, thereby comprehensively capturing the similarity relationships between data items. Second, a common representation is introduced to correlate different modalities. By enforcing the modal-specific descriptors and the common representation to be aligned with each other, the proposed HNH significantly bridges the modality gap and maintains the intra-consistency. Third, an effective affinity preserving objective function is delicately designed to generate high-quality binary codes. Extensive experiments evidence the superiority of the proposed HNH in unsupervised cross-modal retrieval tasks over the state-of-the-art baselines.</p>
</td>
    <td>
      
        Compact Codes 
      
        Multimodal Retrieval 
      
        Neural Hashing 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/zhang2025self/">Self-taught Hashing For Fast Similarity Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Self-taught Hashing For Fast Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Self-taught Hashing For Fast Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval</td>
    <td>352</td>
    <td><p>The ability of fast similarity search at large scale is of great
importance to many Information Retrieval (IR) applications.
A promising way to accelerate similarity search is semantic
hashing which designs compact binary codes for a large number
of documents so that semantically similar documents
are mapped to similar codes (within a short Hamming distance).
Although some recently proposed techniques are
able to generate high-quality codes for documents known
in advance, obtaining the codes for previously unseen documents
remains to be a very challenging problem. In this
paper, we emphasise this issue and propose a novel SelfTaught
Hashing (STH) approach to semantic hashing: we
first find the optimal l-bit binary codes for all documents in
the given corpus via unsupervised learning, and then train
l classifiers via supervised learning to predict the l-bit code
for any query document unseen before. Our experiments on
three real-world text datasets show that the proposed approach
using binarised Laplacian Eigenmap (LapEig) and
linear Support Vector Machine (SVM) outperforms stateof-the-art
techniques significantly.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Alt 
      
        Text Retrieval 
      
        SIGIR 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/zhang2025efficient/">Efficient Training Of Very Deep Neural Networks For Supervised Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Efficient Training Of Very Deep Neural Networks For Supervised Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Efficient Training Of Very Deep Neural Networks For Supervised Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang Ziming, Chen, Saligrama</td> <!-- ðŸ”§ You were missing this -->
    <td>2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>111</td>
    <td><p>In this paper, we propose training very deep neural networks (DNNs) for supervised learning of hash codes. Existing methods in this context train relatively â€œshallowâ€ networks limited by the issues arising in back propagation (e.e. vanishing gradients) as well as computational efficiency. We propose a novel and efficient training algorithm inspired by alternating direction method of multipliers (ADMM) that overcomes some of these limitations. Our method decomposes the training process into independent layer-wise local updates through auxiliary variables. Empirically we observe that our training algorithm always converges and its computational complexity is linearly proportional to the number of edges in the networks. Empirically we manage to train DNNs with 64 hidden layers and 1024 nodes per layer for supervised hashing in about 3 hours using a single GPU. Our proposed very deep supervised hashing (VDSH) method significantly outperforms the state-of-the-art on several benchmark datasets.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        CVPR 
      
        Alt 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/zhang2025deep/">Deep Center-based Dual-constrained Hashing For Discriminative Face Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Center-based Dual-constrained Hashing For Discriminative Face Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Center-based Dual-constrained Hashing For Discriminative Face Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang Ming, Zhe, Yan</td> <!-- ðŸ”§ You were missing this -->
    <td>Pattern Recognition</td>
    <td>21</td>
    <td><p>With the advantages of low storage cost and extremely fast retrieval speed, deep hashing methods have attracted much attention for image retrieval recently. However, large-scale face image retrieval with significant intra-class variations is still challenging. Neither existing pairwise/triplet labels-based nor softmax classification loss-based deep hashing works can generate compact and discriminative binary codes. Considering these issues, we propose a center-based framework integrating end-to-end hashing learning and class centers learning simultaneously. The framework minimizes the intra-class variance by clustering intra-class samples into a learnable class center. To strengthen inter-class separability, it additionally imposes a novel regularization term to enlarge the Hamming distance between pairwise class centers. Moreover, a simple yet effective regression matrix is introduced to encourage intra-class samples to generate the same binary codes, which further enhances the hashing codes compactness. Experiments on four large-scale datasets show the proposed method outperforms state-of-the-art baselines under various code lengths and commonly-used evaluation metrics.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        CVPR 
      
        Compact Codes 
      
        Neural Hashing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/zhang2025composite/">Composite Hashing With Multiple Information Sources</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Composite Hashing With Multiple Information Sources' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Composite Hashing With Multiple Information Sources' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang D., Wang, Si</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval</td>
    <td>221</td>
    <td><p>Similarity search applications with a large amount of text
and image data demands an efficient and effective solution.
One useful strategy is to represent the examples in databases
as compact binary codes through semantic hashing, which
has attracted much attention due to its fast query/search
speed and drastically reduced storage requirement. All of
the current semantic hashing methods only deal with the
case when each example is represented by one type of features.
However, examples are often described from several
different information sources in many real world applications.
For example, the characteristics of a webpage can be
derived from both its content part and its associated links.
To address the problem of learning good hashing codes in
this scenario, we propose a novel research problem â€“ Composite
Hashing with Multiple Information Sources (CHMIS).
The focus of the new research problem is to design an algorithm
for incorporating the features from different information
sources into the binary hashing codes efficiently and
effectively. In particular, we propose an algorithm CHMISAW
(CHMIS with Adjusted Weights) for learning the codes.
The proposed algorithm integrates information from several
different sources into the binary hashing codes by adjusting
the weights on each individual source for maximizing
the coding performance, and enables fast conversion from
query examples to their binary hashing codes. Experimental
results on five different datasets demonstrate the superior
performance of the proposed method against several other
state-of-the-art semantic hashing techniques.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Text Retrieval 
      
        SIGIR 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/zhang2025discrete/">Discrete Scale-invariant Metric Learning For Efficient Collaborative Filtering</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Discrete Scale-invariant Metric Learning For Efficient Collaborative Filtering' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Discrete Scale-invariant Metric Learning For Efficient Collaborative Filtering' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Information Retrieval</td>
    <td>32</td>
    <td><p>Metric learning has attracted extensive interest for its ability to provide personalized recommendations based on the importance of observed user-item interactions. Current metric learning methods aim to push negative items away from the corresponding users and positive items by an absolute geometrical distance margin. However, items may come from imbalanced categories with different intra-class variations. Thus, the absolute distance margin may not be ideal for estimating the difference between user preferences over imbalanced items. To this end, we propose a new method, named discrete scale-invariant metric learning (DSIML), by adding binary constraints to users and items, which maps users and items into binary codes of a shared Hamming subspace to speed up the online recommendation. Specifically, we firstly propose a scale-invariant margin based on angles at the negative item points in the shared Hamming subspace. Then, we derive a scale-invariant triple hinge loss based on the margin. To capture more preference difference information, we integrate a pairwise ranking loss into the scale-invariant loss in the proposed model. Due to the difficulty of directly optimizing the mixed integer optimization problem formulated with \textit{log-sum-exp} functions, we seek to optimize its variational quadratic upper bound and learn hash codes with an alternating optimization strategy. Experiments on benchmark datasets clearly show that our proposed method is superior to competitive metric learning and hashing-based baselines for recommender systems. The implementation code is available at https://github.com/AnonyFeb/dsml.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        Compact Codes 
      
        Alt 
      
        Recommender Systems 
      
        SIGIR 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/zhang2025fast/">Fast Discrete Cross-modal Hashing Based On Label Relaxation And Matrix Factorization</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fast Discrete Cross-modal Hashing Based On Label Relaxation And Matrix Factorization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fast Discrete Cross-modal Hashing Based On Label Relaxation And Matrix Factorization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2020 25th International Conference on Pattern Recognition (ICPR)</td>
    <td>9</td>
    <td><p>In recent years, cross-media retrieval has drawn considerable attention due to the exponential growth of multimedia data. Many hashing approaches have been proposed for the cross-media search task. However, there are still open problems that warrant investigation. For example, most existing supervised hashing approaches employ a binary label matrix, which achieves small margins between wrong labels (0) and true labels (1). This may affect the retrieval performance by generating many false negatives and false positives. In addition, some methods adopt a relaxation scheme to solve the binary constraints, which may cause large quantization errors. There are also some discrete hashing methods that have been presented, but most of them are time-consuming. To conquer these problems, we present a label relaxation and discrete matrix factorization method (LRMF) for cross-modal retrieval. It offers a number of innovations. First of all, the proposed approach employs a novel label relaxation scheme to control the margins adaptively, which has the benefit of reducing the quantization error. Second, by virtue of the proposed discrete matrix factorization method designed to learn the binary codes, large quantization errors caused by relaxation can be avoided. The experimental results obtained on two widely-used databases demonstrate that LRMF outperforms state-of-the-art cross-media methods.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Compact Codes 
      
        Multimodal Retrieval 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/zhang2025supervised/">Supervised Hashing With Latent Factor Models</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Supervised Hashing With Latent Factor Models' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Supervised Hashing With Latent Factor Models' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 37th international ACM SIGIR conference on Research &amp; development in information retrieval</td>
    <td>285</td>
    <td><p>Due to its low storage cost and fast query speed, hashing
has been widely adopted for approximate nearest neighbor
search in large-scale datasets. Traditional hashing methods
try to learn the hash codes in an unsupervised way where
the metric (Euclidean) structure of the training data is preserved.
Very recently, supervised hashing methods, which
try to preserve the semantic structure constructed from the
semantic labels of the training points, have exhibited higher
accuracy than unsupervised methods. In this paper, we
propose a novel supervised hashing method, called latent
factor hashing (LFH), to learn similarity-preserving binary
codes based on latent factor models. An algorithm with
convergence guarantee is proposed to learn the parameters
of LFH. Furthermore, a linear-time variant with stochastic
learning is proposed for training LFH on large-scale datasets.
Experimental results on two large datasets with semantic
labels show that LFH can achieve superior accuracy than
state-of-the-art methods with comparable training time.</p>
</td>
    <td>
      
        Efficiency And Optimization 
      
        DATASETS 
      
        SIGIR 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/zhang2025binary/">Binary Code Ranking With Weighted Hamming Distance</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Binary Code Ranking With Weighted Hamming Distance' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Binary Code Ranking With Weighted Hamming Distance' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2013 IEEE Conference on Computer Vision and Pattern Recognition</td>
    <td>98</td>
    <td><p>Binary hashing has been widely used for efficient similarity search due to its query and storage efficiency. In most
existing binary hashing methods, the high-dimensional data are embedded into Hamming space and the distance or
similarity of two points are approximated by the Hamming
distance between their binary codes. The Hamming distance calculation is efficient, however, in practice, there are
often lots of results sharing the same Hamming distance to
a query, which makes this distance measure ambiguous and
poses a critical issue for similarity search where ranking is
important. In this paper, we propose a weighted Hamming
distance ranking algorithm (WhRank) to rank the binary
codes of hashing methods. By assigning different bit-level
weights to different hash bits, the returned binary codes
are ranked at a finer-grained binary code level. We give
an algorithm to learn the data-adaptive and query-sensitive
weight for each hash bit. Evaluations on two large-scale
image data sets demonstrate the efficacy of our weighted
Hamming distance for binary code ranking.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        CVPR 
      
        Compact Codes 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/zhang2025bit/">Bit-scalable Deep Hashing With Regularized Similarity Learning For Image Retrieval And Person Re-identification</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Bit-scalable Deep Hashing With Regularized Similarity Learning For Image Retrieval And Person Re-identification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Bit-scalable Deep Hashing With Regularized Similarity Learning For Image Retrieval And Person Re-identification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Image Processing</td>
    <td>418</td>
    <td><p>Extracting informative image features and learning
effective approximate hashing functions are two crucial steps in
image retrieval . Conventional methods often study these two
steps separately, e.g., learning hash functions from a predefined
hand-crafted feature space. Meanwhile, the bit lengths of output
hashing codes are preset in most previous methods, neglecting the
significance level of different bits and restricting their practical
flexibility. To address these issues, we propose a supervised
learning framework to generate compact and bit-scalable hashing
codes directly from raw images. We pose hashing learning as
a problem of regularized similarity learning. Specifically, we
organize the training images into a batch of triplet samples,
each sample containing two images with the same label and one
with a different label. With these triplet samples, we maximize
the margin between matched pairs and mismatched pairs in the
Hamming space. In addition, a regularization term is introduced
to enforce the adjacency consistency, i.e., images of similar
appearances should have similar codes. The deep convolutional
neural network is utilized to train the model in an end-to-end
fashion, where discriminative image features and hash functions
are simultaneously optimized. Furthermore, each bit of our
hashing codes is unequally weighted so that we can manipulate
the code lengths by truncating the insignificant bits. Our
framework outperforms state-of-the-arts on public benchmarks
of similar image search and also achieves promising results in
the application of person re-identification in surveillance. It is
also shown that the generated bit-scalable hashing codes well
preserve the discriminative powers with shorter code lengths.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Neural Hashing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/yuan2025central/">Central Similarity Hashing For Efficient Image And Video Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Central Similarity Hashing For Efficient Image And Video Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Central Similarity Hashing For Efficient Image And Video Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yuan et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>264</td>
    <td><p>Existing data-dependent hashing methods usually learn
hash functions from the pairwise or triplet data relationships, which only capture the data similarity locally, and
often suffer low learning efficiency and low collision rate.
In this work, we propose a new global similarity metric,
termed as central similarity, with which the hash codes for
similar data pairs are encouraged to approach a common
center and those for dissimilar pairs to converge to different centers, to improve hash learning efficiency and retrieval accuracy. We principally formulate the computation of the proposed central similarity metric by introducing a new concept, i.e. hash center that refers to a set
of data points scattered in the Hamming space with sufficient mutual distance between each other. We then provide an efficient method to construct well separated hash
centers by leveraging the Hadamard matrix and Bernoulli
distributions. Finally, we propose the Central Similarity
Hashing (CSH) that optimizes the central similarity between data points w.r.t. their hash centers instead of optimizing the local similarity. The CSH is generic and applicable to both image and video hashing. Extensive experiments on large-scale image and video retrieval demonstrate CSH can generate cohesive hash codes for similar
data pairs and dispersed hash codes for dissimilar pairs,
and achieve noticeable boost in retrieval performance, i.e.
3%-20% in mAP over the previous state-of-the-art. The
codes are in: https://github.com/yuanli2333/
Hadamard-Matrix-for-hashing</p>
</td>
    <td>
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        Efficiency And Optimization 
      
        CVPR 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/yuan2025neighbor/">Neighbor-based Feature And Index Enhancement For Person Re-identification</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Neighbor-based Feature And Index Enhancement For Person Re-identification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Neighbor-based Feature And Index Enhancement For Person Re-identification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yuan Chao, Zhang Tianyi, Niu Guanglin</td> <!-- ðŸ”§ You were missing this -->
    <td>Expert Systems with Applications</td>
    <td>28</td>
    <td><p>Person re-identification (Re-ID) aims to match the same pedestrian in a large
gallery with different cameras and views. Enhancing the robustness of the
extracted feature representations is a main challenge in Re-ID. Existing
methods usually improve feature representation by improving model architecture,
but most methods ignore the potential contextual information, which limits the
effectiveness of feature representation and retrieval performance. Neighborhood
information, especially the potential information of multi-order neighborhoods,
can effectively enrich feature expression and improve retrieval accuracy, but
this has not been fully explored in existing research. Therefore, we propose a
novel model DMON-ARO that leverages latent neighborhood information to enhance
both feature representation and index performance. Our approach is built on two
complementary modules: Dynamic Multi-Order Neighbor Modeling (DMON) and
Asymmetric Relationship Optimization (ARO). The DMON module dynamically
aggregates multi-order neighbor relationships, allowing it to capture richer
contextual information and enhance feature representation through adaptive
neighborhood modeling. Meanwhile, ARO refines the distance matrix by optimizing
query-to-gallery relationships, improving the index accuracy. Extensive
experiments on three benchmark datasets demonstrate that our approach achieves
performance improvements against baseline models, which illustrate the
effectiveness of our model. Specifically, our model demonstrates improvements
in Rank-1 accuracy and mAP. Moreover, this method can also be directly extended
to other re-identification tasks.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/yu2025circulant/">Circulant Binary Embedding</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Circulant Binary Embedding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Circulant Binary Embedding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>132</td>
    <td><p>Binary embedding of high-dimensional data requires
long codes to preserve the discriminative
power of the input space. Traditional binary coding
methods often suffer from very high computation
and storage costs in such a scenario. To
address this problem, we propose Circulant Binary
Embedding (CBE) which generates binary
codes by projecting the data with a circulant matrix.
The circulant structure enables the use of
Fast Fourier Transformation to speed up the computation.
Compared to methods that use unstructured
matrices, the proposed method improves
the time complexity from O(d^2
) to O(d log d),
and the space complexity from O(d^2) to O(d)
where d is the input dimensionality. We also
propose a novel time-frequency alternating optimization
to learn data-dependent circulant projections,
which alternatively minimizes the objective
in original and Fourier domains. We show
by extensive experiments that the proposed approach
gives much better performance than the
state-of-the-art approaches for fixed time, and
provides much faster computation with no performance
degradation for fixed number of bits.</p>
</td>
    <td>
      
        Alt 
      
        Hashing Methods 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/yu2025deep/">Deep Graph-neighbor Coherence Preserving Network For Unsupervised Cross-modal Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Graph-neighbor Coherence Preserving Network For Unsupervised Cross-modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Graph-neighbor Coherence Preserving Network For Unsupervised Cross-modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>136</td>
    <td><p>Unsupervised cross-modal hashing (UCMH) has become a hot topic recently. Current UCMH focuses on exploring data similarities. However, current UCMH methods calculate the similarity between two data, mainly relying on the two dataâ€™s cross-modal features. These methods suffer from inaccurate similarity problems that result in a suboptimal retrieval Hamming space, because the cross-modal features between the data are not sufficient to describe the complex data relationships, such as situations where two data have different feature representations but share the inherent concepts. In this paper, we devise a deep graph-neighbor coherence preserving network (DGCPN). Specifically, DGCPN stems from graph models and explores graph-neighbor coherence by consolidating the information between data and their neighbors. DGCPN regulates comprehensive similarity preserving losses by exploiting three types of data similarities (i.e., the graph-neighbor coherence, the coexistent similarity, and the intra- and inter-modality consistency) and designs a half-real and half-binary optimization strategy to reduce the quantization errors during hashing. Essentially, DGCPN addresses the inaccurate similarity problem by exploring and exploiting the dataâ€™s intrinsic relationships in a graph. We conduct extensive experiments on three public UCMH datasets. The experimental results demonstrate the superiority of DGCPN, e.g., by improving the mean average precision from 0.722 to 0.751 on MIRFlickr-25K using 64-bit hashing codes to retrieval texts from images. We will release the source code package and the trained model on https://github.com/Atmegal/DGCPN.</p>
</td>
    <td>
      
        AAAI 
      
        DATASETS 
      
        Hashing Methods 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/yuan2025towards/">Towards Optimal Deep Hashing Via Policy Gradient</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Towards Optimal Deep Hashing Via Policy Gradient' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Towards Optimal Deep Hashing Via Policy Gradient' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yuan et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>27</td>
    <td><p>In this paper, we propose a simple yet effective relaxation free method to learn more effective binary codes via policy gradient for
scalable image search. While a variety of deep hashing methods have been
proposed in recent years, most of them are confronted by the dilemma
to obtain optimal binary codes in a truly end-to-end manner with nonsmooth sign activations. Unlike existing methods which usually employ a
general relaxation framework to adapt to the gradient-based algorithms,
our approach formulates the non-smooth part of the hashing network
as sampling with a stochastic policy, so that the retrieval performance
degradation caused by the relaxation can be avoided. Specifically, our
method directly generates the binary codes and maximizes the expectation of rewards for similarity preservation, where the network can be
trained directly via policy gradient. Hence, the differentiation challenge
for discrete optimization can be naturally addressed, which leads to effective gradients and binary codes. Extensive experimental results on three
benchmark datasets validate the effectiveness of the proposed method.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Neural Hashing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/zhen2025co/">Co-regularized Hashing For Multimodal Data</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Co-regularized Hashing For Multimodal Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Co-regularized Hashing For Multimodal Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhen Y., Yeung</td> <!-- ðŸ”§ You were missing this -->
    <td>No Venue</td>
    <td>195</td>
    <td><p>Hashing-based methods provide a very promising approach to large-scale similarity
search. To obtain compact hash codes, a recent trend seeks to learn the hash
functions from data automatically. In this paper, we study hash function learning
in the context of multimodal data. We propose a novel multimodal hash function
learning method, called Co-Regularized Hashing (CRH), based on a boosted coregularization
framework. The hash functions for each bit of the hash codes are
learned by solving DC (difference of convex functions) programs, while the learning
for multiple bits proceeds via a boosting procedure so that the bias introduced
by the hash functions can be sequentially minimized. We empirically compare
CRH with two state-of-the-art multimodal hash function learning methods on two
publicly available data sets.</p>
</td>
    <td>
      
        Tools & Libraries 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/zheng2025enhancing/">Enhancing Embedding Representation Stability In Recommendation Systems With Semantic ID</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Enhancing Embedding Representation Stability In Recommendation Systems With Semantic ID' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Enhancing Embedding Representation Stability In Recommendation Systems With Semantic ID' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zheng et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Companion Proceedings of the ACM Web Conference 2024</td>
    <td>16</td>
    <td><p>The exponential growth of online content has posed significant challenges to
ID-based models in industrial recommendation systems, ranging from extremely
high cardinality and dynamically growing ID space, to highly skewed engagement
distributions, to prediction instability as a result of natural id life cycles
(e.g, the birth of new IDs and retirement of old IDs). To address these issues,
many systems rely on random hashing to handle the id space and control the
corresponding model parameters (i.e embedding table). However, this approach
introduces data pollution from multiple ids sharing the same embedding, leading
to degraded model performance and embedding representation instability.
  This paper examines these challenges and introduces Semantic ID prefix ngram,
a novel token parameterization technique that significantly improves the
performance of the original Semantic ID. Semantic ID prefix ngram creates
semantically meaningful collisions by hierarchically clustering items based on
their content embeddings, as opposed to random assignments. Through extensive
experimentation, we demonstrate that Semantic ID prefix ngram not only
addresses embedding instability but also significantly improves tail id
modeling, reduces overfitting, and mitigates representation shifts. We further
highlight the advantages of Semantic ID prefix ngram in attention-based models
that contextualize user histories, showing substantial performance
improvements. We also report our experience of integrating Semantic ID into
Meta production Ads Ranking system, leading to notable performance gains and
enhanced prediction stability in live deployments.</p>
</td>
    <td>
      
        Recommender Systems 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/zhao2025note/">A Note On Efficient Privacy-preserving Similarity Search For Encrypted Vectors</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Note On Efficient Privacy-preserving Similarity Search For Encrypted Vectors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Note On Efficient Privacy-preserving Similarity Search For Encrypted Vectors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhao Dongfang</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Dependable and Secure Computing</td>
    <td>26</td>
    <td><p>Traditional approaches to vector similarity search over encrypted data rely
on fully homomorphic encryption (FHE) to enable computation without decryption.
However, the substantial computational overhead of FHE makes it impractical for
large-scale real-time applications. This work explores a more efficient
alternative: using additively homomorphic encryption (AHE) for
privacy-preserving similarity search. We consider scenarios where either the
query vector or the database vectors remain encrypted, a setting that
frequently arises in applications such as confidential recommender systems and
secure federated learning. While AHE only supports addition and scalar
multiplication, we show that it is sufficient to compute inner product
similarityâ€“one of the most widely used similarity measures in vector
retrieval. Compared to FHE-based solutions, our approach significantly reduces
computational overhead by avoiding ciphertext-ciphertext multiplications and
bootstrapping, while still preserving correctness and privacy. We present an
efficient algorithm for encrypted similarity search under AHE and analyze its
error growth and security implications. Our method provides a scalable and
practical solution for privacy-preserving vector search in real-world machine
learning applications.</p>
</td>
    <td>
      
        Alt 
      
        Similarity Search 
      
        Recommender Systems 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/zhao2025deep/">Deep Semantic Ranking Based Hashing For Multi-label Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Semantic Ranking Based Hashing For Multi-label Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Semantic Ranking Based Hashing For Multi-label Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhao et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>463</td>
    <td><p>With the rapid growth of web images, hashing has received
increasing interests in large scale image retrieval.
Research efforts have been devoted to learning compact binary
codes that preserve semantic similarity based on labels.
However, most of these hashing methods are designed
to handle simple binary similarity. The complex multilevel
semantic structure of images associated with multiple labels
have not yet been well explored. Here we propose a deep
semantic ranking based method for learning hash functions
that preserve multilevel semantic similarity between multilabel
images. In our approach, deep convolutional neural
network is incorporated into hash functions to jointly
learn feature representations and mappings from them to
hash codes, which avoids the limitation of semantic representation
power of hand-crafted features. Meanwhile, a
ranking list that encodes the multilevel similarity information
is employed to guide the learning of such deep hash
functions. An effective scheme based on surrogate loss is
used to solve the intractable optimization problem of nonsmooth
and multivariate ranking measures involved in the
learning procedure. Experimental results show the superiority
of our proposed approach over several state-of-theart
hashing methods in term of ranking evaluation metrics
when tested on multi-label image datasets.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        CVPR 
      
        Neural Hashing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/zou2025prompthash/">Prompthash: Affinity-prompted Collaborative Cross-modal Learning For Adaptive Hashing Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Prompthash: Affinity-prompted Collaborative Cross-modal Learning For Adaptive Hashing Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Prompthash: Affinity-prompted Collaborative Cross-modal Learning For Adaptive Hashing Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zou Qiang, Cheng Shuli, Chen Jiayi</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 2018 ACM on International Conference on Multimedia Retrieval</td>
    <td>7</td>
    <td><p>Cross-modal hashing is a promising approach for efficient data retrieval and
storage optimization. However, contemporary methods exhibit significant
limitations in semantic preservation, contextual integrity, and information
redundancy, which constrains retrieval efficacy. We present PromptHash, an
innovative framework leveraging affinity prompt-aware collaborative learning
for adaptive cross-modal hashing. We propose an end-to-end framework for
affinity-prompted collaborative hashing, with the following fundamental
technical contributions: (i) a text affinity prompt learning mechanism that
preserves contextual information while maintaining parameter efficiency, (ii)
an adaptive gated selection fusion architecture that synthesizes State Space
Model with Transformer network for precise cross-modal feature integration, and
(iii) a prompt affinity alignment strategy that bridges modal heterogeneity
through hierarchical contrastive learning. To the best of our knowledge, this
study presents the first investigation into affinity prompt awareness within
collaborative cross-modal adaptive hash learning, establishing a paradigm for
enhanced semantic consistency across modalities. Through comprehensive
evaluation on three benchmark multi-label datasets, PromptHash demonstrates
substantial performance improvements over existing approaches. Notably, on the
NUS-WIDE dataset, our method achieves significant gains of 18.22% and 18.65% in
image-to-text and text-to-image retrieval tasks, respectively. The code is
publicly available at https://github.com/ShiShuMo/PromptHash.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Image Retrieval 
      
        Tools & Libraries 
      
        Multimodal Retrieval 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/zhu2025deep/">Deep Hashing Network For Efficient Similarity Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Hashing Network For Efficient Similarity Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Hashing Network For Efficient Similarity Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>636</td>
    <td><p>Due to the storage and retrieval efficiency, hashing has been widely deployed to approximate nearest neighbor search for large-scale multimedia retrieval. Supervised hashing, which improves the quality of hash coding by exploiting the semantic similarity on data pairs, has received increasing attention recently. For most existing supervised hashing methods for image retrieval, an image is first represented as a vector of hand-crafted or machine-learned features, followed by another separate quantization step that generates binary codes.
However, suboptimal hash coding may be produced, because the quantization error is not statistically minimized and the feature representation is not optimally compatible with the binary coding. In this paper, we propose a novel Deep Hashing Network (DHN) architecture for supervised hashing, in which we jointly learn good image representation tailored to hash coding and formally control the quantization error.
The DHN model constitutes four key components: (1) a sub-network with multiple convolution-pooling layers to capture image representations; (2) a fully-connected hashing layer to generate compact binary hash codes; (3) a pairwise cross-entropy loss layer for similarity-preserving learning; and (4) a pairwise quantization loss for controlling hashing quality. Extensive experiments on standard image retrieval datasets show the proposed DHN model yields substantial boosts over latest state-of-the-art hashing methods.</p>
</td>
    <td>
      
        Image Retrieval 
      
        AAAI 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Neural Hashing 
      
        Similarity Search 
      
        Quantization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2025</td>
    <td>
      <a href="/publications/zhu2025linear/">Linear Cross-modal Hashing For Efficient Multimedia Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Linear Cross-modal Hashing For Efficient Multimedia Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Linear Cross-modal Hashing For Efficient Multimedia Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 21st ACM international conference on Multimedia</td>
    <td>278</td>
    <td><p>Most existing cross-modal hashing methods suffer from the scalability issue in the training phase. In this paper, we propose a novel 
cross-modal hashing approach with a linear time complexity to the training data size, to enable scalable indexing for multimedia 
search across multiple modals. Taking both the intra-similarity in each modal and the inter-similarity across different modals 
into consideration, the proposed approach aims at effectively learning hash functions from large-scale training datasets. 
More specifically, for each modal, we first partition the training data into \(k\) clusters and then represent each training data 
point with its distances to \(k\) centroids of the clusters. Interestingly, such a k-dimensional data representation can reduce 
the time complexity of the training phase from traditional O(n2) or higher to O(n), where \(n\) is the training data size, leading to 
practical learning on large-scale datasets. We further prove that this new representation preserves the intra-similarity in each modal. 
To preserve the inter-similarity among data points across different modals, we transform the derived data representations into a 
common binary subspace in which binary codes from all the modals are â€œconsistentâ€ and comparable. The transformation simultaneously 
outputs the hash functions for all modals, which are used to convert unseen data into binary codes. Given a query of one modal, 
it is first mapped into the binary codes using the modalâ€™s hash functions, followed by matching the database binary codes of any other 
modals. Experimental results on two benchmark datasets confirm the scalability and the effectiveness of the proposed approach in 
comparison with the state of the art.</p>
</td>
    <td>
      
        Compact Codes 
      
        DATASETS 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
    
      
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/qiu2024hihpq/">Hihpq: Hierarchical Hyperbolic Product Quantization For Unsupervised Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hihpq: Hierarchical Hyperbolic Product Quantization For Unsupervised Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hihpq: Hierarchical Hyperbolic Product Quantization For Unsupervised Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Qiu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>5</td>
    <td><p>Existing unsupervised deep product quantization methods primarily aim for the
increased similarity between different views of the identical image, whereas
the delicate multi-level semantic similarities preserved between images are
overlooked. Moreover, these methods predominantly focus on the Euclidean space
for computational convenience, compromising their ability to map the
multi-level semantic relationships between images effectively. To mitigate
these shortcomings, we propose a novel unsupervised product quantization method
dubbed \textbf{Hi}erarchical \textbf{H}yperbolic \textbf{P}roduct
\textbf{Q}uantization (HiHPQ), which learns quantized representations by
incorporating hierarchical semantic similarity within hyperbolic geometry.
Specifically, we propose a hyperbolic product quantizer, where the hyperbolic
codebook attention mechanism and the quantized contrastive learning on the
hyperbolic product manifold are introduced to expedite quantization.
Furthermore, we propose a hierarchical semantics learning module, designed to
enhance the distinction between similar and non-matching images for a query by
utilizing the extracted hierarchical semantics as an additional training
supervision. Experiments on benchmarks show that our proposed method
outperforms state-of-the-art baselines.</p>
</td>
    <td>
      
        Image Retrieval 
      
        AAAI 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/puram2024quantum/">Quantum Algorithm For Jaccard Similarity</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Quantum Algorithm For Jaccard Similarity' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Quantum Algorithm For Jaccard Similarity' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Puram Varun, Bobbili Ruthvik Rao, Thomas Johnson P</td> <!-- ðŸ”§ You were missing this -->
    <td>Dictionary of Bioinformatics and Computational Biology</td>
    <td>32</td>
    <td><p>Jaccard Similarity is a very common proximity measurement used to compute the
similarity between two asymmetric binary vectors. Jaccard Similarity is the
ratio between the 1s (Intersection of two vectors) to 1s (Union of two
vectors). This paper introduces a quantum algorithm for finding the Jaccard
Similarity 1s, in the Intersection and Union of two binary vectors. There are
two sub-algorithms one for each. Measuring the register for respective
algorithm gives count of number of 1 s in binary format. Implementation on IBM
composer is also included.</p>
</td>
    <td>
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/pourdamghani2024hash/">Hash & Adjust: Competitive Demand-aware Consistent Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hash & Adjust: Competitive Demand-aware Consistent Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hash & Adjust: Competitive Demand-aware Consistent Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Pourdamghani et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>International Journal of Computer Vision</td>
    <td>6</td>
    <td><p>Distributed systems often serve dynamic workloads and resource demands evolve
over time. Such a temporal behavior stands in contrast to the static and
demand-oblivious nature of most data structures used by these systems. In this
paper, we are particularly interested in consistent hashing, a fundamental
building block in many large distributed systems. Our work is motivated by the
hypothesis that a more adaptive approach to consistent hashing can leverage
structure in the demand, and hence improve storage utilization and reduce
access time. We initiate the study of demand-aware consistent hashing. Our main
contribution is H&amp;A, a constant-competitive online algorithm (i.e., it comes
with provable performance guarantees over time). H&amp;A is demand-aware and
optimizes its internal structure to enable faster access times, while offering
a high utilization of storage. We further evaluate H&amp;A empirically.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/patel2024three/">Three Things To Know About Deep Metric Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Three Things To Know About Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Three Things To Know About Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Patel Yash, Tolias Giorgos, Matas Jiri</td> <!-- ðŸ”§ You were missing this -->
    <td>AMA Journal of Ethics</td>
    <td>39</td>
    <td><p>This paper addresses supervised deep metric learning for open-set image
retrieval, focusing on three key aspects: the loss function, mixup
regularization, and model initialization. In deep metric learning, optimizing
the retrieval evaluation metric, recall@k, via gradient descent is desirable
but challenging due to its non-differentiable nature. To overcome this, we
propose a differentiable surrogate loss that is computed on large batches,
nearly equivalent to the entire training set. This computationally intensive
process is made feasible through an implementation that bypasses the GPU memory
limitations. Additionally, we introduce an efficient mixup regularization
technique that operates on pairwise scalar similarities, effectively increasing
the batch size even further. The training process is further enhanced by
initializing the vision encoder using foundational models, which are
pre-trained on large-scale datasets. Through a systematic study of these
components, we demonstrate that their synergy enables large models to nearly
solve popular benchmarks.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/paudel2024pixelmod/">PIXELMOD: Improving Soft Moderation Of Visual Misleading Information On Twitter</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=PIXELMOD: Improving Soft Moderation Of Visual Misleading Information On Twitter' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=PIXELMOD: Improving Soft Moderation Of Visual Misleading Information On Twitter' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Paudel et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2023 IEEE Symposium on Security and Privacy (SP)</td>
    <td>5</td>
    <td><p>Images are a powerful and immediate vehicle to carry misleading or outright
false messages, yet identifying image-based misinformation at scale poses
unique challenges. In this paper, we present PIXELMOD, a system that leverages
perceptual hashes, vector databases, and optical character recognition (OCR) to
efficiently identify images that are candidates to receive soft moderation
labels on Twitter. We show that PIXELMOD outperforms existing image similarity
approaches when applied to soft moderation, with negligible performance
overhead. We then test PIXELMOD on a dataset of tweets surrounding the 2020 US
Presidential Election, and find that it is able to identify visually misleading
images that are candidates for soft moderation with 0.99% false detection and
2.06% false negatives.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/patel2024acorn/">ACORN: Performant And Predicate-agnostic Search Over Vector Embeddings And Structured Data</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=ACORN: Performant And Predicate-agnostic Search Over Vector Embeddings And Structured Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=ACORN: Performant And Predicate-agnostic Search Over Vector Embeddings And Structured Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Patel et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the ACM on Management of Data</td>
    <td>13</td>
    <td><p>Applications increasingly leverage mixed-modality data, and must jointly
search over vector data, such as embedded images, text and video, as well as
structured data, such as attributes and keywords. Proposed methods for this
hybrid search setting either suffer from poor performance or support a severely
restricted set of search predicates (e.g., only small sets of equality
predicates), making them impractical for many applications. To address this, we
present ACORN, an approach for performant and predicate-agnostic hybrid search.
ACORN builds on Hierarchical Navigable Small Worlds (HNSW), a state-of-the-art
graph-based approximate nearest neighbor index, and can be implemented
efficiently by extending existing HNSW libraries. ACORN introduces the idea of
predicate subgraph traversal to emulate a theoretically ideal, but impractical,
hybrid search strategy. ACORNâ€™s predicate-agnostic construction algorithm is
designed to enable this effective search strategy, while supporting a wide
array of predicate sets and query semantics. We systematically evaluate ACORN
on both prior benchmark datasets, with simple, low-cardinality predicate sets,
and complex multi-modal datasets not supported by prior methods. We show that
ACORN achieves state-of-the-art performance on all datasets, outperforming
prior methods with 2-1,000x higher throughput at a fixed recall.</p>
</td>
    <td>
      
        Graph Based ANN 
      
        DATASETS 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/nardini2024efficient/">Efficient Multi-vector Dense Retrieval Using Bit Vectors</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Efficient Multi-vector Dense Retrieval Using Bit Vectors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Efficient Multi-vector Dense Retrieval Using Bit Vectors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Nardini Franco Maria, Rulli Cosimo, Venturini Rossano</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>10</td>
    <td><p>Dense retrieval techniques employ pre-trained large language models to build
a high-dimensional representation of queries and passages. These
representations compute the relevance of a passage w.r.t. to a query using
efficient similarity measures. In this line, multi-vector representations show
improved effectiveness at the expense of a one-order-of-magnitude increase in
memory footprint and query latency by encoding queries and documents on a
per-token level. Recently, PLAID has tackled these problems by introducing a
centroid-based term representation to reduce the memory impact of multi-vector
systems. By exploiting a centroid interaction mechanism, PLAID filters out
non-relevant documents, thus reducing the cost of the successive ranking
stages. This paper proposes ``Efficient Multi-Vector dense retrieval with Bit
vectorsâ€™â€™ (EMVB), a novel framework for efficient query processing in
multi-vector dense retrieval. First, EMVB employs a highly efficient
pre-filtering step of passages using optimized bit vectors. Second, the
computation of the centroid interaction happens column-wise, exploiting SIMD
instructions, thus reducing its latency. Third, EMVB leverages Product
Quantization (PQ) to reduce the memory footprint of storing vector
representations while jointly allowing for fast late interaction. Fourth, we
introduce a per-document term filtering method that further improves the
efficiency of the last step. Experiments on MS MARCO and LoTTE show that EMVB
is up to 2.8x faster while reducing the memory footprint by 1.8x with no loss
in retrieval accuracy compared to PLAID.</p>
</td>
    <td>
      
        Tools & Libraries 
      
        Quantization 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/wu2024sign/">Sign-guided Bipartite Graph Hashing For Hamming Space Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Sign-guided Bipartite Graph Hashing For Hamming Space Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Sign-guided Bipartite Graph Hashing For Hamming Space Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wu Xueyi</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the ACM Web Conference 2023</td>
    <td>10</td>
    <td><p>Bipartite graph hashing (BGH) is extensively used for Top-K search in Hamming
space at low storage and inference costs. Recent research adopts graph
convolutional hashing for BGH and has achieved the state-of-the-art
performance. However, the contributions of its various influencing factors to
hashing performance have not been explored in-depth, including the
same/different sign count between two binary embeddings during Hamming space
search (sign property), the contribution of sub-embeddings at each layer (model
property), the contribution of different node types in the bipartite graph
(node property), and the combination of augmentation methods. In this work, we
build a lightweight graph convolutional hashing model named LightGCH by mainly
removing the augmentation methods of the state-of-the-art model BGCH. By
analyzing the contributions of each layer and node type to performance, as well
as analyzing the Hamming similarity statistics at each layer, we find that the
actual neighbors in the bipartite graph tend to have low Hamming similarity at
the shallow layer, and all nodes tend to have high Hamming similarity at the
deep layers in LightGCH. To tackle these problems, we propose a novel
sign-guided framework SGBGH to make improvement, which uses sign-guided
negative sampling to improve the Hamming similarity of neighbors, and uses
sign-aware contrastive learning to help nodes learn more uniform
representations. Experimental results show that SGBGH outperforms BGCH and
LightGCH significantly in embedding quality.</p>
</td>
    <td>
      
        Similarity Search 
      
        Tools & Libraries 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/luo2024learning/">Learning To Hash For Recommendation: A Survey</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning To Hash For Recommendation: A Survey' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning To Hash For Recommendation: A Survey' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Luo et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Pattern Analysis and Machine Intelligence</td>
    <td>705</td>
    <td><p>With the explosive growth of users and items, Recommender Systems (RS) are
facing unprecedented challenges on both retrieval efficiency and storage cost.
Fortunately, Learning to Hash (L2H) techniques have been shown as a promising
solution to address the two dilemmas, whose core idea is encoding
high-dimensional data into compact hash codes. To this end, L2H for RS (HashRec
for short) has recently received widespread attention to support large-scale
recommendations. In this survey, we present a comprehensive review of current
HashRec algorithms. Specifically, we first introduce the commonly used
two-tower models in the recall stage and identify two search strategies
frequently employed in L2H. Then, we categorize prior works into two-tier
taxonomy based on: (i) the type of loss function and (ii) the optimization
strategy. We also introduce some commonly used evaluation metrics to measure
the performance of HashRec algorithms. Finally, we shed light on the
limitations of the current research and outline the future research directions.
Furthermore, the summary of HashRec methods reviewed in this survey can be
found at
\href{https://github.com/Luo-Fangyuan/HashRec}{https://github.com/Luo-Fangyuan/HashRec}.</p>
</td>
    <td>
      
        Survey Paper 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Recommender Systems 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/luo2024fine/">Fine-grained Embedding Dimension Optimization During Training For Recommender Systems</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fine-grained Embedding Dimension Optimization During Training For Recommender Systems' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fine-grained Embedding Dimension Optimization During Training For Recommender Systems' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Luo et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the Web Conference 2021</td>
    <td>38</td>
    <td><p>Huge embedding tables in modern deep learning recommender models (DLRM)
require prohibitively large memory during training and inference. This paper
proposes FIITED, a system to automatically reduce the memory footprint via
FIne-grained In-Training Embedding Dimension pruning. By leveraging the key
insight that embedding vectors are not equally important, FIITED adaptively
adjusts the dimension of each individual embedding vector during model
training, assigning larger dimensions to more important embeddings while
adapting to dynamic changes in data. We prioritize embedding dimensions with
higher frequencies and gradients as more important. To enable efficient pruning
of embeddings and their dimensions during model training, we propose an
embedding storage system based on virtually-hashed physically-indexed hash
tables. Experiments on two industry models and months of realistic datasets
show that FIITED can reduce DLRM embedding size by more than 65% while
preserving model quality, outperforming state-of-the-art in-training embedding
pruning methods. On public datasets, FIITED can reduce the size of embedding
tables by 2.1x to 800x with negligible accuracy drop, while improving model
throughput.</p>
</td>
    <td>
      
        Efficiency And Optimization 
      
        DATASETS 
      
        Recommender Systems 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/li2024mixed/">Mixed-precision Embeddings For Large-scale Recommendation Models</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Mixed-precision Embeddings For Large-scale Recommendation Models' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Mixed-precision Embeddings For Large-scale Recommendation Models' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Fourteenth ACM Conference on Recommender Systems</td>
    <td>89</td>
    <td><p>Embedding techniques have become essential components of large databases in
the deep learning era. By encoding discrete entities, such as words, items, or
graph nodes, into continuous vector spaces, embeddings facilitate more
efficient storage, retrieval, and processing in large databases. Especially in
the domain of recommender systems, millions of categorical features are encoded
as unique embedding vectors, which facilitates the modeling of similarities and
interactions among features. However, numerous embedding vectors can result in
significant storage overhead. In this paper, we aim to compress the embedding
table through quantization techniques. Given that features vary in importance
levels, we seek to identify an appropriate precision for each feature to
balance model accuracy and memory usage. To this end, we propose a novel
embedding compression method, termed Mixed-Precision Embeddings (MPE).
Specifically, to reduce the size of the search space, we first group features
by frequency and then search precision for each feature group. MPE further
learns the probability distribution over precision levels for each feature
group, which can be used to identify the most suitable precision with a
specially designed sampling strategy. Extensive experiments on three public
datasets demonstrate that MPE significantly outperforms existing embedding
compression methods. Remarkably, MPE achieves about 200x compression on the
Criteo dataset without comprising the prediction accuracy.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        Quantization 
      
        Recommender Systems 
      
        RecSys 
      
        Compact Codes 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/leroux2024euclidean/">Euclidean Distance Compression Via Deep Random Features</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Euclidean Distance Compression Via Deep Random Features' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Euclidean Distance Compression Via Deep Random Features' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Leroux Brett, Rademacher Luis</td> <!-- ðŸ”§ You were missing this -->
    <td>Computer Vision and Image Understanding</td>
    <td>13</td>
    <td><p>Motivated by the problem of compressing point sets into as few bits as
possible while maintaining information about approximate distances between
points, we construct random nonlinear maps \(\varphi_\ell\) that compress point
sets in the following way. For a point set \(S\), the map
\(\varphi_\ell:\mathbb{R}^d \to N^{-1/2}\{-1,1\}^N\) has the property that
storing \(\varphi_\ell(S)\) (a <em>sketch</em> of \(S\)) allows one to report
pairwise squared distances between points in \(S\) up to some multiplicative
\((1\pm \epsilon)\) error with high probability as long as the minimum distance
is not too small compared to \(\epsilon\). The maps \(\varphi_\ell\) are the
\(\ell\)-fold composition of a certain type of random feature mapping. Moreover,
we determine how large \(N\) needs to be as a function of \(\epsilon\) and other
parameters of the point set.
  Compared to existing techniques, our maps offer several advantages. The
standard method for compressing point sets by random mappings relies on the
Johnson-Lindenstrauss lemma which implies that if a set of \(n\) points is mapped
by a Gaussian random matrix to \(\mathbb{R}^k\) with \(k =\Theta(\epsilon^{-2}log
n)\), then pairwise distances between points are preserved up to a
multiplicative \((1\pm \epsilon)\) error with high probability. The main
advantage of our maps \(\varphi_\ell\) over random linear maps is that ours map
point sets directly into the discrete cube \(N^{-1/2}\{-1,1\}^N\) and so there is
no additional step needed to convert the sketch to bits. For some range of
parameters, our maps \(\varphi_\ell\) produce sketches which require fewer bits
of storage space.</p>
</td>
    <td>
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/miao2024locality/">Locality-sensitive Hashing-based Efficient Point Transformer With Applications In High-energy Physics</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Locality-sensitive Hashing-based Efficient Point Transformer With Applications In High-energy Physics' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Locality-sensitive Hashing-based Efficient Point Transformer With Applications In High-energy Physics' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Miao et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 21st ACM international conference on Information and knowledge management</td>
    <td>52</td>
    <td><p>This study introduces a novel transformer model optimized for large-scale
point cloud processing in scientific domains such as high-energy physics (HEP)
and astrophysics. Addressing the limitations of graph neural networks and
standard transformers, our model integrates local inductive bias and achieves
near-linear complexity with hardware-friendly regular operations. One
contribution of this work is the quantitative analysis of the error-complexity
tradeoff of various sparsification techniques for building efficient
transformers. Our findings highlight the superiority of using
locality-sensitive hashing (LSH), especially OR &amp; AND-construction LSH, in
kernel approximation for large-scale point cloud data with local inductive
bias. Based on this finding, we propose LSH-based Efficient Point Transformer
(HEPT), which combines E\(^2\)LSH with OR &amp; AND constructions and is built upon
regular computations. HEPT demonstrates remarkable performance on two critical
yet time-consuming HEP tasks, significantly outperforming existing GNNs and
transformers in accuracy and computational speed, marking a significant
advancement in geometric deep learning and large-scale scientific data
processing. Our code is available at https://github.com/Graph-COM/HEPT.</p>
</td>
    <td>
      
        CIKM 
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/saberi2024drew/">DREW : Towards Robust Data Provenance By Leveraging Error-controlled Watermarking</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=DREW : Towards Robust Data Provenance By Leveraging Error-controlled Watermarking' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=DREW : Towards Robust Data Provenance By Leveraging Error-controlled Watermarking' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Saberi et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2021 IEEE Symposium on Security and Privacy (SP)</td>
    <td>43</td>
    <td><p>Identifying the origin of data is crucial for data provenance, with
applications including data ownership protection, media forensics, and
detecting AI-generated content. A standard approach involves embedding-based
retrieval techniques that match query data with entries in a reference dataset.
However, this method is not robust against benign and malicious edits. To
address this, we propose Data Retrieval with Error-corrected codes and
Watermarking (DREW). DREW randomly clusters the reference dataset, injects
unique error-controlled watermark keys into each cluster, and uses these keys
at query time to identify the appropriate cluster for a given sample. After
locating the relevant cluster, embedding vector similarity retrieval is
performed within the cluster to find the most accurate matches. The integration
of error control codes (ECC) ensures reliable cluster assignments, enabling the
method to perform retrieval on the entire dataset in case the ECC algorithm
cannot detect the correct cluster with high confidence. This makes DREW
maintain baseline performance, while also providing opportunities for
performance improvements due to the increased likelihood of correctly matching
queries to their origin when performing retrieval on a smaller subset of the
dataset. Depending on the watermark technique used, DREW can provide
substantial improvements in retrieval accuracy (up to 40% for some datasets
and modification types) across multiple datasets and state-of-the-art embedding
models (e.g., DinoV2, CLIP), making our method a promising solution for secure
and reliable source identification. The code is available at
https://github.com/mehrdadsaberi/DREW</p>
</td>
    <td>
      
        DATASETS 
      
        Similarity Search 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/juvekar2024cos/">Cos-mix: Cosine Similarity And Distance Fusion For Improved Information Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Cos-mix: Cosine Similarity And Distance Fusion For Improved Information Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Cos-mix: Cosine Similarity And Distance Fusion For Improved Information Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Juvekar Kush, Purwar Anupam</td> <!-- ðŸ”§ You were missing this -->
    <td>2012 7th International Conference on Computer Science &amp; Education (ICCSE)</td>
    <td>12</td>
    <td><p>This study proposes a novel hybrid retrieval strategy for Retrieval-Augmented
Generation (RAG) that integrates cosine similarity and cosine distance measures
to improve retrieval performance, particularly for sparse data. The traditional
cosine similarity measure is widely used to capture the similarity between
vectors in high-dimensional spaces. However, it has been shown that this
measure can yield arbitrary results in certain scenarios. To address this
limitation, we incorporate cosine distance measures to provide a complementary
perspective by quantifying the dissimilarity between vectors. Our approach is
experimented on proprietary data, unlike recent publications that have used
open-source datasets. The proposed method demonstrates enhanced retrieval
performance and provides a more comprehensive understanding of the semantic
relationships between documents or items. This hybrid strategy offers a
promising solution for efficiently and accurately retrieving relevant
information in knowledge-intensive applications, leveraging techniques such as
BM25 (sparse) retrieval , vector (Dense) retrieval, and cosine distance based
retrieval to facilitate efficient information retrieval.</p>
</td>
    <td>
      
        DATASETS 
      
        Distance Metric Learning 
      
        ICCV 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/wang2024weakly/">Weakly Supervised Deep Hyperspherical Quantization For Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Weakly Supervised Deep Hyperspherical Quantization For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Weakly Supervised Deep Hyperspherical Quantization For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>9</td>
    <td><p>Deep quantization methods have shown high efficiency on large-scale image
retrieval. However, current models heavily rely on ground-truth information,
hindering the application of quantization in label-hungry scenarios. A more
realistic demand is to learn from inexhaustible uploaded images that are
associated with informal tags provided by amateur users. Though such sketchy
tags do not obviously reveal the labels, they actually contain useful semantic
information for supervising deep quantization. To this end, we propose
Weakly-Supervised Deep Hyperspherical Quantization (WSDHQ), which is the first
work to learn deep quantization from weakly tagged images. Specifically, 1) we
use word embeddings to represent the tags and enhance their semantic
information based on a tag correlation graph. 2) To better preserve semantic
information in quantization codes and reduce quantization error, we jointly
learn semantics-preserving embeddings and supervised quantizer on hypersphere
by employing a well-designed fusion layer and tailor-made loss functions.
Extensive experiments show that WSDHQ can achieve state-of-art performance on
weakly-supervised compact coding. Code is available at
https://github.com/gimpong/AAAI21-WSDHQ.</p>
</td>
    <td>
      
        Image Retrieval 
      
        AAAI 
      
        Efficiency And Optimization 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/wong2024shotit/">Shotit: Compute-efficient Image-to-video Search Engine For The Cloud</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Shotit: Compute-efficient Image-to-video Search Engine For The Cloud' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Shotit: Compute-efficient Image-to-video Search Engine For The Cloud' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wong Leslie</td> <!-- ðŸ”§ You were missing this -->
    <td>2014 IEEE International Conference on Image Processing (ICIP)</td>
    <td>15</td>
    <td><p>With the rapid growth of information technology, users are exposed to a
massive amount of data online, including image, music, and video. This has led
to strong needs to provide effective corresponsive search services such as
image, music, and video search services. Most of them are operated based on
keywords, namely using keywords to find related image, music, and video.
Additionally, there are image-to-image search services that enable users to
find similar images using one input image. Given that videos are essentially
composed of image frames, then similar videos can be searched by one input
image or screenshot. We want to target this scenario and provide an efficient
method and implementation in this paper.
  We present Shotit, a cloud-native image-to-video search engine that tailors
this search scenario in a compute-efficient approach. One main limitation faced
in this scenario is the scale of its dataset. A typical image-to-image search
engine only handles one-to-one relationships, colloquially, one image
corresponds to another single image. But image-to-video proliferates. Take a
24-min length video as an example, it will generate roughly 20,000 image
frames. As the number of videos grows, the scale of the dataset explodes
exponentially. In this case, a compute-efficient approach ought to be
considered, and the system design should cater to the cloud-native trend.
Choosing an emerging technology - vector database as its backbone, Shotit fits
these two metrics performantly. Experiments for two different datasets, a 50
thousand-scale Blender Open Movie dataset, and a 50 million-scale proprietary
TV genre dataset at a 4 Core 32GB RAM Intel Xeon Gold 6271C cloud machine with
object storage reveal the effectiveness of Shotit. A demo regarding the Blender
Open Movie dataset is illustrated within this paper.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/xu2024bi/">A Bi-metric Framework For Fast Similarity Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Bi-metric Framework For Fast Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Bi-metric Framework For Fast Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Xu Haike, Silwal Sandeep, Indyk Piotr</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>39</td>
    <td><p>We propose a new â€œbi-metricâ€ framework for designing nearest neighbor data
structures. Our framework assumes two dissimilarity functions: a ground-truth
metric that is accurate but expensive to compute, and a proxy metric that is
cheaper but less accurate. In both theory and practice, we show how to
construct data structures using only the proxy metric such that the query
procedure achieves the accuracy of the expensive metric, while only using a
limited number of calls to both metrics. Our theoretical results instantiate
this framework for two popular nearest neighbor search algorithms: DiskANN and
Cover Tree. In both cases we show that, as long as the proxy metric used to
construct the data structure approximates the ground-truth metric up to a
bounded factor, our data structure achieves arbitrarily good approximation
guarantees with respect to the ground-truth metric. On the empirical side, we
apply the framework to the text retrieval problem with two dissimilarity
functions evaluated by ML models with vastly different computational costs. We
observe that for almost all data sets in the MTEB benchmark, our approach
achieves a considerably better accuracy-efficiency tradeoff than the
alternatives, such as re-ranking.</p>
</td>
    <td>
      
        Efficiency And Optimization 
      
        Alt 
      
        Text Retrieval 
      
        Similarity Search 
      
        Tree Based ANN 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/jedidi2024zero/">Zero-shot Dense Retrieval With Embeddings From Relevance Feedback</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Zero-shot Dense Retrieval With Embeddings From Relevance Feedback' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Zero-shot Dense Retrieval With Embeddings From Relevance Feedback' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jedidi et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</td>
    <td>77</td>
    <td><p>Building effective dense retrieval systems remains difficult when relevance
supervision is not available. Recent work has looked to overcome this challenge
by using a Large Language Model (LLM) to generate hypothetical documents that
can be used to find the closest real document. However, this approach relies
solely on the LLM to have domain-specific knowledge relevant to the query,
which may not be practical. Furthermore, generating hypothetical documents can
be inefficient as it requires the LLM to generate a large number of tokens for
each query. To address these challenges, we introduce Real Document Embeddings
from Relevance Feedback (ReDE-RF). Inspired by relevance feedback, ReDE-RF
proposes to re-frame hypothetical document generation as a relevance estimation
task, using an LLM to select which documents should be used for nearest
neighbor search. Through this re-framing, the LLM no longer needs
domain-specific knowledge but only needs to judge what is relevant.
Additionally, relevance estimation only requires the LLM to output a single
token, thereby improving search latency. Our experiments show that ReDE-RF
consistently surpasses state-of-the-art zero-shot dense retrieval methods
across a wide range of low-resource retrieval datasets while also making
significant improvements in latency per-query.</p>
</td>
    <td>
      
        DATASETS 
      
        ACL 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/islam2024spatially/">Spatially Optimized Compact Deep Metric Learning Model For Similarity Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Spatially Optimized Compact Deep Metric Learning Model For Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Spatially Optimized Compact Deep Metric Learning Model For Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Islam et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Information Fusion</td>
    <td>61</td>
    <td><p>Spatial optimization is often overlooked in many computer vision tasks.
Filters should be able to recognize the features of an object regardless of
where it is in the image. Similarity search is a crucial task where spatial
features decide an important output. The capacity of convolution to capture
visual patterns across various locations is limited. In contrast to
convolution, the involution kernel is dynamically created at each pixel based
on the pixel value and parameters that have been learned. This study
demonstrates that utilizing a single layer of involution feature extractor
alongside a compact convolution model significantly enhances the performance of
similarity search. Additionally, we improve predictions by using the GELU
activation function rather than the ReLU. The negligible amount of weight
parameters in involution with a compact model with better performance makes the
model very useful in real-world implementations. Our proposed model is below 1
megabyte in size. We have experimented with our proposed methodology and other
models on CIFAR-10, FashionMNIST, and MNIST datasets. Our proposed method
outperforms across all three datasets.</p>
</td>
    <td>
      
        DATASETS 
      
        Similarity Search 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/he2024hybridhash/">Hybridhash: Hybrid Convolutional And Self-attention Deep Hashing For Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hybridhash: Hybrid Convolutional And Self-attention Deep Hashing For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hybridhash: Hybrid Convolutional And Self-attention Deep Hashing For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>He Chao, Wei Hongxi</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 2024 International Conference on Multimedia Retrieval</td>
    <td>5</td>
    <td><p>Deep image hashing aims to map input images into simple binary hash codes via
deep neural networks and thus enable effective large-scale image retrieval.
Recently, hybrid networks that combine convolution and Transformer have
achieved superior performance on various computer tasks and have attracted
extensive attention from researchers. Nevertheless, the potential benefits of
such hybrid networks in image retrieval still need to be verified. To this end,
we propose a hybrid convolutional and self-attention deep hashing method known
as HybridHash. Specifically, we propose a backbone network with stage-wise
architecture in which the block aggregation function is introduced to achieve
the effect of local self-attention and reduce the computational complexity. The
interaction module has been elaborately designed to promote the communication
of information between image blocks and to enhance the visual representations.
We have conducted comprehensive experiments on three widely used datasets:
CIFAR-10, NUS-WIDE and IMAGENET. The experimental results demonstrate that the
method proposed in this paper has superior performance with respect to
state-of-the-art deep hashing methods. Source code is available
https://github.com/shuaichaochao/HybridHash.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        Neural Hashing 
      
        Hashing Methods 
      
        Image Retrieval 
      
        Multimodal Retrieval 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/han2024hashing/">Hashing For Protein Structure Similarity Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hashing For Protein Structure Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hashing For Protein Structure Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Han Jin, Li Wu-jun</td> <!-- ðŸ”§ You were missing this -->
    <td>Bioinformatics</td>
    <td>50</td>
    <td><p>Protein structure similarity search (PSSS), which tries to search proteins
with similar structures, plays a crucial role across diverse domains from drug
design to protein function prediction and molecular evolution. Traditional
alignment-based PSSS methods, which directly calculate alignment on the protein
structures, are highly time-consuming with high memory cost. Recently,
alignment-free methods, which represent protein structures as fixed-length
real-valued vectors, are proposed for PSSS. Although these methods have lower
time and memory cost than alignment-based methods, their time and memory cost
is still too high for large-scale PSSS, and their accuracy is unsatisfactory.
In this paper, we propose a novel method, called
\(\underline{\text{p}}\)r\(\underline{\text{o}}\)tein
\(\underline{\text{s}}\)tructure \(\underline{\text{h}}\)ashing (POSH), for PSSS.
POSH learns a binary vector representation for each protein structure, which
can dramatically reduce the time and memory cost for PSSS compared with
real-valued vector representation based methods. Furthermore, in POSH we also
propose expressive hand-crafted features and a structure encoder to well model
both node and edge interactions in proteins. Experimental results on real
datasets show that POSH can outperform other methods to achieve
state-of-the-art accuracy. Furthermore, POSH achieves a memory saving of more
than six times and speed improvement of more than four times, compared with
other methods.</p>
</td>
    <td>
      
        Alt 
      
        Similarity Search 
      
        Hashing Methods 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/gottesb%C3%BCren2024unleashing/">Unleashing Graph Partitioning For Large-scale Nearest Neighbor Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Unleashing Graph Partitioning For Large-scale Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Unleashing Graph Partitioning For Large-scale Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>GottesbÃ¼ren et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Computers</td>
    <td>19</td>
    <td><p>We consider the fundamental problem of decomposing a large-scale approximate
nearest neighbor search (ANNS) problem into smaller sub-problems. The goal is
to partition the input points into neighborhood-preserving shards, so that the
nearest neighbors of any point are contained in only a few shards. When a query
arrives, a routing algorithm is used to identify the shards which should be
searched for its nearest neighbors. This approach forms the backbone of
distributed ANNS, where the dataset is so large that it must be split across
multiple machines.
  In this paper, we design simple and highly efficient routing methods, and
prove strong theoretical guarantees on their performance. A crucial
characteristic of our routing algorithms is that they are inherently modular,
and can be used with any partitioning method. This addresses a key drawback of
prior approaches, where the routing algorithms are inextricably linked to their
associated partitioning method. In particular, our new routing methods enable
the use of balanced graph partitioning, which is a high-quality partitioning
method without a naturally associated routing algorithm. Thus, we provide the
first methods for routing using balanced graph partitioning that are extremely
fast to train, admit low latency, and achieve high recall. We provide a
comprehensive evaluation of our full partitioning and routing pipeline on
billion-scale datasets, where it outperforms existing scalable partitioning
methods by significant margins, achieving up to 2.14x higher QPS at 90%
recall\(@10\) than the best competitor.</p>
</td>
    <td>
      
        Large Scale Search 
      
        DATASETS 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/gebre2024pfeed/">Pfeed: Generating Near Real-time Personalized Feeds Using Precomputed Embedding Similarities</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Pfeed: Generating Near Real-time Personalized Feeds Using Precomputed Embedding Similarities' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Pfeed: Generating Near Real-time Personalized Feeds Using Precomputed Embedding Similarities' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Gebre et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 21st ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games</td>
    <td>30</td>
    <td><p>In personalized recommender systems, embeddings are often used to encode
customer actions and items, and retrieval is then performed in the embedding
space using approximate nearest neighbor search. However, this approach can
lead to two challenges: 1) user embeddings can restrict the diversity of
interests captured and 2) the need to keep them up-to-date requires an
expensive, real-time infrastructure. In this paper, we propose a method that
overcomes these challenges in a practical, industrial setting. The method
dynamically updates customer profiles and composes a feed every two minutes,
employing precomputed embeddings and their respective similarities. We tested
and deployed this method to personalise promotional items at Bol, one of the
largest e-commerce platforms of the Netherlands and Belgium. The method
enhanced customer engagement and experience, leading to a significant 4.9%
uplift in conversions.</p>
</td>
    <td>
      
        Recommender Systems 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/garciamorato2024parametrizable/">A Parametrizable Algorithm For Distributed Approximate Similarity Search With Arbitrary Distances</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Parametrizable Algorithm For Distributed Approximate Similarity Search With Arbitrary Distances' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Parametrizable Algorithm For Distributed Approximate Similarity Search With Arbitrary Distances' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Garcia-morato et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Advances in Database Systems</td>
    <td>37</td>
    <td><p>Recent studies have explored alternative distance measures for similarity
search in spaces with diverse topologies, emphasizing the importance of
selecting an appropriate distance function to improve the performance of
k-Nearest Neighbour search algorithms. However, a critical gap remains in
accommodating such diverse similarity measures, as most existing methods for
exact or approximate similarity search are explicitly designed for metric
spaces.
  To address this need, we propose PDASC (Parametrizable Distributed
Approximate Similarity Search with Clustering), a novel Approximate Nearest
Neighbour search algorithm. PDASC combines an innovative multilevel indexing
structure particularly adept at managing outliers, highly imbalanced datasets,
and sparse data distributions, with the flexibility to support arbitrary
distance functions achieved through the integration of clustering algorithms
that inherently accommodate them.
  Experimental results show that PDASC constitutes a reliable ANN search
method, suitable for operating in distributed data environments and for
handling datasets defined in different topologies, where the selection of the
most appropriate distance function is often non-trivial.</p>
</td>
    <td>
      
        Alt 
      
        Similarity Search 
      
        Evaluation 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/gao2024rabitq/">Rabitq: Quantizing High-dimensional Vectors With A Theoretical Error Bound For Approximate Nearest Neighbor Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Rabitq: Quantizing High-dimensional Vectors With A Theoretical Error Bound For Approximate Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Rabitq: Quantizing High-dimensional Vectors With A Theoretical Error Bound For Approximate Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Gao Jianyang, Long Cheng</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the ACM on Management of Data</td>
    <td>15</td>
    <td><p>Searching for approximate nearest neighbors (ANN) in the high-dimensional
Euclidean space is a pivotal problem. Recently, with the help of fast
SIMD-based implementations, Product Quantization (PQ) and its variants can
often efficiently and accurately estimate the distances between the vectors and
have achieved great success in the in-memory ANN search. Despite their
empirical success, we note that these methods do not have a theoretical error
bound and are observed to fail disastrously on some real-world datasets.
Motivated by this, we propose a new randomized quantization method named
RaBitQ, which quantizes \(D\)-dimensional vectors into \(D\)-bit strings. RaBitQ
guarantees a sharp theoretical error bound and provides good empirical accuracy
at the same time. In addition, we introduce efficient implementations of
RaBitQ, supporting to estimate the distances with bitwise operations or
SIMD-based operations. Extensive experiments on real-world datasets confirm
that (1) our method outperforms PQ and its variants in terms of
accuracy-efficiency trade-off by a clear margin and (2) its empirical
performance is well-aligned with our theoretical analysis.</p>
</td>
    <td>
      
        DATASETS 
      
        Efficiency And Optimization 
      
        Similarity Search 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/engels2024approximate/">Approximate Nearest Neighbor Search With Window Filters</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Approximate Nearest Neighbor Search With Window Filters' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Approximate Nearest Neighbor Search With Window Filters' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Engels et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the ACM Web Conference 2023</td>
    <td>27</td>
    <td><p>We define and investigate the problem of \(\textit{c-approximate window
search}\): approximate nearest neighbor search where each point in the dataset
has a numeric label, and the goal is to find nearest neighbors to queries
within arbitrary label ranges. Many semantic search problems, such as image and
document search with timestamp filters, or product search with cost filters,
are natural examples of this problem. We propose and theoretically analyze a
modular tree-based framework for transforming an index that solves the
traditional c-approximate nearest neighbor problem into a data structure that
solves window search. On standard nearest neighbor benchmark datasets equipped
with random label values, adversarially constructed embeddings, and image
search embeddings with real timestamps, we obtain up to a \(75\times\) speedup
over existing solutions at the same level of recall.</p>
</td>
    <td>
      
        DATASETS 
      
        Efficiency And Optimization 
      
        Tree Based ANN 
      
        Tools & Libraries 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/douze2024faiss/">The Faiss Library</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=The Faiss Library' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=The Faiss Library' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Douze et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>17</td>
    <td><p>Vector databases typically manage large collections of embedding vectors.
Currently, AI applications are growing rapidly, and so is the number of
embeddings that need to be stored and indexed. The Faiss library is dedicated
to vector similarity search, a core functionality of vector databases. Faiss is
a toolkit of indexing methods and related primitives used to search, cluster,
compress and transform vectors. This paper describes the trade-off space of
vector search and the design principles of Faiss in terms of structure,
approach to optimization and interfacing. We benchmark key features of the
library and discuss a few selected applications to highlight its broad
applicability.</p>
</td>
    <td>
      
        Similarity Search 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/chen2024hac/">HAC: Hash-grid Assisted Context For 3D Gaussian Splatting Compression</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=HAC: Hash-grid Assisted Context For 3D Gaussian Splatting Compression' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=HAC: Hash-grid Assisted Context For 3D Gaussian Splatting Compression' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Chen et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>5</td>
    <td><p>3D Gaussian Splatting (3DGS) has emerged as a promising framework for novel
view synthesis, boasting rapid rendering speed with high fidelity. However, the
substantial Gaussians and their associated attributes necessitate effective
compression techniques. Nevertheless, the sparse and unorganized nature of the
point cloud of Gaussians (or anchors in our paper) presents challenges for
compression. To address this, we make use of the relations between the
unorganized anchors and the structured hash grid, leveraging their mutual
information for context modeling, and propose a Hash-grid Assisted Context
(HAC) framework for highly compact 3DGS representation. Our approach introduces
a binary hash grid to establish continuous spatial consistencies, allowing us
to unveil the inherent spatial relations of anchors through a carefully
designed context model. To facilitate entropy coding, we utilize Gaussian
distributions to accurately estimate the probability of each quantized
attribute, where an adaptive quantization module is proposed to enable
high-precision quantization of these attributes for improved fidelity
restoration. Additionally, we incorporate an adaptive masking strategy to
eliminate invalid Gaussians and anchors. Importantly, our work is the pioneer
to explore context-based compression for 3DGS representation, resulting in a
remarkable size reduction of over \(75\times\) compared to vanilla 3DGS, while
simultaneously improving fidelity, and achieving over \(11\times\) size reduction
over SOTA 3DGS compression approach Scaffold-GS. Our code is available here:
https://github.com/YihangChen-ee/HAC</p>
</td>
    <td>
      
        Quantization 
      
        Tools & Libraries 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/yun2024neurohash/">Neurohash: A Hyperdimensional Neuro-symbolic Framework For Spatially-aware Image Hashing And Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Neurohash: A Hyperdimensional Neuro-symbolic Framework For Spatially-aware Image Hashing And Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Neurohash: A Hyperdimensional Neuro-symbolic Framework For Spatially-aware Image Hashing And Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yun et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 5th ACM on International Conference on Multimedia Retrieval</td>
    <td>10</td>
    <td><p>Customizable image retrieval from large datasets remains a critical
challenge, particularly when preserving spatial relationships within images.
Traditional hashing methods, primarily based on deep learning, often fail to
capture spatial information adequately and lack transparency. In this paper, we
introduce NeuroHash, a novel neuro-symbolic framework leveraging
Hyperdimensional Computing (HDC) to enable highly customizable, spatially-aware
image retrieval. NeuroHash combines pre-trained deep neural network models with
HDC-based symbolic models, allowing for flexible manipulation of hash values to
support conditional image retrieval. Our method includes a self-supervised
context-aware HDC encoder and novel loss terms for optimizing lower-dimensional
bipolar hashing using multilinear hyperplanes. We evaluate NeuroHash on two
benchmark datasets, demonstrating superior performance compared to
state-of-the-art hashing methods, as measured by mAP@5K scores and our newly
introduced metric, mAP@5Kr, which assesses spatial alignment. The results
highlight NeuroHashâ€™s ability to achieve competitive performance while offering
significant advantages in flexibility and customization, paving the way for
more advanced and versatile image retrieval systems.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        Hashing Methods 
      
        Image Retrieval 
      
        Tools & Libraries 
      
        Multimodal Retrieval 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/bruch2024optimistic/">Optimistic Query Routing In Clustering-based Approximate Maximum Inner Product Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Optimistic Query Routing In Clustering-based Approximate Maximum Inner Product Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Optimistic Query Routing In Clustering-based Approximate Maximum Inner Product Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Bruch Sebastian, Krishnan Aditya, Nardini Franco Maria</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>6</td>
    <td><p>Clustering-based nearest neighbor search is an effective method in which
points are partitioned into geometric shards to form an index, with only a few
shards searched during query processing to find a set of top-\(k\) vectors. Even
though the search efficacy is heavily influenced by the algorithm that
identifies the shards to probe, it has received little attention in the
literature. This work bridges that gap by studying routing in clustering-based
maximum inner product search. We unpack existing routers and notice the
surprising contribution of optimism. We then take a page from the sequential
decision making literature and formalize that insight following the principle
of ``optimism in the face of uncertainty.â€™â€™ In particular, we present a
framework that incorporates the moments of the distribution of inner products
within each shard to estimate the maximum inner product. We then present an
instance of our algorithm that uses only the first two moments to reach the
same accuracy as state-of-the-art routers such as ScaNN by probing up to \(50%\)
fewer points on benchmark datasets. Our algorithm is also space-efficient: we
design a sketch of the second moment whose size is independent of the number of
points and requires \(\mathcal{O}(1)\) vectors per shard.</p>
</td>
    <td>
      
        AAAI 
      
        DATASETS 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/bruch2024efficient/">Efficient Inverted Indexes For Approximate Retrieval Over Learned Sparse Representations</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Efficient Inverted Indexes For Approximate Retrieval Over Learned Sparse Representations' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Efficient Inverted Indexes For Approximate Retrieval Over Learned Sparse Representations' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Bruch et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval</td>
    <td>6</td>
    <td><p>Learned sparse representations form an attractive class of contextual
embeddings for text retrieval. That is so because they are effective models of
relevance and are interpretable by design. Despite their apparent compatibility
with inverted indexes, however, retrieval over sparse embeddings remains
challenging. That is due to the distributional differences between learned
embeddings and term frequency-based lexical models of relevance such as BM25.
Recognizing this challenge, a great deal of research has gone into, among other
things, designing retrieval algorithms tailored to the properties of learned
sparse representations, including approximate retrieval systems. In fact, this
task featured prominently in the latest BigANN Challenge at NeurIPS 2023, where
approximate algorithms were evaluated on a large benchmark dataset by
throughput and recall. In this work, we propose a novel organization of the
inverted index that enables fast yet effective approximate retrieval over
learned sparse embeddings. Our approach organizes inverted lists into
geometrically-cohesive blocks, each equipped with a summary vector. During
query processing, we quickly determine if a block must be evaluated using the
summaries. As we show experimentally, single-threaded query processing using
our method, Seismic, reaches sub-millisecond per-query latency on various
sparse embeddings of the MS MARCO dataset while maintaining high recall. Our
results indicate that Seismic is one to two orders of magnitude faster than
state-of-the-art inverted index-based solutions and further outperforms the
winning (graph-based) submissions to the BigANN Challenge by a significant
margin.</p>
</td>
    <td>
      
        DATASETS 
      
        Graph Based ANN 
      
        Efficiency And Optimization 
      
        Text Retrieval 
      
        SIGIR 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/bateni2024efficient/">Efficient Centroid-linkage Clustering</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Efficient Centroid-linkage Clustering' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Efficient Centroid-linkage Clustering' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Bateni et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Applied Intelligence</td>
    <td>33</td>
    <td><p>We give an efficient algorithm for Centroid-Linkage Hierarchical
Agglomerative Clustering (HAC), which computes a \(c\)-approximate clustering in
roughly \(n^{1+O(1/c^2)}\) time. We obtain our result by combining a new
Centroid-Linkage HAC algorithm with a novel fully dynamic data structure for
nearest neighbor search which works under adaptive updates.
  We also evaluate our algorithm empirically. By leveraging a state-of-the-art
nearest-neighbor search library, we obtain a fast and accurate Centroid-Linkage
HAC algorithm. Compared to an existing state-of-the-art exact baseline, our
implementation maintains the clustering quality while delivering up to a
\(36\times\) speedup due to performing fewer distance comparisons.</p>
</td>
    <td>
      
        Tools & Libraries 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/backurs2024efficiently/">Efficiently Computing Similarities To Private Datasets</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Efficiently Computing Similarities To Private Datasets' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Efficiently Computing Similarities To Private Datasets' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Backurs et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</td>
    <td>23</td>
    <td><p>Many methods in differentially private model training rely on computing the
similarity between a query point (such as public or synthetic data) and private
data. We abstract out this common subroutine and study the following
fundamental algorithmic problem: Given a similarity function \(f\) and a large
high-dimensional private dataset \(X \subset \mathbb{R}^d\), output a
differentially private (DP) data structure which approximates \(\sum_{x \in X}
f(x,y)\) for any query \(y\). We consider the cases where \(f\) is a kernel
function, such as \(f(x,y) = e^{-|x-y|_2^2/\sigma^2}\) (also known as DP kernel
density estimation), or a distance function such as \(f(x,y) = |x-y|_2\), among
others.
  Our theoretical results improve upon prior work and give better
privacy-utility trade-offs as well as faster query times for a wide range of
kernels and distance functions. The unifying approach behind our results is
leveraging `low-dimensional structuresâ€™ present in the specific functions \(f\)
that we study, using tools such as provable dimensionality reduction,
approximation theory, and one-dimensional decomposition of the functions. Our
algorithms empirically exhibit improved query times and accuracy over prior
state of the art. We also present an application to DP classification. Our
experiments demonstrate that the simple methodology of classifying based on
average similarity is orders of magnitude faster than prior DP-SGD based
approaches for comparable accuracy.</p>
</td>
    <td>
      
        DATASETS 
      
        ICASSP 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/bhatnagar2024piecewise/">Piecewise-linear Manifolds For Deep Metric Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Piecewise-linear Manifolds For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Piecewise-linear Manifolds For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Bhatnagar Shubhang, Ahuja Narendra</td> <!-- ðŸ”§ You were missing this -->
    <td>Transactions of the American Mathematical Society</td>
    <td>7</td>
    <td><p>Unsupervised deep metric learning (UDML) focuses on learning a semantic
representation space using only unlabeled data. This challenging problem
requires accurately estimating the similarity between data points, which is
used to supervise a deep network. For this purpose, we propose to model the
high-dimensional data manifold using a piecewise-linear approximation, with
each low-dimensional linear piece approximating the data manifold in a small
neighborhood of a point. These neighborhoods are used to estimate similarity
between data points. We empirically show that this similarity estimate
correlates better with the ground truth than the similarity estimates of
current state-of-the-art techniques. We also show that proxies, commonly used
in supervised metric learning, can be used to model the piecewise-linear
manifold in an unsupervised setting, helping improve performance. Our method
outperforms existing unsupervised metric learning approaches on standard
zero-shot image retrieval benchmarks.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/aamand2024hashing/">Hashing For Sampling-based Estimation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hashing For Sampling-based Estimation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hashing For Sampling-based Estimation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Aamand et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>116</td>
    <td><p>Hash-based sampling and estimation are common themes in computing. Using
hashing for sampling gives us the coordination needed to compare samples from
different sets. Hashing is also used when we want to count distinct elements.
The quality of the estimator for, say, the Jaccard similarity between two sets,
depends on the concentration of the number of sampled elements from their
intersection. Often we want to compare one query set against many stored sets
to find one of the most similar sets, so we need strong concentration and low
error-probability. In this paper, we provide strong explicit concentration
bounds for Tornado Tabulation hashing [Bercea, Beretta, Klausen, Houen, and
Thorup, FOCSâ€™23] which is a realistic constant time hashing scheme. Previous
concentration bounds for fast hashing were off by orders of magnitude, in the
sample size needed to guarantee the same concentration. The true power of our
result appears when applied in the local uniformity framework by [Dahlgaard,
Knudsen, Rotenberg, and Thorup, STOCâ€™15].</p>
</td>
    <td>
      
        AAAI 
      
        Tools & Libraries 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/tripathi2024honeybee/">Honeybee: A Scalable Modular Framework For Creating Multimodal Oncology Datasets With Foundational Embedding Models</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Honeybee: A Scalable Modular Framework For Creating Multimodal Oncology Datasets With Foundational Embedding Models' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Honeybee: A Scalable Modular Framework For Creating Multimodal Oncology Datasets With Foundational Embedding Models' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Tripathi et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Sensors</td>
    <td>9</td>
    <td><p>Developing accurate machine learning models for oncology requires
large-scale, high-quality multimodal datasets. However, creating such datasets
remains challenging due to the complexity and heterogeneity of medical data. To
address this challenge, we introduce HoneyBee, a scalable modular framework for
building multimodal oncology datasets that leverages foundation models to
generate representative embeddings. HoneyBee integrates various data
modalities, including clinical diagnostic and pathology imaging data, medical
notes, reports, records, and molecular data. It employs data preprocessing
techniques and foundation models to generate embeddings that capture the
essential features and relationships within the raw medical data. The generated
embeddings are stored in a structured format using Hugging Face datasets and
PyTorch dataloaders for accessibility. Vector databases enable efficient
querying and retrieval for machine learning applications. We demonstrate the
effectiveness of HoneyBee through experiments assessing the quality and
representativeness of these embeddings. The framework is designed to be
extensible to other medical domains and aims to accelerate oncology research by
providing high-quality, machine learning-ready datasets. HoneyBee is an ongoing
open-source effort, and the code, datasets, and models are available at the
project repository.</p>
</td>
    <td>
      
        DATASETS 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/tian2024fusionanns/">Fusionanns: An Efficient CPU/GPU Cooperative Processing Architecture For Billion-scale Approximate Nearest Neighbor Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fusionanns: An Efficient CPU/GPU Cooperative Processing Architecture For Billion-scale Approximate Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fusionanns: An Efficient CPU/GPU Cooperative Processing Architecture For Billion-scale Approximate Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Tian et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2023 60th ACM/IEEE Design Automation Conference (DAC)</td>
    <td>7</td>
    <td><p>Approximate nearest neighbor search (ANNS) has emerged as a crucial component
of database and AI infrastructure. Ever-increasing vector datasets pose
significant challenges in terms of performance, cost, and accuracy for ANNS
services. None of modern ANNS systems can address these issues simultaneously.
We present FusionANNS, a high-throughput, low-latency, cost-efficient, and
high-accuracy ANNS system for billion-scale datasets using SSDs and only one
entry-level GPU. The key idea of FusionANNS lies in CPU/GPU collaborative
filtering and re-ranking mechanisms, which significantly reduce I/O operations
across CPUs, GPU, and SSDs to break through the I/O performance bottleneck.
Specifically, we propose three novel designs: (1) multi-tiered indexing to
avoid data swapping between CPUs and GPU, (2) heuristic re-ranking to eliminate
unnecessary I/Os and computations while guaranteeing high accuracy, and (3)
redundant-aware I/O deduplication to further improve I/O efficiency. We
implement FusionANNS and compare it with the state-of-the-art SSD-based ANNS
system â€“ SPANN and GPU-accelerated in-memory ANNS system â€“ RUMMY.
Experimental results show that FusionANNS achieves 1) 9.4-13.1X higher query
per second (QPS) and 5.7-8.8X higher cost efficiency compared with SPANN; 2)
and 2-4.9X higher QPS and 2.3-6.8X higher cost efficiency compared with RUMMY,
while guaranteeing low latency and high accuracy.</p>
</td>
    <td>
      
        Large Scale Search 
      
        DATASETS 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/su%C3%A1rez2024beblid/">BEBLID: Boosted Efficient Binary Local Image Descriptor</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=BEBLID: Boosted Efficient Binary Local Image Descriptor' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=BEBLID: Boosted Efficient Binary Local Image Descriptor' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>SuÃ¡rez et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Pattern Recognition Letters</td>
    <td>87</td>
    <td><p>Efficient matching of local image features is a fundamental task in many
computer vision applications. However, the real-time performance of top
matching algorithms is compromised in computationally limited devices, such as
mobile phones or drones, due to the simplicity of their hardware and their
finite energy supply. In this paper we introduce BEBLID, an efficient learned
binary image descriptor. It improves our previous real-valued descriptor,
BELID, making it both more efficient for matching and more accurate. To this
end we use AdaBoost with an improved weak-learner training scheme that produces
better local descriptions. Further, we binarize our descriptor by forcing all
weak-learners to have the same weight in the strong learner combination and
train it in an unbalanced data set to address the asymmetries arising in
matching and retrieval tasks. In our experiments BEBLID achieves an accuracy
close to SIFT and better computational efficiency than ORB, the fastest
algorithm in the literature.</p>
</td>
    <td>
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2024</td>
    <td>
      <a href="/publications/zeighami2024nudge/">NUDGE: Lightweight Non-parametric Fine-tuning Of Embeddings For Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=NUDGE: Lightweight Non-parametric Fine-tuning Of Embeddings For Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=NUDGE: Lightweight Non-parametric Fine-tuning Of Embeddings For Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zeighami Sepanta, Wellmer Zac, Parameswaran Aditya</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</td>
    <td>5</td>
    <td><p>\(k\)-Nearest Neighbor search on dense vector embeddings (\(k\)-NN retrieval)
from pre-trained embedding models is the predominant retrieval method for text
and images, as well as Retrieval-Augmented Generation (RAG) pipelines. In
practice, application developers often fine-tune the embeddings to improve
their accuracy on the dataset and query workload in hand. Existing approaches
either fine-tune the pre-trained model itself or, more efficiently, but at the
cost of accuracy, train adaptor models to transform the output of the
pre-trained model. We present NUDGE, a family of novel non-parametric embedding
fine-tuning approaches that are significantly more accurate and efficient than
both sets of existing approaches. NUDGE directly modifies the embeddings of
data records to maximize the accuracy of \(k\)-NN retrieval. We present a
thorough theoretical and experimental study of NUDGEâ€™s non-parametric approach.
We show that even though the underlying problem is NP-Hard, constrained
variations can be solved efficiently. These constraints additionally ensure
that the changes to the embeddings are modest, avoiding large distortions to
the semantics learned during pre-training. In experiments across five
pre-trained models and nine standard text and image retrieval datasets, NUDGE
runs in minutes and often improves NDCG@10 by more than 10% over existing
fine-tuning methods. On average, NUDGE provides 3.3x and 4.3x higher increase
in accuracy and runs 200x and 3x faster, respectively, over fine-tuning the
pre-trained model and training adaptors.</p>
</td>
    <td>
      
        Image Retrieval 
      
        SIGIR 
      
        DATASETS 
      
    </td>
    </tr>      
    
    
      
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/ravfogel2023description/">Description-based Text Similarity</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Description-based Text Similarity' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Description-based Text Similarity' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ravfogel et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Sensors</td>
    <td>8</td>
    <td><p>Identifying texts with a given semantics is central for many information
seeking scenarios. Similarity search over vector embeddings appear to be
central to this ability, yet the similarity reflected in current text
embeddings is corpus-driven, and is inconsistent and sub-optimal for many use
cases. What, then, is a good notion of similarity for effective retrieval of
text?
  We identify the need to search for texts based on abstract descriptions of
their content, and the corresponding notion of <em>description based
similarity</em>. We demonstrate the inadequacy of current text embeddings and
propose an alternative model that significantly improves when used in standard
nearest neighbor search. The model is trained using positive and negative pairs
sourced through prompting a LLM, demonstrating how data from LLMs can be used
for creating new capabilities not immediately possible using the original
model.</p>
</td>
    <td>
      
        Alt 
      
        Similarity Search 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/rajput2023recommender/">Recommender Systems With Generative Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Recommender Systems With Generative Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Recommender Systems With Generative Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Rajput et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>17</td>
    <td><p>Modern recommender systems perform large-scale retrieval by first embedding
queries and item candidates in the same unified space, followed by approximate
nearest neighbor search to select top candidates given a query embedding. In
this paper, we propose a novel generative retrieval approach, where the
retrieval model autoregressively decodes the identifiers of the target
candidates. To that end, we create semantically meaningful tuple of codewords
to serve as a Semantic ID for each item. Given Semantic IDs for items in a user
session, a Transformer-based sequence-to-sequence model is trained to predict
the Semantic ID of the next item that the user will interact with. To the best
of our knowledge, this is the first Semantic ID-based generative model for
recommendation tasks. We show that recommender systems trained with the
proposed paradigm significantly outperform the current SOTA models on various
datasets. In addition, we show that incorporating Semantic IDs into the
sequence-to-sequence model enhances its ability to generalize, as evidenced by
the improved retrieval performance observed for items with no prior interaction
history.</p>
</td>
    <td>
      
        Recommender Systems 
      
        Evaluation 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/rabbani2023large/">Large-scale Distributed Learning Via Private On-device Locality-sensitive Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Large-scale Distributed Learning Via Private On-device Locality-sensitive Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Large-scale Distributed Learning Via Private On-device Locality-sensitive Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Rabbani Tahseen, Bornstein Marco, Huang Furong</td> <!-- ðŸ”§ You were missing this -->
    <td>2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)</td>
    <td>7</td>
    <td><p>Locality-sensitive hashing (LSH) based frameworks have been used efficiently
to select weight vectors in a dense hidden layer with high cosine similarity to
an input, enabling dynamic pruning. While this type of scheme has been shown to
improve computational training efficiency, existing algorithms require repeated
randomized projection of the full layer weight, which is impractical for
computational- and memory-constrained devices. In a distributed setting,
deferring LSH analysis to a centralized host is (i) slow if the device cluster
is large and (ii) requires access to input data which is forbidden in a
federated context. Using a new family of hash functions, we develop one of the
first private, personalized, and memory-efficient on-device LSH frameworks. Our
framework enables privacy and personalization by allowing each device to
generate hash tables, without the help of a central host, using device-specific
hashing hyper-parameters (e.g. number of hash tables or hash length). Hash
tables are generated with a compressed set of the full weights, and can be
serially generated and discarded if the process is memory-intensive. This
allows devices to avoid maintaining (i) the fully-sized model and (ii) large
amounts of hash tables in local memory for LSH analysis. We prove several
statistical and sensitivity properties of our hash functions, and
experimentally demonstrate that our framework is competitive in training
large-scale recommender networks compared to other LSH frameworks which assume
unrestricted on-device capacity.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        Efficiency And Optimization 
      
        Recommender Systems 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/prezza2023algorithms/">Algorithms For Massive Data -- Lecture Notes</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Algorithms For Massive Data -- Lecture Notes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Algorithms For Massive Data -- Lecture Notes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Prezza Nicola</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>36</td>
    <td><p>These are the lecture notes for the course CM0622 - Algorithms for Massive
Data, Caâ€™ Foscari University of Venice. The goal of this course is to introduce
algorithmic techniques for dealing with massive data: data so large that it
does not fit in the computerâ€™s memory. There are two main solutions to deal
with massive data: (lossless) compressed data structures and (lossy) data
sketches. These notes cover both topics: compressed suffix arrays,
probabilistic filters, sketching under various metrics, Locality Sensitive
Hashing, nearest neighbour search, algorithms on streams.</p>
</td>
    <td>
      
        Similarity Search 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/peer2023towards/">Towards Writer Retrieval For Historical Datasets</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Towards Writer Retrieval For Historical Datasets' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Towards Writer Retrieval For Historical Datasets' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Peer Marco, Kleber Florian, Sablatnig Robert</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>7</td>
    <td><p>This paper presents an unsupervised approach for writer retrieval based on
clustering SIFT descriptors detected at keypoint locations resulting in
pseudo-cluster labels. With those cluster labels, a residual network followed
by our proposed NetRVLAD, an encoding layer with reduced complexity compared to
NetVLAD, is trained on 32x32 patches at keypoint locations. Additionally, we
suggest a graph-based reranking algorithm called SGR to exploit similarities of
the page embeddings to boost the retrieval performance. Our approach is
evaluated on two historical datasets (Historical-WI and HisIR19). We include an
evaluation of different backbones and NetRVLAD. It competes with related work
on historical datasets without using explicit encodings. We set a new
State-of-the-art on both datasets by applying our reranking scheme and show
that our approach achieves comparable performance on a modern dataset as well.</p>
</td>
    <td>
      
        Graph Based ANN 
      
        DATASETS 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/pang2023locally/">Locally Stylized Neural Radiance Fields</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Locally Stylized Neural Radiance Fields' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Locally Stylized Neural Radiance Fields' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Pang Hong-wing, Hua Binh-son, Yeung Sai-kit</td> <!-- ðŸ”§ You were missing this -->
    <td>2023 IEEE/CVF International Conference on Computer Vision (ICCV)</td>
    <td>11</td>
    <td><p>In recent years, there has been increasing interest in applying stylization
on 3D scenes from a reference style image, in particular onto neural radiance
fields (NeRF). While performing stylization directly on NeRF guarantees
appearance consistency over arbitrary novel views, it is a challenging problem
to guide the transfer of patterns from the style image onto different parts of
the NeRF scene. In this work, we propose a stylization framework for NeRF based
on local style transfer. In particular, we use a hash-grid encoding to learn
the embedding of the appearance and geometry components, and show that the
mapping defined by the hash table allows us to control the stylization to a
certain extent. Stylization is then achieved by optimizing the appearance
branch while keeping the geometry branch fixed. To support local style
transfer, we propose a new loss function that utilizes a segmentation network
and bipartite matching to establish region correspondences between the style
image and the content images obtained from volume rendering. Our experiments
show that our method yields plausible stylization results with novel view
synthesis while having flexible controllability via manipulating and
customizing the region correspondences.</p>
</td>
    <td>
      
        ICCV 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/palmer2023efficient/">Efficient Online String Matching Through Linked Weak Factors</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Efficient Online String Matching Through Linked Weak Factors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Efficient Online String Matching Through Linked Weak Factors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Palmer Matthew N., Faro Simone, Scafiti Stefano</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>16</td>
    <td><p>Online string matching is a computational problem involving the search for
patterns or substrings in a large text dataset, with the pattern and text being
processed sequentially, without prior access to the entire text. Its relevance
stems from applications in data compression, data mining, text editing, and
bioinformatics, where rapid and efficient pattern matching is crucial. Various
solutions have been proposed over the past few decades, employing diverse
techniques. Recently, weak recognition approaches have attracted increasing
attention. This paper presents Hash Chain, a new algorithm based on a robust
weak factor recognition approach that connects adjacent factors through
hashing. Despite its O(nm) complexity, the algorithm exhibits a sublinear
behavior in practice and achieves superior performance compared to the most
effective algorithms.</p>
</td>
    <td>
      
        DATASETS 
      
        Tools & Libraries 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/ootomo2023cagra/">CAGRA: Highly Parallel Graph Construction And Approximate Nearest Neighbor Search For Gpus</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=CAGRA: Highly Parallel Graph Construction And Approximate Nearest Neighbor Search For Gpus' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=CAGRA: Highly Parallel Graph Construction And Approximate Nearest Neighbor Search For Gpus' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ootomo et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2024 IEEE 40th International Conference on Data Engineering (ICDE)</td>
    <td>7</td>
    <td><p>Approximate Nearest Neighbor Search (ANNS) plays a critical role in various
disciplines spanning data mining and artificial intelligence, from information
retrieval and computer vision to natural language processing and recommender
systems. Data volumes have soared in recent years and the computational cost of
an exhaustive exact nearest neighbor search is often prohibitive, necessitating
the adoption of approximate techniques. The balanced performance and recall of
graph-based approaches have more recently garnered significant attention in
ANNS algorithms, however, only a few studies have explored harnessing the power
of GPUs and multi-core processors despite the widespread use of massively
parallel and general-purpose computing. To bridge this gap, we introduce a
novel parallel computing hardware-based proximity graph and search algorithm.
By leveraging the high-performance capabilities of modern hardware, our
approach achieves remarkable efficiency gains. In particular, our method
surpasses existing CPU and GPU-based methods in constructing the proximity
graph, demonstrating higher throughput in both large- and small-batch searches
while maintaining compatible accuracy. In graph construction time, our method,
CAGRA, is 2.2~27x faster than HNSW, which is one of the CPU SOTA
implementations. In large-batch query throughput in the 90% to 95% recall
range, our method is 33~77x faster than HNSW, and is 3.8~8.8x faster than the
SOTA implementations for GPU. For a single query, our method is 3.4~53x faster
than HNSW at 95% recall.</p>
</td>
    <td>
      
        Graph Based ANN 
      
        Recommender Systems 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/ng2023unsupervised/">Unsupervised Hashing With Similarity Distribution Calibration</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Unsupervised Hashing With Similarity Distribution Calibration' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Unsupervised Hashing With Similarity Distribution Calibration' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ng et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Image Processing</td>
    <td>15</td>
    <td><p>Unsupervised hashing methods typically aim to preserve the similarity between
data points in a feature space by mapping them to binary hash codes. However,
these methods often overlook the fact that the similarity between data points
in the continuous feature space may not be preserved in the discrete hash code
space, due to the limited similarity range of hash codes. The similarity range
is bounded by the code length and can lead to a problem known as similarity
collapse. That is, the positive and negative pairs of data points become less
distinguishable from each other in the hash space. To alleviate this problem,
in this paper a novel Similarity Distribution Calibration (SDC) method is
introduced. SDC aligns the hash code similarity distribution towards a
calibration distribution (e.g., beta distribution) with sufficient spread
across the entire similarity range, thus alleviating the similarity collapse
problem. Extensive experiments show that our SDC outperforms significantly the
state-of-the-art alternatives on coarse category-level and instance-level image
retrieval. Code is available at https://github.com/kamwoh/sdc.</p>
</td>
    <td>
      
        Alt 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/neuman2023graph/">Graph Laplacians On Shared Nearest Neighbor Graphs And Graph Laplacians On \(k\)-nearest Neighbor Graphs Having The Same Limit</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Graph Laplacians On Shared Nearest Neighbor Graphs And Graph Laplacians On \(k\)-nearest Neighbor Graphs Having The Same Limit' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Graph Laplacians On Shared Nearest Neighbor Graphs And Graph Laplacians On \(k\)-nearest Neighbor Graphs Having The Same Limit' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Neuman A. Martina</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>10</td>
    <td><p>A Shared Nearest Neighbor (SNN) graph is a type of graph construction using
shared nearest neighbor information, which is a secondary similarity measure
based on the rankings induced by a primary \(k\)-nearest neighbor (\(k\)-NN)
measure. SNN measures have been touted as being less prone to the curse of
dimensionality than conventional distance measures, and thus methods using SNN
graphs have been widely used in applications, particularly in clustering
high-dimensional data sets and in finding outliers in subspaces of high
dimensional data. Despite this, the theoretical study of SNN graphs and graph
Laplacians remains unexplored. In this pioneering work, we make the first
contribution in this direction. We show that large scale asymptotics of an SNN
graph Laplacian reach a consistent continuum limit; this limit is the same as
that of a \(k\)-NN graph Laplacian. Moreover, we show that the pointwise
convergence rate of the graph Laplacian is linear with respect to \((k/n)^{1/m}\)
with high probability.</p>
</td>
    <td>
      
        Graph Based ANN 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/mandarapu2023arkade/">Arkade: K-nearest Neighbor Search With Non-euclidean Distances Using GPU Ray Tracing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Arkade: K-nearest Neighbor Search With Non-euclidean Distances Using GPU Ray Tracing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Arkade: K-nearest Neighbor Search With Non-euclidean Distances Using GPU Ray Tracing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Mandarapu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 38th ACM International Conference on Supercomputing</td>
    <td>5</td>
    <td><p>High-performance implementations of \(k\)-Nearest Neighbor Search (\(k\)NN) in
low dimensions use tree-based data structures. Tree algorithms are hard to
parallelize on GPUs due to their irregularity. However, newer Nvidia GPUs offer
hardware support for tree operations through ray-tracing cores. Recent works
have proposed using RT cores to implement \(k\)NN search, but they all have a
hardware-imposed constraint on the distance metric used in the search â€“ the
Euclidean distance. We propose and implement two reductions to support \(k\)NN
for a broad range of distances other than the Euclidean distance: Arkade
Filter-Refine and Arkade Monotone Transformation, each of which allows
non-Euclidean distance-based nearest neighbor queries to be performed in terms
of the Euclidean distance. With our reductions, we observe that \(k\)NN search
time speedups range between \(1.6\)x-\(200\)x and \(1.3\)x-\(33.1\)x over various
state-of-the-art GPU shader core and RT core baselines, respectively. In
evaluation, we provide several insights on RT architecturesâ€™ ability to
efficiently build and traverse the tree by analyzing the \(k\)NN search time
trends.</p>
</td>
    <td>
      
        Tree Based ANN 
      
        Distance Metric Learning 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/manohar2023parlayann/">Parlayann: Scalable And Deterministic Parallel Graph-based Approximate Nearest Neighbor Search Algorithms</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Parlayann: Scalable And Deterministic Parallel Graph-based Approximate Nearest Neighbor Search Algorithms' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Parlayann: Scalable And Deterministic Parallel Graph-based Approximate Nearest Neighbor Search Algorithms' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Manohar et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 29th ACM SIGPLAN Annual Symposium on Principles and Practice of Parallel Programming</td>
    <td>5</td>
    <td><p>Approximate nearest-neighbor search (ANNS) algorithms are a key part of the
modern deep learning stack due to enabling efficient similarity search over
high-dimensional vector space representations (i.e., embeddings) of data. Among
various ANNS algorithms, graph-based algorithms are known to achieve the best
throughput-recall tradeoffs. Despite the large scale of modern ANNS datasets,
existing parallel graph based implementations suffer from significant
challenges to scale to large datasets due to heavy use of locks and other
sequential bottlenecks, which 1) prevents them from efficiently scaling to a
large number of processors, and 2) results in nondeterminism that is
undesirable in certain applications.
  In this paper, we introduce ParlayANN, a library of deterministic and
parallel graph-based approximate nearest neighbor search algorithms, along with
a set of useful tools for developing such algorithms. In this library, we
develop novel parallel implementations for four state-of-the-art graph-based
ANNS algorithms that scale to billion-scale datasets. Our algorithms are
deterministic and achieve high scalability across a diverse set of challenging
datasets. In addition to the new algorithmic ideas, we also conduct a detailed
experimental study of our new algorithms as well as two existing non-graph
approaches. Our experimental results both validate the effectiveness of our new
techniques, and lead to a comprehensive comparison among ANNS algorithms on
large scale datasets with a list of interesting findings.</p>
</td>
    <td>
      
        DATASETS 
      
        Graph Based ANN 
      
        Large Scale Search 
      
        Similarity Search 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/wang2023graph/">Graph-collaborated Auto-encoder Hashing For Multi-view Binary Clustering</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Graph-collaborated Auto-encoder Hashing For Multi-view Binary Clustering' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Graph-collaborated Auto-encoder Hashing For Multi-view Binary Clustering' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Neural Networks and Learning Systems</td>
    <td>56</td>
    <td><p>Unsupervised hashing methods have attracted widespread attention with the
explosive growth of large-scale data, which can greatly reduce storage and
computation by learning compact binary codes. Existing unsupervised hashing
methods attempt to exploit the valuable information from samples, which fails
to take the local geometric structure of unlabeled samples into consideration.
Moreover, hashing based on auto-encoders aims to minimize the reconstruction
loss between the input data and binary codes, which ignores the potential
consistency and complementarity of multiple sources data. To address the above
issues, we propose a hashing algorithm based on auto-encoders for multi-view
binary clustering, which dynamically learns affinity graphs with low-rank
constraints and adopts collaboratively learning between auto-encoders and
affinity graphs to learn a unified binary code, called Graph-Collaborated
Auto-Encoder Hashing for Multi-view Binary Clustering (GCAE). Specifically, we
propose a multi-view affinity graphs learning model with low-rank constraint,
which can mine the underlying geometric information from multi-view data. Then,
we design an encoder-decoder paradigm to collaborate the multiple affinity
graphs, which can learn a unified binary code effectively. Notably, we impose
the decorrelation and code balance constraints on binary codes to reduce the
quantization errors. Finally, we utilize an alternating iterative optimization
scheme to obtain the multi-view clustering results. Extensive experimental
results on \(5\) public datasets are provided to reveal the effectiveness of the
algorithm and its superior performance over other state-of-the-art
alternatives.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Alt 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/ma2023anserini/">Anserini Gets Dense Retrieval: Integration Of Lucene's HNSW Indexes</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Anserini Gets Dense Retrieval: Integration Of Lucene's HNSW Indexes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Anserini Gets Dense Retrieval: Integration Of Lucene's HNSW Indexes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ma Xueguang, Teofili Tommaso, Lin Jimmy</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 32nd ACM International Conference on Information and Knowledge Management</td>
    <td>5</td>
    <td><p>Anserini is a Lucene-based toolkit for reproducible information retrieval
research in Java that has been gaining traction in the community. It provides
retrieval capabilities for both â€œtraditionalâ€ bag-of-words retrieval models
such as BM25 as well as retrieval using learned sparse representations such as
SPLADE. With Pyserini, which provides a Python interface to Anserini, users
gain access to both sparse and dense retrieval models, as Pyserini implements
bindings to the Faiss vector search library alongside Lucene inverted indexes
in a uniform, consistent interface. Nevertheless, hybrid fusion techniques that
integrate sparse and dense retrieval models need to stitch together results
from two completely different â€œsoftware stacksâ€, which creates unnecessary
complexities and inefficiencies. However, the introduction of HNSW indexes for
dense vector search in Lucene promises the integration of both dense and sparse
retrieval within a single software framework. We explore exactly this
integration in the context of Anserini. Experiments on the MS MARCO passage and
BEIR datasets show that our Anserini HNSW integration supports (reasonably)
effective and (reasonably) efficient approximate nearest neighbor search for
dense retrieval models, using only Lucene.</p>
</td>
    <td>
      
        CIKM 
      
        DATASETS 
      
        Tools & Libraries 
      
        Graph Based ANN 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/zhang2023cafe/">CAFE: Towards Compact, Adaptive, And Fast Embedding For Large-scale Recommendation Models</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=CAFE: Towards Compact, Adaptive, And Fast Embedding For Large-scale Recommendation Models' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=CAFE: Towards Compact, Adaptive, And Fast Embedding For Large-scale Recommendation Models' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the ACM on Management of Data</td>
    <td>8</td>
    <td><p>Recently, the growing memory demands of embedding tables in Deep Learning
Recommendation Models (DLRMs) pose great challenges for model training and
deployment. Existing embedding compression solutions cannot simultaneously meet
three key design requirements: memory efficiency, low latency, and adaptability
to dynamic data distribution. This paper presents CAFE, a Compact, Adaptive,
and Fast Embedding compression framework that addresses the above requirements.
The design philosophy of CAFE is to dynamically allocate more memory resources
to important features (called hot features), and allocate less memory to
unimportant ones. In CAFE, we propose a fast and lightweight sketch data
structure, named HotSketch, to capture feature importance and report hot
features in real time. For each reported hot feature, we assign it a unique
embedding. For the non-hot features, we allow multiple features to share one
embedding by using hash embedding technique. Guided by our design philosophy,
we further propose a multi-level hash embedding framework to optimize the
embedding tables of non-hot features. We theoretically analyze the accuracy of
HotSketch, and analyze the model convergence against deviation. Extensive
experiments show that CAFE significantly outperforms existing embedding
compression methods, yielding 3.92% and 3.68% superior testing AUC on Criteo
Kaggle dataset and CriteoTB dataset at a compression ratio of 10000x. The
source codes of CAFE are available at GitHub.</p>
</td>
    <td>
      
        Efficiency And Optimization 
      
        DATASETS 
      
        Tools & Libraries 
      
        Recommender Systems 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/lu2023attributes/">Attributes Grouping And Mining Hashing For Fine-grained Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Attributes Grouping And Mining Hashing For Fine-grained Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Attributes Grouping And Mining Hashing For Fine-grained Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 31st ACM International Conference on Multimedia</td>
    <td>8</td>
    <td><p>In recent years, hashing methods have been popular in the large-scale media
search for low storage and strong representation capabilities. To describe
objects with similar overall appearance but subtle differences, more and more
studies focus on hashing-based fine-grained image retrieval. Existing hashing
networks usually generate both local and global features through attention
guidance on the same deep activation tensor, which limits the diversity of
feature representations. To handle this limitation, we substitute convolutional
descriptors for attention-guided features and propose an Attributes Grouping
and Mining Hashing (AGMH), which groups and embeds the category-specific visual
attributes in multiple descriptors to generate a comprehensive feature
representation for efficient fine-grained image retrieval. Specifically, an
Attention Dispersion Loss (ADL) is designed to force the descriptors to attend
to various local regions and capture diverse subtle details. Moreover, we
propose a Stepwise Interactive External Attention (SIEA) to mine critical
attributes in each descriptor and construct correlations between fine-grained
attributes and objects. The attention mechanism is dedicated to learning
discrete attributes, which will not cost additional computations in hash codes
generation. Finally, the compact binary codes are learned by preserving
pairwise similarities. Experimental results demonstrate that AGMH consistently
yields the best performance against state-of-the-art methods on fine-grained
benchmark datasets.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/macgregor2023fast/">Fast Approximation Of Similarity Graphs With Kernel Density Estimation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fast Approximation Of Similarity Graphs With Kernel Density Estimation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fast Approximation Of Similarity Graphs With Kernel Density Estimation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Macgregor Peter, Sun He</td> <!-- ðŸ”§ You were missing this -->
    <td>2018 21st International Conference on Information Fusion (FUSION)</td>
    <td>12</td>
    <td><p>Constructing a similarity graph from a set \(X\) of data points in
\(\mathbb{R}^d\) is the first step of many modern clustering algorithms. However,
typical constructions of a similarity graph have high time complexity, and a
quadratic space dependency with respect to \(|X|\). We address this limitation
and present a new algorithmic framework that constructs a sparse approximation
of the fully connected similarity graph while preserving its cluster structure.
Our presented algorithm is based on the kernel density estimation problem, and
is applicable for arbitrary kernel functions. We compare our designed algorithm
with the well-known implementations from the scikit-learn library and the FAISS
library, and find that our method significantly outperforms the implementation
from both libraries on a variety of datasets.</p>
</td>
    <td>
      
        DATASETS 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/liu2023hs/">HS-GCN: Hamming Spatial Graph Convolutional Networks For Recommendation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=HS-GCN: Hamming Spatial Graph Convolutional Networks For Recommendation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=HS-GCN: Hamming Spatial Graph Convolutional Networks For Recommendation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Knowledge and Data Engineering</td>
    <td>32</td>
    <td><p>An efficient solution to the large-scale recommender system is to represent
users and items as binary hash codes in the Hamming space. Towards this end,
existing methods tend to code users by modeling their Hamming similarities with
the items they historically interact with, which are termed as the first-order
similarities in this work. Despite their efficiency, these methods suffer from
the suboptimal representative capacity, since they forgo the correlation
established by connecting multiple first-order similarities, i.e., the relation
among the indirect instances, which could be defined as the high-order
similarity. To tackle this drawback, we propose to model both the first- and
the high-order similarities in the Hamming space through the user-item
bipartite graph. Therefore, we develop a novel learning to hash framework,
namely Hamming Spatial Graph Convolutional Networks (HS-GCN), which explicitly
models the Hamming similarity and embeds it into the codes of users and items.
Extensive experiments on three public benchmark datasets demonstrate that our
proposed model significantly outperforms several state-of-the-art hashing
models, and obtains performance comparable with the real-valued recommendation
models.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Recommender Systems 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/ling2023vector/">Vector Quantization With Error Uniformly Distributed Over An Arbitrary Set</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Vector Quantization With Error Uniformly Distributed Over An Arbitrary Set' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Vector Quantization With Error Uniformly Distributed Over An Arbitrary Set' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ling Chih Wei, Li Cheuk Ting</td> <!-- ðŸ”§ You were missing this -->
    <td>2023 IEEE International Symposium on Information Theory (ISIT)</td>
    <td>5</td>
    <td><p>For uniform scalar quantization, the error distribution is approximately a
uniform distribution over an interval (which is also a 1-dimensional ball).
Nevertheless, for lattice vector quantization, the error distribution is
uniform not over a ball, but over the basic cell of the quantization lattice.
In this paper, we construct vector quantizers with periodic properties, where
the error is uniformly distributed over the n-ball, or any other prescribed
set. We then prove upper and lower bounds on the entropy of the quantized
signals. We also discuss how our construction can be applied to give a
randomized quantization scheme with a nonuniform error distribution.</p>
</td>
    <td>
      
        Quantization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/lin2023rafic/">RAFIC: Retrieval-augmented Few-shot Image Classification</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=RAFIC: Retrieval-augmented Few-shot Image Classification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=RAFIC: Retrieval-augmented Few-shot Image Classification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lin Hangfei, Miao Li, Ziai Amir</td> <!-- ðŸ”§ You were missing this -->
    <td>Findings of the Association for Computational Linguistics: EMNLP 2023</td>
    <td>5</td>
    <td><p>Few-shot image classification is the task of classifying unseen images to one
of N mutually exclusive classes, using only a small number of training examples
for each class. The limited availability of these examples (denoted as K)
presents a significant challenge to classification accuracy in some cases. To
address this, we have developed a method for augmenting the set of K with an
addition set of A retrieved images. We call this system Retrieval-Augmented
Few-shot Image Classification (RAFIC). Through a series of experiments, we
demonstrate that RAFIC markedly improves performance of few-shot image
classification across two challenging datasets. RAFIC consists of two main
components: (a) a retrieval component which uses CLIP, LAION-5B, and faiss, in
order to efficiently retrieve images similar to the supplied images, and (b)
retrieval meta-learning, which learns to judiciously utilize the retrieved
images. Code and data is available at github.com/amirziai/rafic.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        ACL 
      
        Tools & Libraries 
      
        EMNLP 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/lin2023searching/">Searching Dense Representations With Inverted Indexes</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Searching Dense Representations With Inverted Indexes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Searching Dense Representations With Inverted Indexes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lin Jimmy, Teofili Tommaso</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval</td>
    <td>17</td>
    <td><p>Nearly all implementations of top-\(k\) retrieval with dense vector
representations today take advantage of hierarchical navigable small-world
network (HNSW) indexes. However, the generation of vector representations and
efficiently searching large collections of vectors are distinct challenges that
can be decoupled. In this work, we explore the contrarian approach of
performing top-\(k\) retrieval on dense vector representations using inverted
indexes. We present experiments on the MS MARCO passage ranking dataset,
evaluating three dimensions of interest: output quality, speed, and index size.
Results show that searching dense representations using inverted indexes is
possible. Our approach exhibits reasonable effectiveness with compact indexes,
but is impractically slow. Thus, while workable, our solution does not provide
a compelling tradeoff and is perhaps best characterized today as a â€œtechnical
curiosityâ€.</p>
</td>
    <td>
      
        DATASETS 
      
        SIGIR 
      
        Graph Based ANN 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/li2023slim/">SLIM: Sparsified Late Interaction For Multi-vector Retrieval With Inverted Indexes</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=SLIM: Sparsified Late Interaction For Multi-vector Retrieval With Inverted Indexes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=SLIM: Sparsified Late Interaction For Multi-vector Retrieval With Inverted Indexes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval</td>
    <td>7</td>
    <td><p>This paper introduces Sparsified Late Interaction for Multi-vector (SLIM)
retrieval with inverted indexes. Multi-vector retrieval methods have
demonstrated their effectiveness on various retrieval datasets, and among them,
ColBERT is the most established method based on the late interaction of
contextualized token embeddings of pre-trained language models. However,
efficient ColBERT implementations require complex engineering and cannot take
advantage of off-the-shelf search libraries, impeding their practical use. To
address this issue, SLIM first maps each contextualized token vector to a
sparse, high-dimensional lexical space before performing late interaction
between these sparse token embeddings. We then introduce an efficient two-stage
retrieval architecture that includes inverted index retrieval followed by a
score refinement module to approximate the sparsified late interaction, which
is fully compatible with off-the-shelf lexical search libraries such as Lucene.
SLIM achieves competitive accuracy on MS MARCO Passages and BEIR compared to
ColBERT while being much smaller and faster on CPUs. To our knowledge, we are
the first to explore using sparse token representations for multi-vector
retrieval. Source code and data are integrated into the Pyserini IR toolkit.</p>
</td>
    <td>
      
        SIGIR 
      
        Evaluation 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/li2023dual/">Dual-stream Knowledge-preserving Hashing For Unsupervised Video Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Dual-stream Knowledge-preserving Hashing For Unsupervised Video Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Dual-stream Knowledge-preserving Hashing For Unsupervised Video Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>16</td>
    <td><p>Unsupervised video hashing usually optimizes binary codes by learning to
reconstruct input videos. Such reconstruction constraint spends much effort on
frame-level temporal context changes without focusing on video-level global
semantics that are more useful for retrieval. Hence, we address this problem by
decomposing video information into reconstruction-dependent and
semantic-dependent information, which disentangles the semantic extraction from
reconstruction constraint. Specifically, we first design a simple dual-stream
structure, including a temporal layer and a hash layer. Then, with the help of
semantic similarity knowledge obtained from self-supervision, the hash layer
learns to capture information for semantic retrieval, while the temporal layer
learns to capture the information for reconstruction. In this way, the model
naturally preserves the disentangled semantics into binary codes. Validated by
comprehensive experiments, our method consistently outperforms the
state-of-the-arts on three video benchmarks.</p>
</td>
    <td>
      
        Compact Codes 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/li2023constructing/">Constructing Tree-based Index For Efficient And Effective Dense Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Constructing Tree-based Index For Efficient And Effective Dense Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Constructing Tree-based Index For Efficient And Effective Dense Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval</td>
    <td>8</td>
    <td><p>Recent studies have shown that Dense Retrieval (DR) techniques can
significantly improve the performance of first-stage retrieval in IR systems.
Despite its empirical effectiveness, the application of DR is still limited. In
contrast to statistic retrieval models that rely on highly efficient inverted
index solutions, DR models build dense embeddings that are difficult to be
pre-processed with most existing search indexing systems. To avoid the
expensive cost of brute-force search, the Approximate Nearest Neighbor (ANN)
algorithm and corresponding indexes are widely applied to speed up the
inference process of DR models. Unfortunately, while ANN can improve the
efficiency of DR models, it usually comes with a significant price on retrieval
performance.
  To solve this issue, we propose JTR, which stands for Joint optimization of
TRee-based index and query encoding. Specifically, we design a new unified
contrastive learning loss to train tree-based index and query encoder in an
end-to-end manner. The tree-based negative sampling strategy is applied to make
the tree have the maximum heap property, which supports the effectiveness of
beam search well. Moreover, we treat the cluster assignment as an optimization
problem to update the tree-based index that allows overlapped clustering. We
evaluate JTR on numerous popular retrieval benchmarks. Experimental results
show that JTR achieves better retrieval performance while retaining high system
efficiency compared with widely-adopted baselines. It provides a potential
solution to balance efficiency and effectiveness in neural retrieval system
designs.</p>
</td>
    <td>
      
        Tree Based ANN 
      
        SIGIR 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/li2023differentially/">Differentially Private One Permutation Hashing And Bin-wise Consistent Weighted Sampling</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Differentially Private One Permutation Hashing And Bin-wise Consistent Weighted Sampling' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Differentially Private One Permutation Hashing And Bin-wise Consistent Weighted Sampling' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li Xiaoyun, Li Ping</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</td>
    <td>36</td>
    <td><p>Minwise hashing (MinHash) is a standard algorithm widely used in the
industry, for large-scale search and learning applications with the binary
(0/1) Jaccard similarity. One common use of MinHash is for processing massive
n-gram text representations so that practitioners do not have to materialize
the original data (which would be prohibitive). Another popular use of MinHash
is for building hash tables to enable sub-linear time approximate near neighbor
(ANN) search. MinHash has also been used as a tool for building large-scale
machine learning systems. The standard implementation of MinHash requires
applying \(K\) random permutations. In comparison, the method of one permutation
hashing (OPH), is an efficient alternative of MinHash which splits the data
vectors into \(K\) bins and generates hash values within each bin. OPH is
substantially more efficient and also more convenient to use.
  In this paper, we combine the differential privacy (DP) with OPH (as well as
MinHash), to propose the DP-OPH framework with three variants: DP-OPH-fix,
DP-OPH-re and DP-OPH-rand, depending on which densification strategy is adopted
to deal with empty bins in OPH. A detailed roadmap to the algorithm design is
presented along with the privacy analysis. An analytical comparison of our
proposed DP-OPH methods with the DP minwise hashing (DP-MH) is provided to
justify the advantage of DP-OPH. Experiments on similarity search confirm the
merits of DP-OPH, and guide the choice of the proper variant in different
practical scenarios. Our technique is also extended to bin-wise consistent
weighted sampling (BCWS) to develop a new DP algorithm called DP-BCWS for
non-binary data. Experiments on classification tasks demonstrate that DP-BCWS
is able to achieve excellent utility at around \(\epsilon = 5\sim 10\), where
\(\epsilon\) is the standard parameter in the language of \((\epsilon,
\delta)\)-DP.</p>
</td>
    <td>
      
        KDD 
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Large Scale Search 
      
        Alt 
      
        Similarity Search 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/leyvavallina2023data/">Data-efficient Large Scale Place Recognition With Graded Similarity Supervision</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Data-efficient Large Scale Place Recognition With Graded Similarity Supervision' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Data-efficient Large Scale Place Recognition With Graded Similarity Supervision' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Leyva-vallina Maria, Strisciuglio Nicola, Petkov Nicolai</td> <!-- ðŸ”§ You were missing this -->
    <td>2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>23</td>
    <td><p>Visual place recognition (VPR) is a fundamental task of computer vision for
visual localization. Existing methods are trained using image pairs that either
depict the same place or not. Such a binary indication does not consider
continuous relations of similarity between images of the same place taken from
different positions, determined by the continuous nature of camera pose. The
binary similarity induces a noisy supervision signal into the training of VPR
methods, which stall in local minima and require expensive hard mining
algorithms to guarantee convergence. Motivated by the fact that two images of
the same place only partially share visual cues due to camera pose differences,
we deploy an automatic re-annotation strategy to re-label VPR datasets. We
compute graded similarity labels for image pairs based on available
localization metadata. Furthermore, we propose a new Generalized Contrastive
Loss (GCL) that uses graded similarity labels for training contrastive
networks. We demonstrate that the use of the new labels and GCL allow to
dispense from hard-pair mining, and to train image descriptors that perform
better in VPR by nearest neighbor search, obtaining superior or comparable
results than methods that require expensive hard-pair mining and re-ranking
techniques. Code and models available at:
https://github.com/marialeyvallina/generalized_contrastive_loss</p>
</td>
    <td>
      
        CVPR 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/lehmann2023sliding/">Sliding Block Hashing (slick) -- Basic Algorithmic Ideas</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Sliding Block Hashing (slick) -- Basic Algorithmic Ideas' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Sliding Block Hashing (slick) -- Basic Algorithmic Ideas' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lehmann Hans-peter, Sanders Peter, Walzer Stefan</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the Ninth European Conference on Computer Systems</td>
    <td>103</td>
    <td><p>We present {\bf Sli}ding Blo{\bf ck} Hashing (Slick), a simple hash table
data structure that combines high performance with very good space efficiency.
This preliminary report outlines avenues for analysis and implementation that
we intend to pursue.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/kulkarni2023lexically/">Lexically-accelerated Dense Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Lexically-accelerated Dense Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Lexically-accelerated Dense Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Kulkarni et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval</td>
    <td>13</td>
    <td><p>Retrieval approaches that score documents based on learned dense vectors
(i.e., dense retrieval) rather than lexical signals (i.e., conventional
retrieval) are increasingly popular. Their ability to identify related
documents that do not necessarily contain the same terms as those appearing in
the userâ€™s query (thereby improving recall) is one of their key advantages.
However, to actually achieve these gains, dense retrieval approaches typically
require an exhaustive search over the document collection, making them
considerably more expensive at query-time than conventional lexical approaches.
Several techniques aim to reduce this computational overhead by approximating
the results of a full dense retriever. Although these approaches reasonably
approximate the top results, they suffer in terms of recall â€“ one of the key
advantages of dense retrieval. We introduce â€˜LADRâ€™ (Lexically-Accelerated Dense
Retrieval), a simple-yet-effective approach that improves the efficiency of
existing dense retrieval models without compromising on retrieval
effectiveness. LADR uses lexical retrieval techniques to seed a dense retrieval
exploration that uses a document proximity graph. We explore two variants of
LADR: a proactive approach that expands the search space to the neighbors of
all seed documents, and an adaptive approach that selectively searches the
documents with the highest estimated relevance in an iterative fashion. Through
extensive experiments across a variety of dense retrieval models, we find that
LADR establishes a new dense retrieval effectiveness-efficiency Pareto frontier
among approximate k nearest neighbor techniques. Further, we find that when
tuned to take around 8ms per query in retrieval latency on our hardware, LADR
consistently achieves both precision and recall that are on par with an
exhaustive search on standard benchmarks.</p>
</td>
    <td>
      
        Graph Based ANN 
      
        Efficiency And Optimization 
      
        Alt 
      
        SIGIR 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/yang2023efficient/">Efficient And Effective Similarity Search Over Bipartite Graphs</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Efficient And Effective Similarity Search Over Bipartite Graphs' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Efficient And Effective Similarity Search Over Bipartite Graphs' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yang Renchi</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the ACM Web Conference 2022</td>
    <td>9</td>
    <td><p>Similarity search over a bipartite graph aims to retrieve from the graph the
nodes that are similar to each other, which finds applications in various
fields such as online advertising, recommender systems etc. Existing similarity
measures either (i) overlook the unique properties of bipartite graphs, or (ii)
fail to capture high-order information between nodes accurately, leading to
suboptimal result quality. Recently, Hidden Personalized PageRank (HPP) is
applied to this problem and found to be more effective compared with prior
similarity measures. However, existing solutions for HPP computation incur
significant computational costs, rendering it inefficient especially on large
graphs.
  In this paper, we first identify an inherent drawback of HPP and overcome it
by proposing bidirectional HPP (BHPP). Then, we formulate similarity search
over bipartite graphs as the problem of approximate BHPP computation, and
present an efficient solution Approx-BHPP. Specifically, Approx-BHPP offers
rigorous theoretical accuracy guarantees with optimal computational complexity
by combining deterministic graph traversal with matrix operations in an
optimized and non-trivial way. Moreover, our solution achieves significant gain
in practical efficiency due to several carefully-designed optimizations.
Extensive experiments, comparing BHPP against 8 existing similarity measures
over 7 real bipartite graphs, demonstrate the effectiveness of BHPP on query
rewriting and item recommendation. Moreover, Approx-BHPP outperforms baseline
solutions often by up to orders of magnitude in terms of computational time on
both small and large datasets.</p>
</td>
    <td>
      
        Efficiency And Optimization 
      
        DATASETS 
      
        Similarity Search 
      
        Recommender Systems 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/wei2023attribute/">Attribute-aware Deep Hashing With Self-consistency For Large-scale Fine-grained Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Attribute-aware Deep Hashing With Self-consistency For Large-scale Fine-grained Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Attribute-aware Deep Hashing With Self-consistency For Large-scale Fine-grained Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wei et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Pattern Analysis and Machine Intelligence</td>
    <td>16</td>
    <td><p>Our work focuses on tackling large-scale fine-grained image retrieval as
ranking the images depicting the concept of interests (i.e., the same
sub-category labels) highest based on the fine-grained details in the query. It
is desirable to alleviate the challenges of both fine-grained nature of small
inter-class variations with large intra-class variations and explosive growth
of fine-grained data for such a practical task. In this paper, we propose
attribute-aware hashing networks with self-consistency for generating
attribute-aware hash codes to not only make the retrieval process efficient,
but also establish explicit correspondences between hash codes and visual
attributes. Specifically, based on the captured visual representations by
attention, we develop an encoder-decoder structure network of a reconstruction
task to unsupervisedly distill high-level attribute-specific vectors from the
appearance-specific visual representations without attribute annotations. Our
models are also equipped with a feature decorrelation constraint upon these
attribute vectors to strengthen their representative abilities. Then, driven by
preserving original entitiesâ€™ similarity, the required hash codes can be
generated from these attribute-specific vectors and thus become
attribute-aware. Furthermore, to combat simplicity bias in deep hashing, we
consider the model design from the perspective of the self-consistency
principle and propose to further enhance modelsâ€™ self-consistency by equipping
an additional image reconstruction path. Comprehensive quantitative experiments
under diverse empirical settings on six fine-grained retrieval datasets and two
generic retrieval datasets show the superiority of our models over competing
methods.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Neural Hashing 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/wang2023reliable/">Reliable And Efficient Evaluation Of Adversarial Robustness For Deep Hashing-based Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Reliable And Efficient Evaluation Of Adversarial Robustness For Deep Hashing-based Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Reliable And Efficient Evaluation Of Adversarial Robustness For Deep Hashing-based Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Information Forensics and Security</td>
    <td>21</td>
    <td><p>Deep hashing has been extensively applied to massive image retrieval due to
its efficiency and effectiveness. Recently, several adversarial attacks have
been presented to reveal the vulnerability of deep hashing models against
adversarial examples. However, existing attack methods suffer from degraded
performance or inefficiency because they underutilize the semantic relations
between original samples or spend a lot of time learning these relations with a
deep neural network. In this paper, we propose a novel Pharos-guided Attack,
dubbed PgA, to evaluate the adversarial robustness of deep hashing networks
reliably and efficiently. Specifically, we design pharos code to represent the
semantics of the benign image, which preserves the similarity to semantically
relevant samples and dissimilarity to irrelevant ones. It is proven that we can
quickly calculate the pharos code via a simple math formula. Accordingly, PgA
can directly conduct a reliable and efficient attack on deep hashing-based
retrieval by maximizing the similarity between the hash code of the adversarial
example and the pharos code. Extensive experiments on the benchmark datasets
verify that the proposed algorithm outperforms the prior state-of-the-arts in
both attack strength and speed.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Neural Hashing 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/indyk2023worst/">Worst-case Performance Of Popular Approximate Nearest Neighbor Search Implementations: Guarantees And Limitations</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Worst-case Performance Of Popular Approximate Nearest Neighbor Search Implementations: Guarantees And Limitations' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Worst-case Performance Of Popular Approximate Nearest Neighbor Search Implementations: Guarantees And Limitations' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Indyk Piotr, Xu Haike</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 50th Annual ACM SIGACT Symposium on Theory of Computing</td>
    <td>34</td>
    <td><p>Graph-based approaches to nearest neighbor search are popular and powerful
tools for handling large datasets in practice, but they have limited
theoretical guarantees. We study the worst-case performance of recent
graph-based approximate nearest neighbor search algorithms, such as HNSW, NSG
and DiskANN. For DiskANN, we show that its â€œslow preprocessingâ€ version
provably supports approximate nearest neighbor search query with constant
approximation ratio and poly-logarithmic query time, on data sets with bounded
â€œintrinsicâ€ dimension. For the other data structure variants studied, including
DiskANN with â€œfast preprocessingâ€, HNSW and NSG, we present a family of
instances on which the empirical query time required to achieve a â€œreasonableâ€
accuracy is linear in instance size. For example, for DiskANN, we show that the
query procedure can take at least \(0.1 n\) steps on instances of size \(n\) before
it encounters any of the \(5\) nearest neighbors of the query.</p>
</td>
    <td>
      
        Graph Based ANN 
      
        DATASETS 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/wei2023chain/">CHAIN: Exploring Global-local Spatio-temporal Information For Improved Self-supervised Video Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=CHAIN: Exploring Global-local Spatio-temporal Information For Improved Self-supervised Video Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=CHAIN: Exploring Global-local Spatio-temporal Information For Improved Self-supervised Video Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wei et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 31st ACM International Conference on Multimedia</td>
    <td>5</td>
    <td><p>Compressing videos into binary codes can improve retrieval speed and reduce
storage overhead. However, learning accurate hash codes for video retrieval can
be challenging due to high local redundancy and complex global dependencies
between video frames, especially in the absence of labels. Existing
self-supervised video hashing methods have been effective in designing
expressive temporal encoders, but have not fully utilized the temporal dynamics
and spatial appearance of videos due to less challenging and unreliable
learning tasks. To address these challenges, we begin by utilizing the
contrastive learning task to capture global spatio-temporal information of
videos for hashing. With the aid of our designed augmentation strategies, which
focus on spatial and temporal variations to create positive pairs, the learning
framework can generate hash codes that are invariant to motion, scale, and
viewpoint. Furthermore, we incorporate two collaborative learning tasks, i.e.,
frame order verification and scene change regularization, to capture local
spatio-temporal details within video frames, thereby enhancing the perception
of temporal structure and the modeling of spatio-temporal relationships. Our
proposed Contrastive Hashing with Global-Local Spatio-temporal Information
(CHAIN) outperforms state-of-the-art self-supervised video hashing methods on
four video benchmark datasets. Our codes will be released.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/horaud2023polyhedral/">Polyhedral Object Recognition By Indexing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Polyhedral Object Recognition By Indexing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Polyhedral Object Recognition By Indexing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Horaud Radu, Sossa Humberto</td> <!-- ðŸ”§ You were missing this -->
    <td>Pattern Recognition</td>
    <td>48</td>
    <td><p>In computer vision, the indexing problem is the problem of recognizing a few
objects in a large database of objects while avoiding the help of the classical
image-feature-to-object-feature matching paradigm. In this paper we address the
problem of recognizing 3-D polyhedral objects from 2-D images by indexing. Both
the objects to be recognized and the images are represented by weighted graphs.
The indexing problem is therefore the problem of determining whether a graph
extracted from the image is present or absent in a database of model graphs. We
introduce a novel method for performing this graph indexing process which is
based both on polynomial characterization of binary and weighted graphs and on
hashing. We describe in detail this polynomial characterization and then we
show how it can be used in the context of polyhedral object recognition. Next
we describe a practical recognition-by-indexing system that includes the
organization of the database, the representation of polyhedral objects in terms
of 2-D characteristic views, the representation of this views in terms of
weighted graphs, and the associated image processing. Finally, some
experimental results allow the evaluation of the system performance.</p>
</td>
    <td>
      
        CVPR 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/hou2023semstamp/">Semstamp: A Semantic Watermark With Paraphrastic Robustness For Text Generation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Semstamp: A Semantic Watermark With Paraphrastic Robustness For Text Generation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Semstamp: A Semantic Watermark With Paraphrastic Robustness For Text Generation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Hou et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)</td>
    <td>7</td>
    <td><p>Existing watermarking algorithms are vulnerable to paraphrase attacks because
of their token-level design. To address this issue, we propose SemStamp, a
robust sentence-level semantic watermarking algorithm based on
locality-sensitive hashing (LSH), which partitions the semantic space of
sentences. The algorithm encodes and LSH-hashes a candidate sentence generated
by an LLM, and conducts sentence-level rejection sampling until the sampled
sentence falls in watermarked partitions in the semantic embedding space. A
margin-based constraint is used to enhance its robustness. To show the
advantages of our algorithm, we propose a â€œbigramâ€ paraphrase attack using the
paraphrase that has the fewest bigram overlaps with the original sentence. This
attack is shown to be effective against the existing token-level watermarking
method. Experimental results show that our novel semantic watermark algorithm
is not only more robust than the previous state-of-the-art method on both
common and bigram paraphrase attacks, but also is better at preserving the
quality of generation.</p>
</td>
    <td>
      
        NAACL 
      
        Robustness 
      
        Hashing Methods 
      
        Locality Sensitive Hashing 
      
        ACL 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/huang2023lightweight/">Lightweight-yet-efficient: Revitalizing Ball-tree For Point-to-hyperplane Nearest Neighbor Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Lightweight-yet-efficient: Revitalizing Ball-tree For Point-to-hyperplane Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Lightweight-yet-efficient: Revitalizing Ball-tree For Point-to-hyperplane Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Huang Qiang, Tung Anthony K. H.</td> <!-- ðŸ”§ You were missing this -->
    <td>2023 IEEE 39th International Conference on Data Engineering (ICDE)</td>
    <td>5</td>
    <td><p>Finding the nearest neighbor to a hyperplane (or Point-to-Hyperplane Nearest
Neighbor Search, simply P2HNNS) is a new and challenging problem with
applications in many research domains. While existing state-of-the-art hashing
schemes (e.g., NH and FH) are able to achieve sublinear time complexity without
the assumption of the data being in a unit hypersphere, they require an
asymmetric transformation, which increases the data dimension from \(d\) to
\(Î©(d^2)\). This leads to considerable overhead for indexing and incurs
significant distortion errors.
  In this paper, we investigate a tree-based approach for solving P2HNNS using
the classical Ball-Tree index. Compared to hashing-based methods, tree-based
methods usually require roughly linear costs for construction, and they provide
different kinds of approximations with excellent flexibility. A simple
branch-and-bound algorithm with a novel lower bound is first developed on
Ball-Tree for performing P2HNNS. Then, a new tree structure named BC-Tree,
which maintains the Ball and Cone structures in the leaf nodes of Ball-Tree, is
described together with two effective strategies, i.e., point-level pruning and
collaborative inner product computing. BC-Tree inherits both the low
construction cost and lightweight property of Ball-Tree while providing a
similar or more efficient search. Experimental results over 16 real-world data
sets show that Ball-Tree and BC-Tree are around 1.1\(\sim\)10\(\times\) faster than
NH and FH, and they can reduce the index size and indexing time by about
1\(\sim\)3 orders of magnitudes on average. The code is available at
https://github.com/HuangQiang/BC-Tree.</p>
</td>
    <td>
      
        Tree Based ANN 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/gupta2023caps/">CAPS: A Practical Partition Index For Filtered Similarity Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=CAPS: A Practical Partition Index For Filtered Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=CAPS: A Practical Partition Index For Filtered Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Gupta et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 37th international ACM SIGIR conference on Research &amp; development in information retrieval</td>
    <td>6</td>
    <td><p>With the surging popularity of approximate near-neighbor search (ANNS),
driven by advances in neural representation learning, the ability to serve
queries accompanied by a set of constraints has become an area of intense
interest. While the community has recently proposed several algorithms for
constrained ANNS, almost all of these methods focus on integration with
graph-based indexes, the predominant class of algorithms achieving
state-of-the-art performance in latency-recall tradeoffs. In this work, we take
a different approach and focus on developing a constrained ANNS algorithm via
space partitioning as opposed to graphs. To that end, we introduce Constrained
Approximate Partitioned Search (CAPS), an index for ANNS with filters via space
partitions that not only retains the benefits of a partition-based algorithm
but also outperforms state-of-the-art graph-based constrained search techniques
in recall-latency tradeoffs, with only 10% of the index size.</p>
</td>
    <td>
      
        Graph Based ANN 
      
        Efficiency And Optimization 
      
        SIGIR 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/gao2023high/">High-dimensional Approximate Nearest Neighbor Search: With Reliable And Efficient Distance Comparison Operations</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=High-dimensional Approximate Nearest Neighbor Search: With Reliable And Efficient Distance Comparison Operations' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=High-dimensional Approximate Nearest Neighbor Search: With Reliable And Efficient Distance Comparison Operations' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Gao Jianyang, Long Cheng</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the ACM on Management of Data</td>
    <td>24</td>
    <td><p>Approximate K nearest neighbor (AKNN) search is a fundamental and challenging
problem. We observe that in high-dimensional space, the time consumption of
nearly all AKNN algorithms is dominated by that of the distance comparison
operations (DCOs). For each operation, it scans full dimensions of an object
and thus, runs in linear time wrt the dimensionality. To speed it up, we
propose a randomized algorithm named ADSampling which runs in logarithmic time
wrt to the dimensionality for the majority of DCOs and succeeds with high
probability. In addition, based on ADSampling we develop one general and two
algorithm-specific techniques as plugins to enhance existing AKNN algorithms.
Both theoretical and empirical studies confirm that: (1) our techniques
introduce nearly no accuracy loss and (2) they consistently improve the
efficiency.</p>
</td>
    <td>
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/gan2023binary/">Binary Embedding-based Retrieval At Tencent</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Binary Embedding-based Retrieval At Tencent' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Binary Embedding-based Retrieval At Tencent' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Gan et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</td>
    <td>7</td>
    <td><p>Large-scale embedding-based retrieval (EBR) is the cornerstone of
search-related industrial applications. Given a user query, the system of EBR
aims to identify relevant information from a large corpus of documents that may
be tens or hundreds of billions in size. The storage and computation turn out
to be expensive and inefficient with massive documents and high concurrent
queries, making it difficult to further scale up. To tackle the challenge, we
propose a binary embedding-based retrieval (BEBR) engine equipped with a
recurrent binarization algorithm that enables customized bits per dimension.
Specifically, we compress the full-precision query and document embeddings,
formulated as float vectors in general, into a composition of multiple binary
vectors using a lightweight transformation model with residual multilayer
perception (MLP) blocks. We can therefore tailor the number of bits for
different applications to trade off accuracy loss and cost savings.
Importantly, we enable task-agnostic efficient training of the binarization
model using a new embedding-to-embedding strategy. We also exploit the
compatible training of binary embeddings so that the BEBR engine can support
indexing among multiple embedding versions within a unified system. To further
realize efficient search, we propose Symmetric Distance Calculation (SDC) to
achieve lower response time than Hamming codes. We successfully employed the
introduced BEBR to Tencent products, including Sogou, Tencent Video, QQ World,
etc. The binarization algorithm can be seamlessly generalized to various tasks
with multiple modalities. Extensive experiments on offline benchmarks and
online A/B tests demonstrate the efficiency and effectiveness of our method,
significantly saving 30%~50% index costs with almost no loss of accuracy at the
system level.</p>
</td>
    <td>
      
        KDD 
      
        Hashing Methods 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/fleischhacker2023invertible/">Invertible Bloom Lookup Tables With Less Memory And Randomness</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Invertible Bloom Lookup Tables With Less Memory And Randomness' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Invertible Bloom Lookup Tables With Less Memory And Randomness' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Fleischhacker et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2011 49th Annual Allerton Conference on Communication, Control, and Computing (Allerton)</td>
    <td>144</td>
    <td><p>In this work we study Invertible Bloom Lookup Tables (IBLTs) with small
failure probabilities. IBLTs are highly versatile data structures that have
found applications in set reconciliation protocols, error-correcting codes, and
even the design of advanced cryptographic primitives. For storing \(n\) elements
and ensuring correctness with probability at least \(1 - \delta\), existing IBLT
constructions require \(Î©(n(\frac{log(1/\delta)}{log(n)}+1))\) space and
they crucially rely on fully random hash functions.
  We present new constructions of IBLTs that are simultaneously more space
efficient and require less randomness. For storing \(n\) elements with a failure
probability of at most \(\delta\), our data structure only requires
\(\mathcal{O}\left(n + log(1/\delta)loglog(1/\delta)\right)\) space and
\(\mathcal{O}\left(log(log(n)/\delta)\right)\)-wise independent hash functions.
  As a key technical ingredient we show that hashing \(n\) keys with any \(k\)-wise
independent hash function \(h:U \to [Cn]\) for some sufficiently large constant
\(C\) guarantees with probability \(1 - 2^{-Î©(k)}\) that at least \(n/2\) keys
will have a unique hash value. Proving this is non-trivial as \(k\) approaches
\(n\). We believe that the techniques used to prove this statement may be of
independent interest.
  We apply our new IBLTs to the encrypted compression problem, recently studied
by Fleischhacker, Larsen, Simkin (Eurocrypt 2023). We extend their approach to
work for a more general class of encryption schemes and using our new IBLT we
achieve an asymptotically better compression rate.</p>
</td>
    <td>
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/yuan2023semantic/">Semantic-aware Adversarial Training For Reliable Deep Hashing Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Semantic-aware Adversarial Training For Reliable Deep Hashing Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Semantic-aware Adversarial Training For Reliable Deep Hashing Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yuan et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Information Forensics and Security</td>
    <td>12</td>
    <td><p>Deep hashing has been intensively studied and successfully applied in
large-scale image retrieval systems due to its efficiency and effectiveness.
Recent studies have recognized that the existence of adversarial examples poses
a security threat to deep hashing models, that is, adversarial vulnerability.
Notably, it is challenging to efficiently distill reliable semantic
representatives for deep hashing to guide adversarial learning, and thereby it
hinders the enhancement of adversarial robustness of deep hashing-based
retrieval models. Moreover, current researches on adversarial training for deep
hashing are hard to be formalized into a unified minimax structure. In this
paper, we explore Semantic-Aware Adversarial Training (SAAT) for improving the
adversarial robustness of deep hashing models. Specifically, we conceive a
discriminative mainstay features learning (DMFL) scheme to construct semantic
representatives for guiding adversarial learning in deep hashing. Particularly,
our DMFL with the strict theoretical guarantee is adaptively optimized in a
discriminative learning manner, where both discriminative and semantic
properties are jointly considered. Moreover, adversarial examples are
fabricated by maximizing the Hamming distance between the hash codes of
adversarial samples and mainstay features, the efficacy of which is validated
in the adversarial attack trials. Further, we, for the first time, formulate
the formalized adversarial training of deep hashing into a unified minimax
optimization under the guidance of the generated mainstay codes. Extensive
experiments on benchmark datasets show superb attack performance against the
state-of-the-art algorithms, meanwhile, the proposed adversarial training can
effectively eliminate adversarial perturbations for trustworthy deep
hashing-based retrieval. Our code is available at
https://github.com/xandery-geek/SAAT.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Neural Hashing 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/dong2023seine/">SEINE: Segment-based Indexing For Neural Information Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=SEINE: Segment-based Indexing For Neural Information Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=SEINE: Segment-based Indexing For Neural Information Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Dong Sibo, Goldstein Justin, Yang Grace Hui</td> <!-- ðŸ”§ You were missing this -->
    <td>International Journal of Computer Science and Information Technology</td>
    <td>13</td>
    <td><p>Many early neural Information Retrieval (NeurIR) methods are re-rankers that
rely on a traditional first-stage retriever due to expensive query time
computations. Recently, representation-based retrievers have gained much
attention, which learns query representation and document representation
separately, making it possible to pre-compute document representations offline
and reduce the workload at query time. Both dense and sparse
representation-based retrievers have been explored. However, these methods
focus on finding the representation that best represents a text (aka metric
learning) and the actual retrieval function that is responsible for similarity
matching between query and document is kept at a minimum by using dot product.
One drawback is that unlike traditional term-level inverted index, the index
formed by these embeddings cannot be easily re-used by another retrieval
method. Another drawback is that keeping the interaction at minimum hurts
retrieval effectiveness. On the contrary, interaction-based retrievers are
known for their better retrieval effectiveness. In this paper, we propose a
novel SEgment-based Neural Indexing method, SEINE, which provides a general
indexing framework that can flexibly support a variety of interaction-based
neural retrieval methods. We emphasize on a careful decomposition of common
components in existing neural retrieval methods and propose to use
segment-level inverted index to store the atomic query-document interaction
values. Experiments on LETOR MQ2007 and MQ2008 datasets show that our indexing
method can accelerate multiple neural retrieval methods up to 28-times faster
without sacrificing much effectiveness.</p>
</td>
    <td>
      
        DATASETS 
      
        Tools & Libraries 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/desai2023heterogeneous/">Heterogeneous Federated Collaborative Filtering Using FAIR: Federated Averaging In Random Subspaces</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Heterogeneous Federated Collaborative Filtering Using FAIR: Federated Averaging In Random Subspaces' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Heterogeneous Federated Collaborative Filtering Using FAIR: Federated Averaging In Random Subspaces' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Desai et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence</td>
    <td>76</td>
    <td><p>Recommendation systems (RS) for items (e.g., movies, books) and ads are
widely used to tailor content to users on various internet platforms.
Traditionally, recommendation models are trained on a central server. However,
due to rising concerns for data privacy and regulations like the GDPR,
federated learning is an increasingly popular paradigm in which data never
leaves the client device. Applying federated learning to recommendation models
is non-trivial due to large embedding tables, which often exceed the memory
constraints of most user devices. To include data from all devices in federated
learning, we must enable collective training of embedding tables on devices
with heterogeneous memory capacities. Current solutions to heterogeneous
federated learning can only accommodate a small range of capacities and thus
limit the number of devices that can participate in training. We present
Federated Averaging in Random subspaces (FAIR), which allows arbitrary
compression of embedding tables based on device capacity and ensures the
participation of all devices in training. FAIR uses what we call consistent and
collapsible subspaces defined by hashing-based random projections to jointly
train large embedding tables while using varying amounts of compression on user
devices. We evaluate FAIR on Neural Collaborative Filtering tasks with multiple
datasets and verify that FAIR can gather and share information from a wide
range of devices with varying capacities, allowing for seamless collaboration.
We prove the convergence of FAIR in the homogeneous setting with non-i.i.d data
distribution. Our code is open source at {https://github.com/apd10/FLCF}</p>
</td>
    <td>
      
        DATASETS 
      
        IJCAI 
      
        Recommender Systems 
      
        Hashing Methods 
      
        Locality Sensitive Hashing 
      
        AAAI 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/chen2023supervised/">Supervised Auto-encoding Twin-bottleneck Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Supervised Auto-encoding Twin-bottleneck Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Supervised Auto-encoding Twin-bottleneck Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Chen Yuan, Marchand-maillet StÃ©phane</td> <!-- ðŸ”§ You were missing this -->
    <td>2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>105</td>
    <td><p>Deep hashing has shown to be a complexity-efficient solution for the
Approximate Nearest Neighbor search problem in high dimensional space. Many
methods usually build the loss function from pairwise or triplet data points to
capture the local similarity structure. Other existing methods construct the
similarity graph and consider all points simultaneously. Auto-encoding
Twin-bottleneck Hashing is one such method that dynamically builds the graph.
Specifically, each input data is encoded into a binary code and a continuous
variable, or the so-called twin bottlenecks. The similarity graph is then
computed from these binary codes, which get updated consistently during the
training. In this work, we generalize the original model into a supervised deep
hashing network by incorporating the label information. In addition, we examine
the differences of codes structure between these two networks and consider the
class imbalance problem especially in multi-labeled datasets. Experiments on
three datasets yield statistically significant improvement against the original
model. Results are also comparable and competitive to other supervised methods.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        CVPR 
      
        Compact Codes 
      
        Neural Hashing 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/chen2023bipartite/">Bipartite Graph Convolutional Hashing For Effective And Efficient Top-n Search In Hamming Space</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Bipartite Graph Convolutional Hashing For Effective And Efficient Top-n Search In Hamming Space' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Bipartite Graph Convolutional Hashing For Effective And Efficient Top-n Search In Hamming Space' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Chen et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the ACM Web Conference 2023</td>
    <td>15</td>
    <td><p>Searching on bipartite graphs is basal and versatile to many real-world Web
applications, e.g., online recommendation, database retrieval, and
query-document searching. Given a query node, the conventional approaches rely
on the similarity matching with the vectorized node embeddings in the
continuous Euclidean space. To efficiently manage intensive similarity
computation, developing hashing techniques for graph structured data has
recently become an emerging research direction. Despite the retrieval
efficiency in Hamming space, prior work is however confronted with catastrophic
performance decay. In this work, we investigate the problem of hashing with
Graph Convolutional Network on bipartite graphs for effective Top-N search. We
propose an end-to-end Bipartite Graph Convolutional Hashing approach, namely
BGCH, which consists of three novel and effective modules: (1) adaptive graph
convolutional hashing, (2) latent feature dispersion, and (3) Fourier
serialized gradient estimation. Specifically, the former two modules achieve
the substantial retention of the structural information against the inevitable
information loss in hash encoding; the last module develops Fourier Series
decomposition to the hashing function in the frequency domain mainly for more
accurate gradient estimation. The extensive experiments on six real-world
datasets not only show the performance superiority over the competing
hashing-based counterparts, but also demonstrate the effectiveness of all
proposed model components contained therein.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Recommender Systems 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/chatzigeorgakidis2023accelerating/">Accelerating Spatio-textual Queries With Learned Indices</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Accelerating Spatio-textual Queries With Learned Indices' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Accelerating Spatio-textual Queries With Learned Indices' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Chatzigeorgakidis et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>5</td>
    <td><p>Efficiently computing spatio-textual queries has become increasingly
important in various applications that need to quickly retrieve geolocated
entities associated with textual information, such as in location-based
services and social networks. To accelerate such queries, several works have
proposed combining spatial and textual indices into hybrid index structures.
Recently, the novel idea of replacing traditional indices with ML models has
attracted a lot of attention. This includes works on learned spatial indices,
where the main challenge is to address the lack of a total ordering among
objects in a multidimensional space. In this work, we investigate how to extend
this novel type of index design to the case of spatio-textual data. We study
different design choices, based on either loose or tight coupling between the
spatial and textual part, as well as a hybrid index that combines a traditional
and a learned component. We also perform an experimental evaluation using
several real-world datasets to assess the potential benefits of using a learned
index for evaluating spatio-textual queries.</p>
</td>
    <td>
      
        Vector Indexing 
      
        Evaluation 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/centurion2023geometric/">Geometric Algorithms For \(k\)-nn Poisoning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Geometric Algorithms For \(k\)-nn Poisoning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Geometric Algorithms For \(k\)-nn Poisoning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Centurion et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of 1994 American Control Conference - ACC '94</td>
    <td>14</td>
    <td><p>We propose a label poisoning attack on geometric data sets against
\(k\)-nearest neighbor classification. We provide an algorithm that can compute
an \(\epsilon n\)-additive approximation of the optimal poisoning in \(n\cdot
2^{2^{O(d+k/\epsilon)}}\) time for a given data set \(X \in \mathbb{R}^d\),
where \(|X| = n\). Our algorithm achieves its objectives through the application
of multi-scale random partitions.</p>
</td>
    <td>
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/bruch2023approximate/">An Approximate Algorithm For Maximum Inner Product Search Over Streaming Sparse Vectors</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=An Approximate Algorithm For Maximum Inner Product Search Over Streaming Sparse Vectors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=An Approximate Algorithm For Maximum Inner Product Search Over Streaming Sparse Vectors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Bruch et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>ACM Transactions on Information Systems</td>
    <td>6</td>
    <td><p>Maximum Inner Product Search or top-k retrieval on sparse vectors is
well-understood in information retrieval, with a number of mature algorithms
that solve it exactly. However, all existing algorithms are tailored to text
and frequency-based similarity measures. To achieve optimal memory footprint
and query latency, they rely on the near stationarity of documents and on laws
governing natural languages. We consider, instead, a setup in which collections
are streaming â€“ necessitating dynamic indexing â€“ and where indexing and
retrieval must work with arbitrarily distributed real-valued vectors. As we
show, existing algorithms are no longer competitive in this setup, even against
naive solutions. We investigate this gap and present a novel approximate
solution, called Sinnamon, that can efficiently retrieve the top-k results for
sparse real valued vectors drawn from arbitrary distributions. Notably,
Sinnamon offers levers to trade-off memory consumption, latency, and accuracy,
making the algorithm suitable for constrained applications and systems. We give
theoretical results on the error introduced by the approximate nature of the
algorithm, and present an empirical evaluation of its performance on two
hardware platforms and synthetic and real-valued datasets. We conclude by
laying out concrete directions for future research on this general top-k
retrieval problem over sparse vectors.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/aguerrebere2023similarity/">Similarity Search In The Blink Of An Eye With Compressed Indices</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Similarity Search In The Blink Of An Eye With Compressed Indices' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Similarity Search In The Blink Of An Eye With Compressed Indices' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Aguerrebere et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the VLDB Endowment</td>
    <td>15</td>
    <td><p>Nowadays, data is represented by vectors. Retrieving those vectors, among
millions and billions, that are similar to a given query is a ubiquitous
problem, known as similarity search, of relevance for a wide range of
applications. Graph-based indices are currently the best performing techniques
for billion-scale similarity search. However, their random-access memory
pattern presents challenges to realize their full potential. In this work, we
present new techniques and systems for creating faster and smaller graph-based
indices. To this end, we introduce a novel vector compression method,
Locally-adaptive Vector Quantization (LVQ), that uses per-vector scaling and
scalar quantization to improve search performance with fast similarity
computations and a reduced effective bandwidth, while decreasing memory
footprint and barely impacting accuracy. LVQ, when combined with a new
high-performance computing system for graph-based similarity search,
establishes the new state of the art in terms of performance and memory
footprint. For billions of vectors, LVQ outcompetes the second-best
alternatives: (1) in the low-memory regime, by up to 20.7x in throughput with
up to a 3x memory footprint reduction, and (2) in the high-throughput regime by
5.8x with 1.4x less memory.</p>
</td>
    <td>
      
        Graph Based ANN 
      
        Efficiency And Optimization 
      
        Large Scale Search 
      
        Alt 
      
        Similarity Search 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/aghamolaei2023massively/">Massively-parallel Heat Map Sorting And Applications To Explainable Clustering</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Massively-parallel Heat Map Sorting And Applications To Explainable Clustering' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Massively-parallel Heat Map Sorting And Applications To Explainable Clustering' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Aghamolaei Sepideh, Ghodsi Mohammad</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 27th ACM symposium on Parallelism in Algorithms and Architectures</td>
    <td>33</td>
    <td><p>Given a set of points labeled with \(k\) labels, we introduce the heat map
sorting problem as reordering and merging the points and dimensions while
preserving the clusters (labels). A cluster is preserved if it remains
connected, i.e., if it is not split into several clusters and no two clusters
are merged.
  We prove the problem is NP-hard and we give a fixed-parameter algorithm with
a constant number of rounds in the massively parallel computation model, where
each machine has a sublinear memory and the total memory of the machines is
linear. We give an approximation algorithm for a NP-hard special case of the
problem. We empirically compare our algorithm with k-means and density-based
clustering (DBSCAN) using a dimensionality reduction via locality-sensitive
hashing on several directed and undirected graphs of email and computer
networks.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/takikawa2023compact/">Compact Neural Graphics Primitives With Learned Hash Probing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Compact Neural Graphics Primitives With Learned Hash Probing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Compact Neural Graphics Primitives With Learned Hash Probing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Takikawa et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>SIGGRAPH Asia 2023 Conference Papers</td>
    <td>8</td>
    <td><p>Neural graphics primitives are faster and achieve higher quality when their
neural networks are augmented by spatial data structures that hold trainable
features arranged in a grid. However, existing feature grids either come with a
large memory footprint (dense or factorized grids, trees, and hash tables) or
slow performance (index learning and vector quantization). In this paper, we
show that a hash table with learned probes has neither disadvantage, resulting
in a favorable combination of size and speed. Inference is faster than unprobed
hash tables at equal quality while training is only 1.2-2.6x slower,
significantly outperforming prior index learning approaches. We arrive at this
formulation by casting all feature grids into a common framework: they each
correspond to a lookup function that indexes into a table of feature vectors.
In this framework, the lookup functions of existing data structures can be
combined by simple arithmetic combinations of their indices, resulting in
Pareto optimal compression and speed.</p>
</td>
    <td>
      
        Quantization 
      
        Tools & Libraries 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/tan2023unfolded/">Unfolded Self-reconstruction LSH: Towards Machine Unlearning In Approximate Nearest Neighbour Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Unfolded Self-reconstruction LSH: Towards Machine Unlearning In Approximate Nearest Neighbour Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Unfolded Self-reconstruction LSH: Towards Machine Unlearning In Approximate Nearest Neighbour Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Tan et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Electronics Letters</td>
    <td>5</td>
    <td><p>Approximate nearest neighbour (ANN) search is an essential component of
search engines, recommendation systems, etc. Many recent works focus on
learning-based data-distribution-dependent hashing and achieve good retrieval
performance. However, due to increasing demand for usersâ€™ privacy and security,
we often need to remove usersâ€™ data information from Machine Learning (ML)
models to satisfy specific privacy and security requirements. This need
requires the ANN search algorithm to support fast online data deletion and
insertion. Current learning-based hashing methods need retraining the hash
function, which is prohibitable due to the vast time-cost of large-scale data.
To address this problem, we propose a novel data-dependent hashing method named
unfolded self-reconstruction locality-sensitive hashing (USR-LSH). Our USR-LSH
unfolded the optimization update for instance-wise data reconstruction, which
is better for preserving data information than data-independent LSH. Moreover,
our USR-LSH supports fast online data deletion and insertion without
retraining. To the best of our knowledge, we are the first to address the
machine unlearning of retrieval problems. Empirically, we demonstrate that
USR-LSH outperforms the state-of-the-art data-distribution-independent LSH in
ANN tasks in terms of precision and recall. We also show that USR-LSH has
significantly faster data deletion and insertion time than learning-based
data-dependent hashing.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Recommender Systems 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/wang2023note/">A Note On "efficient Task-specific Data Valuation For Nearest Neighbor Algorithms"</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Note On "efficient Task-specific Data Valuation For Nearest Neighbor Algorithms"' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Note On "efficient Task-specific Data Valuation For Nearest Neighbor Algorithms"' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang Jiachen T., Jia Ruoxi</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the VLDB Endowment</td>
    <td>98</td>
    <td><p>Data valuation is a growing research field that studies the influence of
individual data points for machine learning (ML) models. Data Shapley, inspired
by cooperative game theory and economics, is an effective method for data
valuation. However, it is well-known that the Shapley value (SV) can be
computationally expensive. Fortunately, Jia et al. (2019) showed that for
K-Nearest Neighbors (KNN) models, the computation of Data Shapley is
surprisingly simple and efficient.
  In this note, we revisit the work of Jia et al. (2019) and propose a more
natural and interpretable utility function that better reflects the performance
of KNN models. We derive the corresponding calculation procedure for the Data
Shapley of KNN classifiers/regressors with the new utility functions. Our new
approach, dubbed soft-label KNN-SV, achieves the same time complexity as the
original method. We further provide an efficient approximation algorithm for
soft-label KNN-SV based on locality sensitive hashing (LSH). Our experimental
results demonstrate that Soft-label KNN-SV outperforms the original method on
most datasets in the task of mislabeled data detection, making it a better
baseline for future work on data valuation.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Evaluation 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/zhu2023deep/">Deep Metric Multi-view Hashing For Multimedia Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Metric Multi-view Hashing For Multimedia Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Metric Multi-view Hashing For Multimedia Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2023 IEEE International Conference on Multimedia and Expo (ICME)</td>
    <td>7</td>
    <td><p>Learning the hash representation of multi-view heterogeneous data is an
important task in multimedia retrieval. However, existing methods fail to
effectively fuse the multi-view features and utilize the metric information
provided by the dissimilar samples, leading to limited retrieval precision.
Current methods utilize weighted sum or concatenation to fuse the multi-view
features. We argue that these fusion methods cannot capture the interaction
among different views. Furthermore, these methods ignored the information
provided by the dissimilar samples. We propose a novel deep metric multi-view
hashing (DMMVH) method to address the mentioned problems. Extensive empirical
evidence is presented to show that gate-based fusion is better than typical
methods. We introduce deep metric learning to the multi-view hashing problems,
which can utilize metric information of dissimilar samples. On the
MIR-Flickr25K, MS COCO, and NUS-WIDE, our method outperforms the current
state-of-the-art methods by a large margin (up to 15.28 mean Average Precision
(mAP) improvement).</p>
</td>
    <td>
      
        Hashing Methods 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/shohoud2023quranic/">Quranic Conversations: Developing A Semantic Search Tool For The Quran Using Arabic NLP Techniques</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Quranic Conversations: Developing A Semantic Search Tool For The Quran Using Arabic NLP Techniques' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Quranic Conversations: Developing A Semantic Search Tool For The Quran Using Arabic NLP Techniques' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Shohoud Yasser, Shoman Maged, Abdelazim Sarah</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>8</td>
    <td><p>The Holy Book of Quran is believed to be the literal word of God (Allah) as
revealed to the Prophet Muhammad (PBUH) over a period of approximately 23
years. It is the book where God provides guidance on how to live a righteous
and just life, emphasizing principles like honesty, compassion, charity and
justice, as well as providing rules for personal conduct, family matters,
business ethics and much more. However, due to constraints related to the
language and the Quran organization, it is challenging for Muslims to get all
relevant ayahs (verses) pertaining to a matter or inquiry of interest. Hence,
we developed a Quran semantic search tool which finds the verses pertaining to
the user inquiry or prompt. To achieve this, we trained several models on a
large dataset of over 30 tafsirs, where typically each tafsir corresponds to
one verse in the Quran and, using cosine similarity, obtained the tafsir tensor
which is most similar to the prompt tensor of interest, which was then used to
index for the corresponding ayah in the Quran. Using the SNxLM model, we were
able to achieve a cosine similarity score as high as 0.97 which corresponds to
the abdu tafsir for a verse relating to financial matters.</p>
</td>
    <td>
      
        DATASETS 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/she2023image/">Image Patch-matching With Graph-based Learning In Street Scenes</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Image Patch-matching With Graph-based Learning In Street Scenes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Image Patch-matching With Graph-based Learning In Street Scenes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>She et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Image Processing</td>
    <td>7</td>
    <td><p>Matching landmark patches from a real-time image captured by an on-vehicle
camera with landmark patches in an image database plays an important role in
various computer perception tasks for autonomous driving. Current methods focus
on local matching for regions of interest and do not take into account spatial
neighborhood relationships among the image patches, which typically correspond
to objects in the environment. In this paper, we construct a spatial graph with
the graph vertices corresponding to patches and edges capturing the spatial
neighborhood information. We propose a joint feature and metric learning model
with graph-based learning. We provide a theoretical basis for the graph-based
loss by showing that the information distance between the distributions
conditioned on matched and unmatched pairs is maximized under our framework. We
evaluate our model using several street-scene datasets and demonstrate that our
approach achieves state-of-the-art matching results.</p>
</td>
    <td>
      
        DATASETS 
      
        Tools & Libraries 
      
        Graph Based ANN 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/zhao2023embedding/">Embedding In Recommender Systems: A Survey</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Embedding In Recommender Systems: A Survey' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Embedding In Recommender Systems: A Survey' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhao et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>8</td>
    <td><p>Recommender systems have become an essential component of many online
platforms, providing personalized recommendations to users. A crucial aspect is
embedding techniques that coverts the high-dimensional discrete features, such
as user and item IDs, into low-dimensional continuous vectors and can enhance
the recommendation performance. Applying embedding techniques captures complex
entity relationships and has spurred substantial research. In this survey, we
provide an overview of the recent literature on embedding techniques in
recommender systems. This survey covers embedding methods like collaborative
filtering, self-supervised learning, and graph-based techniques. Collaborative
filtering generates embeddings capturing user-item preferences, excelling in
sparse data. Self-supervised methods leverage contrastive or generative
learning for various tasks. Graph-based techniques like node2vec exploit
complex relationships in network-rich environments. Addressing the scalability
challenges inherent to embedding methods, our survey delves into innovative
directions within the field of recommendation systems. These directions aim to
enhance performance and reduce computational complexity, paving the way for
improved recommender systems. Among these innovative approaches, we will
introduce Auto Machine Learning (AutoML), hash techniques, and quantization
techniques in this survey. We discuss various architectures and techniques and
highlight the challenges and future directions in these aspects. This survey
aims to provide a comprehensive overview of the state-of-the-art in this
rapidly evolving field and serve as a useful resource for researchers and
practitioners working in the area of recommender systems.</p>
</td>
    <td>
      
        Survey Paper 
      
        Graph Based ANN 
      
        Recommender Systems 
      
        Quantization 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/zhang2023model/">Model-enhanced Vector Index</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Model-enhanced Vector Index' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Model-enhanced Vector Index' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Universe</td>
    <td>17</td>
    <td><p>Embedding-based retrieval methods construct vector indices to search for
document representations that are most similar to the query representations.
They are widely used in document retrieval due to low latency and decent recall
performance. Recent research indicates that deep retrieval solutions offer
better model quality, but are hindered by unacceptable serving latency and the
inability to support document updates. In this paper, we aim to enhance the
vector index with end-to-end deep generative models, leveraging the
differentiable advantages of deep retrieval models while maintaining desirable
serving efficiency. We propose Model-enhanced Vector Index (MEVI), a
differentiable model-enhanced index empowered by a twin-tower representation
model. MEVI leverages a Residual Quantization (RQ) codebook to bridge the
sequence-to-sequence deep retrieval and embedding-based models. To
substantially reduce the inference time, instead of decoding the unique
document ids in long sequential steps, we first generate some semantic virtual
cluster ids of candidate documents in a small number of steps, and then
leverage the well-adapted embedding vectors to further perform a fine-grained
search for the relevant documents in the candidate virtual clusters. We
empirically show that our model achieves better performance on the commonly
used academic benchmarks MSMARCO Passage and Natural Questions, with comparable
serving latency to dense retrieval solutions.</p>
</td>
    <td>
      
        Efficiency And Optimization 
      
        Text Retrieval 
      
        Quantization 
      
        Vector Indexing 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/wagner2023fast/">Fast Private Kernel Density Estimation Via Locality Sensitive Quantization</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fast Private Kernel Density Estimation Via Locality Sensitive Quantization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fast Private Kernel Density Estimation Via Locality Sensitive Quantization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wagner Tal, Naamad Yonatan, Mishra Nina</td> <!-- ðŸ”§ You were missing this -->
    <td>The Annals of Statistics</td>
    <td>1523</td>
    <td><p>We study efficient mechanisms for differentially private kernel density
estimation (DP-KDE). Prior work for the Gaussian kernel described algorithms
that run in time exponential in the number of dimensions \(d\). This paper breaks
the exponential barrier, and shows how the KDE can privately be approximated in
time linear in \(d\), making it feasible for high-dimensional data. We also
present improved bounds for low-dimensional data.
  Our results are obtained through a general framework, which we term Locality
Sensitive Quantization (LSQ), for constructing private KDE mechanisms where
existing KDE approximation techniques can be applied. It lets us leverage
several efficient non-private KDE methods â€“ like Random Fourier Features, the
Fast Gauss Transform, and Locality Sensitive Hashing â€“ and ``privatizeâ€™â€™ them
in a black-box manner. Our experiments demonstrate that our resulting DP-KDE
mechanisms are fast and accurate on large datasets in both high and low
dimensions.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Quantization 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/turati2023locality/">Locality-sensitive Hashing Does Not Guarantee Privacy! Attacks On Google's Floc And The Minhash Hierarchy System</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Locality-sensitive Hashing Does Not Guarantee Privacy! Attacks On Google's Floc And The Minhash Hierarchy System' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Locality-sensitive Hashing Does Not Guarantee Privacy! Attacks On Google's Floc And The Minhash Hierarchy System' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Turati et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings on Privacy Enhancing Technologies</td>
    <td>6</td>
    <td><p>Recently proposed systems aim at achieving privacy using locality-sensitive
hashing. We show how these approaches fail by presenting attacks against two
such systems: Googleâ€™s FLoC proposal for privacy-preserving targeted
advertising and the MinHash Hierarchy, a system for processing mobile usersâ€™
traffic behavior in a privacy-preserving way. Our attacks refute the pre-image
resistance, anonymity, and privacy guarantees claimed for these systems.
  In the case of FLoC, we show how to deanonymize users using Sybil attacks and
to reconstruct 10% or more of the browsing history for 30% of its users using
Generative Adversarial Networks. We achieve this only analyzing the hashes used
by FLoC. For MinHash, we precisely identify the movement of a subset of
individuals and, on average, we can limit usersâ€™ movement to just 10% of the
possible geographic area, again using just the hashes. In addition, we refute
their differential privacy claims.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/trivigno2023divide/">Divide&classify: Fine-grained Classification For City-wide Visual Place Recognition</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Divide&classify: Fine-grained Classification For City-wide Visual Place Recognition' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Divide&classify: Fine-grained Classification For City-wide Visual Place Recognition' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Trivigno et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2023 IEEE/CVF International Conference on Computer Vision (ICCV)</td>
    <td>7</td>
    <td><p>Visual Place recognition is commonly addressed as an image retrieval problem.
However, retrieval methods are impractical to scale to large datasets, densely
sampled from city-wide maps, since their dimension impact negatively on the
inference time. Using approximate nearest neighbour search for retrieval helps
to mitigate this issue, at the cost of a performance drop. In this paper we
investigate whether we can effectively approach this task as a classification
problem, thus bypassing the need for a similarity search. We find that existing
classification methods for coarse, planet-wide localization are not suitable
for the fine-grained and city-wide setting. This is largely due to how the
dataset is split into classes, because these methods are designed to handle a
sparse distribution of photos and as such do not consider the visual aliasing
problem across neighbouring classes that naturally arises in dense scenarios.
Thus, we propose a partitioning scheme that enables a fast and accurate
inference, preserving a simple learning procedure, and a novel inference
pipeline based on an ensemble of novel classifiers that uses the prototypes
learned via an angular margin loss. Our method, Divide&amp;Classify (D&amp;C), enjoys
the fast inference of classification solutions and an accuracy competitive with
retrieval methods on the fine-grained, city-wide setting. Moreover, we show
that D&amp;C can be paired with existing retrieval pipelines to speed up
computations by over 20 times while increasing their recall, leading to new
state-of-the-art results.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        ICCV 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/zhu2023clip/">CLIP Multi-modal Hashing: A New Baseline CLIPMH</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=CLIP Multi-modal Hashing: A New Baseline CLIPMH' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=CLIP Multi-modal Hashing: A New Baseline CLIPMH' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Information Fusion</td>
    <td>37</td>
    <td><p>The multi-modal hashing method is widely used in multimedia retrieval. It can
fuse multi-source data to generate binary hash code. However, the current
multi-modal methods have the problem of low retrieval accuracy. The reason is
that the individual backbone networks have limited feature expression
capabilities and are not jointly pre-trained on large-scale unsupervised
multi-modal data. To solve this problem, we propose a new baseline CLIP
Multi-modal Hashing (CLIPMH) method. It uses CLIP model to extract text and
image features, and then fuse to generate hash code. CLIP improves the
expressiveness of each modal feature. In this way, it can greatly improve the
retrieval performance of multi-modal hashing methods. In comparison to
state-of-the-art unsupervised and supervised multi-modal hashing methods,
experiments reveal that the proposed CLIPMH can significantly enhance
performance (Maximum increase of 8.38%). CLIP also has great advantages over
the text and visual backbone networks commonly used before.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2023</td>
    <td>
      <a href="/publications/weng2023constant/">Constant Sequence Extension For Fast Search Using Weighted Hamming Distance</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Constant Sequence Extension For Fast Search Using Weighted Hamming Distance' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Constant Sequence Extension For Fast Search Using Weighted Hamming Distance' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Weng et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Image Processing</td>
    <td>8</td>
    <td><p>Representing visual data using compact binary codes is attracting increasing
attention as binary codes are used as direct indices into hash table(s) for
fast non-exhaustive search. Recent methods show that ranking binary codes using
weighted Hamming distance (WHD) rather than Hamming distance (HD) by generating
query-adaptive weights for each bit can better retrieve query-related items.
However, search using WHD is slower than that using HD. One main challenge is
that the complexity of extending a monotone increasing sequence using WHD to
probe buckets in hash table(s) for existing methods is at least proportional to
the square of the sequence length, while that using HD is proportional to the
sequence length. To overcome this challenge, we propose a novel fast
non-exhaustive search method using WHD. The key idea is to design a constant
sequence extension algorithm to perform each sequence extension in constant
computational complexity and the total complexity is proportional to the
sequence length, which is justified by theoretical analysis. Experimental
results show that our method is faster than other WHD-based search methods.
Also, compared with the HD-based non-exhaustive search method, our method has
comparable efficiency but retrieves more query-related items for the dataset of
up to one billion items.</p>
</td>
    <td>
      
        Compact Codes 
      
        DATASETS 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
    
      
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/wang2022hybrid/">Hybrid Contrastive Quantization For Efficient Cross-view Video Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hybrid Contrastive Quantization For Efficient Cross-view Video Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hybrid Contrastive Quantization For Efficient Cross-view Video Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the ACM Web Conference 2022</td>
    <td>5</td>
    <td><p>With the recent boom of video-based social platforms (e.g., YouTube and
TikTok), video retrieval using sentence queries has become an important demand
and attracts increasing research attention. Despite the decent performance,
existing text-video retrieval models in vision and language communities are
impractical for large-scale Web search because they adopt brute-force search
based on high-dimensional embeddings. To improve efficiency, Web search engines
widely apply vector compression libraries (e.g., FAISS) to post-process the
learned embeddings. Unfortunately, separate compression from feature encoding
degrades the robustness of representations and incurs performance decay. To
pursue a better balance between performance and efficiency, we propose the
first quantized representation learning method for cross-view video retrieval,
namely Hybrid Contrastive Quantization (HCQ). Specifically, HCQ learns both
coarse-grained and fine-grained quantizations with transformers, which provide
complementary understandings for texts and videos and preserve comprehensive
semantic information. By performing Asymmetric-Quantized Contrastive Learning
(AQ-CL) across views, HCQ aligns texts and videos at coarse-grained and
multiple fine-grained levels. This hybrid-grained learning strategy serves as
strong supervision on the cross-view video quantization model, where
contrastive learning at different levels can be mutually promoted. Extensive
experiments on three Web video benchmark datasets demonstrate that HCQ achieves
competitive performance with state-of-the-art non-compressed retrieval methods
while showing high efficiency in storage and computation. Code and
configurations are available at https://github.com/gimpong/WWW22-HCQ.</p>
</td>
    <td>
      
        DATASETS 
      
        Efficiency And Optimization 
      
        Quantization 
      
        Tools & Libraries 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/qiu2022hashvfl/">Hashvfl: Defending Against Data Reconstruction Attacks In Vertical Federated Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hashvfl: Defending Against Data Reconstruction Attacks In Vertical Federated Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hashvfl: Defending Against Data Reconstruction Attacks In Vertical Federated Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Qiu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Information Forensics and Security</td>
    <td>8</td>
    <td><p>Vertical Federated Learning (VFL) is a trending collaborative machine
learning model training solution. Existing industrial frameworks employ secure
multi-party computation techniques such as homomorphic encryption to ensure
data security and privacy. Despite these efforts, studies have revealed that
data leakage remains a risk in VFL due to the correlations between intermediate
representations and raw data. Neural networks can accurately capture these
correlations, allowing an adversary to reconstruct the data. This emphasizes
the need for continued research into securing VFL systems.
  Our work shows that hashing is a promising solution to counter data
reconstruction attacks. The one-way nature of hashing makes it difficult for an
adversary to recover data from hash codes. However, implementing hashing in VFL
presents new challenges, including vanishing gradients and information loss. To
address these issues, we propose HashVFL, which integrates hashing and
simultaneously achieves learnability, bit balance, and consistency.
  Experimental results indicate that HashVFL effectively maintains task
performance while defending against data reconstruction attacks. It also brings
additional benefits in reducing the degree of label leakage, mitigating
adversarial attacks, and detecting abnormal inputs. We hope our work will
inspire further research into the potential applications of HashVFL.</p>
</td>
    <td>
      
        Tools & Libraries 
      
        Hashing Methods 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/qi2022principled/">A Principled Design Of Image Representation: Towards Forensic Tasks</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Principled Design Of Image Representation: Towards Forensic Tasks' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Principled Design Of Image Representation: Towards Forensic Tasks' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Qi et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Pattern Analysis and Machine Intelligence</td>
    <td>19</td>
    <td><p>Image forensics is a rising topic as the trustworthy multimedia content is
critical for modern society. Like other vision-related applications, forensic
analysis relies heavily on the proper image representation. Despite the
importance, current theoretical understanding for such representation remains
limited, with varying degrees of neglect for its key role. For this gap, we
attempt to investigate the forensic-oriented image representation as a distinct
problem, from the perspectives of theory, implementation, and application. Our
work starts from the abstraction of basic principles that the representation
for forensics should satisfy, especially revealing the criticality of
robustness, interpretability, and coverage. At the theoretical level, we
propose a new representation framework for forensics, called Dense Invariant
Representation (DIR), which is characterized by stable description with
mathematical guarantees. At the implementation level, the discrete calculation
problems of DIR are discussed, and the corresponding accurate and fast
solutions are designed with generic nature and constant complexity. We
demonstrate the above arguments on the dense-domain pattern detection and
matching experiments, providing comparison results with state-of-the-art
descriptors. Also, at the application level, the proposed DIR is initially
explored in passive and active forensics, namely copy-move forgery detection
and perceptual hashing, exhibiting the benefits in fulfilling the requirements
of such forensic tasks.</p>
</td>
    <td>
      
        Tools & Libraries 
      
        Hashing Methods 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/pibiri2022locality/">Locality-preserving Minimal Perfect Hashing Of K-mers</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Locality-preserving Minimal Perfect Hashing Of K-mers' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Locality-preserving Minimal Perfect Hashing Of K-mers' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Pibiri Giulio Ermanno, Shibuya Yoshihiro, Limasset Antoine</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>5</td>
    <td><p>Minimal perfect hashing is the problem of mapping a static set of \(n\)
distinct keys into the address space \(\{1,\ldots,n\}\) bijectively. It is
well-known that \(nlog_2(e)\) bits are necessary to specify a minimal perfect
hash function (MPHF) \(f\), when no additional knowledge of the input keys is to
be used. However, it is often the case in practice that the input keys have
intrinsic relationships that we can exploit to lower the bit complexity of \(f\).
For example, consider a string and the set of all its distinct \(k\)-mers as
input keys: since two consecutive \(k\)-mers share an overlap of \(k-1\) symbols,
it seems possible to beat the classic \(log_2(e)\) bits/key barrier in this
case. Moreover, we would like \(f\) to map consecutive \(k\)-mers to consecutive
addresses, as to also preserve as much as possible their relationship in the
codomain. This is a useful feature in practice as it guarantees a certain
degree of locality of reference for \(f\), resulting in a better evaluation time
when querying consecutive \(k\)-mers. Motivated by these premises, we initiate
the study of a new type of locality-preserving MPHF designed for \(k\)-mers
extracted consecutively from a collection of strings. We design a construction
whose space usage decreases for growing \(k\) and discuss experiments with a
practical implementation of the method: in practice, the functions built with
our method can be several times smaller and even faster to query than the most
efficient MPHFs in the literature.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/wang2022inverted/">Inverted Semantic-index For Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Inverted Semantic-index For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Inverted Semantic-index For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang Ying</td> <!-- ðŸ”§ You were missing this -->
    <td>2006 10th International Database Engineering and Applications Symposium (IDEAS'06)</td>
    <td>14</td>
    <td><p>This paper addresses the construction of inverted index for large-scale image
retrieval. The inverted index proposed by J. Sivic brings a significant
acceleration by reducing distance computations with only a small fraction of
the database. The state-of-the-art inverted indices aim to build finer
partitions that produce a concise and accurate candidate list. However,
partitioning in these frameworks is generally achieved by unsupervised
clustering methods which ignore the semantic information of images. In this
paper, we replace the clustering method with image classification, during the
construction of codebook. We then propose a merging and splitting method to
solve the problem that the number of partitions is unchangeable in the inverted
semantic-index. Next, we combine our semantic-index with the product
quantization (PQ) so as to alleviate the accuracy loss caused by PQ
compression. Finally, we evaluate our model on large-scale image retrieval
benchmarks. Experiment results demonstrate that our model can significantly
improve the retrieval accuracy by generating high-quality candidate lists.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Quantization 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/pascualgaspar2022fast/">Fast On-line Signature Recognition Based On VQ With Time Modeling</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fast On-line Signature Recognition Based On VQ With Time Modeling' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fast On-line Signature Recognition Based On VQ With Time Modeling' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Pascual-gaspar Juan-manuel, Faundez-zanuy Marcos, Vivaracho Carlos</td> <!-- ðŸ”§ You were missing this -->
    <td>Engineering Applications of Artificial Intelligence</td>
    <td>43</td>
    <td><p>This paper proposes a multi-section vector quantization approach for on-line
signature recognition. We have used the MCYT database, which consists of 330
users and 25 skilled forgeries per person performed by 5 different impostors.
This database is larger than those typically used in the literature.
Nevertheless, we also provide results from the SVC database.
  Our proposed system outperforms the winner of SVC with a reduced
computational requirement, which is around 47 times lower than DTW. In
addition, our system improves the database storage requirements due to vector
compression, and is more privacy-friendly as it is not possible to recover the
original signature using the codebooks. Experimental results with MCYT provide
a 99.76% identification rate and 2.46% EER (skilled forgeries and individual
threshold). Experimental results with SVC are 100% of identification rate and
0% (individual threshold) and 0.31% (general threshold) when using a
two-section VQ approach.</p>
</td>
    <td>
      
        Quantization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/wu2022self/">Self-supervised Consistent Quantization For Fully Unsupervised Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Self-supervised Consistent Quantization For Fully Unsupervised Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Self-supervised Consistent Quantization For Fully Unsupervised Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wu Guile, Zhang Chao, Liwicki Stephan</td> <!-- ðŸ”§ You were missing this -->
    <td>2021 IEEE/CVF International Conference on Computer Vision (ICCV)</td>
    <td>51</td>
    <td><p>Unsupervised image retrieval aims to learn an efficient retrieval system
without expensive data annotations, but most existing methods rely heavily on
handcrafted feature descriptors or pre-trained feature extractors. To minimize
human supervision, recent advance proposes deep fully unsupervised image
retrieval aiming at training a deep model from scratch to jointly optimize
visual features and quantization codes. However, existing approach mainly
focuses on instance contrastive learning without considering underlying
semantic structure information, resulting in sub-optimal performance. In this
work, we propose a novel self-supervised consistent quantization approach to
deep fully unsupervised image retrieval, which consists of part consistent
quantization and global consistent quantization. In part consistent
quantization, we devise part neighbor semantic consistency learning with
codeword diversity regularization. This allows to discover underlying neighbor
structure information of sub-quantized representations as self-supervision. In
global consistent quantization, we employ contrastive learning for both
embedding and quantized representations and fuses these representations for
consistent contrastive regularization between instances. This can make up for
the loss of useful representation information during quantization and
regularize consistency between instances. With a unified learning objective of
part and global consistent quantization, our approach exploits richer
self-supervision cues to facilitate model learning. Extensive experiments on
three benchmark datasets show the superiority of our approach over the
state-of-the-art methods.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        ICCV 
      
        Similarity Search 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/pansare2022learning/">Learning Compressed Embeddings For On-device Inference</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning Compressed Embeddings For On-device Inference' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning Compressed Embeddings For On-device Inference' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Pansare et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Image Processing</td>
    <td>9</td>
    <td><p>In deep learning, embeddings are widely used to represent categorical
entities such as words, apps, and movies. An embedding layer maps each entity
to a unique vector, causing the layerâ€™s memory requirement to be proportional
to the number of entities. In the recommendation domain, a given category can
have hundreds of thousands of entities, and its embedding layer can take
gigabytes of memory. The scale of these networks makes them difficult to deploy
in resource constrained environments. In this paper, we propose a novel
approach for reducing the size of an embedding table while still mapping each
entity to its own unique embedding. Rather than maintaining the full embedding
table, we construct each entityâ€™s embedding â€œon the flyâ€ using two separate
embedding tables. The first table employs hashing to force multiple entities to
share an embedding. The second table contains one trainable weight per entity,
allowing the model to distinguish between entities sharing the same embedding.
Since these two tables are trained jointly, the network is able to learn a
unique embedding per entity, helping it maintain a discriminative capability
similar to a model with an uncompressed embedding table. We call this approach
MEmCom (Multi-Embedding Compression). We compare with state-of-the-art model
compression techniques for multiple problem classes including classification
and ranking. On four popular recommender system datasets, MEmCom had a 4%
relative loss in nDCG while compressing the input embedding sizes of our
recommendation models by 16x, 4x, 12x, and 40x. MEmCom outperforms the
state-of-the-art techniques, which achieved 16%, 6%, 10%, and 8% relative loss
in nDCG at the respective compression ratios. Additionally, MEmCom is able to
compress the RankNet ranking model by 32x on a dataset with millions of usersâ€™
interactions with games while incurring only a 1% relative loss in nDCG.</p>
</td>
    <td>
      
        Recommender Systems 
      
        Hashing Methods 
      
        Evaluation 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/wang2022binary/">Binary Representation Via Jointly Personalized Sparse Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Binary Representation Via Jointly Personalized Sparse Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Binary Representation Via Jointly Personalized Sparse Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>ACM Transactions on Multimedia Computing, Communications, and Applications</td>
    <td>18</td>
    <td><p>Unsupervised hashing has attracted much attention for binary representation
learning due to the requirement of economical storage and efficiency of binary
codes. It aims to encode high-dimensional features in the Hamming space with
similarity preservation between instances. However, most existing methods learn
hash functions in manifold-based approaches. Those methods capture the local
geometric structures (i.e., pairwise relationships) of data, and lack
satisfactory performance in dealing with real-world scenarios that produce
similar features (e.g. color and shape) with different semantic information. To
address this challenge, in this work, we propose an effective unsupervised
method, namely Jointly Personalized Sparse Hashing (JPSH), for binary
representation learning. To be specific, firstly, we propose a novel
personalized hashing module, i.e., Personalized Sparse Hashing (PSH). Different
personalized subspaces are constructed to reflect category-specific attributes
for different clusters, adaptively mapping instances within the same cluster to
the same Hamming space. In addition, we deploy sparse constraints for different
personalized subspaces to select important features. We also collect the
strengths of the other clusters to build the PSH module with avoiding
over-fitting. Then, to simultaneously preserve semantic and pairwise
similarities in our JPSH, we incorporate the PSH and manifold-based hash
learning into the seamless formulation. As such, JPSH not only distinguishes
the instances from different clusters, but also preserves local neighborhood
structures within the cluster. Finally, an alternating optimization algorithm
is adopted to iteratively capture analytical solutions of the JPSH model.
Extensive experiments on four benchmark datasets verify that the JPSH
outperforms several hashing algorithms on the similarity search task.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Alt 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/wang2022navigable/">Navigable Proximity Graph-driven Native Hybrid Queries With Structured And Unstructured Constraints</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Navigable Proximity Graph-driven Native Hybrid Queries With Structured And Unstructured Constraints' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Navigable Proximity Graph-driven Native Hybrid Queries With Structured And Unstructured Constraints' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management</td>
    <td>7</td>
    <td><p>As research interest surges, vector similarity search is applied in multiple
fields, including data mining, computer vision, and information retrieval.
{Given a set of objects (e.g., a set of images) and a query object, we can
easily transform each object into a feature vector and apply the vector
similarity search to retrieve the most similar objects. However, the original
vector similarity search cannot well support \textit{hybrid queries}, where
users not only input unstructured query constraint (i.e., the feature vector of
query object) but also structured query constraint (i.e., the desired
attributes of interest). Hybrid query processing aims at identifying these
objects with similar feature vectors to query object and satisfying the given
attribute constraints. Recent efforts have attempted to answer a hybrid query
by performing attribute filtering and vector similarity search separately and
then merging the results later, which limits efficiency and accuracy because
they are not purpose-built for hybrid queries.} In this paper, we propose a
native hybrid query (NHQ) framework based on proximity graph (PG), which
provides the specialized \textit{composite index and joint pruning} modules for
hybrid queries. We easily deploy existing various PGs on this framework to
process hybrid queries efficiently. Moreover, we present two novel navigable
PGs (NPGs) with optimized edge selection and routing strategies, which obtain
better overall performance than existing PGs. After that, we deploy the
proposed NPGs in NHQ to form two hybrid query methods, which significantly
outperform the state-of-the-art competitors on all experimental datasets
(10\(\times\) faster under the same \textit{Recall}), including eight public and
one in-house real-world datasets. Our code and datasets have been released at
https://github.com/AshenOn3/NHQ.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        Efficiency And Optimization 
      
        Graph Based ANN 
      
        CIKM 
      
        Similarity Search 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/ortega2022unconventional/">Unconventional Application Of K-means For Distributed Approximate Similarity Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Unconventional Application Of K-means For Distributed Approximate Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Unconventional Application Of K-means For Distributed Approximate Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ortega et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Information Sciences</td>
    <td>5</td>
    <td><p>Similarity search based on a distance function in metric spaces is a
fundamental problem for many applications. Queries for similar objects lead to
the well-known machine learning task of nearest-neighbours identification. Many
data indexing strategies, collectively known as Metric Access Methods (MAM),
have been proposed to speed up queries for similar elements in this context.
Moreover, since exact approaches to solve similarity queries can be complex and
time-consuming, alternative options have appeared to reduce query execution
time, such as returning approximate results or resorting to distributed
computing platforms. In this paper, we introduce MASK (Multilevel Approximate
Similarity search with \(k\)-means), an unconventional application of the
\(k\)-means algorithm as the foundation of a multilevel index structure for
approximate similarity search, suitable for metric spaces. We show that
inherent properties of \(k\)-means, like representing high-density data areas
with fewer prototypes, can be leveraged for this purpose. An implementation of
this new indexing method is evaluated, using a synthetic dataset and a
real-world dataset in a high-dimensional and high-sparsity space. Results are
promising and underpin the applicability of this novel indexing method in
multiple domains.</p>
</td>
    <td>
      
        Alt 
      
        Similarity Search 
      
        Vector Indexing 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/wu2022hqann/">HQANN: Efficient And Robust Similarity Search For Hybrid Queries With Structured And Unstructured Constraints</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=HQANN: Efficient And Robust Similarity Search For Hybrid Queries With Structured And Unstructured Constraints' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=HQANN: Efficient And Robust Similarity Search For Hybrid Queries With Structured And Unstructured Constraints' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management</td>
    <td>8</td>
    <td><p>The in-memory approximate nearest neighbor search (ANNS) algorithms have
achieved great success for fast high-recall query processing, but are extremely
inefficient when handling hybrid queries with unstructured (i.e., feature
vectors) and structured (i.e., related attributes) constraints. In this paper,
we present HQANN, a simple yet highly efficient hybrid query processing
framework which can be easily embedded into existing proximity graph-based ANNS
algorithms. We guarantee both low latency and high recall by leveraging
navigation sense among attributes and fusing vector similarity search with
attribute filtering. Experimental results on both public and in-house datasets
demonstrate that HQANN is 10x faster than the state-of-the-art hybrid ANNS
solutions to reach the same recall quality and its performance is hardly
affected by the complexity of attributes. It can reach 99% recall@10 in just
around 50 microseconds On GLOVE-1.2M with thousands of attribute constraints.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        Efficiency And Optimization 
      
        Graph Based ANN 
      
        CIKM 
      
        Similarity Search 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/wang2022cgat/">Cgat: Center-guided Adversarial Training For Deep Hashing-based Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Cgat: Center-guided Adversarial Training For Deep Hashing-based Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Cgat: Center-guided Adversarial Training For Deep Hashing-based Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang Xunguang, Lin Yiqun, Li Xiaomeng</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the ACM Web Conference 2023</td>
    <td>5</td>
    <td><p>Deep hashing has been extensively utilized in massive image retrieval because
of its efficiency and effectiveness. However, deep hashing models are
vulnerable to adversarial examples, making it essential to develop adversarial
defense methods for image retrieval. Existing solutions achieved limited
defense performance because of using weak adversarial samples for training and
lacking discriminative optimization objectives to learn robust features. In
this paper, we present a min-max based Center-guided Adversarial Training,
namely CgAT, to improve the robustness of deep hashing networks through worst
adversarial examples. Specifically, we first formulate the center code as a
semantically-discriminative representative of the input image content, which
preserves the semantic similarity with positive samples and dissimilarity with
negative examples. We prove that a mathematical formula can calculate the
center code immediately. After obtaining the center codes in each optimization
iteration of the deep hashing network, they are adopted to guide the
adversarial training process. On the one hand, CgAT generates the worst
adversarial examples as augmented data by maximizing the Hamming distance
between the hash codes of the adversarial examples and the center codes. On the
other hand, CgAT learns to mitigate the effects of adversarial samples by
minimizing the Hamming distance to the center codes. Extensive experiments on
the benchmark datasets demonstrate the effectiveness of our adversarial
training algorithm in defending against adversarial attacks for deep
hashing-based retrieval. Compared with the current state-of-the-art defense
method, we significantly improve the defense performance by an average of
18.61%, 12.35%, and 11.56% on FLICKR-25K, NUS-WIDE, and MS-COCO,
respectively. The code is available at https://github.com/xunguangwang/CgAT.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Neural Hashing 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/mikriukov2022deep/">Deep Unsupervised Contrastive Hashing For Large-scale Cross-modal Text-image Retrieval In Remote Sensing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Unsupervised Contrastive Hashing For Large-scale Cross-modal Text-image Retrieval In Remote Sensing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Unsupervised Contrastive Hashing For Large-scale Cross-modal Text-image Retrieval In Remote Sensing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Mikriukov Georgii, Ravanbakhsh Mahdyar, Demir BegÃ¼m</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>19</td>
    <td><p>Due to the availability of large-scale multi-modal data (e.g., satellite
images acquired by different sensors, text sentences, etc) archives, the
development of cross-modal retrieval systems that can search and retrieve
semantically relevant data across different modalities based on a query in any
modality has attracted great attention in RS. In this paper, we focus our
attention on cross-modal text-image retrieval, where queries from one modality
(e.g., text) can be matched to archive entries from another (e.g., image). Most
of the existing cross-modal text-image retrieval systems require a high number
of labeled training samples and also do not allow fast and memory-efficient
retrieval due to their intrinsic characteristics. These issues limit the
applicability of the existing cross-modal retrieval systems for large-scale
applications in RS. To address this problem, in this paper we introduce a novel
deep unsupervised cross-modal contrastive hashing (DUCH) method for RS
text-image retrieval. The proposed DUCH is made up of two main modules: 1)
feature extraction module (which extracts deep representations of the
text-image modalities); and 2) hashing module (which learns to generate
cross-modal binary hash codes from the extracted representations). Within the
hashing module, we introduce a novel multi-objective loss function including:
i) contrastive objectives that enable similarity preservation in both intra-
and inter-modal similarities; ii) an adversarial objective that is enforced
across two modalities for cross-modal representation consistency; iii)
binarization objectives for generating representative hash codes. Experimental
results show that the proposed DUCH outperforms state-of-the-art unsupervised
cross-modal hashing methods on two multi-modal (image and text) benchmark
archives in RS. Our code is publicly available at
https://git.tu-berlin.de/rsim/duch.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Multimodal Retrieval 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/mikriukov2022unsupervised/">Unsupervised Contrastive Hashing For Cross-modal Retrieval In Remote Sensing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Unsupervised Contrastive Hashing For Cross-modal Retrieval In Remote Sensing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Unsupervised Contrastive Hashing For Cross-modal Retrieval In Remote Sensing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Mikriukov Georgii, Ravanbakhsh Mahdyar, Demir BegÃ¼m</td> <!-- ðŸ”§ You were missing this -->
    <td>ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</td>
    <td>50</td>
    <td><p>The development of cross-modal retrieval systems that can search and retrieve
semantically relevant data across different modalities based on a query in any
modality has attracted great attention in remote sensing (RS). In this paper,
we focus our attention on cross-modal text-image retrieval, where queries from
one modality (e.g., text) can be matched to archive entries from another (e.g.,
image). Most of the existing cross-modal text-image retrieval systems in RS
require a high number of labeled training samples and also do not allow fast
and memory-efficient retrieval. These issues limit the applicability of the
existing cross-modal retrieval systems for large-scale applications in RS. To
address this problem, in this paper we introduce a novel unsupervised
cross-modal contrastive hashing (DUCH) method for text-image retrieval in RS.
To this end, the proposed DUCH is made up of two main modules: 1) feature
extraction module, which extracts deep representations of two modalities; 2)
hashing module that learns to generate cross-modal binary hash codes from the
extracted representations. We introduce a novel multi-objective loss function
including: i) contrastive objectives that enable similarity preservation in
intra- and inter-modal similarities; ii) an adversarial objective that is
enforced across two modalities for cross-modal representation consistency; and
iii) binarization objectives for generating hash codes. Experimental results
show that the proposed DUCH outperforms state-of-the-art methods. Our code is
publicly available at https://git.tu-berlin.de/rsim/duch.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Multimodal Retrieval 
      
        Similarity Search 
      
        ICASSP 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/tian2022learned/">A Learned Index For Exact Similarity Search In Metric Spaces</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Learned Index For Exact Similarity Search In Metric Spaces' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Learned Index For Exact Similarity Search In Metric Spaces' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Tian et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Knowledge and Data Engineering</td>
    <td>12</td>
    <td><p>Indexing is an effective way to support efficient query processing in large
databases. Recently the concept of learned index, which replaces or complements
traditional index structures with machine learning models, has been actively
explored to reduce storage and search costs. However, accurate and efficient
similarity query processing in high-dimensional metric spaces remains to be an
open challenge. In this paper, we propose a novel indexing approach called LIMS
that uses data clustering, pivot-based data transformation techniques and
learned indexes to support efficient similarity query processing in metric
spaces. In LIMS, the underlying data is partitioned into clusters such that
each cluster follows a relatively uniform data distribution. Data
redistribution is achieved by utilizing a small number of pivots for each
cluster. Similar data are mapped into compact regions and the mapped values are
totally ordinal. Machine learning models are developed to approximate the
position of each data record on disk. Efficient algorithms are designed for
processing range queries and nearest neighbor queries based on LIMS, and for
index maintenance with dynamic updates. Extensive experiments on real-world and
synthetic datasets demonstrate the superiority of LIMS compared with
traditional indexes and state-of-the-art learned indexes.</p>
</td>
    <td>
      
        Vector Indexing 
      
        Similarity Search 
      
        Evaluation 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/mckeown2022hamming/">Hamming Distributions Of Popular Perceptual Hashing Techniques</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hamming Distributions Of Popular Perceptual Hashing Techniques' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hamming Distributions Of Popular Perceptual Hashing Techniques' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Mckeown Sean, Buchanan William J</td> <!-- ðŸ”§ You were missing this -->
    <td>Forensic Science International: Digital Investigation</td>
    <td>9</td>
    <td><p>Content-based file matching has been widely deployed for decades, largely for
the detection of sources of copyright infringement, extremist materials, and
abusive sexual media. Perceptual hashes, such as Microsoftâ€™s PhotoDNA, are one
automated mechanism for facilitating detection, allowing for machines to
approximately match visual features of an image or video in a robust manner.
However, there does not appear to be much public evaluation of such approaches,
particularly when it comes to how effective they are against content-preserving
modifications to media files. In this paper, we present a million-image scale
evaluation of several perceptual hashing archetypes for popular algorithms
(including Facebookâ€™s PDQ, Appleâ€™s Neuralhash, and the popular pHash library)
against seven image variants. The focal point is the distribution of Hamming
distance scores between both unrelated images and image variants to better
understand the problems faced by each approach.</p>
</td>
    <td>
      
        Tools & Libraries 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/mccarter2022look/">Look-ups Are Not (yet) All You Need For Deep Learning Inference</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Look-ups Are Not (yet) All You Need For Deep Learning Inference' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Look-ups Are Not (yet) All You Need For Deep Learning Inference' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Mccarter Calvin, Dronen Nicholas</td> <!-- ðŸ”§ You were missing this -->
    <td>Information Fusion</td>
    <td>1027</td>
    <td><p>Fast approximations to matrix multiplication have the potential to
dramatically reduce the cost of neural network inference. Recent work on
approximate matrix multiplication proposed to replace costly multiplications
with table-lookups by fitting a fast hash function from training data. In this
work, we propose improvements to this previous work, targeted to the deep
learning inference setting, where one has access to both training data and
fixed (already learned) model weight matrices. We further propose a fine-tuning
procedure for accelerating entire neural networks while minimizing loss in
accuracy. Finally, we analyze the proposed method on a simple image
classification task. While we show improvements to prior work, overall
classification accuracy remains substantially diminished compared to exact
matrix multiplication. Our work, despite this negative result, points the way
towards future efforts to accelerate inner products with fast nonlinear hashing
methods.</p>
</td>
    <td>
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/messina2022aladin/">ALADIN: Distilling Fine-grained Alignment Scores For Efficient Image-text Matching And Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=ALADIN: Distilling Fine-grained Alignment Scores For Efficient Image-text Matching And Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=ALADIN: Distilling Fine-grained Alignment Scores For Efficient Image-text Matching And Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Messina et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 19th International Conference on Content-based Multimedia Indexing</td>
    <td>20</td>
    <td><p>Image-text matching is gaining a leading role among tasks involving the joint
understanding of vision and language. In literature, this task is often used as
a pre-training objective to forge architectures able to jointly deal with
images and texts. Nonetheless, it has a direct downstream application:
cross-modal retrieval, which consists in finding images related to a given
query text or vice-versa. Solving this task is of critical importance in
cross-modal search engines. Many recent methods proposed effective solutions to
the image-text matching problem, mostly using recent large vision-language (VL)
Transformer networks. However, these models are often computationally
expensive, especially at inference time. This prevents their adoption in
large-scale cross-modal retrieval scenarios, where results should be provided
to the user almost instantaneously. In this paper, we propose to fill in the
gap between effectiveness and efficiency by proposing an ALign And DIstill
Network (ALADIN). ALADIN first produces high-effective scores by aligning at
fine-grained level images and texts. Then, it learns a shared embedding space -
where an efficient kNN search can be performed - by distilling the relevance
scores obtained from the fine-grained alignments. We obtained remarkable
results on MS-COCO, showing that our method can compete with state-of-the-art
VL Transformers while being almost 90 times faster. The code for reproducing
our results is available at https://github.com/mesnico/ALADIN.</p>
</td>
    <td>
      
        Multimodal Retrieval 
      
        Similarity Search 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/malali2022learning/">Learning To Embed Semantic Similarity For Joint Image-text Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning To Embed Semantic Similarity For Joint Image-text Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning To Embed Semantic Similarity For Joint Image-text Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Malali Noam, Keller Yosi</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Pattern Analysis and Machine Intelligence</td>
    <td>8</td>
    <td><p>We present a deep learning approach for learning the joint semantic
embeddings of images and captions in a Euclidean space, such that the semantic
similarity is approximated by the L2 distances in the embedding space. For
that, we introduce a metric learning scheme that utilizes multitask learning to
learn the embedding of identical semantic concepts using a center loss. By
introducing a differentiable quantization scheme into the end-to-end trainable
network, we derive a semantic embedding of semantically similar concepts in
Euclidean space. We also propose a novel metric learning formulation using an
adaptive margin hinge loss, that is refined during the training phase. The
proposed scheme was applied to the MS-COCO, Flicke30K and Flickr8K datasets,
and was shown to compare favorably with contemporary state-of-the-art
approaches.</p>
</td>
    <td>
      
        Text Retrieval 
      
        DATASETS 
      
        Quantization 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/ma2022deep/">Deep Forest With Hashing Screening And Window Screening</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Forest With Hashing Screening And Window Screening' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Forest With Hashing Screening And Window Screening' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ma et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>ACM Transactions on Knowledge Discovery from Data</td>
    <td>16</td>
    <td><p>As a novel deep learning model, gcForest has been widely used in various
applications. However, the current multi-grained scanning of gcForest produces
many redundant feature vectors, and this increases the time cost of the model.
To screen out redundant feature vectors, we introduce a hashing screening
mechanism for multi-grained scanning and propose a model called HW-Forest which
adopts two strategies, hashing screening and window screening. HW-Forest
employs perceptual hashing algorithm to calculate the similarity between
feature vectors in hashing screening strategy, which is used to remove the
redundant feature vectors produced by multi-grained scanning and can
significantly decrease the time cost and memory consumption. Furthermore, we
adopt a self-adaptive instance screening strategy to improve the performance of
our approach, called window screening, which can achieve higher accuracy
without hyperparameter tuning on different datasets. Our experimental results
show that HW-Forest has higher accuracy than other models, and the time cost is
also reduced.</p>
</td>
    <td>
      
        DATASETS 
      
        Tools & Libraries 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/xiao2022progressively/">Progressively Optimized Bi-granular Document Representation For Scalable Embedding Based Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Progressively Optimized Bi-granular Document Representation For Scalable Embedding Based Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Progressively Optimized Bi-granular Document Representation For Scalable Embedding Based Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Xiao et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the ACM Web Conference 2022</td>
    <td>13</td>
    <td><p>Ad-hoc search calls for the selection of appropriate answers from a
massive-scale corpus. Nowadays, the embedding-based retrieval (EBR) becomes a
promising solution, where deep learning based document representation and ANN
search techniques are allied to handle this task. However, a major challenge is
that the ANN index can be too large to fit into memory, given the considerable
size of answer corpus. In this work, we tackle this problem with Bi-Granular
Document Representation, where the lightweight sparse embeddings are indexed
and standby in memory for coarse-grained candidate search, and the heavyweight
dense embeddings are hosted in disk for fine-grained post verification. For the
best of retrieval accuracy, a Progressive Optimization framework is designed.
The sparse embeddings are learned ahead for high-quality search of candidates.
Conditioned on the candidate distribution induced by the sparse embeddings, the
dense embeddings are continuously learned to optimize the discrimination of
ground-truth from the shortlisted candidates. Besides, two techniques: the
contrastive quantization and the locality-centric sampling are introduced for
the learning of sparse and dense embeddings, which substantially contribute to
their performances. Thanks to the above features, our method effectively
handles massive-scale EBR with strong advantages in accuracy: with up to +4.3%
recall gain on million-scale corpus, and up to +17.5% recall gain on
billion-scale corpus. Besides, Our method is applied to a major sponsored
search platform with substantial gains on revenue (+1.95%), Recall (+1.01%) and
CTR (+0.49%). Our code is available at https://github.com/microsoft/BiDR.</p>
</td>
    <td>
      
        Graph Based ANN 
      
        Large Scale Search 
      
        Quantization 
      
        Vector Indexing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/thakur2022injecting/">Injecting Domain Adaptation With Learning-to-hash For Effective And Efficient Zero-shot Dense Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Injecting Domain Adaptation With Learning-to-hash For Effective And Efficient Zero-shot Dense Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Injecting Domain Adaptation With Learning-to-hash For Effective And Efficient Zero-shot Dense Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Thakur Nandan, Reimers Nils, Lin Jimmy</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>6</td>
    <td><p>Dense retrieval overcome the lexical gap and has shown great success in
ad-hoc information retrieval (IR). Despite their success, dense retrievers are
expensive to serve across practical use cases. For use cases requiring to
search from millions of documents, the dense index becomes bulky and requires
high memory usage for storing the index. More recently, learning-to-hash (LTH)
techniques, for e.g., BPR and JPQ, produce binary document vectors, thereby
reducing the memory requirement to efficiently store the dense index. LTH
techniques are supervised and finetune the retriever using a ranking loss. They
outperform their counterparts, i.e., traditional out-of-the-box vector
compression techniques such as PCA or PQ. A missing piece from prior work is
that existing techniques have been evaluated only in-domain, i.e., on a single
dataset such as MS MARCO. In our work, we evaluate LTH and vector compression
techniques for improving the downstream zero-shot retrieval accuracy of the
TAS-B dense retriever while maintaining efficiency at inference. Our results
demonstrate that, unlike prior work, LTH strategies when applied naively can
underperform the zero-shot TAS-B dense retriever on average by up to 14%
nDCG@10 on the BEIR benchmark. To solve this limitation, in our work, we
propose an easy yet effective solution of injecting domain adaptation with
existing supervised LTH techniques. We experiment with two well-known
unsupervised domain adaptation techniques: GenQ and GPL. Our domain adaptation
injection technique can improve the downstream zero-shot retrieval
effectiveness for both BPR and JPQ variants of the TAS-B model by on average
11.5% and 8.2% nDCG@10 while both maintaining 32\(\times\) memory efficiency and
14\(\times\) and 2\(\times\) speedup respectively in CPU retrieval latency on BEIR.
All our code, models, and data are publicly available at
https://github.com/thakur-nandan/income.</p>
</td>
    <td>
      
        DATASETS 
      
        Quantization 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/zhang2022hashing/">Hashing Learning With Hyper-class Representation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hashing Learning With Hyper-class Representation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hashing Learning With Hyper-class Representation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang Shichao, Li Jiaye</td> <!-- ðŸ”§ You were missing this -->
    <td>Neurocomputing</td>
    <td>26</td>
    <td><p>Existing unsupervised hash learning is a kind of attribute-centered
calculation. It may not accurately preserve the similarity between data. This
leads to low down the performance of hash function learning. In this paper, a
hash algorithm is proposed with a hyper-class representation. It is a two-steps
approach. The first step finds potential decision features and establish
hyper-class. The second step constructs hash learning based on the hyper-class
information in the first step, so that the hash codes of the data within the
hyper-class are as similar as possible, as well as the hash codes of the data
between the hyper-classes are as different as possible. To evaluate the
efficiency, a series of experiments are conducted on four public datasets. The
experimental results show that the proposed hash algorithm is more efficient
than the compared algorithms, in terms of mean average precision (MAP), average
precision (AP) and Hamming radius 2 (HAM2)</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/lu2022asymmetric/">Asymmetric Transfer Hashing With Adaptive Bipartite Graph Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Asymmetric Transfer Hashing With Adaptive Bipartite Graph Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Asymmetric Transfer Hashing With Adaptive Bipartite Graph Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Cybernetics</td>
    <td>8</td>
    <td><p>Thanks to the efficient retrieval speed and low storage consumption, learning
to hash has been widely used in visual retrieval tasks. However, existing
hashing methods assume that the query and retrieval samples lie in homogeneous
feature space within the same domain. As a result, they cannot be directly
applied to heterogeneous cross-domain retrieval. In this paper, we propose a
Generalized Image Transfer Retrieval (GITR) problem, which encounters two
crucial bottlenecks: 1) the query and retrieval samples may come from different
domains, leading to an inevitable {domain distribution gap}; 2) the features of
the two domains may be heterogeneous or misaligned, bringing up an additional
{feature gap}. To address the GITR problem, we propose an Asymmetric Transfer
Hashing (ATH) framework with its unsupervised/semi-supervised/supervised
realizations. Specifically, ATH characterizes the domain distribution gap by
the discrepancy between two asymmetric hash functions, and minimizes the
feature gap with the help of a novel adaptive bipartite graph constructed on
cross-domain data. By jointly optimizing asymmetric hash functions and the
bipartite graph, not only can knowledge transfer be achieved but information
loss caused by feature alignment can also be avoided. Meanwhile, to alleviate
negative transfer, the intrinsic geometrical structure of single-domain data is
preserved by involving a domain affinity graph. Extensive experiments on both
single-domain and cross-domain benchmarks under different GITR subtasks
indicate the superiority of our ATH method in comparison with the
state-of-the-art hashing methods.</p>
</td>
    <td>
      
        Similarity Search 
      
        Tools & Libraries 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/liu2022towards/">Towards Fast And Accurate Federated Learning With Non-iid Data For Cloud-based Iot Applications</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Towards Fast And Accurate Federated Learning With Non-iid Data For Cloud-based Iot Applications' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Towards Fast And Accurate Federated Learning With Non-iid Data For Cloud-based Iot Applications' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Journal of Circuits, Systems and Computers</td>
    <td>7</td>
    <td><p>As a promising method of central model training on decentralized device data
while securing user privacy, Federated Learning (FL)is becoming popular in
Internet of Things (IoT) design. However, when the data collected by IoT
devices are highly skewed in a non-independent and identically distributed
(non-IID) manner, the accuracy of vanilla FL method cannot be guaranteed.
Although there exist various solutions that try to address the bottleneck of FL
with non-IID data, most of them suffer from extra intolerable communication
overhead and low model accuracy. To enable fast and accurate FL, this paper
proposes a novel data-based device grouping approach that can effectively
reduce the disadvantages of weight divergence during the training of non-IID
data. However, since our grouping method is based on the similarity of
extracted feature maps from IoT devices, it may incur additional risks of
privacy exposure. To solve this problem, we propose an improved version by
exploiting similarity information using the Locality-Sensitive Hashing (LSH)
algorithm without exposing extracted feature maps. Comprehensive experimental
results on well-known benchmarks show that our approach can not only accelerate
the convergence rate, but also improve the prediction accuracy for FL with
non-IID data.</p>
</td>
    <td>
      
        Alt 
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/liu2022das/">DAS: Densely-anchored Sampling For Deep Metric Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=DAS: Densely-anchored Sampling For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=DAS: Densely-anchored Sampling For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>13</td>
    <td><p>Deep Metric Learning (DML) serves to learn an embedding function to project
semantically similar data into nearby embedding space and plays a vital role in
many applications, such as image retrieval and face recognition. However, the
performance of DML methods often highly depends on sampling methods to choose
effective data from the embedding space in the training. In practice, the
embeddings in the embedding space are obtained by some deep models, where the
embedding space is often with barren area due to the absence of training
points, resulting in so called â€œmissing embeddingâ€ issue. This issue may impair
the sample quality, which leads to degenerated DML performance. In this work,
we investigate how to alleviate the â€œmissing embeddingâ€ issue to improve the
sampling quality and achieve effective DML. To this end, we propose a
Densely-Anchored Sampling (DAS) scheme that considers the embedding with
corresponding data point as â€œanchorâ€ and exploits the anchorâ€™s nearby embedding
space to densely produce embeddings without data points. Specifically, we
propose to exploit the embedding space around single anchor with Discriminative
Feature Scaling (DFS) and multiple anchors with Memorized Transformation
Shifting (MTS). In this way, by combing the embeddings with and without data
points, we are able to provide more embeddings to facilitate the sampling
process thus boosting the performance of DML. Our method is effortlessly
integrated into existing DML frameworks and improves them without bells and
whistles. Extensive experiments on three benchmark datasets demonstrate the
superiority of our method.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Distance Metric Learning 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/liu2022wl/">Wl-align: Weisfeiler-lehman Relabeling For Aligning Users Across Networks Via Regularized Representation Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Wl-align: Weisfeiler-lehman Relabeling For Aligning Users Across Networks Via Regularized Representation Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Wl-align: Weisfeiler-lehman Relabeling For Aligning Users Across Networks Via Regularized Representation Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Knowledge and Data Engineering</td>
    <td>9</td>
    <td><p>Aligning users across networks using graph representation learning has been
found effective where the alignment is accomplished in a low-dimensional
embedding space. Yet, achieving highly precise alignment is still challenging,
especially when nodes with long-range connectivity to the labeled anchors are
encountered. To alleviate this limitation, we purposefully designed WL-Align
which adopts a regularized representation learning framework to learn
distinctive node representations. It extends the Weisfeiler-Lehman Isormorphism
Test and learns the alignment in alternating phases of â€œacross-network
Weisfeiler-Lehman relabelingâ€ and â€œproximity-preserving representation
learningâ€. The across-network Weisfeiler-Lehman relabeling is achieved through
iterating the anchor-based label propagation and a similarity-based hashing to
exploit the known anchorsâ€™ connectivity to different nodes in an efficient and
robust manner. The representation learning module preserves the second-order
proximity within individual networks and is regularized by the across-network
Weisfeiler-Lehman hash labels. Extensive experiments on real-world and
synthetic datasets have demonstrated that our proposed WL-Align outperforms the
state-of-the-art methods, achieving significant performance improvements in the
â€œexact matchingâ€ scenario. Data and code of WL-Align are available at
https://github.com/ChenPengGang/WLAlignCode.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Alt 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/lin2022deep/">Deep Unsupervised Hashing With Latent Semantic Components</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Unsupervised Hashing With Latent Semantic Components' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Unsupervised Hashing With Latent Semantic Components' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lin et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>17</td>
    <td><p>Deep unsupervised hashing has been appreciated in the regime of image
retrieval. However, most prior arts failed to detect the semantic components
and their relationships behind the images, which makes them lack discriminative
power. To make up the defect, we propose a novel Deep Semantic Components
Hashing (DSCH), which involves a common sense that an image normally contains a
bunch of semantic components with homology and co-occurrence relationships.
Based on this prior, DSCH regards the semantic components as latent variables
under the Expectation-Maximization framework and designs a two-step iterative
algorithm with the objective of maximum likelihood of training data. Firstly,
DSCH constructs a semantic component structure by uncovering the fine-grained
semantics components of images with a Gaussian Mixture Modal~(GMM), where an
image is represented as a mixture of multiple components, and the semantics
co-occurrence are exploited. Besides, coarse-grained semantics components, are
discovered by considering the homology relationships between fine-grained
components, and the hierarchy organization is then constructed. Secondly, DSCH
makes the images close to their semantic component centers at both fine-grained
and coarse-grained levels, and also makes the images share similar semantic
components close to each other. Extensive experiments on three benchmark
datasets demonstrate that the proposed hierarchical semantic components indeed
facilitate the hashing model to achieve superior performance.</p>
</td>
    <td>
      
        AAAI 
      
        DATASETS 
      
        Hashing Methods 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/xue2022cross/">Cross-scale Context Extracted Hashing For Fine-grained Image Binary Encoding</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Cross-scale Context Extracted Hashing For Fine-grained Image Binary Encoding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Cross-scale Context Extracted Hashing For Fine-grained Image Binary Encoding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Xue et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>5</td>
    <td><p>Deep hashing has been widely applied to large-scale image retrieval tasks
owing to efficient computation and low storage cost by encoding
high-dimensional image data into binary codes. Since binary codes do not
contain as much information as float features, the essence of binary encoding
is preserving the main context to guarantee retrieval quality. However, the
existing hashing methods have great limitations on suppressing redundant
background information and accurately encoding from Euclidean space to Hamming
space by a simple sign function. In order to solve these problems, a
Cross-Scale Context Extracted Hashing Network (CSCE-Net) is proposed in this
paper. Firstly, we design a two-branch framework to capture fine-grained local
information while maintaining high-level global semantic information. Besides,
Attention guided Information Extraction module (AIE) is introduced between two
branches, which suppresses areas of low context information cooperated with
global sliding windows. Unlike previous methods, our CSCE-Net learns a
content-related Dynamic Sign Function (DSF) to replace the original simple sign
function. Therefore, the proposed CSCE-Net is context-sensitive and able to
perform well on accurate image binary encoding. We further demonstrate that our
CSCE-Net is superior to the existing hashing methods, which improves retrieval
performance on standard benchmarks.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Neural Hashing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/xu2022hyp/">Hyp\(^2\) Loss: Beyond Hypersphere Metric Space For Multi-label Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hyp\(^2\) Loss: Beyond Hypersphere Metric Space For Multi-label Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hyp\(^2\) Loss: Beyond Hypersphere Metric Space For Multi-label Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Xu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 30th ACM International Conference on Multimedia</td>
    <td>15</td>
    <td><p>Image retrieval has become an increasingly appealing technique with broad
multimedia application prospects, where deep hashing serves as the dominant
branch towards low storage and efficient retrieval. In this paper, we carried
out in-depth investigations on metric learning in deep hashing for establishing
a powerful metric space in multi-label scenarios, where the pair loss suffers
high computational overhead and converge difficulty, while the proxy loss is
theoretically incapable of expressing the profound label dependencies and
exhibits conflicts in the constructed hypersphere space. To address the
problems, we propose a novel metric learning framework with Hybrid Proxy-Pair
Loss (HyP\(^2\) Loss) that constructs an expressive metric space with efficient
training complexity w.r.t. the whole dataset. The proposed HyP\(^2\) Loss focuses
on optimizing the hypersphere space by learnable proxies and excavating
data-to-data correlations of irrelevant pairs, which integrates sufficient data
correspondence of pair-based methods and high-efficiency of proxy-based
methods. Extensive experiments on four standard multi-label benchmarks justify
the proposed method outperforms the state-of-the-art, is robust among different
hash bits and achieves significant performance gains with a faster, more stable
convergence speed. Our code is available at
https://github.com/JerryXu0129/HyP2-Loss.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Distance Metric Learning 
      
        Neural Hashing 
      
        Similarity Search 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/li2022asymmetric/">Asymmetric Scalable Cross-modal Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Asymmetric Scalable Cross-modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Asymmetric Scalable Cross-modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li Wenyun, Pun Chi-man</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Knowledge and Data Engineering</td>
    <td>113</td>
    <td><p>Cross-modal hashing is a successful method to solve large-scale multimedia
retrieval issue. A lot of matrix factorization-based hashing methods are
proposed. However, the existing methods still struggle with a few problems,
such as how to generate the binary codes efficiently rather than directly relax
them to continuity. In addition, most of the existing methods choose to use an
\(n\times n\) similarity matrix for optimization, which makes the memory and
computation unaffordable. In this paper we propose a novel Asymmetric Scalable
Cross-Modal Hashing (ASCMH) to address these issues. It firstly introduces a
collective matrix factorization to learn a common latent space from the
kernelized features of different modalities, and then transforms the similarity
matrix optimization to a distance-distance difference problem minimization with
the help of semantic labels and common latent space. Hence, the computational
complexity of the \(n\times n\) asymmetric optimization is relieved. In the
generation of hash codes we also employ an orthogonal constraint of label
information, which is indispensable for search accuracy. So the redundancy of
computation can be much reduced. For efficient optimization and scalable to
large-scale datasets, we adopt the two-step approach rather than optimizing
simultaneously. Extensive experiments on three benchmark datasets: Wiki,
MIRFlickr-25K, and NUS-WIDE, demonstrate that our ASCMH outperforms the
state-of-the-art cross-modal hashing methods in terms of accuracy and
efficiency.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/li2022adaptive/">Adaptive Structural Similarity Preserving For Unsupervised Cross Modal Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Adaptive Structural Similarity Preserving For Unsupervised Cross Modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Adaptive Structural Similarity Preserving For Unsupervised Cross Modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li Liang, Zheng Baihua, Sun Weiwei</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 30th ACM International Conference on Multimedia</td>
    <td>22</td>
    <td><p>Cross-modal hashing is an important approach for multimodal data management
and application. Existing unsupervised cross-modal hashing algorithms mainly
rely on data features in pre-trained models to mine their similarity
relationships. However, their optimization objectives are based on the static
metric between the original uni-modal features, without further exploring data
correlations during the training. In addition, most of them mainly focus on
association mining and alignment among pairwise instances in continuous space
but ignore the latent structural correlations contained in the semantic hashing
space. In this paper, we propose an unsupervised hash learning framework,
namely Adaptive Structural Similarity Preservation Hashing (ASSPH), to solve
the above problems. Firstly, we propose an adaptive learning scheme, with
limited data and training batches, to enrich semantic correlations of unlabeled
instances during the training process and meanwhile to ensure a smooth
convergence of the training process. Secondly, we present an asymmetric
structural semantic representation learning scheme. We introduce structural
semantic metrics based on graph adjacency relations during the semantic
reconstruction and correlation mining stage and meanwhile align the structure
semantics in the hash space with an asymmetric binary optimization process.
Finally, we conduct extensive experiments to validate the enhancements of our
work in comparison with existing works.</p>
</td>
    <td>
      
        Text Retrieval 
      
        Tools & Libraries 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/lassance2022composite/">Composite Code Sparse Autoencoders For First Stage Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Composite Code Sparse Autoencoders For First Stage Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Composite Code Sparse Autoencoders For First Stage Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lassance Carlos, Formal Thibault, Clinchant Stephane</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</td>
    <td>5</td>
    <td><p>We propose a Composite Code Sparse Autoencoder (CCSA) approach for
Approximate Nearest Neighbor (ANN) search of document representations based on
Siamese-BERT models. In Information Retrieval (IR), the ranking pipeline is
generally decomposed in two stages: the first stage focus on retrieving a
candidate set from the whole collection. The second stage re-ranks the
candidate set by relying on more complex models. Recently, Siamese-BERT models
have been used as first stage ranker to replace or complement the traditional
bag-of-word models. However, indexing and searching a large document collection
require efficient similarity search on dense vectors and this is why ANN
techniques come into play. Since composite codes are naturally sparse, we first
show how CCSA can learn efficient parallel inverted index thanks to an
uniformity regularizer. Second, CCSA can be used as a binary quantization
method and we propose to combine it with the recent graph based ANN techniques.
Our experiments on MSMARCO dataset reveal that CCSA outperforms IVF with
product quantization. Furthermore, CCSA binary quantization is beneficial for
the index size, and memory usage for the graph-based HNSW method, while
maintaining a good level of recall and MRR. Third, we compare with recent
supervised quantization methods for image retrieval and find that CCSA is able
to outperform them.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Graph Based ANN 
      
        Efficiency And Optimization 
      
        SIGIR 
      
        Similarity Search 
      
        Quantization 
      
        Vector Indexing 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/wang2022contrastive/">Contrastive Masked Autoencoders For Self-supervised Video Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Contrastive Masked Autoencoders For Self-supervised Video Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Contrastive Masked Autoencoders For Self-supervised Video Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>17</td>
    <td><p>Self-Supervised Video Hashing (SSVH) models learn to generate short binary
representations for videos without ground-truth supervision, facilitating
large-scale video retrieval efficiency and attracting increasing research
attention. The success of SSVH lies in the understanding of video content and
the ability to capture the semantic relation among unlabeled videos. Typically,
state-of-the-art SSVH methods consider these two points in a two-stage training
pipeline, where they firstly train an auxiliary network by instance-wise
mask-and-predict tasks and secondly train a hashing model to preserve the
pseudo-neighborhood structure transferred from the auxiliary network. This
consecutive training strategy is inflexible and also unnecessary. In this
paper, we propose a simple yet effective one-stage SSVH method called ConMH,
which incorporates video semantic information and video similarity relationship
understanding in a single stage. To capture video semantic information for
better hashing learning, we adopt an encoder-decoder structure to reconstruct
the video from its temporal-masked frames. Particularly, we find that a higher
masking ratio helps video understanding. Besides, we fully exploit the
similarity relationship between videos by maximizing agreement between two
augmented views of a video, which contributes to more discriminative and robust
hash codes. Extensive experiments on three large-scale video datasets (i.e.,
FCVID, ActivityNet and YFCC) indicate that ConMH achieves state-of-the-art
results. Code is available at https://github.com/huangmozhi9527/ConMH.</p>
</td>
    <td>
      
        AAAI 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/kuszmaul2022hash/">A Hash Table Without Hash Functions, And How To Get The Most Out Of Your Random Bits</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Hash Table Without Hash Functions, And How To Get The Most Out Of Your Random Bits' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Hash Table Without Hash Functions, And How To Get The Most Out Of Your Random Bits' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Kuszmaul William</td> <!-- ðŸ”§ You were missing this -->
    <td>2022 IEEE 63rd Annual Symposium on Foundations of Computer Science (FOCS)</td>
    <td>5</td>
    <td><p>This paper considers the basic question of how strong of a probabilistic
guarantee can a hash table, storing \(n\) \((1 + \Theta(1)) log n\)-bit key/value
pairs, offer? Past work on this question has been bottlenecked by limitations
of the known families of hash functions: The only hash tables to achieve
failure probabilities less than \(1 / 2^{\polylog n}\) require access to
fully-random hash functions â€“ if the same hash tables are implemented using
the known explicit families of hash functions, their failure probabilities
become \(1 / \poly(n)\).
  To get around these obstacles, we show how to construct a randomized data
structure that has the same guarantees as a hash table, but that <em>avoids
the direct use of hash functions</em>. Building on this, we are able to construct a
hash table using \(O(n)\) random bits that achieves failure probability \(1 /
n^{n^{1 - \epsilon}}\) for an arbitrary positive constant \(\epsilon\).
  In fact, we show that this guarantee can even be achieved by a <em>succinct
dictionary</em>, that is, by a dictionary that uses space within a \(1 + o(1)\)
factor of the information-theoretic optimum.
  Finally we also construct a succinct hash table whose probabilistic
guarantees fall on a different extreme, offering a failure probability of \(1 /
\poly(n)\) while using only \(\tilde{O}(log n)\) random bits. This latter result
matches (up to low-order terms) a guarantee previously achieved by
Dietzfelbinger et al., but with increased space efficiency and with several
surprising technical components.</p>
</td>
    <td>
      
        TACL 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/zhang2022lightfr/">Lightfr: Lightweight Federated Recommendation With Privacy-preserving Matrix Factorization</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Lightfr: Lightweight Federated Recommendation With Privacy-preserving Matrix Factorization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Lightfr: Lightweight Federated Recommendation With Privacy-preserving Matrix Factorization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>ACM Transactions on Information Systems</td>
    <td>43</td>
    <td><p>Federated recommender system (FRS), which enables many local devices to train
a shared model jointly without transmitting local raw data, has become a
prevalent recommendation paradigm with privacy-preserving advantages. However,
previous work on FRS performs similarity search via inner product in continuous
embedding space, which causes an efficiency bottleneck when the scale of items
is extremely large. We argue that such a scheme in federated settings ignores
the limited capacities in resource-constrained user devices (i.e., storage
space, computational overhead, and communication bandwidth), and makes it
harder to be deployed in large-scale recommender systems. Besides, it has been
shown that transmitting local gradients in real-valued form between server and
clients may leak usersâ€™ private information. To this end, we propose a
lightweight federated recommendation framework with privacy-preserving matrix
factorization, LightFR, that is able to generate high-quality binary codes by
exploiting learning to hash technique under federated settings, and thus enjoys
both fast online inference and economic memory consumption. Moreover, we devise
an efficient federated discrete optimization algorithm to collaboratively train
model parameters between the server and clients, which can effectively prevent
real-valued gradient attacks from malicious parties. Through extensive
experiments on four real-world datasets, we show that our LightFR model
outperforms several state-of-the-art FRS methods in terms of recommendation
accuracy, inference efficiency and data privacy.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Recommender Systems 
      
        Similarity Search 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/yeh2022embedding/">Embedding Compression With Hashing For Efficient Representation Learning In Large-scale Graph</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Embedding Compression With Hashing For Efficient Representation Learning In Large-scale Graph' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Embedding Compression With Hashing For Efficient Representation Learning In Large-scale Graph' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yeh et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</td>
    <td>13</td>
    <td><p>Graph neural networks (GNNs) are deep learning models designed specifically
for graph data, and they typically rely on node features as the input to the
first layer. When applying such a type of network on the graph without node
features, one can extract simple graph-based node features (e.g., number of
degrees) or learn the input node representations (i.e., embeddings) when
training the network. While the latter approach, which trains node embeddings,
more likely leads to better performance, the number of parameters associated
with the embeddings grows linearly with the number of nodes. It is therefore
impractical to train the input node embeddings together with GNNs within
graphics processing unit (GPU) memory in an end-to-end fashion when dealing
with industrial-scale graph data. Inspired by the embedding compression methods
developed for natural language processing (NLP) tasks, we develop a node
embedding compression method where each node is compactly represented with a
bit vector instead of a floating-point vector. The parameters utilized in the
compression method can be trained together with GNNs. We show that the proposed
node embedding compression method achieves superior performance compared to the
alternatives.</p>
</td>
    <td>
      
        KDD 
      
        Hashing Methods 
      
        Graph Based ANN 
      
        Alt 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/kim2022accelerating/">Accelerating Large-scale Graph-based Nearest Neighbor Search On A Computational Storage Platform</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Accelerating Large-scale Graph-based Nearest Neighbor Search On A Computational Storage Platform' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Accelerating Large-scale Graph-based Nearest Neighbor Search On A Computational Storage Platform' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Kim et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Computers</td>
    <td>20</td>
    <td><p>K-nearest neighbor search is one of the fundamental tasks in various
applications and the hierarchical navigable small world (HNSW) has recently
drawn attention in large-scale cloud services, as it easily scales up the
database while offering fast search. On the other hand, a computational storage
device (CSD) that combines programmable logic and storage modules on a single
board becomes popular to address the data bandwidth bottleneck of modern
computing systems. In this paper, we propose a computational storage platform
that can accelerate a large-scale graph-based nearest neighbor search algorithm
based on SmartSSD CSD. To this end, we modify the algorithm more amenable on
the hardware and implement two types of accelerators using HLS- and RTL-based
methodology with various optimization methods. In addition, we scale up the
proposed platform to have 4 SmartSSDs and apply graph parallelism to boost the
system performance further. As a result, the proposed computational storage
platform achieves 75.59 query per second throughput for the SIFT1B dataset at
258.66W power dissipation, which is 12.83x and 17.91x faster and 10.43x and
24.33x more energy efficient than the conventional CPU-based and GPU-based
server platform, respectively. With multi-terabyte storage and custom
acceleration capability, we believe that the proposed computational storage
platform is a promising solution for cost-sensitive cloud datacenters.</p>
</td>
    <td>
      
        Graph Based ANN 
      
        DATASETS 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/ke2022compare/">Compare Learning: Bi-attention Network For Few-shot Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Compare Learning: Bi-attention Network For Few-shot Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Compare Learning: Bi-attention Network For Few-shot Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ke et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</td>
    <td>6</td>
    <td><p>Learning with few labeled data is a key challenge for visual recognition, as
deep neural networks tend to overfit using a few samples only. One of the
Few-shot learning methods called metric learning addresses this challenge by
first learning a deep distance metric to determine whether a pair of images
belong to the same category, then applying the trained metric to instances from
other test set with limited labels. This method makes the most of the few
samples and limits the overfitting effectively. However, extant metric networks
usually employ Linear classifiers or Convolutional neural networks (CNN) that
are not precise enough to globally capture the subtle differences between
vectors. In this paper, we propose a novel approach named Bi-attention network
to compare the instances, which can measure the similarity between embeddings
of instances precisely, globally and efficiently. We verify the effectiveness
of our model on two benchmarks. Experiments show that our approach achieved
improved accuracy and convergence speed over baseline models.</p>
</td>
    <td>
      
        ICASSP 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/wei2022accurate/">Accurate Instance-level CAD Model Retrieval In A Large-scale Database</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Accurate Instance-level CAD Model Retrieval In A Large-scale Database' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Accurate Instance-level CAD Model Retrieval In A Large-scale Database' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wei et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</td>
    <td>5</td>
    <td><p>We present a new solution to the fine-grained retrieval of clean CAD models
from a large-scale database in order to recover detailed object shape
geometries for RGBD scans. Unlike previous work simply indexing into a
moderately small database using an object shape descriptor and accepting the
top retrieval result, we argue that in the case of a large-scale database a
more accurate model may be found within a neighborhood of the descriptor. More
importantly, we propose that the distinctiveness deficiency of shape
descriptors at the instance level can be compensated by a geometry-based
re-ranking of its neighborhood. Our approach first leverages the discriminative
power of learned representations to distinguish between different categories of
models and then uses a novel robust point set distance metric to re-rank the
CAD neighborhood, enabling fine-grained retrieval in a large shape database.
Evaluation on a real-world dataset shows that our geometry-based re-ranking is
a conceptually simple but highly effective method that can lead to a
significant improvement in retrieval accuracy compared to the state-of-the-art.</p>
</td>
    <td>
      
        DATASETS 
      
        IROS 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/wei2022hyperbolic/">Hyperbolic Hierarchical Contrastive Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hyperbolic Hierarchical Contrastive Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hyperbolic Hierarchical Contrastive Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wei et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence</td>
    <td>19</td>
    <td><p>Hierarchical semantic structures, naturally existing in real-world datasets,
can assist in capturing the latent distribution of data to learn robust hash
codes for retrieval systems. Although hierarchical semantic structures can be
simply expressed by integrating semantically relevant data into a high-level
taxon with coarser-grained semantics, the construction, embedding, and
exploitation of the structures remain tricky for unsupervised hash learning. To
tackle these problems, we propose a novel unsupervised hashing method named
Hyperbolic Hierarchical Contrastive Hashing (HHCH). We propose to embed
continuous hash codes into hyperbolic space for accurate semantic expression
since embedding hierarchies in hyperbolic space generates less distortion than
in hyper-sphere space and Euclidean space. In addition, we extend the K-Means
algorithm to hyperbolic space and perform the proposed hierarchical hyperbolic
K-Means algorithm to construct hierarchical semantic structures adaptively. To
exploit the hierarchical semantic structures in hyperbolic space, we designed
the hierarchical contrastive learning algorithm, including hierarchical
instance-wise and hierarchical prototype-wise contrastive learning. Extensive
experiments on four benchmark datasets demonstrate that the proposed method
outperforms the state-of-the-art unsupervised hashing methods. Codes will be
released.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        IJCAI 
      
        Hashing Methods 
      
        AAAI 
      
        Alt 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/jung2022few/">Few-shot Metric Learning: Online Adaptation Of Embedding For Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Few-shot Metric Learning: Online Adaptation Of Embedding For Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Few-shot Metric Learning: Online Adaptation Of Embedding For Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jung et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>5</td>
    <td><p>Metric learning aims to build a distance metric typically by learning an
effective embedding function that maps similar objects into nearby points in
its embedding space. Despite recent advances in deep metric learning, it
remains challenging for the learned metric to generalize to unseen classes with
a substantial domain gap. To tackle the issue, we explore a new problem of
few-shot metric learning that aims to adapt the embedding function to the
target domain with only a few annotated data. We introduce three few-shot
metric learning baselines and propose the Channel-Rectifier Meta-Learning
(CRML), which effectively adapts the metric space online by adjusting channels
of intermediate layers. Experimental analyses on miniImageNet, CUB-200-2011,
MPII, as well as a new dataset, miniDeepFashion, demonstrate that our method
consistently improves the learned metric by adapting it to target classes and
achieves a greater gain in image retrieval when the domain gap from the source
classes is larger.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/jia2022fast/">Fast Online Hashing With Multi-label Projection</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fast Online Hashing With Multi-label Projection' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fast Online Hashing With Multi-label Projection' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jia et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>6</td>
    <td><p>Hashing has been widely researched to solve the large-scale approximate
nearest neighbor search problem owing to its time and storage superiority. In
recent years, a number of online hashing methods have emerged, which can update
the hash functions to adapt to the new stream data and realize dynamic
retrieval. However, existing online hashing methods are required to update the
whole database with the latest hash functions when a query arrives, which leads
to low retrieval efficiency with the continuous increase of the stream data. On
the other hand, these methods ignore the supervision relationship among the
examples, especially in the multi-label case. In this paper, we propose a novel
Fast Online Hashing (FOH) method which only updates the binary codes of a small
part of the database. To be specific, we first build a query pool in which the
nearest neighbors of each central point are recorded. When a new query arrives,
only the binary codes of the corresponding potential neighbors are updated. In
addition, we create a similarity matrix which takes the multi-label supervision
information into account and bring in the multi-label projection loss to
further preserve the similarity among the multi-label data. The experimental
results on two common benchmarks show that the proposed FOH can achieve
dramatic superiority on query time up to 6.28 seconds less than
state-of-the-art baselines with competitive retrieval accuracy.</p>
</td>
    <td>
      
        AAAI 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/jaiswal2022ood/">Ood-diskann: Efficient And Scalable Graph ANNS For Out-of-distribution Queries</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Ood-diskann: Efficient And Scalable Graph ANNS For Out-of-distribution Queries' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Ood-diskann: Efficient And Scalable Graph ANNS For Out-of-distribution Queries' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jaiswal et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Knowledge and Data Engineering</td>
    <td>47</td>
    <td><p>State-of-the-art algorithms for Approximate Nearest Neighbor Search (ANNS)
such as DiskANN, FAISS-IVF, and HNSW build data dependent indices that offer
substantially better accuracy and search efficiency over data-agnostic indices
by overfitting to the index data distribution. When the query data is drawn
from a different distribution - e.g., when index represents image embeddings
and query represents textual embeddings - such algorithms lose much of this
performance advantage. On a variety of datasets, for a fixed recall target,
latency is worse by an order of magnitude or more for Out-Of-Distribution (OOD)
queries as compared to In-Distribution (ID) queries. The question we address in
this work is whether ANNS algorithms can be made efficient for OOD queries if
the index construction is given access to a small sample set of these queries.
We answer positively by presenting OOD-DiskANN, which uses a sparing sample (1%
of index set size) of OOD queries, and provides up to 40% improvement in mean
query latency over SoTA algorithms of a similar memory footprint. OOD-DiskANN
is scalable and has the efficiency of graph-based ANNS indices. Some of our
contributions can improve query efficiency for ID queries as well.</p>
</td>
    <td>
      
        DATASETS 
      
        Graph Based ANN 
      
        Efficiency And Optimization 
      
        Vector Indexing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/jafari2022experimental/">Experimental Analysis Of Machine Learning Techniques For Finding Search Radius In Locality Sensitive Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Experimental Analysis Of Machine Learning Techniques For Finding Search Radius In Locality Sensitive Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Experimental Analysis Of Machine Learning Techniques For Finding Search Radius In Locality Sensitive Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jafari Omid, Nagarkar Parth</td> <!-- ðŸ”§ You were missing this -->
    <td>International Journal of Fuzzy Logic and Intelligent Systems</td>
    <td>13</td>
    <td><p>Finding similar data in high-dimensional spaces is one of the important tasks
in multimedia applications. Approaches introduced to find exact searching
techniques often use tree-based index structures which are known to suffer from
the curse of the dimensionality problem that limits their performance.
Approximate searching techniques prefer performance over accuracy and they
return good enough results while achieving a better performance. Locality
Sensitive Hashing (LSH) is one of the most popular approximate nearest neighbor
search techniques for high-dimensional spaces. One of the most time-consuming
processes in LSH is to find the neighboring points in the projected spaces. An
improved LSH-based index structure, called radius-optimized Locality Sensitive
Hashing (roLSH) has been proposed to utilize Machine Learning and efficiently
find these neighboring points; thus, further improve the overall performance of
LSH. In this paper, we extend roLSH by experimentally studying the effect of
different types of famous Machine Learning techniques on overall performance.
We compare ten regression techniques on four real-world datasets and show that
Neural Network-based techniques are the best fit to be used in roLSH as their
accuracy and performance trade-off are the best compared to the other
techniques.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Tree Based ANN 
      
        Vector Indexing 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/tu2022unsupervised/">Unsupervised Hashing With Semantic Concept Mining</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Unsupervised Hashing With Semantic Concept Mining' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Unsupervised Hashing With Semantic Concept Mining' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Tu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the ACM on Management of Data</td>
    <td>6</td>
    <td><p>Recently, to improve the unsupervised image retrieval performance, plenty of
unsupervised hashing methods have been proposed by designing a semantic
similarity matrix, which is based on the similarities between image features
extracted by a pre-trained CNN model. However, most of these methods tend to
ignore high-level abstract semantic concepts contained in images. Intuitively,
concepts play an important role in calculating the similarity among images. In
real-world scenarios, each image is associated with some concepts, and the
similarity between two images will be larger if they share more identical
concepts. Inspired by the above intuition, in this work, we propose a novel
Unsupervised Hashing with Semantic Concept Mining, called UHSCM, which
leverages a VLP model to construct a high-quality similarity matrix.
Specifically, a set of randomly chosen concepts is first collected. Then, by
employing a vision-language pretraining (VLP) model with the prompt engineering
which has shown strong power in visual representation learning, the set of
concepts is denoised according to the training images. Next, the proposed
method UHSCM applies the VLP model with prompting again to mine the concept
distribution of each image and construct a high-quality semantic similarity
matrix based on the mined concept distributions. Finally, with the semantic
similarity matrix as guiding information, a novel hashing loss with a modified
contrastive loss based regularization item is proposed to optimize the hashing
network. Extensive experiments on three benchmark datasets show that the
proposed method outperforms the state-of-the-art baselines in the image
retrieval task.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/hu2022badhash/">Badhash: Invisible Backdoor Attacks Against Deep Hashing With Clean Label</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Badhash: Invisible Backdoor Attacks Against Deep Hashing With Clean Label' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Badhash: Invisible Backdoor Attacks Against Deep Hashing With Clean Label' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Hu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 30th ACM International Conference on Multimedia</td>
    <td>26</td>
    <td><p>Due to its powerful feature learning capability and high efficiency, deep
hashing has achieved great success in large-scale image retrieval. Meanwhile,
extensive works have demonstrated that deep neural networks (DNNs) are
susceptible to adversarial examples, and exploring adversarial attack against
deep hashing has attracted many research efforts. Nevertheless, backdoor
attack, another famous threat to DNNs, has not been studied for deep hashing
yet. Although various backdoor attacks have been proposed in the field of image
classification, existing approaches failed to realize a truly imperceptive
backdoor attack that enjoys invisible triggers and clean label setting
simultaneously, and they also cannot meet the intrinsic demand of image
retrieval backdoor. In this paper, we propose BadHash, the first
generative-based imperceptible backdoor attack against deep hashing, which can
effectively generate invisible and input-specific poisoned images with clean
label. Specifically, we first propose a new conditional generative adversarial
network (cGAN) pipeline to effectively generate poisoned samples. For any given
benign image, it seeks to generate a natural-looking poisoned counterpart with
a unique invisible trigger. In order to improve the attack effectiveness, we
introduce a label-based contrastive learning network LabCLN to exploit the
semantic characteristics of different labels, which are subsequently used for
confusing and misleading the target model to learn the embedded trigger. We
finally explore the mechanism of backdoor attacks on image retrieval in the
hash space. Extensive experiments on multiple benchmark datasets verify that
BadHash can generate imperceptible poisoned samples with strong attack ability
and transferability over state-of-the-art deep hashing schemes.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Alt 
      
        Neural Hashing 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/hemati2022learning/">Learning Binary And Sparse Permutation-invariant Representations For Fast And Memory Efficient Whole Slide Image Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning Binary And Sparse Permutation-invariant Representations For Fast And Memory Efficient Whole Slide Image Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning Binary And Sparse Permutation-invariant Representations For Fast And Memory Efficient Whole Slide Image Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Hemati et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Computers in Biology and Medicine</td>
    <td>9</td>
    <td><p>Learning suitable Whole slide images (WSIs) representations for efficient
retrieval systems is a non-trivial task. The WSI embeddings obtained from
current methods are in Euclidean space not ideal for efficient WSI retrieval.
Furthermore, most of the current methods require high GPU memory due to the
simultaneous processing of multiple sets of patches. To address these
challenges, we propose a novel framework for learning binary and sparse WSI
representations utilizing a deep generative modelling and the Fisher Vector. We
introduce new loss functions for learning sparse and binary
permutation-invariant WSI representations that employ instance-based training
achieving better memory efficiency. The learned WSI representations are
validated on The Cancer Genomic Atlas (TCGA) and Liver-Kidney-Stomach (LKS)
datasets. The proposed method outperforms Yottixel (a recent search engine for
histopathology images) both in terms of retrieval accuracy and speed. Further,
we achieve competitive performance against SOTA on the public benchmark LKS
dataset for WSI classification.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Efficiency And Optimization 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/houen2022understanding/">Understanding The Moments Of Tabulation Hashing Via Chaoses</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Understanding The Moments Of Tabulation Hashing Via Chaoses' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Understanding The Moments Of Tabulation Hashing Via Chaoses' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Houen Jakob BÃ¦k Tejs, Thorup Mikkel</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the Twenty-Fourth Annual ACM-SIAM Symposium on Discrete Algorithms</td>
    <td>6</td>
    <td><p>Simple tabulation hashing dates back to Zobrist in 1970 and is defined as
follows: Each key is viewed as \(c\) characters from some alphabet \(\Sigma\), we
have \(c\) fully random hash functions \(h_0, \ldots, h_{c - 1} \colon \Sigma \to
\{0, \ldots, 2^l - 1\}\), and a key \(x = (x_0, \ldots, x_{c - 1})\) is hashed to
\(h(x) = h_0(x_0) \oplus \ldots \oplus h_{c - 1}(x_{c - 1})\) where \(\oplus\) is
the bitwise XOR operation. The previous results on tabulation hashing by P{\v
a}tra{\c s}cu and Thorup~[J.ACMâ€™11] and by Aamand et al.~[STOCâ€™20] focused on
proving Chernoff-style tail bounds on hash-based sums, e.g., the number keys
hashing to a given value, for simple tabulation hashing, but their bounds do
not cover the entire tail.
  Chaoses are random variables of the form \(\sum a_{i_0, \ldots, i_{c - 1}}
X_{i_0} \cdot \ldots \cdot X_{i_{c - 1}}\) where \(X_i\) are independent random
variables. Chaoses are a well-studied concept from probability theory, and
tight analysis has been proven in several instances, e.g., when the independent
random variables are standard Gaussian variables and when the independent
random variables have logarithmically convex tails. We notice that hash-based
sums of simple tabulation hashing can be seen as a sum of chaoses that are not
independent. This motivates us to use techniques from the theory of chaoses to
analyze hash-based sums of simple tabulation hashing.
  In this paper, we obtain bounds for all the moments of hash-based sums for
simple tabulation hashing which are tight up to constants depending only on
\(c\). In contrast with the previous attempts, our approach will mostly be
analytical and does not employ intricate combinatorial arguments. The improved
analysis of simple tabulation hashing allows us to obtain bounds for the
moments of hash-based sums for the mixed tabulation hashing introduced by
Dahlgaard et al.~[FOCSâ€™15].</p>
</td>
    <td>
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/heddes2022hyperdimensional/">Hyperdimensional Hashing: A Robust And Efficient Dynamic Hash Table</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hyperdimensional Hashing: A Robust And Efficient Dynamic Hash Table' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hyperdimensional Hashing: A Robust And Efficient Dynamic Hash Table' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Heddes et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 59th ACM/IEEE Design Automation Conference</td>
    <td>10</td>
    <td><p>Most cloud services and distributed applications rely on hashing algorithms
that allow dynamic scaling of a robust and efficient hash table. Examples
include AWS, Google Cloud and BitTorrent. Consistent and rendezvous hashing are
algorithms that minimize key remapping as the hash table resizes. While memory
errors in large-scale cloud deployments are common, neither algorithm offers
both efficiency and robustness. Hyperdimensional Computing is an emerging
computational model that has inherent efficiency, robustness and is well suited
for vector or hardware acceleration. We propose Hyperdimensional (HD) hashing
and show that it has the efficiency to be deployed in large systems. Moreover,
a realistic level of memory errors causes more than 20% mismatches for
consistent hashing while HD hashing remains unaffected.</p>
</td>
    <td>
      
        Efficiency And Optimization 
      
        Hashing Methods 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/gupta2022medical/">Medical Image Retrieval Via Nearest Neighbor Search On Pre-trained Image Features</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Medical Image Retrieval Via Nearest Neighbor Search On Pre-trained Image Features' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Medical Image Retrieval Via Nearest Neighbor Search On Pre-trained Image Features' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Gupta et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Knowledge-Based Systems</td>
    <td>7</td>
    <td><p>Nearest neighbor search (NNS) aims to locate the points in high-dimensional
space that is closest to the query point. The brute-force approach for finding
the nearest neighbor becomes computationally infeasible when the number of
points is large. The NNS has multiple applications in medicine, such as
searching large medical imaging databases, disease classification, diagnosis,
etc. With a focus on medical imaging, this paper proposes DenseLinkSearch an
effective and efficient algorithm that searches and retrieves the relevant
images from heterogeneous sources of medical images. Towards this, given a
medical database, the proposed algorithm builds the index that consists of
pre-computed links of each point in the database. The search algorithm utilizes
the index to efficiently traverse the database in search of the nearest
neighbor. We extensively tested the proposed NNS approach and compared the
performance with state-of-the-art NNS approaches on benchmark datasets and our
created medical image datasets. The proposed approach outperformed the existing
approach in terms of retrieving accurate neighbors and retrieval speed. We also
explore the role of medical image feature representation in content-based
medical image retrieval tasks. We propose a Transformer-based feature
representation technique that outperformed the existing pre-trained Transformer
approach on CLEF 2011 medical image retrieval task. The source code of our
experiments are available at https://github.com/deepaknlp/DLS.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/yu2022live/">Live Laparoscopic Video Retrieval With Compressed Uncertainty</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Live Laparoscopic Video Retrieval With Compressed Uncertainty' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Live Laparoscopic Video Retrieval With Compressed Uncertainty' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Medical Image Analysis</td>
    <td>5</td>
    <td><p>Searching through large volumes of medical data to retrieve relevant
information is a challenging yet crucial task for clinical care. However the
primitive and most common approach to retrieval, involving text in the form of
keywords, is severely limited when dealing with complex media formats.
Content-based retrieval offers a way to overcome this limitation, by using rich
media as the query itself. Surgical video-to-video retrieval in particular is a
new and largely unexplored research problem with high clinical value,
especially in the real-time case: using real-time video hashing, search can be
achieved directly inside of the operating room. Indeed, the process of hashing
converts large data entries into compact binary arrays or hashes, enabling
large-scale search operations at a very fast rate. However, due to fluctuations
over the course of a video, not all bits in a given hash are equally reliable.
In this work, we propose a method capable of mitigating this uncertainty while
maintaining a light computational footprint. We present superior retrieval
results (3-4 % top 10 mean average precision) on a multi-task evaluation
protocol for surgery, using cholecystectomy phases, bypass phases, and coming
from an entirely new dataset introduced here, critical events across six
different surgery types. Success on this multi-task benchmark shows the
generalizability of our approach for surgical video retrieval.</p>
</td>
    <td>
      
        Large Scale Search 
      
        DATASETS 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/gu2022accelerating/">Accelerating Code Search With Deep Hashing And Code Classification</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Accelerating Code Search With Deep Hashing And Code Classification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Accelerating Code Search With Deep Hashing And Code Classification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Gu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</td>
    <td>9</td>
    <td><p>Code search is to search reusable code snippets from source code corpus based
on natural languages queries. Deep learning-based methods of code search have
shown promising results. However, previous methods focus on retrieval accuracy
but lacked attention to the efficiency of the retrieval process. We propose a
novel method CoSHC to accelerate code search with deep hashing and code
classification, aiming to perform an efficient code search without sacrificing
too much accuracy. To evaluate the effectiveness of CoSHC, we apply our method
to five code search models. Extensive experimental results indicate that
compared with previous code search baselines, CoSHC can save more than 90% of
retrieval time meanwhile preserving at least 99% of retrieval accuracy.</p>
</td>
    <td>
      
        Efficiency And Optimization 
      
        ACL 
      
        Neural Hashing 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/wald2022gpu/">Gpu-friendly, Parallel, And (almost-)in-place Construction Of Left-balanced K-d Trees</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Gpu-friendly, Parallel, And (almost-)in-place Construction Of Left-balanced K-d Trees' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Gpu-friendly, Parallel, And (almost-)in-place Construction Of Left-balanced K-d Trees' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wald Ingo</td> <!-- ðŸ”§ You were missing this -->
    <td>Concurrency and Computation: Practice and Experience</td>
    <td>18</td>
    <td><p>We present an algorithm that allows for building left-balanced and complete
k-d trees over k-dimensional points in a trivially parallel and GPU friendly
way. Our algorithm requires exactly one int per data point as temporary
storage, and uses O(log N) iterations, each of which performs one parallel
sort, and one trivially parallel CUDA per-node update kernel.</p>
</td>
    <td>
      
        Tree Based ANN 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/ghaemmaghami2022learning/">Learning To Collide: Recommendation System Model Compression With Learned Hash Functions</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning To Collide: Recommendation System Model Compression With Learned Hash Functions' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning To Collide: Recommendation System Model Compression With Learned Hash Functions' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ghaemmaghami et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the VLDB Endowment</td>
    <td>6</td>
    <td><p>A key characteristic of deep recommendation models is the immense memory
requirements of their embedding tables. These embedding tables can often reach
hundreds of gigabytes which increases hardware requirements and training cost.
A common technique to reduce model size is to hash all of the categorical
variable identifiers (ids) into a smaller space. This hashing reduces the
number of unique representations that must be stored in the embedding table;
thus decreasing its size. However, this approach introduces collisions between
semantically dissimilar ids that degrade model quality. We introduce an
alternative approach, Learned Hash Functions, which instead learns a new
mapping function that encourages collisions between semantically similar ids.
We derive this learned mapping from historical data and embedding access
patterns. We experiment with this technique on a production model and find that
a mapping informed by the combination of access frequency and a learned low
dimension embedding is the most effective. We demonstrate a small improvement
relative to the hashing trick and other collision related compression
techniques. This is ongoing work that explores the impact of categorical id
collisions on recommendation model quality and how those collisions may be
controlled to improve model performance.</p>
</td>
    <td>
      
        Alt 
      
        Hashing Methods 
      
        Evaluation 
      
        Recommender Systems 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/gao2022long/">Long-tail Cross Modal Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Long-tail Cross Modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Long-tail Cross Modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Gao et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>5</td>
    <td><p>Existing Cross Modal Hashing (CMH) methods are mainly designed for balanced
data, while imbalanced data with long-tail distribution is more general in
real-world. Several long-tail hashing methods have been proposed but they can
not adapt for multi-modal data, due to the complex interplay between labels and
individuality and commonality information of multi-modal data. Furthermore, CMH
methods mostly mine the commonality of multi-modal data to learn hash codes,
which may override tail labels encoded by the individuality of respective
modalities. In this paper, we propose LtCMH (Long-tail CMH) to handle
imbalanced multi-modal data. LtCMH firstly adopts auto-encoders to mine the
individuality and commonality of different modalities by minimizing the
dependency between the individuality of respective modalities and by enhancing
the commonality of these modalities. Then it dynamically combines the
individuality and commonality with direct features extracted from respective
modalities to create meta features that enrich the representation of tail
labels, and binaries meta features to generate hash codes. LtCMH significantly
outperforms state-of-the-art baselines on long-tail datasets and holds a better
(or comparable) performance on datasets with balanced labels.</p>
</td>
    <td>
      
        AAAI 
      
        DATASETS 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/fernandez2022active/">Active Image Indexing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Active Image Indexing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Active Image Indexing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Fernandez et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Journal of Geophysical Research: Atmospheres</td>
    <td>142</td>
    <td><p>Image copy detection and retrieval from large databases leverage two
components. First, a neural network maps an image to a vector representation,
that is relatively robust to various transformations of the image. Second, an
efficient but approximate similarity search algorithm trades scalability (size
and speed) against quality of the search, thereby introducing a source of
error. This paper improves the robustness of image copy detection with active
indexing, that optimizes the interplay of these two components. We reduce the
quantization loss of a given image representation by making imperceptible
changes to the image before its release. The loss is back-propagated through
the deep neural network back to the image, under perceptual constraints. These
modifications make the image more retrievable. Our experiments show that the
retrieval and copy detection of activated images is significantly improved. For
instance, activation improves by \(+40%\) the Recall1@1 on various image
transformations, and for several popular indexing structures based on product
quantization and locality sensitivity hashing.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Similarity Search 
      
        Quantization 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/filtser2022labeled/">Labeled Nearest Neighbor Search And Metric Spanners Via Locality Sensitive Orderings</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Labeled Nearest Neighbor Search And Metric Spanners Via Locality Sensitive Orderings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Labeled Nearest Neighbor Search And Metric Spanners Via Locality Sensitive Orderings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Filtser Arnold</td> <!-- ðŸ”§ You were missing this -->
    <td>International Journal of Fuzzy Logic and Intelligent Systems</td>
    <td>13</td>
    <td><p>Chan, Har-Peled, and Jones [SICOMP 2020] developed locality-sensitive
orderings (LSO) for Euclidean space. A \((\tau,\rho)\)-LSO is a collection
\(\Sigma\) of orderings such that for every \(x,y\in\mathbb{R}^d\) there is an
ordering \(\sigma\in\Sigma\), where all the points between \(x\) and \(y\) w.r.t.
\(\sigma\) are in the \(\rho\)-neighborhood of either \(x\) or \(y\). In essence, LSO
allow one to reduce problems to the \(1\)-dimensional line. Later, Filtser and Le
[STOC 2022] developed LSOâ€™s for doubling metrics, general metric spaces, and
minor free graphs. For Euclidean and doubling spaces, the number of orderings
in the LSO is exponential in the dimension, which made them mainly useful for
the low dimensional regime. In this paper, we develop new LSOâ€™s for Euclidean,
\(\ell_p\), and doubling spaces that allow us to trade larger stretch for a much
smaller number of orderings. We then use our new LSOâ€™s (as well as the previous
ones) to construct path reporting low hop spanners, fault tolerant spanners,
reliable spanners, and light spanners for different metric spaces. While many
nearest neighbor search (NNS) data structures were constructed for metric
spaces with implicit distance representations (where the distance between two
metric points can be computed using their names, e.g. Euclidean space), for
other spaces almost nothing is known. In this paper we initiate the study of
the labeled NNS problem, where one is allowed to artificially assign labels
(short names) to metric points. We use LSOâ€™s to construct efficient labeled NNS
data structures in this model.</p>
</td>
    <td>
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/fahim2022unsupervised/">Unsupervised Space Partitioning For Nearest Neighbor Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Unsupervised Space Partitioning For Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Unsupervised Space Partitioning For Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Fahim Abrar, Ali Mohammed Eunus, Cheema Muhammad Aamir</td> <!-- ðŸ”§ You were missing this -->
    <td>2021 11th Workshop on Hyperspectral Imaging and Signal Processing: Evolution in Remote Sensing (WHISPERS)</td>
    <td>8</td>
    <td><p>Approximate Nearest Neighbor Search (ANNS) in high dimensional spaces is
crucial for many real-life applications (e.g., e-commerce, web, multimedia,
etc.) dealing with an abundance of data. This paper proposes an end-to-end
learning framework that couples the partitioning (one critical step of ANNS)
and learning-to-search steps using a custom loss function. A key advantage of
our proposed solution is that it does not require any expensive pre-processing
of the dataset, which is one of the critical limitations of the
state-of-the-art approach. We achieve the above edge by formulating a
multi-objective custom loss function that does not need ground truth labels to
quantify the quality of a given data-space partition, making it entirely
unsupervised. We also propose an ensembling technique by adding varying input
weights to the loss function to train an ensemble of models to enhance the
search quality. On several standard benchmarks for ANNS, we show that our
method beats the state-of-the-art space partitioning method and the ubiquitous
K-means clustering method while using fewer parameters and shorter offline
training times. We also show that incorporating our space-partitioning strategy
into state-of-the-art ANNS techniques such as ScaNN can improve their
performance significantly. Finally, we present our unsupervised partitioning
approach as a promising alternative to many widely used clustering methods,
such as K-means clustering and DBSCAN.</p>
</td>
    <td>
      
        Alt 
      
        Tools & Libraries 
      
        Evaluation 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/ermolov2022hyperbolic/">Hyperbolic Vision Transformers: Combining Improvements In Metric Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hyperbolic Vision Transformers: Combining Improvements In Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hyperbolic Vision Transformers: Combining Improvements In Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ermolov et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>61</td>
    <td><p>Metric learning aims to learn a highly discriminative model encouraging the
embeddings of similar classes to be close in the chosen metrics and pushed
apart for dissimilar ones. The common recipe is to use an encoder to extract
embeddings and a distance-based loss function to match the representations â€“
usually, the Euclidean distance is utilized. An emerging interest in learning
hyperbolic data embeddings suggests that hyperbolic geometry can be beneficial
for natural data. Following this line of work, we propose a new
hyperbolic-based model for metric learning. At the core of our method is a
vision transformer with output embeddings mapped to hyperbolic space. These
embeddings are directly optimized using modified pairwise cross-entropy loss.
We evaluate the proposed model with six different formulations on four datasets
achieving the new state-of-the-art performance. The source code is available at
https://github.com/htdt/hyp_metric.</p>
</td>
    <td>
      
        CVPR 
      
        DATASETS 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/elezi2022group/">The Group Loss++: A Deeper Look Into Group Loss For Deep Metric Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=The Group Loss++: A Deeper Look Into Group Loss For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=The Group Loss++: A Deeper Look Into Group Loss For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Elezi et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Pattern Analysis and Machine Intelligence</td>
    <td>13</td>
    <td><p>Deep metric learning has yielded impressive results in tasks such as
clustering and image retrieval by leveraging neural networks to obtain highly
discriminative feature embeddings, which can be used to group samples into
different classes. Much research has been devoted to the design of smart loss
functions or data mining strategies for training such networks. Most methods
consider only pairs or triplets of samples within a mini-batch to compute the
loss function, which is commonly based on the distance between embeddings. We
propose Group Loss, a loss function based on a differentiable label-propagation
method that enforces embedding similarity across all samples of a group while
promoting, at the same time, low-density regions amongst data points belonging
to different groups. Guided by the smoothness assumption that â€œsimilar objects
should belong to the same groupâ€, the proposed loss trains the neural network
for a classification task, enforcing a consistent labelling amongst samples
within a class. We design a set of inference strategies tailored towards our
algorithm, named Group Loss++ that further improve the results of our model. We
show state-of-the-art results on clustering and image retrieval on four
retrieval datasets, and present competitive results on two person
re-identification datasets, providing a unified framework for retrieval and
re-identification.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Tools & Libraries 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/gong2022vit2hash/">Vit2hash: Unsupervised Information-preserving Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Vit2hash: Unsupervised Information-preserving Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Vit2hash: Unsupervised Information-preserving Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Gong et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 24th ACM international conference on Multimedia</td>
    <td>10</td>
    <td><p>Unsupervised image hashing, which maps images into binary codes without
supervision, is a compressor with a high compression rate. Hence, how to
preserving meaningful information of the original data is a critical problem.
Inspired by the large-scale vision pre-training model, known as ViT, which has
shown significant progress for learning visual representations, in this paper,
we propose a simple information-preserving compressor to finetune the ViT model
for the target unsupervised hashing task. Specifically, from pixels to
continuous features, we first propose a feature-preserving module, using the
corrupted image as input to reconstruct the original feature from the
pre-trained ViT model and the complete image, so that the feature extractor can
focus on preserving the meaningful information of original data. Secondly, from
continuous features to hash codes, we propose a hashing-preserving module,
which aims to keep the semantic information from the pre-trained ViT model by
using the proposed Kullback-Leibler divergence loss. Besides, the quantization
loss and the similarity loss are added to minimize the quantization error. Our
method is very simple and achieves a significantly higher degree of MAP on
three benchmark image datasets.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/doan2022coophash/">Coophash: Cooperative Learning Of Multipurpose Descriptor And Contrastive Pair Generator Via Variational MCMC Teaching For Supervised Image Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Coophash: Cooperative Learning Of Multipurpose Descriptor And Contrastive Pair Generator Via Variational MCMC Teaching For Supervised Image Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Coophash: Cooperative Learning Of Multipurpose Descriptor And Contrastive Pair Generator Via Variational MCMC Teaching For Supervised Image Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Doan et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>397</td>
    <td><p>Leveraging supervised information can lead to superior retrieval performance
in the image hashing domain but the performance degrades significantly without
enough labeled data. One effective solution to boost performance is to employ
generative models, such as Generative Adversarial Networks (GANs), to generate
synthetic data in an image hashing model. However, GAN-based methods are
difficult to train, which prevents the hashing approaches from jointly training
the generative models and the hash functions. This limitation results in
sub-optimal retrieval performance. To overcome this limitation, we propose a
novel framework, the generative cooperative hashing network, which is based on
energy-based cooperative learning. This framework jointly learns a powerful
generative representation of the data and a robust hash function via two
components: a top-down contrastive pair generator that synthesizes contrastive
images and a bottom-up multipurpose descriptor that simultaneously represents
the images from multiple perspectives, including probability density, hash
code, latent code, and category. The two components are jointly learned via a
novel likelihood-based cooperative learning scheme. We conduct experiments on
several real-world datasets and show that the proposed method outperforms the
competing hashing supervised methods, achieving up to 10% relative improvement
over the current state-of-the-art supervised hashing methods, and exhibits a
significantly better performance in out-of-distribution retrieval.</p>
</td>
    <td>
      
        Image Retrieval 
      
        AAAI 
      
        DATASETS 
      
        Hashing Methods 
      
        Tools & Libraries 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/doan2022one/">One Loss For Quantization: Deep Hashing With Discrete Wasserstein Distributional Matching</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=One Loss For Quantization: Deep Hashing With Discrete Wasserstein Distributional Matching' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=One Loss For Quantization: Deep Hashing With Discrete Wasserstein Distributional Matching' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Doan Khoa D., Yang Peng, Li Ping</td> <!-- ðŸ”§ You were missing this -->
    <td>2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>37</td>
    <td><p>Image hashing is a principled approximate nearest neighbor approach to find
similar items to a query in a large collection of images. Hashing aims to learn
a binary-output function that maps an image to a binary vector. For optimal
retrieval performance, producing balanced hash codes with low-quantization
error to bridge the gap between the learning stageâ€™s continuous relaxation and
the inference stageâ€™s discrete quantization is important. However, in the
existing deep supervised hashing methods, coding balance and low-quantization
error are difficult to achieve and involve several losses. We argue that this
is because the existing quantization approaches in these methods are
heuristically constructed and not effective to achieve these objectives. This
paper considers an alternative approach to learning the quantization
constraints. The task of learning balanced codes with low quantization error is
re-formulated as matching the learned distribution of the continuous codes to a
pre-defined discrete, uniform distribution. This is equivalent to minimizing
the distance between two distributions. We then propose a computationally
efficient distributional distance by leveraging the discrete property of the
hash functions. This distributional distance is a valid distance and enjoys
lower time and sample complexities. The proposed single-loss quantization
objective can be integrated into any existing supervised hashing method to
improve code balance and quantization error. Experiments confirm that the
proposed approach substantially improves the performance of several
representative hashing~methods.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        CVPR 
      
        Alt 
      
        Neural Hashing 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/chen2022learning/">Learning Binarized Graph Representations With Multi-faceted Quantization Reinforcement For Top-k Recommendation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning Binarized Graph Representations With Multi-faceted Quantization Reinforcement For Top-k Recommendation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning Binarized Graph Representations With Multi-faceted Quantization Reinforcement For Top-k Recommendation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Chen et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</td>
    <td>24</td>
    <td><p>Learning vectorized embeddings is at the core of various recommender systems
for user-item matching. To perform efficient online inference, representation
quantization, aiming to embed the latent features by a compact sequence of
discrete numbers, recently shows the promising potentiality in optimizing both
memory and computation overheads. However, existing work merely focuses on
numerical quantization whilst ignoring the concomitant information loss issue,
which, consequently, leads to conspicuous performance degradation. In this
paper, we propose a novel quantization framework to learn Binarized Graph
Representations for Top-K Recommendation (BiGeaR). BiGeaR introduces
multi-faceted quantization reinforcement at the pre-, mid-, and post-stage of
binarized representation learning, which substantially retains the
representation informativeness against embedding binarization. In addition to
saving the memory footprint, BiGeaR further develops solid online inference
acceleration with bitwise operations, providing alternative flexibility for the
realistic deployment. The empirical results over five large real-world
benchmarks show that BiGeaR achieves about 22%~40% performance improvement over
the state-of-the-art quantization-based recommender system, and recovers about
95%~102% of the performance capability of the best full-precision counterpart
with over 8x time and space reduction.</p>
</td>
    <td>
      
        KDD 
      
        Efficiency And Optimization 
      
        Recommender Systems 
      
        Alt 
      
        Quantization 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/chen2022finger/">FINGER: Fast Inference For Graph-based Approximate Nearest Neighbor Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=FINGER: Fast Inference For Graph-based Approximate Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=FINGER: Fast Inference For Graph-based Approximate Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Chen et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the ACM Web Conference 2023</td>
    <td>10</td>
    <td><p>Approximate K-Nearest Neighbor Search (AKNNS) has now become ubiquitous in
modern applications, for example, as a fast search procedure with two tower
deep learning models. Graph-based methods for AKNNS in particular have received
great attention due to their superior performance. These methods rely on greedy
graph search to traverse the data points as embedding vectors in a database.
Under this greedy search scheme, we make a key observation: many distance
computations do not influence search updates so these computations can be
approximated without hurting performance. As a result, we propose FINGER, a
fast inference method to achieve efficient graph search. FINGER approximates
the distance function by estimating angles between neighboring residual vectors
with low-rank bases and distribution matching. The approximated distance can be
used to bypass unnecessary computations, which leads to faster searches.
Empirically, accelerating a popular graph-based method named HNSW by FINGER is
shown to outperform existing graph-based methods by 20%-60% across different
benchmark datasets.</p>
</td>
    <td>
      
        Graph Based ANN 
      
        DATASETS 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/chen2022approximate/">Approximate Nearest Neighbor Search Under Neural Similarity Metric For Large-scale Recommendation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Approximate Nearest Neighbor Search Under Neural Similarity Metric For Large-scale Recommendation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Approximate Nearest Neighbor Search Under Neural Similarity Metric For Large-scale Recommendation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Chen et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management</td>
    <td>12</td>
    <td><p>Model-based methods for recommender systems have been studied extensively for
years. Modern recommender systems usually resort to 1) representation learning
models which define user-item preference as the distance between their
embedding representations, and 2) embedding-based Approximate Nearest Neighbor
(ANN) search to tackle the efficiency problem introduced by large-scale corpus.
While providing efficient retrieval, the embedding-based retrieval pattern also
limits the model capacity since the form of user-item preference measure is
restricted to the distance between their embedding representations. However,
for other more precise user-item preference measures, e.g., preference scores
directly derived from a deep neural network, they are computationally
intractable because of the lack of an efficient retrieval method, and an
exhaustive search for all user-item pairs is impractical. In this paper, we
propose a novel method to extend ANN search to arbitrary matching functions,
e.g., a deep neural network. Our main idea is to perform a greedy walk with a
matching function in a similarity graph constructed from all items. To solve
the problem that the similarity measures of graph construction and user-item
matching function are heterogeneous, we propose a pluggable adversarial
training task to ensure the graph search with arbitrary matching function can
achieve fairly high precision. Experimental results in both open source and
industry datasets demonstrate the effectiveness of our method. The proposed
method has been fully deployed in the Taobao display advertising platform and
brings a considerable advertising revenue increase. We also summarize our
detailed experiences in deployment in this paper.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        Robustness 
      
        Recommender Systems 
      
        Efficiency And Optimization 
      
        Distance Metric Learning 
      
        Graph Based ANN 
      
        CIKM 
      
        Similarity Search 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/cao2022context/">Context Recovery And Knowledge Retrieval: A Novel Two-stream Framework For Video Anomaly Detection</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Context Recovery And Knowledge Retrieval: A Novel Two-stream Framework For Video Anomaly Detection' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Context Recovery And Knowledge Retrieval: A Novel Two-stream Framework For Video Anomaly Detection' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Cao Congqi, Lu Yue, Zhang Yanning</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Image Processing</td>
    <td>14</td>
    <td><p>Video anomaly detection aims to find the events in a video that do not
conform to the expected behavior. The prevalent methods mainly detect anomalies
by snippet reconstruction or future frame prediction error. However, the error
is highly dependent on the local context of the current snippet and lacks the
understanding of normality. To address this issue, we propose to detect
anomalous events not only by the local context, but also according to the
consistency between the testing event and the knowledge about normality from
the training data. Concretely, we propose a novel two-stream framework based on
context recovery and knowledge retrieval, where the two streams can complement
each other. For the context recovery stream, we propose a spatiotemporal U-Net
which can fully utilize the motion information to predict the future frame.
Furthermore, we propose a maximum local error mechanism to alleviate the
problem of large recovery errors caused by complex foreground objects. For the
knowledge retrieval stream, we propose an improved learnable locality-sensitive
hashing, which optimizes hash functions via a Siamese network and a mutual
difference loss. The knowledge about normality is encoded and stored in hash
tables, and the distance between the testing event and the knowledge
representation is used to reveal the probability of anomaly. Finally, we fuse
the anomaly scores from the two streams to detect anomalies. Extensive
experiments demonstrate the effectiveness and complementarity of the two
streams, whereby the proposed two-stream framework achieves state-of-the-art
performance on four datasets.</p>
</td>
    <td>
      
        DATASETS 
      
        Tools & Libraries 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/amsaleg2022intrinsic/">Intrinsic Dimensionality Estimation Within Tight Localities: A Theoretical And Experimental Analysis</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Intrinsic Dimensionality Estimation Within Tight Localities: A Theoretical And Experimental Analysis' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Intrinsic Dimensionality Estimation Within Tight Localities: A Theoretical And Experimental Analysis' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Amsaleg et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 2019 SIAM International Conference on Data Mining</td>
    <td>30</td>
    <td><p>Accurate estimation of Intrinsic Dimensionality (ID) is of crucial importance
in many data mining and machine learning tasks, including dimensionality
reduction, outlier detection, similarity search and subspace clustering.
However, since their convergence generally requires sample sizes (that is,
neighborhood sizes) on the order of hundreds of points, existing ID estimation
methods may have only limited usefulness for applications in which the data
consists of many natural groups of small size. In this paper, we propose a
local ID estimation strategy stable even for `tightâ€™ localities consisting of
as few as 20 sample points. The estimator applies MLE techniques over all
available pairwise distances among the members of the sample, based on a recent
extreme-value-theoretic model of intrinsic dimensionality, the Local Intrinsic
Dimension (LID). Our experimental results show that our proposed estimation
technique can achieve notably smaller variance, while maintaining comparable
levels of bias, at much smaller sample sizes than state-of-the-art estimators.</p>
</td>
    <td>
      
        Similarity Search 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/adir2022privacy/">Privacy-preserving Record Linkage Using Local Sensitive Hash And Private Set Intersection</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Privacy-preserving Record Linkage Using Local Sensitive Hash And Private Set Intersection' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Privacy-preserving Record Linkage Using Local Sensitive Hash And Private Set Intersection' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Adir et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>5</td>
    <td><p>The amount of data stored in data repositories increases every year. This
makes it challenging to link records between different datasets across
companies and even internally, while adhering to privacy regulations. Address
or name changes, and even different spelling used for entity data, can prevent
companies from using private deduplication or record-linking solutions such as
private set intersection (PSI). To this end, we propose a new and efficient
privacy-preserving record linkage (PPRL) protocol that combines PSI and local
sensitive hash (LSH) functions, and runs in linear time. We explain the privacy
guarantees that our protocol provides and demonstrate its practicality by
executing the protocol over two datasets with \(2^{20}\) records each, in \(11-45\)
minutes, depending on network settings.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/aksoy2022satellite/">Satellite Image Search In Agoraeo</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Satellite Image Search In Agoraeo' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Satellite Image Search In Agoraeo' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Aksoy et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the VLDB Endowment</td>
    <td>8</td>
    <td><p>The growing operational capability of global Earth Observation (EO) creates
new opportunities for data-driven approaches to understand and protect our
planet. However, the current use of EO archives is very restricted due to the
huge archive sizes and the limited exploration capabilities provided by EO
platforms. To address this limitation, we have recently proposed MiLaN, a
content-based image retrieval approach for fast similarity search in satellite
image archives. MiLaN is a deep hashing network based on metric learning that
encodes high-dimensional image features into compact binary hash codes. We use
these codes as keys in a hash table to enable real-time nearest neighbor search
and highly accurate retrieval. In this demonstration, we showcase the
efficiency of MiLaN by integrating it with EarthQube, a browser and search
engine within AgoraEO. EarthQube supports interactive visual exploration and
Query-by-Example over satellite image repositories. Demo visitors will interact
with EarthQube playing the role of different users that search images in a
large-scale remote sensing archive by their semantic content and apply other
filters.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Distance Metric Learning 
      
        Neural Hashing 
      
        Similarity Search 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/shi2022learning/">Learning Similarity Preserving Binary Codes For Recommender Systems</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning Similarity Preserving Binary Codes For Recommender Systems' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning Similarity Preserving Binary Codes For Recommender Systems' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Shi Yang, Chung Young-joo</td> <!-- ðŸ”§ You were missing this -->
    <td>ACM Transactions on Multimedia Computing, Communications, and Applications</td>
    <td>19</td>
    <td><p>Hashing-based Recommender Systems (RSs) are widely studied to provide
scalable services. The existing methods for the systems combine three modules
to achieve efficiency: feature extraction, interaction modeling, and
binarization. In this paper, we study an unexplored module combination for the
hashing-based recommender systems, namely Compact Cross-Similarity Recommender
(CCSR). Inspired by cross-modal retrieval, CCSR utilizes Maximum a Posteriori
similarity instead of matrix factorization and rating reconstruction to model
interactions between users and items. We conducted experiments on MovieLens1M,
Amazon product review, Ichiba purchase dataset and confirmed CCSR outperformed
the existing matrix factorization-based methods. On the Movielens1M dataset,
the absolute performance improvements are up to 15.69% in NDCG and 4.29% in
Recall. In addition, we extensively studied three binarization modules: \(sign\),
scaled tanh, and sign-scaled tanh. The result demonstrated that although
differentiable scaled tanh is popular in recent discrete feature learning
literature, a huge performance drop occurs when outputs of scaled \(tanh\) are
forced to be binary.</p>
</td>
    <td>
      
        Survey Paper 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Alt 
      
        Recommender Systems 
      
        Multimodal Retrieval 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/shi2022information/">Information-theoretic Hashing For Zero-shot Cross-modal Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Information-theoretic Hashing For Zero-shot Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Information-theoretic Hashing For Zero-shot Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Shi et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE International Conference on Data Mining (ICDM)</td>
    <td>11</td>
    <td><p>Zero-shot cross-modal retrieval (ZS-CMR) deals with the retrieval problem
among heterogenous data from unseen classes. Typically, to guarantee
generalization, the pre-defined class embeddings from natural language
processing (NLP) models are used to build a common space. In this paper,
instead of using an extra NLP model to define a common space beforehand, we
consider a totally different way to construct (or learn) a common hamming space
from an information-theoretic perspective. We term our model the
Information-Theoretic Hashing (ITH), which is composed of two cascading
modules: an Adaptive Information Aggregation (AIA) module; and a Semantic
Preserving Encoding (SPE) module. Specifically, our AIA module takes the
inspiration from the Principle of Relevant Information (PRI) to construct a
common space that adaptively aggregates the intrinsic semantics of different
modalities of data and filters out redundant or irrelevant information. On the
other hand, our SPE module further generates the hashing codes of different
modalities by preserving the similarity of intrinsic semantics with the
element-wise Kullback-Leibler (KL) divergence. A total correlation
regularization term is also imposed to reduce the redundancy amongst different
dimensions of hash codes. Sufficient experiments on three benchmark datasets
demonstrate the superiority of the proposed ITH in ZS-CMR. Source code is
available in the supplementary material.</p>
</td>
    <td>
      
        Multimodal Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/su2022global/">Global Learnable Attention For Single Image Super-resolution</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Global Learnable Attention For Single Image Super-resolution' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Global Learnable Attention For Single Image Super-resolution' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Su et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Pattern Analysis and Machine Intelligence</td>
    <td>33</td>
    <td><p>Self-similarity is valuable to the exploration of non-local textures in
single image super-resolution (SISR). Researchers usually assume that the
importance of non-local textures is positively related to their similarity
scores. In this paper, we surprisingly found that when repairing severely
damaged query textures, some non-local textures with low-similarity which are
closer to the target can provide more accurate and richer details than the
high-similarity ones. In these cases, low-similarity does not mean inferior but
is usually caused by different scales or orientations. Utilizing this finding,
we proposed a Global Learnable Attention (GLA) to adaptively modify similarity
scores of non-local textures during training instead of only using a fixed
similarity scoring function such as the dot product. The proposed GLA can
explore non-local textures with low-similarity but more accurate details to
repair severely damaged textures. Furthermore, we propose to adopt Super-Bit
Locality-Sensitive Hashing (SB-LSH) as a preprocessing method for our GLA. With
the SB-LSH, the computational complexity of our GLA is reduced from quadratic
to asymptotic linear with respect to the image size. In addition, the proposed
GLA can be integrated into existing deep SISR models as an efficient general
building block. Based on the GLA, we constructed a Deep Learnable Similarity
Network (DLSN), which achieves state-of-the-art performance for SISR tasks of
different degradation types (e.g. blur and noise). Our code and a pre-trained
DLSN have been uploaded to GitHub{\dag} for validation.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/song2022asymmetric/">Asymmetric Hash Code Learning For Remote Sensing Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Asymmetric Hash Code Learning For Remote Sensing Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Asymmetric Hash Code Learning For Remote Sensing Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Song et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Geoscience and Remote Sensing</td>
    <td>44</td>
    <td><p>Remote sensing image retrieval (RSIR), aiming at searching for a set of
similar items to a given query image, is a very important task in remote
sensing applications. Deep hashing learning as the current mainstream method
has achieved satisfactory retrieval performance. On one hand, various deep
neural networks are used to extract semantic features of remote sensing images.
On the other hand, the hashing techniques are subsequently adopted to map the
high-dimensional deep features to the low-dimensional binary codes. This kind
of methods attempts to learn one hash function for both the query and database
samples in a symmetric way. However, with the number of database samples
increasing, it is typically time-consuming to generate the hash codes of
large-scale database images. In this paper, we propose a novel deep hashing
method, named asymmetric hash code learning (AHCL), for RSIR. The proposed AHCL
generates the hash codes of query and database images in an asymmetric way. In
more detail, the hash codes of query images are obtained by binarizing the
output of the network, while the hash codes of database images are directly
learned by solving the designed objective function. In addition, we combine the
semantic information of each image and the similarity information of pairs of
images as supervised information to train a deep hashing network, which
improves the representation ability of deep features and hash codes. The
experimental results on three public datasets demonstrate that the proposed
method outperforms symmetric methods in terms of retrieval accuracy and
efficiency. The source code is available at
https://github.com/weiweisong415/Demo AHCL for TGRS2022.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Neural Hashing 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/zhu2022lower/">A Lower Bound Of Hash Codes' Performance</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Lower Bound Of Hash Codes' Performance' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Lower Bound Of Hash Codes' Performance' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of IEEE International Symposium on Information Theory</td>
    <td>9</td>
    <td><p>As a crucial approach for compact representation learning, hashing has
achieved great success in effectiveness and efficiency. Numerous heuristic
Hamming space metric learning objectives are designed to obtain high-quality
hash codes. Nevertheless, a theoretical analysis of criteria for learning good
hash codes remains largely unexploited. In this paper, we prove that
inter-class distinctiveness and intra-class compactness among hash codes
determine the lower bound of hash codesâ€™ performance. Promoting these two
characteristics could lift the bound and improve hash learning. We then propose
a surrogate model to fully exploit the above objective by estimating the
posterior of hash codes and controlling it, which results in a low-bias
optimization. Extensive experiments reveal the effectiveness of the proposed
method. By testing on a series of hash-models, we obtain performance
improvements among all of them, with an up to \(26.5%\) increase in mean Average
Precision and an up to \(20.5%\) increase in accuracy. Our code is publicly
available at https://github.com/VL-Group/LBHash.</p>
</td>
    <td>
      
        Distance Metric Learning 
      
        Hashing Methods 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/zhao2022constrained/">Constrained Approximate Similarity Search On Proximity Graph</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Constrained Approximate Similarity Search On Proximity Graph' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Constrained Approximate Similarity Search On Proximity Graph' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhao Weijie, Tan Shulong, Li Ping</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</td>
    <td>19</td>
    <td><p>Search engines and recommendation systems are built to efficiently display
relevant information from those massive amounts of candidates. Typically a
three-stage mechanism is employed in those systems: (i) a small collection of
items are first retrieved by (e.g.,) approximate near neighbor search
algorithms; (ii) then a collection of constraints are applied on the retrieved
items; (iii) a fine-grained ranking neural network is employed to determine the
final recommendation. We observe a major defect of the original three-stage
pipeline: Although we only target to retrieve \(k\) vectors in the final
recommendation, we have to preset a sufficiently large \(s\) (\(s &gt; k\)) for each
query, and ``hopeâ€™â€™ the number of survived vectors after the filtering is not
smaller than \(k\). That is, at least \(k\) vectors in the \(s\) similar candidates
satisfy the query constraints.
  In this paper, we investigate this constrained similarity search problem and
attempt to merge the similarity search stage and the filtering stage into one
single search operation. We introduce AIRSHIP, a system that integrates a
user-defined function filtering into the similarity search framework. The
proposed system does not need to build extra indices nor require prior
knowledge of the query constraints. We propose three optimization strategies:
(1) starting point selection, (2) multi-direction search, and (3) biased
priority queue selection. Experimental evaluations on both synthetic and real
data confirm the effectiveness of the proposed AIRSHIP algorithm. We focus on
constrained graph-based approximate near neighbor (ANN) search in this study,
in part because graph-based ANN is known to achieve excellent performance. We
believe it is also possible to develop constrained hashing-based ANN or
constrained quantization-based ANN.</p>
</td>
    <td>
      
        KDD 
      
        Hashing Methods 
      
        Graph Based ANN 
      
        Alt 
      
        Recommender Systems 
      
        Similarity Search 
      
        Quantization 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/yu2022learning/">Learning To Hash Naturally Sorts</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning To Hash Naturally Sorts' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning To Hash Naturally Sorts' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence</td>
    <td>11</td>
    <td><p>Learning to hash pictures a list-wise sorting problem. Its testing metrics,
e.g., mean-average precision, count on a sorted candidate list ordered by
pair-wise code similarity. However, scarcely does one train a deep hashing
model with the sorted results end-to-end because of the non-differentiable
nature of the sorting operation. This inconsistency in the objectives of
training and test may lead to sub-optimal performance since the training loss
often fails to reflect the actual retrieval metric. In this paper, we tackle
this problem by introducing Naturally-Sorted Hashing (NSH). We sort the Hamming
distances of samplesâ€™ hash codes and accordingly gather their latent
representations for self-supervised training. Thanks to the recent advances in
differentiable sorting approximations, the hash head receives gradients from
the sorter so that the hash encoder can be optimized along with the training
procedure. Additionally, we describe a novel Sorted Noise-Contrastive
Estimation (SortedNCE) loss that selectively picks positive and negative
samples for contrastive learning, which allows NSH to mine data semantic
relations during training in an unsupervised manner. Our extensive experiments
show the proposed NSH model significantly outperforms the existing unsupervised
hashing methods on three benchmarked datasets.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        IJCAI 
      
        Neural Hashing 
      
        Hashing Methods 
      
        AAAI 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/shen2022semicon/">SEMICON: A Learning-to-hash Solution For Large-scale Fine-grained Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=SEMICON: A Learning-to-hash Solution For Large-scale Fine-grained Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=SEMICON: A Learning-to-hash Solution For Large-scale Fine-grained Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Shen et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>12</td>
    <td><p>In this paper, we propose Suppression-Enhancing Mask based attention and
Interactive Channel transformatiON (SEMICON) to learn binary hash codes for
dealing with large-scale fine-grained image retrieval tasks. In SEMICON, we
first develop a suppression-enhancing mask (SEM) based attention to dynamically
localize discriminative image regions. More importantly, different from
existing attention mechanism simply erasing previous discriminative regions,
our SEM is developed to restrain such regions and then discover other
complementary regions by considering the relation between activated regions in
a stage-by-stage fashion. In each stage, the interactive channel transformation
(ICON) module is afterwards designed to exploit correlations across channels of
attended activation tensors. Since channels could generally correspond to the
parts of fine-grained objects, the part correlation can be also modeled
accordingly, which further improves fine-grained retrieval accuracy. Moreover,
to be computational economy, ICON is realized by an efficient two-step process.
Finally, the hash learning of our SEMICON consists of both global- and
local-level branches for better representing fine-grained objects and then
generating binary hash codes explicitly corresponding to multiple levels.
Experiments on five benchmark fine-grained datasets show our superiority over
competing methods.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/shao2022johnson/">Johnson-lindenstrauss Embeddings For Noisy Vectors -- Taking Advantage Of The Noise</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Johnson-lindenstrauss Embeddings For Noisy Vectors -- Taking Advantage Of The Noise' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Johnson-lindenstrauss Embeddings For Noisy Vectors -- Taking Advantage Of The Noise' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Shao Zhen</td> <!-- ðŸ”§ You were missing this -->
    <td>SIAM Journal on Matrix Analysis and Applications</td>
    <td>7</td>
    <td><p>This paper investigates theoretical properties of subsampling and hashing as
tools for approximate Euclidean norm-preserving embeddings for vectors with
(unknown) additive Gaussian noises. Such embeddings are sometimes called
Johnson-lindenstrauss embeddings due to their celebrated lemma. Previous work
shows that as sparse embeddings, the success of subsampling and hashing closely
depends on the \(l_\infty\) to \(l_2\) ratios of the vector to be mapped. This
paper shows that the presence of noise removes such constrain in
high-dimensions, in other words, sparse embeddings such as subsampling and
hashing with comparable embedding dimensions to dense embeddings have similar
approximate norm-preserving dimensionality-reduction properties. The key is
that the noise should be treated as an information to be exploited, not simply
something to be removed. Theoretical bounds for subsampling and hashing to
recover the approximate norm of a high dimension vector in the presence of
noise are derived, with numerical illustrations showing better performances are
achieved in the presence of noise.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/shahreza2022mlp/">Mlp-hash: Protecting Face Templates Via Hashing Of Randomized Multi-layer Perceptron</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Mlp-hash: Protecting Face Templates Via Hashing Of Randomized Multi-layer Perceptron' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Mlp-hash: Protecting Face Templates Via Hashing Of Randomized Multi-layer Perceptron' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Shahreza Hatef Otroshi, Hahn Vedrana KrivokuÄ‡a, Marcel SÃ©bastien</td> <!-- ðŸ”§ You were missing this -->
    <td>2023 31st European Signal Processing Conference (EUSIPCO)</td>
    <td>18</td>
    <td><p>Applications of face recognition systems for authentication purposes are
growing rapidly. Although state-of-the-art (SOTA) face recognition systems have
high recognition accuracy, the features which are extracted for each user and
are stored in the systemâ€™s database contain privacy-sensitive information.
Accordingly, compromising this data would jeopardize usersâ€™ privacy. In this
paper, we propose a new cancelable template protection method, dubbed MLP-hash,
which generates protected templates by passing the extracted features through a
user-specific randomly-weighted multi-layer perceptron (MLP) and binarizing the
MLP output. We evaluated the unlinkability, irreversibility, and recognition
accuracy of our proposed biometric template protection method to fulfill the
ISO/IEC 30136 standard requirements. Our experiments with SOTA face recognition
systems on the MOBIO and LFW datasets show that our method has competitive
performance with the BioHashing and IoM Hashing (IoM-GRP and IoM-URP) template
protection algorithms. We provide an open-source implementation of all the
experiments presented in this paper so that other researchers can verify our
findings and build upon our work.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Alt 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2022</td>
    <td>
      <a href="/publications/sheynin2022knn/">Knn-diffusion: Image Generation Via Large-scale Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Knn-diffusion: Image Generation Via Large-scale Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Knn-diffusion: Image Generation Via Large-scale Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Sheynin et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>26</td>
    <td><p>Recent text-to-image models have achieved impressive results. However, since
they require large-scale datasets of text-image pairs, it is impractical to
train them on new domains where data is scarce or not labeled. In this work, we
propose using large-scale retrieval methods, in particular, efficient
k-Nearest-Neighbors (kNN), which offers novel capabilities: (1) training a
substantially small and efficient text-to-image diffusion model without any
text, (2) generating out-of-distribution images by simply swapping the
retrieval database at inference time, and (3) performing text-driven local
semantic manipulations while preserving object identity. To demonstrate the
robustness of our method, we apply our kNN approach on two state-of-the-art
diffusion backbones, and show results on several different datasets. As
evaluated by human studies and automatic metrics, our method achieves
state-of-the-art results compared to existing approaches that train
text-to-image generation models using images only (without paired text data)</p>
</td>
    <td>
      
        DATASETS 
      
        Robustness 
      
    </td>
    </tr>      
    
    
      
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/t%C4%9Btek2021edge/">Edge Sampling And Graph Parameter Estimation Via Vertex Neighborhood Accesses</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Edge Sampling And Graph Parameter Estimation Via Vertex Neighborhood Accesses' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Edge Sampling And Graph Parameter Estimation Via Vertex Neighborhood Accesses' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>TÄ›tek Jakub, Thorup Mikkel</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 54th Annual ACM SIGACT Symposium on Theory of Computing</td>
    <td>8</td>
    <td><p>In this paper, we consider the problems from the area of sublinear-time
algorithms of edge sampling, edge counting, and triangle counting. Part of our
contribution is that we consider three different settings, differing in the way
in which one may access the neighborhood of a given vertex. In previous work,
people have considered indexed neighbor access, with a query returning the
\(i\)-th neighbor of a given vertex. Full neighborhood access model, which has a
query that returns the entire neighborhood at a unit cost, has recently been
considered in the applied community. Between these, we propose hash-ordered
neighbor access, inspired by coordinated sampling, where we have a global fully
random hash function, and can access neighbors in order of their hash values,
paying a constant for each accessed neighbor.
  For edge sampling and counting, our new lower bounds are in the most powerful
full neighborhood access model. We provide matching upper bounds in the weaker
hash-ordered neighbor access model. Our new faster algorithms can be provably
implemented efficiently on massive graphs in external memory and with the
current APIs for, e.g., Twitter or Wikipedia. For triangle counting, we provide
a separation: a better upper bound with full neighborhood access than the known
lower bounds with indexed neighbor access. The technical core of our paper is
our edge-sampling algorithm on which the other results depend.</p>
</td>
    <td>
      
        Tools & Libraries 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/koo2021semantic/">Semantic-aware Binary Code Representation With BERT</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Semantic-aware Binary Code Representation With BERT' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Semantic-aware Binary Code Representation With BERT' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Koo et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>11</td>
    <td><p>A wide range of binary analysis applications, such as bug discovery, malware
analysis and code clone detection, require recovery of contextual meanings on a
binary code. Recently, binary analysis techniques based on machine learning
have been proposed to automatically reconstruct the code representation of a
binary instead of manually crafting specifics of the analysis algorithm.
However, the existing approaches utilizing machine learning are still
specialized to solve one domain of problems, rendering recreation of models for
different types of binary analysis. In this paper, we propose DeepSemantic
utilizing BERT in producing the semantic-aware code representation of a binary
code.
  To this end, we introduce well-balanced instruction normalization that holds
rich information for each of instructions yet minimizing an out-of-vocabulary
(OOV) problem. DeepSemantic has been carefully designed based on our study with
large swaths of binaries. Besides, DeepSemantic leverages the essence of the
BERT architecture into re-purposing a pre-trained generic model that is readily
available as a one-time processing, followed by quickly applying specific
downstream tasks with a fine-tuning process. We demonstrate DeepSemantic with
two downstream tasks, namely, binary similarity comparison and compiler
provenance (i.e., compiler and optimization level) prediction. Our experimental
results show that the binary similarity model outperforms two state-of-the-art
binary similarity tools, DeepBinDiff and SAFE, 49.84% and 15.83% on average,
respectively.</p>
</td>
    <td>
      
        Compact Codes 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/kordopatiszilos2021dns/">Dns: Distill-and-select For Efficient And Accurate Video Indexing And Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Dns: Distill-and-select For Efficient And Accurate Video Indexing And Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Dns: Distill-and-select For Efficient And Accurate Video Indexing And Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Kordopatis-zilos et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>International Journal of Computer Vision</td>
    <td>27</td>
    <td><p>In this paper, we address the problem of high performance and computationally
efficient content-based video retrieval in large-scale datasets. Current
methods typically propose either: (i) fine-grained approaches employing
spatio-temporal representations and similarity calculations, achieving high
performance at a high computational cost or (ii) coarse-grained approaches
representing/indexing videos as global vectors, where the spatio-temporal
structure is lost, providing low performance but also having low computational
cost. In this work, we propose a Knowledge Distillation framework, called
Distill-and-Select (DnS), that starting from a well-performing fine-grained
Teacher Network learns: a) Student Networks at different retrieval performance
and computational efficiency trade-offs and b) a Selector Network that at test
time rapidly directs samples to the appropriate student to maintain both high
retrieval performance and high computational efficiency. We train several
students with different architectures and arrive at different trade-offs of
performance and efficiency, i.e., speed and storage requirements, including
fine-grained students that store/index videos using binary representations.
Importantly, the proposed scheme allows Knowledge Distillation in large,
unlabelled datasets â€“ this leads to good students. We evaluate DnS on five
public datasets on three different video retrieval tasks and demonstrate a)
that our students achieve state-of-the-art performance in several cases and b)
that the DnS framework provides an excellent trade-off between retrieval
performance, computational speed, and storage space. In specific
configurations, the proposed method achieves similar mAP with the teacher but
is 20 times faster and requires 240 times less storage space. The collected
dataset and implementation are publicly available:
https://github.com/mever-team/distill-and-select.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/wang2021comprehensive/">A Comprehensive Survey And Experimental Comparison Of Graph-based Approximate Nearest Neighbor Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Comprehensive Survey And Experimental Comparison Of Graph-based Approximate Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Comprehensive Survey And Experimental Comparison Of Graph-based Approximate Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the VLDB Endowment</td>
    <td>119</td>
    <td><p>Approximate nearest neighbor search (ANNS) constitutes an important operation
in a multitude of applications, including recommendation systems, information
retrieval, and pattern recognition. In the past decade, graph-based ANNS
algorithms have been the leading paradigm in this domain, with dozens of
graph-based ANNS algorithms proposed. Such algorithms aim to provide effective,
efficient solutions for retrieving the nearest neighbors for a given query.
Nevertheless, these efforts focus on developing and optimizing algorithms with
different approaches, so there is a real need for a comprehensive survey about
the approachesâ€™ relative performance, strengths, and pitfalls. Thus here we
provide a thorough comparative analysis and experimental evaluation of 13
representative graph-based ANNS algorithms via a new taxonomy and fine-grained
pipeline. We compared each algorithm in a uniform test environment on eight
real-world datasets and 12 synthetic datasets with varying sizes and
characteristics. Our study yields novel discoveries, offerings several useful
principles to improve algorithms, thus designing an optimized method that
outperforms the state-of-the-art algorithms. This effort also helped us
pinpoint algorithmsâ€™ working portions, along with rule-of-thumb recommendations
about promising research directions and suitable algorithms for practitioners
in different fields.</p>
</td>
    <td>
      
        Survey Paper 
      
        DATASETS 
      
        Graph Based ANN 
      
        Recommender Systems 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/ko2021low/">Low-precision Quantization For Efficient Nearest Neighbor Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Low-precision Quantization For Efficient Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Low-precision Quantization For Efficient Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ko et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Pattern Analysis and Machine Intelligence</td>
    <td>1863</td>
    <td><p>Fast k-Nearest Neighbor search over real-valued vector spaces (KNN) is an
important algorithmic task for information retrieval and recommendation
systems. We present a method for using reduced precision to represent vectors
through quantized integer values, enabling both a reduction in the memory
overhead of indexing these vectors and faster distance computations at query
time. While most traditional quantization techniques focus on minimizing the
reconstruction error between a point and its uncompressed counterpart, we focus
instead on preserving the behavior of the underlying distance metric.
Furthermore, our quantization approach is applied at the implementation level
and can be combined with existing KNN algorithms. Our experiments on both open
source and proprietary datasets across multiple popular KNN frameworks validate
that quantized distance metrics can reduce memory by 60% and improve query
throughput by 30%, while incurring only a 2% reduction in recall.</p>
</td>
    <td>
      
        DATASETS 
      
        Distance Metric Learning 
      
        Recommender Systems 
      
        Quantization 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/kim2021multi/">Multi-level Distance Regularization For Deep Metric Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Multi-level Distance Regularization For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Multi-level Distance Regularization For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Kim Yonghyun, Park Wonpyo</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>11</td>
    <td><p>We propose a novel distance-based regularization method for deep metric
learning called Multi-level Distance Regularization (MDR). MDR explicitly
disturbs a learning procedure by regularizing pairwise distances between
embedding vectors into multiple levels that represents a degree of similarity
between a pair. In the training stage, the model is trained with both MDR and
an existing loss function of deep metric learning, simultaneously; the two
losses interfere with the objective of each other, and it makes the learning
process difficult. Moreover, MDR prevents some examples from being ignored or
overly influenced in the learning process. These allow the parameters of the
embedding network to be settle on a local optima with better generalization.
Without bells and whistles, MDR with simple Triplet loss achieves
the-state-of-the-art performance in various benchmark datasets: CUB-200-2011,
Cars-196, Stanford Online Products, and In-Shop Clothes Retrieval. We
extensively perform ablation studies on its behaviors to show the effectiveness
of MDR. By easily adopting our MDR, the previous approaches can be improved in
performance and generalization ability.</p>
</td>
    <td>
      
        AAAI 
      
        DATASETS 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/zhang2021improved/">Improved Deep Classwise Hashing With Centers Similarity Learning For Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Improved Deep Classwise Hashing With Centers Similarity Learning For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Improved Deep Classwise Hashing With Centers Similarity Learning For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang Ming, Yan Hong</td> <!-- ðŸ”§ You were missing this -->
    <td>2020 25th International Conference on Pattern Recognition (ICPR)</td>
    <td>8</td>
    <td><p>Deep supervised hashing for image retrieval has attracted researchersâ€™
attention due to its high efficiency and superior retrieval performance. Most
existing deep supervised hashing works, which are based on pairwise/triplet
labels, suffer from the expensive computational cost and insufficient
utilization of the semantics information. Recently, deep classwise hashing
introduced a classwise loss supervised by class labels information
alternatively; however, we find it still has its drawback. In this paper, we
propose an improved deep classwise hashing, which enables hashing learning and
class centers learning simultaneously. Specifically, we design a two-step
strategy on center similarity learning. It interacts with the classwise loss to
attract the class center to concentrate on the intra-class samples while
pushing other class centers as far as possible. The centers similarity learning
contributes to generating more compact and discriminative hashing codes. We
conduct experiments on three benchmark datasets. It shows that the proposed
method effectively surpasses the original method and outperforms
state-of-the-art baselines under various commonly-used evaluation metrics for
image retrieval.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Alt 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/khan2021deep/">A Deep Metric Learning Approach To Account Linking</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Deep Metric Learning Approach To Account Linking' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Deep Metric Learning Approach To Account Linking' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Khan et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</td>
    <td>8</td>
    <td><p>We consider the task of linking social media accounts that belong to the same
author in an automated fashion on the basis of the content and metadata of
their corresponding document streams. We focus on learning an embedding that
maps variable-sized samples of user activity â€“ ranging from single posts to
entire months of activity â€“ to a vector space, where samples by the same
author map to nearby points. The approach does not require human-annotated data
for training purposes, which allows us to leverage large amounts of social
media content. The proposed model outperforms several competitive baselines
under a novel evaluation framework modeled after established recognition
benchmarks in other domains. Our method achieves high linking accuracy, even
with small samples from accounts not seen at training time, a prerequisite for
practical applications of the proposed linking framework.</p>
</td>
    <td>
      
        Evaluation 
      
        NAACL 
      
        ACL 
      
        Distance Metric Learning 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/zhang2021orthonormal/">Orthonormal Product Quantization Network For Scalable Face Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Orthonormal Product Quantization Network For Scalable Face Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Orthonormal Product Quantization Network For Scalable Face Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang Ming, Zhe Xuefei, Yan Hong</td> <!-- ðŸ”§ You were missing this -->
    <td>Pattern Recognition</td>
    <td>9</td>
    <td><p>Existing deep quantization methods provided an efficient solution for
large-scale image retrieval. However, the significant intra-class variations
like pose, illumination, and expressions in face images, still pose a challenge
for face image retrieval. In light of this, face image retrieval requires
sufficiently powerful learning metrics, which are absent in current deep
quantization works. Moreover, to tackle the growing unseen identities in the
query stage, face image retrieval drives more demands regarding model
generalization and system scalability than general image retrieval tasks. This
paper integrates product quantization with orthonormal constraints into an
end-to-end deep learning framework to effectively retrieve face images.
Specifically, a novel scheme that uses predefined orthonormal vectors as
codewords is proposed to enhance the quantization informativeness and reduce
codewordsâ€™ redundancy. A tailored loss function maximizes discriminability
among identities in each quantization subspace for both the quantized and
original features. An entropy-based regularization term is imposed to reduce
the quantization error. Experiments are conducted on four commonly-used face
datasets under both seen and unseen identities retrieval settings. Our method
outperforms all the compared deep hashing/quantization state-of-the-arts under
both settings. Results validate the effectiveness of the proposed orthonormal
codewords in improving modelsâ€™ standard retrieval performance and
generalization ability. Combing with further experiments on two general image
datasets, it demonstrates the broad superiority of our method for scalable
image retrieval.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        CVPR 
      
        Neural Hashing 
      
        Quantization 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/vanblokland2021partial/">Partial 3D Object Retrieval Using Local Binary QUICCI Descriptors And Dissimilarity Tree Indexing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Partial 3D Object Retrieval Using Local Binary QUICCI Descriptors And Dissimilarity Tree Indexing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Partial 3D Object Retrieval Using Local Binary QUICCI Descriptors And Dissimilarity Tree Indexing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>van Blokland Bart Iver, Theoharis Theoharis</td> <!-- ðŸ”§ You were missing this -->
    <td>Computers &amp; Graphics</td>
    <td>6</td>
    <td><p>A complete pipeline is presented for accurate and efficient partial 3D object
retrieval based on Quick Intersection Count Change Image (QUICCI) binary local
descriptors and a novel indexing tree. It is shown how a modification to the
QUICCI query descriptor makes it ideal for partial retrieval. An indexing
structure called Dissimilarity Tree is proposed which can significantly
accelerate searching the large space of local descriptors; this is applicable
to QUICCI and other binary descriptors. The index exploits the distribution of
bits within descriptors for efficient retrieval. The retrieval pipeline is
tested on the artificial part of SHRECâ€™16 dataset with near-ideal retrieval
results.</p>
</td>
    <td>
      
        DATASETS 
      
        Similarity Search 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/jia2021joint/">Joint Representation Learning And Novel Category Discovery On Single- And Multi-modal Data</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Joint Representation Learning And Novel Category Discovery On Single- And Multi-modal Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Joint Representation Learning And Novel Category Discovery On Single- And Multi-modal Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jia et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2021 IEEE/CVF International Conference on Computer Vision (ICCV)</td>
    <td>46</td>
    <td><p>This paper studies the problem of novel category discovery on single- and
multi-modal data with labels from different but relevant categories. We present
a generic, end-to-end framework to jointly learn a reliable representation and
assign clusters to unlabelled data. To avoid over-fitting the learnt embedding
to labelled data, we take inspiration from self-supervised representation
learning by noise-contrastive estimation and extend it to jointly handle
labelled and unlabelled data. In particular, we propose using category
discrimination on labelled data and cross-modal discrimination on multi-modal
data to augment instance discrimination used in conventional contrastive
learning approaches. We further employ Winner-Take-All (WTA) hashing algorithm
on the shared representation space to generate pairwise pseudo labels for
unlabelled data to better predict cluster assignments. We thoroughly evaluate
our framework on large-scale multi-modal video benchmarks Kinetics-400 and
VGG-Sound, and image benchmarks CIFAR10, CIFAR100 and ImageNet, obtaining
state-of-the-art results.</p>
</td>
    <td>
      
        ICCV 
      
        Tools & Libraries 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/jang2021similarity/">Similarity Guided Deep Face Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Similarity Guided Deep Face Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Similarity Guided Deep Face Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jang Young Kyun, Cho Nam Ik</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 2020 International Conference on Multimedia Retrieval</td>
    <td>8</td>
    <td><p>Face image retrieval, which searches for images of the same identity from the
query input face image, is drawing more attention as the size of the image
database increases rapidly. In order to conduct fast and accurate retrieval, a
compact hash code-based methods have been proposed, and recently, deep face
image hashing methods with supervised classification training have shown
outstanding performance. However, classification-based scheme has a
disadvantage in that it cannot reveal complex similarities between face images
into the hash code learning. In this paper, we attempt to improve the face
image retrieval quality by proposing a Similarity Guided Hashing (SGH) method,
which gently considers self and pairwise-similarity simultaneously. SGH employs
various data augmentations designed to explore elaborate similarities between
face images, solving both intra and inter identity-wise difficulties. Extensive
experimental results on the protocols with existing benchmarks and an
additionally proposed large scale higher resolution face image dataset
demonstrate that our SGH delivers state-of-the-art retrieval performance.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        Hashing Methods 
      
        Image Retrieval 
      
        Tools & Libraries 
      
        Multimodal Retrieval 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/jang2021self/">Self-supervised Product Quantization For Deep Unsupervised Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Self-supervised Product Quantization For Deep Unsupervised Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Self-supervised Product Quantization For Deep Unsupervised Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jang Young Kyun, Cho Nam Ik</td> <!-- ðŸ”§ You were missing this -->
    <td>2021 IEEE/CVF International Conference on Computer Vision (ICCV)</td>
    <td>52</td>
    <td><p>Supervised deep learning-based hash and vector quantization are enabling fast
and large-scale image retrieval systems. By fully exploiting label annotations,
they are achieving outstanding retrieval performances compared to the
conventional methods. However, it is painstaking to assign labels precisely for
a vast amount of training data, and also, the annotation process is
error-prone. To tackle these issues, we propose the first deep unsupervised
image retrieval method dubbed Self-supervised Product Quantization (SPQ)
network, which is label-free and trained in a self-supervised manner. We design
a Cross Quantized Contrastive learning strategy that jointly learns codewords
and deep visual descriptors by comparing individually transformed images
(views). Our method analyzes the image contents to extract descriptive
features, allowing us to understand image representations for accurate
retrieval. By conducting extensive experiments on benchmarks, we demonstrate
that the proposed method yields state-of-the-art results even without
supervised pretraining.</p>
</td>
    <td>
      
        ICCV 
      
        Image Retrieval 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/jang2021ultra/">Ultra-high Dimensional Sparse Representations With Binarization For Efficient Text Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Ultra-high Dimensional Sparse Representations With Binarization For Efficient Text Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Ultra-high Dimensional Sparse Representations With Binarization For Efficient Text Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</td>
    <td>9</td>
    <td><p>The semantic matching capabilities of neural information retrieval can
ameliorate synonymy and polysemy problems of symbolic approaches. However,
neural modelsâ€™ dense representations are more suitable for re-ranking, due to
their inefficiency. Sparse representations, either in symbolic or latent form,
are more efficient with an inverted index. Taking the merits of the sparse and
dense representations, we propose an ultra-high dimensional (UHD)
representation scheme equipped with directly controllable sparsity. UHDâ€™s large
capacity and minimal noise and interference among the dimensions allow for
binarized representations, which are highly efficient for storage and search.
Also proposed is a bucketing method, where the embeddings from multiple layers
of BERT are selected/merged to represent diverse linguistic aspects. We test
our models with MS MARCO and TREC CAR, showing that our models outperforms
other sparse models</p>
</td>
    <td>
      
        Text Retrieval 
      
        EMNLP 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/struppek2021learning/">Learning To Break Deep Perceptual Hashing: The Use Case Neuralhash</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning To Break Deep Perceptual Hashing: The Use Case Neuralhash' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning To Break Deep Perceptual Hashing: The Use Case Neuralhash' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Struppek et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2022 ACM Conference on Fairness Accountability and Transparency</td>
    <td>116</td>
    <td><p>Apple recently revealed its deep perceptual hashing system NeuralHash to
detect child sexual abuse material (CSAM) on user devices before files are
uploaded to its iCloud service. Public criticism quickly arose regarding the
protection of user privacy and the systemâ€™s reliability. In this paper, we
present the first comprehensive empirical analysis of deep perceptual hashing
based on NeuralHash. Specifically, we show that current deep perceptual hashing
may not be robust. An adversary can manipulate the hash values by applying
slight changes in images, either induced by gradient-based approaches or simply
by performing standard image transformations, forcing or preventing hash
collisions. Such attacks permit malicious actors easily to exploit the
detection system: from hiding abusive material to framing innocent users,
everything is possible. Moreover, using the hash values, inferences can still
be made about the data stored on user devices. In our view, based on our
results, deep perceptual hashing in its current form is generally not ready for
robust client-side scanning and should not be used from a privacy perspective.</p>
</td>
    <td>
      
        Tools & Libraries 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/zeng2021phpq/">PHPQ: Pyramid Hybrid Pooling Quantization For Efficient Fine-grained Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=PHPQ: Pyramid Hybrid Pooling Quantization For Efficient Fine-grained Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=PHPQ: Pyramid Hybrid Pooling Quantization For Efficient Fine-grained Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zeng et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Pattern Recognition Letters</td>
    <td>9</td>
    <td><p>Deep hashing approaches, including deep quantization and deep binary hashing,
have become a common solution to large-scale image retrieval due to their high
computation and storage efficiency. Most existing hashing methods cannot
produce satisfactory results for fine-grained retrieval, because they usually
adopt the outputs of the last CNN layer to generate binary codes. Since deeper
layers tend to summarize visual clues, e.g., texture, into abstract semantics,
e.g., dogs and cats, the feature produced by the last CNN layer is less
effective in capturing subtle but discriminative visual details that mostly
exist in shallow layers. To improve fine-grained image hashing, we propose
Pyramid Hybrid Pooling Quantization (PHPQ). Specifically, we propose a Pyramid
Hybrid Pooling (PHP) module to capture and preserve fine-grained semantic
information from multi-level features, which emphasizes the subtle
discrimination of different sub-categories. Besides, we propose a learnable
quantization module with a partial codebook attention mechanism, which helps to
optimize the most relevant codewords and improves the quantization.
Comprehensive experiments on two widely-used public benchmarks, i.e.,
CUB-200-2011 and Stanford Dogs, demonstrate that PHPQ outperforms
state-of-the-art methods.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Neural Hashing 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/jang2021deep/">Deep Hash Distillation For Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Hash Distillation For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Hash Distillation For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>23</td>
    <td><p>In hash-based image retrieval systems, degraded or transformed inputs usually
generate different codes from the original, deteriorating the retrieval
accuracy. To mitigate this issue, data augmentation can be applied during
training. However, even if augmented samples of an image are similar in real
feature space, the quantization can scatter them far away in Hamming space.
This results in representation discrepancies that can impede training and
degrade performance. In this work, we propose a novel self-distilled hashing
scheme to minimize the discrepancy while exploiting the potential of augmented
data. By transferring the hash knowledge of the weakly-transformed samples to
the strong ones, we make the hash code insensitive to various transformations.
We also introduce hash proxy-based similarity learning and binary cross
entropy-based quantization loss to provide fine quality hash codes. Ultimately,
we construct a deep hashing framework that not only improves the existing deep
hashing approaches, but also achieves the state-of-the-art retrieval results.
Extensive experiments are conducted and confirm the effectiveness of our work.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Neural Hashing 
      
        Quantization 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/su%C3%A1rez2021revisiting/">Revisiting Binary Local Image Description For Resource Limited Devices</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Revisiting Binary Local Image Description For Resource Limited Devices' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Revisiting Binary Local Image Description For Resource Limited Devices' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>SuÃ¡rez Iago, Buenaposada JosÃ© M., Baumela Luis</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Robotics and Automation Letters</td>
    <td>10</td>
    <td><p>The advent of a panoply of resource limited devices opens up new challenges
in the design of computer vision algorithms with a clear compromise between
accuracy and computational requirements. In this paper we present new binary
image descriptors that emerge from the application of triplet ranking loss,
hard negative mining and anchor swapping to traditional features based on pixel
differences and image gradients. These descriptors, BAD (Box Average
Difference) and HashSIFT, establish new operating points in the
state-of-the-artâ€™s accuracy vs.\ resources trade-off curve. In our experiments
we evaluate the accuracy, execution time and energy consumption of the proposed
descriptors. We show that BAD bears the fastest descriptor implementation in
the literature while HashSIFT approaches in accuracy that of the top deep
learning-based descriptors, being computationally more efficient. We have made
the source code public.</p>
</td>
    <td>
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/hoe2021one/">One Loss For All: Deep Hashing With A Single Cosine Similarity Based Learning Objective</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=One Loss For All: Deep Hashing With A Single Cosine Similarity Based Learning Objective' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=One Loss For All: Deep Hashing With A Single Cosine Similarity Based Learning Objective' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Hoe et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>46</td>
    <td><p>A deep hashing model typically has two main learning objectives: to make the
learned binary hash codes discriminative and to minimize a quantization error.
With further constraints such as bit balance and code orthogonality, it is not
uncommon for existing models to employ a large number (&gt;4) of losses. This
leads to difficulties in model training and subsequently impedes their
effectiveness. In this work, we propose a novel deep hashing model with only a
single learning objective. Specifically, we show that maximizing the cosine
similarity between the continuous codes and their corresponding binary
orthogonal codes can ensure both hash code discriminativeness and quantization
error minimization. Further, with this learning objective, code balancing can
be achieved by simply using a Batch Normalization (BN) layer and multi-label
classification is also straightforward with label smoothing. The result is an
one-loss deep hashing model that removes all the hassles of tuning the weights
of various losses. Importantly, extensive experiments show that our model is
highly effective, outperforming the state-of-the-art multi-loss hashing models
on three large-scale instance retrieval benchmarks, often by significant
margins. Code is available at https://github.com/kamwoh/orthohash</p>
</td>
    <td>
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        Neural Hashing 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/hoang2021multi/">Multi-modal Mutual Information Maximization: A Novel Approach For Unsupervised Deep Cross-modal Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Multi-modal Mutual Information Maximization: A Novel Approach For Unsupervised Deep Cross-modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Multi-modal Mutual Information Maximization: A Novel Approach For Unsupervised Deep Cross-modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Hoang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Neural Networks and Learning Systems</td>
    <td>27</td>
    <td><p>In this paper, we adopt the maximizing mutual information (MI) approach to
tackle the problem of unsupervised learning of binary hash codes for efficient
cross-modal retrieval. We proposed a novel method, dubbed Cross-Modal Info-Max
Hashing (CMIMH). First, to learn informative representations that can preserve
both intra- and inter-modal similarities, we leverage the recent advances in
estimating variational lower-bound of MI to maximize the MI between the binary
representations and input features and between binary representations of
different modalities. By jointly maximizing these MIs under the assumption that
the binary representations are modelled by multivariate Bernoulli
distributions, we can learn binary representations, which can preserve both
intra- and inter-modal similarities, effectively in a mini-batch manner with
gradient descent. Furthermore, we find out that trying to minimize the modality
gap by learning similar binary representations for the same instance from
different modalities could result in less informative representations. Hence,
balancing between reducing the modality gap and losing modality-private
information is important for the cross-modal retrieval tasks. Quantitative
evaluations on standard benchmark datasets demonstrate that the proposed method
consistently outperforms other state-of-the-art cross-modal retrieval methods.</p>
</td>
    <td>
      
        Multimodal Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/wei2021pp/">Pp-shitu: A Practical Lightweight Image Recognition System</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Pp-shitu: A Practical Lightweight Image Recognition System' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Pp-shitu: A Practical Lightweight Image Recognition System' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wei et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>6</td>
    <td><p>In recent years, image recognition applications have developed rapidly. A
large number of studies and techniques have emerged in different fields, such
as face recognition, pedestrian and vehicle re-identification, landmark
retrieval, and product recognition. In this paper, we propose a practical
lightweight image recognition system, named PP-ShiTu, consisting of the
following 3 modules, mainbody detection, feature extraction and vector search.
We introduce popular strategies including metric learning, deep hash, knowledge
distillation and model quantization to improve accuracy and inference speed.
With strategies above, PP-ShiTu works well in different scenarios with a set of
models trained on a mixed dataset. Experiments on different datasets and
benchmarks show that the system is widely effective in different domains of
image recognition. All the above mentioned models are open-sourced and the code
is available in the GitHub repository PaddleClas on PaddlePaddle.</p>
</td>
    <td>
      
        DATASETS 
      
        Distance Metric Learning 
      
        Neural Hashing 
      
        Quantization 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/he2021unsupervised/">Unsupervised Domain-adaptive Hash For Networks</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Unsupervised Domain-adaptive Hash For Networks' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Unsupervised Domain-adaptive Hash For Networks' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>He et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of The Web Conference 2020</td>
    <td>98</td>
    <td><p>Abundant real-world data can be naturally represented by large-scale
networks, which demands efficient and effective learning algorithms. At the
same time, labels may only be available for some networks, which demands these
algorithms to be able to adapt to unlabeled networks. Domain-adaptive hash
learning has enjoyed considerable success in the computer vision community in
many practical tasks due to its lower cost in both retrieval time and storage
footprint. However, it has not been applied to multiple-domain networks. In
this work, we bridge this gap by developing an unsupervised domain-adaptive
hash learning method for networks, dubbed UDAH. Specifically, we develop four
{task-specific yet correlated} components: (1) network structure preservation
via a hard groupwise contrastive loss, (2) relaxation-free supervised hashing,
(3) cross-domain intersected discriminators, and (4) semantic center alignment.
We conduct a wide range of experiments to evaluate the effectiveness and
efficiency of our method on a range of tasks including link prediction, node
classification, and neighbor recommendation. Our evaluation results demonstrate
that our model achieves better performance than the state-of-the-art
conventional discrete embedding methods over all the tasks.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        Efficiency And Optimization 
      
        Recommender Systems 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/zhao2021large/">Large-scale Visual Search With Binary Distributed Graph At Alibaba</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Large-scale Visual Search With Binary Distributed Graph At Alibaba' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Large-scale Visual Search With Binary Distributed Graph At Alibaba' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhao et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 28th ACM International Conference on Information and Knowledge Management</td>
    <td>10</td>
    <td><p>Graph-based approximate nearest neighbor search has attracted more and more
attentions due to its online search advantages. Numbers of methods studying the
enhancement of speed and recall have been put forward. However, few of them
focus on the efficiency and scale of offline graph-construction. For a deployed
visual search system with several billions of online images in total, building
a billion-scale offline graph in hours is essential, which is almost
unachievable by most existing methods. In this paper, we propose a novel
algorithm called Binary Distributed Graph to solve this problem. Specifically,
we combine binary codes with graph structure to speedup online and offline
procedures, and achieve comparable performance with the ones in real-value
based scenarios by recalling more binary candidates. Furthermore, the
graph-construction is optimized to completely distributed implementation, which
significantly accelerates the offline process and gets rid of the limitation of
memory and disk within a single machine. Experimental comparisons on Alibaba
Commodity Data Set (more than three billion images) show that the proposed
method outperforms the state-of-the-art with respect to the online/offline
trade-off.</p>
</td>
    <td>
      
        CIKM 
      
        Image Retrieval 
      
        Graph Based ANN 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Large Scale Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/hashimoto2021case/">Case-based Similar Image Retrieval For Weakly Annotated Large Histopathological Images Of Malignant Lymphoma Using Deep Metric Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Case-based Similar Image Retrieval For Weakly Annotated Large Histopathological Images Of Malignant Lymphoma Using Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Case-based Similar Image Retrieval For Weakly Annotated Large Histopathological Images Of Malignant Lymphoma Using Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Hashimoto et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Medical Image Analysis</td>
    <td>18</td>
    <td><p>In the present study, we propose a novel case-based similar image retrieval
(SIR) method for hematoxylin and eosin (H&amp;E)-stained histopathological images
of malignant lymphoma. When a whole slide image (WSI) is used as an input
query, it is desirable to be able to retrieve similar cases by focusing on
image patches in pathologically important regions such as tumor cells. To
address this problem, we employ attention-based multiple instance learning,
which enables us to focus on tumor-specific regions when the similarity between
cases is computed. Moreover, we employ contrastive distance metric learning to
incorporate immunohistochemical (IHC) staining patterns as useful supervised
information for defining appropriate similarity between heterogeneous malignant
lymphoma cases. In the experiment with 249 malignant lymphoma patients, we
confirmed that the proposed method exhibited higher evaluation measures than
the baseline case-based SIR methods. Furthermore, the subjective evaluation by
pathologists revealed that our similarity measure using IHC staining patterns
is appropriate for representing the similarity of H&amp;E-stained tissue images for
malignant lymphoma.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/hansen2021unsupervised/">Unsupervised Multi-index Semantic Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Unsupervised Multi-index Semantic Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Unsupervised Multi-index Semantic Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Hansen et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the Web Conference 2021</td>
    <td>8</td>
    <td><p>Semantic hashing represents documents as compact binary vectors (hash codes)
and allows both efficient and effective similarity search in large-scale
information retrieval. The state of the art has primarily focused on learning
hash codes that improve similarity search effectiveness, while assuming a
brute-force linear scan strategy for searching over all the hash codes, even
though much faster alternatives exist. One such alternative is multi-index
hashing, an approach that constructs a smaller candidate set to search over,
which depending on the distribution of the hash codes can lead to sub-linear
search time. In this work, we propose Multi-Index Semantic Hashing (MISH), an
unsupervised hashing model that learns hash codes that are both effective and
highly efficient by being optimized for multi-index hashing. We derive novel
training objectives, which enable to learn hash codes that reduce the candidate
sets produced by multi-index hashing, while being end-to-end trainable. In
fact, our proposed training objectives are model agnostic, i.e., not tied to
how the hash codes are generated specifically in MISH, and are straight-forward
to include in existing and future semantic hashing models. We experimentally
compare MISH to state-of-the-art semantic hashing baselines in the task of
document similarity search. We find that even though multi-index hashing also
improves the efficiency of the baselines compared to a linear scan, they are
still upwards of 33% slower than MISH, while MISH is still able to obtain
state-of-the-art effectiveness.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Alt 
      
        Text Retrieval 
      
        Similarity Search 
      
        Vector Indexing 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/hansen2021representation/">Representation Learning For Efficient And Effective Similarity Search And Recommendation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Representation Learning For Efficient And Effective Similarity Search And Recommendation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Representation Learning For Efficient And Effective Similarity Search And Recommendation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Hansen Casper</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval</td>
    <td>16</td>
    <td><p>How data is represented and operationalized is critical for building
computational solutions that are both effective and efficient. A common
approach is to represent data objects as binary vectors, denoted \textit{hash
codes}, which require little storage and enable efficient similarity search
through direct indexing into a hash table or through similarity computations in
an appropriate space. Due to the limited expressibility of hash codes, compared
to real-valued representations, a core open challenge is how to generate hash
codes that well capture semantic content or latent properties using a small
number of bits, while ensuring that the hash codes are distributed in a way
that does not reduce their search efficiency. State of the art methods use
representation learning for generating such hash codes, focusing on neural
autoencoder architectures where semantics are encoded into the hash codes by
learning to reconstruct the original inputs of the hash codes. This thesis
addresses the above challenge and makes a number of contributions to
representation learning that (i) improve effectiveness of hash codes through
more expressive representations and a more effective similarity measure than
the current state of the art, namely the Hamming distance, and (ii) improve
efficiency of hash codes by learning representations that are especially suited
to the choice of search method. The contributions are empirically validated on
several tasks related to similarity search and recommendation.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Recommender Systems 
      
        SIGIR 
      
        Similarity Search 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/gupta2021irli/">IRLI: Iterative Re-partitioning For Learning To Index</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=IRLI: Iterative Re-partitioning For Learning To Index' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=IRLI: Iterative Re-partitioning For Learning To Index' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Gupta et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</td>
    <td>6</td>
    <td><p>Neural models have transformed the fundamental information retrieval problem
of mapping a query to a giant set of items. However, the need for efficient and
low latency inference forces the community to reconsider efficient approximate
near-neighbor search in the item space. To this end, learning to index is
gaining much interest in recent times. Methods have to trade between obtaining
high accuracy while maintaining load balance and scalability in distributed
settings. We propose a novel approach called IRLI (pronounced `earlyâ€™), which
iteratively partitions the items by learning the relevant buckets directly from
the query-item relevance data. Furthermore, IRLI employs a superior
power-of-\(k\)-choices based load balancing strategy. We mathematically show that
IRLI retrieves the correct item with high probability under very natural
assumptions and provides superior load balancing. IRLI surpasses the best
baselineâ€™s precision on multi-label classification while being \(5x\) faster on
inference. For near-neighbor search tasks, the same method outperforms the
state-of-the-art Learned Hashing approach NeuralLSH by requiring only ~
{1/6}^th of the candidates for the same recall. IRLI is both data and model
parallel, making it ideal for distributed GPU implementation. We demonstrate
this advantage by indexing 100 million dense vectors and surpassing the popular
FAISS library by &gt;10% on recall.</p>
</td>
    <td>
      
        KDD 
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/sun2021real/">Real-time Human Action Recognition Using Locally Aggregated Kinematic-guided Skeletonlet And Supervised Hashing-by-analysis Model</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Real-time Human Action Recognition Using Locally Aggregated Kinematic-guided Skeletonlet And Supervised Hashing-by-analysis Model' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Real-time Human Action Recognition Using Locally Aggregated Kinematic-guided Skeletonlet And Supervised Hashing-by-analysis Model' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Sun et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Cybernetics</td>
    <td>15</td>
    <td><p>3D action recognition is referred to as the classification of action
sequences which consist of 3D skeleton joints. While many research work are
devoted to 3D action recognition, it mainly suffers from three problems: highly
complicated articulation, a great amount of noise, and a low implementation
efficiency. To tackle all these problems, we propose a real-time 3D action
recognition framework by integrating the locally aggregated kinematic-guided
skeletonlet (LAKS) with a supervised hashing-by-analysis (SHA) model. We first
define the skeletonlet as a few combinations of joint offsets grouped in terms
of kinematic principle, and then represent an action sequence using LAKS, which
consists of a denoising phase and a locally aggregating phase. The denoising
phase detects the noisy action data and adjust it by replacing all the features
within it with the features of the corresponding previous frame, while the
locally aggregating phase sums the difference between an offset feature of the
skeletonlet and its cluster center together over all the offset features of the
sequence. Finally, the SHA model which combines sparse representation with a
hashing model, aiming at promoting the recognition accuracy while maintaining a
high efficiency. Experimental results on MSRAction3D, UTKinectAction3D and
Florence3DAction datasets demonstrate that the proposed method outperforms
state-of-the-art methods in both recognition accuracy and implementation
efficiency.</p>
</td>
    <td>
      
        DATASETS 
      
        Tools & Libraries 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/fleischhacker2021property/">Property-preserving Hash Functions From Standard Assumptions</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Property-preserving Hash Functions From Standard Assumptions' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Property-preserving Hash Functions From Standard Assumptions' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Fleischhacker Nils, Larsen Kasper Green, Simkin And Mark</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>5</td>
    <td><p>Property-preserving hash functions allow for compressing long inputs \(x_0\)
and \(x_1\) into short hashes \(h(x_0)\) and \(h(x_1)\) in a manner that allows for
computing a predicate \(P(x_0, x_1)\) given only the two hash values without
having access to the original data. Such hash functions are said to be
adversarially robust if an adversary that gets to pick \(x_0\) and \(x_1\) after
the hash function has been sampled, cannot find inputs for which the predicate
evaluated on the hash values outputs the incorrect result.
  In this work we construct robust property-preserving hash functions for the
hamming-distance predicate which distinguishes inputs with a hamming distance
at least some threshold \(t\) from those with distance less than \(t\). The
security of the construction is based on standard lattice hardness assumptions.
  Our construction has several advantages over the best known previous
construction by Fleischhacker and Simkin. Our construction relies on a single
well-studied hardness assumption from lattice cryptography whereas the previous
work relied on a newly introduced family of computational hardness assumptions.
In terms of computational effort, our construction only requires a small number
of modular additions per input bit, whereas previously several exponentiations
per bit as well as the interpolation and evaluation of high-degree polynomials
over large fields were required. An additional benefit of our construction is
that the description of the hash function can be compressed to \(\lambda\) bits
assuming a random oracle. Previous work has descriptions of length
\(\mathcal{O}(\ell \lambda)\) bits for input bit-length \(\ell\), which has a
secret structure and thus cannot be compressed.
  We prove a lower bound on the output size of any property-preserving hash
function for the hamming distance predicate. The bound shows that the size of
our hash value is not far from optimal.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/fitzgerald2021moleman/">MOLEMAN: Mention-only Linking Of Entities With A Mention Annotation Network</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=MOLEMAN: Mention-only Linking Of Entities With A Mention Annotation Network' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=MOLEMAN: Mention-only Linking Of Entities With A Mention Annotation Network' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Fitzgerald et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)</td>
    <td>8</td>
    <td><p>We present an instance-based nearest neighbor approach to entity linking. In
contrast to most prior entity retrieval systems which represent each entity
with a single vector, we build a contextualized mention-encoder that learns to
place similar mentions of the same entity closer in vector space than mentions
of different entities. This approach allows all mentions of an entity to serve
as â€œclass prototypesâ€ as inference involves retrieving from the full set of
labeled entity mentions in the training set and applying the nearest mention
neighborâ€™s entity label. Our model is trained on a large multilingual corpus of
mention pairs derived from Wikipedia hyperlinks, and performs nearest neighbor
inference on an index of 700 million mentions. It is simpler to train, gives
more interpretable predictions, and outperforms all other systems on two
multilingual entity linking benchmarks.</p>
</td>
    <td>
      
        ACL 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/zhao2021feature/">A Feature Consistency Driven Attention Erasing Network For Fine-grained Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Feature Consistency Driven Attention Erasing Network For Fine-grained Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Feature Consistency Driven Attention Erasing Network For Fine-grained Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhao et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Pattern Recognition</td>
    <td>20</td>
    <td><p>Large-scale fine-grained image retrieval has two main problems. First, low
dimensional feature embedding can fasten the retrieval process but bring
accuracy reduce due to overlooking the feature of significant attention regions
of images in fine-grained datasets. Second, fine-grained images lead to the
same category query hash codes mapping into the different cluster in database
hash latent space. To handle these two issues, we propose a feature consistency
driven attention erasing network (FCAENet) for fine-grained image retrieval.
For the first issue, we propose an adaptive augmentation module in FCAENet,
which is selective region erasing module (SREM). SREM makes the network more
robust on subtle differences of fine-grained task by adaptively covering some
regions of raw images. The feature extractor and hash layer can learn more
representative hash code for fine-grained images by SREM. With regard to the
second issue, we fully exploit the pair-wise similarity information and add the
enhancing space relation loss (ESRL) in FCAENet to make the vulnerable relation
stabler between the query hash code and database hash code. We conduct
extensive experiments on five fine-grained benchmark datasets (CUB2011,
Aircraft, NABirds, VegFru, Food101) for 12bits, 24bits, 32bits, 48bits hash
code. The results show that FCAENet achieves the state-of-the-art (SOTA)
fine-grained retrieval performance compared with other methods.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        CVPR 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/fang2021combating/">Combating Ambiguity For Hash-code Learning In Medical Instance Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Combating Ambiguity For Hash-code Learning In Medical Instance Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Combating Ambiguity For Hash-code Learning In Medical Instance Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Fang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Journal of Biomedical and Health Informatics</td>
    <td>10</td>
    <td><p>When encountering a dubious diagnostic case, medical instance retrieval can
help radiologists make evidence-based diagnoses by finding images containing
instances similar to a query case from a large image database. The similarity
between the query case and retrieved similar cases is determined by visual
features extracted from pathologically abnormal regions. However, the
manifestation of these regions often lacks specificity, i.e., different
diseases can have the same manifestation, and different manifestations may
occur at different stages of the same disease. To combat the manifestation
ambiguity in medical instance retrieval, we propose a novel deep framework
called Y-Net, encoding images into compact hash-codes generated from
convolutional features by feature aggregation. Y-Net can learn highly
discriminative convolutional features by unifying the pixel-wise segmentation
loss and classification loss. The segmentation loss allows exploring subtle
spatial differences for good spatial-discriminability while the classification
loss utilizes class-aware semantic information for good semantic-separability.
As a result, Y-Net can enhance the visual features in pathologically abnormal
regions and suppress the disturbing of the background during model training,
which could effectively embed discriminative features into the hash-codes in
the retrieval stage. Extensive experiments on two medical image datasets
demonstrate that Y-Net can alleviate the ambiguity of pathologically abnormal
regions and its retrieval performance outperforms the state-of-the-art method
by an average of 9.27% on the returned list of 10.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        ALT 
      
        Tools & Libraries 
      
        Alt 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/fang2021deep/">Deep Triplet Hashing Network For Case-based Medical Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Triplet Hashing Network For Case-based Medical Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Triplet Hashing Network For Case-based Medical Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Fang Jiansheng, Fu Huazhu, Liu Jiang</td> <!-- ðŸ”§ You were missing this -->
    <td>Medical Image Analysis</td>
    <td>50</td>
    <td><p>Deep hashing methods have been shown to be the most efficient approximate
nearest neighbor search techniques for large-scale image retrieval. However,
existing deep hashing methods have a poor small-sample ranking performance for
case-based medical image retrieval. The top-ranked images in the returned query
results may be as a different class than the query image. This ranking problem
is caused by classification, regions of interest (ROI), and small-sample
information loss in the hashing space. To address the ranking problem, we
propose an end-to-end framework, called Attention-based Triplet Hashing (ATH)
network, to learn low-dimensional hash codes that preserve the classification,
ROI, and small-sample information. We embed a spatial-attention module into the
network structure of our ATH to focus on ROI information. The spatial-attention
module aggregates the spatial information of feature maps by utilizing
max-pooling, element-wise maximum, and element-wise mean operations jointly
along the channel axis. The triplet cross-entropy loss can help to map the
classification information of images and similarity between images into the
hash codes. Extensive experiments on two case-based medical datasets
demonstrate that our proposed ATH can further improve the retrieval performance
compared to the state-of-the-art deep hashing methods and boost the ranking
performance for small samples. Compared to the other loss methods, the triplet
cross-entropy loss can enhance the classification performance and hash
code-discriminability</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Neural Hashing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/esser2021faster/">A Faster Algorithm For Finding Closest Pairs In Hamming Metric</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Faster Algorithm For Finding Closest Pairs In Hamming Metric' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Faster Algorithm For Finding Closest Pairs In Hamming Metric' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Esser Andre, KÃ¼bler Robert, Zweydinger Floyd</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 1st Workshop on New Trends in Similarity Search</td>
    <td>7</td>
    <td><p>We study the Closest Pair Problem in Hamming metric, which asks to find the
pair with the smallest Hamming distance in a collection of binary vectors. We
give a new randomized algorithm for the problem on uniformly random input
outperforming previous approaches whenever the dimension of input points is
small compared to the dataset size. For moderate to large dimensions, our
algorithm matches the time complexity of the previously best-known locality
sensitive hashing based algorithms. Technically our algorithm follows similar
design principles as Dubiner (IEEE Trans. Inf. Theory 2010) and May-Ozerov
(Eurocrypt 2015). Besides improving the time complexity in the aforementioned
areas, we significantly simplify the analysis of these previous works. We give
a modular analysis, which allows us to investigate the performance of the
algorithm also on non-uniform input distributions. Furthermore, we give a proof
of concept implementation of our algorithm which performs well in comparison to
a quadratic search baseline. This is the first step towards answering an open
question raised by May and Ozerov regarding the practicability of algorithms
following these design principles.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Graph Based ANN 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/maziarz2021hashing/">Hashing Modulo Alpha-equivalence</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hashing Modulo Alpha-equivalence' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hashing Modulo Alpha-equivalence' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Maziarz et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation</td>
    <td>7</td>
    <td><p>In many applications one wants to identify identical subtrees of a program
syntax tree. This identification should ideally be robust to alpha-renaming of
the program, but no existing technique has been shown to achieve this with good
efficiency (better than \(\mathcal{O}(n^2)\) in expression size). We present a
new, asymptotically efficient way to hash modulo alpha-equivalence. A key
insight of our method is to use a weak (commutative) hash combiner at exactly
one point in the construction, which admits an algorithm with \(\mathcal{O}(n
(log n)^2)\) time complexity. We prove that the use of the commutative combiner
nevertheless yields a strong hash with low collision probability. Numerical
benchmarks attest to the asymptotic behaviour of the method.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/xiao2021neural/">Neural Pathsim For Inductive Similarity Search In Heterogeneous Information Networks</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Neural Pathsim For Inductive Similarity Search In Heterogeneous Information Networks' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Neural Pathsim For Inductive Similarity Search In Heterogeneous Information Networks' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Xiao et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management</td>
    <td>7</td>
    <td><p>PathSim is a widely used meta-path-based similarity in heterogeneous
information networks. Numerous applications rely on the computation of PathSim,
including similarity search and clustering. Computing PathSim scores on large
graphs is computationally challenging due to its high time and storage
complexity. In this paper, we propose to transform the problem of approximating
the ground truth PathSim scores into a learning problem. We design an
encoder-decoder based framework, NeuPath, where the algorithmic structure of
PathSim is considered. Specifically, the encoder module identifies Top T
optimized path instances, which can approximate the ground truth PathSim, and
maps each path instance to an embedding vector. The decoder transforms each
embedding vector into a scalar respectively, which identifies the similarity
score. We perform extensive experiments on two real-world datasets in different
domains, ACM and IMDB. Our results demonstrate that NeuPath performs better
than state-of-the-art baselines in the PathSim approximation task and
similarity search task.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        CIKM 
      
        Similarity Search 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/ma2021rank/">Rank-consistency Deep Hashing For Scalable Multi-label Image Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Rank-consistency Deep Hashing For Scalable Multi-label Image Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Rank-consistency Deep Hashing For Scalable Multi-label Image Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ma Cheng, Lu Jiwen, Zhou Jie</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Multimedia</td>
    <td>14</td>
    <td><p>As hashing becomes an increasingly appealing technique for large-scale image
retrieval, multi-label hashing is also attracting more attention for the
ability to exploit multi-level semantic contents. In this paper, we propose a
novel deep hashing method for scalable multi-label image search. Unlike
existing approaches with conventional objectives such as contrast and triplet
losses, we employ a rank list, rather than pairs or triplets, to provide
sufficient global supervision information for all the samples. Specifically, a
new rank-consistency objective is applied to align the similarity orders from
two spaces, the original space and the hamming space. A powerful loss function
is designed to penalize the samples whose semantic similarity and hamming
distance are mismatched in two spaces. Besides, a multi-label softmax
cross-entropy loss is presented to enhance the discriminative power with a
concise formulation of the derivative function. In order to manipulate the
neighborhood structure of the samples with different labels, we design a
multi-label clustering loss to cluster the hashing vectors of the samples with
the same labels by reducing the distances between the samples and their
multiple corresponding class centers. The state-of-the-art experimental results
achieved on three public multi-label datasets, MIRFLICKR-25K, IAPRTC12 and
NUS-WIDE, demonstrate the effectiveness of the proposed method.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Neural Hashing 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/macdonald2021approximate/">On Approximate Nearest Neighbour Selection For Multi-stage Dense Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=On Approximate Nearest Neighbour Selection For Multi-stage Dense Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=On Approximate Nearest Neighbour Selection For Multi-stage Dense Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Macdonald Craig, Tonellotto Nicola</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management</td>
    <td>14</td>
    <td><p>Dense retrieval, which describes the use of contextualised language models
such as BERT to identify documents from a collection by leveraging approximate
nearest neighbour (ANN) techniques, has been increasing in popularity. Two
families of approaches have emerged, depending on whether documents and queries
are represented by single or multiple embeddings. ColBERT, the exemplar of the
latter, uses an ANN index and approximate scores to identify a set of candidate
documents for each query embedding, which are then re-ranked using accurate
document representations. In this manner, a large number of documents can be
retrieved for each query, hindering the efficiency of the approach. In this
work, we investigate the use of ANN scores for ranking the candidate documents,
in order to decrease the number of candidate documents being fully scored.
Experiments conducted on the MSMARCO passage ranking corpus demonstrate that,
by cutting of the candidate set by using the approximate scores to only 200
documents, we can still obtain an effective ranking without statistically
significant differences in effectiveness, and resulting in a 2x speedup in
efficiency.</p>
</td>
    <td>
      
        Efficiency And Optimization 
      
        Vector Indexing 
      
        CIKM 
      
        Similarity Search 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/zhang2021moon/">MOON: Multi-hash Codes Joint Learning For Cross-media Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=MOON: Multi-hash Codes Joint Learning For Cross-media Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=MOON: Multi-hash Codes Joint Learning For Cross-media Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Pattern Recognition Letters</td>
    <td>10</td>
    <td><p>In recent years, cross-media hashing technique has attracted increasing
attention for its high computation efficiency and low storage cost. However,
the existing approaches still have some limitations, which need to be explored.
1) A fixed hash length (e.g., 16bits or 32bits) is predefined before learning
the binary codes. Therefore, these models need to be retrained when the hash
length changes, that consumes additional computation power, reducing the
scalability in practical applications. 2) Existing cross-modal approaches only
explore the information in the original multimedia data to perform the hash
learning, without exploiting the semantic information contained in the learned
hash codes. To this end, we develop a novel Multiple hash cOdes jOint learNing
method (MOON) for cross-media retrieval. Specifically, the developed MOON
synchronously learns the hash codes with multiple lengths in a unified
framework. Besides, to enhance the underlying discrimination, we combine the
clues from the multimodal data, semantic labels and learned hash codes for hash
learning. As far as we know, the proposed MOON is the first work to
simultaneously learn different length hash codes without retraining in
cross-media retrieval. Experiments on several databases show that our MOON can
achieve promising performance, outperforming some recent competitive shallow
and deep methods.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/wang2021cross/">Cross-modal Zero-shot Hashing By Label Attributes Embedding</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Cross-modal Zero-shot Hashing By Label Attributes Embedding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Cross-modal Zero-shot Hashing By Label Attributes Embedding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>5</td>
    <td><p>Cross-modal hashing (CMH) is one of the most promising methods in cross-modal
approximate nearest neighbor search. Most CMH solutions ideally assume the
labels of training and testing set are identical. However, the assumption is
often violated, causing a zero-shot CMH problem. Recent efforts to address this
issue focus on transferring knowledge from the seen classes to the unseen ones
using label attributes. However, the attributes are isolated from the features
of multi-modal data. To reduce the information gap, we introduce an approach
called LAEH (Label Attributes Embedding for zero-shot cross-modal Hashing).
LAEH first gets the initial semantic attribute vectors of labels by word2vec
model and then uses a transformation network to transform them into a common
subspace. Next, it leverages the hash vectors and the feature similarity matrix
to guide the feature extraction network of different modalities. At the same
time, LAEH uses the attribute similarity as the supplement of label similarity
to rectify the label embedding and common subspace. Experiments show that LAEH
outperforms related representative zero-shot and cross-modal hashing methods.</p>
</td>
    <td>
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/lu2021learnable/">Learnable Locality-sensitive Hashing For Video Anomaly Detection</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learnable Locality-sensitive Hashing For Video Anomaly Detection' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learnable Locality-sensitive Hashing For Video Anomaly Detection' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lu Yue, Cao Congqi, Zhang Yanning</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Circuits and Systems for Video Technology</td>
    <td>23</td>
    <td><p>Video anomaly detection (VAD) mainly refers to identifying anomalous events
that have not occurred in the training set where only normal samples are
available. Existing works usually formulate VAD as a reconstruction or
prediction problem. However, the adaptability and scalability of these methods
are limited. In this paper, we propose a novel distance-based VAD method to
take advantage of all the available normal data efficiently and flexibly. In
our method, the smaller the distance between a testing sample and normal
samples, the higher the probability that the testing sample is normal.
Specifically, we propose to use locality-sensitive hashing (LSH) to map samples
whose similarity exceeds a certain threshold into the same bucket in advance.
In this manner, the complexity of near neighbor search is cut down
significantly. To make the samples that are semantically similar get closer and
samples not similar get further apart, we propose a novel learnable version of
LSH that embeds LSH into a neural network and optimizes the hash functions with
contrastive learning strategy. The proposed method is robust to data imbalance
and can handle the large intra-class variations in normal data flexibly.
Besides, it has a good ability of scalability. Extensive experiments
demonstrate the superiority of our method, which achieves new state-of-the-art
results on VAD benchmarks.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/xu2021hhf/">HHF: Hashing-guided Hinge Function For Deep Hashing Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=HHF: Hashing-guided Hinge Function For Deep Hashing Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=HHF: Hashing-guided Hinge Function For Deep Hashing Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Xu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Multimedia</td>
    <td>13</td>
    <td><p>Deep hashing has shown promising performance in large-scale image retrieval.
However, latent codes extracted by Deep Neural Networks (DNNs) will inevitably
lose semantic information during the binarization process, which damages the
retrieval accuracy and makes it challenging. Although many existing approaches
perform regularization to alleviate quantization errors, we figure out an
incompatible conflict between metric learning and quantization learning. The
metric loss penalizes the inter-class distances to push different classes
unconstrained far away. Worse still, it tends to map the latent code deviate
from ideal binarization point and generate severe ambiguity in the binarization
process. Based on the minimum distance of the binary linear code, we creatively
propose Hashing-guided Hinge Function (HHF) to avoid such conflict. In detail,
the carefully-designed inflection point, which relies on the hash bit length
and category numbers, is explicitly adopted to balance the metric term and
quantization term. Such a modification prevents the network from falling into
local metric optimal minima in deep hashing. Extensive experiments in CIFAR-10,
CIFAR-100, ImageNet, and MS-COCO show that HHF consistently outperforms
existing techniques, and is robust and flexible to transplant into other
methods. Code is available at https://github.com/JerryXu0129/HHF.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        Alt 
      
        Neural Hashing 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/torres2021compact/">Compact And Effective Representations For Sketch-based Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Compact And Effective Representations For Sketch-based Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Compact And Effective Representations For Sketch-based Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Torres Pablo, Saavedra Jose M.</td> <!-- ðŸ”§ You were missing this -->
    <td>2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</td>
    <td>12</td>
    <td><p>Sketch-based image retrieval (SBIR) has undergone an increasing interest in
the community of computer vision bringing high impact in real applications. For
instance, SBIR brings an increased benefit to eCommerce search engines because
it allows users to formulate a query just by drawing what they need to buy.
However, current methods showing high precision in retrieval work in a high
dimensional space, which negatively affects aspects like memory consumption and
time processing. Although some authors have also proposed compact
representations, these drastically degrade the performance in a low dimension.
Therefore in this work, we present different results of evaluating methods for
producing compact embeddings in the context of sketch-based image retrieval.
Our main interest is in strategies aiming to keep the local structure of the
original space. The recent unsupervised local-topology preserving dimension
reduction method UMAP fits our requirements and shows outstanding performance,
improving even the precision achieved by SOTA methods. We evaluate six methods
in two different datasets. We use Flickr15K and eCommerce datasets; the latter
is another contribution of this work. We show that UMAP allows us to have
feature vectors of 16 bytes improving precision by more than 35%.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        CVPR 
      
        Alt 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/liu2021fddh/">FDDH: Fast Discriminative Discrete Hashing For Large-scale Cross-modal Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=FDDH: Fast Discriminative Discrete Hashing For Large-scale Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=FDDH: Fast Discriminative Discrete Hashing For Large-scale Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu Xin, Wang Xingzhi, Cheung Yiu-ming</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Neural Networks and Learning Systems</td>
    <td>49</td>
    <td><p>Cross-modal hashing, favored for its effectiveness and efficiency, has
received wide attention to facilitating efficient retrieval across different
modalities. Nevertheless, most existing methods do not sufficiently exploit the
discriminative power of semantic information when learning the hash codes,
while often involving time-consuming training procedure for handling the
large-scale dataset. To tackle these issues, we formulate the learning of
similarity-preserving hash codes in terms of orthogonally rotating the semantic
data so as to minimize the quantization loss of mapping such data to hamming
space, and propose an efficient Fast Discriminative Discrete Hashing (FDDH)
approach for large-scale cross-modal retrieval. More specifically, FDDH
introduces an orthogonal basis to regress the targeted hash codes of training
examples to their corresponding semantic labels, and utilizes â€œ-dragging
technique to provide provable large semantic margins. Accordingly, the
discriminative power of semantic information can be explicitly captured and
maximized. Moreover, an orthogonal transformation scheme is further proposed to
map the nonlinear embedding data into the semantic subspace, which can well
guarantee the semantic consistency between the data feature and its semantic
representation. Consequently, an efficient closed form solution is derived for
discriminative hash code learning, which is very computationally efficient. In
addition, an effective and stable online learning strategy is presented for
optimizing modality-specific projection functions, featuring adaptivity to
different training sizes and streaming data. The proposed FDDH approach
theoretically approximates the bi-Lipschitz continuity, runs sufficiently fast,
and also significantly improves the retrieval performance over the
state-of-the-art methods. The source code is released at:
https://github.com/starxliu/FDDH.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Multimodal Retrieval 
      
        Similarity Search 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/lin2021deep/">Deep Self-adaptive Hashing For Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Self-adaptive Hashing For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Self-adaptive Hashing For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lin et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management</td>
    <td>8</td>
    <td><p>Hashing technology has been widely used in image retrieval due to its
computational and storage efficiency. Recently, deep unsupervised hashing
methods have attracted increasing attention due to the high cost of human
annotations in the real world and the superiority of deep learning technology.
However, most deep unsupervised hashing methods usually pre-compute a
similarity matrix to model the pairwise relationship in the pre-trained feature
space. Then this similarity matrix would be used to guide hash learning, in
which most of the data pairs are treated equivalently. The above process is
confronted with the following defects: 1) The pre-computed similarity matrix is
inalterable and disconnected from the hash learning process, which cannot
explore the underlying semantic information. 2) The informative data pairs may
be buried by the large number of less-informative data pairs. To solve the
aforementioned problems, we propose a Deep Self-Adaptive Hashing (DSAH) model
to adaptively capture the semantic information with two special designs:
Adaptive Neighbor Discovery (AND) and Pairwise Information Content (PIC).
Firstly, we adopt the AND to initially construct a neighborhood-based
similarity matrix, and then refine this initial similarity matrix with a novel
update strategy to further investigate the semantic structure behind the
learned representation. Secondly, we measure the priorities of data pairs with
PIC and assign adaptive weights to them, which is relies on the assumption that
more dissimilar data pairs contain more discriminative information for hash
learning. Extensive experiments on several datasets demonstrate that the above
two technologies facilitate the deep hashing model to achieve superior
performance.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        Neural Hashing 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        CIKM 
      
        Image Retrieval 
      
        Alt 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/zhang2021joint/">Joint Learning Of Deep Retrieval Model And Product Quantization Based Embedding Index</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Joint Learning Of Deep Retrieval Model And Product Quantization Based Embedding Index' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Joint Learning Of Deep Retrieval Model And Product Quantization Based Embedding Index' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</td>
    <td>6</td>
    <td><p>Embedding index that enables fast approximate nearest neighbor(ANN) search,
serves as an indispensable component for state-of-the-art deep retrieval
systems. Traditional approaches, often separating the two steps of embedding
learning and index building, incur additional indexing time and decayed
retrieval accuracy. In this paper, we propose a novel method called Poeem,
which stands for product quantization based embedding index jointly trained
with deep retrieval model, to unify the two separate steps within an end-to-end
training, by utilizing a few techniques including the gradient straight-through
estimator, warm start strategy, optimal space decomposition and Givens
rotation. Extensive experimental results show that the proposed method not only
improves retrieval accuracy significantly but also reduces the indexing time to
almost none. We have open sourced our approach for the sake of comparison and
reproducibility.</p>
</td>
    <td>
      
        Vector Indexing 
      
        Quantization 
      
        SIGIR 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/singh2021freshdiskann/">Freshdiskann: A Fast And Accurate Graph-based ANN Index For Streaming Similarity Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Freshdiskann: A Fast And Accurate Graph-based ANN Index For Streaming Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Freshdiskann: A Fast And Accurate Graph-based ANN Index For Streaming Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Singh et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>10</td>
    <td><p>Approximate nearest neighbor search (ANNS) is a fundamental building block in
information retrieval with graph-based indices being the current
state-of-the-art and widely used in the industry. Recent advances in
graph-based indices have made it possible to index and search billion-point
datasets with high recall and millisecond-level latency on a single commodity
machine with an SSD.
  However, existing graph algorithms for ANNS support only static indices that
cannot reflect real-time changes to the corpus required by many key real-world
scenarios (e.g. index of sentences in documents, email, or a news index). To
overcome this drawback, the current industry practice for manifesting updates
into such indices is to periodically re-build these indices, which can be
prohibitively expensive.
  In this paper, we present the first graph-based ANNS index that reflects
corpus updates into the index in real-time without compromising on search
performance. Using update rules for this index, we design FreshDiskANN, a
system that can index over a billion points on a workstation with an SSD and
limited memory, and support thousands of concurrent real-time inserts, deletes
and searches per second each, while retaining \(&gt;95%\) 5-recall@5. This
represents a 5-10x reduction in the cost of maintaining freshness in indices
when compared to existing methods.</p>
</td>
    <td>
      
        DATASETS 
      
        Graph Based ANN 
      
        Efficiency And Optimization 
      
        Similarity Search 
      
        Vector Indexing 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/yan2021binary/">Binary Code Based Hash Embedding For Web-scale Applications</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Binary Code Based Hash Embedding For Web-scale Applications' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Binary Code Based Hash Embedding For Web-scale Applications' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yan et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management</td>
    <td>10</td>
    <td><p>Nowadays, deep learning models are widely adopted in web-scale applications
such as recommender systems, and online advertising. In these applications,
embedding learning of categorical features is crucial to the success of deep
learning models. In these models, a standard method is that each categorical
feature value is assigned a unique embedding vector which can be learned and
optimized. Although this method can well capture the characteristics of the
categorical features and promise good performance, it can incur a huge memory
cost to store the embedding table, especially for those web-scale applications.
Such a huge memory cost significantly holds back the effectiveness and
usability of EDRMs. In this paper, we propose a binary code based hash
embedding method which allows the size of the embedding table to be reduced in
arbitrary scale without compromising too much performance. Experimental
evaluation results show that one can still achieve 99% performance even if the
embedding table size is reduced 1000\(\times\) smaller than the original one with
our proposed method.</p>
</td>
    <td>
      
        Evaluation 
      
        Recommender Systems 
      
        Large Scale Search 
      
        Compact Codes 
      
        CIKM 
      
        Alt 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/zhang2021visual/">Visual Search At Alibaba</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Visual Search At Alibaba' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Visual Search At Alibaba' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</td>
    <td>58</td>
    <td><p>This paper introduces the large scale visual search algorithm and system
infrastructure at Alibaba. The following challenges are discussed under the
E-commercial circumstance at Alibaba (a) how to handle heterogeneous image data
and bridge the gap between real-shot images from user query and the online
images. (b) how to deal with large scale indexing for massive updating data.
(c) how to train deep models for effective feature representation without huge
human annotations. (d) how to improve the user engagement by considering the
quality of the content. We take advantage of large image collection of Alibaba
and state-of-the-art deep learning techniques to perform visual search at
scale. We present solutions and implementation details to overcome those
problems and also share our learnings from building such a large scale
commercial visual search engine. Specifically, model and search-based fusion
approach is introduced to effectively predict categories. Also, we propose a
deep CNN model for joint detection and feature learning by mining user click
behavior. The binary index engine is designed to scale up indexing without
compromising recall and precision. Finally, we apply all the stages into an
end-to-end system architecture, which can simultaneously achieve highly
efficient and scalable performance adapting to real-shot images. Extensive
experiments demonstrate the advancement of each module in our system. We hope
visual search at Alibaba becomes more widely incorporated into todayâ€™s
commercial applications.</p>
</td>
    <td>
      
        KDD 
      
        Image Retrieval 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/vasudeva2021loop/">Loop: Looking For Optimal Hard Negative Embeddings For Deep Metric Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Loop: Looking For Optimal Hard Negative Embeddings For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Loop: Looking For Optimal Hard Negative Embeddings For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Vasudeva et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2021 IEEE/CVF International Conference on Computer Vision (ICCV)</td>
    <td>12</td>
    <td><p>Deep metric learning has been effectively used to learn distance metrics for
different visual tasks like image retrieval, clustering, etc. In order to aid
the training process, existing methods either use a hard mining strategy to
extract the most informative samples or seek to generate hard synthetics using
an additional network. Such approaches face different challenges and can lead
to biased embeddings in the former case, and (i) harder optimization (ii)
slower training speed (iii) higher model complexity in the latter case. In
order to overcome these challenges, we propose a novel approach that looks for
optimal hard negatives (LoOp) in the embedding space, taking full advantage of
each tuple by calculating the minimum distance between a pair of positives and
a pair of negatives. Unlike mining-based methods, our approach considers the
entire space between pairs of embeddings to calculate the optimal hard
negatives. Extensive experiments combining our approach and representative
metric learning losses reveal a significant boost in performance on three
benchmark datasets.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Distance Metric Learning 
      
        ICCV 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/li2021extra/">EXTRA: Explanation Ranking Datasets For Explainable Recommendation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=EXTRA: Explanation Ranking Datasets For Explainable Recommendation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=EXTRA: Explanation Ranking Datasets For Explainable Recommendation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li Lei, Zhang Yongfeng, Chen Li</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</td>
    <td>29</td>
    <td><p>Recently, research on explainable recommender systems has drawn much
attention from both academia and industry, resulting in a variety of
explainable models. As a consequence, their evaluation approaches vary from
model to model, which makes it quite difficult to compare the explainability of
different models. To achieve a standard way of evaluating recommendation
explanations, we provide three benchmark datasets for EXplanaTion RAnking
(denoted as EXTRA), on which explainability can be measured by ranking-oriented
metrics. Constructing such datasets, however, poses great challenges. First,
user-item-explanation triplet interactions are rare in existing recommender
systems, so how to find alternatives becomes a challenge. Our solution is to
identify nearly identical sentences from user reviews. This idea then leads to
the second challenge, i.e., how to efficiently categorize the sentences in a
dataset into different groups, since it has quadratic runtime complexity to
estimate the similarity between any two sentences. To mitigate this issue, we
provide a more efficient method based on Locality Sensitive Hashing (LSH) that
can detect near-duplicates in sub-linear time for a given query. Moreover, we
make our code publicly available to allow researchers in the community to
create their own datasets.</p>
</td>
    <td>
      
        Survey Paper 
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Alt 
      
        Recommender Systems 
      
        SIGIR 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/li2021c/">C-minhash: Practically Reducing Two Permutations To Just One</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=C-minhash: Practically Reducing Two Permutations To Just One' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=C-minhash: Practically Reducing Two Permutations To Just One' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li Xiaoyun, Li Ping</td> <!-- ðŸ”§ You were missing this -->
    <td>Journal of Combinatorial Theory, Series A</td>
    <td>5</td>
    <td><p>Traditional minwise hashing (MinHash) requires applying \(K\) independent
permutations to estimate the Jaccard similarity in massive binary (0/1) data,
where \(K\) can be (e.g.,) 1024 or even larger, depending on applications. The
recent work on C-MinHash (Li and Li, 2021) has shown, with rigorous proofs,
that only two permutations are needed. An initial permutation is applied to
break whatever structures which might exist in the data, and a second
permutation is re-used \(K\) times to produce \(K\) hashes, via a circulant
shifting fashion. (Li and Li, 2021) has proved that, perhaps surprisingly, even
though the \(K\) hashes are correlated, the estimation variance is strictly
smaller than the variance of the traditional MinHash.
  It has been demonstrated in (Li and Li, 2021) that the initial permutation in
C-MinHash is indeed necessary. For the ease of theoretical analysis, they have
used two independent permutations. In this paper, we show that one can actually
simply use one permutation. That is, one single permutation is used for both
the initial pre-processing step to break the structures in the data and the
circulant hashing step to generate \(K\) hashes. Although the theoretical
analysis becomes very complicated, we are able to explicitly write down the
expression for the expectation of the estimator. The new estimator is no longer
unbiased but the bias is extremely small and has essentially no impact on the
estimation accuracy (mean square errors). An extensive set of experiments are
provided to verify our claim for using just one permutation.</p>
</td>
    <td>
      
        Alt 
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/li2021ce/">Ce-dedup: Cost-effective Convolutional Neural Nets Training Based On Image Deduplication</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Ce-dedup: Cost-effective Convolutional Neural Nets Training Based On Image Deduplication' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Ce-dedup: Cost-effective Convolutional Neural Nets Training Based On Image Deduplication' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li Xuan, Chang Liqiong, Liu Xue</td> <!-- ðŸ”§ You were missing this -->
    <td>2021 IEEE Intl Conf on Parallel &amp; Distributed Processing with Applications, Big Data &amp; Cloud Computing, Sustainable Computing &amp; Communications, Social Computing &amp; Networking (ISPA/BDCloud/SocialCom/SustainCom)</td>
    <td>5</td>
    <td><p>Attributed to the ever-increasing large image datasets, Convolutional Neural
Networks (CNNs) have become popular for vision-based tasks. It is generally
admirable to have larger-sized datasets for higher network training accuracies.
However, the impact of dataset quality has not to be involved. It is reasonable
to assume the near-duplicate images exist in the datasets. For instance, the
Street View House Numbers (SVHN) dataset having cropped house plate digits from
0 to 9 are likely to have repetitive digits from the same/similar house plates.
Redundant images may take up a certain portion of the dataset without
consciousness. While contributing little to no accuracy improvement for the
CNNs training, these duplicated images unnecessarily pose extra resource and
computation consumption. To this end, this paper proposes a framework to assess
the impact of the near-duplicate images on CNN training performance, called
CE-Dedup. Specifically, CE-Dedup associates a hashing-based image deduplication
approach with downstream CNNs-based image classification tasks. CE-Dedup
balances the tradeoff between a large deduplication ratio and a stable accuracy
by adjusting the deduplication threshold. The effectiveness of CE-Dedup is
validated through extensive experiments on well-known CNN benchmarks. On one
hand, while maintaining the same validation accuracy, CE-Dedup can reduce the
dataset size by 23%. On the other hand, when allowing a small validation
accuracy drop (by 5%), CE-Dedup can trim the dataset size by 75%.</p>
</td>
    <td>
      
        DATASETS 
      
        Tools & Libraries 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/li2021more/">More Robust Dense Retrieval With Contrastive Dual Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=More Robust Dense Retrieval With Contrastive Dual Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=More Robust Dense Retrieval With Contrastive Dual Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 2021 ACM SIGIR International Conference on Theory of Information Retrieval</td>
    <td>23</td>
    <td><p>Dense retrieval conducts text retrieval in the embedding space and has shown
many advantages compared to sparse retrieval. Existing dense retrievers
optimize representations of queries and documents with contrastive training and
map them to the embedding space. The embedding space is optimized by aligning
the matched query-document pairs and pushing the negative documents away from
the query. However, in such training paradigm, the queries are only optimized
to align to the documents and are coarsely positioned, leading to an
anisotropic query embedding space. In this paper, we analyze the embedding
space distributions and propose an effective training paradigm, Contrastive
Dual Learning for Approximate Nearest Neighbor (DANCE) to learn fine-grained
query representations for dense retrieval. DANCE incorporates an additional
dual training object of query retrieval, inspired by the classic information
retrieval training axiom, query likelihood. With contrastive learning, the dual
training object of DANCE learns more tailored representations for queries and
documents to keep the embedding space smooth and uniform, thriving on the
ranking performance of DANCE on the MS MARCO document retrieval task. Different
from ANCE that only optimized with the document retrieval task, DANCE
concentrates the query embeddings closer to document representations while
making the document distribution more discriminative. Such concentrated query
embedding distribution assigns more uniform negative sampling probabilities to
queries and helps to sufficiently optimize query representations in the query
retrieval task. Our codes are released at https://github.com/thunlp/DANCE.</p>
</td>
    <td>
      
        Text Retrieval 
      
        SIGIR 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/ufer2021object/">Object Retrieval And Localization In Large Art Collections Using Deep Multi-style Feature Fusion And Iterative Voting</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Object Retrieval And Localization In Large Art Collections Using Deep Multi-style Feature Fusion And Iterative Voting' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Object Retrieval And Localization In Large Art Collections Using Deep Multi-style Feature Fusion And Iterative Voting' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ufer Nikolai, Lang Sabine, Ommer BjÃ¶rn</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>8</td>
    <td><p>The search for specific objects or motifs is essential to art history as both
assist in decoding the meaning of artworks. Digitization has produced large art
collections, but manual methods prove to be insufficient to analyze them. In
the following, we introduce an algorithm that allows users to search for image
regions containing specific motifs or objects and find similar regions in an
extensive dataset, helping art historians to analyze large digitized art
collections. Computer vision has presented efficient methods for visual
instance retrieval across photographs. However, applied to art collections,
they reveal severe deficiencies because of diverse motifs and massive domain
shifts induced by differences in techniques, materials, and styles. In this
paper, we present a multi-style feature fusion approach that successfully
reduces the domain gap and improves retrieval results without labelled data or
curated image collections. Our region-based voting with GPU-accelerated
approximate nearest-neighbour search allows us to find and localize even small
motifs within an extensive dataset in a few seconds. We obtain state-of-the-art
results on the Brueghel dataset and demonstrate its generalization to
inhomogeneous collections with a large number of distractors.</p>
</td>
    <td>
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/tanaka2021fake/">Fake-image Detection With Robust Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fake-image Detection With Robust Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fake-image Detection With Robust Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Tanaka Miki, Kiya Hitoshi</td> <!-- ðŸ”§ You were missing this -->
    <td>2021 IEEE 3rd Global Conference on Life Sciences and Technologies (LifeTech)</td>
    <td>10</td>
    <td><p>In this paper, we investigate whether robust hashing has a possibility to
robustly detect fake-images even when multiple manipulation techniques such as
JPEG compression are applied to images for the first time. In an experiment,
the proposed fake detection with robust hashing is demonstrated to outperform
state-of-the-art one under the use of various datasets including fake images
generated with GANs.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/liu2021ternary/">Ternary Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Ternary Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Ternary Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Knowledge and Data Engineering</td>
    <td>35</td>
    <td><p>This paper proposes a novel ternary hash encoding for learning to hash
methods, which provides a principled more efficient coding scheme with
performances better than those of the state-of-the-art binary hashing
counterparts. Two kinds of axiomatic ternary logic, Kleene logic and
{\L}ukasiewicz logic are adopted to calculate the Ternary Hamming Distance
(THD) for both the learning/encoding and testing/querying phases. Our work
demonstrates that, with an efficient implementation of ternary logic on
standard binary machines, the proposed ternary hashing is compared favorably to
the binary hashing methods with consistent improvements of retrieval mean
average precision (mAP) ranging from 1% to 5.9% as shown in CIFAR10, NUS-WIDE
and ImageNet100 datasets.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/yamada2021efficient/">Efficient Passage Retrieval With Hashing For Open-domain Question Answering</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Efficient Passage Retrieval With Hashing For Open-domain Question Answering' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Efficient Passage Retrieval With Hashing For Open-domain Question Answering' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yamada Ikuya, Asai Akari, Hajishirzi Hannaneh</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)</td>
    <td>46</td>
    <td><p>Most state-of-the-art open-domain question answering systems use a neural
retrieval model to encode passages into continuous vectors and extract them
from a knowledge source. However, such retrieval models often require large
memory to run because of the massive size of their passage index. In this
paper, we introduce Binary Passage Retriever (BPR), a memory-efficient neural
retrieval model that integrates a learning-to-hash technique into the
state-of-the-art Dense Passage Retriever (DPR) to represent the passage index
using compact binary codes rather than continuous vectors. BPR is trained with
a multi-task objective over two tasks: efficient candidate generation based on
binary codes and accurate reranking based on continuous vectors. Compared with
DPR, BPR substantially reduces the memory cost from 65GB to 2GB without a loss
of accuracy on two standard open-domain question answering benchmarks: Natural
Questions and TriviaQA. Our code and trained models are available at
https://github.com/studio-ousia/bpr.</p>
</td>
    <td>
      
        Evaluation 
      
        Hashing Methods 
      
        ACL 
      
        Graph Based ANN 
      
        Compact Codes 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/lakshman2021embracing/">Embracing Structure In Data For Billion-scale Semantic Product Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Embracing Structure In Data For Billion-scale Semantic Product Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Embracing Structure In Data For Billion-scale Semantic Product Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lakshman et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</td>
    <td>56</td>
    <td><p>We present principled approaches to train and deploy dyadic neural embedding
models at the billion scale, focusing our investigation on the application of
semantic product search. When training a dyadic model, one seeks to embed two
different types of entities (e.g., queries and documents or users and movies)
in a common vector space such that pairs with high relevance are positioned
nearby. During inference, given an embedding of one type (e.g., a query or a
user), one seeks to retrieve the entities of the other type (e.g., documents or
movies, respectively) that are highly relevant. In this work, we show that
exploiting the natural structure of real-world datasets helps address both
challenges efficiently. Specifically, we model dyadic data as a bipartite graph
with edges between pairs with positive associations. We then propose to
partition this network into semantically coherent clusters and thus reduce our
search space by focusing on a small subset of these partitions for a given
input. During training, this technique enables us to efficiently mine hard
negative examples while, at inference, we can quickly find the nearest
neighbors for a given embedding. We provide offline experimental results that
demonstrate the efficacy of our techniques for both training and inference on a
billion-scale Amazon.com product search dataset.</p>
</td>
    <td>
      
        KDD 
      
        Large Scale Search 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/vaiwsri2021accurate/">Accurate And Efficient Suffix Tree Based Privacy-preserving String Matching</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Accurate And Efficient Suffix Tree Based Privacy-preserving String Matching' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Accurate And Efficient Suffix Tree Based Privacy-preserving String Matching' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Vaiwsri et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>International Journal of Data Science and Analytics</td>
    <td>7</td>
    <td><p>The task of calculating similarities between strings held by different
organizations without revealing these strings is an increasingly important
problem in areas such as health informatics, national censuses, genomics, and
fraud detection. Most existing privacy-preserving string comparison functions
are either based on comparing sets of encoded character q-grams, allow only
exact matching of encrypted strings, or they are aimed at long genomic
sequences that have a small alphabet. The set-based privacy-preserving
similarity functions commonly used to compare name and address strings in the
context of privacy-preserving record linkage do not take the positions of
sub-strings into account. As a result, two very different strings can
potentially be considered as an exact match leading to wrongly linked records.
Existing set-based techniques also cannot identify the length of the longest
common sub-string across two strings. In this paper we propose a novel approach
for accurate and efficient privacy-preserving string matching based on suffix
trees that are encoded using chained hashing. We incorporate a hashing based
encoding technique upon the encoded suffixes to improve privacy against
frequency attacks such as those exploiting Benfordâ€™s law. Our approach allows
various operations to be performed without the strings to be compared being
revealed: the length of the longest common sub-string, do two strings have the
same beginning, middle or end, and the longest common sub-string similarity
between two strings. These functions allow a more accurate comparison of, for
example, bank account, credit card, or telephone numbers, which cannot be
compared appropriately with existing privacy-preserving string matching
techniques. Our evaluation on several data sets with different types of strings
validates the privacy and accuracy of our proposed approach.</p>
</td>
    <td>
      
        Alt 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/patgiri2021deepbf/">Deepbf: Malicious URL Detection Using Learned Bloom Filter And Evolutionary Deep Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deepbf: Malicious URL Detection Using Learned Bloom Filter And Evolutionary Deep Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deepbf: Malicious URL Detection Using Learned Bloom Filter And Evolutionary Deep Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Patgiri Ripon, Biswas Anupam, Nayak Sabuzima</td> <!-- ðŸ”§ You were missing this -->
    <td>Computer Communications</td>
    <td>21</td>
    <td><p>Malicious URL detection is an emerging research area due to continuous
modernization of various systems, for instance, Edge Computing. In this
article, we present a novel malicious URL detection technique, called deepBF
(deep learning and Bloom Filter). deepBF is presented in two-fold. Firstly, we
propose a learned Bloom Filter using 2-dimensional Bloom Filter. We
experimentally decide the best non-cryptography string hash function. Then, we
derive a modified non-cryptography string hash function from the selected hash
function for deepBF by introducing biases in the hashing method and compared
among the string hash functions. The modified string hash function is compared
to other variants of diverse non-cryptography string hash functions. It is also
compared with various filters, particularly, counting Bloom Filter, Kirsch
\textit{et al.}, and Cuckoo Filter using various use cases. The use cases
unearth weakness and strength of the filters. Secondly, we propose a malicious
URL detection mechanism using deepBF. We apply the evolutionary convolutional
neural network to identify the malicious URLs. The evolutionary convolutional
neural network is trained and tested with malicious URL datasets. The output is
tested in deepBF for accuracy. We have achieved many conclusions from our
experimental evaluation and results and are able to reach various conclusive
decisions which are presented in the article.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/wu2021online/">Online Enhanced Semantic Hashing: Towards Effective And Efficient Retrieval For Streaming Multi-modal Data</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Online Enhanced Semantic Hashing: Towards Effective And Efficient Retrieval For Streaming Multi-modal Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Online Enhanced Semantic Hashing: Towards Effective And Efficient Retrieval For Streaming Multi-modal Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>5</td>
    <td><p>With the vigorous development of multimedia equipment and applications,
efficient retrieval of large-scale multi-modal data has become a trendy
research topic. Thereinto, hashing has become a prevalent choice due to its
retrieval efficiency and low storage cost. Although multi-modal hashing has
drawn lots of attention in recent years, there still remain some problems. The
first point is that existing methods are mainly designed in batch mode and not
able to efficiently handle streaming multi-modal data. The second point is that
all existing online multi-modal hashing methods fail to effectively handle
unseen new classes which come continuously with streaming data chunks. In this
paper, we propose a new model, termed Online enhAnced SemantIc haShing (OASIS).
We design novel semantic-enhanced representation for data, which could help
handle the new coming classes, and thereby construct the enhanced semantic
objective function. An efficient and effective discrete online optimization
algorithm is further proposed for OASIS. Extensive experiments show that our
method can exceed the state-of-the-art models. For good reproducibility and
benefiting the community, our code and data are already available in
supplementary material and will be made publicly available.</p>
</td>
    <td>
      
        AAAI 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Alt 
      
        Text Retrieval 
      
        Similarity Search 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/parravicini2021scaling/">Scaling Up HBM Efficiency Of Top-k Spmv For Approximate Embedding Similarity On Fpgas</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Scaling Up HBM Efficiency Of Top-k Spmv For Approximate Embedding Similarity On Fpgas' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Scaling Up HBM Efficiency Of Top-k Spmv For Approximate Embedding Similarity On Fpgas' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Parravicini et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2021 58th ACM/IEEE Design Automation Conference (DAC)</td>
    <td>9</td>
    <td><p>Top-K SpMV is a key component of similarity-search on sparse embeddings. This
sparse workload does not perform well on general-purpose NUMA systems that
employ traditional caching strategies. Instead, modern FPGA accelerator cards
have a few tricks up their sleeve. We introduce a Top-K SpMV FPGA design that
leverages reduced precision and a novel packet-wise CSR matrix compression,
enabling custom data layouts and delivering bandwidth efficiency often
unreachable even in architectures with higher peak bandwidth. With HBM-based
boards, we are 100x faster than a multi-threaded CPU implementation and 2x
faster than a GPU with 20% higher bandwidth, with 14.2x higher
power-efficiency.</p>
</td>
    <td>
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/patel2021recall/">Recall@k Surrogate Loss With Large Batches And Similarity Mixup</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Recall@k Surrogate Loss With Large Batches And Similarity Mixup' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Recall@k Surrogate Loss With Large Batches And Similarity Mixup' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Patel Yash, Tolias Giorgos, Matas Jiri</td> <!-- ðŸ”§ You were missing this -->
    <td>2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>28</td>
    <td><p>This work focuses on learning deep visual representation models for retrieval
by exploring the interplay between a new loss function, the batch size, and a
new regularization approach. Direct optimization, by gradient descent, of an
evaluation metric, is not possible when it is non-differentiable, which is the
case for recall in retrieval. A differentiable surrogate loss for the recall is
proposed in this work. Using an implementation that sidesteps the hardware
constraints of the GPU memory, the method trains with a very large batch size,
which is essential for metrics computed on the entire retrieval database. It is
assisted by an efficient mixup regularization approach that operates on
pairwise scalar similarities and virtually increases the batch size further.
The suggested method achieves state-of-the-art performance in several image
retrieval benchmarks when used for deep metric learning. For instance-level
recognition, the method outperforms similar approaches that train using an
approximation of average precision.</p>
</td>
    <td>
      
        CVPR 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/wang2021contrastive/">Contrastive Quantization With Code Memory For Unsupervised Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Contrastive Quantization With Code Memory For Unsupervised Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Contrastive Quantization With Code Memory For Unsupervised Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>23</td>
    <td><p>The high efficiency in computation and storage makes hashing (including
binary hashing and quantization) a common strategy in large-scale retrieval
systems. To alleviate the reliance on expensive annotations, unsupervised deep
hashing becomes an important research problem. This paper provides a novel
solution to unsupervised deep quantization, namely Contrastive Quantization
with Code Memory (MeCoQ). Different from existing reconstruction-based
strategies, we learn unsupervised binary descriptors by contrastive learning,
which can better capture discriminative visual semantics. Besides, we uncover
that codeword diversity regularization is critical to prevent contrastive
learning-based quantization from model degeneration. Moreover, we introduce a
novel quantization code memory module that boosts contrastive learning with
lower feature drift than conventional feature memories. Extensive experiments
on benchmark datasets show that MeCoQ outperforms state-of-the-art methods.
Code and configurations are publicly available at
https://github.com/gimpong/AAAI22-MeCoQ.</p>
</td>
    <td>
      
        Image Retrieval 
      
        AAAI 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/sanakoyeu2021improving/">Improving Deep Metric Learning By Divide And Conquer</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Improving Deep Metric Learning By Divide And Conquer' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Improving Deep Metric Learning By Divide And Conquer' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Sanakoyeu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Pattern Analysis and Machine Intelligence</td>
    <td>16</td>
    <td><p>Deep metric learning (DML) is a cornerstone of many computer vision
applications. It aims at learning a mapping from the input domain to an
embedding space, where semantically similar objects are located nearby and
dissimilar objects far from another. The target similarity on the training data
is defined by user in form of ground-truth class labels. However, while the
embedding space learns to mimic the user-provided similarity on the training
data, it should also generalize to novel categories not seen during training.
Besides user-provided groundtruth training labels, a lot of additional visual
factors (such as viewpoint changes or shape peculiarities) exist and imply
different notions of similarity between objects, affecting the generalization
on the images unseen during training. However, existing approaches usually
directly learn a single embedding space on all available training data,
struggling to encode all different types of relationships, and do not
generalize well. We propose to build a more expressive representation by
jointly splitting the embedding space and the data hierarchically into smaller
sub-parts. We successively focus on smaller subsets of the training data,
reducing its variance and learning a different embedding subspace for each data
subset. Moreover, the subspaces are learned jointly to cover not only the
intricacies, but the breadth of the data as well. Only after that, we build the
final embedding from the subspaces in the conquering stage. The proposed
algorithm acts as a transparent wrapper that can be placed around arbitrary
existing DML methods. Our approach significantly improves upon the
state-of-the-art on image retrieval, clustering, and re-identification tasks
evaluated using CUB200-2011, CARS196, Stanford Online Products, In-shop
Clothes, and PKU VehicleID datasets.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/nguyen2021oscar/">Oscar-net: Object-centric Scene Graph Attention For Image Attribution</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Oscar-net: Object-centric Scene Graph Attention For Image Attribution' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Oscar-net: Object-centric Scene Graph Attention For Image Attribution' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Nguyen et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2021 IEEE/CVF International Conference on Computer Vision (ICCV)</td>
    <td>14</td>
    <td><p>Images tell powerful stories but cannot always be trusted. Matching images
back to trusted sources (attribution) enables users to make a more informed
judgment of the images they encounter online. We propose a robust image hashing
algorithm to perform such matching. Our hash is sensitive to manipulation of
subtle, salient visual details that can substantially change the story told by
an image. Yet the hash is invariant to benign transformations (changes in
quality, codecs, sizes, shapes, etc.) experienced by images during online
redistribution. Our key contribution is OSCAR-Net (Object-centric Scene Graph
Attention for Image Attribution Network); a robust image hashing model inspired
by recent successes of Transformers in the visual domain. OSCAR-Net constructs
a scene graph representation that attends to fine-grained changes of every
objectâ€™s visual appearance and their spatial relationships. The network is
trained via contrastive learning on a dataset of original and manipulated
images yielding a state of the art image hash for content fingerprinting that
scales to millions of images.</p>
</td>
    <td>
      
        ICCV 
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/wu2021hashing/">Hashing-accelerated Graph Neural Networks For Link Prediction</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hashing-accelerated Graph Neural Networks For Link Prediction' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hashing-accelerated Graph Neural Networks For Link Prediction' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the Web Conference 2021</td>
    <td>30</td>
    <td><p>Networks are ubiquitous in the real world. Link prediction, as one of the key
problems for network-structured data, aims to predict whether there exists a
link between two nodes. The traditional approaches are based on the explicit
similarity computation between the compact node representation by embedding
each node into a low-dimensional space. In order to efficiently handle the
intensive similarity computation in link prediction, the hashing technique has
been successfully used to produce the node representation in the Hamming space.
However, the hashing-based link prediction algorithms face accuracy loss from
the randomized hashing techniques or inefficiency from the learning to hash
techniques in the embedding process. Currently, the Graph Neural Network (GNN)
framework has been widely applied to the graph-related tasks in an end-to-end
manner, but it commonly requires substantial computational resources and memory
costs due to massive parameter learning, which makes the GNN-based algorithms
impractical without the help of a powerful workhorse. In this paper, we propose
a simple and effective model called #GNN, which balances the trade-off between
accuracy and efficiency. #GNN is able to efficiently acquire node
representation in the Hamming space for link prediction by exploiting the
randomized hashing technique to implement message passing and capture
high-order proximity in the GNN framework. Furthermore, we characterize the
discriminative power of #GNN in probability. The extensive experimental results
demonstrate that the proposed #GNN algorithm achieves accuracy comparable to
the learning-based algorithms and outperforms the randomized algorithm, while
running significantly faster than the learning-based algorithms. Also, the
proposed algorithm shows excellent scalability on a large-scale network with
the limited resources.</p>
</td>
    <td>
      
        Tools & Libraries 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/miech2021thinking/">Thinking Fast And Slow: Efficient Text-to-visual Retrieval With Transformers</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Thinking Fast And Slow: Efficient Text-to-visual Retrieval With Transformers' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Thinking Fast And Slow: Efficient Text-to-visual Retrieval With Transformers' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Miech et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>111</td>
    <td><p>Our objective is language-based search of large-scale image and video
datasets. For this task, the approach that consists of independently mapping
text and vision to a joint embedding space, a.k.a. dual encoders, is attractive
as retrieval scales and is efficient for billions of images using approximate
nearest neighbour search. An alternative approach of using vision-text
transformers with cross-attention gives considerable improvements in accuracy
over the joint embeddings, but is often inapplicable in practice for
large-scale retrieval given the cost of the cross-attention mechanisms required
for each sample at test time. This work combines the best of both worlds. We
make the following three contributions. First, we equip transformer-based
models with a new fine-grained cross-attention architecture, providing
significant improvements in retrieval accuracy whilst preserving scalability.
Second, we introduce a generic approach for combining a Fast dual encoder model
with our Slow but accurate transformer-based model via distillation and
re-ranking. Finally, we validate our approach on the Flickr30K image dataset
where we show an increase in inference speed by several orders of magnitude
while having results competitive to the state of the art. We also extend our
method to the video domain, improving the state of the art on the VATEX
dataset.</p>
</td>
    <td>
      
        DATASETS 
      
        CVPR 
      
        Alt 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/wu2021linear/">Linear-time Self Attention With Codeword Histogram For Efficient Recommendation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Linear-time Self Attention With Codeword Histogram For Efficient Recommendation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Linear-time Self Attention With Codeword Histogram For Efficient Recommendation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the Web Conference 2021</td>
    <td>15</td>
    <td><p>Self-attention has become increasingly popular in a variety of sequence
modeling tasks from natural language processing to recommendation, due to its
effectiveness. However, self-attention suffers from quadratic computational and
memory complexities, prohibiting its applications on long sequences. Existing
approaches that address this issue mainly rely on a sparse attention context,
either using a local window, or a permuted bucket obtained by
locality-sensitive hashing (LSH) or sorting, while crucial information may be
lost. Inspired by the idea of vector quantization that uses cluster centroids
to approximate items, we propose LISA (LInear-time Self Attention), which
enjoys both the effectiveness of vanilla self-attention and the efficiency of
sparse attention. LISA scales linearly with the sequence length, while enabling
full contextual attention via computing differentiable histograms of codeword
distributions. Meanwhile, unlike some efficient attention methods, our method
poses no restriction on casual masking or sequence length. We evaluate our
method on four real-world datasets for sequential recommendation. The results
show that LISA outperforms the state-of-the-art efficient attention methods in
both performance and speed; and it is up to 57x faster and 78x more memory
efficient than vanilla self-attention.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Recommender Systems 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/tang2021when/">When Similarity Digest Meets Vector Management System: A Survey On Similarity Hash Function</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=When Similarity Digest Meets Vector Management System: A Survey On Similarity Hash Function' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=When Similarity Digest Meets Vector Management System: A Survey On Similarity Hash Function' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Tang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the VLDB Endowment</td>
    <td>95</td>
    <td><p>The booming vector manage system calls for feasible similarity hash function
as a front-end to perform similarity analysis. In this paper, we make a
systematical survey on the existent well-known similarity hash functions to
tease out the satisfied ones. We conclude that the similarity hash function
MinHash and Nilsimsa can be directly marshaled into the pipeline of similarity
analysis using vector manage system. After that, we make a brief and empirical
discussion on the performance, drawbacks of the these functions and highlight
MinHash, the variant of SimHash and feature hashing are the best for vector
management system for large-scale similarity analysis.</p>
</td>
    <td>
      
        Survey Paper 
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/qiu2021unsupervised/">Unsupervised Hashing With Contrastive Information Bottleneck</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Unsupervised Hashing With Contrastive Information Bottleneck' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Unsupervised Hashing With Contrastive Information Bottleneck' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Qiu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence</td>
    <td>51</td>
    <td><p>Many unsupervised hashing methods are implicitly established on the idea of
reconstructing the input data, which basically encourages the hashing codes to
retain as much information of original data as possible. However, this
requirement may force the models spending lots of their effort on
reconstructing the unuseful background information, while ignoring to preserve
the discriminative semantic information that is more important for the hashing
task. To tackle this problem, inspired by the recent success of contrastive
learning in learning continuous representations, we propose to adapt this
framework to learn binary hashing codes. Specifically, we first propose to
modify the objective function to meet the specific requirement of hashing and
then introduce a probabilistic binary representation layer into the model to
facilitate end-to-end training of the entire model. We further prove the strong
connection between the proposed contrastive-learning-based hashing method and
the mutual information, and show that the proposed model can be considered
under the broader framework of the information bottleneck (IB). Under this
perspective, a more general hashing model is naturally obtained. Extensive
experimental results on three benchmark image datasets demonstrate that the
proposed hashing method significantly outperforms existing baselines.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        IJCAI 
      
        Hashing Methods 
      
        Tools & Libraries 
      
        AAAI 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/radhakrishnan2021deep/">Deep Metric Learning For Ground Images</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Metric Learning For Ground Images' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Metric Learning For Ground Images' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Radhakrishnan et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>50</td>
    <td><p>Ground texture based localization methods are potential prospects for
low-cost, high-accuracy self-localization solutions for robots. These methods
estimate the pose of a given query image, i.e. the current observation of the
ground from a downward-facing camera, in respect to a set of reference images
whose poses are known in the application area. In this work, we deal with the
initial localization task, in which we have no prior knowledge about the
current robot positioning. In this situation, the localization method would
have to consider all available reference images. However, in order to reduce
computational effort and the risk of receiving a wrong result, we would like to
consider only those reference images that are actually overlapping with the
query image. For this purpose, we propose a deep metric learning approach that
retrieves the most similar reference images to the query image. In contrast to
existing approaches to image retrieval for ground images, our approach achieves
significantly better recall performance and improves the localization
performance of a state-of-the-art ground texture based localization method.</p>
</td>
    <td>
      
        Image Retrieval 
      
        AAAI 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/wang2021prototype/">Prototype-supervised Adversarial Network For Targeted Attack Of Deep Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Prototype-supervised Adversarial Network For Targeted Attack Of Deep Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Prototype-supervised Adversarial Network For Targeted Attack Of Deep Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>41</td>
    <td><p>Due to its powerful capability of representation learning and high-efficiency
computation, deep hashing has made significant progress in large-scale image
retrieval. However, deep hashing networks are vulnerable to adversarial
examples, which is a practical secure problem but seldom studied in
hashing-based retrieval field. In this paper, we propose a novel
prototype-supervised adversarial network (ProS-GAN), which formulates a
flexible generative architecture for efficient and effective targeted hashing
attack. To the best of our knowledge, this is the first generation-based method
to attack deep hashing networks. Generally, our proposed framework consists of
three parts, i.e., a PrototypeNet, a generator, and a discriminator.
Specifically, the designed PrototypeNet embeds the target label into the
semantic representation and learns the prototype code as the category-level
representative of the target label. Moreover, the semantic representation and
the original image are jointly fed into the generator for a flexible targeted
attack. Particularly, the prototype code is adopted to supervise the generator
to construct the targeted adversarial example by minimizing the Hamming
distance between the hash code of the adversarial example and the prototype
code. Furthermore, the generator is against the discriminator to simultaneously
encourage the adversarial examples visually realistic and the semantic
representation informative. Extensive experiments verify that the proposed
framework can efficiently produce adversarial examples with better targeted
attack performance and transferability over state-of-the-art targeted attack
methods of deep hashing. The related codes could be available at
https://github.com/xunguangwang/ProS-GAN .</p>
</td>
    <td>
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        CVPR 
      
        Neural Hashing 
      
        Tools & Libraries 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/pibiri2021parallel/">Parallel And External-memory Construction Of Minimal Perfect Hash Functions With Pthash</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Parallel And External-memory Construction Of Minimal Perfect Hash Functions With Pthash' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Parallel And External-memory Construction Of Minimal Perfect Hash Functions With Pthash' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Pibiri Giulio Ermanno, Trani Roberto</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Knowledge and Data Engineering</td>
    <td>9</td>
    <td><p>A function \(f : U \to \{0,\ldots,n-1\}\) is a minimal perfect hash function
for a set \(S \subseteq U\) of size \(n\), if \(f\) bijectively maps \(S\) into the
first \(n\) natural numbers. These functions are important for many practical
applications in computing, such as search engines, computer networks, and
databases. Several algorithms have been proposed to build minimal perfect hash
functions that: scale well to large sets, retain fast evaluation time, and take
very little space, e.g., 2 - 3 bits/key. PTHash is one such algorithm,
achieving very fast evaluation in compressed space, typically several times
faster than other techniques. In this work, we propose a new construction
algorithm for PTHash enabling: (1) multi-threading, to either build functions
more quickly or more space-efficiently, and (2) external-memory processing to
scale to inputs much larger than the available internal memory. Only few other
algorithms in the literature share these features, despite of their big
practical impact. We conduct an extensive experimental assessment on large
real-world string collections and show that, with respect to other techniques,
PTHash is competitive in construction time and space consumption, but retains 2</p>
<ul>
  <li>6\(\times\) better lookup time.</li>
</ul>
</td>
    <td>
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/pham2021training/">Training Multi-bit Quantized And Binarized Networks With A Learnable Symmetric Quantizer</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Training Multi-bit Quantized And Binarized Networks With A Learnable Symmetric Quantizer' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Training Multi-bit Quantized And Binarized Networks With A Learnable Symmetric Quantizer' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Pham Phuoc, Abraham Jacob, Chung Jaeyong</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Access</td>
    <td>14</td>
    <td><p>Quantizing weights and activations of deep neural networks is essential for
deploying them in resource-constrained devices, or cloud platforms for at-scale
services. While binarization is a special case of quantization, this extreme
case often leads to several training difficulties, and necessitates specialized
models and training methods. As a result, recent quantization methods do not
provide binarization, thus losing the most resource-efficient option, and
quantized and binarized networks have been distinct research areas. We examine
binarization difficulties in a quantization framework and find that all we need
to enable the binary training are a symmetric quantizer, good initialization,
and careful hyperparameter selection. These techniques also lead to substantial
improvements in multi-bit quantization. We demonstrate our unified quantization
framework, denoted as UniQ, on the ImageNet dataset with various architectures
such as ResNet-18,-34 and MobileNetV2. For multi-bit quantization, UniQ
outperforms existing methods to achieve the state-of-the-art accuracy. In
binarization, the achieved accuracy is comparable to existing state-of-the-art
methods even without modifying the original architectures.</p>
</td>
    <td>
      
        DATASETS 
      
        Tools & Libraries 
      
        Quantization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/pibiri2021pthash/">Pthash: Revisiting FCH Minimal Perfect Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Pthash: Revisiting FCH Minimal Perfect Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Pthash: Revisiting FCH Minimal Perfect Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Pibiri Giulio Ermanno, Trani Roberto</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</td>
    <td>17</td>
    <td><p>Given a set \(S\) of \(n\) distinct keys, a function \(f\) that bijectively maps
the keys of \(S\) into the range \(\{0,\ldots,n-1\}\) is called a minimal perfect
hash function for \(S\). Algorithms that find such functions when \(n\) is large
and retain constant evaluation time are of practical interest; for instance,
search engines and databases typically use minimal perfect hash functions to
quickly assign identifiers to static sets of variable-length keys such as
strings. The challenge is to design an algorithm which is efficient in three
different aspects: time to find \(f\) (construction time), time to evaluate \(f\)
on a key of \(S\) (lookup time), and space of representation for \(f\). Several
algorithms have been proposed to trade-off between these aspects. In 1992, Fox,
Chen, and Heath (FCH) presented an algorithm at SIGIR providing very fast
lookup evaluation. However, the approach received little attention because of
its large construction time and higher space consumption compared to other
subsequent techniques. Almost thirty years later we revisit their framework and
present an improved algorithm that scales well to large sets and reduces space
consumption altogether, without compromising the lookup time. We conduct an
extensive experimental assessment and show that the algorithm finds functions
that are competitive in space with state-of-the art techniques and provide
\(2-4\times\) better lookup time.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Alt 
      
        SIGIR 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/rodrigues2021combining/">Combining Minkowski And Chebyshev: New Distance Proposal And Survey Of Distance Metrics Using K-nearest Neighbours Classifier</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Combining Minkowski And Chebyshev: New Distance Proposal And Survey Of Distance Metrics Using K-nearest Neighbours Classifier' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Combining Minkowski And Chebyshev: New Distance Proposal And Survey Of Distance Metrics Using K-nearest Neighbours Classifier' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Rodrigues Ã‰rick Oliveira</td> <!-- ðŸ”§ You were missing this -->
    <td>Pattern Recognition Letters</td>
    <td>75</td>
    <td><p>This work proposes a distance that combines Minkowski and Chebyshev distances
and can be seen as an intermediary distance. This combination not only achieves
efficient run times in neighbourhood iteration tasks in Z^2, but also obtains
good accuracies when coupled with the k-Nearest Neighbours (k-NN) classifier.
The proposed distance is approximately 1.3 times faster than Manhattan distance
and 329.5 times faster than Euclidean distance in discrete neighbourhood
iterations. An accuracy analysis of the k-NN classifier using a total of 33
datasets from the UCI repository, 15 distances and values assigned to k that
vary from 1 to 200 is presented. In this experiment, the proposed distance
obtained accuracies that were better than the average more often than its
counterparts (in 26 cases out of 33), and also obtained the best accuracy more
frequently (in 9 out of 33 cases).</p>
</td>
    <td>
      
        Survey Paper 
      
        DATASETS 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/roller2021hash/">Hash Layers For Large Sparse Models</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hash Layers For Large Sparse Models' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hash Layers For Large Sparse Models' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Roller et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>47</td>
    <td><p>We investigate the training of sparse layers that use different parameters
for different inputs based on hashing in large Transformer models.
Specifically, we modify the feedforward layer to hash to different sets of
weights depending on the current token, over all tokens in the sequence. We
show that this procedure either outperforms or is competitive with
learning-to-route mixture-of-expert methods such as Switch Transformers and
BASE Layers, while requiring no routing parameters or extra terms in the
objective function such as a load balancing loss, and no sophisticated
assignment algorithm. We study the performance of different hashing techniques,
hash sizes and input features, and show that balanced and random hashes focused
on the most local features work best, compared to either learning clusters or
using longer-range context. We show our approach works well both on large
language modeling and dialogue tasks, and on downstream fine-tuning tasks.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/sharma2021learning/">Learning Canonical Embedding For Non-rigid Shape Matching</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning Canonical Embedding For Non-rigid Shape Matching' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning Canonical Embedding For Non-rigid Shape Matching' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Sharma Abhishek, Ovsjanikov Maks</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>23</td>
    <td><p>This paper provides a novel framework that learns canonical embeddings for
non-rigid shape matching. In contrast to prior work in this direction, our
framework is trained end-to-end and thus avoids instabilities and constraints
associated with the commonly-used Laplace-Beltrami basis or sequential
optimization schemes. On multiple datasets, we demonstrate that learning self
symmetry maps with a deep functional map projects 3D shapes into a low
dimensional canonical embedding that facilitates non-rigid shape correspondence
via a simple nearest neighbor search. Our framework outperforms multiple recent
learning based methods on FAUST and SHREC benchmarks while being
computationally cheaper, data-efficient, and robust.</p>
</td>
    <td>
      
        DATASETS 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/tang2021improving/">Improving Document Representations By Generating Pseudo Query Embeddings For Dense Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Improving Document Representations By Generating Pseudo Query Embeddings For Dense Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Improving Document Representations By Generating Pseudo Query Embeddings For Dense Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Tang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</td>
    <td>23</td>
    <td><p>Recently, the retrieval models based on dense representations have been
gradually applied in the first stage of the document retrieval tasks, showing
better performance than traditional sparse vector space models. To obtain high
efficiency, the basic structure of these models is Bi-encoder in most cases.
However, this simple structure may cause serious information loss during the
encoding of documents since the queries are agnostic. To address this problem,
we design a method to mimic the queries on each of the documents by an
iterative clustering process and represent the documents by multiple pseudo
queries (i.e., the cluster centroids). To boost the retrieval process using
approximate nearest neighbor search library, we also optimize the matching
function with a two-step score calculation procedure. Experimental results on
several popular ranking and QA datasets show that our model can achieve
state-of-the-art results.</p>
</td>
    <td>
      
        DATASETS 
      
        Text Retrieval 
      
        Evaluation 
      
        Efficiency And Optimization 
      
        ACL 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/wang2021meta/">Meta Cross-modal Hashing On Long-tailed Data</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Meta Cross-modal Hashing On Long-tailed Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Meta Cross-modal Hashing On Long-tailed Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>7</td>
    <td><p>Due to the advantage of reducing storage while speeding up query time on big
heterogeneous data, cross-modal hashing has been extensively studied for
approximate nearest neighbor search of multi-modal data. Most hashing methods
assume that training data is class-balanced.However, in practice, real world
data often have a long-tailed distribution. In this paper, we introduce a
meta-learning based cross-modal hashing method (MetaCMH) to handle long-tailed
data. Due to the lack of training samples in the tail classes, MetaCMH first
learns direct features from data in different modalities, and then introduces
an associative memory module to learn the memory features of samples of the
tail classes. It then combines the direct and memory features to obtain meta
features for each sample. For samples of the head classes of the long tail
distribution, the weight of the direct features is larger, because there are
enough training data to learn them well; while for rare classes, the weight of
the memory features is larger. Finally, MetaCMH uses a likelihood loss function
to preserve the similarity in different modalities and learns hash functions in
an end-to-end fashion. Experiments on long-tailed datasets show that MetaCMH
performs significantly better than state-of-the-art methods, especially on the
tail classes.</p>
</td>
    <td>
      
        AAAI 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/ertl2021setsketch/">Setsketch: Filling The Gap Between Minhash And Hyperloglog</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Setsketch: Filling The Gap Between Minhash And Hyperloglog' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Setsketch: Filling The Gap Between Minhash And Hyperloglog' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ertl Otmar</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the VLDB Endowment</td>
    <td>17</td>
    <td><p>MinHash and HyperLogLog are sketching algorithms that have become
indispensable for set summaries in big data applications. While HyperLogLog
allows counting different elements with very little space, MinHash is suitable
for the fast comparison of sets as it allows estimating the Jaccard similarity
and other joint quantities. This work presents a new data structure called
SetSketch that is able to continuously fill the gap between both use cases. Its
commutative and idempotent insert operation and its mergeable state make it
suitable for distributed environments. Fast, robust, and easy-to-implement
estimators for cardinality and joint quantities, as well as the ability to use
SetSketch for similarity search, enable versatile applications. The presented
joint estimator can also be applied to other data structures such as MinHash,
HyperLogLog, or HyperMinHash, where it even performs better than the
corresponding state-of-the-art estimators in many cases.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/engels2021practical/">Practical Near Neighbor Search Via Group Testing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Practical Near Neighbor Search Via Group Testing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Practical Near Neighbor Search Via Group Testing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Engels Joshua, Coleman Benjamin, Shrivastava Anshumali</td> <!-- ðŸ”§ You were missing this -->
    <td>ACM SIGMOD Record</td>
    <td>12</td>
    <td><p>We present a new algorithm for the approximate near neighbor problem that
combines classical ideas from group testing with locality-sensitive hashing
(LSH). We reduce the near neighbor search problem to a group testing problem by
designating neighbors as â€œpositives,â€ non-neighbors as â€œnegatives,â€ and
approximate membership queries as group tests. We instantiate this framework
using distance-sensitive Bloom Filters to Identify Near-Neighbor Groups
(FLINNG). We prove that FLINNG has sub-linear query time and show that our
algorithm comes with a variety of practical advantages. For example, FLINNG can
be constructed in a single pass through the data, consists entirely of
efficient integer operations, and does not require any distance computations.
We conduct large-scale experiments on high-dimensional search tasks such as
genome search, URL similarity search, and embedding search over the massive
YFCC100M dataset. In our comparison with leading algorithms such as HNSW and
FAISS, we find that FLINNG can provide up to a 10x query speedup with
substantially smaller indexing time and memory.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Graph Based ANN 
      
        Efficiency And Optimization 
      
        Similarity Search 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/elnouby2021training/">Training Vision Transformers For Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Training Vision Transformers For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Training Vision Transformers For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>El-nouby et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>120</td>
    <td><p>Transformers have shown outstanding results for natural language
understanding and, more recently, for image classification. We here extend this
work and propose a transformer-based approach for image retrieval: we adopt
vision transformers for generating image descriptors and train the resulting
model with a metric learning objective, which combines a contrastive loss with
a differential entropy regularizer. Our results show consistent and significant
improvements of transformers over convolution-based approaches. In particular,
our method outperforms the state of the art on several public benchmarks for
category-level retrieval, namely Stanford Online Product, In-Shop and CUB-200.
Furthermore, our experiments on ROxford and RParis also show that, in
comparable settings, transformers are competitive for particular object
retrieval, especially in the regime of short vector representations and
low-resolution images.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/zhan2021learning/">Learning Discrete Representations Via Constrained Clustering For Effective And Efficient Dense Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning Discrete Representations Via Constrained Clustering For Effective And Efficient Dense Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning Discrete Representations Via Constrained Clustering For Effective And Efficient Dense Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhan et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining</td>
    <td>32</td>
    <td><p>Dense Retrieval (DR) has achieved state-of-the-art first-stage ranking
effectiveness. However, the efficiency of most existing DR models is limited by
the large memory cost of storing dense vectors and the time-consuming nearest
neighbor search (NNS) in vector space. Therefore, we present RepCONC, a novel
retrieval model that learns discrete Representations via CONstrained
Clustering. RepCONC jointly trains dual-encoders and the Product Quantization
(PQ) method to learn discrete document representations and enables fast
approximate NNS with compact indexes. It models quantization as a constrained
clustering process, which requires the document embeddings to be uniformly
clustered around the quantization centroids and supports end-to-end
optimization of the quantization method and dual-encoders. We theoretically
demonstrate the importance of the uniform clustering constraint in RepCONC and
derive an efficient approximate solution for constrained clustering by reducing
it to an instance of the optimal transport problem. Besides constrained
clustering, RepCONC further adopts a vector-based inverted file system (IVF) to
support highly efficient vector search on CPUs. Extensive experiments on two
popular ad-hoc retrieval benchmarks show that RepCONC achieves better ranking
effectiveness than competitive vector quantization baselines under different
compression ratio settings. It also substantially outperforms a wide range of
existing retrieval models in terms of retrieval effectiveness, memory
efficiency, and time efficiency.</p>
</td>
    <td>
      
        Vector Indexing 
      
        Quantization 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/dubey2021vision/">Vision Transformer Hashing For Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Vision Transformer Hashing For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Vision Transformer Hashing For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Dubey Shiv Ram, Singh Satish Kumar, Chu Wei-ta</td> <!-- ðŸ”§ You were missing this -->
    <td>2022 IEEE International Conference on Multimedia and Expo (ICME)</td>
    <td>47</td>
    <td><p>Deep learning has shown a tremendous growth in hashing techniques for image
retrieval. Recently, Transformer has emerged as a new architecture by utilizing
self-attention without convolution. Transformer is also extended to Vision
Transformer (ViT) for the visual recognition with a promising performance on
ImageNet. In this paper, we propose a Vision Transformer based Hashing (VTS)
for image retrieval. We utilize the pre-trained ViT on ImageNet as the backbone
network and add the hashing head. The proposed VTS model is fine tuned for
hashing under six different image retrieval frameworks, including Deep
Supervised Hashing (DSH), HashNet, GreedyHash, Improved Deep Hashing Network
(IDHN), Deep Polarized Network (DPN) and Central Similarity Quantization (CSQ)
with their objective functions. We perform the extensive experiments on
CIFAR10, ImageNet, NUS-Wide, and COCO datasets. The proposed VTS based image
retrieval outperforms the recent state-of-the-art hashing techniques with a
great margin. We also find the proposed VTS model as the backbone network is
better than the existing networks, such as AlexNet and ResNet. The code is
released at https://github.com/shivram1987/VisionTransformerHashing.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Neural Hashing 
      
        Quantization 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/zhan2021jointly/">Jointly Optimizing Query Encoder And Product Quantization To Improve Retrieval Performance</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Jointly Optimizing Query Encoder And Product Quantization To Improve Retrieval Performance' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Jointly Optimizing Query Encoder And Product Quantization To Improve Retrieval Performance' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhan et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management</td>
    <td>58</td>
    <td><p>Recently, Information Retrieval community has witnessed fast-paced advances
in Dense Retrieval (DR), which performs first-stage retrieval with
embedding-based search. Despite the impressive ranking performance, previous
studies usually adopt brute-force search to acquire candidates, which is
prohibitive in practical Web search scenarios due to its tremendous memory
usage and time cost. To overcome these problems, vector compression methods
have been adopted in many practical embedding-based retrieval applications. One
of the most popular methods is Product Quantization (PQ). However, although
existing vector compression methods including PQ can help improve the
efficiency of DR, they incur severely decayed retrieval performance due to the
separation between encoding and compression. To tackle this problem, we present
JPQ, which stands for Joint optimization of query encoding and Product
Quantization. It trains the query encoder and PQ index jointly in an end-to-end
manner based on three optimization strategies, namely ranking-oriented loss, PQ
centroid optimization, and end-to-end negative sampling. We evaluate JPQ on two
publicly available retrieval benchmarks. Experimental results show that JPQ
significantly outperforms popular vector compression methods. Compared with
previous DR models that use brute-force search, JPQ almost matches the best
retrieval performance with 30x compression on index size. The compressed index
further brings 10x speedup on CPU and 2x speedup on GPU in query latency.</p>
</td>
    <td>
      
        Evaluation 
      
        Quantization 
      
        Efficiency And Optimization 
      
        CIKM 
      
        Alt 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/westermann2021sentence/">Sentence Embeddings And High-speed Similarity Search For Fast Computer Assisted Annotation Of Legal Documents</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Sentence Embeddings And High-speed Similarity Search For Fast Computer Assisted Annotation Of Legal Documents' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Sentence Embeddings And High-speed Similarity Search For Fast Computer Assisted Annotation Of Legal Documents' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Westermann et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Frontiers in Artificial Intelligence and Applications</td>
    <td>22</td>
    <td><p>Human-performed annotation of sentences in legal documents is an important
prerequisite to many machine learning based systems supporting legal tasks.
Typically, the annotation is done sequentially, sentence by sentence, which is
often time consuming and, hence, expensive. In this paper, we introduce a
proof-of-concept system for annotating sentences â€œlaterally.â€ The approach is
based on the observation that sentences that are similar in meaning often have
the same label in terms of a particular type system. We use this observation in
allowing annotators to quickly view and annotate sentences that are
semantically similar to a given sentence, across an entire corpus of documents.
Here, we present the interface of the system and empirically evaluate the
approach. The experiments show that lateral annotation has the potential to
make the annotation process quicker and more consistent.</p>
</td>
    <td>
      
        Similarity Search 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/tan2021fast/">A Fast Partial Video Copy Detection Using KNN And Global Feature Database</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Fast Partial Video Copy Detection Using KNN And Global Feature Database' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Fast Partial Video Copy Detection Using KNN And Global Feature Database' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Tan Weijun, Guo Hongwei, Liu Rushuai</td> <!-- ðŸ”§ You were missing this -->
    <td>2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</td>
    <td>12</td>
    <td><p>We propose a fast partial video copy detection framework in this paper. In
this framework all frame features of the reference videos are organized in a
KNN searchable database. Instead of scanning all reference videos, the query
video segment does a fast KNN search in the global feature database. The
returned results are used to generate a short list of candidate videos. A
modified temporal network is then used to localize the copy segment in the
candidate videos. We evaluate different choice of CNN features on the VCDB
dataset. Our benchmark F1 score exceeds the state of the art by a big margin.</p>
</td>
    <td>
      
        DATASETS 
      
        Similarity Search 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/talamantes2021instance/">Instance-based Learning Using The Half-space Proximal Graph</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Instance-based Learning Using The Half-space Proximal Graph' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Instance-based Learning Using The Half-space Proximal Graph' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Talamantes Ariana, Chavez Edgar</td> <!-- ðŸ”§ You were missing this -->
    <td>Pattern Recognition Letters</td>
    <td>7</td>
    <td><p>The primary example of instance-based learning is the \(k\)-nearest neighbor
rule (kNN), praised for its simplicity and the capacity to adapt to new unseen
data and toss away old data. The main disadvantages often mentioned are the
classification complexity, which is \(O(n)\), and the estimation of the parameter
\(k\), the number of nearest neighbors to be used. The use of indexes at
classification time lifts the former disadvantage, while there is no conclusive
method for the latter.
  This paper presents a parameter-free instance-based learning algorithm using
the {\em Half-Space Proximal} (HSP) graph. The HSP neighbors simultaneously
possess proximity and variety concerning the center node. To classify a given
query, we compute its HSP neighbors and apply a simple majority rule over them.
In our experiments, the resulting classifier bettered \(KNN\) for any \(k\) in a
battery of datasets. This improvement sticks even when applying weighted
majority rules to both kNN and HSP classifiers.
  Surprisingly, when using a probabilistic index to approximate the HSP graph
and consequently speeding-up the classification task, our method could {\em
improve} its accuracy in stark contrast with the kNN classifier, which worsens
with a probabilistic index.</p>
</td>
    <td>
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/cheng2021cnn/">CNN Retrieval Based Unsupervised Metric Learning For Near-duplicated Video Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=CNN Retrieval Based Unsupervised Metric Learning For Near-duplicated Video Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=CNN Retrieval Based Unsupervised Metric Learning For Near-duplicated Video Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Cheng Hao, Wang Ping, Qi Chun</td> <!-- ðŸ”§ You were missing this -->
    <td>2020 25th International Conference on Pattern Recognition (ICPR)</td>
    <td>16</td>
    <td><p>As important data carriers, the drastically increasing number of multimedia
videos often brings many duplicate and near-duplicate videos in the top results
of search. Near-duplicate video retrieval (NDVR) can cluster and filter out the
redundant contents. In this paper, the proposed NDVR approach extracts the
frame-level video representation based on convolutional neural network (CNN)
features from fully-connected layer and aggregated intermediate convolutional
layers. Unsupervised metric learning is used for similarity measurement and
feature matching. An efficient re-ranking algorithm combined with k-nearest
neighborhood fuses the retrieval results from two levels of features and
further improves the retrieval performance. Extensive experiments on the widely
used CC_WEB_VIDEO dataset shows that the proposed approach exhibits superior
performance over the state-of-the-art.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/coleman2021graph/">Graph Reordering For Cache-efficient Near Neighbor Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Graph Reordering For Cache-efficient Near Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Graph Reordering For Cache-efficient Near Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Coleman et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>5</td>
    <td><p>Graph search is one of the most successful algorithmic trends in near
neighbor search. Several of the most popular and empirically successful
algorithms are, at their core, a simple walk along a pruned near neighbor
graph. Such algorithms consistently perform at the top of industrial speed
benchmarks for applications such as embedding search. However, graph traversal
applications often suffer from poor memory access patterns, and near neighbor
search is no exception to this rule. Our measurements show that popular search
indices such as the hierarchical navigable small-world graph (HNSW) can have
poor cache miss performance. To address this problem, we apply graph reordering
algorithms to near neighbor graphs. Graph reordering is a memory layout
optimization that groups commonly-accessed nodes together in memory. We present
exhaustive experiments applying several reordering algorithms to a leading
graph-based near neighbor method based on the HNSW index. We find that
reordering improves the query time by up to 40%, and we demonstrate that the
time needed to reorder the graph is negligible compared to the time required to
construct the index.</p>
</td>
    <td>
      
        Graph Based ANN 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/chen2021transhash/">Transhash: Transformer-based Hamming Hashing For Efficient Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Transhash: Transformer-based Hamming Hashing For Efficient Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Transhash: Transformer-based Hamming Hashing For Efficient Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Chen et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 2022 International Conference on Multimedia Retrieval</td>
    <td>36</td>
    <td><p>Deep hamming hashing has gained growing popularity in approximate nearest
neighbour search for large-scale image retrieval. Until now, the deep hashing
for the image retrieval community has been dominated by convolutional neural
network architectures, e.g. \texttt{Resnet}\cite{he2016deep}. In this paper,
inspired by the recent advancements of vision transformers, we present
\textbf{Transhash}, a pure transformer-based framework for deep hashing
learning. Concretely, our framework is composed of two major modules: (1) Based
on \textit{Vision Transformer} (ViT), we design a siamese vision transformer
backbone for image feature extraction. To learn fine-grained features, we
innovate a dual-stream feature learning on top of the transformer to learn
discriminative global and local features. (2) Besides, we adopt a Bayesian
learning scheme with a dynamically constructed similarity matrix to learn
compact binary hash codes. The entire framework is jointly trained in an
end-to-end manner.~To the best of our knowledge, this is the first work to
tackle deep hashing learning problems without convolutional neural networks
(\textit{CNNs}). We perform comprehensive experiments on three widely-studied
datasets: \textbf{CIFAR-10}, \textbf{NUSWIDE} and \textbf{IMAGENET}. The
experiments have evidenced our superiority against the existing
state-of-the-art deep hashing methods. Specifically, we achieve 8.2%, 2.6%,
12.7% performance gains in terms of average \textit{mAP} for different hash
bit lengths on three public datasets, respectively.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        Neural Hashing 
      
        Hashing Methods 
      
        Image Retrieval 
      
        Tools & Libraries 
      
        Multimodal Retrieval 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/chaudhuri2021crossatnet/">Crossatnet - A Novel Cross-attention Based Framework For Sketch-based Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Crossatnet - A Novel Cross-attention Based Framework For Sketch-based Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Crossatnet - A Novel Cross-attention Based Framework For Sketch-based Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Chaudhuri et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Image and Vision Computing</td>
    <td>28</td>
    <td><p>We propose a novel framework for cross-modal zero-shot learning (ZSL) in the
context of sketch-based image retrieval (SBIR). Conventionally, the SBIR schema
mainly considers simultaneous mappings among the two image views and the
semantic side information. Therefore, it is desirable to consider fine-grained
classes mainly in the sketch domain using highly discriminative and
semantically rich feature space. However, the existing deep generative
modeling-based SBIR approaches majorly focus on bridging the gaps between the
seen and unseen classes by generating pseudo-unseen-class samples. Besides,
violating the ZSL protocol by not utilizing any unseen-class information during
training, such techniques do not pay explicit attention to modeling the
discriminative nature of the shared space. Also, we note that learning a
unified feature space for both the multi-view visual data is a tedious task
considering the significant domain difference between sketches and color
images. In this respect, as a remedy, we introduce a novel framework for
zero-shot SBIR. While we define a cross-modal triplet loss to ensure the
discriminative nature of the shared space, an innovative cross-modal attention
learning strategy is also proposed to guide feature extraction from the image
domain exploiting information from the respective sketch counterpart. In order
to preserve the semantic consistency of the shared space, we consider a graph
CNN-based module that propagates the semantic class topology to the shared
space. To ensure an improved response time during inference, we further explore
the possibility of representing the shared space in terms of hash codes.
Experimental results obtained on the benchmark TU-Berlin and the Sketchy
datasets confirm the superiority of CrossATNet in yielding state-of-the-art
results.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/black2021compositional/">Compositional Sketch Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Compositional Sketch Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Compositional Sketch Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Black et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>75</td>
    <td><p>We present an algorithm for searching image collections using free-hand
sketches that describe the appearance and relative positions of multiple
objects. Sketch based image retrieval (SBIR) methods predominantly match
queries containing a single, dominant object invariant to its position within
an image. Our work exploits drawings as a concise and intuitive representation
for specifying entire scene compositions. We train a convolutional neural
network (CNN) to encode masked visual features from sketched objects, pooling
these into a spatial descriptor encoding the spatial relationships and
appearances of objects in the composition. Training the CNN backbone as a
Siamese network under triplet loss yields a metric search embedding for
measuring compositional similarity which may be efficiently leveraged for
visual search by applying product quantization.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Quantization 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/bender2021iceberg/">Iceberg Hashing: Optimizing Many Hash-table Criteria At Once</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Iceberg Hashing: Optimizing Many Hash-table Criteria At Once' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Iceberg Hashing: Optimizing Many Hash-table Criteria At Once' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Bender et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Journal of the ACM</td>
    <td>10</td>
    <td><p>Despite being one of the oldest data structures in computer science, hash
tables continue to be the focus of a great deal of both theoretical and
empirical research. A central reason for this is that many of the fundamental
properties that one desires from a hash table are difficult to achieve
simultaneously; thus many variants offering different trade-offs have been
proposed.
  This paper introduces Iceberg hashing, a hash table that simultaneously
offers the strongest known guarantees on a large number of core properties.
Iceberg hashing supports constant-time operations while improving on the state
of the art for space efficiency, cache efficiency, and low failure probability.
Iceberg hashing is also the first hash table to support a load factor of up to
\(1 - o(1)\) while being stable, meaning that the position where an element is
stored only ever changes when resizes occur. In fact, in the setting where keys
are \(\Theta(log n)\) bits, the space guarantees that Iceberg hashing offers,
namely that it uses at most \(log \binom{|U|}{n} + O(n log log n)\) bits to
store \(n\) items from a universe \(U\), matches a lower bound by Demaine et al.
that applies to any stable hash table.
  Iceberg hashing introduces new general-purpose techniques for some of the
most basic aspects of hash-table design. Notably, our indirection-free
technique for dynamic resizing, which we call waterfall addressing, and our
techniques for achieving stability and very-high probability guarantees, can be
applied to any hash table that makes use of the front-yard/backyard paradigm
for hash table design.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/bender2021optimal/">On The Optimal Time/space Tradeoff For Hash Tables</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=On The Optimal Time/space Tradeoff For Hash Tables' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=On The Optimal Time/space Tradeoff For Hash Tables' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Bender et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 54th Annual ACM SIGACT Symposium on Theory of Computing</td>
    <td>16</td>
    <td><p>For nearly six decades, the central open question in the study of hash tables
has been to determine the optimal achievable tradeoff curve between time and
space. State-of-the-art hash tables offer the following guarantee: If
keys/values are Theta(log n) bits each, then it is possible to achieve
constant-time insertions/deletions/queries while wasting only O(loglog n) bits
of space per key when compared to the information-theoretic optimum. Even prior
to this bound being achieved, the target of O(loglog n) wasted bits per key was
known to be a natural end goal, and was proven to be optimal for a number of
closely related problems (e.g., stable hashing, dynamic retrieval, and
dynamically-resized filters).
  This paper shows that O(loglog n) wasted bits per key is not the end of the
line for hashing. In fact, for any k \in [log* n], it is possible to achieve
O(k)-time insertions/deletions, O(1)-time queries, and O(log^{(k)} n) wasted
bits per key (all with high probability in n). This means that, each time we
increase insertion/deletion time by an <em>additive constant</em>, we reduce the
wasted bits per key <em>exponentially</em>. We further show that this tradeoff
curve is the best achievable by any of a large class of hash tables, including
any hash table designed using the current framework for making constant-time
hash tables succinct.</p>
</td>
    <td>
      
        Tools & Libraries 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/bera2021dimensionality/">Dimensionality Reduction For Categorical Data</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Dimensionality Reduction For Categorical Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Dimensionality Reduction For Categorical Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Bera Debajyoti, Pratap Rameshwar, Verma Bhisham Dev</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Knowledge and Data Engineering</td>
    <td>6</td>
    <td><p>Categorical attributes are those that can take a discrete set of values,
e.g., colours. This work is about compressing vectors over categorical
attributes to low-dimension discrete vectors. The current hash-based methods
compressing vectors over categorical attributes to low-dimension discrete
vectors do not provide any guarantee on the Hamming distances between the
compressed representations. Here we present FSketch to create sketches for
sparse categorical data and an estimator to estimate the pairwise Hamming
distances among the uncompressed data only from their sketches. We claim that
these sketches can be used in the usual data mining tasks in place of the
original data without compromising the quality of the task. For that, we ensure
that the sketches also are categorical, sparse, and the Hamming distance
estimates are reasonably precise. Both the sketch construction and the Hamming
distance estimation algorithms require just a single-pass; furthermore, changes
to a data point can be incorporated into its sketch in an efficient manner. The
compressibility depends upon how sparse the data is and is independent of the
original dimension â€“ making our algorithm attractive for many real-life
scenarios. Our claims are backed by rigorous theoretical analysis of the
properties of FSketch and supplemented by extensive comparative evaluations
with related algorithms on some real-world datasets. We show that FSketch is
significantly faster, and the accuracy obtained by using its sketches are among
the top for the standard unsupervised tasks of RMSE, clustering and similarity
search.</p>
</td>
    <td>
      
        Compact Codes 
      
        DATASETS 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/awad2021better/">Better GPU Hash Tables</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Better GPU Hash Tables' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Better GPU Hash Tables' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Awad et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Symposium on Algorithmic Principles of Computer Systems (APOCS)</td>
    <td>5</td>
    <td><p>We revisit the problem of building static hash tables on the GPU and design
and build three bucketed hash tables that use different probing schemes. Our
implementations are lock-free and offer efficient memory access patterns; thus,
only the probing scheme is the factor affecting the performance of the hash
tableâ€™s different operations. Our results show that a bucketed cuckoo hash
table that uses three hash functions (BCHT) outperforms alternative methods
that use power-of-two choices, iceberg hashing, and a cuckoo hash table that
uses a bucket size one. At high load factors as high as 0.99, BCHT enjoys an
average probe count of 1.43 during insertion. Using three hash functions only,
positive and negative queries require at most 1.39 and 2.8 average probes per
key, respectively.</p>
</td>
    <td>
      
        Alt 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/bera2021quint/">QUINT: Node Embedding Using Network Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=QUINT: Node Embedding Using Network Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=QUINT: Node Embedding Using Network Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Bera et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Knowledge and Data Engineering</td>
    <td>5</td>
    <td><p>Representation learning using network embedding has received tremendous
attention due to its efficacy to solve downstream tasks. Popular embedding
methods (such as deepwalk, node2vec, LINE) are based on a neural architecture,
thus unable to scale on large networks both in terms of time and space usage.
Recently, we proposed BinSketch, a sketching technique for compressing binary
vectors to binary vectors. In this paper, we show how to extend BinSketch and
use it for network hashing. Our proposal named QUINT is built upon BinSketch,
and it embeds nodes of a sparse network onto a low-dimensional space using
simple bi-wise operations. QUINT is the first of its kind that provides
tremendous gain in terms of speed and space usage without compromising much on
the accuracy of the downstream tasks. Extensive experiments are conducted to
compare QUINT with seven state-of-the-art network embedding methods for two end
tasks - link prediction and node classification. We observe huge performance
gain for QUINT in terms of speedup (up to 7000x) and space saving (up to 80x)
due to its bit-wise nature to obtain node embedding. Moreover, QUINT is a
consistent top-performer for both the tasks among the baselines across all the
datasets. Our empirical observations are backed by rigorous theoretical
analysis to justify the effectiveness of QUINT. In particular, we prove that
QUINT retains enough structural information which can be used further to
approximate many topological properties of networks with high confidence.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/zhang2021finger/">Finger Vein Recognition By Generating Code</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Finger Vein Recognition By Generating Code' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Finger Vein Recognition By Generating Code' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang Zhongxia, Wang Mingwen</td> <!-- ðŸ”§ You were missing this -->
    <td>Sensors</td>
    <td>84</td>
    <td><p>Finger vein recognition has drawn increasing attention as one of the most
popular and promising biometrics due to its high distinguishes ability,
security and non-invasive procedure. The main idea of traditional schemes is to
directly extract features from finger vein images or patterns and then compare
features to find the best match. However, the features extracted from images
contain much redundant data, while the features extracted from patterns are
greatly influenced by image segmentation methods. To tack these problems, this
paper proposes a new finger vein recognition by generating code. The proposed
method does not require an image segmentation algorithm, is simple to calculate
and has a small amount of data. Firstly, the finger vein images were divided
into blocks to calculate the mean value. Then the centrosymmetric coding is
performed by using the generated eigenmatrix. The obtained codewords are
concatenated as the feature codewords of the image. The similarity between vein
codes is measured by the ratio of minimum Hamming distance to codeword length.
Extensive experiments on two public finger vein databases verify the
effectiveness of the proposed method. The results indicate that our method
outperforms the state-of-theart methods and has competitive potential in
performing the matching task.</p>
</td>
    <td>
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/andrecut2021additive/">Additive Feature Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Additive Feature Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Additive Feature Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Andrecut M.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 18th ACM international conference on Multimedia</td>
    <td>17</td>
    <td><p>The hashing trick is a machine learning technique used to encode categorical
features into a numerical vector representation of pre-defined fixed length. It
works by using the categorical hash values as vector indices, and updating the
vector values at those indices. Here we discuss a different approach based on
additive-hashing and the â€œalmost orthogonalâ€ property of high-dimensional
random vectors. That is, we show that additive feature hashing can be performed
directly by adding the hash values and converting them into high-dimensional
numerical vectors. We show that the performance of additive feature hashing is
similar to the hashing trick, and we illustrate the results numerically using
synthetic, language recognition, and SMS spam detection data.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/andoni2021average/">From Average Embeddings To Nearest Neighbor Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=From Average Embeddings To Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=From Average Embeddings To Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Andoni Alexandr, Cheikhi David</td> <!-- ðŸ”§ You were missing this -->
    <td>Journal of Mathematical Imaging and Vision</td>
    <td>6</td>
    <td><p>In this note, we show that one can use average embeddings, introduced
recently in [Naorâ€™20, arXiv:1905.01280], to obtain efficient algorithms for
approximate nearest neighbor search. In particular, a metric \(X\) embeds into
\(â„“â‚‚\) on average, with distortion \(D\), if, for any distribution \(\mu\) on
\(X\), the embedding is \(D\) Lipschitz and the (square of) distance does not
decrease on average (wrt \(\mu\)). In particular existence of such an embedding
(assuming it is efficient) implies a \(O(D^3)\) approximate nearest neighbor
search under \(X\). This can be seen as a strengthening of the classic
(bi-Lipschitz) embedding approach to nearest neighbor search, and is another
application of data-dependent hashing paradigm.</p>
</td>
    <td>
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/zhang2021graph/">Graph Convolution For Re-ranking In Person Re-identification</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Graph Convolution For Re-ranking In Person Re-identification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Graph Convolution For Re-ranking In Person Re-identification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</td>
    <td>13</td>
    <td><p>Nowadays, deep learning is widely applied to extract features for similarity
computation in person re-identification (re-ID) and have achieved great
success. However, due to the non-overlapping between training and testing IDs,
the difference between the data used for model training and the testing data
makes the performance of learned feature degraded during testing. Hence,
re-ranking is proposed to mitigate this issue and various algorithms have been
developed. However, most of existing re-ranking methods focus on replacing the
Euclidean distance with sophisticated distance metrics, which are not friendly
to downstream tasks and hard to be used for fast retrieval of massive data in
real applications. In this work, we propose a graph-based re-ranking method to
improve learned features while still keeping Euclidean distance as the
similarity metric. Inspired by graph convolution networks, we develop an
operator to propagate features over an appropriate graph. Since graph is the
essential key for the propagation, two important criteria are considered for
designing the graph, and three different graphs are explored accordingly.
Furthermore, a simple yet effective method is proposed to generate a profile
vector for each tracklet in videos, which helps extend our method to video
re-ID. Extensive experiments on three benchmark data sets, e.g., Market-1501,
Duke, and MARS, demonstrate the effectiveness of our proposed approach.</p>
</td>
    <td>
      
        Graph Based ANN 
      
        Distance Metric Learning 
      
        Efficiency And Optimization 
      
        ICASSP 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/amrouche2021hashing/">Hashing And Metric Learning For Charged Particle Tracking</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hashing And Metric Learning For Charged Particle Tracking' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hashing And Metric Learning For Charged Particle Tracking' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Amrouche et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>5</td>
    <td><p>We propose a novel approach to charged particle tracking at high intensity
particle colliders based on Approximate Nearest Neighbors search. With hundreds
of thousands of measurements per collision to be reconstructed e.g. at the High
Luminosity Large Hadron Collider, the currently employed combinatorial track
finding approaches become inadequate. Here, we use hashing techniques to
separate measurements into buckets of 20-50 hits and increase their purity
using metric learning. Two different approaches are studied to further resolve
tracks inside buckets: Local Fisher Discriminant Analysis and Neural Networks
for triplet similarity learning. We demonstrate the proposed approach on
simulated collisions and show significant speed improvement with bucket
tracking efficiency of 96% and a fake rate of 8% on unseen particle events.</p>
</td>
    <td>
      
        Distance Metric Learning 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/wieczorek2021unreasonable/">On The Unreasonable Effectiveness Of Centroids In Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=On The Unreasonable Effectiveness Of Centroids In Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=On The Unreasonable Effectiveness Of Centroids In Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wieczorek Mikolaj, Rychalska Barbara, Dabrowski Jacek</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>84</td>
    <td><p>Image retrieval task consists of finding similar images to a query image from
a set of gallery (database) images. Such systems are used in various
applications e.g. person re-identification (ReID) or visual product search.
Despite active development of retrieval models it still remains a challenging
task mainly due to large intra-class variance caused by changes in view angle,
lighting, background clutter or occlusion, while inter-class variance may be
relatively low. A large portion of current research focuses on creating more
robust features and modifying objective functions, usually based on Triplet
Loss. Some works experiment with using centroid/proxy representation of a class
to alleviate problems with computing speed and hard samples mining used with
Triplet Loss. However, these approaches are used for training alone and
discarded during the retrieval stage. In this paper we propose to use the mean
centroid representation both during training and retrieval. Such an aggregated
representation is more robust to outliers and assures more stable features. As
each class is represented by a single embedding - the class centroid - both
retrieval time and storage requirements are reduced significantly. Aggregating
multiple embeddings results in a significant reduction of the search space due
to lowering the number of candidate target vectors, which makes the method
especially suitable for production deployments. Comprehensive experiments
conducted on two ReID and Fashion Retrieval datasets demonstrate effectiveness
of our method, which outperforms the current state-of-the-art. We propose
centroid training and retrieval as a viable method for both Fashion Retrieval
and ReID applications.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/agarwal2021dynamic/">Dynamic Enumeration Of Similarity Joins</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Dynamic Enumeration Of Similarity Joins' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Dynamic Enumeration Of Similarity Joins' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Agarwal et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2008 IEEE 24th International Conference on Data Engineering</td>
    <td>10</td>
    <td><p>This paper considers enumerating answers to similarity-join queries under
dynamic updates: Given two sets of \(n\) points \(A,B\) in \(\mathbb{R}^d\), a metric
\(\phi(\cdot)\), and a distance threshold \(r &gt; 0\), report all pairs of points
\((a, b) \in A \times B\) with \(\phi(a,b) \le r\). Our goal is to store \(A,B\) into
a dynamic data structure that, whenever asked, can enumerate all result pairs
with worst-case delay guarantee, i.e., the time between enumerating two
consecutive pairs is bounded. Furthermore, the data structure can be
efficiently updated when a point is inserted into or deleted from \(A\) or \(B\).
  We propose several efficient data structures for answering similarity-join
queries in low dimension. For exact enumeration of similarity join, we present
near-linear-size data structures for \(\ell_1, \ell_\infty\) metrics with
\(log^{O(1)} n\) update time and delay. We show that such a data structure is
not feasible for the \(â„“â‚‚\) metric for \(d \ge 4\). For approximate enumeration
of similarity join, where the distance threshold is a soft constraint, we
obtain a unified linear-size data structure for \(\ell_p\) metric, with
\(log^{O(1)} n\) delay and update time. In high dimensions, we present an
efficient data structure with worst-case delay-guarantee using locality
sensitive hashing (LSH).</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Graph Based ANN 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/wang2021towards/">Towards A Model For LSH</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Towards A Model For LSH' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Towards A Model For LSH' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang Li</td> <!-- ðŸ”§ You were missing this -->
    <td>Infection and Immunity</td>
    <td>19</td>
    <td><p>As data volumes continue to grow, clustering and outlier detection algorithms
are becoming increasingly time-consuming. Classical index structures for
neighbor search are no longer sustainable due to the â€œcurse of dimensionalityâ€.
Instead, approximated index structures offer a good opportunity to
significantly accelerate the neighbor search for clustering and outlier
detection and to have the lowest possible error rate in the results of the
algorithms. Locality-sensitive hashing is one of those. We indicate directions
to model the properties of LSH.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Vector Indexing 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/schubert2021triangle/">A Triangle Inequality For Cosine Similarity</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Triangle Inequality For Cosine Similarity' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Triangle Inequality For Cosine Similarity' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Schubert Erich</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>19</td>
    <td><p>Similarity search is a fundamental problem for many data analysis techniques.
Many efficient search techniques rely on the triangle inequality of metrics,
which allows pruning parts of the search space based on transitive bounds on
distances. Recently, Cosine similarity has become a popular alternative choice
to the standard Euclidean metric, in particular in the context of textual data
and neural network embeddings. Unfortunately, Cosine similarity is not metric
and does not satisfy the standard triangle inequality. Instead, many search
techniques for Cosine rely on approximation techniques such as locality
sensitive hashing. In this paper, we derive a triangle inequality for Cosine
similarity that is suitable for efficient similarity search with many standard
search structures (such as the VP-tree, Cover-tree, and M-tree); show that this
bound is tight and discuss fast approximations for it. We hope that this spurs
new research on accelerating exact similarity search for cosine similarity, and
possible other similarity measures beyond the existing work for distance
metrics.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        Alt 
      
        Similarity Search 
      
        Tree Based ANN 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/schubert2021beyond/">Beyond ANN: Exploiting Structural Knowledge For Efficient Place Recognition</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Beyond ANN: Exploiting Structural Knowledge For Efficient Place Recognition' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Beyond ANN: Exploiting Structural Knowledge For Efficient Place Recognition' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Schubert Stefan, Neubert Peer, Protzel Peter</td> <!-- ðŸ”§ You were missing this -->
    <td>2021 IEEE International Conference on Robotics and Automation (ICRA)</td>
    <td>7</td>
    <td><p>Visual place recognition is the task of recognizing same places of query
images in a set of database images, despite potential condition changes due to
time of day, weather or seasons. It is important for loop closure detection in
SLAM and candidate selection for global localization. Many approaches in the
literature perform computationally inefficient full image comparisons between
queries and all database images. There is still a lack of suited methods for
efficient place recognition that allow a fast, sparse comparison of only the
most promising image pairs without any loss in performance. While this is
partially given by ANN-based methods, they trade speed for precision and
additional memory consumption, and many cannot find arbitrary numbers of
matching database images in case of loops in the database. In this paper, we
propose a novel fast sequence-based method for efficient place recognition that
can be applied online. It uses relocalization to recover from sequence losses,
and exploits usually available but often unused intra-database similarities for
a potential detection of all matching database images for each query in case of
loops or stops in the database. We performed extensive experimental evaluations
over five datasets and 21 sequence combinations, and show that our method
outperforms two state-of-the-art approaches and even full image comparisons in
many cases, while providing a good tradeoff between performance and percentage
of evaluated image pairs. Source code for Matlab will be provided with
publication of this paper.</p>
</td>
    <td>
      
        DATASETS 
      
        ICRA 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/schuhmann2021laion/">LAION-400M: Open Dataset Of Clip-filtered 400 Million Image-text Pairs</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=LAION-400M: Open Dataset Of Clip-filtered 400 Million Image-text Pairs' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=LAION-400M: Open Dataset Of Clip-filtered 400 Million Image-text Pairs' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Schuhmann et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>312</td>
    <td><p>Multi-modal language-vision models trained on hundreds of millions of
image-text pairs (e.g. CLIP, DALL-E) gained a recent surge, showing remarkable
capability to perform zero- or few-shot learning and transfer even in absence
of per-sample labels on target image data. Despite this trend, to date there
has been no publicly available datasets of sufficient scale for training such
models from scratch. To address this issue, in a community effort we build and
release for public LAION-400M, a dataset with CLIP-filtered 400 million
image-text pairs, their CLIP embeddings and kNN indices that allow efficient
similarity search.</p>
</td>
    <td>
      
        DATASETS 
      
        Similarity Search 
      
    </td>
    </tr>      
    
     <tr>
  <td>2021</td>
    <td>
      <a href="/publications/seidenschwarz2021learning/">Learning Intra-batch Connections For Deep Metric Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning Intra-batch Connections For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning Intra-batch Connections For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Seidenschwarz Jenny, Elezi Ismail, Leal-taixÃ© Laura</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>23</td>
    <td><p>The goal of metric learning is to learn a function that maps samples to a
lower-dimensional space where similar samples lie closer than dissimilar ones.
Particularly, deep metric learning utilizes neural networks to learn such a
mapping. Most approaches rely on losses that only take the relations between
pairs or triplets of samples into account, which either belong to the same
class or two different classes. However, these methods do not explore the
embedding space in its entirety. To this end, we propose an approach based on
message passing networks that takes all the relations in a mini-batch into
account. We refine embedding vectors by exchanging messages among all samples
in a given batch allowing the training process to be aware of its overall
structure. Since not all samples are equally important to predict a decision
boundary, we use an attention mechanism during message passing to allow samples
to weigh the importance of each neighbor accordingly. We achieve
state-of-the-art results on clustering and image retrieval on the CUB-200-2011,
Cars196, Stanford Online Products, and In-Shop Clothes datasets. To facilitate
further research, we make available the code and the models at
https://github.com/dvl-tum/intra_batch_connections.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
    
      
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/wu2020nearest/">Nearest Neighbor Search For Hyperbolic Embeddings</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Nearest Neighbor Search For Hyperbolic Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Nearest Neighbor Search For Hyperbolic Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wu Xian, Charikar Moses</td> <!-- ðŸ”§ You were missing this -->
    <td>Journal of Mathematical Imaging and Vision</td>
    <td>6</td>
    <td><p>Embedding into hyperbolic space is emerging as an effective representation
technique for datasets that exhibit hierarchical structure. This development
motivates the need for algorithms that are able to effectively extract
knowledge and insights from datapoints embedded in negatively curved spaces. We
focus on the problem of nearest neighbor search, a fundamental problem in data
analysis. We present efficient algorithmic solutions that build upon
established methods for nearest neighbor search in Euclidean space, allowing
for easy adoption and integration with existing systems. We prove theoretical
guarantees for our techniques and our experiments demonstrate the effectiveness
of our approach on real datasets over competing algorithms.</p>
</td>
    <td>
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/ko2020embedding/">Embedding Expansion: Augmentation In Embedding Space For Deep Metric Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Embedding Expansion: Augmentation In Embedding Space For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Embedding Expansion: Augmentation In Embedding Space For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ko Byungsoo, Gu Geonmo</td> <!-- ðŸ”§ You were missing this -->
    <td>2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>47</td>
    <td><p>Learning the distance metric between pairs of samples has been studied for
image retrieval and clustering. With the remarkable success of pair-based
metric learning losses, recent works have proposed the use of generated
synthetic points on metric learning losses for augmentation and generalization.
However, these methods require additional generative networks along with the
main network, which can lead to a larger model size, slower training speed, and
harder optimization. Meanwhile, post-processing techniques, such as query
expansion and database augmentation, have proposed the combination of feature
points to obtain additional semantic information. In this paper, inspired by
query expansion and database augmentation, we propose an augmentation method in
an embedding space for pair-based metric learning losses, called embedding
expansion. The proposed method generates synthetic points containing augmented
information by a combination of feature points and performs hard negative pair
mining to learn with the most informative feature representations. Because of
its simplicity and flexibility, it can be used for existing metric learning
losses without affecting model size, training speed, or optimization
difficulty. Finally, the combination of embedding expansion and representative
metric learning losses outperforms the state-of-the-art losses and previous
sample generation methods in both image retrieval and clustering tasks. The
implementation is publicly available.</p>
</td>
    <td>
      
        CVPR 
      
        Image Retrieval 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/kim2020boosted/">Boosted Locality Sensitive Hashing: Discriminative Binary Codes For Source Separation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Boosted Locality Sensitive Hashing: Discriminative Binary Codes For Source Separation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Boosted Locality Sensitive Hashing: Discriminative Binary Codes For Source Separation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Kim Sunwoo, Yang Haici, Kim Minje</td> <!-- ðŸ”§ You were missing this -->
    <td>ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</td>
    <td>9</td>
    <td><p>Speech enhancement tasks have seen significant improvements with the advance
of deep learning technology, but with the cost of increased computational
complexity. In this study, we propose an adaptive boosting approach to learning
locality sensitive hash codes, which represent audio spectra efficiently. We
use the learned hash codes for single-channel speech denoising tasks as an
alternative to a complex machine learning model, particularly to address the
resource-constrained environments. Our adaptive boosting algorithm learns
simple logistic regressors as the weak learners. Once trained, their binary
classification results transform each spectrum of test noisy speech into a bit
string. Simple bitwise operations calculate Hamming distance to find the
K-nearest matching frames in the dictionary of training noisy speech spectra,
whose associated ideal binary masks are averaged to estimate the denoising mask
for that test mixture. Our proposed learning algorithm differs from AdaBoost in
the sense that the projections are trained to minimize the distances between
the self-similarity matrix of the hash codes and that of the original spectra,
rather than the misclassification rate. We evaluate our discriminative hash
codes on the TIMIT corpus with various noise types, and show comparative
performance to deep learning methods in terms of denoising performance and
complexity.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Compact Codes 
      
        Alt 
      
        ICASSP 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/reimers2020curse/">The Curse Of Dense Low-dimensional Information Retrieval For Large Index Sizes</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=The Curse Of Dense Low-dimensional Information Retrieval For Large Index Sizes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=The Curse Of Dense Low-dimensional Information Retrieval For Large Index Sizes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Reimers Nils, Gurevych Iryna</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)</td>
    <td>31</td>
    <td><p>Information Retrieval using dense low-dimensional representations recently
became popular and showed out-performance to traditional sparse-representations
like BM25. However, no previous work investigated how dense representations
perform with large index sizes. We show theoretically and empirically that the
performance for dense representations decreases quicker than sparse
representations for increasing index sizes. In extreme cases, this can even
lead to a tipping point where at a certain index size sparse representations
outperform dense representations. We show that this behavior is tightly
connected to the number of dimensions of the representations: The lower the
dimension, the higher the chance for false positives, i.e. returning irrelevant
documents.</p>
</td>
    <td>
      
        Efficiency And Optimization 
      
        ACL 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/keisler2020visual/">Visual Search Over Billions Of Aerial And Satellite Images</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Visual Search Over Billions Of Aerial And Satellite Images' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Visual Search Over Billions Of Aerial And Satellite Images' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Keisler et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Computer Vision and Image Understanding</td>
    <td>21</td>
    <td><p>We present a system for performing visual search over billions of aerial and
satellite images. The purpose of visual search is to find images that are
visually similar to a query image. We define visual similarity using 512
abstract visual features generated by a convolutional neural network that has
been trained on aerial and satellite imagery. The features are converted to
binary values to reduce data and compute requirements. We employ a hash-based
search using Bigtable, a scalable database service from Google Cloud. Searching
the continental United States at 1-meter pixel resolution, corresponding to
approximately 2 billion images, takes approximately 0.1 seconds. This system
enables real-time visual search over the surface of the earth, and an
interactive demo is available at https://search.descarteslabs.com.</p>
</td>
    <td>
      
        Image Retrieval 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/kazemi2020memory/">In-memory Nearest Neighbor Search With Fefet Multi-bit Content-addressable Memories</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=In-memory Nearest Neighbor Search With Fefet Multi-bit Content-addressable Memories' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=In-memory Nearest Neighbor Search With Fefet Multi-bit Content-addressable Memories' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Kazemi et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2021 Design, Automation &amp; Test in Europe Conference &amp; Exhibition (DATE)</td>
    <td>42</td>
    <td><p>Nearest neighbor (NN) search is an essential operation in many applications,
such as one/few-shot learning and image classification. As such, fast and
low-energy hardware support for accurate NN search is highly desirable. Ternary
content-addressable memories (TCAMs) have been proposed to accelerate NN search
for few-shot learning tasks by implementing \(L_\infty\) and Hamming distance
metrics, but they cannot achieve software-comparable accuracies. This paper
proposes a novel distance function that can be natively evaluated with
multi-bit content-addressable memories (MCAMs) based on ferroelectric FETs
(FeFETs) to perform a single-step, in-memory NN search. Moreover, this approach
achieves accuracies comparable to floating-point precision implementations in
software for NN classification and one/few-shot learning tasks. As an example,
the proposed method achieves a 98.34% accuracy for a 5-way, 5-shot
classification task for the Omniglot dataset (only 0.8% lower than
software-based implementations) with a 3-bit MCAM. This represents a 13%
accuracy improvement over state-of-the-art TCAM-based implementations at
iso-energy and iso-delay. The presented distance function is resilient to the
effects of FeFET device-to-device variations. Furthermore, this work
experimentally demonstrates a 2-bit implementation of FeFET MCAM using AND
arrays from GLOBALFOUNDRIES to further validate proof of concept.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/kaplan2020locality/">Locality Sensitive Hashing For Set-queries, Motivated By Group Recommendations</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Locality Sensitive Hashing For Set-queries, Motivated By Group Recommendations' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Locality Sensitive Hashing For Set-queries, Motivated By Group Recommendations' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Kaplan Haim, Tenenbaum Jay</td> <!-- ðŸ”§ You were missing this -->
    <td>Information Sciences</td>
    <td>15</td>
    <td><p>Locality Sensitive Hashing (LSH) is an effective method to index a set of
points such that we can efficiently find the nearest neighbors of a query
point. We extend this method to our novel Set-query LSH (SLSH), such that it
can find the nearest neighbors of a set of points, given as a query.
  Let \( s(x,y) \) be the similarity between two points \( x \) and \( y \). We
define a similarity between a set \( Q\) and a point \( x \) by aggregating the
similarities \( s(p,x) \) for all \( p\in Q \). For example, we can take \( s(p,x) \)
to be the angular similarity between \( p \) and \( x \) (i.e., \(1-{\angle
(x,p)}/{\pi}\)), and aggregate by arithmetic or geometric averaging, or taking
the lowest similarity.
  We develop locality sensitive hash families and data structures for a large
set of such arithmetic and geometric averaging similarities, and analyze their
collision probabilities. We also establish an analogous framework and hash
families for distance functions. Specifically, we give a structure for the
euclidean distance aggregated by either averaging or taking the maximum.
  We leverage SLSH to solve a geometric extension of the approximate near
neighbors problem. In this version, we consider a metric for which the unit
ball is an ellipsoid and its orientation is specified with the query.
  An important application that motivates our work is group recommendation
systems. Such a system embeds movies and users in the same feature space, and
the task of recommending a movie for a group to watch together, translates to a
set-query \( Q \) using an appropriate similarity.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        Recommender Systems 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/kapralov2020scaling/">Scaling Up Kernel Ridge Regression Via Locality Sensitive Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Scaling Up Kernel Ridge Regression Via Locality Sensitive Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Scaling Up Kernel Ridge Regression Via Locality Sensitive Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Kapralov et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>7</td>
    <td><p>Random binning features, introduced in the seminal paper of Rahimi and Recht
(2007), are an efficient method for approximating a kernel matrix using
locality sensitive hashing. Random binning features provide a very simple and
efficient way of approximating the Laplace kernel but unfortunately do not
apply to many important classes of kernels, notably ones that generate smooth
Gaussian processes, such as the Gaussian kernel and Matern kernel. In this
paper, we introduce a simple weighted version of random binning features and
show that the corresponding kernel function generates Gaussian processes of any
desired smoothness. We show that our weighted random binning features provide a
spectral approximation to the corresponding kernel matrix, leading to efficient
algorithms for kernel ridge regression. Experiments on large scale regression
datasets show that our method outperforms the accuracy of random Fourier
features method.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/karpusha2020calibrated/">Calibrated Neighborhood Aware Confidence Measure For Deep Metric Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Calibrated Neighborhood Aware Confidence Measure For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Calibrated Neighborhood Aware Confidence Measure For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Karpusha Maryna, Yun Sunghee, Fehervari Istvan</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>102</td>
    <td><p>Deep metric learning has gained promising improvement in recent years
following the success of deep learning. It has been successfully applied to
problems in few-shot learning, image retrieval, and open-set classifications.
However, measuring the confidence of a deep metric learning model and
identifying unreliable predictions is still an open challenge. This paper
focuses on defining a calibrated and interpretable confidence metric that
closely reflects its classification accuracy. While performing similarity
comparison directly in the latent space using the learned distance metric, our
approach approximates the distribution of data points for each class using a
Gaussian kernel smoothing function. The post-processing calibration algorithm
with proposed confidence metric on the held-out validation dataset improves
generalization and robustness of state-of-the-art deep metric learning models
while provides an interpretable estimation of the confidence. Extensive tests
on four popular benchmark datasets (Caltech-UCSD Birds, Stanford Online
Product, Stanford Car-196, and In-shop Clothes Retrieval) show consistent
improvements even at the presence of distribution shifts in test data related
to additional noise or adversarial examples.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Distance Metric Learning 
      
        CVPR 
      
        Alt 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/kang2020learning/">Learning To Embed Categorical Features Without Embedding Tables For Recommendation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning To Embed Categorical Features Without Embedding Tables For Recommendation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning To Embed Categorical Features Without Embedding Tables For Recommendation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Kang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining</td>
    <td>34</td>
    <td><p>Embedding learning of categorical features (e.g. user/item IDs) is at the
core of various recommendation models including matrix factorization and neural
collaborative filtering. The standard approach creates an embedding table where
each row represents a dedicated embedding vector for every unique feature
value. However, this method fails to efficiently handle high-cardinality
features and unseen feature values (e.g. new video ID) that are prevalent in
real-world recommendation systems. In this paper, we propose an alternative
embedding framework Deep Hash Embedding (DHE), replacing embedding tables by a
deep embedding network to compute embeddings on the fly. DHE first encodes the
feature value to a unique identifier vector with multiple hashing functions and
transformations, and then applies a DNN to convert the identifier vector to an
embedding. The encoding module is deterministic, non-learnable, and free of
storage, while the embedding network is updated during the training time to
learn embedding generation. Empirical results show that DHE achieves comparable
AUC against the standard one-hot full embedding, with smaller model sizes. Our
work sheds light on the design of DNN-based alternative embedding schemes for
categorical features without using embedding table lookup.</p>
</td>
    <td>
      
        KDD 
      
        Hashing Methods 
      
        Alt 
      
        Recommender Systems 
      
        Neural Hashing 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/kanda2020succinct/">Succinct Trit-array Trie For Scalable Trajectory Similarity Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Succinct Trit-array Trie For Scalable Trajectory Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Succinct Trit-array Trie For Scalable Trajectory Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Kanda et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 28th International Conference on Advances in Geographic Information Systems</td>
    <td>11</td>
    <td><p>Massive datasets of spatial trajectories representing the mobility of a
diversity of moving objects are ubiquitous in research and industry. Similarity
search of a large collection of trajectories is indispensable for turning these
datasets into knowledge. Locality sensitive hashing (LSH) is a powerful
technique for fast similarity searches. Recent methods employ LSH and attempt
to realize an efficient similarity search of trajectories; however, those
methods are inefficient in terms of search time and memory when applied to
massive datasets. To address this problem, we present the trajectory-indexing
succinct trit-array trie (tSTAT), which is a scalable method leveraging LSH for
trajectory similarity searches. tSTAT quickly performs the search on a tree
data structure called trie. We also present two novel techniques that enable to
dramatically enhance the memory efficiency of tSTAT. One is a node reduction
technique that substantially omits redundant trie nodes while maintaining the
time performance. The other is a space-efficient representation that leverages
the idea behind succinct data structures (i.e., a compressed data structure
supporting fast data operations). We experimentally test tSTAT on its ability
to retrieve similar trajectories for a query from large collections of
trajectories and show that tSTAT performs superiorly in comparison to
state-of-the-art similarity search methods.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/song2020deep/">Deep Robust Multilevel Semantic Cross-modal Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Robust Multilevel Semantic Cross-modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Robust Multilevel Semantic Cross-modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Song Ge, Zhao Jun, Tan Xiaoyang</td> <!-- ðŸ”§ You were missing this -->
    <td>Pattern Recognition</td>
    <td>21</td>
    <td><p>Hashing based cross-modal retrieval has recently made significant progress.
But straightforward embedding data from different modalities into a joint
Hamming space will inevitably produce false codes due to the intrinsic modality
discrepancy and noises. We present a novel Robust Multilevel Semantic Hashing
(RMSH) for more accurate cross-modal retrieval. It seeks to preserve
fine-grained similarity among data with rich semantics, while explicitly
require distances between dissimilar points to be larger than a specific value
for strong robustness. For this, we give an effective bound of this value based
on the information coding-theoretic analysis, and the above goals are embodied
into a margin-adaptive triplet loss. Furthermore, we introduce pseudo-codes via
fusing multiple hash codes to explore seldom-seen semantics, alleviating the
sparsity problem of similarity information. Experiments on three benchmarks
show the validity of the derived bounds, and our method achieves
state-of-the-art performance.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        CVPR 
      
        Text Retrieval 
      
        Multimodal Retrieval 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/jose2020optimized/">Optimized Feature Space Learning For Generating Efficient Binary Codes For Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Optimized Feature Space Learning For Generating Efficient Binary Codes For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Optimized Feature Space Learning For Generating Efficient Binary Codes For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jose et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Signal Processing: Image Communication</td>
    <td>7</td>
    <td><p>In this paper we propose an approach for learning low dimensional optimized
feature space with minimum intra-class variance and maximum inter-class
variance. We address the problem of high-dimensionality of feature vectors
extracted from neural networks by taking care of the global statistics of
feature space. Classical approach of Linear Discriminant Analysis (LDA) is
generally used for generating an optimized low dimensional feature space for
single-labeled images. Since, image retrieval involves both multi-labeled and
single-labeled images, we utilize the equivalence between LDA and Canonical
Correlation Analysis (CCA) to generate an optimized feature space for
single-labeled images and use CCA to generate an optimized feature space for
multi-labeled images. Our approach correlates the projections of feature
vectors with label vectors in our CCA based network architecture. The neural
network minimize a loss function which maximizes the correlation coefficients.
We binarize our generated feature vectors with the popular Iterative
Quantization (ITQ) approach and also propose an ensemble network to generate
binary codes of desired bit length for image retrieval. Our measurement of mean
average precision shows competitive results on other state-of-the-art
single-labeled and multi-labeled image retrieval datasets.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Compact Codes 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/zhu2020dual/">Dual-level Semantic Transfer Deep Hashing For Efficient Social Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Dual-level Semantic Transfer Deep Hashing For Efficient Social Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Dual-level Semantic Transfer Deep Hashing For Efficient Social Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Circuits and Systems for Video Technology</td>
    <td>38</td>
    <td><p>Social network stores and disseminates a tremendous amount of user shared
images. Deep hashing is an efficient indexing technique to support large-scale
social image retrieval, due to its deep representation capability, fast
retrieval speed and low storage cost. Particularly, unsupervised deep hashing
has well scalability as it does not require any manually labelled data for
training. However, owing to the lacking of label guidance, existing methods
suffer from severe semantic shortage when optimizing a large amount of deep
neural network parameters. Differently, in this paper, we propose a Dual-level
Semantic Transfer Deep Hashing (DSTDH) method to alleviate this problem with a
unified deep hash learning framework. Our model targets at learning the
semantically enhanced deep hash codes by specially exploiting the
user-generated tags associated with the social images. Specifically, we design
a complementary dual-level semantic transfer mechanism to efficiently discover
the potential semantics of tags and seamlessly transfer them into binary hash
codes. On the one hand, instance-level semantics are directly preserved into
hash codes from the associated tags with adverse noise removing. Besides, an
image-concept hypergraph is constructed for indirectly transferring the latent
high-order semantic correlations of images and tags into hash codes. Moreover,
the hash codes are obtained simultaneously with the deep representation
learning by the discrete hash optimization strategy. Extensive experiments on
two public social image retrieval datasets validate the superior performance of
our method compared with state-of-the-art hashing methods. The source codes of
our method can be obtained at https://github.com/research2020-1/DSTDH</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Neural Hashing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/xiong2020approximate/">Approximate Nearest Neighbor Negative Contrastive Learning For Dense Text Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Approximate Nearest Neighbor Negative Contrastive Learning For Dense Text Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Approximate Nearest Neighbor Negative Contrastive Learning For Dense Text Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Xiong et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>356</td>
    <td><p>Conducting text retrieval in a dense learned representation space has many
intriguing advantages over sparse retrieval. Yet the effectiveness of dense
retrieval (DR) often requires combination with sparse retrieval. In this paper,
we identify that the main bottleneck is in the training mechanisms, where the
negative instances used in training are not representative of the irrelevant
documents in testing. This paper presents Approximate nearest neighbor Negative
Contrastive Estimation (ANCE), a training mechanism that constructs negatives
from an Approximate Nearest Neighbor (ANN) index of the corpus, which is
parallelly updated with the learning process to select more realistic negative
training instances. This fundamentally resolves the discrepancy between the
data distribution used in the training and testing of DR. In our experiments,
ANCE boosts the BERT-Siamese DR model to outperform all competitive dense and
sparse retrieval baselines. It nearly matches the accuracy of
sparse-retrieval-and-BERT-reranking using dot-product in the ANCE-learned
representation space and provides almost 100x speed-up.</p>
</td>
    <td>
      
        Text Retrieval 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/wang2020deep/">Deep Reinforcement Learning With Label Embedding Reward For Supervised Image Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Reinforcement Learning With Label Embedding Reward For Supervised Image Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Reinforcement Learning With Label Embedding Reward For Supervised Image Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang Zhenzhen, Hong Weixiang, Yuan Junsong</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>214</td>
    <td><p>Deep hashing has shown promising results in image retrieval and recognition.
Despite its success, most existing deep hashing approaches are rather similar:
either multi-layer perceptron or CNN is applied to extract image feature,
followed by different binarization activation functions such as sigmoid, tanh
or autoencoder to generate binary code. In this work, we introduce a novel
decision-making approach for deep supervised hashing. We formulate the hashing
problem as travelling across the vertices in the binary code space, and learn a
deep Q-network with a novel label embedding reward defined by
Bose-Chaudhuri-Hocquenghem (BCH) codes to explore the best path. Extensive
experiments and analysis on the CIFAR-10 and NUS-WIDE dataset show that our
approach outperforms state-of-the-art supervised hashing methods under various
code lengths.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        CVPR 
      
        Compact Codes 
      
        Neural Hashing 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/zhang2020leveraging/">Leveraging Local And Global Descriptors In Parallel To Search Correspondences For Visual Localization</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Leveraging Local And Global Descriptors In Parallel To Search Correspondences For Visual Localization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Leveraging Local And Global Descriptors In Parallel To Search Correspondences For Visual Localization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang Pengju, Wu Yihong, Liu Bingxi</td> <!-- ðŸ”§ You were missing this -->
    <td>Pattern Recognition</td>
    <td>13</td>
    <td><p>Visual localization to compute 6DoF camera pose from a given image has wide
applications such as in robotics, virtual reality, augmented reality, etc. Two
kinds of descriptors are important for the visual localization. One is global
descriptors that extract the whole feature from each image. The other is local
descriptors that extract the local feature from each image patch usually
enclosing a key point. More and more methods of the visual localization have
two stages: at first to perform image retrieval by global descriptors and then
from the retrieval feedback to make 2D-3D point correspondences by local
descriptors. The two stages are in serial for most of the methods. This simple
combination has not achieved superiority of fusing local and global
descriptors. The 3D points obtained from the retrieval feedback are as the
nearest neighbor candidates of the 2D image points only by global descriptors.
Each of the 2D image points is also called a query local feature when
performing the 2D-3D point correspondences. In this paper, we propose a novel
parallel search framework, which leverages advantages of both local and global
descriptors to get nearest neighbor candidates of a query local feature.
Specifically, besides using deep learning based global descriptors, we also
utilize local descriptors to construct random tree structures for obtaining
nearest neighbor candidates of the query local feature. We propose a new
probabilistic model and a new deep learning based local descriptor when
constructing the random trees. A weighted Hamming regularization term to keep
discriminativeness after binarization is given in the loss function for the
proposed local descriptor. The loss function co-trains both real and binary
descriptors of which the results are integrated into the random trees.</p>
</td>
    <td>
      
        CVPR 
      
        Image Retrieval 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/jang2020generalized/">Generalized Product Quantization Network For Semi-supervised Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Generalized Product Quantization Network For Semi-supervised Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Generalized Product Quantization Network For Semi-supervised Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jang Young Kyun, Cho Nam Ik</td> <!-- ðŸ”§ You were missing this -->
    <td>2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>41</td>
    <td><p>Image retrieval methods that employ hashing or vector quantization have
achieved great success by taking advantage of deep learning. However, these
approaches do not meet expectations unless expensive label information is
sufficient. To resolve this issue, we propose the first quantization-based
semi-supervised image retrieval scheme: Generalized Product Quantization (GPQ)
network. We design a novel metric learning strategy that preserves semantic
similarity between labeled data, and employ entropy regularization term to
fully exploit inherent potentials of unlabeled data. Our solution increases the
generalization capacity of the quantization network, which allows overcoming
previous limitations in the retrieval community. Extensive experimental results
demonstrate that GPQ yields state-of-the-art performance on large-scale real
image benchmark datasets.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        CVPR 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/%C3%B1anculef2020self/">Self-supervised Bernoulli Autoencoders For Semi-supervised Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Self-supervised Bernoulli Autoencoders For Semi-supervised Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Self-supervised Bernoulli Autoencoders For Semi-supervised Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ã‘anculef et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>5</td>
    <td><p>Semantic hashing is an emerging technique for large-scale similarity search
based on representing high-dimensional data using similarity-preserving binary
codes used for efficient indexing and search. It has recently been shown that
variational autoencoders, with Bernoulli latent representations parametrized by
neural nets, can be successfully trained to learn such codes in supervised and
unsupervised scenarios, improving on more traditional methods thanks to their
ability to handle the binary constraints architecturally. However, the scenario
where labels are scarce has not been studied yet.
  This paper investigates the robustness of hashing methods based on
variational autoencoders to the lack of supervision, focusing on two
semi-supervised approaches currently in use. The first augments the variational
autoencoderâ€™s training objective to jointly model the distribution over the
data and the class labels. The second approach exploits the annotations to
define an additional pairwise loss that enforces consistency between the
similarity in the code (Hamming) space and the similarity in the label space.
Our experiments show that both methods can significantly increase the hash
codesâ€™ quality. The pairwise approach can exhibit an advantage when the number
of labelled points is large. However, we found that this method degrades
quickly and loses its advantage when labelled samples decrease. To circumvent
this problem, we propose a novel supervision method in which the model uses its
label distribution predictions to implement the pairwise objective. Compared to
the best baseline, this procedure yields similar performance in fully
supervised settings but improves the results significantly when labelled data
is scarce. Our code is made publicly available at
https://github.com/amacaluso/SSB-VAE.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Text Retrieval 
      
        Similarity Search 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/hu2020creating/">Creating Something From Nothing: Unsupervised Knowledge Distillation For Cross-modal Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Creating Something From Nothing: Unsupervised Knowledge Distillation For Cross-modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Creating Something From Nothing: Unsupervised Knowledge Distillation For Cross-modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Hu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>117</td>
    <td><p>In recent years, cross-modal hashing (CMH) has attracted increasing
attentions, mainly because its potential ability of mapping contents from
different modalities, especially in vision and language, into the same space,
so that it becomes efficient in cross-modal data retrieval. There are two main
frameworks for CMH, differing from each other in whether semantic supervision
is required. Compared to the unsupervised methods, the supervised methods often
enjoy more accurate results, but require much heavier labors in data
annotation. In this paper, we propose a novel approach that enables guiding a
supervised method using outputs produced by an unsupervised method.
Specifically, we make use of teacher-student optimization for propagating
knowledge. Experiments are performed on two popular CMH benchmarks, i.e., the
MIRFlickr and NUS-WIDE datasets. Our approach outperforms all existing
unsupervised methods by a large margin.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        CVPR 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/pan2020tcdesc/">Tcdesc: Learning Topology Consistent Descriptors For Image Matching</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Tcdesc: Learning Topology Consistent Descriptors For Image Matching' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Tcdesc: Learning Topology Consistent Descriptors For Image Matching' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Pan et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Circuits and Systems for Video Technology</td>
    <td>24</td>
    <td><p>The constraint of neighborhood consistency or local consistency is widely
used for robust image matching. In this paper, we focus on learning
neighborhood topology consistent descriptors (TCDesc), while former works of
learning descriptors, such as HardNet and DSM, only consider point-to-point
Euclidean distance among descriptors and totally neglect neighborhood
information of descriptors. To learn topology consistent descriptors, first we
propose the linear combination weights to depict the topological relationship
between center descriptor and its kNN descriptors, where the difference between
center descriptor and the linear combination of its kNN descriptors is
minimized. Then we propose the global mapping function which maps the local
linear combination weights to the global topology vector and define the
topology distance of matching descriptors as l1 distance between their topology
vectors. Last we employ adaptive weighting strategy to jointly minimize
topology distance and Euclidean distance, which automatically adjust the weight
or attention of two distances in triplet loss. Our method has the following two
advantages: (1) We are the first to consider neighborhood information of
descriptors, while former works mainly focus on neighborhood consistency of
feature points; (2) Our method can be applied in any former work of learning
descriptors by triplet loss. Experimental results verify the generalization of
our method: We can improve the performances of both HardNet and DSM on several
benchmarks.</p>
</td>
    <td>
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/helbling2020directed/">Directed Graph Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Directed Graph Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Directed Graph Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Helbling Caleb</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Cybernetics</td>
    <td>23</td>
    <td><p>This paper presents several algorithms for hashing directed graphs. The
algorithms given are capable of hashing entire graphs as well as assigning hash
values to specific nodes in a given graph. The notion of node symmetry is made
precise via computation of vertex orbits and the graph automorphism group, and
nodes that are symmetrically identical are assigned equal hashes. We also
present a novel Merkle-style hashing algorithm that seeks to fulfill the
recursive principle that a hash of a node should depend only on the hash of its
neighbors. This algorithm works even in the presence of cycles, which would not
be possible with a naive approach. Structurally hashing trees has seen
widespread use in blockchain, source code version control, and web
applications. Despite the popularity of tree hashing, directed graph hashing
remains unstudied in the literature. Our algorithms open new possibilities to
hashing both directed graphs and more complex data structures that can be
reduced to directed graphs such as hypergraphs.</p>
</td>
    <td>
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/hoang2020unsupervised/">Unsupervised Deep Cross-modality Spectral Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Unsupervised Deep Cross-modality Spectral Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Unsupervised Deep Cross-modality Spectral Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Hoang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Image Processing</td>
    <td>27</td>
    <td><p>This paper presents a novel framework, namely Deep Cross-modality Spectral
Hashing (DCSH), to tackle the unsupervised learning problem of binary hash
codes for efficient cross-modal retrieval. The framework is a two-step hashing
approach which decouples the optimization into (1) binary optimization and (2)
hashing function learning. In the first step, we propose a novel spectral
embedding-based algorithm to simultaneously learn single-modality and binary
cross-modality representations. While the former is capable of well preserving
the local structure of each modality, the latter reveals the hidden patterns
from all modalities. In the second step, to learn mapping functions from
informative data inputs (images and word embeddings) to binary codes obtained
from the first step, we leverage the powerful CNN for images and propose a
CNN-based deep architecture to learn text modality. Quantitative evaluations on
three standard benchmark datasets demonstrate that the proposed DCSH method
consistently outperforms other state-of-the-art methods.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Multimodal Retrieval 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/hansen2020content/">Content-aware Neural Hashing For Cold-start Recommendation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Content-aware Neural Hashing For Cold-start Recommendation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Content-aware Neural Hashing For Cold-start Recommendation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Hansen et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</td>
    <td>36</td>
    <td><p>Content-aware recommendation approaches are essential for providing
meaningful recommendations for \textit{new} (i.e., \textit{cold-start}) items
in a recommender system. We present a content-aware neural hashing-based
collaborative filtering approach (NeuHash-CF), which generates binary hash
codes for users and items, such that the highly efficient Hamming distance can
be used for estimating user-item relevance. NeuHash-CF is modelled as an
autoencoder architecture, consisting of two joint hashing components for
generating user and item hash codes. Inspired from semantic hashing, the item
hashing component generates a hash code directly from an itemâ€™s content
information (i.e., it generates cold-start and seen item hash codes in the same
manner). This contrasts existing state-of-the-art models, which treat the two
item cases separately. The user hash codes are generated directly based on user
id, through learning a user embedding matrix. We show experimentally that
NeuHash-CF significantly outperforms state-of-the-art baselines by up to 12%
NDCG and 13% MRR in cold-start recommendation settings, and up to 4% in both
NDCG and MRR in standard settings where all items are present while training.
Our approach uses 2-4x shorter hash codes, while obtaining the same or better
performance compared to the state of the art, thus consequently also enabling a
notable storage reduction.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Text Retrieval 
      
        Recommender Systems 
      
        Neural Hashing 
      
        SIGIR 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/hansen2020unsupervised/">Unsupervised Semantic Hashing With Pairwise Reconstruction</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Unsupervised Semantic Hashing With Pairwise Reconstruction' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Unsupervised Semantic Hashing With Pairwise Reconstruction' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Hansen et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</td>
    <td>22</td>
    <td><p>Semantic Hashing is a popular family of methods for efficient similarity
search in large-scale datasets. In Semantic Hashing, documents are encoded as
short binary vectors (i.e., hash codes), such that semantic similarity can be
efficiently computed using the Hamming distance. Recent state-of-the-art
approaches have utilized weak supervision to train better performing hashing
models. Inspired by this, we present Semantic Hashing with Pairwise
Reconstruction (PairRec), which is a discrete variational autoencoder based
hashing model. PairRec first encodes weakly supervised training pairs (a query
document and a semantically similar document) into two hash codes, and then
learns to reconstruct the same query document from both of these hash codes
(i.e., pairwise reconstruction). This pairwise reconstruction enables our model
to encode local neighbourhood structures within the hash code directly through
the decoder. We experimentally compare PairRec to traditional and
state-of-the-art approaches, and obtain significant performance improvements in
the task of document similarity search.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Text Retrieval 
      
        SIGIR 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/guo2020deep/">Deep Kernel Supervised Hashing For Node Classification In Structural Networks</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Kernel Supervised Hashing For Node Classification In Structural Networks' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Kernel Supervised Hashing For Node Classification In Structural Networks' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Guo et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Information Sciences</td>
    <td>5</td>
    <td><p>Node classification in structural networks has been proven to be useful in
many real world applications. With the development of network embedding, the
performance of node classification has been greatly improved. However, nearly
all the existing network embedding based methods are hard to capture the actual
category features of a node because of the linearly inseparable problem in
low-dimensional space; meanwhile they cannot incorporate simultaneously network
structure information and node label information into network embedding. To
address the above problems, in this paper, we propose a novel Deep Kernel
Supervised Hashing (DKSH) method to learn the hashing representations of nodes
for node classification. Specifically, a deep multiple kernel learning is first
proposed to map nodes into suitable Hilbert space to deal with linearly
inseparable problem. Then, instead of only considering structural similarity
between two nodes, a novel similarity matrix is designed to merge both network
structure information and node label information. Supervised by the similarity
matrix, the learned hashing representations of nodes simultaneously preserve
the two kinds of information well from the learned Hilbert space. Extensive
experiments show that the proposed method significantly outperforms the
state-of-the-art baselines over three real world benchmark datasets.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/gu2020symmetrical/">Symmetrical Synthesis For Deep Metric Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Symmetrical Synthesis For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Symmetrical Synthesis For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Gu Geonmo, Ko Byungsoo</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>21</td>
    <td><p>Deep metric learning aims to learn embeddings that contain semantic
similarity information among data points. To learn better embeddings, methods
to generate synthetic hard samples have been proposed. Existing methods of
synthetic hard sample generation are adopting autoencoders or generative
adversarial networks, but this leads to more hyper-parameters, harder
optimization, and slower training speed. In this paper, we address these
problems by proposing a novel method of synthetic hard sample generation called
symmetrical synthesis. Given two original feature points from the same class,
the proposed method firstly generates synthetic points with each other as an
axis of symmetry. Secondly, it performs hard negative pair mining within the
original and synthetic points to select a more informative negative pair for
computing the metric learning loss. Our proposed method is hyper-parameter free
and plug-and-play for existing metric learning losses without network
modification. We demonstrate the superiority of our proposed method over
existing methods for a variety of loss functions on clustering and image
retrieval tasks. Our implementations is publicly available.</p>
</td>
    <td>
      
        AAAI 
      
        Distance Metric Learning 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/nikoli%C4%872020bitpruning/">Bitpruning: Learning Bitlengths For Aggressive And Accurate Quantization</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Bitpruning: Learning Bitlengths For Aggressive And Accurate Quantization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Bitpruning: Learning Bitlengths For Aggressive And Accurate Quantization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>NikoliÄ‡ et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>13</td>
    <td><p>Neural networks have demonstrably achieved state-of-the art accuracy using
low-bitlength integer quantization, yielding both execution time and energy
benefits on existing hardware designs that support short bitlengths. However,
the question of finding the minimum bitlength for a desired accuracy remains
open. We introduce a training method for minimizing inference bitlength at any
granularity while maintaining accuracy. Namely, we propose a regularizer that
penalizes large bitlength representations throughout the architecture and show
how it can be modified to minimize other quantifiable criteria, such as number
of operations or memory footprint. We demonstrate that our method learns
thrifty representations while maintaining accuracy. With ImageNet, the method
produces an average per layer bitlength of 4.13, 3.76 and 4.36 bits on AlexNet,
ResNet18 and MobileNet V2 respectively, remaining within 2.0%, 0.5% and 0.5% of
the base TOP-1 accuracy.</p>
</td>
    <td>
      
        Quantization 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/garg2020fast/">Fast, Compact And Highly Scalable Visual Place Recognition Through Sequence-based Matching Of Overloaded Representations</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fast, Compact And Highly Scalable Visual Place Recognition Through Sequence-based Matching Of Overloaded Representations' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fast, Compact And Highly Scalable Visual Place Recognition Through Sequence-based Matching Of Overloaded Representations' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Garg Sourav, Milford Michael</td> <!-- ðŸ”§ You were missing this -->
    <td>2020 IEEE International Conference on Robotics and Automation (ICRA)</td>
    <td>14</td>
    <td><p>Visual place recognition algorithms trade off three key characteristics:
their storage footprint, their computational requirements, and their resultant
performance, often expressed in terms of recall rate. Significant prior work
has investigated highly compact place representations, sub-linear computational
scaling and sub-linear storage scaling techniques, but have always involved a
significant compromise in one or more of these regards, and have only been
demonstrated on relatively small datasets. In this paper we present a novel
place recognition system which enables for the first time the combination of
ultra-compact place representations, near sub-linear storage scaling and
extremely lightweight compute requirements. Our approach exploits the
inherently sequential nature of much spatial data in the robotics domain and
inverts the typical target criteria, through intentionally coarse scalar
quantization-based hashing that leads to more collisions but is resolved by
sequence-based matching. For the first time, we show how effective place
recognition rates can be achieved on a new very large 10 million place dataset,
requiring only 8 bytes of storage per place and 37K unitary operations to
achieve over 50% recall for matching a sequence of 100 frames, where a
conventional state-of-the-art approach both consumes 1300 times more compute
and fails catastrophically. We present analysis investigating the effectiveness
of our hashing overload approach under varying sizes of quantized vector
length, comparison of near miss matches with the actual match selections and
characterise the effect of variance re-scaling of data on quantization.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        Quantization 
      
        ICRA 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/weng2020random/">Random VLAD Based Deep Hashing For Efficient Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Random VLAD Based Deep Hashing For Efficient Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Random VLAD Based Deep Hashing For Efficient Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Weng et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2016 IEEE International Conference on Multimedia and Expo (ICME)</td>
    <td>9</td>
    <td><p>Image hash algorithms generate compact binary representations that can be
quickly matched by Hamming distance, thus become an efficient solution for
large-scale image retrieval. This paper proposes RV-SSDH, a deep image hash
algorithm that incorporates the classical VLAD (vector of locally aggregated
descriptors) architecture into neural networks. Specifically, a novel neural
network component is formed by coupling a random VLAD layer with a latent hash
layer through a transform layer. This component can be combined with
convolutional layers to realize a hash algorithm. We implement RV-SSDH as a
point-wise algorithm that can be efficiently trained by minimizing
classification error and quantization loss. Comprehensive experiments show this
new architecture significantly outperforms baselines such as NetVLAD and SSDH,
and offers a cost-effective trade-off in the state-of-the-art. In addition, the
proposed random VLAD layer leads to satisfactory accuracy with low complexity,
thus shows promising potentials as an alternative to NetVLAD.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Alt 
      
        Neural Hashing 
      
        Quantization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/weng2020fast/">Fast Search On Binary Codes By Weighted Hamming Distance</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fast Search On Binary Codes By Weighted Hamming Distance' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fast Search On Binary Codes By Weighted Hamming Distance' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Weng Zhenyu, Zhu Yuesheng, Liu Ruixin</td> <!-- ðŸ”§ You were missing this -->
    <td>2013 IEEE International Conference on Acoustics, Speech and Signal Processing</td>
    <td>11</td>
    <td><p>Weighted Hamming distance, as a similarity measure between binary codes and
binary queries, provides superior accuracy in search tasks than Hamming
distance. However, how to efficiently and accurately find \(K\) binary codes that
have the smallest weighted Hamming distance to the query remains an open issue.
In this paper, a fast search algorithm is proposed to perform the
non-exhaustive search for \(K\) nearest binary codes by weighted Hamming
distance. By using binary codes as direct bucket indices in a hash table, the
search algorithm generates a sequence to probe the buckets based on the
independence characteristic of the weights for each bit. Furthermore, a fast
search framework based on the proposed search algorithm is designed to solve
the problem of long binary codes. Specifically, long binary codes are split
into substrings and multiple hash tables are built on them. Then, the search
algorithm probes the buckets to obtain candidates according to the generated
substring indices, and a merging algorithm is proposed to find the nearest
binary codes by merging the candidates. Theoretical analysis and experimental
results demonstrate that the search algorithm improves the search accuracy
compared to other non-exhaustive algorithms and provides orders-of-magnitude
faster search than the linear scan baseline.</p>
</td>
    <td>
      
        ICASSP 
      
        Tools & Libraries 
      
        Compact Codes 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/fu2020deep/">Deep Momentum Uncertainty Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Momentum Uncertainty Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Momentum Uncertainty Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Fu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Pattern Recognition</td>
    <td>15</td>
    <td><p>Combinatorial optimization (CO) has been a hot research topic because of its
theoretic and practical importance. As a classic CO problem, deep hashing aims
to find an optimal code for each data from finite discrete possibilities, while
the discrete nature brings a big challenge to the optimization process.
Previous methods usually mitigate this challenge by binary approximation,
substituting binary codes for real-values via activation functions or
regularizations. However, such approximation leads to uncertainty between
real-values and binary ones, degrading retrieval performance. In this paper, we
propose a novel Deep Momentum Uncertainty Hashing (DMUH). It explicitly
estimates the uncertainty during training and leverages the uncertainty
information to guide the approximation process. Specifically, we model
bit-level uncertainty via measuring the discrepancy between the output of a
hashing network and that of a momentum-updated network. The discrepancy of each
bit indicates the uncertainty of the hashing network to the approximate output
of that bit. Meanwhile, the mean discrepancy of all bits in a hashing code can
be regarded as image-level uncertainty. It embodies the uncertainty of the
hashing network to the corresponding input image. The hashing bit and image
with higher uncertainty are paid more attention during optimization. To the
best of our knowledge, this is the first work to study the uncertainty in
hashing bits. Extensive experiments are conducted on four datasets to verify
the superiority of our method, including CIFAR-10, NUS-WIDE, MS-COCO, and a
million-scale dataset Clothing1M. Our method achieves the best performance on
all of the datasets and surpasses existing state-of-the-art methods by a large
margin.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        CVPR 
      
        Compact Codes 
      
        Neural Hashing 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/frady2020neuromorphic/">Neuromorphic Nearest-neighbor Search Using Intel's Pohoiki Springs</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Neuromorphic Nearest-neighbor Search Using Intel's Pohoiki Springs' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Neuromorphic Nearest-neighbor Search Using Intel's Pohoiki Springs' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Frady et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the Neuro-inspired Computational Elements Workshop</td>
    <td>47</td>
    <td><p>Neuromorphic computing applies insights from neuroscience to uncover
innovations in computing technology. In the brain, billions of interconnected
neurons perform rapid computations at extremely low energy levels by leveraging
properties that are foreign to conventional computing systems, such as temporal
spiking codes and finely parallelized processing units integrating both memory
and computation. Here, we showcase the Pohoiki Springs neuromorphic system, a
mesh of 768 interconnected Loihi chips that collectively implement 100 million
spiking neurons in silicon. We demonstrate a scalable approximate k-nearest
neighbor (k-NN) algorithm for searching large databases that exploits
neuromorphic principles. Compared to state-of-the-art conventional CPU-based
implementations, we achieve superior latency, index build time, and energy
efficiency when evaluated on several standard datasets containing over 1
million high-dimensional patterns. Further, the system supports adding new data
points to the indexed database online in O(1) time unlike all but brute force
conventional k-NN implementations.</p>
</td>
    <td>
      
        DATASETS 
      
        Tools & Libraries 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/riba2020learning/">Learning Graph Edit Distance By Graph Neural Networks</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning Graph Edit Distance By Graph Neural Networks' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning Graph Edit Distance By Graph Neural Networks' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Riba et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Pattern Recognition</td>
    <td>25</td>
    <td><p>The emergence of geometric deep learning as a novel framework to deal with
graph-based representations has faded away traditional approaches in favor of
completely new methodologies. In this paper, we propose a new framework able to
combine the advances on deep metric learning with traditional approximations of
the graph edit distance. Hence, we propose an efficient graph distance based on
the novel field of geometric deep learning. Our method employs a message
passing neural network to capture the graph structure, and thus, leveraging
this information for its use on a distance computation. The performance of the
proposed graph distance is validated on two different scenarios. On the one
hand, in a graph retrieval of handwritten words~\ie~keyword spotting, showing
its superior performance when compared with (approximate) graph edit distance
benchmarks. On the other hand, demonstrating competitive results for graph
similarity learning when compared with the current state-of-the-art on a recent
benchmark dataset.</p>
</td>
    <td>
      
        DATASETS 
      
        Graph Based ANN 
      
        Distance Metric Learning 
      
        CVPR 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/feinberg2020chromatic/">Chromatic Learning For Sparse Datasets</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Chromatic Learning For Sparse Datasets' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Chromatic Learning For Sparse Datasets' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Feinberg Vladimir, Bailis Peter</td> <!-- ðŸ”§ You were missing this -->
    <td>Image and Vision Computing</td>
    <td>15</td>
    <td><p>Learning over sparse, high-dimensional data frequently necessitates the use
of specialized methods such as the hashing trick. In this work, we design a
highly scalable alternative approach that leverages the low degree of feature
co-occurrences present in many practical settings. This approach, which we call
Chromatic Learning (CL), obtains a low-dimensional dense feature representation
by performing graph coloring over the co-occurrence graph of featuresâ€”an
approach previously used as a runtime performance optimization for GBDT
training. This color-based dense representation can be combined with additional
dense categorical encoding approaches, e.g., submodular feature compression, to
further reduce dimensionality. CL exhibits linear parallelizability and
consumes memory linear in the size of the co-occurrence graph. By leveraging
the structural properties of the co-occurrence graph, CL can compress sparse
datasets, such as KDD Cup 2012, that contain over 50M features down to 1024,
using an order of magnitude fewer features than frequency-based truncation and
the hashing trick while maintaining the same test error for linear models. This
compression further enables the use of deep networks in this wide, sparse
setting, where CL similarly has favorable performance compared to existing
baselines for budgeted input dimension.</p>
</td>
    <td>
      
        KDD 
      
        DATASETS 
      
        Hashing Methods 
      
        Alt 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/zhan2020weakly/">Weakly-supervised Online Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Weakly-supervised Online Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Weakly-supervised Online Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhan et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2021 IEEE International Conference on Multimedia and Expo (ICME)</td>
    <td>8</td>
    <td><p>With the rapid development of social websites, recent years have witnessed an
explosive growth of social images with user-provided tags which continuously
arrive in a streaming fashion. Due to the fast query speed and low storage
cost, hashing-based methods for image search have attracted increasing
attention. However, existing hashing methods for social image retrieval are
based on batch mode which violates the nature of social images, i.e., social
images are usually generated periodically or collected in a stream fashion.
Although there exist many online image hashing methods, they either adopt
unsupervised learning which ignore the relevant tags, or are designed in the
supervised manner which needs high-quality labels. In this paper, to overcome
the above limitations, we propose a new method named Weakly-supervised Online
Hashing (WOH). In order to learn high-quality hash codes, WOH exploits the weak
supervision by considering the semantics of tags and removing the noise.
Besides, We develop a discrete online optimization algorithm for WOH, which is
efficient and scalable. Extensive experiments conducted on two real-world
datasets demonstrate the superiority of WOH compared with several
state-of-the-art hashing baselines.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Alt 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/feng2020adversarial/">Adversarial Attack On Deep Product Quantization Network For Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Adversarial Attack On Deep Product Quantization Network For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Adversarial Attack On Deep Product Quantization Network For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Feng et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>43</td>
    <td><p>Deep product quantization network (DPQN) has recently received much attention
in fast image retrieval tasks due to its efficiency of encoding
high-dimensional visual features especially when dealing with large-scale
datasets. Recent studies show that deep neural networks (DNNs) are vulnerable
to input with small and maliciously designed perturbations (a.k.a., adversarial
examples). This phenomenon raises the concern of security issues for DPQN in
the testing/deploying stage as well. However, little effort has been devoted to
investigating how adversarial examples affect DPQN. To this end, we propose
product quantization adversarial generation (PQ-AG), a simple yet effective
method to generate adversarial examples for product quantization based
retrieval systems. PQ-AG aims to generate imperceptible adversarial
perturbations for query images to form adversarial queries, whose nearest
neighbors from a targeted product quantizaiton model are not semantically
related to those from the original queries. Extensive experiments show that our
PQ-AQ successfully creates adversarial examples to mislead targeted product
quantization retrieval models. Besides, we found that our PQ-AG significantly
degrades retrieval performance in both white-box and black-box settings.</p>
</td>
    <td>
      
        Image Retrieval 
      
        AAAI 
      
        DATASETS 
      
        Efficiency And Optimization 
      
        Quantization 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/fang2020attention/">Attention-based Saliency Hashing For Ophthalmic Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Attention-based Saliency Hashing For Ophthalmic Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Attention-based Saliency Hashing For Ophthalmic Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Fang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2020 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)</td>
    <td>12</td>
    <td><p>Deep hashing methods have been proved to be effective for the large-scale
medical image search assisting reference-based diagnosis for clinicians.
However, when the salient region plays a maximal discriminative role in
ophthalmic image, existing deep hashing methods do not fully exploit the
learning ability of the deep network to capture the features of salient regions
pointedly. The different grades or classes of ophthalmic images may be share
similar overall performance but have subtle differences that can be
differentiated by mining salient regions. To address this issue, we propose a
novel end-to-end network, named Attention-based Saliency Hashing (ASH), for
learning compact hash-code to represent ophthalmic images. ASH embeds a
spatial-attention module to focus more on the representation of salient regions
and highlights their essential role in differentiating ophthalmic images.
Benefiting from the spatial-attention module, the information of salient
regions can be mapped into the hash-code for similarity calculation. In the
training stage, we input the image pairs to share the weights of the network,
and a pairwise loss is designed to maximize the discriminability of the
hash-code. In the retrieval stage, ASH obtains the hash-code by inputting an
image with an end-to-end manner, then the hash-code is used to similarity
calculation to return the most similar images. Extensive experiments on two
different modalities of ophthalmic image datasets demonstrate that the proposed
ASH can further improve the retrieval performance compared to the
state-of-the-art deep hashing methods due to the huge contributions of the
spatial-attention module.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Neural Hashing 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/ryali2020bio/">Bio-inspired Hashing For Unsupervised Similarity Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Bio-inspired Hashing For Unsupervised Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Bio-inspired Hashing For Unsupervised Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ryali et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Cybernetics</td>
    <td>45</td>
    <td><p>The fruit fly Drosophilaâ€™s olfactory circuit has inspired a new locality
sensitive hashing (LSH) algorithm, FlyHash. In contrast with classical LSH
algorithms that produce low dimensional hash codes, FlyHash produces sparse
high-dimensional hash codes and has also been shown to have superior empirical
performance compared to classical LSH algorithms in similarity search. However,
FlyHash uses random projections and cannot learn from data. Building on
inspiration from FlyHash and the ubiquity of sparse expansive representations
in neurobiology, our work proposes a novel hashing algorithm BioHash that
produces sparse high dimensional hash codes in a data-driven manner. We show
that BioHash outperforms previously published benchmarks for various hashing
methods. Since our learning algorithm is based on a local and biologically
plausible synaptic plasticity rule, our work provides evidence for the proposal
that LSH might be a computational reason for the abundance of sparse expansive
motifs in a variety of biological systems. We also propose a convolutional
variant BioConvHash that further improves performance. From the perspective of
computer science, BioHash and BioConvHash are fast, scalable and yield
compressed binary representations that are useful for similarity search.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Similarity Search 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/engelsma2020hers/">HERS: Homomorphically Encrypted Representation Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=HERS: Homomorphically Encrypted Representation Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=HERS: Homomorphically Encrypted Representation Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Engelsma Joshua J., Jain Anil K., Boddeti Vishnu Naresh</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Biometrics, Behavior, and Identity Science</td>
    <td>34</td>
    <td><p>We present a method to search for a probe (or query) image representation
against a large gallery in the encrypted domain. We require that the probe and
gallery images be represented in terms of a fixed-length representation, which
is typical for representations obtained from learned networks. Our encryption
scheme is agnostic to how the fixed-length representation is obtained and can
therefore be applied to any fixed-length representation in any application
domain. Our method, dubbed HERS (Homomorphically Encrypted Representation
Search), operates by (i) compressing the representation towards its estimated
intrinsic dimensionality with minimal loss of accuracy (ii) encrypting the
compressed representation using the proposed fully homomorphic encryption
scheme, and (iii) efficiently searching against a gallery of encrypted
representations directly in the encrypted domain, without decrypting them.
Numerical results on large galleries of face, fingerprint, and object datasets
such as ImageNet show that, for the first time, accurate and fast image search
within the encrypted domain is feasible at scale (500 seconds; \(275\times\)
speed up over state-of-the-art for encrypted search against a gallery of 100
million). Code is available at
https://github.com/human-analysis/hers-encrypted-image-search</p>
</td>
    <td>
      
        Compact Codes 
      
        Image Retrieval 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/taherkhani2020error/">Error-corrected Margin-based Deep Cross-modal Hashing For Facial Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Error-corrected Margin-based Deep Cross-modal Hashing For Facial Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Error-corrected Margin-based Deep Cross-modal Hashing For Facial Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Taherkhani et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Biometrics, Behavior, and Identity Science</td>
    <td>14</td>
    <td><p>Cross-modal hashing facilitates mapping of heterogeneous multimedia data into
a common Hamming space, which can beutilized for fast and flexible retrieval
across different modalities. In this paper, we propose a novel cross-modal
hashingarchitecture-deep neural decoder cross-modal hashing (DNDCMH), which
uses a binary vector specifying the presence of certainfacial attributes as an
input query to retrieve relevant face images from a database. The DNDCMH
network consists of two separatecomponents: an attribute-based deep cross-modal
hashing (ADCMH) module, which uses a margin (m)-based loss function
toefficiently learn compact binary codes to preserve similarity between
modalities in the Hamming space, and a neural error correctingdecoder (NECD),
which is an error correcting decoder implemented with a neural network. The
goal of NECD network in DNDCMH isto error correct the hash codes generated by
ADCMH to improve the retrieval efficiency. The NECD network is trained such
that it hasan error correcting capability greater than or equal to the margin
(m) of the margin-based loss function. This results in NECD cancorrect the
corrupted hash codes generated by ADCMH up to the Hamming distance of m. We
have evaluated and comparedDNDCMH with state-of-the-art cross-modal hashing
methods on standard datasets to demonstrate the superiority of our method.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/takeshita2020secure/">Secure Single-server Nearly-identical Image Deduplication</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Secure Single-server Nearly-identical Image Deduplication' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Secure Single-server Nearly-identical Image Deduplication' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Takeshita Jonathan, Karl Ryan, Jung Taeho</td> <!-- ðŸ”§ You were missing this -->
    <td>2020 29th International Conference on Computer Communications and Networks (ICCCN)</td>
    <td>14</td>
    <td><p>Cloud computing is often utilized for file storage. Clients of cloud storage
services want to ensure the privacy of their data, and both clients and servers
want to use as little storage as possible. Cross-user deduplication is one
method to reduce the amount of storage a server uses. Deduplication and privacy
are naturally conflicting goals, especially for nearly-identical (``fuzzyâ€™â€™)
deduplication, as some information about the data must be used to perform
deduplication. Prior solutions thus utilize multiple servers, or only function
for exact deduplication. In this paper, we present a single-server protocol for
cross-user nearly-identical deduplication based on secure locality-sensitive
hashing (SLSH). We formally define our ideal security, and rigorously prove our
protocol secure against fully malicious, colluding adversaries with a proof by
simulation. We show experimentally that the individual parts of the protocol
are computationally feasible, and further discuss practical issues of security
and efficiency.</p>
</td>
    <td>
      
        Efficiency And Optimization 
      
        ICCV 
      
        Hashing Methods 
      
        Locality Sensitive Hashing 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/schubert2020graph/">Graph-based Non-linear Least Squares Optimization For Visual Place Recognition In Changing Environments</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Graph-based Non-linear Least Squares Optimization For Visual Place Recognition In Changing Environments' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Graph-based Non-linear Least Squares Optimization For Visual Place Recognition In Changing Environments' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Schubert Stefan, Neubert Peer, Protzel Peter</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Robotics and Automation Letters</td>
    <td>9</td>
    <td><p>Visual place recognition is an important subproblem of mobile robot
localization. Since it is a special case of image retrieval, the basic source
of information is the pairwise similarity of image descriptors. However, the
embedding of the image retrieval problem in this robotic task provides
additional structure that can be exploited, e.g. spatio-temporal consistency.
Several algorithms exist to exploit this structure, e.g., sequence processing
approaches or descriptor standardization approaches for changing environments.
In this paper, we propose a graph-based framework to systematically exploit
different types of additional structure and information. The graphical model is
used to formulate a non-linear least squares problem that can be optimized with
standard tools. Beyond sequences and standardization, we propose the usage of
intra-set similarities within the database and/or the query image set as
additional source of information. If available, our approach also allows to
seamlessly integrate additional knowledge about poses of database images. We
evaluate the system on a variety of standard place recognition datasets and
demonstrate performance improvements for a large number of different
configurations including different sources of information, different types of
constraints, and online or offline place recognition setups.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Graph Based ANN 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/duan2020slade/">SLADE: A Self-training Framework For Distance Metric Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=SLADE: A Self-training Framework For Distance Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=SLADE: A Self-training Framework For Distance Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Duan et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>8</td>
    <td><p>Most existing distance metric learning approaches use fully labeled data to
learn the sample similarities in an embedding space. We present a self-training
framework, SLADE, to improve retrieval performance by leveraging additional
unlabeled data. We first train a teacher model on the labeled data and use it
to generate pseudo labels for the unlabeled data. We then train a student model
on both labels and pseudo labels to generate final feature embeddings. We use
self-supervised representation learning to initialize the teacher model. To
better deal with noisy pseudo labels generated by the teacher network, we
design a new feature basis learning component for the student network, which
learns basis functions of feature representations for unlabeled data. The
learned basis vectors better measure the pairwise similarity and are used to
select high-confident samples for training the student network. We evaluate our
method on standard retrieval benchmarks: CUB-200, Cars-196 and In-shop.
Experimental results demonstrate that our approach significantly improves the
performance over the state-of-the-art methods.</p>
</td>
    <td>
      
        CVPR 
      
        Tools & Libraries 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/dou2020learning/">Learning Global And Local Consistent Representations For Unsupervised Image Retrieval Via Deep Graph Diffusion Networks</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning Global And Local Consistent Representations For Unsupervised Image Retrieval Via Deep Graph Diffusion Networks' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning Global And Local Consistent Representations For Unsupervised Image Retrieval Via Deep Graph Diffusion Networks' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Dou et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>7</td>
    <td><p>Diffusion has shown great success in improving accuracy of unsupervised image
retrieval systems by utilizing high-order structures of image manifold.
However, existing diffusion methods suffer from three major limitations: 1)
they usually rely on local structures without considering global manifold
information; 2) they focus on improving pair-wise similarities within existing
images input output transductively while lacking flexibility to learn
representations for novel unseen instances inductively; 3) they fail to scale
to large datasets due to prohibitive memory consumption and computational
burden due to intrinsic high-order operations on the whole graph. In this
paper, to address these limitations, we propose a novel method, Graph Diffusion
Networks (GRAD-Net), that adopts graph neural networks (GNNs), a novel variant
of deep learning algorithms on irregular graphs. GRAD-Net learns semantic
representations by exploiting both local and global structures of image
manifold in an unsupervised fashion. By utilizing sparse coding techniques,
GRAD-Net not only preserves global information on the image manifold, but also
enables scalable training and efficient querying. Experiments on several large
benchmark datasets demonstrate effectiveness of our method over
state-of-the-art diffusion algorithms for unsupervised image retrieval.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/dolhansky2020adversarial/">Adversarial Collision Attacks On Image Hashing Functions</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Adversarial Collision Attacks On Image Hashing Functions' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Adversarial Collision Attacks On Image Hashing Functions' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Dolhansky Brian, Ferrer Cristian Canton</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>9</td>
    <td><p>Hashing images with a perceptual algorithm is a common approach to solving
duplicate image detection problems. However, perceptual image hashing
algorithms are differentiable, and are thus vulnerable to gradient-based
adversarial attacks. We demonstrate that not only is it possible to modify an
image to produce an unrelated hash, but an exact image hash collision between a
source and target image can be produced via minuscule adversarial
perturbations. In a white box setting, these collisions can be replicated
across nearly every image pair and hash type (including both deep and
non-learned hashes). Furthermore, by attacking points other than the output of
a hashing function, an attacker can avoid having to know the details of a
particular algorithm, resulting in collisions that transfer across different
hash sizes or model architectures. Using these techniques, an adversary can
poison the image lookup table of a duplicate image detection service, resulting
in undefined or unwanted behavior. Finally, we offer several potential
mitigations to gradient-based image hash attacks.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/dirksen2020binarized/">Binarized Johnson-lindenstrauss Embeddings</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Binarized Johnson-lindenstrauss Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Binarized Johnson-lindenstrauss Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Dirksen Sjoerd, Stollenwerk Alexander</td> <!-- ðŸ”§ You were missing this -->
    <td>SIAM Journal on Matrix Analysis and Applications</td>
    <td>7</td>
    <td><p>We consider the problem of encoding a set of vectors into a minimal number of
bits while preserving information on their Euclidean geometry. We show that
this task can be accomplished by applying a Johnson-Lindenstrauss embedding and
subsequently binarizing each vector by comparing each entry of the vector to a
uniformly random threshold. Using this simple construction we produce two
encodings of a dataset such that one can query Euclidean information for a pair
of points using a small number of bit operations up to a desired additive error</p>
<ul>
  <li>Euclidean distances in the first case and inner products and squared
Euclidean distances in the second. In the latter case, each point is encoded in
near-linear time. The number of bits required for these encodings is quantified
in terms of two natural complexity parameters of the dataset - its covering
numbers and localized Gaussian complexity - and shown to be near-optimal.</li>
</ul>
</td>
    <td>
      
        DATASETS 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/fernandes2020locality/">Locality Sensitive Hashing With Extended Differential Privacy</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Locality Sensitive Hashing With Extended Differential Privacy' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Locality Sensitive Hashing With Extended Differential Privacy' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Fernandes Natasha, Kawamoto Yusuke, Murakami Takao</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>7</td>
    <td><p>Extended differential privacy, a generalization of standard differential
privacy (DP) using a general metric, has been widely studied to provide
rigorous privacy guarantees while keeping high utility. However, existing works
on extended DP are limited to few metrics, such as the Euclidean metric.
Consequently, they have only a small number of applications, such as
location-based services and document processing. In this paper, we propose a
couple of mechanisms providing extended DP with a different metric: angular
distance (or cosine distance). Our mechanisms are based on locality sensitive
hashing (LSH), which can be applied to the angular distance and work well for
personal data in a high-dimensional space. We theoretically analyze the privacy
properties of our mechanisms, and prove extended DP for input data by taking
into account that LSH preserves the original metric only approximately. We
apply our mechanisms to friend matching based on high-dimensional personal data
with angular distance in the local model, and evaluate our mechanisms using two
real datasets. We show that LDP requires a very large privacy budget and that
RAPPOR does not work in this application. Then we show that our mechanisms
enable friend matching with high utility and rigorous privacy guarantees based
on extended DP.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/daras2020smyrf/">SMYRF: Efficient Attention Using Asymmetric Clustering</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=SMYRF: Efficient Attention Using Asymmetric Clustering' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=SMYRF: Efficient Attention Using Asymmetric Clustering' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Daras et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>12</td>
    <td><p>We propose a novel type of balanced clustering algorithm to approximate
attention. Attention complexity is reduced from \(O(N^2)\) to \(O(N log N)\),
where \(N\) is the sequence length. Our algorithm, SMYRF, uses Locality Sensitive
Hashing (LSH) in a novel way by defining new Asymmetric transformations and an
adaptive scheme that produces balanced clusters. The biggest advantage of SMYRF
is that it can be used as a drop-in replacement for dense attention layers
without any retraining. On the contrary, prior fast attention methods impose
constraints (e.g. queries and keys share the same vector representations) and
require re-training from scratch. We apply our method to pre-trained
state-of-the-art Natural Language Processing and Computer Vision models and we
report significant memory and speed benefits. Notably, SMYRF-BERT outperforms
(slightly) BERT on GLUE, while using \(50%\) less memory. We also show that
SMYRF can be used interchangeably with dense attention before and after
training. Finally, we use SMYRF to train GANs with attention in high
resolutions. Using a single TPU, we were able to scale attention to 128x128=16k
and 256x256=65k tokens on BigGAN on CelebA-HQ.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/dai2020convolutional/">Convolutional Embedding For Edit Distance</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Convolutional Embedding For Edit Distance' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Convolutional Embedding For Edit Distance' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Dai et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</td>
    <td>7</td>
    <td><p>Edit-distance-based string similarity search has many applications such as
spell correction, data de-duplication, and sequence alignment. However,
computing edit distance is known to have high complexity, which makes string
similarity search challenging for large datasets. In this paper, we propose a
deep learning pipeline (called CNN-ED) that embeds edit distance into Euclidean
distance for fast approximate similarity search. A convolutional neural network
(CNN) is used to generate fixed-length vector embeddings for a dataset of
strings and the loss function is a combination of the triplet loss and the
approximation error. To justify our choice of using CNN instead of other
structures (e.g., RNN) as the model, theoretical analysis is conducted to show
that some basic operations in our CNN model preserve edit distance.
Experimental results show that CNN-ED outperforms data-independent CGK
embedding and RNN-based GRU embedding in terms of both accuracy and efficiency
by a large margin. We also show that string similarity search can be
significantly accelerated using CNN-based embeddings, sometimes by orders of
magnitude.</p>
</td>
    <td>
      
        DATASETS 
      
        Distance Metric Learning 
      
        Efficiency And Optimization 
      
        SIGIR 
      
        Similarity Search 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/dadaneh2020pairwise/">Pairwise Supervised Hashing With Bernoulli Variational Auto-encoder And Self-control Gradient Estimator</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Pairwise Supervised Hashing With Bernoulli Variational Auto-encoder And Self-control Gradient Estimator' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Pairwise Supervised Hashing With Bernoulli Variational Auto-encoder And Self-control Gradient Estimator' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Dadaneh et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Uncertainty in Artificial Intelligence Conference (UAI) 2020</td>
    <td>11</td>
    <td><p>Semantic hashing has become a crucial component of fast similarity search in
many large-scale information retrieval systems, in particular, for text data.
Variational auto-encoders (VAEs) with binary latent variables as hashing codes
provide state-of-the-art performance in terms of precision for document
retrieval. We propose a pairwise loss function with discrete latent VAE to
reward within-class similarity and between-class dissimilarity for supervised
hashing. Instead of solving the optimization relying on existing biased
gradient estimators, an unbiased low-variance gradient estimator is adopted to
optimize the hashing function by evaluating the non-differentiable loss
function over two correlated sets of binary hashing codes to control the
variance of gradient estimates. This new semantic hashing framework achieves
superior performance compared to the state-of-the-arts, as demonstrated by our
comprehensive experiments.</p>
</td>
    <td>
      
        Text Retrieval 
      
        Evaluation 
      
        Hashing Methods 
      
        UAI 
      
        Similarity Search 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/cunningham2020k/">K-nearest Neighbour Classifiers: 2nd Edition (with Python Examples)</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=K-nearest Neighbour Classifiers: 2nd Edition (with Python Examples)' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=K-nearest Neighbour Classifiers: 2nd Edition (with Python Examples)' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Cunningham Padraig, Delany Sarah Jane</td> <!-- ðŸ”§ You were missing this -->
    <td>Undergraduate Topics in Computer Science</td>
    <td>16</td>
    <td><p>Perhaps the most straightforward classifier in the arsenal or machine
learning techniques is the Nearest Neighbour Classifier â€“ classification is
achieved by identifying the nearest neighbours to a query example and using
those neighbours to determine the class of the query. This approach to
classification is of particular importance because issues of poor run-time
performance is not such a problem these days with the computational power that
is available. This paper presents an overview of techniques for Nearest
Neighbour classification focusing on; mechanisms for assessing similarity
(distance), computational issues in identifying nearest neighbours and
mechanisms for reducing the dimension of the data.
  This paper is the second edition of a paper previously published as a
technical report. Sections on similarity measures for time-series, retrieval
speed-up and intrinsic dimensionality have been added. An Appendix is included
providing access to Python code for the key methods.</p>
</td>
    <td>
      
        Survey Paper 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/cui2020exchnet/">Exchnet: A Unified Hashing Network For Large-scale Fine-grained Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Exchnet: A Unified Hashing Network For Large-scale Fine-grained Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Exchnet: A Unified Hashing Network For Large-scale Fine-grained Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Cui et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>31</td>
    <td><p>Retrieving content relevant images from a large-scale fine-grained dataset
could suffer from intolerably slow query speed and highly redundant storage
cost, due to high-dimensional real-valued embeddings which aim to distinguish
subtle visual differences of fine-grained objects. In this paper, we study the
novel fine-grained hashing topic to generate compact binary codes for
fine-grained images, leveraging the search and storage efficiency of hash
learning to alleviate the aforementioned problems. Specifically, we propose a
unified end-to-end trainable network, termed as ExchNet. Based on attention
mechanisms and proposed attention constraints, it can firstly obtain both local
and global features to represent object parts and whole fine-grained objects,
respectively. Furthermore, to ensure the discriminative ability and semantic
meaningâ€™s consistency of these part-level features across images, we design a
local feature alignment approach by performing a feature exchanging operation.
Later, an alternative learning algorithm is employed to optimize the whole
ExchNet and then generate the final binary hash codes. Validated by extensive
experiments, our proposal consistently outperforms state-of-the-art generic
hashing methods on five fine-grained datasets, which shows our effectiveness.
Moreover, compared with other approximate nearest neighbor methods, ExchNet
achieves the best speed-up and storage reduction, revealing its efficiency and
practicality.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Alt 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/christiani2020dartminhash/">Dartminhash: Fast Sketching For Weighted Sets</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Dartminhash: Fast Sketching For Weighted Sets' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Dartminhash: Fast Sketching For Weighted Sets' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Christiani Tobias</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 IEEE 58th Annual Symposium on Foundations of Computer Science (FOCS)</td>
    <td>16</td>
    <td><p>Weighted minwise hashing is a standard dimensionality reduction technique
with applications to similarity search and large-scale kernel machines. We
introduce a simple algorithm that takes a weighted set \(x \in \mathbb{R}<em>{\geq
0}^{d}\) and computes \(k\) independent minhashes in expected time \(O(k log k +
\Vert x \Vert</em>{0}log( \Vert x \Vert_1 + 1/\Vert x \Vert_1))\), improving upon
the state-of-the-art BagMinHash algorithm (KDD â€˜18) and representing the
fastest weighted minhash algorithm for sparse data. Our experiments show
running times that scale better with \(k\) and \(\Vert x \Vert_0\) compared to ICWS
(ICDM â€˜10) and BagMinhash, obtaining \(10\)x speedups in common use cases. Our
approach also gives rise to a technique for computing fully independent
locality-sensitive hash values for \((L, K)\)-parameterized approximate near
neighbor search under weighted Jaccard similarity in optimal expected time
\(O(LK + \Vert x \Vert_0)\), improving on prior work even in the case of
unweighted sets.</p>
</td>
    <td>
      
        KDD 
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Similarity Search 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/coleman2020similarity/">Similarity Search For Efficient Active Learning And Search Of Rare Concepts</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Similarity Search For Efficient Active Learning And Search Of Rare Concepts' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Similarity Search For Efficient Active Learning And Search Of Rare Concepts' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Coleman et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>16</td>
    <td><p>Many active learning and search approaches are intractable for large-scale
industrial settings with billions of unlabeled examples. Existing approaches
search globally for the optimal examples to label, scaling linearly or even
quadratically with the unlabeled data. In this paper, we improve the
computational efficiency of active learning and search methods by restricting
the candidate pool for labeling to the nearest neighbors of the currently
labeled set instead of scanning over all of the unlabeled data. We evaluate
several selection strategies in this setting on three large-scale computer
vision datasets: ImageNet, OpenImages, and a de-identified and aggregated
dataset of 10 billion images provided by a large internet company. Our approach
achieved similar mean average precision and recall as the traditional global
approach while reducing the computational cost of selection by up to three
orders of magnitude, thus enabling web-scale active learning.</p>
</td>
    <td>
      
        AAAI 
      
        DATASETS 
      
        Efficiency And Optimization 
      
        Large Scale Search 
      
        Similarity Search 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/chen2020making/">Making Online Sketching Hashing Even Faster</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Making Online Sketching Hashing Even Faster' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Making Online Sketching Hashing Even Faster' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Chen et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Knowledge and Data Engineering</td>
    <td>21</td>
    <td><p>Data-dependent hashing methods have demonstrated good performance in various
machine learning applications to learn a low-dimensional representation from
the original data. However, they still suffer from several obstacles: First,
most of existing hashing methods are trained in a batch mode, yielding
inefficiency for training streaming data. Second, the computational cost and
the memory consumption increase extraordinarily in the big data setting, which
perplexes the training procedure. Third, the lack of labeled data hinders the
improvement of the model performance. To address these difficulties, we utilize
online sketching hashing (OSH) and present a FasteR Online Sketching Hashing
(FROSH) algorithm to sketch the data in a more compact form via an independent
transformation. We provide theoretical justification to guarantee that our
proposed FROSH consumes less time and achieves a comparable sketching precision
under the same memory cost of OSH. We also extend FROSH to its distributed
implementation, namely DFROSH, to further reduce the training time cost of
FROSH while deriving the theoretical bound of the sketching precision. Finally,
we conduct extensive experiments on both synthetic and real datasets to
demonstrate the attractive merits of FROSH and DFROSH.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        TACL 
      
        Efficiency And Optimization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/charikar2020kernel/">Kernel Density Estimation Through Density Constrained Near Neighbor Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Kernel Density Estimation Through Density Constrained Near Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Kernel Density Estimation Through Density Constrained Near Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Charikar et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2020 IEEE 61st Annual Symposium on Foundations of Computer Science (FOCS)</td>
    <td>6</td>
    <td><p>In this paper we revisit the kernel density estimation problem: given a
kernel \(K(x, y)\) and a dataset of \(n\) points in high dimensional Euclidean
space, prepare a data structure that can quickly output, given a query \(q\), a
\((1+\epsilon)\)-approximation to \(\mu:=\frac1{|P|}\sum_{p\in P} K(p, q)\). First,
we give a single data structure based on classical near neighbor search
techniques that improves upon or essentially matches the query time and space
complexity for all radial kernels considered in the literature so far. We then
show how to improve both the query complexity and runtime by using recent
advances in data-dependent near neighbor search.
  We achieve our results by giving a new implementation of the natural
importance sampling scheme. Unlike previous approaches, our algorithm first
samples the dataset uniformly (considering a geometric sequence of sampling
rates), and then uses existing approximate near neighbor search techniques on
the resulting smaller dataset to retrieve the sampled points that lie at an
appropriate distance from the query. We show that the resulting sampled dataset
has strong geometric structure, making approximate near neighbor search return
the required samples much more efficiently than for worst case datasets of the
same size. As an example application, we show that this approach yields a data
structure that achieves query time \(\mu^{-(1+o(1))/4}\) and space complexity
\(\mu^{-(1+o(1))}\) for the Gaussian kernel. Our data dependent approach achieves
query time \(\mu^{-0.173-o(1)}\) and space \(\mu^{-(1+o(1))}\) for the Gaussian
kernel. The data dependent analysis relies on new techniques for tracking the
geometric structure of the input datasets in a recursive hashing process that
we hope will be of interest in other applications in near neighbor search.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/talreja2020deep/">Deep Hashing For Secure Multimodal Biometrics</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Hashing For Secure Multimodal Biometrics' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Hashing For Secure Multimodal Biometrics' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Talreja Veeru, Valenti Matthew, Nasrabadi Nasser</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Information Forensics and Security</td>
    <td>24</td>
    <td><p>When compared to unimodal systems, multimodal biometric systems have several
advantages, including lower error rate, higher accuracy, and larger population
coverage. However, multimodal systems have an increased demand for integrity
and privacy because they must store multiple biometric traits associated with
each user. In this paper, we present a deep learning framework for
feature-level fusion that generates a secure multimodal template from each
userâ€™s face and iris biometrics. We integrate a deep hashing (binarization)
technique into the fusion architecture to generate a robust binary multimodal
shared latent representation. Further, we employ a hybrid secure architecture
by combining cancelable biometrics with secure sketch techniques and integrate
it with a deep hashing framework, which makes it computationally prohibitive to
forge a combination of multiple biometrics that pass the authentication. The
efficacy of the proposed approach is shown using a multimodal database of face
and iris and it is observed that the matching performance is improved due to
the fusion of multiple biometrics. Furthermore, the proposed approach also
provides cancelability and unlinkability of the templates along with improved
privacy of the biometric data. Additionally, we also test the proposed hashing
function for an image retrieval application using a benchmark dataset. The main
goal of this paper is to develop a method for integrating multimodal fusion,
deep hashing, and biometric security, with an emphasis on structural data from
modalities like face and iris. The proposed approach is in no way a general
biometric security framework that can be applied to all biometric modalities,
as further research is needed to extend the proposed framework to other
unconstrained biometric modalities.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Neural Hashing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/wang2020distilling/">Distilling Knowledge By Mimicking Features</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Distilling Knowledge By Mimicking Features' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Distilling Knowledge By Mimicking Features' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang Guo-hua, Ge Yifan, Wu Jianxin</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Pattern Analysis and Machine Intelligence</td>
    <td>20</td>
    <td><p>Knowledge distillation (KD) is a popular method to train efficient networks
(â€œstudentâ€) with the help of high-capacity networks (â€œteacherâ€). Traditional
methods use the teacherâ€™s soft logits as extra supervision to train the student
network. In this paper, we argue that it is more advantageous to make the
student mimic the teacherâ€™s features in the penultimate layer. Not only the
student can directly learn more effective information from the teacher feature,
feature mimicking can also be applied for teachers trained without a softmax
layer. Experiments show that it can achieve higher accuracy than traditional
KD. To further facilitate feature mimicking, we decompose a feature vector into
the magnitude and the direction. We argue that the teacher should give more
freedom to the student featureâ€™s magnitude, and let the student pay more
attention on mimicking the feature direction. To meet this requirement, we
propose a loss term based on locality-sensitive hashing (LSH). With the help of
this new loss, our method indeed mimics feature directions more accurately,
relaxes constraints on feature magnitudes, and achieves state-of-the-art
distillation accuracy. We provide theoretical analyses of how LSH facilitates
feature direction mimicking, and further extend feature mimicking to
multi-label recognition and object detection.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/sarafijanovicdjukic2020fast/">Fast Distance-based Anomaly Detection In Images Using An Inception-like Autoencoder</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fast Distance-based Anomaly Detection In Images Using An Inception-like Autoencoder' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fast Distance-based Anomaly Detection In Images Using An Inception-like Autoencoder' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Sarafijanovic-djukic Natasa, Davis Jesse</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>32</td>
    <td><p>The goal of anomaly detection is to identify examples that deviate from
normal or expected behavior. We tackle this problem for images. We consider a
two-phase approach. First, using normal examples, a convolutional autoencoder
(CAE) is trained to extract a low-dimensional representation of the images.
Here, we propose a novel architectural choice when designing the CAE, an
Inception-like CAE. It combines convolutional filters of different kernel sizes
and it uses a Global Average Pooling (GAP) operation to extract the
representations from the CAEâ€™s bottleneck layer. Second, we employ a
distanced-based anomaly detector in the low-dimensional space of the learned
representation for the images. However, instead of computing the exact
distance, we compute an approximate distance using product quantization. This
alleviates the high memory and prediction time costs of distance-based anomaly
detectors. We compare our proposed approach to a number of baselines and
state-of-the-art methods on four image datasets, and we find that our approach
resulted in improved predictive performance.</p>
</td>
    <td>
      
        DATASETS 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/zhang2020survey/">A Survey On Deep Hashing For Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Survey On Deep Hashing For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Survey On Deep Hashing For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang Xiaopeng</td> <!-- ðŸ”§ You were missing this -->
    <td>Artificial Intelligence Review</td>
    <td>40</td>
    <td><p>Hashing has been widely used in approximate nearest search for large-scale
database retrieval for its computation and storage efficiency. Deep hashing,
which devises convolutional neural network architecture to exploit and extract
the semantic information or feature of images, has received increasing
attention recently. In this survey, several deep supervised hashing methods for
image retrieval are evaluated and I conclude three main different directions
for deep supervised hashing methods. Several comments are made at the end.
Moreover, to break through the bottleneck of the existing hashing methods, I
propose a Shadow Recurrent Hashing(SRH) method as a try. Specifically, I devise
a CNN architecture to extract the semantic features of images and design a loss
function to encourage similar images projected close. To this end, I propose a
concept: shadow of the CNN output. During optimization process, the CNN output
and its shadow are guiding each other so as to achieve the optimal solution as
much as possible. Several experiments on dataset CIFAR-10 show the satisfying
performance of SRH.</p>
</td>
    <td>
      
        Survey Paper 
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Neural Hashing 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/zhang2020fedocr/">Fedocr: Communication-efficient Federated Learning For Scene Text Recognition</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fedocr: Communication-efficient Federated Learning For Scene Text Recognition' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fedocr: Communication-efficient Federated Learning For Scene Text Recognition' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>EAI/Springer Innovations in Communication and Computing</td>
    <td>24</td>
    <td><p>While scene text recognition techniques have been widely used in commercial
applications, data privacy has rarely been taken into account by this research
community. Most existing algorithms have assumed a set of shared or centralized
training data. However, in practice, data may be distributed on different local
devices that can not be centralized to share due to the privacy restrictions.
In this paper, we study how to make use of decentralized datasets for training
a robust scene text recognizer while keeping them stay on local devices. To the
best of our knowledge, we propose the first framework leveraging federated
learning for scene text recognition, which is trained with decentralized
datasets collaboratively. Hence we name it FedOCR. To make FedCOR fairly
suitable to be deployed on end devices, we make two improvements including
using lightweight models and hashing techniques. We argue that both are crucial
for FedOCR in terms of the communication efficiency of federated learning. The
simulations on decentralized datasets show that the proposed FedOCR achieves
competitive results to the models that are trained with centralized data, with
fewer communication costs and higher-level privacy-preserving.</p>
</td>
    <td>
      
        DATASETS 
      
        Tools & Libraries 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/castellano2020visual/">Visual Link Retrieval And Knowledge Discovery In Painting Datasets</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Visual Link Retrieval And Knowledge Discovery In Painting Datasets' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Visual Link Retrieval And Knowledge Discovery In Painting Datasets' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Castellano Giovanna, Lella Eufemia, Vessio Gennaro</td> <!-- ðŸ”§ You were missing this -->
    <td>Multimedia Tools and Applications</td>
    <td>40</td>
    <td><p>Visual arts are of inestimable importance for the cultural, historic and
economic growth of our society. One of the building blocks of most analysis in
visual arts is to find similarity relationships among paintings of different
artists and painting schools. To help art historians better understand visual
arts, this paper presents a framework for visual link retrieval and knowledge
discovery in digital painting datasets. Visual link retrieval is accomplished
by using a deep convolutional neural network to perform feature extraction and
a fully unsupervised nearest neighbor mechanism to retrieve links among
digitized paintings. Historical knowledge discovery is achieved by performing a
graph analysis that makes it possible to study influences among artists. An
experimental evaluation on a database collecting paintings by very popular
artists shows the effectiveness of the method. The unsupervised strategy makes
the method interesting especially in cases where metadata are scarce,
unavailable or difficult to collect.</p>
</td>
    <td>
      
        DATASETS 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/zhang2020model/">Model Size Reduction Using Frequency Based Double Hashing For Recommender Systems</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Model Size Reduction Using Frequency Based Double Hashing For Recommender Systems' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Model Size Reduction Using Frequency Based Double Hashing For Recommender Systems' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Fourteenth ACM Conference on Recommender Systems</td>
    <td>31</td>
    <td><p>Deep Neural Networks (DNNs) with sparse input features have been widely used
in recommender systems in industry. These models have large memory requirements
and need a huge amount of training data. The large model size usually entails a
cost, in the range of millions of dollars, for storage and communication with
the inference services. In this paper, we propose a hybrid hashing method to
combine frequency hashing and double hashing techniques for model size
reduction, without compromising performance. We evaluate the proposed models on
two product surfaces. In both cases, experiment results demonstrated that we
can reduce the model size by around 90 % while keeping the performance on par
with the original baselines.</p>
</td>
    <td>
      
        Recommender Systems 
      
        RecSys 
      
        Evaluation 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/zhang2020faster/">Faster Binary Embeddings For Preserving Euclidean Distances</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Faster Binary Embeddings For Preserving Euclidean Distances' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Faster Binary Embeddings For Preserving Euclidean Distances' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang Jinjie, Saab Rayan</td> <!-- ðŸ”§ You were missing this -->
    <td>CVPR 2011</td>
    <td>31</td>
    <td><p>We propose a fast, distance-preserving, binary embedding algorithm to
transform a high-dimensional dataset \(\mathcal{T}\subseteq\mathbb{R}^n\) into
binary sequences in the cube \(\{\pm 1\}^m\). When \(\mathcal{T}\) consists of
well-spread (i.e., non-sparse) vectors, our embedding method applies a stable
noise-shaping quantization scheme to \(A x\) where \(A\in\mathbb{R}^{m\times n}\)
is a sparse Gaussian random matrix. This contrasts with most binary embedding
methods, which usually use \(x\mapsto \mathrm{sign}(Ax)\) for the embedding.
Moreover, we show that Euclidean distances among the elements of \(\mathcal{T}\)
are approximated by the \(\ell_1\) norm on the images of \(\{\pm 1\}^m\) under a
fast linear transformation. This again contrasts with standard methods, where
the Hamming distance is used instead. Our method is both fast and memory
efficient, with time complexity \(O(m)\) and space complexity \(O(m)\). Further, we
prove that the method is accurate and its associated error is comparable to
that of a continuous valued Johnson-Lindenstrauss embedding plus a quantization
error that admits a polynomial decay as the embedding dimension \(m\) increases.
Thus the length of the binary codes required to achieve a desired accuracy is
quite small, and we show it can even be compressed further without compromising
the accuracy. To illustrate our results, we test the proposed method on natural
images and show that it achieves strong performance.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        CVPR 
      
        Compact Codes 
      
        Quantization 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/biswas2020perceptual/">Perceptual Hashing Applied To Tor Domains Recognition</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Perceptual Hashing Applied To Tor Domains Recognition' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Perceptual Hashing Applied To Tor Domains Recognition' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Biswas et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Neurocomputing</td>
    <td>26</td>
    <td><p>The Tor darknet hosts different types of illegal content, which are monitored
by cybersecurity agencies. However, manually classifying Tor content can be
slow and error-prone. To support this task, we introduce Frequency-Dominant
Neighborhood Structure (F-DNS), a new perceptual hashing method for
automatically classifying domains by their screenshots. First, we evaluated
F-DNS using images subject to various content preserving operations. We
compared them with their original images, achieving better correlation
coefficients than other state-of-the-art methods, especially in the case of
rotation. Then, we applied F-DNS to categorize Tor domains using the Darknet
Usage Service Images-2K (DUSI-2K), a dataset with screenshots of active Tor
service domains. Finally, we measured the performance of F-DNS against an image
classification approach and a state-of-the-art hashing method. Our proposal
obtained 98.75% accuracy in Tor images, surpassing all other methods compared.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/bibak2020mmh/">MMH* With Arbitrary Modulus Is Always Almost-universal</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=MMH* With Arbitrary Modulus Is Always Almost-universal' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=MMH* With Arbitrary Modulus Is Always Almost-universal' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Bibak Khodakhast, Kapron Bruce M., Srinivasan Venkatesh</td> <!-- ðŸ”§ You were missing this -->
    <td>Information Processing Letters</td>
    <td>10</td>
    <td><p>Universal hash functions, discovered by Carter and Wegman in 1979, are of
great importance in computer science with many applications. MMH\(^<em>\) is a
well-known \(\triangle\)-universal hash function family, based on the evaluation
of a dot product modulo a prime. In this paper, we introduce a generalization
of MMH\(^</em>\), that we call GMMH\(^<em>\), using the same construction as MMH\(^</em>\) but
with an arbitrary integer modulus \(n&gt;1\), and show that GMMH\(^*\) is
\(\frac{1}{p}\)-almost-\(\triangle\)-universal, where \(p\) is the smallest prime
divisor of \(n\). This bound is tight.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/zhang2020collaborative/">Collaborative Generative Hashing For Marketing And Fast Cold-start Recommendation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Collaborative Generative Hashing For Marketing And Fast Cold-start Recommendation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Collaborative Generative Hashing For Marketing And Fast Cold-start Recommendation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang Yan, Tsang Ivor W., Duan Lixin</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Intelligent Systems</td>
    <td>6</td>
    <td><p>Cold-start has being a critical issue in recommender systems with the
explosion of data in e-commerce. Most existing studies proposed to alleviate
the cold-start problem are also known as hybrid recommender systems that learn
representations of users and items by combining user-item interactive and
user/item content information. However, previous hybrid methods regularly
suffered poor efficiency bottlenecking in online recommendations with
large-scale items, because they were designed to project users and items into
continuous latent space where the online recommendation is expensive. To this
end, we propose a collaborative generated hashing (CGH) framework to improve
the efficiency by denoting users and items as binary codes, then fast hashing
search techniques can be used to speed up the online recommendation. In
addition, the proposed CGH can generate potential users or items for marketing
application where the generative network is designed with the principle of
Minimum Description Length (MDL), which is used to learn compact and
informative binary codes. Extensive experiments on two public datasets show the
advantages for recommendations in various settings over competing baselines and
analyze its feasibility in marketing application.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Recommender Systems 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/wang2020asymmetric/">Asymmetric Correlation Quantization Hashing For Cross-modal Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Asymmetric Correlation Quantization Hashing For Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Asymmetric Correlation Quantization Hashing For Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang Lu, Yang Jie</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Multimedia</td>
    <td>21</td>
    <td><p>Due to the superiority in similarity computation and database storage for
large-scale multiple modalities data, cross-modal hashing methods have
attracted extensive attention in similarity retrieval across the heterogeneous
modalities. However, there are still some limitations to be further taken into
account: (1) most current CMH methods transform real-valued data points into
discrete compact binary codes under the binary constraints, limiting the
capability of representation for original data on account of abundant loss of
information and producing suboptimal hash codes; (2) the discrete binary
constraint learning model is hard to solve, where the retrieval performance may
greatly reduce by relaxing the binary constraints for large quantization error;
(3) handling the learning problem of CMH in a symmetric framework, leading to
difficult and complex optimization objective. To address above challenges, in
this paper, a novel Asymmetric Correlation Quantization Hashing (ACQH) method
is proposed. Specifically, ACQH learns the projection matrixs of heterogeneous
modalities data points for transforming query into a low-dimensional
real-valued vector in latent semantic space and constructs the stacked
compositional quantization embedding in a coarse-to-fine manner for indicating
database points by a series of learnt real-valued codeword in the codebook with
the help of pointwise label information regression simultaneously. Besides, the
unified hash codes across modalities can be directly obtained by the discrete
iterative optimization framework devised in the paper. Comprehensive
experiments on diverse three benchmark datasets have shown the effectiveness
and rationality of ACQH.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Multimodal Retrieval 
      
        Similarity Search 
      
        Quantization 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/schulz2020can/">Can Embeddings Adequately Represent Medical Terminology? New Large-scale Medical Term Similarity Datasets Have The Answer!</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Can Embeddings Adequately Represent Medical Terminology? New Large-scale Medical Term Similarity Datasets Have The Answer!' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Can Embeddings Adequately Represent Medical Terminology? New Large-scale Medical Term Similarity Datasets Have The Answer!' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Schulz Claudia, Juric Damir</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>8</td>
    <td><p>A large number of embeddings trained on medical data have emerged, but it
remains unclear how well they represent medical terminology, in particular
whether the close relationship of semantically similar medical terms is encoded
in these embeddings. To date, only small datasets for testing medical term
similarity are available, not allowing to draw conclusions about the
generalisability of embeddings to the enormous amount of medical terms used by
doctors. We present multiple automatically created large-scale medical term
similarity datasets and confirm their high quality in an annotation study with
doctors. We evaluate state-of-the-art word and contextual embeddings on our new
datasets, comparing multiple vector similarity metrics and word vector
aggregation techniques. Our results show that current embeddings are limited in
their ability to adequately encode medical terms. The novel datasets thus form
a challenging new benchmark for the development of medical embeddings able to
accurately represent the whole medical terminology.</p>
</td>
    <td>
      
        AAAI 
      
        DATASETS 
      
        Graph Based ANN 
      
        Distance Metric Learning 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/shand2020locality/">Locality-sensitive Hashing In Function Spaces</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Locality-sensitive Hashing In Function Spaces' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Locality-sensitive Hashing In Function Spaces' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Shand Will, Becker Stephen</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the Third International Conference on SImilarity Search and APplications</td>
    <td>15</td>
    <td><p>We discuss the problem of performing similarity search over function spaces.
To perform search over such spaces in a reasonable amount of time, we use {\it
locality-sensitive hashing} (LSH). We present two methods that allow LSH
functions on \(\mathbb{R}^N\) to be extended to \(L^p\) spaces: one using function
approximation in an orthonormal basis, and another using (quasi-)Monte
Carlo-style techniques. We use the presented hashing schemes to construct an
LSH family for Wasserstein distance over one-dimensional, continuous
probability distributions.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Similarity Search 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/banerjee2020simpatch/">Simpatch: A Nearest Neighbor Similarity Match Between Image Patches</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Simpatch: A Nearest Neighbor Similarity Match Between Image Patches' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Simpatch: A Nearest Neighbor Similarity Match Between Image Patches' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Banerjee Aritra</td> <!-- ðŸ”§ You were missing this -->
    <td>2012 19th IEEE International Conference on Image Processing</td>
    <td>7</td>
    <td><p>Measuring the similarity between patches in images is a fundamental building
block in various tasks. Naturally, the patch-size has a major impact on the
matching quality, and on the consequent application performance. We try to use
large patches instead of relatively small patches so that each patch contains
more information. We use different feature extraction mechanisms to extract the
features of each individual image patches which forms a feature matrix and find
out the nearest neighbor patches in the image. The nearest patches are
calculated using two different nearest neighbor algorithms in this paper for a
query patch for a given image and the results have been demonstrated in this
paper.</p>
</td>
    <td>
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/bai2020targeted/">Targeted Attack For Deep Hashing Based Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Targeted Attack For Deep Hashing Based Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Targeted Attack For Deep Hashing Based Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Bai et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>67</td>
    <td><p>The deep hashing based retrieval method is widely adopted in large-scale
image and video retrieval. However, there is little investigation on its
security. In this paper, we propose a novel method, dubbed deep hashing
targeted attack (DHTA), to study the targeted attack on such retrieval.
Specifically, we first formulate the targeted attack as a point-to-set
optimization, which minimizes the average distance between the hash code of an
adversarial example and those of a set of objects with the target label. Then
we design a novel component-voting scheme to obtain an anchor code as the
representative of the set of hash codes of objects with the target label, whose
optimality guarantee is also theoretically derived. To balance the performance
and perceptibility, we propose to minimize the Hamming distance between the
hash code of the adversarial example and the anchor code under the
\(\ell^\infty\) restriction on the perturbation. Extensive experiments verify
that DHTA is effective in attacking both deep hashing based image retrieval and
video retrieval.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Neural Hashing 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/aum%C3%BCller2020differentially/">Differentially Private Sketches For Jaccard Similarity Estimation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Differentially Private Sketches For Jaccard Similarity Estimation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Differentially Private Sketches For Jaccard Similarity Estimation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>AumÃ¼ller Martin, Bourgeat Anders, Schmurr Jana</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>5</td>
    <td><p>This paper describes two locally-differential private algorithms for
releasing user vectors such that the Jaccard similarity between these vectors
can be efficiently estimated. The basic building block is the well known
MinHash method. To achieve a privacy-utility trade-off, MinHash is extended in
two ways using variants of Generalized Randomized Response and the Laplace
Mechanism. A theoretical analysis provides bounds on the absolute error and
experiments show the utility-privacy trade-off on synthetic and real-world
data. The paper ends with a critical discussion of related work.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/tchayekondi2020new/">A New Hashing Based Nearest Neighbors Selection Technique For Big Datasets</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A New Hashing Based Nearest Neighbors Selection Technique For Big Datasets' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A New Hashing Based Nearest Neighbors Selection Technique For Big Datasets' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Tchaye-kondi Jude, Zhai Yanlong, Zhu Liehuang</td> <!-- ðŸ”§ You were missing this -->
    <td>Computer Science &amp; Information Technology (CS &amp; IT)</td>
    <td>5</td>
    <td><p>KNN has the reputation to be the word simplest but efficient supervised
learning algorithm used for either classification or regression. KNN prediction
efficiency highly depends on the size of its training data but when this
training data grows KNN suffers from slowness in making decisions since it
needs to search nearest neighbors within the entire dataset at each decision
making. This paper proposes a new technique that enables the selection of
nearest neighbors directly in the neighborhood of a given observation. The
proposed approach consists of dividing the data space into subcells of a
virtual grid built on top of data space. The mapping between the data points
and subcells is performed using hashing. When it comes to select the nearest
neighbors of a given observation, we firstly identify the cell the observation
belongs by using hashing, and then we look for nearest neighbors from that
central cell and cells around it layer by layer. From our experiment
performance analysis on publicly available datasets, our algorithm outperforms
the original KNN in time efficiency with a prediction quality as good as that
of KNN it also offers competitive performance with solutions like KDtree</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/sumbul2020deep/">Deep Learning For Image Search And Retrieval In Large Remote Sensing Archives</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Learning For Image Search And Retrieval In Large Remote Sensing Archives' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Learning For Image Search And Retrieval In Large Remote Sensing Archives' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Sumbul Gencer, Kang Jian, Demir BegÃ¼m</td> <!-- ðŸ”§ You were missing this -->
    <td>Deep Learning for the Earth Sciences</td>
    <td>23</td>
    <td><p>This chapter presents recent advances in content based image search and
retrieval (CBIR) systems in remote sensing (RS) for fast and accurate
information discovery from massive data archives. Initially, we analyze the
limitations of the traditional CBIR systems that rely on the hand-crafted RS
image descriptors. Then, we focus our attention on the advances in RS CBIR
systems for which deep learning (DL) models are at the forefront. In
particular, we present the theoretical properties of the most recent DL based
CBIR systems for the characterization of the complex semantic content of RS
images. After discussing their strengths and limitations, we present the deep
hashing based CBIR systems that have high time-efficient search capability
within huge data archives. Finally, the most promising research directions in
RS CBIR are discussed.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/an2020fast/">Fast And Incremental Loop Closure Detection With Deep Features And Proximity Graphs</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fast And Incremental Loop Closure Detection With Deep Features And Proximity Graphs' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fast And Incremental Loop Closure Detection With Deep Features And Proximity Graphs' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>An et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Journal of Field Robotics</td>
    <td>44</td>
    <td><p>In recent years, the robotics community has extensively examined methods
concerning the place recognition task within the scope of simultaneous
localization and mapping applications.This article proposes an appearance-based
loop closure detection pipeline named ``FILD++â€ (Fast and Incremental Loop
closure Detection).First, the system is fed by consecutive images and, via
passing them twice through a single convolutional neural network, global and
local deep features are extracted.Subsequently, a hierarchical navigable
small-world graph incrementally constructs a visual database representing the
robotâ€™s traversed path based on the computed global features.Finally, a query
image, grabbed each time step, is set to retrieve similar locations on the
traversed route.An image-to-image pairing follows, which exploits local
features to evaluate the spatial information. Thus, in the proposed article, we
propose a single network for global and local feature extraction in contrast to
our previous work (FILD), while an exhaustive search for the verification
process is adopted over the generated deep local features avoiding the
utilization of hash codes. Exhaustive experiments on eleven publicly available
datasets exhibit the systemâ€™s high performance (achieving the highest recall
score on eight of them) and low execution times (22.05 ms on average in New
College, which is the largest one containing 52480 images) compared to other
state-of-the-art approaches.</p>
</td>
    <td>
      
        Graph Based ANN 
      
        DATASETS 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/alparslan2020towards/">Towards Evaluating Gaussian Blurring In Perceptual Hashing As A Facial Image Filter</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Towards Evaluating Gaussian Blurring In Perceptual Hashing As A Facial Image Filter' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Towards Evaluating Gaussian Blurring In Perceptual Hashing As A Facial Image Filter' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Alparslan et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 40th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)</td>
    <td>15</td>
    <td><p>With the growth in social media, there is a huge amount of images of faces
available on the internet. Often, people use other peopleâ€™s pictures on their
own profile. Perceptual hashing is often used to detect whether two images are
identical. Therefore, it can be used to detect whether people are misusing
othersâ€™ pictures. In perceptual hashing, a hash is calculated for a given
image, and a new test image is mapped to one of the existing hashes if
duplicate features are present. Therefore, it can be used as an image filter to
flag banned image content or adversarial attacks â€“which are modifications that
are made on purpose to deceive the filterâ€“ even though the content might be
changed to deceive the filters. For this reason, it is critical for perceptual
hashing to be robust enough to take transformations such as resizing, cropping,
and slight pixel modifications into account. In this paper, we would like to
propose to experiment with effect of gaussian blurring in perceptual hashing
for detecting misuse of personal images specifically for face images. We
hypothesize that use of gaussian blurring on the image before calculating its
hash will increase the accuracy of our filter that detects adversarial attacks
which consist of image cropping, adding text annotation, and image rotation.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/ali2020cross/">Cross Hashing: Anonymizing Encounters In Decentralised Contact Tracing Protocols</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Cross Hashing: Anonymizing Encounters In Decentralised Contact Tracing Protocols' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Cross Hashing: Anonymizing Encounters In Decentralised Contact Tracing Protocols' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ali Junade, Dyo Vladimir</td> <!-- ðŸ”§ You were missing this -->
    <td>2021 International Conference on Information Networking (ICOIN)</td>
    <td>10</td>
    <td><p>During the COVID-19 (SARS-CoV-2) epidemic, Contact Tracing emerged as an
essential tool for managing the epidemic. App-based solutions have emerged for
Contact Tracing, including a protocol designed by Apple and Google (influenced
by an open-source protocol known as DP3T). This protocol contains two
well-documented de-anonymisation attacks. Firstly that when someone is marked
as having tested positive and their keys are made public, they can be tracked
over a large geographic area for 24 hours at a time. Secondly, whilst the app
requires a minimum exposure duration to register a contact, there is no
cryptographic guarantee for this property. This means an adversary can scan
Bluetooth networks and retrospectively find who is infected. We propose a novel
â€œcross hashingâ€ approach to cryptographically guarantee minimum exposure
durations. We further mitigate the 24-hour data exposure of infected
individuals and reduce computational time for identifying if a user has been
exposed using \(k\)-Anonymous buckets of hashes and Private Set Intersection. We
empirically demonstrate that this modified protocol can offer like-for-like
efficacy to the existing protocol.</p>
</td>
    <td>
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/aghazadeh2020distributed/">A Distributed Approximate Nearest Neighbor Method For Real-time Face Recognition</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Distributed Approximate Nearest Neighbor Method For Real-time Face Recognition' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Distributed Approximate Nearest Neighbor Method For Real-time Face Recognition' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Aghazadeh Aysan, Amirmazlaghani Maryam</td> <!-- ðŸ”§ You were missing this -->
    <td>Pattern Recognition</td>
    <td>24</td>
    <td><p>Nowadays, face recognition and more generally image recognition have many
applications in the modern world and are widely used in our daily tasks. This
paper aims to propose a distributed approximate nearest neighbor (ANN) method
for real-time face recognition using a big dataset that involves a lot of
classes. The proposed approach is based on using a clustering method to
separate the dataset into different clusters and on specifying the importance
of each cluster by defining cluster weights. To this end, reference instances
are selected from each cluster based on the cluster weights using a maximum
likelihood approach. This process leads to a more informed selection of
instances, so it enhances the performance of the algorithm. Experimental
results confirm the efficiency of the proposed method and its out-performance
in terms of accuracy and the processing time.</p>
</td>
    <td>
      
        CVPR 
      
        DATASETS 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/zhang2020deep/">Deep Pairwise Hashing For Cold-start Recommendation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Pairwise Hashing For Cold-start Recommendation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Pairwise Hashing For Cold-start Recommendation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Knowledge and Data Engineering</td>
    <td>9</td>
    <td><p>Recommendation efficiency and data sparsity problems have been regarded as
two challenges of improving performance for online recommendation. Most of the
previous related work focus on improving recommendation accuracy instead of
efficiency. In this paper, we propose a Deep Pairwise Hashing (DPH) to map
users and items to binary vectors in Hamming space, where a userâ€™s preference
for an item can be efficiently calculated by Hamming distance, which
significantly improves the efficiency of online recommendation. To alleviate
data sparsity and cold-start problems, the user-item interactive information
and item content information are unified to learn effective representations of
items and users. Specifically, we first pre-train robust item representation
from item content data by a Denoising Auto-encoder instead of other
deterministic deep learning frameworks; then we finetune the entire framework
by adding a pairwise loss objective with discrete constraints; moreover, DPH
aims to minimize a pairwise ranking loss that is consistent with the ultimate
goal of recommendation. Finally, we adopt the alternating optimization method
to optimize the proposed model with discrete constraints. Extensive experiments
on three different datasets show that DPH can significantly advance the
state-of-the-art frameworks regarding data sparsity and item cold-start
recommendation.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Recommender Systems 
      
        Alt 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/abulibdeh2020learned/">Learned Indexes For A Google-scale Disk-based Database</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learned Indexes For A Google-scale Disk-based Database' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learned Indexes For A Google-scale Disk-based Database' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Abu-libdeh et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>8</td>
    <td><p>There is great excitement about learned index structures, but understandable
skepticism about the practicality of a new method uprooting decades of research
on B-Trees. In this paper, we work to remove some of that uncertainty by
demonstrating how a learned index can be integrated in a distributed,
disk-based database system: Googleâ€™s Bigtable. We detail several design
decisions we made to integrate learned indexes in Bigtable. Our results show
that integrating learned index significantly improves the end-to-end read
latency and throughput for Bigtable.</p>
</td>
    <td>
      
        Vector Indexing 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/aamand2020no/">No Repetition: Fast Streaming With Highly Concentrated Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=No Repetition: Fast Streaming With Highly Concentrated Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=No Repetition: Fast Streaming With Highly Concentrated Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Aamand et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE INFOCOM 2009</td>
    <td>22</td>
    <td><p>To get estimators that work within a certain error bound with high
probability, a common strategy is to design one that works with constant
probability, and then boost the probability using independent repetitions.
Important examples of this approach are small space algorithms for estimating
the number of distinct elements in a stream, or estimating the set similarity
between large sets. Using standard strongly universal hashing to process each
element, we get a sketch based estimator where the probability of a too large
error is, say, 1/4. By performing \(r\) independent repetitions and taking the
median of the estimators, the error probability falls exponentially in \(r\).
However, running \(r\) independent experiments increases the processing time by a
factor \(r\).
  Here we make the point that if we have a hash function with strong
concentration bounds, then we get the same high probability bounds without any
need for repetitions. Instead of \(r\) independent sketches, we have a single
sketch that is \(r\) times bigger, so the total space is the same. However, we
only apply a single hash function, so we save a factor \(r\) in time, and the
overall algorithms just get simpler.
  Fast practical hash functions with strong concentration bounds were recently
proposed by Aamand em et al. (to appear in STOC 2020). Using their hashing
schemes, the algorithms thus become very fast and practical, suitable for
online processing of high volume data streams.</p>
</td>
    <td>
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/mandal2020novel/">A Novel Incremental Cross-modal Hashing Approach</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Novel Incremental Cross-modal Hashing Approach' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Novel Incremental Cross-modal Hashing Approach' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Mandal Devraj, Biswas Soma</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>5</td>
    <td><p>Cross-modal retrieval deals with retrieving relevant items from one modality,
when provided with a search query from another modality. Hashing techniques,
where the data is represented as binary bits have specifically gained
importance due to the ease of storage, fast computations and high accuracy. In
real world, the number of data categories is continuously increasing, which
requires algorithms capable of handling this dynamic scenario. In this work, we
propose a novel incremental cross-modal hashing algorithm termed â€œiCMHâ€, which
can adapt itself to handle incoming data of new categories. The proposed
approach consists of two sequential stages, namely, learning the hash codes and
training the hash functions. At every stage, a small amount of old category
data termed â€œexemplarsâ€ is is used so as not to forget the old data while
trying to learn for the new incoming data, i.e. to avoid catastrophic
forgetting. In the first stage, the hash codes for the exemplars is used, and
simultaneously, hash codes for the new data is computed such that it maintains
the semantic relations with the existing data. For the second stage, we propose
both a non-deep and deep architectures to learn the hash functions effectively.
Extensive experiments across a variety of cross-modal datasets and comparisons
with state-of-the-art cross-modal algorithms shows the usefulness of our
approach.</p>
</td>
    <td>
      
        Multimodal Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/zhong2020compact/">Compact Deep Aggregation For Set Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Compact Deep Aggregation For Set Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Compact Deep Aggregation For Set Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhong Yujie, ArandjeloviÄ‡ Relja, Zisserman Andrew</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>8</td>
    <td><p>The objective of this work is to learn a compact embedding of a set of
descriptors that is suitable for efficient retrieval and ranking, whilst
maintaining discriminability of the individual descriptors. We focus on a
specific example of this general problem â€“ that of retrieving images
containing multiple faces from a large scale dataset of images. Here the set
consists of the face descriptors in each image, and given a query for multiple
identities, the goal is then to retrieve, in order, images which contain all
the identities, all but one, \etc
  To this end, we make the following contributions: first, we propose a CNN
architecture â€“ {\em SetNet} â€“ to achieve the objective: it learns face
descriptors and their aggregation over a set to produce a compact fixed length
descriptor designed for set retrieval, and the score of an image is a count of
the number of identities that match the query; second, we show that this
compact descriptor has minimal loss of discriminability up to two faces per
image, and degrades slowly after that â€“ far exceeding a number of baselines;
third, we explore the speed vs.\ retrieval quality trade-off for set retrieval
using this compact descriptor; and, finally, we collect and annotate a large
dataset of images containing various number of celebrities, which we use for
evaluation and is publicly released.</p>
</td>
    <td>
      
        DATASETS 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/medini2020solar/">SOLAR: Sparse Orthogonal Learned And Random Embeddings</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=SOLAR: Sparse Orthogonal Learned And Random Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=SOLAR: Sparse Orthogonal Learned And Random Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Medini Tharun, Chen Beidi, Shrivastava Anshumali</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>6</td>
    <td><p>Dense embedding models are commonly deployed in commercial search engines,
wherein all the document vectors are pre-computed, and near-neighbor search
(NNS) is performed with the query vector to find relevant documents. However,
the bottleneck of indexing a large number of dense vectors and performing an
NNS hurts the query time and accuracy of these models. In this paper, we argue
that high-dimensional and ultra-sparse embedding is a significantly superior
alternative to dense low-dimensional embedding for both query efficiency and
accuracy. Extreme sparsity eliminates the need for NNS by replacing them with
simple lookups, while its high dimensionality ensures that the embeddings are
informative even when sparse. However, learning extremely high dimensional
embeddings leads to blow up in the model size. To make the training feasible,
we propose a partitioning algorithm that learns such high dimensional
embeddings across multiple GPUs without any communication. This is facilitated
by our novel asymmetric mixture of Sparse, Orthogonal, Learned and Random
(SOLAR) Embeddings. The label vectors are random, sparse, and near-orthogonal
by design, while the query vectors are learned and sparse. We theoretically
prove that our way of one-sided learning is equivalent to learning both query
and label embeddings. With these unique properties, we can successfully train
500K dimensional SOLAR embeddings for the tasks of searching through 1.6M books
and multi-label classification on the three largest public datasets. We achieve
superior precision and recall compared to the respective state-of-the-art
baselines for each of the tasks with up to 10 times faster speed.</p>
</td>
    <td>
      
        Alt 
      
        DATASETS 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/singh2020ihashnet/">Ihashnet: Iris Hashing Network Based On Efficient Multi-index Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Ihashnet: Iris Hashing Network Based On Efficient Multi-index Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Ihashnet: Iris Hashing Network Based On Efficient Multi-index Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Singh et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2020 IEEE International Joint Conference on Biometrics (IJCB)</td>
    <td>5</td>
    <td><p>Massive biometric deployments are pervasive in todayâ€™s world. But despite the
high accuracy of biometric systems, their computational efficiency degrades
drastically with an increase in the database size. Thus, it is essential to
index them. An ideal indexing scheme needs to generate codes that preserve the
intra-subject similarity as well as inter-subject dissimilarity. Here, in this
paper, we propose an iris indexing scheme using real-valued deep iris features
binarized to iris bar codes (IBC) compatible with the indexing structure.
Firstly, for extracting robust iris features, we have designed a network
utilizing the domain knowledge of ordinal filtering and learning their
nonlinear combinations. Later these real-valued features are binarized.
Finally, for indexing the iris dataset, we have proposed a loss that can
transform the binary feature into an improved feature compatible with the
Multi-Index Hashing scheme. This loss function ensures the hamming distance
equally distributed among all the contiguous disjoint sub-strings. To the best
of our knowledge, this is the first work in the iris indexing domain that
presents an end-to-end iris indexing structure. Experimental results on four
datasets are presented to depict the efficacy of the proposed approach.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Neural Hashing 
      
        Vector Indexing 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/meel2020sparse/">Sparse Hashing For Scalable Approximate Model Counting: Theory And Practice</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Sparse Hashing For Scalable Approximate Model Counting: Theory And Practice' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Sparse Hashing For Scalable Approximate Model Counting: Theory And Practice' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Meel Kuldeep S., Akshay S.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 35th Annual ACM/IEEE Symposium on Logic in Computer Science</td>
    <td>15</td>
    <td><p>Given a CNF formula F on n variables, the problem of model counting or #SAT
is to compute the number of satisfying assignments of F . Model counting is a
fundamental but hard problem in computer science with varied applications.
Recent years have witnessed a surge of effort towards developing efficient
algorithmic techniques that combine the classical 2-universal hashing with the
remarkable progress in SAT solving over the past decade. These techniques
augment the CNF formula F with random XOR constraints and invoke an NP oracle
repeatedly on the resultant CNF-XOR formulas. In practice, calls to the NP
oracle calls are replaced a SAT solver whose runtime performance is adversely
affected by size of XOR constraints. The standard construction of 2-universal
hash functions chooses every variable with probability p = 1/2 leading to XOR
constraints of size n/2 in expectation. Consequently, the challenge is to
design sparse hash functions where variables can be chosen with smaller
probability and lead to smaller sized XOR constraints.
  In this paper, we address this challenge from theoretical and practical
perspectives. First, we formalize a relaxation of universal hashing, called
concentrated hashing and establish a novel and beautiful connection between
concentration measures of these hash functions and isoperimetric inequalities
on boolean hypercubes. This allows us to obtain (log m) tight bounds on
variance and dispersion index and show that p = O( log(m)/m ) suffices for
design of sparse hash functions from {0, 1}^n to {0, 1}^m. We then use sparse
hash functions belonging to this concentrated hash family to develop new
approximate counting algorithms. A comprehensive experimental evaluation of our
algorithm on 1893 benchmarks demonstrates that usage of sparse hash functions
can lead to significant speedups.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/memmesheimer2020skeleton/">Skeleton-dml: Deep Metric Learning For Skeleton-based One-shot Action Recognition</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Skeleton-dml: Deep Metric Learning For Skeleton-based One-shot Action Recognition' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Skeleton-dml: Deep Metric Learning For Skeleton-based One-shot Action Recognition' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Memmesheimer et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</td>
    <td>28</td>
    <td><p>One-shot action recognition allows the recognition of human-performed actions
with only a single training example. This can influence human-robot-interaction
positively by enabling the robot to react to previously unseen behaviour. We
formulate the one-shot action recognition problem as a deep metric learning
problem and propose a novel image-based skeleton representation that performs
well in a metric learning setting. Therefore, we train a model that projects
the image representations into an embedding space. In embedding space the
similar actions have a low euclidean distance while dissimilar actions have a
higher distance. The one-shot action recognition problem becomes a
nearest-neighbor search in a set of activity reference samples. We evaluate the
performance of our proposed representation against a variety of other
skeleton-based image representations. In addition, we present an ablation study
that shows the influence of different embedding vector sizes, losses and
augmentation. Our approach lifts the state-of-the-art by 3.3% for the one-shot
action recognition protocol on the NTU RGB+D 120 dataset under a comparable
training setup. With additional augmentation our result improved over 7.7%.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/tu2020deep/">Deep Cross-modal Hashing Via Margin-dynamic-softmax Loss</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Cross-modal Hashing Via Margin-dynamic-softmax Loss' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Cross-modal Hashing Via Margin-dynamic-softmax Loss' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Tu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the Web Conference 2021</td>
    <td>34</td>
    <td><p>Due to their high retrieval efficiency and low storage cost for cross-modal
search task, cross-modal hashing methods have attracted considerable attention.
For the supervised cross-modal hashing methods, how to make the learned hash
codes preserve semantic information sufficiently contained in the label of
datapoints is the key to further enhance the retrieval performance. Hence,
almost all supervised cross-modal hashing methods usually depends on defining a
similarity between datapoints with the label information to guide the hashing
model learning fully or partly. However, the defined similarity between
datapoints can only capture the label information of datapoints partially and
misses abundant semantic information, then hinders the further improvement of
retrieval performance. Thus, in this paper, different from previous works, we
propose a novel cross-modal hashing method without defining the similarity
between datapoints, called Deep Cross-modal Hashing via
\textit{Margin-dynamic-softmax Loss} (DCHML). Specifically, DCHML first trains
a proxy hashing network to transform each category information of a dataset
into a semantic discriminative hash code, called proxy hash code. Each proxy
hash code can preserve the semantic information of its corresponding category
well. Next, without defining the similarity between datapoints to supervise the
training process of the modality-specific hashing networks , we propose a novel
\textit{margin-dynamic-softmax loss} to directly utilize the proxy hashing
codes as supervised information. Finally, by minimizing the novel
\textit{margin-dynamic-softmax loss}, the modality-specific hashing networks
can be trained to generate hash codes which can simultaneously preserve the
cross-modal similarity and abundant semantic information well.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/tseng2020parallel/">Parallel Index-based Structural Graph Clustering And Its Approximation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Parallel Index-based Structural Graph Clustering And Its Approximation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Parallel Index-based Structural Graph Clustering And Its Approximation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Tseng Tom, Dhulipala Laxman, Shun Julian</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 2021 International Conference on Management of Data</td>
    <td>14</td>
    <td><p>SCAN (Structural Clustering Algorithm for Networks) is a well-studied, widely
used graph clustering algorithm. For large graphs, however, sequential SCAN
variants are prohibitively slow, and parallel SCAN variants do not effectively
share work among queries with different SCAN parameter settings. Since users of
SCAN often explore many parameter settings to find good clusterings, it is
worthwhile to precompute an index that speeds up queries.
  This paper presents a practical and provably efficient parallel index-based
SCAN algorithm based on GS<em>-Index, a recent sequential algorithm. Our parallel
algorithm improves upon the asymptotic work of the sequential algorithm by
using integer sorting. It is also highly parallel, achieving logarithmic span
(parallel time) for both index construction and clustering queries.
Furthermore, we apply locality-sensitive hashing (LSH) to design a novel
approximate SCAN algorithm and prove guarantees for its clustering behavior.
  We present an experimental evaluation of our algorithms on large real-world
graphs. On a 48-core machine with two-way hyper-threading, our parallel index
construction achieves 50â€“151\(\times\) speedup over the construction of
GS</em>-Index. In fact, even on a single thread, our index construction algorithm
is faster than GS<em>-Index. Our parallel index query implementation achieves
5â€“32\(\times\) speedup over GS</em>-Index queries across a range of SCAN parameter
values, and our implementation is always faster than ppSCAN, a state-of-the-art
parallel SCAN algorithm. Moreover, our experiments show that applying LSH
results in faster index construction while maintaining good clustering quality.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/shen2020auto/">Auto-encoding Twin-bottleneck Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Auto-encoding Twin-bottleneck Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Auto-encoding Twin-bottleneck Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Shen et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>113</td>
    <td><p>Conventional unsupervised hashing methods usually take advantage of
similarity graphs, which are either pre-computed in the high-dimensional space
or obtained from random anchor points. On the one hand, existing methods
uncouple the procedures of hash function learning and graph construction. On
the other hand, graphs empirically built upon original data could introduce
biased prior knowledge of data relevance, leading to sub-optimal retrieval
performance. In this paper, we tackle the above problems by proposing an
efficient and adaptive code-driven graph, which is updated by decoding in the
context of an auto-encoder. Specifically, we introduce into our framework twin
bottlenecks (i.e., latent variables) that exchange crucial information
collaboratively. One bottleneck (i.e., binary codes) conveys the high-level
intrinsic data structure captured by the code-driven graph to the other (i.e.,
continuous variables for low-level detail information), which in turn
propagates the updated network feedback for the encoder to learn more
discriminative binary codes. The auto-encoding learning objective literally
rewards the code-driven graph to learn an optimal encoder. Moreover, the
proposed model can be simply optimized by gradient descent without violating
the binary constraints. Experiments on benchmarked datasets clearly show the
superiority of our framework over the state-of-the-art hashing methods. Our
source code can be found at https://github.com/ymcidence/TBH.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Graph Based ANN 
      
        CVPR 
      
        Compact Codes 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/sinha2020neural/">Neural Neighborhood Encoding For Classification</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Neural Neighborhood Encoding For Classification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Neural Neighborhood Encoding For Classification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Sinha Kaushik, Ram Parikshit</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining</td>
    <td>5</td>
    <td><p>Inspired by the fruit-fly olfactory circuit, the Fly Bloom Filter [Dasgupta
et al., 2018] is able to efficiently summarize the data with a single pass and
has been used for novelty detection. We propose a new classifier (for binary
and multi-class classification) that effectively encodes the different local
neighborhoods for each class with a per-class Fly Bloom Filter. The inference
on test data requires an efficient {\tt FlyHash} [Dasgupta, et al., 2017]
operation followed by a high-dimensional, but {\em sparse}, dot product with
the per-class Bloom Filters. The learning is trivially parallelizable. On the
theoretical side, we establish conditions under which the prediction of our
proposed classifier on any test example agrees with the prediction of the
nearest neighbor classifier with high probability. We extensively evaluate our
proposed scheme with over \(50\) data sets of varied data dimensionality to
demonstrate that the predictive performance of our proposed neuroscience
inspired classifier is competitive the the nearest-neighbor classifiers and
other single-pass classifiers.</p>
</td>
    <td>
      
        KDD 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/luo2020survey/">A Survey On Deep Hashing Methods</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Survey On Deep Hashing Methods' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Survey On Deep Hashing Methods' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Luo et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>ACM Transactions on Knowledge Discovery from Data</td>
    <td>113</td>
    <td><p>Nearest neighbor search aims to obtain the samples in the database with the
smallest distances from them to the queries, which is a basic task in a range
of fields, including computer vision and data mining. Hashing is one of the
most widely used methods for its computational and storage efficiency. With the
development of deep learning, deep hashing methods show more advantages than
traditional methods. In this survey, we detailedly investigate current deep
hashing algorithms including deep supervised hashing and deep unsupervised
hashing. Specifically, we categorize deep supervised hashing methods into
pairwise methods, ranking-based methods, pointwise methods as well as
quantization according to how measuring the similarities of the learned hash
codes. Moreover, deep unsupervised hashing is categorized into similarity
reconstruction-based methods, pseudo-label-based methods and prediction-free
self-supervised learning-based methods based on their semantic learning
manners. We also introduce three related important topics including
semi-supervised deep hashing, domain adaption deep hashing and multi-modal deep
hashing. Meanwhile, we present some commonly used public datasets and the
scheme to measure the performance of deep hashing algorithms. Finally, we
discuss some potential research directions in conclusion.</p>
</td>
    <td>
      
        Survey Paper 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Neural Hashing 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/luo2020challenge/">Challenge Report: Recognizing Families In The Wild Data Challenge</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Challenge Report: Recognizing Families In The Wild Data Challenge' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Challenge Report: Recognizing Families In The Wild Data Challenge' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Luo et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020)</td>
    <td>9</td>
    <td><p>This paper is a brief report to our submission to the Recognizing Families In
the Wild Data Challenge (4th Edition), in conjunction with FG 2020 Forum.
Automatic kinship recognition has attracted many researchersâ€™ attention for its
full application, but it is still a very challenging task because of the
limited information that can be used to determine whether a pair of faces are
blood relatives or not. In this paper, we studied previous methods and proposed
our method. We try many methods, like deep metric learning-based, to extract
deep embedding feature for every image, then determine if they are blood
relatives by Euclidean distance or method based on classes. Finally, we find
some tricks like sampling more negative samples and high resolution that can
help get better performance. Moreover, we proposed a symmetric network with a
binary classification based method to get our best score in all tasks.</p>
</td>
    <td>
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/luo2020cimon/">CIMON: Towards High-quality Hash Codes</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=CIMON: Towards High-quality Hash Codes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=CIMON: Towards High-quality Hash Codes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Luo et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence</td>
    <td>26</td>
    <td><p>Recently, hashing is widely used in approximate nearest neighbor search for
its storage and computational efficiency. Most of the unsupervised hashing
methods learn to map images into semantic similarity-preserving hash codes by
constructing local semantic similarity structure from the pre-trained model as
the guiding information, i.e., treating each point pair similar if their
distance is small in feature space. However, due to the inefficient
representation ability of the pre-trained model, many false positives and
negatives in local semantic similarity will be introduced and lead to error
propagation during the hash code learning. Moreover, few of the methods
consider the robustness of models, which will cause instability of hash codes
to disturbance. In this paper, we propose a new method named
{\textbf{C}}omprehensive s{\textbf{I}}milarity {\textbf{M}}ining and
c{\textbf{O}}nsistency lear{\textbf{N}}ing (CIMON). First, we use global
refinement and similarity statistical distribution to obtain reliable and
smooth guidance. Second, both semantic and contrastive consistency learning are
introduced to derive both disturb-invariant and discriminative hash codes.
Extensive experiments on several benchmark datasets show that the proposed
method outperforms a wide range of state-of-the-art methods in both retrieval
performance and robustness.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        IJCAI 
      
        Robustness 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        AAAI 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/zheng2020generative/">Generative Semantic Hashing Enhanced Via Boltzmann Machines</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Generative Semantic Hashing Enhanced Via Boltzmann Machines' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Generative Semantic Hashing Enhanced Via Boltzmann Machines' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zheng et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</td>
    <td>10</td>
    <td><p>Generative semantic hashing is a promising technique for large-scale
information retrieval thanks to its fast retrieval speed and small memory
footprint. For the tractability of training, existing generative-hashing
methods mostly assume a factorized form for the posterior distribution,
enforcing independence among the bits of hash codes. From the perspectives of
both model representation and code space size, independence is always not the
best assumption. In this paper, to introduce correlations among the bits of
hash codes, we propose to employ the distribution of Boltzmann machine as the
variational posterior. To address the intractability issue of training, we
first develop an approximate method to reparameterize the distribution of a
Boltzmann machine by augmenting it as a hierarchical concatenation of a
Gaussian-like distribution and a Bernoulli distribution. Based on that, an
asymptotically-exact lower bound is further derived for the evidence lower
bound (ELBO). With these novel techniques, the entire model can be optimized
efficiently. Extensive experimental results demonstrate that by effectively
modeling correlations among different bits within a hash code, our model can
achieve significant performance gains.</p>
</td>
    <td>
      
        Text Retrieval 
      
        Evaluation 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        ACL 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/xu2020multi/">Multi-feature Discrete Collaborative Filtering For Fast Cold-start Recommendation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Multi-feature Discrete Collaborative Filtering For Fast Cold-start Recommendation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Multi-feature Discrete Collaborative Filtering For Fast Cold-start Recommendation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Xu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>21</td>
    <td><p>Hashing is an effective technique to address the large-scale recommendation
problem, due to its high computation and storage efficiency on calculating the
user preferences on items. However, existing hashing-based recommendation
methods still suffer from two important problems: 1) Their recommendation
process mainly relies on the user-item interactions and single specific content
feature. When the interaction history or the content feature is unavailable
(the cold-start problem), their performance will be seriously deteriorated. 2)
Existing methods learn the hash codes with relaxed optimization or adopt
discrete coordinate descent to directly solve binary hash codes, which results
in significant quantization loss or consumes considerable computation time. In
this paper, we propose a fast cold-start recommendation method, called
Multi-Feature Discrete Collaborative Filtering (MFDCF), to solve these
problems. Specifically, a low-rank self-weighted multi-feature fusion module is
designed to adaptively project the multiple content features into binary yet
informative hash codes by fully exploiting their complementarity. Additionally,
we develop a fast discrete optimization algorithm to directly compute the
binary hash codes with simple operations. Experiments on two public
recommendation datasets demonstrate that MFDCF outperforms the
state-of-the-arts on various aspects.</p>
</td>
    <td>
      
        AAAI 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Recommender Systems 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/xu2020learning/">On Learning Semantic Representations For Million-scale Free-hand Sketches</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=On Learning Semantic Representations For Million-scale Free-hand Sketches' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=On Learning Semantic Representations For Million-scale Free-hand Sketches' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Xu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Circuits and Systems for Video Technology</td>
    <td>10</td>
    <td><p>In this paper, we study learning semantic representations for million-scale
free-hand sketches. This is highly challenging due to the domain-unique traits
of sketches, e.g., diverse, sparse, abstract, noisy. We propose a dual-branch
CNNRNN network architecture to represent sketches, which simultaneously encodes
both the static and temporal patterns of sketch strokes. Based on this
architecture, we further explore learning the sketch-oriented semantic
representations in two challenging yet practical settings, i.e., hashing
retrieval and zero-shot recognition on million-scale sketches. Specifically, we
use our dual-branch architecture as a universal representation framework to
design two sketch-specific deep models: (i) We propose a deep hashing model for
sketch retrieval, where a novel hashing loss is specifically designed to
accommodate both the abstract and messy traits of sketches. (ii) We propose a
deep embedding model for sketch zero-shot recognition, via collecting a
large-scale edge-map dataset and proposing to extract a set of semantic vectors
from edge-maps as the semantic knowledge for sketch zero-shot domain alignment.
Both deep models are evaluated by comprehensive experiments on million-scale
sketches and outperform the state-of-the-art competitors.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Neural Hashing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/yu2020comprehensive/">Comprehensive Graph-conditional Similarity Preserving Network For Unsupervised Cross-modal Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Comprehensive Graph-conditional Similarity Preserving Network For Unsupervised Cross-modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Comprehensive Graph-conditional Similarity Preserving Network For Unsupervised Cross-modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Expert Systems with Applications</td>
    <td>18</td>
    <td><p>Unsupervised cross-modal hashing (UCMH) has become a hot topic recently.
Current UCMH focuses on exploring data similarities. However, current UCMH
methods calculate the similarity between two data, mainly relying on the two
dataâ€™s cross-modal features. These methods suffer from inaccurate similarity
problems that result in a suboptimal retrieval Hamming space, because the
cross-modal features between the data are not sufficient to describe the
complex data relationships, such as situations where two data have different
feature representations but share the inherent concepts. In this paper, we
devise a deep graph-neighbor coherence preserving network (DGCPN).
Specifically, DGCPN stems from graph models and explores graph-neighbor
coherence by consolidating the information between data and their neighbors.
DGCPN regulates comprehensive similarity preserving losses by exploiting three
types of data similarities (i.e., the graph-neighbor coherence, the coexistent
similarity, and the intra- and inter-modality consistency) and designs a
half-real and half-binary optimization strategy to reduce the quantization
errors during hashing. Essentially, DGCPN addresses the inaccurate similarity
problem by exploring and exploiting the dataâ€™s intrinsic relationships in a
graph. We conduct extensive experiments on three public UCMH datasets. The
experimental results demonstrate the superiority of DGCPN, e.g., by improving
the mean average precision from 0.722 to 0.751 on MIRFlickr-25K using 64-bit
hashing codes to retrieve texts from images. We will release the source code
package and the trained model on https://github.com/Atmegal/DGCPN.</p>
</td>
    <td>
      
        DATASETS 
      
        Quantization 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/yu2020self/">Self-supervised Asymmetric Deep Hashing With Margin-scalable Constraint</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Self-supervised Asymmetric Deep Hashing With Margin-scalable Constraint' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Self-supervised Asymmetric Deep Hashing With Margin-scalable Constraint' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Neurocomputing</td>
    <td>5</td>
    <td><p>Due to its effectivity and efficiency, deep hashing approaches are widely
used for large-scale visual search. However, it is still challenging to produce
compact and discriminative hash codes for images associated with multiple
semantics for two main reasons, 1) similarity constraints designed in most of
the existing methods are based upon an oversimplified similarity
assignment(i.e., 0 for instance pairs sharing no label, 1 for instance pairs
sharing at least 1 label), 2) the exploration in multi-semantic relevance are
insufficient or even neglected in many of the existing methods. These problems
significantly limit the discrimination of generated hash codes. In this paper,
we propose a novel self-supervised asymmetric deep hashing method with a
margin-scalable constraint(SADH) approach to cope with these problems. SADH
implements a self-supervised network to sufficiently preserve semantic
information in a semantic feature dictionary and a semantic code dictionary for
the semantics of the given dataset, which efficiently and precisely guides a
feature learning network to preserve multilabel semantic information using an
asymmetric learning strategy. By further exploiting semantic dictionaries, a
new margin-scalable constraint is employed for both precise similarity
searching and robust hash code generation. Extensive empirical research on four
popular benchmarks validates the proposed method and shows it outperforms
several state-of-the-art approaches.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        Efficiency And Optimization 
      
        Neural Hashing 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/paria2020minimizing/">Minimizing Flops To Learn Efficient Sparse Representations</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Minimizing Flops To Learn Efficient Sparse Representations' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Minimizing Flops To Learn Efficient Sparse Representations' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Paria et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>14</td>
    <td><p>Deep representation learning has become one of the most widely adopted
approaches for visual search, recommendation, and identification. Retrieval of
such representations from a large database is however computationally
challenging. Approximate methods based on learning compact representations,
have been widely explored for this problem, such as locality sensitive hashing,
product quantization, and PCA. In this work, in contrast to learning compact
representations, we propose to learn high dimensional and sparse
representations that have similar representational capacity as dense embeddings
while being more efficient due to sparse matrix multiplication operations which
can be much faster than dense multiplication. Following the key insight that
the number of operations decreases quadratically with the sparsity of
embeddings provided the non-zero entries are distributed uniformly across
dimensions, we propose a novel approach to learn such distributed sparse
embeddings via the use of a carefully constructed regularization function that
directly minimizes a continuous relaxation of the number of floating-point
operations (FLOPs) incurred during retrieval. Our experiments show that our
approach is competitive to the other baselines and yields a similar or better
speed-vs-accuracy tradeoff on practical datasets.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Recommender Systems 
      
        Quantization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/liu2020reinforcing/">Reinforcing Short-length Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Reinforcing Short-length Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Reinforcing Short-length Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Circuits and Systems for Video Technology</td>
    <td>28</td>
    <td><p>Due to the compelling efficiency in retrieval and storage,
similarity-preserving hashing has been widely applied to approximate nearest
neighbor search in large-scale image retrieval. However, existing methods have
poor performance in retrieval using an extremely short-length hash code due to
weak ability of classification and poor distribution of hash bit. To address
this issue, in this study, we propose a novel reinforcing short-length hashing
(RSLH). In this proposed RSLH, mutual reconstruction between the hash
representation and semantic labels is performed to preserve the semantic
information. Furthermore, to enhance the accuracy of hash representation, a
pairwise similarity matrix is designed to make a balance between accuracy and
training expenditure on memory. In addition, a parameter boosting strategy is
integrated to reinforce the precision with hash bits fusion. Extensive
experiments on three large-scale image benchmarks demonstrate the superior
performance of RSLH under various short-length hashing scenarios.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/liu2020shuffle/">Shuffle And Learn: Minimizing Mutual Information For Unsupervised Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Shuffle And Learn: Minimizing Mutual Information For Unsupervised Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Shuffle And Learn: Minimizing Mutual Information For Unsupervised Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu Fangrui, Liu Zheng</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406)</td>
    <td>8</td>
    <td><p>Unsupervised binary representation allows fast data retrieval without any
annotations, enabling practical application like fast person re-identification
and multimedia retrieval. It is argued that conflicts in binary space are one
of the major barriers to high-performance unsupervised hashing as current
methods failed to capture the precise code conflicts in the full domain. A
novel relaxation method called Shuffle and Learn is proposed to tackle code
conflicts in the unsupervised hash. Approximated derivatives for joint
probability and the gradients for the binary layer are introduced to bridge the
update from the hash to the input. Proof on \(\epsilon\)-Convergence of joint
probability with approximated derivatives is provided to guarantee the
preciseness on update applied on the mutual information. The proposed algorithm
is carried out with iterative global updates to minimize mutual information,
diverging the code before regular unsupervised optimization. Experiments
suggest that the proposed method can relax the code optimization from local
optimum and help to generate binary representations that are more
discriminative and informative without any annotations. Performance benchmarks
on image retrieval with the unsupervised binary code are conducted on three
open datasets, and the model achieves state-of-the-art accuracy on image
retrieval task for all those datasets. Datasets and reproducible code are
provided.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/vanblokland2020indexing/">An Indexing Scheme And Descriptor For 3D Object Retrieval Based On Local Shape Querying</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=An Indexing Scheme And Descriptor For 3D Object Retrieval Based On Local Shape Querying' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=An Indexing Scheme And Descriptor For 3D Object Retrieval Based On Local Shape Querying' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>van Blokland Bart Iver, Theoharis Theoharis</td> <!-- ðŸ”§ You were missing this -->
    <td>Computers &amp; Graphics</td>
    <td>14</td>
    <td><p>A binary descriptor indexing scheme based on Hamming distance called the
Hamming tree for local shape queries is presented. A new binary clutter
resistant descriptor named Quick Intersection Count Change Image (QUICCI) is
also introduced. This local shape descriptor is extremely small and fast to
compare. Additionally, a novel distance function called Weighted Hamming
applicable to QUICCI images is proposed for retrieval applications. The
effectiveness of the indexing scheme and QUICCI is demonstrated on 828 million
QUICCI images derived from the SHREC2017 dataset, while the clutter resistance
of QUICCI is shown using the clutterbox experiment.</p>
</td>
    <td>
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/lin2020fast/">Fast Class-wise Updating For Online Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fast Class-wise Updating For Online Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fast Class-wise Updating For Online Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lin et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Pattern Analysis and Machine Intelligence</td>
    <td>22</td>
    <td><p>Online image hashing has received increasing research attention recently,
which processes large-scale data in a streaming fashion to update the hash
functions on-the-fly. To this end, most existing works exploit this problem
under a supervised setting, i.e., using class labels to boost the hashing
performance, which suffers from the defects in both adaptivity and efficiency:
First, large amounts of training batches are required to learn up-to-date hash
functions, which leads to poor online adaptivity. Second, the training is
time-consuming, which contradicts with the core need of online learning. In
this paper, a novel supervised online hashing scheme, termed Fast Class-wise
Updating for Online Hashing (FCOH), is proposed to address the above two
challenges by introducing a novel and efficient inner product operation. To
achieve fast online adaptivity, a class-wise updating method is developed to
decompose the binary code learning and alternatively renew the hash functions
in a class-wise fashion, which well addresses the burden on large amounts of
training batches. Quantitatively, such a decomposition further leads to at
least 75% storage saving. To further achieve online efficiency, we propose a
semi-relaxation optimization, which accelerates the online training by treating
different binary constraints independently. Without additional constraints and
variables, the time complexity is significantly reduced. Such a scheme is also
quantitatively shown to well preserve past information during updating hashing
functions. We have quantitatively demonstrated that the collective effort of
class-wise updating and semi-relaxation optimization provides a superior
performance comparing to various state-of-the-art methods, which is verified
through extensive experiments on three widely-used datasets.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Alt 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/tan2020learning/">Learning To Hash With Graph Neural Networks For Recommender Systems</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning To Hash With Graph Neural Networks For Recommender Systems' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning To Hash With Graph Neural Networks For Recommender Systems' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Tan et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of The Web Conference 2020</td>
    <td>76</td>
    <td><p>Graph representation learning has attracted much attention in supporting high
quality candidate search at scale. Despite its effectiveness in learning
embedding vectors for objects in the user-item interaction network, the
computational costs to infer usersâ€™ preferences in continuous embedding space
are tremendous. In this work, we investigate the problem of hashing with graph
neural networks (GNNs) for high quality retrieval, and propose a simple yet
effective discrete representation learning framework to jointly learn
continuous and discrete codes. Specifically, a deep hashing with GNNs (HashGNN)
is presented, which consists of two components, a GNN encoder for learning node
representations, and a hash layer for encoding representations to hash codes.
The whole architecture is trained end-to-end by jointly optimizing two losses,
i.e., reconstruction loss from reconstructing observed links, and ranking loss
from preserving the relative ordering of hash codes. A novel discrete
optimization strategy based on straight through estimator (STE) with guidance
is proposed. The principal idea is to avoid gradient magnification in
back-propagation of STE with continuous embedding guidance, in which we begin
from learning an easier network that mimic the continuous embedding and let it
evolve during the training until it finally goes back to STE. Comprehensive
experiments over three publicly available and one real-world Alibaba company
datasets demonstrate that our model not only can achieve comparable performance
compared with its continuous counterpart but also runs multiple times faster
during inference.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Recommender Systems 
      
        Neural Hashing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/liang2020dynamic/">Dynamic Sampling For Deep Metric Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Dynamic Sampling For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Dynamic Sampling For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liang Chang-hui, Zhao Wan-lei, Chen Run-qing</td> <!-- ðŸ”§ You were missing this -->
    <td>Pattern Recognition Letters</td>
    <td>5</td>
    <td><p>Deep metric learning maps visually similar images onto nearby locations and
visually dissimilar images apart from each other in an embedding manifold. The
learning process is mainly based on the supplied image negative and positive
training pairs. In this paper, a dynamic sampling strategy is proposed to
organize the training pairs in an easy-to-hard order to feed into the network.
It allows the network to learn general boundaries between categories from the
easy training pairs at its early stages and finalize the details of the model
mainly relying on the hard training samples in the later. Compared to the
existing training sample mining approaches, the hard samples are mined with
little harm to the learned general model. This dynamic sampling strategy is
formularized as two simple terms that are compatible with various loss
functions. Consistent performance boost is observed when it is integrated with
several popular loss functions on fashion search, fine-grained classification,
and person re-identification tasks.</p>
</td>
    <td>
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/yan2020deep/">Deep Multi-view Enhancement Hashing For Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Multi-view Enhancement Hashing For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Multi-view Enhancement Hashing For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yan et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Pattern Analysis and Machine Intelligence</td>
    <td>413</td>
    <td><p>Hashing is an efficient method for nearest neighbor search in large-scale
data space by embedding high-dimensional feature descriptors into a similarity
preserving Hamming space with a low dimension. However, large-scale high-speed
retrieval through binary code has a certain degree of reduction in retrieval
accuracy compared to traditional retrieval methods. We have noticed that
multi-view methods can well preserve the diverse characteristics of data.
Therefore, we try to introduce the multi-view deep neural network into the hash
learning field, and design an efficient and innovative retrieval model, which
has achieved a significant improvement in retrieval performance. In this paper,
we propose a supervised multi-view hash model which can enhance the multi-view
information through neural networks. This is a completely new hash learning
method that combines multi-view and deep learning methods. The proposed method
utilizes an effective view stability evaluation method to actively explore the
relationship among views, which will affect the optimization direction of the
entire network. We have also designed a variety of multi-data fusion methods in
the Hamming space to preserve the advantages of both convolution and
multi-view. In order to avoid excessive computing resources on the enhancement
procedure during retrieval, we set up a separate structure called memory
network which participates in training together. The proposed method is
systematically evaluated on the CIFAR-10, NUS-WIDE and MS-COCO datasets, and
the results show that our method significantly outperforms the state-of-the-art
single-view and multi-view hashing methods.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/rashtchian2020lsf/">Lsf-join: Locality Sensitive Filtering For Distributed All-pairs Set Similarity Under Skew</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Lsf-join: Locality Sensitive Filtering For Distributed All-pairs Set Similarity Under Skew' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Lsf-join: Locality Sensitive Filtering For Distributed All-pairs Set Similarity Under Skew' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Rashtchian Cyrus, Sharma Aneesh, Woodruff David P.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of The Web Conference 2020</td>
    <td>5</td>
    <td><p>All-pairs set similarity is a widely used data mining task, even for large
and high-dimensional datasets. Traditionally, similarity search has focused on
discovering very similar pairs, for which a variety of efficient algorithms are
known. However, recent work highlights the importance of finding pairs of sets
with relatively small intersection sizes. For example, in a recommender system,
two users may be alike even though their interests only overlap on a small
percentage of items. In such systems, some dimensions are often highly skewed
because they are very popular. Together these two properties render previous
approaches infeasible for large input sizes. To address this problem, we
present a new distributed algorithm, LSF-Join, for approximate all-pairs set
similarity. The core of our algorithm is a randomized selection procedure based
on Locality Sensitive Filtering. Our method deviates from prior approximate
algorithms, which are based on Locality Sensitive Hashing. Theoretically, we
show that LSF-Join efficiently finds most close pairs, even for small
similarity thresholds and for skewed input sets. We prove guarantees on the
communication, work, and maximum load of LSF-Join, and we also experimentally
demonstrate its accuracy on multiple graphs.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Recommender Systems 
      
        Similarity Search 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/li2020topology/">Topology-aware Hashing For Effective Control Flow Graph Similarity Analysis</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Topology-aware Hashing For Effective Control Flow Graph Similarity Analysis' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Topology-aware Hashing For Effective Control Flow Graph Similarity Analysis' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li Yuping, Jang Jiong, Ou Xinming</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering</td>
    <td>5</td>
    <td><p>Control Flow Graph (CFG) similarity analysis is an essential technique for a
variety of security analysis tasks, including malware detection and malware
clustering. Even though various algorithms have been developed, existing CFG
similarity analysis methods still suffer from limited efficiency, accuracy, and
usability. In this paper, we propose a novel fuzzy hashing scheme called
topology-aware hashing (TAH) for effective and efficient CFG similarity
analysis. Given the CFGs constructed from program binaries, we extract blended
n-gram graphical features of the CFGs, encode the graphical features into
numeric vectors (called graph signatures), and then measure the graph
similarity by comparing the graph signatures. We further employ a fuzzy hashing
technique to convert the numeric graph signatures into smaller fixed-size fuzzy
hash signatures for efficient similarity calculation. Our comprehensive
evaluation demonstrates that TAH is more effective and efficient compared to
existing CFG comparison techniques. To demonstrate the applicability of TAH to
real-world security analysis tasks, we develop a binary similarity analysis
tool based on TAH, and show that it outperforms existing similarity analysis
tools while conducting malware clustering.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/li2020deep/">Deep Unsupervised Image Hashing By Maximizing Bit Entropy</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Unsupervised Image Hashing By Maximizing Bit Entropy' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Unsupervised Image Hashing By Maximizing Bit Entropy' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li Yunqiang, van Gemert Jan</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>75</td>
    <td><p>Unsupervised hashing is important for indexing huge image or video
collections without having expensive annotations available. Hashing aims to
learn short binary codes for compact storage and efficient semantic retrieval.
We propose an unsupervised deep hashing layer called Bi-half Net that maximizes
entropy of the binary codes. Entropy is maximal when both possible values of
the bit are uniformly (half-half) distributed. To maximize bit entropy, we do
not add a term to the loss function as this is difficult to optimize and tune.
Instead, we design a new parameter-free network layer to explicitly force
continuous image features to approximate the optimal half-half bit
distribution. This layer is shown to minimize a penalized term of the
Wasserstein distance between the learned continuous image features and the
optimal half-half bit distribution. Experimental results on the image datasets
Flickr25k, Nus-wide, Cifar-10, Mscoco, Mnist and the video datasets Ucf-101 and
Hmdb-51 show that our approach leads to compact codes and compares favorably to
the current state-of-the-art.</p>
</td>
    <td>
      
        Image Retrieval 
      
        AAAI 
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Neural Hashing 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/li2020hamming/">Hamming OCR: A Locality Sensitive Hashing Neural Network For Scene Text Recognition</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hamming OCR: A Locality Sensitive Hashing Neural Network For Scene Text Recognition' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hamming OCR: A Locality Sensitive Hashing Neural Network For Scene Text Recognition' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>5</td>
    <td><p>Recently, inspired by Transformer, self-attention-based scene text
recognition approaches have achieved outstanding performance. However, we find
that the size of model expands rapidly with the lexicon increasing.
Specifically, the number of parameters for softmax classification layer and
output embedding layer are proportional to the vocabulary size. It hinders the
development of a lightweight text recognition model especially applied for
Chinese and multiple languages. Thus, we propose a lightweight scene text
recognition model named Hamming OCR. In this model, a novel Hamming classifier,
which adopts locality sensitive hashing (LSH) algorithm to encode each
character, is proposed to replace the softmax regression and the generated LSH
code is directly employed to replace the output embedding. We also present a
simplified transformer decoder to reduce the number of parameters by removing
the feed-forward network and using cross-layer parameter sharing technique.
Compared with traditional methods, the number of parameters in both
classification and embedding layers is independent on the size of vocabulary,
which significantly reduces the storage requirement without loss of accuracy.
Experimental results on several datasets, including four public benchmaks and a
Chinese text dataset synthesized by SynthText with more than 20,000 characters,
shows that Hamming OCR achieves competitive results.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/li2020perceptual/">Perceptual Robust Hashing For Color Images With Canonical Correlation Analysis</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Perceptual Robust Hashing For Color Images With Canonical Correlation Analysis' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Perceptual Robust Hashing For Color Images With Canonical Correlation Analysis' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Journal of Electronic Imaging</td>
    <td>5</td>
    <td><p>In this paper, a novel perceptual image hashing scheme for color images is
proposed based on ring-ribbon quadtree and color vector angle. First, original
image is subjected to normalization and Gaussian low-pass filtering to produce
a secondary image, which is divided into a series of ring-ribbons with
different radii and the same number of pixels. Then, both textural and color
features are extracted locally and globally. Quadtree decomposition (QD) is
applied on luminance values of the ring-ribbons to extract local textural
features, and the gray level co-occurrence matrix (GLCM) is used to extract
global textural features. Local color features of significant corner points on
outer boundaries of ring-ribbons are extracted through color vector angles
(CVA), and color low-order moments (CLMs) is utilized to extract global color
features. Finally, two types of feature vectors are fused via canonical
correlation analysis (CCA) to prodcue the final hash after scrambling. Compared
with direct concatenation, the CCA feature fusion method improves
classification performance, which better reflects overall correlation between
two sets of feature vectors. Receiver operating characteristic (ROC) curve
shows that our scheme has satisfactory performances with respect to robustness,
discrimination and security, which can be effectively used in copy detection
and content authentication.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/levi2020rethinking/">Rethinking Preventing Class-collapsing In Metric Learning With Margin-based Losses</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Rethinking Preventing Class-collapsing In Metric Learning With Margin-based Losses' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Rethinking Preventing Class-collapsing In Metric Learning With Margin-based Losses' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Levi et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2021 IEEE/CVF International Conference on Computer Vision (ICCV)</td>
    <td>15</td>
    <td><p>Metric learning seeks perceptual embeddings where visually similar instances
are close and dissimilar instances are apart, but learned representations can
be sub-optimal when the distribution of intra-class samples is diverse and
distinct sub-clusters are present. Although theoretically with optimal
assumptions, margin-based losses such as the triplet loss and margin loss have
a diverse family of solutions. We theoretically prove and empirically show that
under reasonable noise assumptions, margin-based losses tend to project all
samples of a class with various modes onto a single point in the embedding
space, resulting in a class collapse that usually renders the space ill-sorted
for classification or retrieval. To address this problem, we propose a simple
modification to the embedding losses such that each sample selects its nearest
same-class counterpart in a batch as the positive element in the tuple. This
allows for the presence of multiple sub-clusters within each class. The
adaptation can be integrated into a wide range of metric learning losses. The
proposed sampling method demonstrates clear benefits on various fine-grained
image retrieval datasets over a variety of existing losses; qualitative
retrieval results show that samples with similar visual patterns are indeed
closer in the embedding space.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Distance Metric Learning 
      
        Alt 
      
        ICCV 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/lei2020locality/">Locality-sensitive Hashing Scheme Based On Longest Circular Co-substring</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Locality-sensitive Hashing Scheme Based On Longest Circular Co-substring' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Locality-sensitive Hashing Scheme Based On Longest Circular Co-substring' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lei et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data</td>
    <td>24</td>
    <td><p>Locality-Sensitive Hashing (LSH) is one of the most popular methods for
\(c\)-Approximate Nearest Neighbor Search (\(c\)-ANNS) in high-dimensional spaces.
In this paper, we propose a novel LSH scheme based on the Longest Circular
Co-Substring (LCCS) search framework (LCCS-LSH) with a theoretical guarantee.
We introduce a novel concept of LCCS and a new data structure named Circular
Shift Array (CSA) for \(k\)-LCCS search. The insight of LCCS search framework is
that close data objects will have a longer LCCS than the far-apart ones with
high probability. LCCS-LSH is <em>LSH-family-independent</em>, and it supports
\(c\)-ANNS with different kinds of distance metrics. We also introduce a
multi-probe version of LCCS-LSH and conduct extensive experiments over five
real-life datasets. The experimental results demonstrate that LCCS-LSH
outperforms state-of-the-art LSH schemes.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/wang2020faster/">Faster Person Re-identification</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Faster Person Re-identification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Faster Person Re-identification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>54</td>
    <td><p>Fast person re-identification (ReID) aims to search person images quickly and
accurately. The main idea of recent fast ReID methods is the hashing algorithm,
which learns compact binary codes and performs fast Hamming distance and
counting sort. However, a very long code is needed for high accuracy (e.g.
2048), which compromises search speed. In this work, we introduce a new
solution for fast ReID by formulating a novel Coarse-to-Fine (CtF) hashing code
search strategy, which complementarily uses short and long codes, achieving
both faster speed and better accuracy. It uses shorter codes to coarsely rank
broad matching similarities and longer codes to refine only a few top
candidates for more accurate instance ReID. Specifically, we design an
All-in-One (AiO) framework together with a Distance Threshold Optimization
(DTO) algorithm. In AiO, we simultaneously learn and enhance multiple codes of
different lengths in a single model. It learns multiple codes in a pyramid
structure, and encourage shorter codes to mimic longer codes by
self-distillation. DTO solves a complex threshold search problem by a simple
optimization process, and the balance between accuracy and speed is easily
controlled by a single parameter. It formulates the optimization target as a
\(F_{\beta}\) score that can be optimised by Gaussian cumulative distribution
functions. Experimental results on 2 datasets show that our proposed method
(CtF) is not only 8% more accurate but also 5x faster than contemporary hashing
ReID methods. Compared with non-hashing ReID methods, CtF is \(50\times\) faster
with comparable accuracy. Code is available at
https://github.com/wangguanan/light-reid.</p>
</td>
    <td>
      
        Compact Codes 
      
        DATASETS 
      
        Tools & Libraries 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/li2020task/">Task-adaptive Asymmetric Deep Cross-modal Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Task-adaptive Asymmetric Deep Cross-modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Task-adaptive Asymmetric Deep Cross-modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Knowledge-Based Systems</td>
    <td>17</td>
    <td><p>Supervised cross-modal hashing aims to embed the semantic correlations of
heterogeneous modality data into the binary hash codes with discriminative
semantic labels. Because of its advantages on retrieval and storage efficiency,
it is widely used for solving efficient cross-modal retrieval. However,
existing researches equally handle the different tasks of cross-modal
retrieval, and simply learn the same couple of hash functions in a symmetric
way for them. Under such circumstance, the uniqueness of different cross-modal
retrieval tasks are ignored and sub-optimal performance may be brought.
Motivated by this, we present a Task-adaptive Asymmetric Deep Cross-modal
Hashing (TA-ADCMH) method in this paper. It can learn task-adaptive hash
functions for two sub-retrieval tasks via simultaneous modality representation
and asymmetric hash learning. Unlike previous cross-modal hashing approaches,
our learning framework jointly optimizes semantic preserving that transforms
deep features of multimedia data into binary hash codes, and the semantic
regression which directly regresses query modality representation to explicit
label. With our model, the binary codes can effectively preserve semantic
correlations across different modalities, meanwhile, adaptively capture the
query semantics. The superiority of TA-ADCMH is proved on two standard datasets
from many aspects.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Multimodal Retrieval 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/lee2020flexor/">Flexor: Trainable Fractional Quantization</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Flexor: Trainable Fractional Quantization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Flexor: Trainable Fractional Quantization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lee et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>9</td>
    <td><p>Quantization based on the binary codes is gaining attention because each
quantized bit can be directly utilized for computations without dequantization
using look-up tables. Previous attempts, however, only allow for integer
numbers of quantization bits, which ends up restricting the search space for
compression ratio and accuracy. In this paper, we propose an encryption
algorithm/architecture to compress quantized weights so as to achieve
fractional numbers of bits per weight. Decryption during inference is
implemented by digital XOR-gate networks added into the neural network model
while XOR gates are described by utilizing \(\tanh(x)\) for backward propagation
to enable gradient calculations. We perform experiments using MNIST, CIFAR-10,
and ImageNet to show that inserting XOR gates learns quantization/encrypted bit
decisions through training and obtains high accuracy even for fractional sub
1-bit weights. As a result, our proposed method yields smaller size and higher
model accuracy compared to binary neural networks.</p>
</td>
    <td>
      
        Compact Codes 
      
        Quantization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/lee2020metric/">Metric Learning Vs Classification For Disentangled Music Representation Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Metric Learning Vs Classification For Disentangled Music Representation Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Metric Learning Vs Classification For Disentangled Music Representation Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lee et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>11</td>
    <td><p>Deep representation learning offers a powerful paradigm for mapping input
data onto an organized embedding space and is useful for many music information
retrieval tasks. Two central methods for representation learning include deep
metric learning and classification, both having the same goal of learning a
representation that can generalize well across tasks. Along with
generalization, the emerging concept of disentangled representations is also of
great interest, where multiple semantic concepts (e.g., genre, mood,
instrumentation) are learned jointly but remain separable in the learned
representation space. In this paper we present a single representation learning
framework that elucidates the relationship between metric learning,
classification, and disentanglement in a holistic manner. For this, we (1)
outline past work on the relationship between metric learning and
classification, (2) extend this relationship to multi-label data by exploring
three different learning approaches and their disentangled versions, and (3)
evaluate all models on four tasks (training time, similarity retrieval,
auto-tagging, and triplet prediction). We find that classification-based models
are generally advantageous for training time, similarity retrieval, and
auto-tagging, while deep metric learning exhibits better performance for
triplet-prediction. Finally, we show that our proposed approach yields
state-of-the-art results for music auto-tagging.</p>
</td>
    <td>
      
        Similarity Search 
      
        Tools & Libraries 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2020</td>
    <td>
      <a href="/publications/morgado2020deep/">Deep Hashing With Hash-consistent Large Margin Proxy Embeddings</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Hashing With Hash-consistent Large Margin Proxy Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Hashing With Hash-consistent Large Margin Proxy Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Morgado et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>International Journal of Computer Vision</td>
    <td>6</td>
    <td><p>Image hash codes are produced by binarizing the embeddings of convolutional
neural networks (CNN) trained for either classification or retrieval. While
proxy embeddings achieve good performance on both tasks, they are non-trivial
to binarize, due to a rotational ambiguity that encourages non-binary
embeddings. The use of a fixed set of proxies (weights of the CNN
classification layer) is proposed to eliminate this ambiguity, and a procedure
to design proxy sets that are nearly optimal for both classification and
hashing is introduced. The resulting hash-consistent large margin (HCLM)
proxies are shown to encourage saturation of hashing units, thus guaranteeing a
small binarization error, while producing highly discriminative hash-codes. A
semantic extension (sHCLM), aimed to improve hashing performance in a transfer
scenario, is also proposed. Extensive experiments show that sHCLM embeddings
achieve significant improvements over state-of-the-art hashing procedures on
several small and large datasets, both within and beyond the set of training
classes.</p>
</td>
    <td>
      
        DATASETS 
      
        Neural Hashing 
      
        Evaluation 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
    
      
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/gillick2019learning/">Learning Dense Representations For Entity Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning Dense Representations For Entity Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning Dense Representations For Entity Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Gillick et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)</td>
    <td>188</td>
    <td><p>We show that it is feasible to perform entity linking by training a dual
encoder (two-tower) model that encodes mentions and entities in the same dense
vector space, where candidate entities are retrieved by approximate nearest
neighbor search. Unlike prior work, this setup does not rely on an alias table
followed by a re-ranker, and is thus the first fully learned entity retrieval
model. We show that our dual encoder, trained using only anchor-text links in
Wikipedia, outperforms discrete alias table and BM25 baselines, and is
competitive with the best comparable results on the standard TACKBP-2010
dataset. In addition, it can retrieve candidates extremely fast, and
generalizes well to a new dataset derived from Wikinews. On the modeling side,
we demonstrate the dramatic value of an unsupervised negative mining algorithm
for this task.</p>
</td>
    <td>
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/zhu2019exploring/">Exploring Auxiliary Context: Discrete Semantic Transfer Hashing For Scalable Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Exploring Auxiliary Context: Discrete Semantic Transfer Hashing For Scalable Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Exploring Auxiliary Context: Discrete Semantic Transfer Hashing For Scalable Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Neural Networks and Learning Systems</td>
    <td>154</td>
    <td><p>Unsupervised hashing can desirably support scalable content-based image
retrieval (SCBIR) for its appealing advantages of semantic label independence,
memory and search efficiency. However, the learned hash codes are embedded with
limited discriminative semantics due to the intrinsic limitation of image
representation. To address the problem, in this paper, we propose a novel
hashing approach, dubbed as <em>Discrete Semantic Transfer Hashing</em> (DSTH).
The key idea is to <em>directly</em> augment the semantics of discrete image hash
codes by exploring auxiliary contextual modalities. To this end, a unified
hashing framework is formulated to simultaneously preserve visual similarities
of images and perform semantic transfer from contextual modalities. Further, to
guarantee direct semantic transfer and avoid information loss, we explicitly
impose the discrete constraint, bitâ€“uncorrelation constraint and bit-balance
constraint on hash codes. A novel and effective discrete optimization method
based on augmented Lagrangian multiplier is developed to iteratively solve the
optimization problem. The whole learning process has linear computation
complexity and desirable scalability. Experiments on three benchmark datasets
demonstrate the superiority of DSTH compared with several state-of-the-art
approaches.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/giraud2019superpixel/">Superpixel-based Color Transfer</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Superpixel-based Color Transfer' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Superpixel-based Color Transfer' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Giraud RÃ©mi, Ta Vinh-thong, Papadakis Nicolas</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 IEEE International Conference on Image Processing (ICIP)</td>
    <td>6</td>
    <td><p>In this work, we propose a fast superpixel-based color transfer method (SCT)
between two images. Superpixels enable to decrease the image dimension and to
extract a reduced set of color candidates. We propose to use a fast approximate
nearest neighbor matching algorithm in which we enforce the match diversity by
limiting the selection of the same superpixels. A fusion framework is designed
to transfer the matched colors, and we demonstrate the improvement obtained
over exact matching results. Finally, we show that SCT is visually competitive
compared to state-of-the-art methods.</p>
</td>
    <td>
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/wang2019cluster/">Cluster-wise Unsupervised Hashing For Cross-modal Similarity Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Cluster-wise Unsupervised Hashing For Cross-modal Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Cluster-wise Unsupervised Hashing For Cross-modal Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang Lu, Yang Jie</td> <!-- ðŸ”§ You were missing this -->
    <td>Pattern Recognition</td>
    <td>25</td>
    <td><p>Large-scale cross-modal hashing similarity retrieval has attracted more and
more attention in modern search applications such as search engines and
autopilot, showing great superiority in computation and storage. However,
current unsupervised cross-modal hashing methods still have some limitations:
(1)many methods relax the discrete constraints to solve the optimization
objective which may significantly degrade the retrieval performance;(2)most
existing hashing model project heterogenous data into a common latent space,
which may always lose sight of diversity in heterogenous data;(3)transforming
real-valued data point to binary codes always results in abundant loss of
information, producing the suboptimal continuous latent space. To overcome
above problems, in this paper, a novel Cluster-wise Unsupervised Hashing (CUH)
method is proposed. Specifically, CUH jointly performs the multi-view
clustering that projects the original data points from different modalities
into its own low-dimensional latent semantic space and finds the cluster
centroid points and the common clustering indicators in its own low-dimensional
space, and learns the compact hash codes and the corresponding linear hash
functions. An discrete optimization framework is developed to learn the unified
binary codes across modalities under the guidance cluster-wise code-prototypes.
The reasonableness and effectiveness of CUH is well demonstrated by
comprehensive experiments on diverse benchmark datasets.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        CVPR 
      
        Compact Codes 
      
        Similarity Search 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/gao2019beyond/">Beyond Product Quantization: Deep Progressive Quantization For Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Beyond Product Quantization: Deep Progressive Quantization For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Beyond Product Quantization: Deep Progressive Quantization For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Gao et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence</td>
    <td>28</td>
    <td><p>Product Quantization (PQ) has long been a mainstream for generating an
exponentially large codebook at very low memory/time cost. Despite its success,
PQ is still tricky for the decomposition of high-dimensional vector space, and
the retraining of model is usually unavoidable when the code length changes. In
this work, we propose a deep progressive quantization (DPQ) model, as an
alternative to PQ, for large scale image retrieval. DPQ learns the quantization
codes sequentially and approximates the original feature space progressively.
Therefore, we can train the quantization codes with different code lengths
simultaneously. Specifically, we first utilize the label information for
guiding the learning of visual features, and then apply several quantization
blocks to progressively approach the visual features. Each quantization block
is designed to be a layer of a convolutional neural network, and the whole
framework can be trained in an end-to-end manner. Experimental results on the
benchmark datasets show that our model significantly outperforms the
state-of-the-art for image retrieval. Our model is trained once for different
code lengths and therefore requires less computation time. Additional ablation
study demonstrates the effect of each component of our proposed model. Our code
is released at https://github.com/cfm-uestc/DPQ.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        IJCAI 
      
        Quantization 
      
        AAAI 
      
        Image Retrieval 
      
        Tools & Libraries 
      
        Alt 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/gajic2019bag/">Bag Of Negatives For Siamese Architectures</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Bag Of Negatives For Siamese Architectures' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Bag Of Negatives For Siamese Architectures' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Gajic et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Angewandte Chemie International Edition</td>
    <td>5</td>
    <td><p>Training a Siamese architecture for re-identification with a large number of
identities is a challenging task due to the difficulty of finding relevant
negative samples efficiently. In this work we present Bag of Negatives (BoN), a
method for accelerated and improved training of Siamese networks that scales
well on datasets with a very large number of identities. BoN is an efficient
and loss-independent method, able to select a bag of high quality negatives,
based on a novel online hashing strategy.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/fu2019high/">High Dimensional Similarity Search With Satellite System Graph: Efficiency, Scalability, And Unindexed Query Compatibility</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=High Dimensional Similarity Search With Satellite System Graph: Efficiency, Scalability, And Unindexed Query Compatibility' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=High Dimensional Similarity Search With Satellite System Graph: Efficiency, Scalability, And Unindexed Query Compatibility' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Fu Cong, Wang Changxu, Cai Deng</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Pattern Analysis and Machine Intelligence</td>
    <td>30</td>
    <td><p>Approximate Nearest Neighbor Search (ANNS) in high dimensional space is
essential in database and information retrieval. Recently, there has been a
surge of interest in exploring efficient graph-based indices for the ANNS
problem. Among them, Navigating Spreading-out Graph (NSG) provides fine
theoretical analysis and achieves state-of-the-art performance. However, we
find there are several limitations with NSG: 1) NSG has no theoretical
guarantee on nearest neighbor search when the query is not indexed in the
database; 2) NSG is too sparse which harms the search performance. In addition,
NSG suffers from high indexing complexity. To address the above problems, we
propose the Satellite System Graphs (SSG) and a practical variant NSSG.
Specifically, we propose a novel pruning strategy to produce SSGs from the
complete graph. SSGs define a new family of MSNETs in which the out-edges of
each node are distributed evenly in all directions. Each node in the graph
builds effective connections to its neighborhood omnidirectionally, whereupon
we derive SSGâ€™s excellent theoretical properties for both indexed and unindexed
queries. We can adaptively adjust the sparsity of an SSG with a hyper-parameter
to optimize the search performance. Further, NSSG is proposed to reduce the
indexing complexity of the SSG for large-scale applications. Both theoretical
and extensive experimental analyses are provided to demonstrate the strengths
of the proposed approach over the existing representative algorithms. Our code
has been released at https://github.com/ZJULearning/SSG.</p>
</td>
    <td>
      
        Graph Based ANN 
      
        Similarity Search 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/filtser2019labelings/">Labelings Vs. Embeddings: On Distributed Representations Of Distances</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Labelings Vs. Embeddings: On Distributed Representations Of Distances' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Labelings Vs. Embeddings: On Distributed Representations Of Distances' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Filtser Arnold, Gottlieb Lee-ad, Krauthgamer Robert</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the Fourteenth Annual ACM-SIAM Symposium on Discrete Algorithms</td>
    <td>5</td>
    <td><p>We investigate for which metric spaces the performance of distance labeling
and of \(\ell_\infty\)-embeddings differ, and how significant can this difference
be. Recall that a distance labeling is a distributed representation of
distances in a metric space \((X,d)\), where each point \(x\in X\) is assigned a
succinct label, such that the distance between any two points \(x,y \in X\) can
be approximated given only their labels. A highly structured special case is an
embedding into \(\ell_\infty\), where each point \(x\in X\) is assigned a vector
\(f(x)\) such that \(|f(x)-f(y)|<em>\infty\) is approximately \(d(x,y)\). The
performance of a distance labeling or an \(\ell</em>\infty\)-embedding is measured
via its distortion and its label-size/dimension.
  We also study the analogous question for the prioritized versions of these
two measures. Here, a priority order \(\pi=(x_1,\dots,x_n)\) of the point set \(X\)
is given, and higher-priority points should have shorter labels. Formally, a
distance labeling has prioritized label-size \(\alpha(\cdot)\) if every \(x_j\) has
label size at most \(\alpha(j)\). Similarly, an embedding \(f: X \to \ell_\infty\)
has prioritized dimension \(\alpha(\cdot)\) if \(f(x_j)\) is non-zero only in the
first \(\alpha(j)\) coordinates. In addition, we compare these prioritized
measures to their classical (worst-case) versions.
  We answer these questions in several scenarios, uncovering a surprisingly
diverse range of behaviors. First, in some cases labelings and embeddings have
very similar worst-case performance, but in other cases there is a huge
disparity. However in the prioritized setting, we most often find a strict
separation between the performance of labelings and embeddings. And finally,
when comparing the classical and prioritized settings, we find that the
worst-case bound for label size often â€œtranslatesâ€ to a prioritized one, but
also find a surprising exception to this rule.</p>
</td>
    <td>
      
        Graph Based ANN 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/francislandau2019exact/">Exact And/or Fast Nearest Neighbors</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Exact And/or Fast Nearest Neighbors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Exact And/or Fast Nearest Neighbors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Francis-landau Matthew, van Durme Benjamin</td> <!-- ðŸ”§ You were missing this -->
    <td>Pattern Recognition</td>
    <td>85</td>
    <td><p>Prior methods for retrieval of nearest neighbors in high dimensions are fast
and approximateâ€“providing probabilistic guarantees of returning the correct
answerâ€“or slow and exact performing an exhaustive search. We present Certified
Cosine, a novel approach to nearest-neighbors which takes advantage of
structure present in the cosine similarity distance metric to offer
certificates. When a certificate is constructed, it guarantees that the nearest
neighbor set is correct, possibly avoiding an exhaustive search. Certified
Cosineâ€™s certificates work with high dimensional data and outperform previous
exact nearest neighbor methods on these datasets.</p>
</td>
    <td>
      
        CVPR 
      
        DATASETS 
      
        Graph Based ANN 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/zhou2019ladder/">Ladder Loss For Coherent Visual-semantic Embedding</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Ladder Loss For Coherent Visual-semantic Embedding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Ladder Loss For Coherent Visual-semantic Embedding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhou et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>27</td>
    <td><p>For visual-semantic embedding, the existing methods normally treat the
relevance between queries and candidates in a bipolar way â€“ relevant or
irrelevant, and all â€œirrelevantâ€ candidates are uniformly pushed away from the
query by an equal margin in the embedding space, regardless of their various
proximity to the query. This practice disregards relatively discriminative
information and could lead to suboptimal ranking in the retrieval results and
poorer user experience, especially in the long-tail query scenario where a
matching candidate may not necessarily exist. In this paper, we introduce a
continuous variable to model the relevance degree between queries and multiple
candidates, and propose to learn a coherent embedding space, where candidates
with higher relevance degrees are mapped closer to the query than those with
lower relevance degrees. In particular, the new ladder loss is proposed by
extending the triplet loss inequality to a more general inequality chain, which
implements variable push-away margins according to respective relevance
degrees. In addition, a proper Coherent Score metric is proposed to better
measure the ranking results including those â€œirrelevantâ€ candidates. Extensive
experiments on multiple datasets validate the efficacy of our proposed method,
which achieves significant improvement over existing state-of-the-art methods.</p>
</td>
    <td>
      
        AAAI 
      
        DATASETS 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/sanakoyeu2019divide/">Divide And Conquer The Embedding Space For Metric Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Divide And Conquer The Embedding Space For Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Divide And Conquer The Embedding Space For Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Sanakoyeu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>121</td>
    <td><p>Learning the embedding space, where semantically similar objects are located
close together and dissimilar objects far apart, is a cornerstone of many
computer vision applications. Existing approaches usually learn a single metric
in the embedding space for all available data points, which may have a very
complex non-uniform distribution with different notions of similarity between
objects, e.g. appearance, shape, color or semantic meaning. Approaches for
learning a single distance metric often struggle to encode all different types
of relationships and do not generalize well. In this work, we propose a novel
easy-to-implement divide and conquer approach for deep metric learning, which
significantly improves the state-of-the-art performance of metric learning. Our
approach utilizes the embedding space more efficiently by jointly splitting the
embedding space and data into \(K\) smaller sub-problems. It divides both, the
data and the embedding space into \(K\) subsets and learns \(K\) separate distance
metrics in the non-overlapping subspaces of the embedding space, defined by
groups of neurons in the embedding layer of the neural network. The proposed
approach increases the convergence speed and improves generalization since the
complexity of each sub-problem is reduced compared to the original one. We show
that our approach outperforms the state-of-the-art by a large margin in
retrieval, clustering and re-identification tasks on CUB200-2011, CARS196,
Stanford Online Products, In-shop Clothes and PKU VehicleID datasets.</p>
</td>
    <td>
      
        CVPR 
      
        DATASETS 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/esposito2019recsplit/">Recsplit: Minimal Perfect Hashing Via Recursive Splitting</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Recsplit: Minimal Perfect Hashing Via Recursive Splitting' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Recsplit: Minimal Perfect Hashing Via Recursive Splitting' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Esposito Emmanuel, Graf Thomas Mueller, Vigna Sebastiano</td> <!-- ðŸ”§ You were missing this -->
    <td>2020 Proceedings of the Twenty-Second Workshop on Algorithm Engineering and Experiments (ALENEX)</td>
    <td>20</td>
    <td><p>A minimal perfect hash function bijectively maps a key set \(S\) out of a
universe \(U\) into the first \(|S|\) natural numbers. Minimal perfect hash
functions are used, for example, to map irregularly-shaped keys, such as
string, in a compact space so that metadata can then be simply stored in an
array. While it is known that just \(1.44\) bits per key are necessary to store a
minimal perfect function, no published technique can go below \(2\) bits per key
in practice. We propose a new technique for storing minimal perfect hash
functions with expected linear construction time and expected constant lookup
time that makes it possible to build for the first time, for example,
structures which need \(1.56\) bits per key, that is, within \(8.3\)% of the lower
bound, in less than \(2\) ms per key. We show that instances of our construction
are able to simultaneously beat the construction time, space usage and lookup
time of the state-of-the-art data structure reaching \(2\) bits per key.
Moreover, we provide parameter choices giving structures which are competitive
with alternative, larger-size data structures in terms of space and lookup
time. The construction of our data structures can be easily parallelized or
mapped on distributed computational units (e.g., within the MapReduce
framework), and structures larger than the available RAM can be directly built
in mass storage.</p>
</td>
    <td>
      
        Alt 
      
        Tools & Libraries 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/jiang2019evaluation/">On The Evaluation Metric For Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=On The Evaluation Metric For Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=On The Evaluation Metric For Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jiang Qing-yuan, Li Ming-wei, Li Wu-jun</td> <!-- ðŸ”§ You were missing this -->
    <td>Medical Image Analysis</td>
    <td>15</td>
    <td><p>Due to its low storage cost and fast query speed, hashing has been widely
used for large-scale approximate nearest neighbor (ANN) search. Bucket search,
also called hash lookup, can achieve fast query speed with a sub-linear time
cost based on the inverted index table constructed from hash codes. Many
metrics have been adopted to evaluate hashing algorithms. However, all existing
metrics are improper to evaluate the hash codes for bucket search. On one hand,
all existing metrics ignore the retrieval time cost which is an important
factor reflecting the performance of search. On the other hand, some of them,
such as mean average precision (MAP), suffer from the uncertainty problem as
the ranked list is based on integer-valued Hamming distance, and are
insensitive to Hamming radius as these metrics only depend on relative Hamming
distance. Other metrics, such as precision at Hamming radius R, fail to
evaluate global performance as these metrics only depend on one specific
Hamming radius. In this paper, we first point out the problems of existing
metrics which have been ignored by the hashing community, and then propose a
novel evaluation metric called radius aware mean average precision (RAMAP) to
evaluate hash codes for bucket search. Furthermore, two coding strategies are
also proposed to qualitatively show the problems of existing metrics.
Experiments demonstrate that our proposed RAMAP can provide more proper
evaluation than existing metrics.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/jia2019efficient/">Efficient Task-specific Data Valuation For Nearest Neighbor Algorithms</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Efficient Task-specific Data Valuation For Nearest Neighbor Algorithms' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Efficient Task-specific Data Valuation For Nearest Neighbor Algorithms' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jia et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the VLDB Endowment</td>
    <td>129</td>
    <td><p>Given a data set \(\mathcal{D}\) containing millions of data points and a data
consumer who is willing to pay for $\(X\) to train a machine learning (ML) model
over \(\mathcal{D}\), how should we distribute this $\(X\) to each data point to
reflect its â€œvalueâ€? In this paper, we define the â€œrelative value of dataâ€ via
the Shapley value, as it uniquely possesses properties with appealing
real-world interpretations, such as fairness, rationality and
decentralizability. For general, bounded utility functions, the Shapley value
is known to be challenging to compute: to get Shapley values for all \(N\) data
points, it requires \(O(2^N)\) model evaluations for exact computation and
\(O(Nlog N)\) for \((\epsilon, \delta)\)-approximation. In this paper, we focus on
one popular family of ML models relying on \(K\)-nearest neighbors (\(K\)NN). The
most surprising result is that for unweighted \(K\)NN classifiers and regressors,
the Shapley value of all \(N\) data points can be computed, exactly, in \(O(Nlog
N)\) time â€“ an exponential improvement on computational complexity! Moreover,
for \((\epsilon, \delta)\)-approximation, we are able to develop an algorithm
based on Locality Sensitive Hashing (LSH) with only sublinear complexity
\(O(N^{h(\epsilon,K)}log N)\) when \(\epsilon\) is not too small and \(K\) is not
too large. We empirically evaluate our algorithms on up to \(10\) million data
points and even our exact algorithm is up to three orders of magnitude faster
than the baseline approximation algorithm. The LSH-based approximation
algorithm can accelerate the value calculation process even further. We then
extend our algorithms to other scenarios such as (1) weighed \(K\)NN classifiers,
(2) different data points are clustered by different data curators, and (3)
there are data analysts providing computation who also requires proper
valuation.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/jiang2019graph/">Graph-based Multi-view Binary Learning For Image Clustering</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Graph-based Multi-view Binary Learning For Image Clustering' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Graph-based Multi-view Binary Learning For Image Clustering' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jiang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Neurocomputing</td>
    <td>28</td>
    <td><p>Hashing techniques, also known as binary code learning, have recently gained
increasing attention in large-scale data analysis and storage. Generally, most
existing hash clustering methods are single-view ones, which lack complete
structure or complementary information from multiple views. For cluster tasks,
abundant prior researches mainly focus on learning discrete hash code while few
works take original data structure into consideration. To address these
problems, we propose a novel binary code algorithm for clustering, which adopts
graph embedding to preserve the original data structure, called (Graph-based
Multi-view Binary Learning) GMBL in this paper. GMBL mainly focuses on encoding
the information of multiple views into a compact binary code, which explores
complementary information from multiple views. In particular, in order to
maintain the graph-based structure of the original data, we adopt a Laplacian
matrix to preserve the local linear relationship of the data and map it to the
Hamming space. Considering different views have distinctive contributions to
the final clustering results, GMBL adopts a strategy of automatically assign
weights for each view to better guide the clustering. Finally, An alternating
iterative optimization method is adopted to optimize discrete binary codes
directly instead of relaxing the binary constraint in two steps. Experiments on
five public datasets demonstrate the superiority of our proposed method
compared with previous approaches in terms of clustering performance.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Graph Based ANN 
      
        Compact Codes 
      
        Alt 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/roy2019metric/">Metric-learning Based Deep Hashing Network For Content Based Retrieval Of Remote Sensing Images</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Metric-learning Based Deep Hashing Network For Content Based Retrieval Of Remote Sensing Images' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Metric-learning Based Deep Hashing Network For Content Based Retrieval Of Remote Sensing Images' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Roy et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Geoscience and Remote Sensing Letters</td>
    <td>75</td>
    <td><p>Hashing methods have been recently found very effective in retrieval of
remote sensing (RS) images due to their computational efficiency and fast
search speed. The traditional hashing methods in RS usually exploit
hand-crafted features to learn hash functions to obtain binary codes, which can
be insufficient to optimally represent the information content of RS images. To
overcome this problem, in this paper we introduce a metric-learning based
hashing network, which learns: 1) a semantic-based metric space for effective
feature representation; and 2) compact binary hash codes for fast archive
search. Our network considers an interplay of multiple loss functions that
allows to jointly learn a metric based semantic space facilitating similar
images to be clustered together in that target space and at the same time
producing compact final activations that lose negligible information when
binarized. Experiments carried out on two benchmark RS archives point out that
the proposed network significantly improves the retrieval performance under the
same retrieval time when compared to the state-of-the-art hashing methods in
RS.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Neural Hashing 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/yuan2019signal/">Signal-to-noise Ratio: A Robust Distance Metric For Deep Metric Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Signal-to-noise Ratio: A Robust Distance Metric For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Signal-to-noise Ratio: A Robust Distance Metric For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yuan et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>81</td>
    <td><p>Deep metric learning, which learns discriminative features to process image
clustering and retrieval tasks, has attracted extensive attention in recent
years. A number of deep metric learning methods, which ensure that similar
examples are mapped close to each other and dissimilar examples are mapped
farther apart, have been proposed to construct effective structures for loss
functions and have shown promising results. In this paper, different from the
approaches on learning the loss structures, we propose a robust SNR distance
metric based on Signal-to-Noise Ratio (SNR) for measuring the similarity of
image pairs for deep metric learning. By exploring the properties of our SNR
distance metric from the view of geometry space and statistical theory, we
analyze the properties of our metric and show that it can preserve the semantic
similarity between image pairs, which well justify its suitability for deep
metric learning. Compared with Euclidean distance metric, our SNR distance
metric can further jointly reduce the intra-class distances and enlarge the
inter-class distances for learned features. Leveraging our SNR distance metric,
we propose Deep SNR-based Metric Learning (DSML) to generate discriminative
feature embeddings. By extensive experiments on three widely adopted
benchmarks, including CARS196, CUB200-2011 and CIFAR10, our DSML has shown its
superiority over other state-of-the-art methods. Additionally, we extend our
SNR distance metric to deep hashing learning, and conduct experiments on two
benchmarks, including CIFAR10 and NUS-WIDE, to demonstrate the effectiveness
and generality of our SNR distance metric.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        CVPR 
      
        Neural Hashing 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/ishaq2019clustered/">Clustered Hierarchical Entropy-scaling Search Of Astronomical And Biological Data</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Clustered Hierarchical Entropy-scaling Search Of Astronomical And Biological Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Clustered Hierarchical Entropy-scaling Search Of Astronomical And Biological Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ishaq Najib, Student George, Daniels Noah M.</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE International Conference on Big Data (Big Data)</td>
    <td>5</td>
    <td><p>Both astronomy and biology are experiencing explosive growth of data,
resulting in a â€œbig dataâ€ problem that stands in the way of a â€œbig dataâ€
opportunity for discovery. One common question asked of such data is that of
approximate search (\(\rho-\)nearest neighbors search). We present a hierarchical
search algorithm for such data sets that takes advantage of particular
geometric properties apparent in both astronomical and biological data sets,
namely the metric entropy and fractal dimensionality of the data. We present
CHESS (Clustered Hierarchical Entropy-Scaling Search), a search tool with
virtually no loss in specificity or sensitivity, demonstrating a \(13.6\times\)
speedup over linear search on the Sloan Digital Sky Surveyâ€™s APOGEE data set
and a \(68\times\) speedup on the GreenGenes 16S metagenomic data set, as well as
asymptotically fewer distance comparisons on APOGEE when compared to the
FALCONN locality-sensitive hashing library. CHESS demonstrates an asymptotic
complexity not directly dependent on data set size, and is in practice at least
an order of magnitude faster than linear search by performing fewer distance
comparisons. Unlike locality-sensitive hashing approaches, CHESS can work with
any user-defined distance function. CHESS also allows for implicit data
compression, which we demonstrate on the APOGEE data set. We also discuss an
extension allowing for efficient k-nearest neighbors search.</p>
</td>
    <td>
      
        Survey Paper 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/jagadeesan2019understanding/">Understanding Sparse JL For Feature Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Understanding Sparse JL For Feature Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Understanding Sparse JL For Feature Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jagadeesan Meena</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>6</td>
    <td><p>Feature hashing and other random projection schemes are commonly used to
reduce the dimensionality of feature vectors. The goal is to efficiently
project a high-dimensional feature vector living in \(\mathbb{R}^n\) into a much
lower-dimensional space \(\mathbb{R}^m\), while approximately preserving
Euclidean norm. These schemes can be constructed using sparse random
projections, for example using a sparse Johnson-Lindenstrauss (JL) transform. A
line of work introduced by Weinberger et. al (ICML â€˜09) analyzes the accuracy
of sparse JL with sparsity 1 on feature vectors with small
\(\ell_\infty\)-to-\(â„“â‚‚\) norm ratio. Recently, Freksen, Kamma, and Larsen
(NeurIPS â€˜18) closed this line of work by proving a tight tradeoff between
\(\ell_\infty\)-to-\(â„“â‚‚\) norm ratio and accuracy for sparse JL with sparsity
\(1\).
  In this paper, we demonstrate the benefits of using sparsity \(s\) greater than
\(1\) in sparse JL on feature vectors. Our main result is a tight tradeoff
between \(\ell_\infty\)-to-\(â„“â‚‚\) norm ratio and accuracy for a general
sparsity \(s\), that significantly generalizes the result of Freksen et. al. Our
result theoretically demonstrates that sparse JL with \(s &gt; 1\) can have
significantly better norm-preservation properties on feature vectors than
sparse JL with \(s = 1\); we also empirically demonstrate this finding.</p>
</td>
    <td>
      
        ICML 
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/lin2019supervised/">Supervised Online Hashing Via Similarity Distribution Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Supervised Online Hashing Via Similarity Distribution Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Supervised Online Hashing Via Similarity Distribution Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lin et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 26th ACM international conference on Multimedia</td>
    <td>47</td>
    <td><p>Online hashing has attracted extensive research attention when facing
streaming data. Most online hashing methods, learning binary codes based on
pairwise similarities of training instances, fail to capture the semantic
relationship, and suffer from a poor generalization in large-scale applications
due to large variations. In this paper, we propose to model the similarity
distributions between the input data and the hashing codes, upon which a novel
supervised online hashing method, dubbed as Similarity Distribution based
Online Hashing (SDOH), is proposed, to keep the intrinsic semantic relationship
in the produced Hamming space. Specifically, we first transform the discrete
similarity matrix into a probability matrix via a Gaussian-based normalization
to address the extremely imbalanced distribution issue. And then, we introduce
a scaling Student t-distribution to solve the challenging initialization
problem, and efficiently bridge the gap between the known and unknown
distributions. Lastly, we align the two distributions via minimizing the
Kullback-Leibler divergence (KL-diverence) with stochastic gradient descent
(SGD), by which an intuitive similarity constraint is imposed to update hashing
model on the new streaming data with a powerful generalizing ability to the
past data. Extensive experiments on three widely-used benchmarks validate the
superiority of the proposed SDOH over the state-of-the-art methods in the
online retrieval task.</p>
</td>
    <td>
      
        Compact Codes 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/liu2019mutual/">Mutual Linear Regression-based Discrete Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Mutual Linear Regression-based Discrete Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Mutual Linear Regression-based Discrete Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu Xingbo, Nie Xiushan, Yin Yilong</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 27th ACM International Conference on Multimedia</td>
    <td>17</td>
    <td><p>Label information is widely used in hashing methods because of its
effectiveness of improving the precision. The existing hashing methods always
use two different projections to represent the mutual regression between hash
codes and class labels. In contrast to the existing methods, we propose a novel
learning-based hashing method termed stable supervised discrete hashing with
mutual linear regression (S2DHMLR) in this study, where only one stable
projection is used to describe the linear correlation between hash codes and
corresponding labels. To the best of our knowledge, this strategy has not been
used for hashing previously. In addition, we further use a boosting strategy to
improve the final performance of the proposed method without adding extra
constraints and with little extra expenditure in terms of time and space.
Extensive experiments conducted on three image benchmarks demonstrate the
superior performance of the proposed method.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/zhao2019weakly/">A Weakly Supervised Adaptive Triplet Loss For Deep Metric Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Weakly Supervised Adaptive Triplet Loss For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Weakly Supervised Adaptive Triplet Loss For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhao et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)</td>
    <td>22</td>
    <td><p>We address the problem of distance metric learning in visual similarity
search, defined as learning an image embedding model which projects images into
Euclidean space where semantically and visually similar images are closer and
dissimilar images are further from one another. We present a weakly supervised
adaptive triplet loss (ATL) capable of capturing fine-grained semantic
similarity that encourages the learned image embedding models to generalize
well on cross-domain data. The method uses weakly labeled product description
data to implicitly determine fine grained semantic classes, avoiding the need
to annotate large amounts of training data. We evaluate on the Amazon fashion
retrieval benchmark and DeepFashion in-shop retrieval data. The method boosts
the performance of triplet loss baseline by 10.6% on cross-domain data and
out-performs the state-of-art model on all evaluation metrics.</p>
</td>
    <td>
      
        ICCV 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/yao2019efficient/">Efficient Discrete Supervised Hashing For Large-scale Cross-modal Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Efficient Discrete Supervised Hashing For Large-scale Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Efficient Discrete Supervised Hashing For Large-scale Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yao et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Neurocomputing</td>
    <td>29</td>
    <td><p>Supervised cross-modal hashing has gained increasing research interest on
large-scale retrieval task owning to its satisfactory performance and
efficiency. However, it still has some challenging issues to be further
studied: 1) most of them fail to well preserve the semantic correlations in
hash codes because of the large heterogenous gap; 2) most of them relax the
discrete constraint on hash codes, leading to large quantization error and
consequent low performance; 3) most of them suffer from relatively high memory
cost and computational complexity during training procedure, which makes them
unscalable. In this paper, to address above issues, we propose a supervised
cross-modal hashing method based on matrix factorization dubbed Efficient
Discrete Supervised Hashing (EDSH). Specifically, collective matrix
factorization on heterogenous features and semantic embedding with class labels
are seamlessly integrated to learn hash codes. Therefore, the feature based
similarities and semantic correlations can be both preserved in hash codes,
which makes the learned hash codes more discriminative. Then an efficient
discrete optimal algorithm is proposed to handle the scalable issue. Instead of
learning hash codes bit-by-bit, hash codes matrix can be obtained directly
which is more efficient. Extensive experimental results on three public
real-world datasets demonstrate that EDSH produces a superior performance in
both accuracy and scalability over some existing cross-modal hashing methods.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Multimodal Retrieval 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/zeng2019simultaneous/">Simultaneous Region Localization And Hash Coding For Fine-grained Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Simultaneous Region Localization And Hash Coding For Fine-grained Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Simultaneous Region Localization And Hash Coding For Fine-grained Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zeng Haien, Lai Hanjiang, Yin Jian</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>5</td>
    <td><p>Fine-grained image hashing is a challenging problem due to the difficulties
of discriminative region localization and hash code generation. Most existing
deep hashing approaches solve the two tasks independently. While these two
tasks are correlated and can reinforce each other. In this paper, we propose a
deep fine-grained hashing to simultaneously localize the discriminative regions
and generate the efficient binary codes. The proposed approach consists of a
region localization module and a hash coding module. The region localization
module aims to provide informative regions to the hash coding module. The hash
coding module aims to generate effective binary codes and give feedback for
learning better localizer. Moreover, to better capture subtle differences,
multi-scale regions at different layers are learned without the need of
bounding-box/part annotations. Extensive experiments are conducted on two
public benchmark fine-grained datasets. The results demonstrate significant
improvements in the performance of our method relative to other fine-grained
hashing algorithms.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Neural Hashing 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/zou2019transductive/">Transductive Zero-shot Hashing For Multilabel Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Transductive Zero-shot Hashing For Multilabel Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Transductive Zero-shot Hashing For Multilabel Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zou et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Neural Networks and Learning Systems</td>
    <td>14</td>
    <td><p>Hash coding has been widely used in approximate nearest neighbor search for
large-scale image retrieval. Given semantic annotations such as class labels
and pairwise similarities of the training data, hashing methods can learn and
generate effective and compact binary codes. While some newly introduced images
may contain undefined semantic labels, which we call unseen images, zeor-shot
hashing techniques have been studied. However, existing zeor-shot hashing
methods focus on the retrieval of single-label images, and cannot handle
multi-label images. In this paper, for the first time, a novel transductive
zero-shot hashing method is proposed for multi-label unseen image retrieval. In
order to predict the labels of the unseen/target data, a visual-semantic bridge
is built via instance-concept coherence ranking on the seen/source data. Then,
pairwise similarity loss and focal quantization loss are constructed for
training a hashing model using both the seen/source and unseen/target data.
Extensive evaluations on three popular multi-label datasets demonstrate that,
the proposed hashing method achieves significantly better results than the
competing methods.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/passalis2019deep/">Deep Supervised Hashing Leveraging Quadratic Spherical Mutual Information For Content-based Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Supervised Hashing Leveraging Quadratic Spherical Mutual Information For Content-based Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Supervised Hashing Leveraging Quadratic Spherical Mutual Information For Content-based Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Passalis Nikolaos, Tefas Anastasios</td> <!-- ðŸ”§ You were missing this -->
    <td>Signal Processing: Image Communication</td>
    <td>14</td>
    <td><p>Several deep supervised hashing techniques have been proposed to allow for
efficiently querying large image databases. However, deep supervised image
hashing techniques are developed, to a great extent, heuristically often
leading to suboptimal results. Contrary to this, we propose an efficient deep
supervised hashing algorithm that optimizes the learned codes using an
information-theoretic measure, the Quadratic Mutual Information (QMI). The
proposed method is adapted to the needs of large-scale hashing and information
retrieval leading to a novel information-theoretic measure, the Quadratic
Spherical Mutual Information (QSMI). Apart from demonstrating the effectiveness
of the proposed method under different scenarios and outperforming existing
state-of-the-art image hashing techniques, this paper provides a structured way
to model the process of information retrieval and develop novel methods adapted
to the needs of each application.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/shen2019embarrassingly/">Embarrassingly Simple Binary Representation Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Embarrassingly Simple Binary Representation Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Embarrassingly Simple Binary Representation Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Shen et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)</td>
    <td>20</td>
    <td><p>Recent binary representation learning models usually require sophisticated
binary optimization, similarity measure or even generative models as
auxiliaries. However, one may wonder whether these non-trivial components are
needed to formulate practical and effective hashing models. In this paper, we
answer the above question by proposing an embarrassingly simple approach to
binary representation learning. With a simple classification objective, our
model only incorporates two additional fully-connected layers onto the top of
an arbitrary backbone network, whilst complying with the binary constraints
during training. The proposed model lower-bounds the Information Bottleneck
(IB) between data samples and their semantics, and can be related to many
recent `learning to hashâ€™ paradigms. We show that, when properly designed, even
such a simple network can generate effective binary codes, by fully exploring
data semantics without any held-out alternating updating steps or auxiliary
models. Experiments are conducted on conventional large-scale benchmarks, i.e.,
CIFAR-10, NUS-WIDE, and ImageNet, where the proposed simple model outperforms
the state-of-the-art methods.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Graph Based ANN 
      
        Compact Codes 
      
        Alt 
      
        ICCV 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/harpeled2019near/">Near Neighbor: Who Is The Fairest Of Them All?</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Near Neighbor: Who Is The Fairest Of Them All?' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Near Neighbor: Who Is The Fairest Of Them All?' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Har-peled Sariel, Mahabadi Sepideh</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>8</td>
    <td><p>\(\newcommand{\ball}{\mathbb{B}}\newcommand{\dsQ}{{\mathcal{Q}}}\newcommand{\dsS}{{\mathcal{S}}}\)In
this work we study a fair variant of the near neighbor problem. Namely, given a
set of \(n\) points \(P\) and a parameter \(r\), the goal is to preprocess the
points, such that given a query point \(q\), any point in the \(r\)-neighborhood of
the query, i.e., \(\ball(q,r)\), have the same probability of being reported as
the near neighbor.
  We show that LSH based algorithms can be made fair, without a significant
loss in efficiency. Specifically, we show an algorithm that reports a point in
the \(r\)-neighborhood of a query \(q\) with almost uniform probability. The query
time is proportional to \(O\bigl( \mathrm{dns}(q.r) \dsQ(n,c) \bigr)\), and its
space is \(O(\dsS(n,c))\), where \(\dsQ(n,c)\) and \(\dsS(n,c)\) are the query time
and space of an LSH algorithm for \(c\)-approximate near neighbor, and
\(\mathrm{dns}(q,r)\) is a function of the local density around \(q\).
  Our approach works more generally for sampling uniformly from a
sub-collection of sets of a given collection and can be used in a few other
applications. Finally, we run experiments to show performance of our approach
on real data.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/song2019deep/">Deep Hashing Learning For Visual And Semantic Retrieval Of Remote Sensing Images</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Hashing Learning For Visual And Semantic Retrieval Of Remote Sensing Images' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Hashing Learning For Visual And Semantic Retrieval Of Remote Sensing Images' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Song Weiwei, Li Shutao, Benediktsson Jon Atli</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Geoscience and Remote Sensing</td>
    <td>59</td>
    <td><p>Driven by the urgent demand for managing remote sensing big data, large-scale
remote sensing image retrieval (RSIR) attracts increasing attention in the
remote sensing field. In general, existing retrieval methods can be regarded as
visual-based retrieval approaches which search and return a set of similar
images from a database to a given query image. Although retrieval methods have
achieved great success, there is still a question that needs to be responded
to: Can we obtain the accurate semantic labels of the returned similar images
to further help analyzing and processing imagery? Inspired by the above
question, in this paper, we redefine the image retrieval problem as visual and
semantic retrieval of images. Specifically, we propose a novel deep hashing
convolutional neural network (DHCNN) to simultaneously retrieve the similar
images and classify their semantic labels in a unified framework. In more
detail, a convolutional neural network (CNN) is used to extract
high-dimensional deep features. Then, a hash layer is perfectly inserted into
the network to transfer the deep features into compact hash codes. In addition,
a fully connected layer with a softmax function is performed on hash layer to
generate class distribution. Finally, a loss function is elaborately designed
to simultaneously consider the label loss of each image and similarity loss of
pairs of images. Experimental results on two remote sensing datasets
demonstrate that the proposed method achieves the state-of-art retrieval and
classification performance.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Alt 
      
        Neural Hashing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/hansen2019unsupervised/">Unsupervised Neural Generative Semantic Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Unsupervised Neural Generative Semantic Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Unsupervised Neural Generative Semantic Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Hansen et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</td>
    <td>25</td>
    <td><p>Fast similarity search is a key component in large-scale information
retrieval, where semantic hashing has become a popular strategy for
representing documents as binary hash codes. Recent advances in this area have
been obtained through neural network based models: generative models trained by
learning to reconstruct the original documents. We present a novel unsupervised
generative semantic hashing approach, \textit{Ranking based Semantic Hashing}
(RBSH) that consists of both a variational and a ranking based component.
Similarly to variational autoencoders, the variational component is trained to
reconstruct the original document conditioned on its generated hash code, and
as in prior work, it only considers documents individually. The ranking
component solves this limitation by incorporating inter-document similarity
into the hash code generation, modelling document ranking through a hinge loss.
To circumvent the need for labelled data to compute the hinge loss, we use a
weak labeller and thus keep the approach fully unsupervised.
  Extensive experimental evaluation on four publicly available datasets against
traditional baselines and recent state-of-the-art methods for semantic hashing
shows that RBSH significantly outperforms all other methods across all
evaluated hash code lengths. In fact, RBSH hash codes are able to perform
similarly to state-of-the-art hash codes while using 2-4x fewer bits.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Text Retrieval 
      
        SIGIR 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/hamann2019hamming/">Hamming Sentence Embeddings For Information Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hamming Sentence Embeddings For Information Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hamming Sentence Embeddings For Information Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Hamann Felix, Kurz Nadja, Ulges Adrian</td> <!-- ðŸ”§ You were missing this -->
    <td>2023 International Conference on Advancement in Computation &amp; Computer Technologies (InCACCT)</td>
    <td>6</td>
    <td><p>In retrieval applications, binary hashes are known to offer significant
improvements in terms of both memory and speed. We investigate the compression
of sentence embeddings using a neural encoder-decoder architecture, which is
trained by minimizing reconstruction error. Instead of employing the original
real-valued embeddings, we use latent representations in Hamming space produced
by the encoder for similarity calculations.
  In quantitative experiments on several benchmarks for semantic similarity
tasks, we show that our compressed hamming embeddings yield a comparable
performance to uncompressed embeddings (Sent2Vec, InferSent, Glove-BoW), at
compression ratios of up to 256:1. We further demonstrate that our model
strongly decorrelates input features, and that the compressor generalizes well
when pre-trained on Wikipedia sentences. We publish the source code on Github
and all experimental results.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/guo2019deep/">Deep Hashing For Signed Social Network Embedding</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Hashing For Signed Social Network Embedding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Hashing For Signed Social Network Embedding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Guo et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 2017 SIAM International Conference on Data Mining</td>
    <td>144</td>
    <td><p>Network embedding is a promising way of network representation, facilitating
many signed social network processing and analysis tasks such as link
prediction and node classification. Recently, feature hashing has been adopted
in several existing embedding algorithms to improve the efficiency, which has
obtained a great success. However, the existing feature hashing based embedding
algorithms only consider the positive links in signed social networks.
Intuitively, negative links can also help improve the performance. Thus, in
this paper, we propose a novel deep hashing method for signed social network
embedding by considering simultaneously positive and negative links. Extensive
experiments show that the proposed method performs better than several
state-of-the-art baselines through link prediction task over two real-world
signed social networks.</p>
</td>
    <td>
      
        Efficiency And Optimization 
      
        Neural Hashing 
      
        Evaluation 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/gui2019supervised/">Supervised Discrete Hashing With Relaxation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Supervised Discrete Hashing With Relaxation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Supervised Discrete Hashing With Relaxation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Gui et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Neural Networks and Learning Systems</td>
    <td>92</td>
    <td><p>Data-dependent hashing has recently attracted attention due to being able to
support efficient retrieval and storage of high-dimensional data such as
documents, images, and videos. In this paper, we propose a novel learning-based
hashing method called â€œSupervised Discrete Hashing with Relaxationâ€ (SDHR)
based on â€œSupervised Discrete Hashingâ€ (SDH). SDH uses ordinary least squares
regression and traditional zero-one matrix encoding of class label information
as the regression target (code words), thus fixing the regression target. In
SDHR, the regression target is instead optimized. The optimized regression
target matrix satisfies a large margin constraint for correct classification of
each example. Compared with SDH, which uses the traditional zero-one matrix,
SDHR utilizes the learned regression target matrix and, therefore, more
accurately measures the classification error of the regression model and is
more flexible. As expected, SDHR generally outperforms SDH. Experimental
results on two large-scale image datasets (CIFAR-10 and MNIST) and a
large-scale and challenging face dataset (FRGC) demonstrate the effectiveness
and efficiency of SDHR.</p>
</td>
    <td>
      
        DATASETS 
      
        Similarity Search 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/gui2019fast/">Fast Supervised Discrete Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fast Supervised Discrete Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fast Supervised Discrete Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Gui et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Pattern Analysis and Machine Intelligence</td>
    <td>265</td>
    <td><p>Learning-based hashing algorithms are <code class="language-plaintext highlighter-rouge">hot topics" because they can greatly
increase the scale at which existing methods operate. In this paper, we propose
a new learning-based hashing method called</code>fast supervised discrete hashingâ€
(FSDH) based on ``supervised discrete hashingâ€ (SDH). Regressing the training
examples (or hash code) to the corresponding class labels is widely used in
ordinary least squares regression. Rather than adopting this method, FSDH uses
a very simple yet effective regression of the class labels of training examples
to the corresponding hash code to accelerate the algorithm. To the best of our
knowledge, this strategy has not previously been used for hashing. Traditional
SDH decomposes the optimization into three sub-problems, with the most critical
sub-problem - discrete optimization for binary hash codes - solved using
iterative discrete cyclic coordinate descent (DCC), which is time-consuming.
However, FSDH has a closed-form solution and only requires a single rather than
iterative hash code-solving step, which is highly efficient. Furthermore, FSDH
is usually faster than SDH for solving the projection matrix for least squares
regression, making FSDH generally faster than SDH. For example, our results
show that FSDH is about 12-times faster than SDH when the number of hashing
bits is 128 on the CIFAR-10 data base, and FSDH is about 151-times faster than
FastHash when the number of hashing bits is 64 on the MNIST data-base. Our
experimental results show that FSDH is not only fast, but also outperforms
other comparative methods.</p>
</td>
    <td>
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/guo2019accelerating/">Accelerating Large-scale Inference With Anisotropic Vector Quantization</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Accelerating Large-scale Inference With Anisotropic Vector Quantization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Accelerating Large-scale Inference With Anisotropic Vector Quantization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Guo et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>91</td>
    <td><p>Quantization based techniques are the current state-of-the-art for scaling
maximum inner product search to massive databases. Traditional approaches to
quantization aim to minimize the reconstruction error of the database points.
Based on the observation that for a given query, the database points that have
the largest inner products are more relevant, we develop a family of
anisotropic quantization loss functions. Under natural statistical assumptions,
we show that quantization with these loss functions leads to a new variant of
vector quantization that more greatly penalizes the parallel component of a
datapointâ€™s residual relative to its orthogonal component. The proposed
approach achieves state-of-the-art results on the public benchmarks available
at \url{ann-benchmarks.com}.</p>
</td>
    <td>
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/wang2019fusion/">Fusion-supervised Deep Cross-modal Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fusion-supervised Deep Cross-modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fusion-supervised Deep Cross-modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE International Conference on Multimedia and Expo (ICME)</td>
    <td>15</td>
    <td><p>Deep hashing has recently received attention in cross-modal retrieval for its
impressive advantages. However, existing hashing methods for cross-modal
retrieval cannot fully capture the heterogeneous multi-modal correlation and
exploit the semantic information. In this paper, we propose a novel
<em>Fusion-supervised Deep Cross-modal Hashing</em> (FDCH) approach. Firstly,
FDCH learns unified binary codes through a fusion hash network with paired
samples as input, which effectively enhances the modeling of the correlation of
heterogeneous multi-modal data. Then, these high-quality unified hash codes
further supervise the training of the modality-specific hash networks for
encoding out-of-sample queries. Meanwhile, both pair-wise similarity
information and classification information are embedded in the hash networks
under one stream framework, which simultaneously preserves cross-modal
similarity and keeps semantic consistency. Experimental results on two
benchmark datasets demonstrate the state-of-the-art performance of FDCH.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Neural Hashing 
      
        Multimodal Retrieval 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/zhai2019learning/">Learning A Unified Embedding For Visual Search At Pinterest</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning A Unified Embedding For Visual Search At Pinterest' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning A Unified Embedding For Visual Search At Pinterest' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhai et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</td>
    <td>33</td>
    <td><p>At Pinterest, we utilize image embeddings throughout our search and
recommendation systems to help our users navigate through visual content by
powering experiences like browsing of related content and searching for exact
products for shopping. In this work we describe a multi-task deep metric
learning system to learn a single unified image embedding which can be used to
power our multiple visual search products. The solution we present not only
allows us to train for multiple application objectives in a single deep neural
network architecture, but takes advantage of correlated information in the
combination of all training data from each application to generate a unified
embedding that outperforms all specialized embeddings previously deployed for
each product. We discuss the challenges of handling images from different
domains such as camera photos, high quality web images, and clean product
catalog images. We also detail how to jointly train for multiple product
objectives and how to leverage both engagement data and human labeled data. In
addition, our trained embeddings can also be binarized for efficient storage
and retrieval without compromising precision and recall. Through comprehensive
evaluations on offline metrics, user studies, and online A/B experiments, we
demonstrate that our proposed unified embedding improves both relevance and
engagement of our visual search products for both browsing and searching
purposes when compared to existing specialized embeddings. Finally, the
deployment of the unified embedding at Pinterest has drastically reduced the
operation and engineering cost of maintaining multiple embeddings while
improving quality.</p>
</td>
    <td>
      
        KDD 
      
        Image Retrieval 
      
        Compact Codes 
      
        Recommender Systems 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/groh2019ggnn/">GGNN: Graph-based GPU Nearest Neighbor Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=GGNN: Graph-based GPU Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=GGNN: Graph-based GPU Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Groh et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Big Data</td>
    <td>33</td>
    <td><p>Approximate nearest neighbor (ANN) search in high dimensions is an integral
part of several computer vision systems and gains importance in deep learning
with explicit memory representations. Since PQT, FAISS, and SONG started to
leverage the massive parallelism offered by GPUs, GPU-based implementations are
a crucial resource for todayâ€™s state-of-the-art ANN methods. While most of
these methods allow for faster queries, less emphasis is devoted to
accelerating the construction of the underlying index structures. In this
paper, we propose a novel GPU-friendly search structure based on nearest
neighbor graphs and information propagation on graphs. Our method is designed
to take advantage of GPU architectures to accelerate the hierarchical
construction of the index structure and for performing the query. Empirical
evaluation shows that GGNN significantly surpasses the state-of-the-art CPU-
and GPU-based systems in terms of build-time, accuracy and search speed.</p>
</td>
    <td>
      
        Graph Based ANN 
      
        Quantization 
      
        Vector Indexing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/yuan2019central/">Central Similarity Quantization For Efficient Image And Video Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Central Similarity Quantization For Efficient Image And Video Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Central Similarity Quantization For Efficient Image And Video Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yuan et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>288</td>
    <td><p>Existing data-dependent hashing methods usually learn hash functions from
pairwise or triplet data relationships, which only capture the data similarity
locally, and often suffer from low learning efficiency and low collision rate.
In this work, we propose a new <em>global</em> similarity metric, termed as
<em>central similarity</em>, with which the hash codes of similar data pairs are
encouraged to approach a common center and those for dissimilar pairs to
converge to different centers, to improve hash learning efficiency and
retrieval accuracy. We principally formulate the computation of the proposed
central similarity metric by introducing a new concept, i.e., <em>hash
center</em> that refers to a set of data points scattered in the Hamming space with
a sufficient mutual distance between each other. We then provide an efficient
method to construct well separated hash centers by leveraging the Hadamard
matrix and Bernoulli distributions. Finally, we propose the Central Similarity
Quantization (CSQ) that optimizes the central similarity between data points
w.r.t.\ their hash centers instead of optimizing the local similarity. CSQ is
generic and applicable to both image and video hashing scenarios. Extensive
experiments on large-scale image and video retrieval tasks demonstrate that CSQ
can generate cohesive hash codes for similar data pairs and dispersed hash
codes for dissimilar pairs, achieving a noticeable boost in retrieval
performance, i.e. 3%-20% in mAP over the previous state-of-the-arts. The code
is at: https://github.com/yuanli2333/Hadamard-Matrix-for-hashing</p>
</td>
    <td>
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        Efficiency And Optimization 
      
        CVPR 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/green2019hashgraph/">Hashgraph -- Scalable Hash Tables Using A Sparse Graph Data Structure</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hashgraph -- Scalable Hash Tables Using A Sparse Graph Data Structure' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hashgraph -- Scalable Hash Tables Using A Sparse Graph Data Structure' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Green Oded</td> <!-- ðŸ”§ You were missing this -->
    <td>ACM Transactions on Parallel Computing</td>
    <td>13</td>
    <td><p>Hash tables are ubiquitous and used in a wide range of applications for
efficient probing of large and unsorted data. If designed properly, hash-tables
can enable efficients look ups in a constant number of operations or commonly
referred to as O(1) operations. As data sizes continue to grow and data becomes
less structured (as is common for big-data applications), the need for
efficient and scalable hash table also grows. In this paper we introduce
HashGraph, a new scalable approach for building hash tables that uses concepts
taken from sparse graph representationsâ€“hence the name HashGraph. We show two
different variants of HashGraph, a simple algorithm that outlines the method to
create the hash-table and an advanced method that creates the hash table in a
more efficient manner (with an improved memory access pattern). HashGraph shows
a new way to deal with hash-collisions that does not use â€œopen-addressingâ€ or
â€œchainingâ€, yet has all the benefits of both these approaches. HashGraph
currently works for static inputs, though recent progress with dynamic graph
data structures suggest that HashGraph might be extended to dynamic inputs as
well. We show that HashGraph can deal with a large number of hash-values per
entry without loss of performance as most open-addressing and chaining
approaches have. Further, we show that HashGraph is indifferent to the
load-factor. Lastly, we show a new probing algorithm for the second phase of
value lookups. Given the above, HashGraph is extremely fast and outperforms
several state of the art hash-table implementations. The implementation of
HashGraph in this paper is for NVIDIA GPUs, though HashGraph is not
architecture dependent. Using a NVIDIA GV100 GPU, HashGraph is anywhere from
2X-8X faster than cuDPP, WarpDrive, and cuDF. HashGraph is able to build a
hash-table at a rate of 2.5 billion keys per second and can probe at nearly the
same rate.</p>
</td>
    <td>
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/guan2019post/">Post-training 4-bit Quantization On Embedding Tables</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Post-training 4-bit Quantization On Embedding Tables' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Post-training 4-bit Quantization On Embedding Tables' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Guan et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>16</td>
    <td><p>Continuous representations have been widely adopted in recommender systems
where a large number of entities are represented using embedding vectors. As
the cardinality of the entities increases, the embedding components can easily
contain millions of parameters and become the bottleneck in both storage and
inference due to large memory consumption. This work focuses on post-training
4-bit quantization on the continuous embeddings. We propose row-wise uniform
quantization with greedy search and codebook-based quantization that
consistently outperforms state-of-the-art quantization approaches on reducing
accuracy degradation. We deploy our uniform quantization technique on a
production model in Facebook and demonstrate that it can reduce the model size
to only 13.89% of the single-precision version while the model quality stays
neutral.</p>
</td>
    <td>
      
        Recommender Systems 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/he2019one/">One Network For Multi-domains: Domain Adaptive Hashing With Intersectant Generative Adversarial Network</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=One Network For Multi-domains: Domain Adaptive Hashing With Intersectant Generative Adversarial Network' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=One Network For Multi-domains: Domain Adaptive Hashing With Intersectant Generative Adversarial Network' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>He et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence</td>
    <td>9</td>
    <td><p>With the recent explosive increase of digital data, image recognition and
retrieval become a critical practical application. Hashing is an effective
solution to this problem, due to its low storage requirement and high query
speed. However, most of past works focus on hashing in a single (source)
domain. Thus, the learned hash function may not adapt well in a new (target)
domain that has a large distributional difference with the source domain. In
this paper, we explore an end-to-end domain adaptive learning framework that
simultaneously and precisely generates discriminative hash codes and classifies
target domain images. Our method encodes two domains images into a semantic
common space, followed by two independent generative adversarial networks
arming at crosswise reconstructing two domainsâ€™ images, reducing domain
disparity and improving alignment in the shared space. We evaluate our
framework on {four} public benchmark datasets, all of which show that our
method is superior to the other state-of-the-art methods on the tasks of object
recognition and image retrieval.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        IJCAI 
      
        Robustness 
      
        Hashing Methods 
      
        Image Retrieval 
      
        Tools & Libraries 
      
        AAAI 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/nathan2019learning/">Learning Multi-dimensional Indexes</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning Multi-dimensional Indexes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning Multi-dimensional Indexes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Nathan et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data</td>
    <td>166</td>
    <td><p>Scanning and filtering over multi-dimensional tables are key operations in
modern analytical database engines. To optimize the performance of these
operations, databases often create clustered indexes over a single dimension or
multi-dimensional indexes such as R-trees, or use complex sort orders (e.g.,
Z-ordering). However, these schemes are often hard to tune and their
performance is inconsistent across different datasets and queries. In this
paper, we introduce Flood, a multi-dimensional in-memory index that
automatically adapts itself to a particular dataset and workload by jointly
optimizing the index structure and data storage. Flood achieves up to three
orders of magnitude faster performance for range scans with predicates than
state-of-the-art multi-dimensional indexes or sort orders on real-world
datasets and workloads. Our work serves as a building block towards an
end-to-end learned database system.</p>
</td>
    <td>
      
        Vector Indexing 
      
        Tools & Libraries 
      
        Evaluation 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/liu2019cross/">Cross-modal Zero-shot Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Cross-modal Zero-shot Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Cross-modal Zero-shot Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Neural Networks and Learning Systems</td>
    <td>83</td>
    <td><p>Hashing has been widely studied for big data retrieval due to its low storage
cost and fast query speed. Zero-shot hashing (ZSH) aims to learn a hashing
model that is trained using only samples from seen categories, but can
generalize well to samples of unseen categories. ZSH generally uses category
attributes to seek a semantic embedding space to transfer knowledge from seen
categories to unseen ones. As a result, it may perform poorly when labeled data
are insufficient. ZSH methods are mainly designed for single-modality data,
which prevents their application to the widely spread multi-modal data. On the
other hand, existing cross-modal hashing solutions assume that all the
modalities share the same category labels, while in practice the labels of
different data modalities may be different. To address these issues, we propose
a general Cross-modal Zero-shot Hashing (CZHash) solution to effectively
leverage unlabeled and labeled multi-modality data with different label spaces.
CZHash first quantifies the composite similarity between instances using label
and feature information. It then defines an objective function to achieve deep
feature learning compatible with the composite similarity preserving, category
attribute space learning, and hashing coding function learning. CZHash further
introduces an alternative optimization procedure to jointly optimize these
learning objectives. Experiments on benchmark multi-modal datasets show that
CZHash significantly outperforms related representative hashing approaches both
on effectiveness and adaptability.</p>
</td>
    <td>
      
        Alt 
      
        Hashing Methods 
      
        Evaluation 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/karaman2019unsupervised/">Unsupervised Rank-preserving Hashing For Large-scale Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Unsupervised Rank-preserving Hashing For Large-scale Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Unsupervised Rank-preserving Hashing For Large-scale Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Karaman et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 2019 on International Conference on Multimedia Retrieval</td>
    <td>14</td>
    <td><p>We propose an unsupervised hashing method which aims to produce binary codes
that preserve the ranking induced by a real-valued representation. Such compact
hash codes enable the complete elimination of real-valued feature storage and
allow for significant reduction of the computation complexity and storage cost
of large-scale image retrieval applications. Specifically, we learn a neural
network-based model, which transforms the input representation into a binary
representation. We formalize the training objective of the network in an
intuitive and effective way, considering each training sample as a query and
aiming to obtain the same retrieval results using the produced hash codes as
those obtained with the original features. This training formulation directly
optimizes the hashing model for the target usage of the hash codes it produces.
We further explore the addition of a decoder trained to obtain an approximated
reconstruction of the original features. At test time, we retrieved the most
promising database samples with an efficient graph-based search procedure using
only our hash codes and perform re-ranking using the reconstructed features,
thus without needing to access the original features at all. Experiments
conducted on multiple publicly available large-scale datasets show that our
method consistently outperforms all compared state-of-the-art unsupervised
hashing methods and that the reconstruction procedure can effectively boost the
search accuracy with a minimal constant additional cost.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Graph Based ANN 
      
        Compact Codes 
      
        Image Retrieval 
      
        Multimodal Retrieval 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/liu2019general/">The General Pair-based Weighting Loss For Deep Metric Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=The General Pair-based Weighting Loss For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=The General Pair-based Weighting Loss For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>550</td>
    <td><p>Deep metric learning aims at learning the distance metric between pair of
samples, through the deep neural networks to extract the semantic feature
embeddings where similar samples are close to each other while dissimilar
samples are farther apart. A large amount of loss functions based on pair
distances have been presented in the literature for guiding the training of
deep metric learning. In this paper, we unify them in a general pair-based
weighting loss function, where the minimizing objective loss is just the
distances weighting of informative pairs. The general pair-based weighting loss
includes two main aspects, (1) samples mining and (2) pairs weighting. Samples
mining aims at selecting the informative positive and negative pair sets to
exploit the structured relationship of samples in a mini-batch and also reduce
the number of non-trivial pairs. Pair weighting aims at assigning different
weights for different pairs according to the pair distances for
discriminatively training the network. We detailedly review those existing
pair-based losses inline with our general loss function, and explore some
possible methods from the perspective of samples mining and pairs weighting.
Finally, extensive experiments on three image retrieval datasets show that our
general pair-based weighting loss obtains new state-of-the-art performance,
demonstrating the effectiveness of the pair-based samples mining and pairs
weighting for deep metric learning.</p>
</td>
    <td>
      
        Survey Paper 
      
        Image Retrieval 
      
        DATASETS 
      
        Distance Metric Learning 
      
        CVPR 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/liu2019deep/">Deep Triplet Quantization</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Triplet Quantization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Triplet Quantization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 26th ACM international conference on Multimedia</td>
    <td>106</td>
    <td><p>Deep hashing establishes efficient and effective image retrieval by
end-to-end learning of deep representations and hash codes from similarity
data. We present a compact coding solution, focusing on deep learning to
quantization approach that has shown superior performance over hashing
solutions for similarity retrieval. We propose Deep Triplet Quantization (DTQ),
a novel approach to learning deep quantization models from the similarity
triplets. To enable more effective triplet training, we design a new triplet
selection approach, Group Hard, that randomly selects hard triplets in each
image group. To generate compact binary codes, we further apply a triplet
quantization with weak orthogonality during triplet training. The quantization
loss reduces the codebook redundancy and enhances the quantizability of deep
representations through back-propagation. Extensive experiments demonstrate
that DTQ can generate high-quality and compact binary codes, which yields
state-of-the-art image retrieval performance on three benchmark datasets,
NUS-WIDE, CIFAR-10, and MS-COCO.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Neural Hashing 
      
        Similarity Search 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/kang2019candidate/">Candidate Generation With Binary Codes For Large-scale Top-n Recommendation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Candidate Generation With Binary Codes For Large-scale Top-n Recommendation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Candidate Generation With Binary Codes For Large-scale Top-n Recommendation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Kang Wang-cheng, Mcauley Julian</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 28th ACM International Conference on Information and Knowledge Management</td>
    <td>53</td>
    <td><p>Generating the Top-N recommendations from a large corpus is computationally
expensive to perform at scale. Candidate generation and re-ranking based
approaches are often adopted in industrial settings to alleviate efficiency
problems. However it remains to be fully studied how well such schemes
approximate complete rankings (or how many candidates are required to achieve a
good approximation), or to develop systematic approaches to generate
high-quality candidates efficiently. In this paper, we seek to investigate
these questions via proposing a candidate generation and re-ranking based
framework (CIGAR), which first learns a preference-preserving binary embedding
for building a hash table to retrieve candidates, and then learns to re-rank
the candidates using real-valued ranking models with a candidate-oriented
objective. We perform a comprehensive study on several large-scale real-world
datasets consisting of millions of users/items and hundreds of millions of
interactions. Our results show that CIGAR significantly boosts the Top-N
accuracy against state-of-the-art recommendation models, while reducing the
query time by orders of magnitude. We hope that this work could draw more
attention to the candidate generation problem in recommender systems.</p>
</td>
    <td>
      
        CIKM 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Recommender Systems 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/liu2019optimal/">Optimal Projection Guided Transfer Hashing For Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Optimal Projection Guided Transfer Hashing For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Optimal Projection Guided Transfer Hashing For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu Ji, Zhang Lei</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Circuits and Systems for Video Technology</td>
    <td>31</td>
    <td><p>Recently, learning to hash has been widely studied for image retrieval thanks
to the computation and storage efficiency of binary codes. For most existing
learning to hash methods, sufficient training images are required and used to
learn precise hashing codes. However, in some real-world applications, there
are not always sufficient training images in the domain of interest. In
addition, some existing supervised approaches need a amount of labeled data,
which is an expensive process in term of time, label and human expertise. To
handle such problems, inspired by transfer learning, we propose a simple yet
effective unsupervised hashing method named Optimal Projection Guided Transfer
Hashing (GTH) where we borrow the images of other different but related domain
i.e., source domain to help learn precise hashing codes for the domain of
interest i.e., target domain. Besides, we propose to seek for the maximum
likelihood estimation (MLE) solution of the hashing functions of target and
source domains due to the domain gap. Furthermore,an alternating optimization
method is adopted to obtain the two projections of target and source domains
such that the domain hashing disparity is reduced gradually. Extensive
experiments on various benchmark databases verify that our method outperforms
many state-of-the-art learning to hash methods. The implementation details are
available at https://github.com/liuji93/GTH.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Alt 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/kalra2019yottixel/">Yottixel -- An Image Search Engine For Large Archives Of Histopathology Whole Slide Images</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Yottixel -- An Image Search Engine For Large Archives Of Histopathology Whole Slide Images' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Yottixel -- An Image Search Engine For Large Archives Of Histopathology Whole Slide Images' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Kalra et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Medical Image Analysis</td>
    <td>115</td>
    <td><p>With the emergence of digital pathology, searching for similar images in
large archives has gained considerable attention. Image retrieval can provide
pathologists with unprecedented access to the evidence embodied in already
diagnosed and treated cases from the past. This paper proposes a search engine
specialized for digital pathology, called Yottixel, a portmanteau for â€œone
yotta pixel,â€ alluding to the big-data nature of histopathology images. The
most impressive characteristic of Yottixel is its ability to represent whole
slide images (WSIs) in a compact manner. Yottixel can perform millions of
searches in real-time with a high search accuracy and low storage profile.
Yottixel uses an intelligent indexing algorithm capable of representing WSIs
with a mosaic of patches by converting them into a small number of methodically
extracted barcodes, called â€œBunch of Barcodesâ€ (BoB), the most prominent
performance enabler of Yottixel. The performance of the prototype platform is
qualitatively tested using 300 WSIs from the University of Pittsburgh Medical
Center (UPMC) and 2,020 WSIs from The Cancer Genome Atlas Program (TCGA)
provided by the National Cancer Institute. Both datasets amount to more than
4,000,000 patches of 1000x1000 pixels. We report three sets of experiments that
show that Yottixel can accurately retrieve organs and malignancies, and its
semantic ordering shows good agreement with the subjective evaluation of human
observers.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/liu2019weakly/">Weakly-paired Cross-modal Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Weakly-paired Cross-modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Weakly-paired Cross-modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Big Data</td>
    <td>17</td>
    <td><p>Hashing has been widely adopted for large-scale data retrieval in many
domains, due to its low storage cost and high retrieval speed. Existing
cross-modal hashing methods optimistically assume that the correspondence
between training samples across modalities are readily available. This
assumption is unrealistic in practical applications. In addition, these methods
generally require the same number of samples across different modalities, which
restricts their flexibility. We propose a flexible cross-modal hashing approach
(Flex-CMH) to learn effective hashing codes from weakly-paired data, whose
correspondence across modalities are partially (or even totally) unknown.
FlexCMH first introduces a clustering-based matching strategy to explore the
local structure of each cluster, and thus to find the potential correspondence
between clusters (and samples therein) across modalities. To reduce the impact
of an incomplete correspondence, it jointly optimizes in a unified objective
function the potential correspondence, the cross-modal hashing functions
derived from the correspondence, and a hashing quantitative loss. An
alternative optimization technique is also proposed to coordinate the
correspondence and hash functions, and to reinforce the reciprocal effects of
the two objectives. Experiments on publicly multi-modal datasets show that
FlexCMH achieves significantly better results than state-of-the-art methods,
and it indeed offers a high degree of flexibility for practical cross-modal
hashing tasks.</p>
</td>
    <td>
      
        Alt 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/liu2019query/">Query-adaptive Hash Code Ranking For Large-scale Multi-view Visual Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Query-adaptive Hash Code Ranking For Large-scale Multi-view Visual Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Query-adaptive Hash Code Ranking For Large-scale Multi-view Visual Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Image Processing</td>
    <td>74</td>
    <td><p>Hash based nearest neighbor search has become attractive in many
applications. However, the quantization in hashing usually degenerates the
discriminative power when using Hamming distance ranking. Besides, for
large-scale visual search, existing hashing methods cannot directly support the
efficient search over the data with multiple sources, and while the literature
has shown that adaptively incorporating complementary information from diverse
sources or views can significantly boost the search performance. To address the
problems, this paper proposes a novel and generic approach to building multiple
hash tables with multiple views and generating fine-grained ranking results at
bitwise and tablewise levels. For each hash table, a query-adaptive bitwise
weighting is introduced to alleviate the quantization loss by simultaneously
exploiting the quality of hash functions and their complement for nearest
neighbor search. From the tablewise aspect, multiple hash tables are built for
different data views as a joint index, over which a query-specific rank fusion
is proposed to rerank all results from the bitwise ranking by diffusing in a
graph. Comprehensive experiments on image search over three well-known
benchmarks show that the proposed method achieves up to 17.11% and 20.28%
performance gains on single and multiple table search over state-of-the-art
methods.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Quantization 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/laarhoven2019polytopes/">Polytopes, Lattices, And Spherical Codes For The Nearest Neighbor Problem</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Polytopes, Lattices, And Spherical Codes For The Nearest Neighbor Problem' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Polytopes, Lattices, And Spherical Codes For The Nearest Neighbor Problem' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Laarhoven Thijs</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Information Theory</td>
    <td>16</td>
    <td><p>We study locality-sensitive hash methods for the nearest neighbor problem for
the angular distance, focusing on the approach of first projecting down onto a
low-dimensional subspace, and then partitioning the projected vectors according
to Voronoi cells induced by a suitable spherical code. This approach
generalizes and interpolates between the fast but suboptimal hyperplane hashing
of Charikar [STOCâ€™02] and the asymptotically optimal but practically often
slower hash families of Andoni-Indyk [FOCSâ€™06], Andoni-Indyk-Nguyen-Razenshteyn
[SODAâ€™14] and Andoni-Indyk-Laarhoven-Razenshteyn-Schmidt [NIPSâ€™15]. We set up a
framework for analyzing the performance of any spherical code in this context,
and we provide results for various codes from the literature, such as those
related to regular polytopes and root lattices. Similar to hyperplane hashing,
and unlike cross-polytope hashing, our analysis of collision probabilities and
query exponents is exact and does not hide order terms which vanish only for
large \(d\), facilitating an easy parameter selection.
  For the two-dimensional case, we derive closed-form expressions for arbitrary
spherical codes, and we show that the equilateral triangle is optimal,
achieving a better performance than the two-dimensional analogues of hyperplane
and cross-polytope hashing. In three and four dimensions, we numerically find
that the tetrahedron, \(5\)-cell, and \(16\)-cell achieve the best query exponents,
while in five or more dimensions orthoplices appear to outperform regular
simplices, as well as the root lattice families \(A_k\) and \(D_k\). We argue that
in higher dimensions, larger spherical codes will likely exist which will
outperform orthoplices in theory, and we argue why using the \(D_k\) root
lattices will likely lead to better results in practice, due to a better
trade-off between the asymptotic query exponent and the concrete costs of
hashing.</p>
</td>
    <td>
      
        Tools & Libraries 
      
        Evaluation 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/junussov2019note/">Note On Distance Matrix Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Note On Distance Matrix Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Note On Distance Matrix Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Junussov I. A.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 37th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems</td>
    <td>13</td>
    <td><p>Hashing algorithm of dynamical set of distances is described. Proposed
hashing function is residual. Data structure which implementation accelerates
computations is presented</p>
</td>
    <td>
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/jin2019node2bits/">Node2bits: Compact Time- And Attribute-aware Node Representations For User Stitching</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Node2bits: Compact Time- And Attribute-aware Node Representations For User Stitching' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Node2bits: Compact Time- And Attribute-aware Node Representations For User Stitching' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jin et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>27</td>
    <td><p>Identity stitching, the task of identifying and matching various online
references (e.g., sessions over different devices and timespans) to the same
user in real-world web services, is crucial for personalization and
recommendations. However, traditional user stitching approaches, such as
grouping or blocking, require quadratic pairwise comparisons between a massive
number of user activities, thus posing both computational and storage
challenges. Recent works, which are often application-specific, heuristically
seek to reduce the amount of comparisons, but they suffer from low precision
and recall. To solve the problem in an application-independent way, we take a
heterogeneous network-based approach in which users (nodes) interact with
content (e.g., sessions, websites), and may have attributes (e.g., location).
We propose node2bits, an efficient framework that represents multi-dimensional
features of node contexts with binary hashcodes. node2bits leverages
feature-based temporal walks to encapsulate short- and long-term interactions
between nodes in heterogeneous web networks, and adopts SimHash to obtain
compact, binary representations and avoid the quadratic complexity for
similarity search. Extensive experiments on large-scale real networks show that
node2bits outperforms traditional techniques and existing works that generate
real-valued embeddings by up to 5.16% in F1 score on user stitching, while
taking only up to 1.56% as much storage.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Recommender Systems 
      
        Similarity Search 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/jin2019deep/">Deep Semantic Multimodal Hashing Network For Scalable Image-text And Video-text Retrievals</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Semantic Multimodal Hashing Network For Scalable Image-text And Video-text Retrievals' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Semantic Multimodal Hashing Network For Scalable Image-text And Video-text Retrievals' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jin Lu, Li Zechao, Tang Jinhui</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Neural Networks and Learning Systems</td>
    <td>90</td>
    <td><p>Hashing has been widely applied to multimodal retrieval on large-scale
multimedia data due to its efficiency in computation and storage. In this
article, we propose a novel deep semantic multimodal hashing network (DSMHN)
for scalable image-text and video-text retrieval. The proposed deep hashing
framework leverages 2-D convolutional neural networks (CNN) as the backbone
network to capture the spatial information for image-text retrieval, while the
3-D CNN as the backbone network to capture the spatial and temporal information
for video-text retrieval. In the DSMHN, two sets of modality-specific hash
functions are jointly learned by explicitly preserving both intermodality
similarities and intramodality semantic labels. Specifically, with the
assumption that the learned hash codes should be optimal for the classification
task, two stream networks are jointly trained to learn the hash functions by
embedding the semantic labels on the resultant hash codes. Moreover, a unified
deep multimodal hashing framework is proposed to learn compact and high-quality
hash codes by exploiting the feature representation learning, intermodality
similarity-preserving learning, semantic label-preserving learning, and hash
function learning with different types of loss functions simultaneously. The
proposed DSMHN method is a generic and scalable deep hashing framework for both
image-text and video-text retrievals, which can be flexibly integrated with
different types of loss functions. We conduct extensive experiments for both
single modal- and cross-modal-retrieval tasks on four widely used
multimodal-retrieval data sets. Experimental results on both image-text- and
video-text-retrieval tasks demonstrate that the DSMHN significantly outperforms
the state-of-the-art methods.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Text Retrieval 
      
        Neural Hashing 
      
        Multimodal Retrieval 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/jin2019ssah/">SSAH: Semi-supervised Adversarial Deep Hashing With Self-paced Hard Sample Generation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=SSAH: Semi-supervised Adversarial Deep Hashing With Self-paced Hard Sample Generation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=SSAH: Semi-supervised Adversarial Deep Hashing With Self-paced Hard Sample Generation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jin et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>28</td>
    <td><p>Deep hashing methods have been proved to be effective and efficient for
large-scale Web media search. The success of these data-driven methods largely
depends on collecting sufficient labeled data, which is usually a crucial
limitation in practical cases. The current solutions to this issue utilize
Generative Adversarial Network (GAN) to augment data in semi-supervised
learning. However, existing GAN-based methods treat image generations and
hashing learning as two isolated processes, leading to generation
ineffectiveness. Besides, most works fail to exploit the semantic information
in unlabeled data. In this paper, we propose a novel Semi-supervised Self-pace
Adversarial Hashing method, named SSAH to solve the above problems in a unified
framework. The SSAH method consists of an adversarial network (A-Net) and a
hashing network (H-Net). To improve the quality of generative images, first,
the A-Net learns hard samples with multi-scale occlusions and multi-angle
rotated deformations which compete against the learning of accurate hashing
codes. Second, we design a novel self-paced hard generation policy to gradually
increase the hashing difficulty of generated samples. To make use of the
semantic information in unlabeled ones, we propose a semi-supervised consistent
loss. The experimental results show that our method can significantly improve
state-of-the-art models on both the widely-used hashing datasets and
fine-grained datasets.</p>
</td>
    <td>
      
        AAAI 
      
        DATASETS 
      
        Hashing Methods 
      
        Neural Hashing 
      
        Tools & Libraries 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/kim2019representation/">Representation Learning With Weighted Inner Product For Universal Approximation Of General Similarities</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Representation Learning With Weighted Inner Product For Universal Approximation Of General Similarities' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Representation Learning With Weighted Inner Product For Universal Approximation Of General Similarities' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Kim et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence</td>
    <td>7</td>
    <td><p>We propose \(\textit{weighted inner product similarity}\) (WIPS) for neural
network-based graph embedding. In addition to the parameters of neural
networks, we optimize the weights of the inner product by allowing positive and
negative values. Despite its simplicity, WIPS can approximate arbitrary general
similarities including positive definite, conditionally positive definite, and
indefinite kernels. WIPS is free from similarity model selection, since it can
learn any similarity models such as cosine similarity, negative Poincar'e
distance and negative Wasserstein distance. Our experiments show that the
proposed method can learn high-quality distributed representations of nodes
from real datasets, leading to an accurate approximation of similarities as
well as high performance in inductive tasks.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        IJCAI 
      
        Distance Metric Learning 
      
        AAAI 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/liu2019ranking/">Ranking-based Deep Cross-modal Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Ranking-based Deep Cross-modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Ranking-based Deep Cross-modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>59</td>
    <td><p>Cross-modal hashing has been receiving increasing interests for its low
storage cost and fast query speed in multi-modal data retrievals. However, most
existing hashing methods are based on hand-crafted or raw level features of
objects, which may not be optimally compatible with the coding process.
Besides, these hashing methods are mainly designed to handle simple pairwise
similarity. The complex multilevel ranking semantic structure of instances
associated with multiple labels has not been well explored yet. In this paper,
we propose a ranking-based deep cross-modal hashing approach (RDCMH). RDCMH
firstly uses the feature and label information of data to derive a
semi-supervised semantic ranking list. Next, to expand the semantic
representation power of hand-crafted features, RDCMH integrates the semantic
ranking information into deep cross-modal hashing and jointly optimizes the
compatible parameters of deep feature representations and of hashing functions.
Experiments on real multi-modal datasets show that RDCMH outperforms other
competitive baselines and achieves the state-of-the-art performance in
cross-modal retrieval applications.</p>
</td>
    <td>
      
        AAAI 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Multimodal Retrieval 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/wang2019memory/">A Memory-efficient Sketch Method For Estimating High Similarities In Streaming Sets</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Memory-efficient Sketch Method For Estimating High Similarities In Streaming Sets' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Memory-efficient Sketch Method For Estimating High Similarities In Streaming Sets' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</td>
    <td>33</td>
    <td><p>Estimating set similarity and detecting highly similar sets are fundamental
problems in areas such as databases, machine learning, and information
retrieval. MinHash is a well-known technique for approximating Jaccard
similarity of sets and has been successfully used for many applications such as
similarity search and large scale learning. Its two compressed versions, b-bit
MinHash and Odd Sketch, can significantly reduce the memory usage of the
original MinHash method, especially for estimating high similarities (i.e.,
similarities around 1). Although MinHash can be applied to static sets as well
as streaming sets, of which elements are given in a streaming fashion and
cardinality is unknown or even infinite, unfortunately, b-bit MinHash and Odd
Sketch fail to deal with streaming data. To solve this problem, we design a
memory efficient sketch method, MaxLogHash, to accurately estimate Jaccard
similarities in streaming sets. Compared to MinHash, our method uses smaller
sized registers (each register consists of less than 7 bits) to build a compact
sketch for each set. We also provide a simple yet accurate estimator for
inferring Jaccard similarity from MaxLogHash sketches. In addition, we derive
formulas for bounding the estimation error and determine the smallest necessary
memory usage (i.e., the number of registers used for a MaxLogHash sketch) for
the desired accuracy. We conduct experiments on a variety of datasets, and
experimental results show that our method MaxLogHash is about 5 times more
memory efficient than MinHash with the same accuracy and computational cost for
estimating high similarities.</p>
</td>
    <td>
      
        KDD 
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Alt 
      
        Similarity Search 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/lin2019hadamard/">Hadamard Matrix Guided Online Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hadamard Matrix Guided Online Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hadamard Matrix Guided Online Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lin et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>International Journal of Computer Vision</td>
    <td>41</td>
    <td><p>Online image hashing has attracted increasing research attention recently,
which receives large-scale data in a streaming manner to update the hash
functions on-the-fly. Its key challenge lies in the difficulty of balancing the
learning timeliness and model accuracy. To this end, most works follow a
supervised setting, i.e., using class labels to boost the hashing performance,
which defects in two aspects: First, strong constraints, e.g., orthogonal or
similarity preserving, are used, which however are typically relaxed and lead
to large accuracy drop. Second, large amounts of training batches are required
to learn the up-to-date hash functions, which largely increase the learning
complexity. To handle the above challenges, a novel supervised online hashing
scheme termed Hadamard Matrix Guided Online Hashing (HMOH) is proposed in this
paper. Our key innovation lies in introducing Hadamard matrix, which is an
orthogonal binary matrix built via Sylvester method. In particular, to release
the need of strong constraints, we regard each column of Hadamard matrix as the
target code for each class label, which by nature satisfies several desired
properties of hashing codes. To accelerate the online training, LSH is first
adopted to align the lengths of target code and to-be-learned binary code. We
then treat the learning of hash functions as a set of binary classification
problems to fit the assigned target code. Finally, extensive experiments
demonstrate the superior accuracy and efficiency of the proposed method over
various state-of-the-art methods. Codes are available at
https://github.com/lmbxmu/mycode.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/wang2019ranked/">Ranked List Loss For Deep Metric Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Ranked List Loss For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Ranked List Loss For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>231</td>
    <td><p>The objective of deep metric learning (DML) is to learn embeddings that can
capture semantic similarity and dissimilarity information among data points.
Existing pairwise or tripletwise loss functions used in DML are known to suffer
from slow convergence due to a large proportion of trivial pairs or triplets as
the model improves. To improve this, ranking-motivated structured losses are
proposed recently to incorporate multiple examples and exploit the structured
information among them. They converge faster and achieve state-of-the-art
performance. In this work, we unveil two limitations of existing
ranking-motivated structured losses and propose a novel ranked list loss to
solve both of them. First, given a query, only a fraction of data points is
incorporated to build the similarity structure. Consequently, some useful
examples are ignored and the structure is less informative. To address this, we
propose to build a set-based similarity structure by exploiting all instances
in the gallery. The learning setting can be interpreted as few-shot retrieval:
given a mini-batch, every example is iteratively used as a query, and the rest
ones compose the gallery to search, i.e., the support set in few-shot setting.
The rest examples are split into a positive set and a negative set. For every
mini-batch, the learning objective of ranked list loss is to make the query
closer to the positive set than to the negative set by a margin. Second,
previous methods aim to pull positive pairs as close as possible in the
embedding space. As a result, the intraclass data distribution tends to be
extremely compressed. In contrast, we propose to learn a hypersphere for each
class in order to preserve useful similarity structure inside it, which
functions as regularisation. Extensive experiments demonstrate the superiority
of our proposal by comparing with the state-of-the-art methods.</p>
</td>
    <td>
      
        CVPR 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/liu2019compositional/">Compositional Coding For Collaborative Filtering</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Compositional Coding For Collaborative Filtering' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Compositional Coding For Collaborative Filtering' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</td>
    <td>15</td>
    <td><p>Efficiency is crucial to the online recommender systems. Representing users
and items as binary vectors for Collaborative Filtering (CF) can achieve fast
user-item affinity computation in the Hamming space, in recent years, we have
witnessed an emerging research effort in exploiting binary hashing techniques
for CF methods. However, CF with binary codes naturally suffers from low
accuracy due to limited representation capability in each bit, which impedes it
from modeling complex structure of the data.
  In this work, we attempt to improve the efficiency without hurting the model
performance by utilizing both the accuracy of real-valued vectors and the
efficiency of binary codes to represent users/items. In particular, we propose
the Compositional Coding for Collaborative Filtering (CCCF) framework, which
not only gains better recommendation efficiency than the state-of-the-art
binarized CF approaches but also achieves even higher accuracy than the
real-valued CF method. Specifically, CCCF innovatively represents each
user/item with a set of binary vectors, which are associated with a sparse
real-value weight vector. Each value of the weight vector encodes the
importance of the corresponding binary vector to the user/item. The continuous
weight vectors greatly enhances the representation capability of binary codes,
and its sparsity guarantees the processing speed. Furthermore, an integer
weight approximation scheme is proposed to further accelerate the speed. Based
on the CCCF framework, we design an efficient discrete optimization algorithm
to learn its parameters. Extensive experiments on three real-world datasets
show that our method outperforms the state-of-the-art binarized CF methods
(even achieves better performance than the real-valued CF method) by a large
margin in terms of both recommendation accuracy and efficiency.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Recommender Systems 
      
        SIGIR 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/morozov2019unsupervised/">Unsupervised Neural Quantization For Compressed-domain Similarity Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Unsupervised Neural Quantization For Compressed-domain Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Unsupervised Neural Quantization For Compressed-domain Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Morozov Stanislav, Babenko Artem</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE/CVF International Conference on Computer Vision (ICCV)</td>
    <td>21</td>
    <td><p>We tackle the problem of unsupervised visual descriptors compression, which
is a key ingredient of large-scale image retrieval systems. While the deep
learning machinery has benefited literally all computer vision pipelines, the
existing state-of-the-art compression methods employ shallow architectures, and
we aim to close this gap by our paper. In more detail, we introduce a DNN
architecture for the unsupervised compressed-domain retrieval, based on
multi-codebook quantization. The proposed architecture is designed to
incorporate both fast data encoding and efficient distances computation via
lookup tables. We demonstrate the exceptional advantage of our scheme over
existing quantization approaches on several datasets of visual descriptors via
outperforming the previous state-of-the-art by a large margin.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        ICCV 
      
        Similarity Search 
      
        Quantization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/weng2019online/">Online Hashing With Efficient Updating Of Binary Codes</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Online Hashing With Efficient Updating Of Binary Codes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Online Hashing With Efficient Updating Of Binary Codes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Weng Zhenyu, Zhu Yuesheng</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>15</td>
    <td><p>Online hashing methods are efficient in learning the hash functions from the
streaming data. However, when the hash functions change, the binary codes for
the database have to be recomputed to guarantee the retrieval accuracy.
Recomputing the binary codes by accumulating the whole database brings a
timeliness challenge to the online retrieval process. In this paper, we propose
a novel online hashing framework to update the binary codes efficiently without
accumulating the whole database. In our framework, the hash functions are fixed
and the projection functions are introduced to learn online from the streaming
data. Therefore, inefficient updating of the binary codes by accumulating the
whole database can be transformed to efficient updating of the binary codes by
projecting the binary codes into another binary space. The queries and the
binary code database are projected asymmetrically to further improve the
retrieval accuracy. The experiments on two multi-label image databases
demonstrate the effectiveness and the efficiency of our method for multi-label
image retrieval.</p>
</td>
    <td>
      
        Image Retrieval 
      
        AAAI 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/fan2019unsupervised/">Unsupervised Co-learning On \(\mathcal{g}\)-manifolds Across Irreducible Representations</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Unsupervised Co-learning On \(\mathcal{g}\)-manifolds Across Irreducible Representations' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Unsupervised Co-learning On \(\mathcal{g}\)-manifolds Across Irreducible Representations' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Fan Yifeng, Gao Tingran, Zhao Zhizhen</td> <!-- ðŸ”§ You were missing this -->
    <td>Communications in Mathematical Physics</td>
    <td>25</td>
    <td><p>We introduce a novel co-learning paradigm for manifolds naturally equipped
with a group action, motivated by recent developments on learning a manifold
from attached fibre bundle structures. We utilize a representation theoretic
mechanism that canonically associates multiple independent vector bundles over
a common base manifold, which provides multiple views for the geometry of the
underlying manifold. The consistency across these fibre bundles provide a
common base for performing unsupervised manifold co-learning through the
redundancy created artificially across irreducible representations of the
transformation group. We demonstrate the efficacy of the proposed algorithmic
paradigm through drastically improved robust nearest neighbor search and
community detection on rotation-invariant cryo-electron microscopy image
analysis.</p>
</td>
    <td>
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/sankar2019transferable/">Transferable Neural Projection Representations</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Transferable Neural Projection Representations' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Transferable Neural Projection Representations' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Sankar Chinnadhurai, Ravi Sujith, Kozareva Zornitsa</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 2019 Conference of the North</td>
    <td>7</td>
    <td><p>Neural word representations are at the core of many state-of-the-art natural
language processing models. A widely used approach is to pre-train, store and
look up word or character embedding matrices. While useful, such
representations occupy huge memory making it hard to deploy on-device and often
do not generalize to unknown words due to vocabulary pruning.
  In this paper, we propose a skip-gram based architecture coupled with
Locality-Sensitive Hashing (LSH) projections to learn efficient dynamically
computable representations. Our model does not need to store lookup tables as
representations are computed on-the-fly and require low memory footprint. The
representations can be trained in an unsupervised fashion and can be easily
transferred to other NLP tasks. For qualitative evaluation, we analyze the
nearest neighbors of the word representations and discover semantically similar
words even with misspellings. For quantitative evaluation, we plug our
transferable projections into a simple LSTM and run it on multiple NLP tasks
and show how our transferable projections achieve better performance compared
to prior work.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/ertl2019probminhash/">Probminhash -- A Class Of Locality-sensitive Hash Algorithms For The (probability) Jaccard Similarity</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Probminhash -- A Class Of Locality-sensitive Hash Algorithms For The (probability) Jaccard Similarity' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Probminhash -- A Class Of Locality-sensitive Hash Algorithms For The (probability) Jaccard Similarity' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ertl Otmar</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Knowledge and Data Engineering</td>
    <td>23</td>
    <td><p>The probability Jaccard similarity was recently proposed as a natural
generalization of the Jaccard similarity to measure the proximity of sets whose
elements are associated with relative frequencies or probabilities. In
combination with a hash algorithm that maps those weighted sets to compact
signatures which allow fast estimation of pairwise similarities, it constitutes
a valuable method for big data applications such as near-duplicate detection,
nearest neighbor search, or clustering. This paper introduces a class of
one-pass locality-sensitive hash algorithms that are orders of magnitude faster
than the original approach. The performance gain is achieved by calculating
signature components not independently, but collectively. Four different
algorithms are proposed based on this idea. Two of them are statistically
equivalent to the original approach and can be used as drop-in replacements.
The other two may even improve the estimation error by introducing statistical
dependence between signature components. Moreover, the presented techniques can
be specialized for the conventional Jaccard similarity, resulting in highly
efficient algorithms that outperform traditional minwise hashing and that are
able to compete with the state of the art.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/xu2019hashing/">Hashing Based Answer Selection</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hashing Based Answer Selection' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hashing Based Answer Selection' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Xu Dong, Li Wu-jun</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>8</td>
    <td><p>Answer selection is an important subtask of question answering (QA), where
deep models usually achieve better performance. Most deep models adopt
question-answer interaction mechanisms, such as attention, to get vector
representations for answers. When these interaction based deep models are
deployed for online prediction, the representations of all answers need to be
recalculated for each question. This procedure is time-consuming for deep
models with complex encoders like BERT which usually have better accuracy than
simple encoders. One possible solution is to store the matrix representation
(encoder output) of each answer in memory to avoid recalculation. But this will
bring large memory cost. In this paper, we propose a novel method, called
hashing based answer selection (HAS), to tackle this problem. HAS adopts a
hashing strategy to learn a binary matrix representation for each answer, which
can dramatically reduce the memory cost for storing the matrix representations
of answers. Hence, HAS can adopt complex encoders like BERT in the model, but
the online prediction of HAS is still fast with a low memory cost. Experimental
results on three popular answer selection datasets show that HAS can outperform
existing models to achieve state-of-the-art performance.</p>
</td>
    <td>
      
        AAAI 
      
        DATASETS 
      
        Hashing Methods 
      
        Graph Based ANN 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/eghbali2019deep/">Deep Spherical Quantization For Image Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Spherical Quantization For Image Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Spherical Quantization For Image Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Eghbali Sepehr, Tahvildari Ladan</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>27</td>
    <td><p>Hashing methods, which encode high-dimensional images with compact discrete
codes, have been widely applied to enhance large-scale image retrieval. In this
paper, we put forward Deep Spherical Quantization (DSQ), a novel method to make
deep convolutional neural networks generate supervised and compact binary codes
for efficient image search. Our approach simultaneously learns a mapping that
transforms the input images into a low-dimensional discriminative space, and
quantizes the transformed data points using multi-codebook quantization. To
eliminate the negative effect of norm variance on codebook learning, we force
the network to L_2 normalize the extracted features and then quantize the
resulting vectors using a new supervised quantization technique specifically
designed for points lying on a unit hypersphere. Furthermore, we introduce an
easy-to-implement extension of our quantization technique that enforces
sparsity on the codebooks. Extensive experiments demonstrate that DSQ and its
sparse variant can generate semantically separable compact binary codes
outperforming many state-of-the-art image retrieval methods on three
benchmarks.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        CVPR 
      
        Compact Codes 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/efremenko2019fast/">Fast And Bayes-consistent Nearest Neighbors</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fast And Bayes-consistent Nearest Neighbors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fast And Bayes-consistent Nearest Neighbors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Efremenko Klim, Kontorovich Aryeh, Noivirt Moshe</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>9</td>
    <td><p>Research on nearest-neighbor methods tends to focus somewhat dichotomously
either on the statistical or the computational aspects â€“ either on, say, Bayes
consistency and rates of convergence or on techniques for speeding up the
proximity search. This paper aims at bridging these realms: to reap the
advantages of fast evaluation time while maintaining Bayes consistency, and
further without sacrificing too much in the risk decay rate. We combine the
locality-sensitive hashing (LSH) technique with a novel missing-mass argument
to obtain a fast and Bayes-consistent classifier. Our algorithmâ€™s prediction
runtime compares favorably against state of the art approximate NN methods,
while maintaining Bayes-consistency and attaining rates comparable to minimax.
On samples of size \(n\) in \(\R^d\), our pre-processing phase has runtime \(O(d n
log n)\), while the evaluation phase has runtime \(O(dlog n)\) per query point.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/dutta2019probabilistic/">A Probabilistic Approach For Learning Embeddings Without Supervision</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Probabilistic Approach For Learning Embeddings Without Supervision' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Probabilistic Approach For Learning Embeddings Without Supervision' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Dutta Ujjal Kr, Harandi Mehrtash, Chellu Chandra Sekhar</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 2019 Conference of the North</td>
    <td>5</td>
    <td><p>For challenging machine learning problems such as zero-shot learning and
fine-grained categorization, embedding learning is the machinery of choice
because of its ability to learn generic notions of similarity, as opposed to
class-specific concepts in standard classification models. Embedding learning
aims at learning discriminative representations of data such that similar
examples are pulled closer, while pushing away dissimilar ones. Despite their
exemplary performances, supervised embedding learning approaches require huge
number of annotations for training. This restricts their applicability for
large datasets in new applications where obtaining labels require extensive
manual efforts and domain knowledge. In this paper, we propose to learn an
embedding in a completely unsupervised manner without using any class labels.
Using a graph-based clustering approach to obtain pseudo-labels, we form
triplet-based constraints following a metric learning paradigm. Our novel
embedding learning approach uses a probabilistic notion, that intuitively
minimizes the chances of each triplet violating a geometric constraint. Due to
nature of the search space, we learn the parameters of our approach using
Riemannian geometry. Our proposed approach performs competitive to
state-of-the-art approaches.</p>
</td>
    <td>
      
        Graph Based ANN 
      
        DATASETS 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/elezi2019group/">The Group Loss For Deep Metric Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=The Group Loss For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=The Group Loss For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Elezi et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>48</td>
    <td><p>Deep metric learning has yielded impressive results in tasks such as
clustering and image retrieval by leveraging neural networks to obtain highly
discriminative feature embeddings, which can be used to group samples into
different classes. Much research has been devoted to the design of smart loss
functions or data mining strategies for training such networks. Most methods
consider only pairs or triplets of samples within a mini-batch to compute the
loss function, which is commonly based on the distance between embeddings. We
propose Group Loss, a loss function based on a differentiable label-propagation
method that enforces embedding similarity across all samples of a group while
promoting, at the same time, low-density regions amongst data points belonging
to different groups. Guided by the smoothness assumption that â€œsimilar objects
should belong to the same groupâ€, the proposed loss trains the neural network
for a classification task, enforcing a consistent labelling amongst samples
within a class. We show state-of-the-art results on clustering and image
retrieval on several datasets, and show the potential of our method when
combined with other techniques such as ensembles</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/ducau2019automatic/">Automatic Malware Description Via Attribute Tagging And Similarity Embedding</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Automatic Malware Description Via Attribute Tagging And Similarity Embedding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Automatic Malware Description Via Attribute Tagging And Similarity Embedding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ducau et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>11</td>
    <td><p>With the rapid proliferation and increased sophistication of malicious
software (malware), detection methods no longer rely only on manually generated
signatures but have also incorporated more general approaches like machine
learning detection. Although powerful for conviction of malicious artifacts,
these methods do not produce any further information about the type of threat
that has been detected neither allows for identifying relationships between
malware samples. In this work, we address the information gap between machine
learning and signature-based detection methods by learning a representation
space for malware samples in which files with similar malicious behaviors
appear close to each other. We do so by introducing a deep learning based
tagging model trained to generate human-interpretable semantic descriptions of
malicious software, which, at the same time provides potentially more useful
and flexible information than malware family names.
  We show that the malware descriptions generated with the proposed approach
correctly identify more than 95% of eleven possible tag descriptions for a
given sample, at a deployable false positive rate of 1% per tag. Furthermore,
we use the learned representation space to introduce a similarity index between
malware files, and empirically demonstrate using dynamic traces from filesâ€™
execution, that is not only more effective at identifying samples from the same
families, but also 32 times smaller than those based on raw feature vectors.</p>
</td>
    <td>
      
        Alt 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/wang2019supervised/">Supervised Quantization For Similarity Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Supervised Quantization For Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Supervised Quantization For Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>82</td>
    <td><p>In this paper, we address the problem of searching for semantically similar
images from a large database. We present a compact coding approach, supervised
quantization. Our approach simultaneously learns feature selection that
linearly transforms the database points into a low-dimensional discriminative
subspace, and quantizes the data points in the transformed space. The
optimization criterion is that the quantized points not only approximate the
transformed points accurately, but also are semantically separable: the points
belonging to a class lie in a cluster that is not overlapped with other
clusters corresponding to other classes, which is formulated as a
classification problem. The experiments on several standard datasets show the
superiority of our approach over the state-of-the art supervised hashing and
unsupervised quantization algorithms.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        CVPR 
      
        Similarity Search 
      
        Quantization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/dourado2019fusion/">Fusion Vectors: Embedding Graph Fusions For Efficient Unsupervised Rank Aggregation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fusion Vectors: Embedding Graph Fusions For Efficient Unsupervised Rank Aggregation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fusion Vectors: Embedding Graph Fusions For Efficient Unsupervised Rank Aggregation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Dourado Icaro Cavalcante, Torres Ricardo da Silva</td> <!-- ðŸ”§ You were missing this -->
    <td>Information Processing &amp; Management</td>
    <td>13</td>
    <td><p>The vast increase in amount and complexity of digital content led to a wide
interest in ad-hoc retrieval systems in recent years. Complementary, the
existence of heterogeneous data sources and retrieval models stimulated the
proliferation of increasingly ingenious and effective rank aggregation
functions. Although recently proposed rank aggregation functions are promising
with respect to effectiveness, existing proposals in the area usually overlook
efficiency aspects. We propose an innovative rank aggregation function that is
unsupervised, intrinsically multimodal, and targeted for fast retrieval and top
effectiveness performance. We introduce the concepts of embedding and indexing
of graph-based rank-aggregation representation models, and their application
for search tasks. Embedding formulations are also proposed for graph-based rank
representations. We introduce the concept of fusion vectors, a late-fusion
representation of objects based on ranks, from which an intrinsically
rank-aggregation retrieval model is defined. Next, we present an approach for
fast retrieval based on fusion vectors, thus promoting an efficient rank
aggregation system. Our method presents top effectiveness performance among
state-of-the-art related work, while bringing novel aspects of multimodality
and effectiveness. Consistent speedups are achieved against the recent
baselines in all datasets considered.</p>
</td>
    <td>
      
        DATASETS 
      
        Graph Based ANN 
      
        Efficiency And Optimization 
      
        Alt 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/dong2019learning/">Learning Space Partitions For Nearest Neighbor Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning Space Partitions For Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning Space Partitions For Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Dong et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>26</td>
    <td><p>Space partitions of \(\mathbb{R}^d\) underlie a vast and important class of
fast nearest neighbor search (NNS) algorithms. Inspired by recent theoretical
work on NNS for general metric spaces [Andoni, Naor, Nikolov, Razenshteyn,
Waingarten STOC 2018, FOCS 2018], we develop a new framework for building space
partitions reducing the problem to balanced graph partitioning followed by
supervised classification. We instantiate this general approach with the KaHIP
graph partitioner [Sanders, Schulz SEA 2013] and neural networks, respectively,
to obtain a new partitioning procedure called Neural Locality-Sensitive Hashing
(Neural LSH). On several standard benchmarks for NNS, our experiments show that
the partitions obtained by Neural LSH consistently outperform partitions found
by quantization-based and tree-based methods as well as classic, data-oblivious
LSH.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Quantization 
      
        Tree Based ANN 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/dong2019document/">Document Hashing With Mixture-prior Generative Models</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Document Hashing With Mixture-prior Generative Models' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Document Hashing With Mixture-prior Generative Models' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Dong et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</td>
    <td>19</td>
    <td><p>Hashing is promising for large-scale information retrieval tasks thanks to
the efficiency of distance evaluation between binary codes. Generative hashing
is often used to generate hashing codes in an unsupervised way. However,
existing generative hashing methods only considered the use of simple priors,
like Gaussian and Bernoulli priors, which limits these methods to further
improve their performance. In this paper, two mixture-prior generative models
are proposed, under the objective to produce high-quality hashing codes for
documents. Specifically, a Gaussian mixture prior is first imposed onto the
variational auto-encoder (VAE), followed by a separate step to cast the
continuous latent representation of VAE into binary code. To avoid the
performance loss caused by the separate casting, a model using a Bernoulli
mixture prior is further developed, in which an end-to-end training is admitted
by resorting to the straight-through (ST) discrete gradient estimator.
Experimental results on several benchmark datasets demonstrate that the
proposed methods, especially the one using Bernoulli mixture priors,
consistently outperform existing ones by a substantial margin.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        EMNLP 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/do2019simultaneous/">Simultaneous Feature Aggregating And Hashing For Compact Binary Code Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Simultaneous Feature Aggregating And Hashing For Compact Binary Code Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Simultaneous Feature Aggregating And Hashing For Compact Binary Code Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Do et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Image Processing</td>
    <td>14</td>
    <td><p>Representing images by compact hash codes is an attractive approach for
large-scale content-based image retrieval. In most state-of-the-art
hashing-based image retrieval systems, for each image, local descriptors are
first aggregated as a global representation vector. This global vector is then
subjected to a hashing function to generate a binary hash code. In previous
works, the aggregating and the hashing processes are designed independently.
Hence these frameworks may generate suboptimal hash codes. In this paper, we
first propose a novel unsupervised hashing framework in which feature
aggregating and hashing are designed simultaneously and optimized jointly.
Specifically, our joint optimization generates aggregated representations that
can be better reconstructed by some binary codes. This leads to more
discriminative binary hash codes and improved retrieval accuracy. In addition,
the proposed method is flexible. It can be extended for supervised hashing.
When the data label is available, the framework can be adapted to learn binary
codes which minimize the reconstruction loss w.r.t. label vectors. Furthermore,
we also propose a fast version of the state-of-the-art hashing method Binary
Autoencoder to be used in our proposed frameworks. Extensive experiments on
benchmark datasets under various settings show that the proposed methods
outperform state-of-the-art unsupervised and supervised hashing methods.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/ding2019bilinear/">Bilinear Supervised Hashing Based On 2D Image Features</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Bilinear Supervised Hashing Based On 2D Image Features' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Bilinear Supervised Hashing Based On 2D Image Features' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ding et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Circuits and Systems for Video Technology</td>
    <td>14</td>
    <td><p>Hashing has been recognized as an efficient representation learning method to
effectively handle big data due to its low computational complexity and memory
cost. Most of the existing hashing methods focus on learning the
low-dimensional vectorized binary features based on the high-dimensional raw
vectorized features. However, studies on how to obtain preferable binary codes
from the original 2D image features for retrieval is very limited. This paper
proposes a bilinear supervised discrete hashing (BSDH) method based on 2D image
features which utilizes bilinear projections to binarize the image matrix
features such that the intrinsic characteristics in the 2D image space are
preserved in the learned binary codes. Meanwhile, the bilinear projection
approximation and vectorization binary codes regression are seamlessly
integrated together to formulate the final robust learning framework.
Furthermore, a discrete optimization strategy is developed to alternatively
update each variable for obtaining the high-quality binary codes. In addition,
two 2D image features, traditional SURF-based FVLAD feature and CNN-based
AlexConv5 feature are designed for further improving the performance of the
proposed BSDH method. Results of extensive experiments conducted on four
benchmark datasets show that the proposed BSDH method almost outperforms all
competing hashing methods with different input features by different evaluation
protocols.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Alt 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/taheri2019similarity/">Similarity-based Android Malware Detection Using Hamming Distance Of Static Binary Features</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Similarity-based Android Malware Detection Using Hamming Distance Of Static Binary Features' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Similarity-based Android Malware Detection Using Hamming Distance Of Static Binary Features' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Taheri et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Future Generation Computer Systems</td>
    <td>192</td>
    <td><p>In this paper, we develop four malware detection methods using Hamming
distance to find similarity between samples which are first nearest neighbors
(FNN), all nearest neighbors (ANN), weighted all nearest neighbors (WANN), and
k-medoid based nearest neighbors (KMNN). In our proposed methods, we can
trigger the alarm if we detect an Android app is malicious. Hence, our
solutions help us to avoid the spread of detected malware on a broader scale.
We provide a detailed description of the proposed detection methods and related
algorithms. We include an extensive analysis to asses the suitability of our
proposed similarity-based detection methods. In this way, we perform our
experiments on three datasets, including benign and malware Android apps like
Drebin, Contagio, and Genome. Thus, to corroborate the actual effectiveness of
our classifier, we carry out performance comparisons with some state-of-the-art
classification and malware detection algorithms, namely Mixed and Separated
solutions, the program dissimilarity measure based on entropy (PDME) and the
FalDroid algorithms. We test our experiments in a different type of features:
API, intent, and permission features on these three datasets. The results
confirm that accuracy rates of proposed algorithms are more than 90% and in
some cases (i.e., considering API features) are more than 99%, and are
comparable with existing state-of-the-art solutions.</p>
</td>
    <td>
      
        DATASETS 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/deng2019triplet/">Triplet-based Deep Hashing Network For Cross-modal Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Triplet-based Deep Hashing Network For Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Triplet-based Deep Hashing Network For Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Deng et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Image Processing</td>
    <td>376</td>
    <td><p>Given the benefits of its low storage requirements and high retrieval
efficiency, hashing has recently received increasing attention. In
particular,cross-modal hashing has been widely and successfully used in
multimedia similarity search applications. However, almost all existing methods
employing cross-modal hashing cannot obtain powerful hash codes due to their
ignoring the relative similarity between heterogeneous data that contains
richer semantic information, leading to unsatisfactory retrieval performance.
In this paper, we propose a triplet-based deep hashing (TDH) network for
cross-modal retrieval. First, we utilize the triplet labels, which describes
the relative relationships among three instances as supervision in order to
capture more general semantic correlations between cross-modal instances. We
then establish a loss function from the inter-modal view and the intra-modal
view to boost the discriminative abilities of the hash codes. Finally, graph
regularization is introduced into our proposed TDH method to preserve the
original semantic similarity between hash codes in Hamming space. Experimental
results show that our proposed method outperforms several state-of-the-art
approaches on two popular cross-modal datasets.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Neural Hashing 
      
        Multimodal Retrieval 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/dalins2019pdq/">PDQ & TMK + PDQF -- A Test Drive Of Facebook's Perceptual Hashing Algorithms</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=PDQ & TMK + PDQF -- A Test Drive Of Facebook's Perceptual Hashing Algorithms' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=PDQ & TMK + PDQF -- A Test Drive Of Facebook's Perceptual Hashing Algorithms' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Dalins Janis, Wilson Campbell, Boudry Douglas</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>5</td>
    <td><p>Efficient and reliable automated detection of modified image and multimedia
files has long been a challenge for law enforcement, compounded by the harm
caused by repeated exposure to psychologically harmful materials. In August
2019 Facebook open-sourced their PDQ and TMK + PDQF algorithms for image and
video similarity measurement, respectively. In this report, we review the
algorithmsâ€™ performance on detecting commonly encountered transformations on
real-world case data, sourced from contemporary investigations. We also provide
a reference implementation to demonstrate the potential application and
integration of such algorithms within existing law enforcement systems.</p>
</td>
    <td>
      
        Survey Paper 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/ma2019hierarchy/">Hierarchy Neighborhood Discriminative Hashing For An Unified View Of Single-label And Multi-label Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hierarchy Neighborhood Discriminative Hashing For An Unified View Of Single-label And Multi-label Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hierarchy Neighborhood Discriminative Hashing For An Unified View Of Single-label And Multi-label Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ma et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence</td>
    <td>22</td>
    <td><p>Recently, deep supervised hashing methods have become popular for large-scale
image retrieval task. To preserve the semantic similarity notion between
examples, they typically utilize the pairwise supervision or the triplet
supervised information for hash learning. However, these methods usually ignore
the semantic class information which can help the improvement of the semantic
discriminative ability of hash codes. In this paper, we propose a novel
hierarchy neighborhood discriminative hashing method. Specifically, we
construct a bipartite graph to build coarse semantic neighbourhood relationship
between the sub-class feature centers and the embeddings features. Moreover, we
utilize the pairwise supervised information to construct the fined semantic
neighbourhood relationship between embeddings features. Finally, we propose a
hierarchy neighborhood discriminative hashing loss to unify the single-label
and multilabel image retrieval problem with a one-stream deep neural network
architecture. Experimental results on two largescale datasets demonstrate that
the proposed method can outperform the state-of-the-art hashing methods.</p>
</td>
    <td>
      
        DATASETS 
      
        IJCAI 
      
        Hashing Methods 
      
        Image Retrieval 
      
        AAAI 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/wang2019fpscreen/">Fpscreen: A Rapid Similarity Search Tool For Massive Molecular Library Based On Molecular Fingerprint Comparison</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fpscreen: A Rapid Similarity Search Tool For Massive Molecular Library Based On Molecular Fingerprint Comparison' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fpscreen: A Rapid Similarity Search Tool For Massive Molecular Library Based On Molecular Fingerprint Comparison' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Methods</td>
    <td>647</td>
    <td><p>We designed a fast similarity search engine for large molecular libraries:
FPScreen. We downloaded 100 million moleculesâ€™ structure files in PubChem with
SDF extension, then applied a computational chemistry tool RDKit to convert
each structure file into one line of text in MACCS format and stored them in a
text file as our molecule library. The similarity search engine compares the
similarity while traversing the 166-bit strings in the library file line by
line. FPScreen can complete similarity search through 100 million entries in
our molecule library within one hour. That is very fast as a biology
computation tool. Additionally, we divided our library into several strides for
parallel processing. FPScreen was developed in WEB mode.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Similarity Search 
      
        Tools & Libraries 
      
        EMNLP 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/coleman2019sub/">Sub-linear Memory Sketches For Near Neighbor Search On Streaming Data</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Sub-linear Memory Sketches For Near Neighbor Search On Streaming Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Sub-linear Memory Sketches For Near Neighbor Search On Streaming Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Coleman Benjamin, Baraniuk Richard G., Shrivastava Anshumali</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of The Web Conference 2020</td>
    <td>11</td>
    <td><p>We present the first sublinear memory sketch that can be queried to find the
nearest neighbors in a dataset. Our online sketching algorithm compresses an N
element dataset to a sketch of size \(O(N^b log^3 N)\) in \(O(N^{(b+1)} log^3
N)\) time, where \(b &lt; 1\). This sketch can correctly report the nearest neighbors
of any query that satisfies a stability condition parameterized by \(b\). We
achieve sublinear memory performance on stable queries by combining recent
advances in locality sensitive hash (LSH)-based estimators, online kernel
density estimation, and compressed sensing. Our theoretical results shed new
light on the memory-accuracy tradeoff for nearest neighbor search, and our
sketch, which consists entirely of short integer arrays, has a variety of
attractive features in practice. We evaluate the memory-recall tradeoff of our
method on a friend recommendation task in the Google Plus social media network.
We obtain orders of magnitude better compression than the random projection
based alternative while retaining the ability to report the nearest neighbors
of practical queries.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Recommender Systems 
      
        Alt 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/zhang2019collaborative/">Collaborative Quantization For Cross-modal Similarity Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Collaborative Quantization For Cross-modal Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Collaborative Quantization For Cross-modal Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang Ting, Wang Jingdong</td> <!-- ðŸ”§ You were missing this -->
    <td>2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>62</td>
    <td><p>Cross-modal similarity search is a problem about designing a search system
supporting querying across content modalities, e.g., using an image to search
for texts or using a text to search for images. This paper presents a compact
coding solution for efficient search, with a focus on the quantization approach
which has already shown the superior performance over the hashing solutions in
the single-modal similarity search. We propose a cross-modal quantization
approach, which is among the early attempts to introduce quantization into
cross-modal search. The major contribution lies in jointly learning the
quantizers for both modalities through aligning the quantized representations
for each pair of image and text belonging to a document. In addition, our
approach simultaneously learns the common space for both modalities in which
quantization is conducted to enable efficient and effective search using the
Euclidean distance computed in the common space with fast distance table
lookup. Experimental results compared with several competitive algorithms over
three benchmark datasets demonstrate that the proposed approach achieves the
state-of-the-art performance.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        CVPR 
      
        Similarity Search 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/zhang2019pairwise/">Pairwise Teacher-student Network For Semi-supervised Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Pairwise Teacher-student Network For Semi-supervised Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Pairwise Teacher-student Network For Semi-supervised Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang Shifeng, Li Jianmin, Zhang Bo</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</td>
    <td>7</td>
    <td><p>Hashing method maps similar high-dimensional data to binary hashcodes with
smaller hamming distance, and it has received broad attention due to its low
storage cost and fast retrieval speed. Pairwise similarity is easily obtained
and widely used for retrieval, and most supervised hashing algorithms are
carefully designed for the pairwise supervisions. As labeling all data pairs is
difficult, semi-supervised hashing is proposed which aims at learning efficient
codes with limited labeled pairs and abundant unlabeled ones. Existing methods
build graphs to capture the structure of dataset, but they are not working well
for complex data as the graph is built based on the data representations and
determining the representations of complex data is difficult. In this paper, we
propose a novel teacher-student semi-supervised hashing framework in which the
student is trained with the pairwise information produced by the teacher
network. The network follows the smoothness assumption, which achieves
consistent distances for similar data pairs so that the retrieval results are
similar for neighborhood queries. Experiments on large-scale datasets show that
the proposed method reaches impressive gain over the supervised baselines and
is superior to state-of-the-art semi-supervised hashing methods.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        CVPR 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/wang2019cross/">Cross-batch Memory For Embedding Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Cross-batch Memory For Embedding Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Cross-batch Memory For Embedding Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>228</td>
    <td><p>Mining informative negative instances are of central importance to deep
metric learning (DML), however this task is intrinsically limited by mini-batch
training, where only a mini-batch of instances is accessible at each iteration.
In this paper, we identify a â€œslow driftâ€ phenomena by observing that the
embedding features drift exceptionally slow even as the model parameters are
updating throughout the training process. This suggests that the features of
instances computed at preceding iterations can be used to considerably
approximate their features extracted by the current model. We propose a
cross-batch memory (XBM) mechanism that memorizes the embeddings of past
iterations, allowing the model to collect sufficient hard negative pairs across
multiple mini-batches - even over the whole dataset. Our XBM can be directly
integrated into a general pair-based DML framework, where the XBM augmented DML
can boost performance considerably. In particular, without bells and whistles,
a simple contrastive loss with our XBM can have large R@1 improvements of
12%-22.5% on three large-scale image retrieval datasets, surpassing the most
sophisticated state-of-the-art methods, by a large margin. Our XBM is
conceptually simple, easy to implement - using several lines of codes, and is
memory efficient - with a negligible 0.2 GB extra GPU memory. Code is available
at: https://github.com/MalongTech/research-xbm.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Distance Metric Learning 
      
        CVPR 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/zhang2019sadih/">SADIH: Semantic-aware Discrete Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=SADIH: Semantic-aware Discrete Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=SADIH: Semantic-aware Discrete Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>17</td>
    <td><p>Due to its low storage cost and fast query speed, hashing has been recognized
to accomplish similarity search in large-scale multimedia retrieval
applications. Particularly supervised hashing has recently received
considerable research attention by leveraging the label information to preserve
the pairwise similarities of data points in the Hamming space. However, there
still remain two crucial bottlenecks: 1) the learning process of the full
pairwise similarity preservation is computationally unaffordable and unscalable
to deal with big data; 2) the available category information of data are not
well-explored to learn discriminative hash functions. To overcome these
challenges, we propose a unified Semantic-Aware DIscrete Hashing (SADIH)
framework, which aims to directly embed the transformed semantic information
into the asymmetric similarity approximation and discriminative hashing
function learning. Specifically, a semantic-aware latent embedding is
introduced to asymmetrically preserve the full pairwise similarities while
skillfully handle the cumbersome n times n pairwise similarity matrix.
Meanwhile, a semantic-aware autoencoder is developed to jointly preserve the
data structures in the discriminative latent semantic space and perform data
reconstruction. Moreover, an efficient alternating optimization algorithm is
proposed to solve the resulting discrete optimization problem. Extensive
experimental results on multiple large-scale datasets demonstrate that our
SADIH can clearly outperform the state-of-the-art baselines with the additional
benefit of lower computational costs.</p>
</td>
    <td>
      
        AAAI 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Alt 
      
        Similarity Search 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/talreja2019learning/">Learning To Authenticate With Deep Multibiometric Hashing And Neural Network Decoding</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning To Authenticate With Deep Multibiometric Hashing And Neural Network Decoding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning To Authenticate With Deep Multibiometric Hashing And Neural Network Decoding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Talreja et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>ICC 2019 - 2019 IEEE International Conference on Communications (ICC)</td>
    <td>19</td>
    <td><p>In this paper, we propose a novel multimodal deep hashing neural decoder
(MDHND) architecture, which integrates a deep hashing framework with a neural
network decoder (NND) to create an effective multibiometric authentication
system. The MDHND consists of two separate modules: a multimodal deep hashing
(MDH) module, which is used for feature-level fusion and binarization of
multiple biometrics, and a neural network decoder (NND) module, which is used
to refine the intermediate binary codes generated by the MDH and compensate for
the difference between enrollment and probe biometrics (variations in pose,
illumination, etc.). Use of NND helps to improve the performance of the overall
multimodal authentication system. The MDHND framework is trained in 3 steps
using joint optimization of the two modules. In Step 1, the MDH parameters are
trained and learned to generate a shared multimodal latent code; in Step 2, the
latent codes from Step 1 are passed through a conventional error-correcting
code (ECC) decoder to generate the ground truth to train a neural network
decoder (NND); in Step 3, the NND decoder is trained using the ground truth
from Step 2 and the MDH and NND are jointly optimized. Experimental results on
a standard multimodal dataset demonstrate the superiority of our method
relative to other current multimodal authentication systems</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Neural Hashing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/talreja2019zero/">Zero-shot Deep Hashing And Neural Network Based Error Correction For Face Template Protection</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Zero-shot Deep Hashing And Neural Network Based Error Correction For Face Template Protection' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Zero-shot Deep Hashing And Neural Network Based Error Correction For Face Template Protection' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Talreja Veeru, Valenti Matthew C., Nasrabadi Nasser M.</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE 10th International Conference on Biometrics Theory, Applications and Systems (BTAS)</td>
    <td>20</td>
    <td><p>In this paper, we present a novel architecture that integrates a deep hashing
framework with a neural network decoder (NND) for application to face template
protection. It improves upon existing face template protection techniques to
provide better matching performance with one-shot and multi-shot enrollment. A
key novelty of our proposed architecture is that the framework can also be used
with zero-shot enrollment. This implies that our architecture does not need to
be re-trained even if a new subject is to be enrolled into the system. The
proposed architecture consists of two major components: a deep hashing (DH)
component, which is used for robust mapping of face images to their
corresponding intermediate binary codes, and a NND component, which corrects
errors in the intermediate binary codes that are caused by differences in the
enrollment and probe biometrics due to factors such as variation in pose,
illumination, and other factors. The final binary code generated by the NND is
then cryptographically hashed and stored as a secure face template in the
database. The efficacy of our approach with zero-shot, one-shot, and multi-shot
enrollments is shown for CMU-PIE, Extended Yale B, WVU multimodal and Multi-PIE
face databases. With zero-shot enrollment, the system achieves approximately
85% genuine accept rates (GAR) at 0.01% false accept rate (FAR), and with
one-shot and multi-shot enrollments, it achieves approximately 99.95% GAR at
0.01% FAR, while providing a high level of template security.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Compact Codes 
      
        Neural Hashing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/chen2019locality/">Locality-sensitive Hashing For F-divergences: Mutual Information Loss And Beyond</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Locality-sensitive Hashing For F-divergences: Mutual Information Loss And Beyond' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Locality-sensitive Hashing For F-divergences: Mutual Information Loss And Beyond' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Chen et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the Twenty-Fifth Annual ACM-SIAM Symposium on Discrete Algorithms</td>
    <td>62</td>
    <td><p>Computing approximate nearest neighbors in high dimensional spaces is a
central problem in large-scale data mining with a wide range of applications in
machine learning and data science. A popular and effective technique in
computing nearest neighbors approximately is the locality-sensitive hashing
(LSH) scheme. In this paper, we aim to develop LSH schemes for distance
functions that measure the distance between two probability distributions,
particularly for f-divergences as well as a generalization to capture mutual
information loss. First, we provide a general framework to design LHS schemes
for f-divergence distance functions and develop LSH schemes for the generalized
Jensen-Shannon divergence and triangular discrimination in this framework. We
show a two-sided approximation result for approximation of the generalized
Jensen-Shannon divergence by the Hellinger distance, which may be of
independent interest. Next, we show a general method of reducing the problem of
designing an LSH scheme for a Krein kernel (which can be expressed as the
difference of two positive definite kernels) to the problem of maximum inner
product search. We exemplify this method by applying it to the mutual
information loss, due to its several important applications such as model
compression.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Tools & Libraries 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/chen2019hadamard/">Hadamard Codebook Based Deep Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hadamard Codebook Based Deep Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hadamard Codebook Based Deep Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Chen et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 26th ACM international conference on Multimedia</td>
    <td>47</td>
    <td><p>As an approximate nearest neighbor search technique, hashing has been widely
applied in large-scale image retrieval due to its excellent efficiency. Most
supervised deep hashing methods have similar loss designs with embedding
learning, while quantizing the continuous high-dim feature into compact binary
space. We argue that the existing deep hashing schemes are defective in two
issues that seriously affect the performance, i.e., bit independence and bit
balance. The former refers to hash codes of different classes should be
independent of each other, while the latter means each bit should have a
balanced distribution of +1s and -1s. In this paper, we propose a novel
supervised deep hashing method, termed Hadamard Codebook based Deep Hashing
(HCDH), which solves the above two problems in a unified formulation.
Specifically, we utilize an off-the-shelf algorithm to generate a binary
Hadamard codebook to satisfy the requirement of bit independence and bit
balance, which subsequently serves as the desired outputs of the hash functions
learning. We also introduce a projection matrix to solve the inconsistency
between the order of Hadamard matrix and the number of classes. Besides, the
proposed HCDH further exploits the supervised labels by constructing a
classifier on top of the outputs of hash functions. Extensive experiments
demonstrate that HCDH can yield discriminative and balanced binary codes, which
well outperforms many state-of-the-arts on three widely-used benchmarks.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Neural Hashing 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/chen2019vector/">Vector And Line Quantization For Billion-scale Similarity Search On Gpus</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Vector And Line Quantization For Billion-scale Similarity Search On Gpus' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Vector And Line Quantization For Billion-scale Similarity Search On Gpus' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Chen et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Future Generation Computer Systems</td>
    <td>7</td>
    <td><p>Billion-scale high-dimensional approximate nearest neighbour (ANN) search has
become an important problem for searching similar objects among the vast amount
of images and videos available online. The existing ANN methods are usually
characterized by their specific indexing structures, including the inverted
index and the inverted multi-index structure. The inverted index structure is
amenable to GPU-based implementations, and the state-of-the-art systems such as
Faiss are able to exploit the massive parallelism offered by GPUs. However, the
inverted index requires high memory overhead to index the dataset effectively.
The inverted multi-index structure is difficult to implement for GPUs, and also
ineffective in dealing with database with different data distributions. In this
paper we propose a novel hierarchical inverted index structure generated by
vector and line quantization methods. Our quantization method improves both
search efficiency and accuracy, while maintaining comparable memory
consumption. This is achieved by reducing search space and increasing the
number of indexed regions. We introduce a new ANN search system, VLQ-ADC, that
is based on the proposed inverted index, and perform extensive evaluation on
two public billion-scale benchmark datasets SIFT1B and DEEP1B. Our evaluation
shows that VLQ-ADC significantly outperforms the state-of-the-art GPU- and
CPU-based systems in terms of both accuracy and search speed. The source code
of VLQ-ADC is available at
https://github.com/zjuchenwei/vector-line-quantization.</p>
</td>
    <td>
      
        DATASETS 
      
        Efficiency And Optimization 
      
        Large Scale Search 
      
        Similarity Search 
      
        Quantization 
      
        Vector Indexing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/luo2019snap/">Snap And Find: Deep Discrete Cross-domain Garment Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Snap And Find: Deep Discrete Cross-domain Garment Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Snap And Find: Deep Discrete Cross-domain Garment Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Luo et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Neurocomputing</td>
    <td>37</td>
    <td><p>With the increasing number of online stores, there is a pressing need for
intelligent search systems to understand the item photos snapped by customers
and search against large-scale product databases to find their desired items.
However, it is challenging for conventional retrieval systems to match up the
item photos captured by customers and the ones officially released by stores,
especially for garment images. To bridge the customer- and store- provided
garment photos, existing studies have been widely exploiting the clothing
attributes (\textit{e.g.,} black) and landmarks (\textit{e.g.,} collar) to
learn a common embedding space for garment representations. Unfortunately they
omit the sequential correlation of attributes and consume large quantity of
human labors to label the landmarks. In this paper, we propose a deep
multi-task cross-domain hashing termed \textit{DMCH}, in which cross-domain
embedding and sequential attribute learning are modeled simultaneously.
Sequential attribute learning not only provides the semantic guidance for
embedding, but also generates rich attention on discriminative local details
(\textit{e.g.,} black buttons) of clothing items without requiring extra
landmark labels. This leads to promising performance and 306\(\times\) boost on
efficiency when compared with the state-of-the-art models, which is
demonstrated through rigorous experiments on two public fashion datasets.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/chehreghani2019unsupervised/">Unsupervised Representation Learning With Minimax Distance Measures</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Unsupervised Representation Learning With Minimax Distance Measures' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Unsupervised Representation Learning With Minimax Distance Measures' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Chehreghani Morteza Haghir</td> <!-- ðŸ”§ You were missing this -->
    <td>Machine Learning</td>
    <td>14</td>
    <td><p>We investigate the use of Minimax distances to extract in a nonparametric way
the features that capture the unknown underlying patterns and structures in the
data. We develop a general-purpose and computationally efficient framework to
employ Minimax distances with many machine learning methods that perform on
numerical data. We study both computing the pairwise Minimax distances for all
pairs of objects and as well as computing the Minimax distances of all the
objects to/from a fixed (test) object. We first efficiently compute the
pairwise Minimax distances between the objects, using the equivalence of
Minimax distances over a graph and over a minimum spanning tree constructed on
that. Then, we perform an embedding of the pairwise Minimax distances into a
new vector space, such that their squared Euclidean distances in the new space
equal to the pairwise Minimax distances in the original space. We also study
the case of having multiple pairwise Minimax matrices, instead of a single one.
Thereby, we propose an embedding via first summing up the centered matrices and
then performing an eigenvalue decomposition to obtain the relevant features. In
the following, we study computing Minimax distances from a fixed (test) object
which can be used for instance in K-nearest neighbor search. Similar to the
case of all-pair pairwise Minimax distances, we develop an efficient and
general-purpose algorithm that is applicable with any arbitrary base distance
measure. Moreover, we investigate in detail the edges selected by the Minimax
distances and thereby explore the ability of Minimax distances in detecting
outlier objects. Finally, for each setting, we perform several experiments to
demonstrate the effectiveness of our framework.</p>
</td>
    <td>
      
        ICML 
      
        Tools & Libraries 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/chen2019differentiable/">Differentiable Product Quantization For End-to-end Embedding Compression</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Differentiable Product Quantization For End-to-end Embedding Compression' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Differentiable Product Quantization For End-to-end Embedding Compression' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Chen Ting, Li Lala, Sun Yizhou</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>13</td>
    <td><p>Embedding layers are commonly used to map discrete symbols into continuous
embedding vectors that reflect their semantic meanings. Despite their
effectiveness, the number of parameters in an embedding layer increases
linearly with the number of symbols and poses a critical challenge on memory
and storage constraints. In this work, we propose a generic and end-to-end
learnable compression framework termed differentiable product quantization
(DPQ). We present two instantiations of DPQ that leverage different
approximation techniques to enable differentiability in end-to-end learning.
Our method can readily serve as a drop-in alternative for any existing
embedding layer. Empirically, DPQ offers significant compression ratios
(14-238\(\times\)) at negligible or no performance cost on 10 datasets across
three different language tasks.</p>
</td>
    <td>
      
        DATASETS 
      
        Alt 
      
        Quantization 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/wang2019multi/">Multi-similarity Loss With General Pair Weighting For Deep Metric Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Multi-similarity Loss With General Pair Weighting For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Multi-similarity Loss With General Pair Weighting For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>736</td>
    <td><p>A family of loss functions built on pair-based computation have been proposed
in the literature which provide a myriad of solutions for deep metric learning.
In this paper, we provide a general weighting framework for understanding
recent pair-based loss functions. Our contributions are three-fold: (1) we
establish a General Pair Weighting (GPW) framework, which casts the sampling
problem of deep metric learning into a unified view of pair weighting through
gradient analysis, providing a powerful tool for understanding recent
pair-based loss functions; (2) we show that with GPW, various existing
pair-based methods can be compared and discussed comprehensively, with clear
differences and key limitations identified; (3) we propose a new loss called
multi-similarity loss (MS loss) under the GPW, which is implemented in two
iterative steps (i.e., mining and weighting). This allows it to fully consider
three similarities for pair weighting, providing a more principled approach for
collecting and weighting informative pairs. Finally, the proposed MS loss
obtains new state-of-the-art performance on four image retrieval benchmarks,
where it outperforms the most recent approaches, such as
ABE\cite{Kim_2018_ECCV} and HTL by a large margin: 60.6% to 65.7% on CUB200,
and 80.9% to 88.0% on In-Shop Clothes Retrieval dataset at Recall@1. Code is
available at https://github.com/MalongTech/research-ms-loss.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Distance Metric Learning 
      
        CVPR 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/sivertsen2019similarity/">Similarity Problems In High Dimensions</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Similarity Problems In High Dimensions' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Similarity Problems In High Dimensions' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Sivertsen Johan von Tangen</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>7</td>
    <td><p>The main contribution of this dissertation is the introduction of new or
improved approximation algorithms and data structures for several similarity
search problems. We examine the furthest neighbor query, the annulus query,
distance sensitive membership, nearest neighbor preserving embeddings and set
similarity queries in the large-scale, high-dimensional setting.</p>
</td>
    <td>
      
        AAAI 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/um2019active/">Active Search For Nearest Neighbors</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Active Search For Nearest Neighbors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Active Search For Nearest Neighbors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Um Hayoung, Choi Heeyoul</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>13</td>
    <td><p>In pattern recognition or machine learning, it is a very fundamental task to
find nearest neighbors of a given point. All the methods for the task work
basically by comparing the given point to all the points in the data set. That
is why the computational cost increases with the number of data points.
However, the human visual system seems to work in a different way. When the
human visual system tries to find the neighbors of one point on a map, it
directly focuses on the area around the point and actively searches the
neighbors by looking or zooming in and out around the point. In this paper, we
propose an innovative search method for nearest neighbors, which seems very
similar to how human visual system works on the task.</p>
</td>
    <td>
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/cerda2019encoding/">Encoding High-cardinality String Categorical Variables</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Encoding High-cardinality String Categorical Variables' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Encoding High-cardinality String Categorical Variables' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Cerda Patricio Parietal, Varoquaux GaÃ«l Neurospin</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Knowledge and Data Engineering</td>
    <td>24</td>
    <td><p>Statistical models usually require vector representations of categorical
variables, using for instance one-hot encoding. This strategy breaks down when
the number of categories grows, as it creates high-dimensional feature vectors.
Additionally, for string entries, one-hot encoding does not capture information
in their representation.Here, we seek low-dimensional encoding of
high-cardinality string categorical variables. Ideally, these should be:
scalable to many categories; interpretable to end users; and facilitate
statistical analysis. We introduce two encoding approaches for string
categories: a Gamma-Poisson matrix factorization on substring counts, and the
min-hash encoder, for fast approximation of string similarities. We show that
min-hash turns set inclusions into inequality relations that are easier to
learn. Both approaches are scalable and streamable. Experiments on real and
simulated data show that these methods improve supervised learning with
high-cardinality categorical variables. We recommend the following: if
scalability is central, the min-hash encoder is the best option as it does not
require any data fit; if interpretability is important, the Gamma-Poisson
factorization is the best alternative, as it can be interpreted as one-hot
encoding on inferred categories with informative feature names. Both models
enable autoML on the original string entries as they remove the need for
feature engineering or data cleaning.</p>
</td>
    <td>
      
        Alt 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/zhang2019generic/">Generic Intent Representation In Web Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Generic Intent Representation In Web Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Generic Intent Representation In Web Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</td>
    <td>33</td>
    <td><p>This paper presents GEneric iNtent Encoder (GEN Encoder) which learns a
distributed representation space for user intent in search. Leveraging large
scale user clicks from Bing search logs as weak supervision of user intent, GEN
Encoder learns to map queries with shared clicks into similar embeddings
end-to-end and then finetunes on multiple paraphrase tasks. Experimental
results on an intrinsic evaluation task - query intent similarity modeling -
demonstrate GEN Encoderâ€™s robust and significant advantages over previous
representation methods. Ablation studies reveal the crucial role of learning
from implicit user feedback in representing user intent and the contributions
of multi-task learning in representation generality. We also demonstrate that
GEN Encoder alleviates the sparsity of tail search traffic and cuts down half
of the unseen queries by using an efficient approximate nearest neighbor search
to effectively identify previous queries with the same search intent. Finally,
we demonstrate distances between GEN encodings reflect certain information
seeking behaviors in search sessions.</p>
</td>
    <td>
      
        SIGIR 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/chakraborty2019conlsh/">Conlsh: Context Based Locality Sensitive Hashing For Mapping Of Noisy SMRT Reads</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Conlsh: Context Based Locality Sensitive Hashing For Mapping Of Noisy SMRT Reads' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Conlsh: Context Based Locality Sensitive Hashing For Mapping Of Noisy SMRT Reads' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Chakraborty Angana, Bandyopadhyay Sanghamitra</td> <!-- ðŸ”§ You were missing this -->
    <td>Computational Biology and Chemistry</td>
    <td>13</td>
    <td><p>Single Molecule Real-Time (SMRT) sequencing is a recent advancement of Next
Gen technology developed by Pacific Bio (PacBio). It comes with an explosion of
long and noisy reads demanding cutting edge research to get most out of it. To
deal with the high error probability of SMRT data, a novel contextual Locality
Sensitive Hashing (conLSH) based algorithm is proposed in this article, which
can effectively align the noisy SMRT reads to the reference genome. Here,
sequences are hashed together based not only on their closeness, but also on
similarity of context. The algorithm has \(\mathcal{O}(n^{\rho+1})\) space
requirement, where \(n\) is the number of sequences in the corpus and \(\rho\) is a
constant. The indexing time and querying time are bounded by \(\mathcal{O}(
\frac{n^{\rho+1} \cdot \ln n}{\ln \frac{1}{P_2}})\) and \(\mathcal{O}(n^\rho)\)
respectively, where \(P_2 &gt; 0\), is a probability value. This algorithm is
particularly useful for retrieving similar sequences, a widely used task in
biology. The proposed conLSH based aligner is compared with rHAT, popularly
used for aligning SMRT reads, and is found to comprehensively beat it in speed
as well as in memory requirements. In particular, it takes approximately
\(24.2%\) less processing time, while saving about \(70.3%\) in peak memory
requirement for H.sapiens PacBio dataset.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/cao2019unsupervised/">Unsupervised Deep Metric Learning Via Auxiliary Rotation Loss</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Unsupervised Deep Metric Learning Via Auxiliary Rotation Loss' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Unsupervised Deep Metric Learning Via Auxiliary Rotation Loss' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Cao Xuefei, Chen Bor-chun, Lim Ser-nam</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>12</td>
    <td><p>Deep metric learning is an important area due to its applicability to many
domains such as image retrieval and person re-identification. The main drawback
of such models is the necessity for labeled data. In this work, we propose to
generate pseudo-labels for deep metric learning directly from clustering
assignment and we introduce unsupervised deep metric learning (UDML)
regularized by a self-supervision (SS) task. In particular, we propose to
regularize the training process by predicting image rotations. Our method
(UDML-SS) jointly learns discriminative embeddings, unsupervised clustering
assignments of the embeddings, as well as a self-supervised pretext task.
UDML-SS iteratively cluster embeddings using traditional clustering algorithm
(e.g., k-means), and sampling training pairs based on the cluster assignment
for metric learning, while optimizing self-supervised pretext task in a
multi-task fashion. The role of self-supervision is to stabilize the training
process and encourages the model to learn meaningful feature representations
that are not distorted due to unreliable clustering assignments. The proposed
method performs well on standard benchmarks for metric learning, where it
outperforms current state-of-the-art approaches by a large margin and it also
shows competitive performance with various metric learning loss functions.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/cao2019enhancing/">Enhancing Remote Sensing Image Retrieval With Triplet Deep Metric Learning Network</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Enhancing Remote Sensing Image Retrieval With Triplet Deep Metric Learning Network' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Enhancing Remote Sensing Image Retrieval With Triplet Deep Metric Learning Network' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Cao et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>International Journal of Remote Sensing</td>
    <td>94</td>
    <td><p>With the rapid growing of remotely sensed imagery data, there is a high
demand for effective and efficient image retrieval tools to manage and exploit
such data. In this letter, we present a novel content-based remote sensing
image retrieval method based on Triplet deep metric learning convolutional
neural network (CNN). By constructing a Triplet network with metric learning
objective function, we extract the representative features of the images in a
semantic space in which images from the same class are close to each other
while those from different classes are far apart. In such a semantic space,
simple metric measures such as Euclidean distance can be used directly to
compare the similarity of images and effectively retrieve images of the same
class. We also investigate a supervised and an unsupervised learning methods
for reducing the dimensionality of the learned semantic features. We present
comprehensive experimental results on two publicly available remote sensing
image retrieval datasets and show that our method significantly outperforms
state-of-the-art.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Tools & Libraries 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/bingmann2019cobs/">COBS: A Compact Bit-sliced Signature Index</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=COBS: A Compact Bit-sliced Signature Index' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=COBS: A Compact Bit-sliced Signature Index' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Bingmann et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>67</td>
    <td><p>We present COBS, a COmpact Bit-sliced Signature index, which is a cross-over
between an inverted index and Bloom filters. Our target application is to index
\(k\)-mers of DNA samples or \(q\)-grams from text documents and process
approximate pattern matching queries on the corpus with a user-chosen coverage
threshold. Query results may contain a number of false positives which
decreases exponentially with the query length. We compare COBS to seven other
index software packages on 100000 microbial DNA samples. COBSâ€™ compact but
simple data structure outperforms the other indexes in construction time and
query performance with Mantis by Pandey et al. in second place. However, unlike
Mantis and other previous work, COBS does not need the complete index in RAM
and is thus designed to scale to larger document sets.</p>
</td>
    <td>
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/magliani2019efficient/">An Efficient Approximate Knn Graph Method For Diffusion On Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=An Efficient Approximate Knn Graph Method For Diffusion On Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=An Efficient Approximate Knn Graph Method For Diffusion On Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Magliani et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>8</td>
    <td><p>The application of the diffusion in many computer vision and artificial
intelligence projects has been shown to give excellent improvements in
performance. One of the main bottlenecks of this technique is the quadratic
growth of the kNN graph size due to the high-quantity of new connections
between nodes in the graph, resulting in long computation times. Several
strategies have been proposed to address this, but none are effective and
efficient. Our novel technique, based on LSH projections, obtains the same
performance as the exact kNN graph after diffusion, but in less time
(approximately 18 times faster on a dataset of a hundred thousand images). The
proposed method was validated and compared with other state-of-the-art on
several public image datasets, including Oxford5k, Paris6k, and Oxford105k.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Locality Sensitive Hashing 
      
        Evaluation 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/markchit2019effective/">Effective And Efficient Indexing In Cross-modal Hashing-based Datasets</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Effective And Efficient Indexing In Cross-modal Hashing-based Datasets' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Effective And Efficient Indexing In Cross-modal Hashing-based Datasets' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Markchit Sarawut, Chiu Chih-yi</td> <!-- ðŸ”§ You were missing this -->
    <td>Signal Processing: Image Communication</td>
    <td>6</td>
    <td><p>To overcome the barrier of storage and computation, the hashing technique has
been widely used for nearest neighbor search in multimedia retrieval
applications recently. Particularly, cross-modal retrieval that searches across
different modalities becomes an active but challenging problem. Although dozens
of cross-modal hashing algorithms are proposed to yield compact binary codes,
the exhaustive search is impractical for the real-time purpose, and Hamming
distance computation suffers inaccurate results. In this paper, we propose a
novel search method that utilizes a probability-based index scheme over binary
hash codes in cross-modal retrieval. The proposed hash code indexing scheme
exploits a few binary bits of the hash code as the index code. We construct an
inverted index table based on index codes and train a neural network to improve
the indexing accuracy and efficiency. Experiments are performed on two
benchmark datasets for retrieval across image and text modalities, where hash
codes are generated by three cross-modal hashing methods. Results show the
proposed method effectively boost the performance on these hash methods.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Alt 
      
        Multimodal Retrieval 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/beck2019distributed/">A Distributed And Approximated Nearest Neighbors Algorithm For An Efficient Large Scale Mean Shift Clustering</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Distributed And Approximated Nearest Neighbors Algorithm For An Efficient Large Scale Mean Shift Clustering' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Distributed And Approximated Nearest Neighbors Algorithm For An Efficient Large Scale Mean Shift Clustering' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Beck et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Journal of Parallel and Distributed Computing</td>
    <td>29</td>
    <td><p>In this paper we target the class of modal clustering methods where clusters
are defined in terms of the local modes of the probability density function
which generates the data. The most well-known modal clustering method is the
k-means clustering. Mean Shift clustering is a generalization of the k-means
clustering which computes arbitrarily shaped clusters as defined as the basins
of attraction to the local modes created by the density gradient ascent paths.
Despite its potential, the Mean Shift approach is a computationally expensive
method for unsupervised learning. Thus, we introduce two contributions aiming
to provide clustering algorithms with a linear time complexity, as opposed to
the quadratic time complexity for the exact Mean Shift clustering. Firstly we
propose a scalable procedure to approximate the density gradient ascent.
Second, our proposed scalable cluster labeling technique is presented. Both
propositions are based on Locality Sensitive Hashing (LSH) to approximate
nearest neighbors. These two techniques may be used for moderate sized
datasets. Furthermore, we show that using our proposed approximations of the
density gradient ascent as a pre-processing step in other clustering methods
can also improve dedicated classification metrics. For the latter, a
distributed implementation, written for the Spark/Scala ecosystem is proposed.
For all these considered clustering methods, we present experimental results
illustrating their labeling accuracy and their potential to solve concrete
problems.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/backurs2019scalable/">Scalable Nearest Neighbor Search For Optimal Transport</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Scalable Nearest Neighbor Search For Optimal Transport' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Scalable Nearest Neighbor Search For Optimal Transport' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Backurs et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>12</td>
    <td><p>The Optimal Transport (a.k.a. Wasserstein) distance is an increasingly
popular similarity measure for rich data domains, such as images or text
documents. This raises the necessity for fast nearest neighbor search
algorithms according to this distance, which poses a substantial computational
bottleneck on massive datasets. In this work we introduce Flowtree, a fast and
accurate approximation algorithm for the Wasserstein-\(1\) distance. We formally
analyze its approximation factor and running time. We perform extensive
experimental evaluation of nearest neighbor search algorithms in the \(W_1\)
distance on real-world dataset. Our results show that compared to previous
state of the art, Flowtree achieves up to \(7.4\) times faster running time.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/baranchuk2019learning/">Learning To Route In Similarity Graphs</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning To Route In Similarity Graphs' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning To Route In Similarity Graphs' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Baranchuk et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>8</td>
    <td><p>Recently similarity graphs became the leading paradigm for efficient nearest
neighbor search, outperforming traditional tree-based and LSH-based methods.
Similarity graphs perform the search via greedy routing: a query traverses the
graph and in each vertex moves to the adjacent vertex that is the closest to
this query. In practice, similarity graphs are often susceptible to local
minima, when queries do not reach its nearest neighbors, getting stuck in
suboptimal vertices. In this paper we propose to learn the routing function
that overcomes local minima via incorporating information about the graph
global structure. In particular, we augment the vertices of a given graph with
additional representations that are learned to provide the optimal routing from
the start vertex to the query nearest neighbor. By thorough experiments, we
demonstrate that the proposed learnable routing successfully diminishes the
local minima problem and significantly improves the overall search performance.</p>
</td>
    <td>
      
        Tree Based ANN 
      
        Locality Sensitive Hashing 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/aum%C3%BCller2019puffinn/">PUFFINN: Parameterless And Universally Fast Finding Of Nearest Neighbors</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=PUFFINN: Parameterless And Universally Fast Finding Of Nearest Neighbors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=PUFFINN: Parameterless And Universally Fast Finding Of Nearest Neighbors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>AumÃ¼ller et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2022 29th International Conference on Systems, Signals and Image Processing (IWSSIP)</td>
    <td>7</td>
    <td><p>We present PUFFINN, a parameterless LSH-based index for solving the
\(k\)-nearest neighbor problem with probabilistic guarantees. By parameterless we
mean that the user is only required to specify the amount of memory the index
is supposed to use and the result quality that should be achieved. The index
combines several heuristic ideas known in the literature. By small adaptions to
the query algorithm, we make heuristics rigorous. We perform experiments on
real-world and synthetic inputs to evaluate implementation choices and show
that the implementation satisfies the quality guarantees while being
competitive with other state-of-the-art approaches to nearest neighbor search.
  We describe a novel synthetic data set that is difficult to solve for almost
all existing nearest neighbor search approaches, and for which PUFFINN
significantly outperform previous methods.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/aum%C3%BCller2019fair/">Fair Near Neighbor Search: Independent Range Sampling In High Dimensions</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fair Near Neighbor Search: Independent Range Sampling In High Dimensions' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fair Near Neighbor Search: Independent Range Sampling In High Dimensions' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>AumÃ¼ller Martin, Pagh Rasmus, Silvestri Francesco</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 39th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems</td>
    <td>16</td>
    <td><p>Similarity search is a fundamental algorithmic primitive, widely used in many
computer science disciplines. There are several variants of the similarity
search problem, and one of the most relevant is the \(r\)-near neighbor (\(r\)-NN)
problem: given a radius \(r&gt;0\) and a set of points \(S\), construct a data
structure that, for any given query point \(q\), returns a point \(p\) within
distance at most \(r\) from \(q\). In this paper, we study the \(r\)-NN problem in
the light of fairness. We consider fairness in the sense of equal opportunity:
all points that are within distance \(r\) from the query should have the same
probability to be returned. In the low-dimensional case, this problem was first
studied by Hu, Qiao, and Tao (PODS 2014). Locality sensitive hashing (LSH), the
theoretically strongest approach to similarity search in high dimensions, does
not provide such a fairness guarantee. To address this, we propose efficient
data structures for \(r\)-NN where all points in \(S\) that are near \(q\) have the
same probability to be selected and returned by the query. Specifically, we
first propose a black-box approach that, given any LSH scheme, constructs a
data structure for uniformly sampling points in the neighborhood of a query.
Then, we develop a data structure for fair similarity search under inner
product that requires nearly-linear space and exploits locality sensitive
filters. The paper concludes with an experimental evaluation that highlights
(un)fairness in a recommendation setting on real-world datasets and discusses
the inherent unfairness introduced by solving other variants of the problem.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Recommender Systems 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/aum%C3%BCller2019role/">The Role Of Local Intrinsic Dimensionality In Benchmarking Nearest Neighbor Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=The Role Of Local Intrinsic Dimensionality In Benchmarking Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=The Role Of Local Intrinsic Dimensionality In Benchmarking Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>AumÃ¼ller Martin, Ceccarello Matteo</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>8</td>
    <td><p>This paper reconsiders common benchmarking approaches to nearest neighbor
search. It is shown that the concept of local intrinsic dimensionality (LID)
allows to choose query sets of a wide range of difficulty for real-world
datasets. Moreover, the effect of different LID distributions on the running
time performance of implementations is empirically studied. To this end,
different visualization concepts are introduced that allow to get a more
fine-grained overview of the inner workings of nearest neighbor search
principles. The paper closes with remarks about the diversity of datasets
commonly used for nearest neighbor search benchmarking. It is shown that such
real-world datasets are not diverse: results on a single dataset predict
results on all other datasets well.</p>
</td>
    <td>
      
        Survey Paper 
      
        DATASETS 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/tu2019deep/">Deep Cross-modal Hashing With Hashing Functions And Unified Hash Codes Jointly Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Cross-modal Hashing With Hashing Functions And Unified Hash Codes Jointly Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Cross-modal Hashing With Hashing Functions And Unified Hash Codes Jointly Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Tu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Knowledge and Data Engineering</td>
    <td>62</td>
    <td><p>Due to their high retrieval efficiency and low storage cost, cross-modal
hashing methods have attracted considerable attention. Generally, compared with
shallow cross-modal hashing methods, deep cross-modal hashing methods can
achieve a more satisfactory performance by integrating feature learning and
hash codes optimizing into a same framework. However, most existing deep
cross-modal hashing methods either cannot learn a unified hash code for the two
correlated data-points of different modalities in a database instance or cannot
guide the learning of unified hash codes by the feedback of hashing function
learning procedure, to enhance the retrieval accuracy. To address the issues
above, in this paper, we propose a novel end-to-end Deep Cross-Modal Hashing
with Hashing Functions and Unified Hash Codes Jointly Learning (DCHUC).
Specifically, by an iterative optimization algorithm, DCHUC jointly learns
unified hash codes for image-text pairs in a database and a pair of hash
functions for unseen query image-text pairs. With the iterative optimization
algorithm, the learned unified hash codes can be used to guide the hashing
function learning procedure; Meanwhile, the learned hashing functions can
feedback to guide the unified hash codes optimizing procedure. Extensive
experiments on three public datasets demonstrate that the proposed method
outperforms the state-of-the-art cross-modal hashing methods.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/arponen2019shrewd/">SHREWD: Semantic Hierarchy-based Relational Embeddings For Weakly-supervised Deep Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=SHREWD: Semantic Hierarchy-based Relational Embeddings For Weakly-supervised Deep Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=SHREWD: Semantic Hierarchy-based Relational Embeddings For Weakly-supervised Deep Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Arponen Heikki, Bishop Tom E</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>27</td>
    <td><p>Using class labels to represent class similarity is a typical approach to
training deep hashing systems for retrieval; samples from the same or different
classes take binary 1 or 0 similarity values. This similarity does not model
the full rich knowledge of semantic relations that may be present between data
points. In this work we build upon the idea of using semantic hierarchies to
form distance metrics between all available sample labels; for example cat to
dog has a smaller distance than cat to guitar. We combine this type of semantic
distance into a loss function to promote similar distances between the deep
neural network embeddings. We also introduce an empirical Kullback-Leibler
divergence loss term to promote binarization and uniformity of the embeddings.
We test the resulting SHREWD method and demonstrate improvements in
hierarchical retrieval scores using compact, binary hash codes instead of real
valued ones, and show that in a weakly supervised hashing setting we are able
to learn competitively without explicitly relying on class labels, but instead
on similarities between labels.</p>
</td>
    <td>
      
        CVPR 
      
        Distance Metric Learning 
      
        Neural Hashing 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/atighehchi2019cryptanalysis/">A Cryptanalysis Of Two Cancelable Biometric Schemes Based On Index-of-max Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Cryptanalysis Of Two Cancelable Biometric Schemes Based On Index-of-max Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Cryptanalysis Of Two Cancelable Biometric Schemes Based On Index-of-max Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Atighehchi et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Information Forensics and Security</td>
    <td>56</td>
    <td><p>Cancelable biometric schemes generate secure biometric templates by combining
user specific tokens and biometric data. The main objective is to create
irreversible, unlinkable, and revocable templates, with high accuracy in
matching. In this paper, we cryptanalyze two recent cancelable biometric
schemes based on a particular locality sensitive hashing function, index-of-max
(IoM): Gaussian Random Projection-IoM (GRP-IoM) and Uniformly Random
Permutation-IoM (URP-IoM). As originally proposed, these schemes were claimed
to be resistant against reversibility, authentication, and linkability attacks
under the stolen token scenario. We propose several attacks against GRP-IoM and
URP-IoM, and argue that both schemes are severely vulnerable against
authentication and linkability attacks. We also propose better, but not yet
practical, reversibility attacks against GRP-IoM. The correctness and practical
impact of our attacks are verified over the same dataset provided by the
authors of these two schemes.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/stylianou2019visualizing/">Visualizing Deep Similarity Networks</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Visualizing Deep Similarity Networks' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Visualizing Deep Similarity Networks' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Stylianou Abby, Souvenir Richard, Pless Robert</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE Winter Conference on Applications of Computer Vision (WACV)</td>
    <td>44</td>
    <td><p>For convolutional neural network models that optimize an image embedding, we
propose a method to highlight the regions of images that contribute most to
pairwise similarity. This work is a corollary to the visualization tools
developed for classification networks, but applicable to the problem domains
better suited to similarity learning. The visualization shows how similarity
networks that are fine-tuned learn to focus on different features. We also
generalize our approach to embedding networks that use different pooling
strategies and provide a simple mechanism to support image similarity searches
on objects or sub-regions in the query image.</p>
</td>
    <td>
      
        Similarity Search 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/andr%C3%A92019derived/">Derived Codebooks For High-accuracy Nearest Neighbor Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Derived Codebooks For High-accuracy Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Derived Codebooks For High-accuracy Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>AndrÃ© Fabien, Kermarrec Anne-marie, Scouarnec Nicolas Le</td> <!-- ðŸ”§ You were missing this -->
    <td>Neurocomputing</td>
    <td>28</td>
    <td><p>High-dimensional Nearest Neighbor (NN) search is central in multimedia search
systems. Product Quantization (PQ) is a widespread NN search technique which
has a high performance and good scalability. PQ compresses high-dimensional
vectors into compact codes thanks to a combination of quantizers. Large
databases can, therefore, be stored entirely in RAM, enabling fast responses to
NN queries. In almost all cases, PQ uses 8-bit quantizers as they offer low
response times. In this paper, we advocate the use of 16-bit quantizers.
Compared to 8-bit quantizers, 16-bit quantizers boost accuracy but they
increase response time by a factor of 3 to 10. We propose a novel approach that
allows 16-bit quantizers to offer the same response time as 8-bit quantizers,
while still providing a boost of accuracy. Our approach builds on two key
ideas: (i) the construction of derived codebooks that allow a fast and
approximate distance evaluation, and (ii) a two-pass NN search procedure which
builds a candidate set using the derived codebooks, and then refines it using
16-bit quantizers. On 1 billion SIFT vectors, with an inverted index, our
approach offers a Recall@100 of 0.85 in 5.2 ms. By contrast, 16-bit quantizers
alone offer a Recall@100 of 0.85 in 39 ms, and 8-bit quantizers a Recall@100 of
0.82 in 3.8 ms.</p>
</td>
    <td>
      
        Compact Codes 
      
        Quantization 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/xuan2019improved/">Improved Embeddings With Easy Positive Triplet Mining</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Improved Embeddings With Easy Positive Triplet Mining' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Improved Embeddings With Easy Positive Triplet Mining' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Xuan Hong, Stylianou Abby, Pless Robert</td> <!-- ðŸ”§ You were missing this -->
    <td>2020 IEEE Winter Conference on Applications of Computer Vision (WACV)</td>
    <td>131</td>
    <td><p>Deep metric learning seeks to define an embedding where semantically similar
images are embedded to nearby locations, and semantically dissimilar images are
embedded to distant locations. Substantial work has focused on loss functions
and strategies to learn these embeddings by pushing images from the same class
as close together in the embedding space as possible. In this paper, we propose
an alternative, loosened embedding strategy that requires the embedding
function only map each training image to the most similar examples from the
same class, an approach we call â€œEasy Positiveâ€ mining. We provide a collection
of experiments and visualizations that highlight that this Easy Positive mining
leads to embeddings that are more flexible and generalize better to new unseen
data. This simple mining strategy yields recall performance that exceeds state
of the art approaches (including those with complicated loss functions and
ensemble methods) on image retrieval datasets including CUB, Stanford Online
Products, In-Shop Clothes and Hotels-50K.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Distance Metric Learning 
      
        Alt 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/ahle2019subsets/">Subsets And Supermajorities: Optimal Hashing-based Set Similarity Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Subsets And Supermajorities: Optimal Hashing-based Set Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Subsets And Supermajorities: Optimal Hashing-based Set Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ahle Thomas Dybdahl, Knudsen Jakob BÃ¦k Tejs</td> <!-- ðŸ”§ You were missing this -->
    <td>2020 IEEE 61st Annual Symposium on Foundations of Computer Science (FOCS)</td>
    <td>5</td>
    <td><p>We formulate and optimally solve a new generalized Set Similarity Search
problem, which assumes the size of the database and query sets are known in
advance. By creating polylog copies of our data-structure, we optimally solve
any symmetric Approximate Set Similarity Search problem, including approximate
versions of Subset Search, Maximum Inner Product Search (MIPS), Jaccard
Similarity Search and Partial Match.
  Our algorithm can be seen as a natural generalization of previous work on Set
as well as Euclidean Similarity Search, but conceptually it differs by
optimally exploiting the information present in the sets as well as their
complements, and doing so asymmetrically between queries and stored sets. Doing
so we improve upon the best previous work: MinHash [J. Discrete Algorithms
1998], SimHash [STOC 2002], Spherical LSF [SODA 2016, 2017] and Chosen Path
[STOC 2017] by as much as a factor \(n^{0.14}\) in both time and space; or in the
near-constant time regime, in space, by an arbitrarily large polynomial factor.
  Turning the geometric concept, based on Boolean supermajority functions, into
a practical algorithm requires ideas from branching random walks on \(\mathbb
Z^2\), for which we give the first non-asymptotic near tight analysis.
  Our lower bounds follow from new hypercontractive arguments, which can be
seen as characterizing the exact family of similarity search problems for which
supermajorities are optimal. The optimality holds for among all hashing based
data structures in the random setting, and by reductions, for 1 cell and 2 cell
probe data structures. As a side effect, we obtain new hypercontractive bounds
on the directed noise operator \(T^{p_1 \to p_2}_\rho\).</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Similarity Search 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/ding2019alex/">ALEX: An Updatable Adaptive Learned Index</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=ALEX: An Updatable Adaptive Learned Index' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=ALEX: An Updatable Adaptive Learned Index' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ding et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data</td>
    <td>224</td>
    <td><p>Recent work on â€œlearned indexesâ€ has changed the way we look at the
decades-old field of DBMS indexing. The key idea is that indexes can be thought
of as â€œmodelsâ€ that predict the position of a key in a dataset. Indexes can,
thus, be learned. The original work by Kraska et al. shows that a learned index
beats a B+Tree by a factor of up to three in search time and by an order of
magnitude in memory footprint. However, it is limited to static, read-only
workloads.
  In this paper, we present a new learned index called ALEX which addresses
practical issues that arise when implementing learned indexes for workloads
that contain a mix of point lookups, short range queries, inserts, updates, and
deletes. ALEX effectively combines the core insights from learned indexes with
proven storage and indexing techniques to achieve high performance and low
memory footprint. On read-only workloads, ALEX beats the learned index from
Kraska et al. by up to 2.2X on performance with up to 15X smaller index size.
Across the spectrum of read-write workloads, ALEX beats B+Trees by up to 4.1X
while never performing worse, with up to 2000X smaller index size. We believe
ALEX presents a key step towards making learned indexes practical for a broader
class of database workloads with dynamic updates.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/wang2019deep/">Deep Collaborative Discrete Hashing With Semantic-invariant Structure</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Collaborative Discrete Hashing With Semantic-invariant Structure' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Collaborative Discrete Hashing With Semantic-invariant Structure' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Multimedia</td>
    <td>39</td>
    <td><p>Existing deep hashing approaches fail to fully explore semantic correlations
and neglect the effect of linguistic context on visual attention learning,
leading to inferior performance. This paper proposes a dual-stream learning
framework, dubbed Deep Collaborative Discrete Hashing (DCDH), which constructs
a discriminative common discrete space by collaboratively incorporating the
shared and individual semantics deduced from visual features and semantic
labels. Specifically, the context-aware representations are generated by
employing the outer product of visual embeddings and semantic encodings.
Moreover, we reconstruct the labels and introduce the focal loss to take
advantage of frequent and rare concepts. The common binary code space is built
on the joint learning of the visual representations attended by language, the
semantic-invariant structure construction and the label distribution
correction. Extensive experiments demonstrate the superiority of our method.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Compact Codes 
      
        Neural Hashing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/yu2019unsupervised/">Unsupervised Multi-modal Hashing For Cross-modal Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Unsupervised Multi-modal Hashing For Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Unsupervised Multi-modal Hashing For Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yu Jun, Wu Xiao-jun</td> <!-- ðŸ”§ You were missing this -->
    <td>Cognitive Computation</td>
    <td>9</td>
    <td><p>With the advantage of low storage cost and high efficiency, hashing learning
has received much attention in the domain of Big Data. In this paper, we
propose a novel unsupervised hashing learning method to cope with this open
problem to directly preserve the manifold structure by hashing. To address this
problem, both the semantic correlation in textual space and the locally
geometric structure in the visual space are explored simultaneously in our
framework. Besides, the `2;1-norm constraint is imposed on the projection
matrices to learn the discriminative hash function for each modality. Extensive
experiments are performed to evaluate the proposed method on the three publicly
available datasets and the experimental results show that our method can
achieve superior performance over the state-of-the-art methods.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Multimodal Retrieval 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/talreja2019using/">Using Deep Cross Modal Hashing And Error Correcting Codes For Improving The Efficiency Of Attribute Guided Facial Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Using Deep Cross Modal Hashing And Error Correcting Codes For Improving The Efficiency Of Attribute Guided Facial Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Using Deep Cross Modal Hashing And Error Correcting Codes For Improving The Efficiency Of Attribute Guided Facial Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Talreja et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2018 IEEE Global Conference on Signal and Information Processing (GlobalSIP)</td>
    <td>25</td>
    <td><p>With benefits of fast query speed and low storage cost, hashing-based image
retrieval approaches have garnered considerable attention from the research
community. In this paper, we propose a novel Error-Corrected Deep Cross Modal
Hashing (CMH-ECC) method which uses a bitmap specifying the presence of certain
facial attributes as an input query to retrieve relevant face images from the
database. In this architecture, we generate compact hash codes using an
end-to-end deep learning module, which effectively captures the inherent
relationships between the face and attribute modality. We also integrate our
deep learning module with forward error correction codes to further reduce the
distance between different modalities of the same subject. Specifically, the
properties of deep hashing and forward error correction codes are exploited to
design a cross modal hashing framework with high retrieval performance.
Experimental results using two standard datasets with facial attributes-image
modalities indicate that our CMH-ECC face image retrieval model outperforms
most of the current attribute-based face image retrieval approaches.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Neural Hashing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/aalto2019metric/">Metric Learning On Manifolds</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Metric Learning On Manifolds' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Metric Learning On Manifolds' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Aalto Max, Verma Nakul</td> <!-- ðŸ”§ You were missing this -->
    <td>2011 IEEE 11th International Conference on Data Mining</td>
    <td>30</td>
    <td><p>Recent literature has shown that symbolic data, such as text and graphs, is
often better represented by points on a curved manifold, rather than in
Euclidean space. However, geometrical operations on manifolds are generally
more complicated than in Euclidean space, and thus many techniques for
processing and analysis taken for granted in Euclidean space are difficult on
manifolds. A priori, it is not obvious how we may generalize such methods to
manifolds. We consider specifically the problem of distance metric learning,
and present a framework that solves it on a large class of manifolds, such that
similar data are located in closer proximity with respect to the manifold
distance function. In particular, we extend the existing metric learning
algorithms, and derive the corresponding sample complexity rates for the case
of manifolds. Additionally, we demonstrate an improvement of performance in
\(k\)-means clustering and \(k\)-nearest neighbor classification on real-world
complex networks using our methods.</p>
</td>
    <td>
      
        Tools & Libraries 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/le2019btel/">BTEL: A Binary Tree Encoding Approach For Visual Localization</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=BTEL: A Binary Tree Encoding Approach For Visual Localization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=BTEL: A Binary Tree Encoding Approach For Visual Localization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Le Huu, Hoang Tuan, Milford Michael</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Robotics and Automation Letters</td>
    <td>5</td>
    <td><p>Visual localization algorithms have achieved significant improvements in
performance thanks to recent advances in camera technology and vision-based
techniques. However, there remains one critical caveat: all current approaches
that are based on image retrieval currently scale at best linearly with the
size of the environment with respect to both storage, and consequentially in
most approaches, query time. This limitation severely curtails the capability
of autonomous systems in a wide range of compute, power, storage, size, weight
or cost constrained applications such as drones. In this work, we present a
novel binary tree encoding approach for visual localization which can serve as
an alternative for existing quantization and indexing techniques. The proposed
tree structure allows us to derive a compressed training scheme that achieves
sub-linearity in both required storage and inference time. The encoding memory
can be easily configured to satisfy different storage constraints. Moreover,
our approach is amenable to an optional sequence filtering mechanism to further
improve the localization results, while maintaining the same amount of storage.
Our system is entirely agnostic to the front-end descriptors, allowing it to be
used on top of recent state-of-the-art image representations. Experimental
results show that the proposed method significantly outperforms
state-of-the-art approaches under limited storage constraints.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Efficiency And Optimization 
      
        Alt 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/teofili2019lucene/">Lucene For Approximate Nearest-neighbors Search On Arbitrary Dense Vectors</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Lucene For Approximate Nearest-neighbors Search On Arbitrary Dense Vectors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Lucene For Approximate Nearest-neighbors Search On Arbitrary Dense Vectors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Teofili Tommaso, Lin Jimmy</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the first ACM workshop on Information hiding and multimedia security</td>
    <td>7</td>
    <td><p>We demonstrate three approaches for adapting the open-source Lucene search
library to perform approximate nearest-neighbor search on arbitrary dense
vectors, using similarity search on word embeddings as a case study. At its
core, Lucene is built around inverted indexes of a document collectionâ€™s
(sparse) term-document matrix, which is incompatible with the lower-dimensional
dense vectors that are common in deep learning applications. We evaluate three
techniques to overcome these challenges that can all be natively integrated
into Lucene: the creation of documents populated with fake words, LSH applied
to lexical realizations of dense vectors, and k-d trees coupled with
dimensionality reduction. Experiments show that the â€œfake wordsâ€ approach
represents the best balance between effectiveness and efficiency. These
techniques are integrated into the Anserini open-source toolkit and made
available to the community.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Efficiency And Optimization 
      
        Similarity Search 
      
        Tree Based ANN 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/mishra2019finding/">Finding Nearest Neighbors In Graphs Locally</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Finding Nearest Neighbors In Graphs Locally' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Finding Nearest Neighbors In Graphs Locally' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Mishra Abhinav</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>12</td>
    <td><p>Many distributed learning techniques have been motivated by the increasing
size of datasets and their inability to fit into main memory on a single
machine. We propose an algorithm that finds the nearest neighbor in a graph
locally without the need of visiting the whole graph. Our algorithm is
distributed which further encourage scalability. We prove the convergence of
the algorithm</p>
</td>
    <td>
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/liberman2019search/">Search-based Serving Architecture Of Embeddings-based Recommendations</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Search-based Serving Architecture Of Embeddings-based Recommendations' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Search-based Serving Architecture Of Embeddings-based Recommendations' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liberman et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2021 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)</td>
    <td>7</td>
    <td><p>Over the past 10 years, many recommendation techniques have been based on
embedding users and items in latent vector spaces, where the inner product of a
(user,item) pair of vectors represents the predicted affinity of the user to
the item. A wealth of literature has focused on the various modeling approaches
that result in embeddings, and has compared their quality metrics, learning
complexity, etc. However, much less attention has been devoted to the issues
surrounding productization of an embeddings-based high throughput, low latency
recommender system. In particular, how the system might keep up with the
changing embeddings as new models are learnt. This paper describes a reference
architecture of a high-throughput, large scale recommendation service which
leverages a search engine as its runtime core. We describe how the search index
and the query builder adapt to changes in the embeddings, which often happen at
a different cadence than index builds. We provide solutions for both id-based
and feature-based embeddings, as well as for batch indexing and incremental
indexing setups. The described system is at the core of a Web content discovery
service that serves tens of billions recommendations per day in response to
billions of user requests.</p>
</td>
    <td>
      
        ICCV 
      
        Recommender Systems 
      
        Alt 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/tian2019global/">Global Hashing System For Fast Image Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Global Hashing System For Fast Image Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Global Hashing System For Fast Image Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Tian Dayong, Tao Dacheng</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Image Processing</td>
    <td>14</td>
    <td><p>Hashing methods have been widely investigated for fast approximate nearest
neighbor searching in large data sets. Most existing methods use binary vectors
in lower dimensional spaces to represent data points that are usually real
vectors of higher dimensionality. We divide the hashing process into two steps.
Data points are first embedded in a low-dimensional space, and the global
positioning system method is subsequently introduced but modified for binary
embedding. We devise dataindependent and data-dependent methods to distribute
the satellites at appropriate locations. Our methods are based on finding the
tradeoff between the information losses in these two steps. Experiments show
that our data-dependent method outperforms other methods in different-sized
data sets from 100k to 10M. By incorporating the orthogonality of the code
matrix, both our data-independent and data-dependent methods are particularly
impressive in experiments on longer bits.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/yang2019asymmetric/">Asymmetric Deep Semantic Quantization For Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Asymmetric Deep Semantic Quantization For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Asymmetric Deep Semantic Quantization For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Access</td>
    <td>5</td>
    <td><p>Due to its fast retrieval and storage efficiency capabilities, hashing has
been widely used in nearest neighbor retrieval tasks. By using deep learning
based techniques, hashing can outperform non-learning based hashing technique
in many applications. However, we argue that the current deep learning based
hashing methods ignore some critical problems (e.g., the learned hash codes are
not discriminative due to the hashing methods being unable to discover rich
semantic information and the training strategy having difficulty optimizing the
discrete binary codes). In this paper, we propose a novel image hashing method,
termed as \textbf{\underline{A}}symmetric \textbf{\underline{D}}eep
\textbf{\underline{S}}emantic \textbf{\underline{Q}}uantization
(\textbf{ADSQ}). \textbf{ADSQ} is implemented using three stream frameworks,
which consist of one <em>LabelNet</em> and two <em>ImgNets</em>. The
<em>LabelNet</em> leverages the power of three fully-connected layers, which are
used to capture rich semantic information between image pairs. For the two
<em>ImgNets</em>, they each adopt the same convolutional neural network
structure, but with different weights (i.e., asymmetric convolutional neural
networks). The two <em>ImgNets</em> are used to generate discriminative compact
hash codes. Specifically, the function of the <em>LabelNet</em> is to capture
rich semantic information that is used to guide the two <em>ImgNets</em> in
minimizing the gap between the real-continuous features and the discrete binary
codes. Furthermore, \textbf{ADSQ} can utilize the most critical semantic
information to guide the feature learning process and consider the consistency
of the common semantic space and Hamming space. Experimental results on three
benchmarks (i.e., CIFAR-10, NUS-WIDE, and ImageNet) demonstrate that the
proposed \textbf{ADSQ} can outperforms current state-of-the-art methods.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Quantization 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/yang2019distillhash/">Distillhash: Unsupervised Deep Hashing By Distilling Data Pairs</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Distillhash: Unsupervised Deep Hashing By Distilling Data Pairs' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Distillhash: Unsupervised Deep Hashing By Distilling Data Pairs' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>149</td>
    <td><p>Due to the high storage and search efficiency, hashing has become prevalent
for large-scale similarity search. Particularly, deep hashing methods have
greatly improved the search performance under supervised scenarios. In
contrast, unsupervised deep hashing models can hardly achieve satisfactory
performance due to the lack of reliable supervisory similarity signals. To
address this issue, we propose a novel deep unsupervised hashing model, dubbed
DistillHash, which can learn a distilled data set consisted of data pairs,
which have confidence similarity signals. Specifically, we investigate the
relationship between the initial noisy similarity signals learned from local
structures and the semantic similarity labels assigned by a Bayes optimal
classifier. We show that under a mild assumption, some data pairs, of which
labels are consistent with those assigned by the Bayes optimal classifier, can
be potentially distilled. Inspired by this fact, we design a simple yet
effective strategy to distill data pairs automatically and further adopt a
Bayesian learning framework to learn hash functions from the distilled data
set. Extensive experimental results on three widely used benchmark datasets
show that the proposed DistillHash consistently accomplishes the
state-of-the-art search performance.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        CVPR 
      
        Neural Hashing 
      
        Similarity Search 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/yang2019shared/">Shared Predictive Cross-modal Deep Quantization</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Shared Predictive Cross-modal Deep Quantization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Shared Predictive Cross-modal Deep Quantization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Neural Networks and Learning Systems</td>
    <td>150</td>
    <td><p>With explosive growth of data volume and ever-increasing diversity of data
modalities, cross-modal similarity search, which conducts nearest neighbor
search across different modalities, has been attracting increasing interest.
This paper presents a deep compact code learning solution for efficient
cross-modal similarity search. Many recent studies have proven that
quantization-based approaches perform generally better than hashing-based
approaches on single-modal similarity search. In this paper, we propose a deep
quantization approach, which is among the early attempts of leveraging deep
neural networks into quantization-based cross-modal similarity search. Our
approach, dubbed shared predictive deep quantization (SPDQ), explicitly
formulates a shared subspace across different modalities and two private
subspaces for individual modalities, and representations in the shared subspace
and the private subspaces are learned simultaneously by embedding them to a
reproducing kernel Hilbert space, where the mean embedding of different
modality distributions can be explicitly compared. In addition, in the shared
subspace, a quantizer is learned to produce the semantics preserving compact
codes with the help of label alignment. Thanks to this novel network
architecture in cooperation with supervised quantization training, SPDQ can
preserve intramodal and intermodal similarities as much as possible and greatly
reduce quantization error. Experiments on two popular benchmarks corroborate
that our approach outperforms state-of-the-art methods.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Compact Codes 
      
        Similarity Search 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/yang2019feature/">Feature Pyramid Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Feature Pyramid Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Feature Pyramid Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 2019 on International Conference on Multimedia Retrieval</td>
    <td>22</td>
    <td><p>In recent years, deep-networks-based hashing has become a leading approach
for large-scale image retrieval. Most deep hashing approaches use the high
layer to extract the powerful semantic representations. However, these methods
have limited ability for fine-grained image retrieval because the semantic
features extracted from the high layer are difficult in capturing the subtle
differences. To this end, we propose a novel two-pyramid hashing architecture
to learn both the semantic information and the subtle appearance details for
fine-grained image search. Inspired by the feature pyramids of convolutional
neural network, a vertical pyramid is proposed to capture the high-layer
features and a horizontal pyramid combines multiple low-layer features with
structural information to capture the subtle differences. To fuse the low-level
features, a novel combination strategy, called consensus fusion, is proposed to
capture all subtle information from several low-layers for finer retrieval.
Extensive evaluation on two fine-grained datasets CUB-200-2011 and Stanford
Dogs demonstrate that the proposed method achieves significant performance
compared with the state-of-art baselines.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        Neural Hashing 
      
        Hashing Methods 
      
        Image Retrieval 
      
        Multimodal Retrieval 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/zhu2019visual/">Visual Explanation For Deep Metric Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Visual Explanation For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Visual Explanation For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhu Sijie, Yang Taojiannan, Chen Chen</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Image Processing</td>
    <td>25</td>
    <td><p>This work explores the visual explanation for deep metric learning and its
applications. As an important problem for learning representation, metric
learning has attracted much attention recently, while the interpretation of
such model is not as well studied as classification. To this end, we propose an
intuitive idea to show where contributes the most to the overall similarity of
two input images by decomposing the final activation. Instead of only providing
the overall activation map of each image, we propose to generate point-to-point
activation intensity between two images so that the relationship between
different regions is uncovered. We show that the proposed framework can be
directly deployed to a large range of metric learning applications and provides
valuable information for understanding the model. Furthermore, our experiments
show its effectiveness on two potential applications, i.e. cross-view pattern
discovery and interactive retrieval. The source code is available at
https://github.com/Jeff-Zilence/Explain_Metric_Learning.</p>
</td>
    <td>
      
        Tools & Libraries 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/qiao2019deep/">Deep Heterogeneous Hashing For Face Video Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Heterogeneous Hashing For Face Video Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Heterogeneous Hashing For Face Video Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Qiao et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Image Processing</td>
    <td>21</td>
    <td><p>Retrieving videos of a particular person with face image as a query via
hashing technique has many important applications. While face images are
typically represented as vectors in Euclidean space, characterizing face videos
with some robust set modeling techniques (e.g. covariance matrices as exploited
in this study, which reside on Riemannian manifold), has recently shown
appealing advantages. This hence results in a thorny heterogeneous spaces
matching problem. Moreover, hashing with handcrafted features as done in many
existing works is clearly inadequate to achieve desirable performance for this
task. To address such problems, we present an end-to-end Deep Heterogeneous
Hashing (DHH) method that integrates three stages including image feature
learning, video modeling, and heterogeneous hashing in a single framework, to
learn unified binary codes for both face images and videos. To tackle the key
challenge of hashing on the manifold, a well-studied Riemannian kernel mapping
is employed to project data (i.e. covariance matrices) into Euclidean space and
thus enables to embed the two heterogeneous representations into a common
Hamming space, where both intra-space discriminability and inter-space
compatibility are considered. To perform network optimization, the gradient of
the kernel mapping is innovatively derived via structured matrix
backpropagation in a theoretically principled way. Experiments on three
challenging datasets show that our method achieves quite competitive
performance compared with existing hashing methods.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/li2019design/">The Design And Implementation Of A Real Time Visual Search System On JD E-commerce Platform</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=The Design And Implementation Of A Real Time Visual Search System On JD E-commerce Platform' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=The Design And Implementation Of A Real Time Visual Search System On JD E-commerce Platform' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 19th International Middleware Conference Industry</td>
    <td>34</td>
    <td><p>We present the design and implementation of a visual search system for real
time image retrieval on JD.com, the worldâ€™s third largest and Chinaâ€™s largest
e-commerce site. We demonstrate that our system can support real time visual
search with hundreds of billions of product images at sub-second timescales and
handle frequent image updates through distributed hierarchical architecture and
efficient indexing methods. We hope that sharing our practice with our real
production system will inspire the middleware communityâ€™s interest and
appreciation for building practical large scale systems for emerging
applications, such as ecommerce visual search.</p>
</td>
    <td>
      
        Image Retrieval 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/li2019coupled/">Coupled Cyclegan: Unsupervised Hashing Network For Cross-modal Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Coupled Cyclegan: Unsupervised Hashing Network For Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Coupled Cyclegan: Unsupervised Hashing Network For Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>105</td>
    <td><p>In recent years, hashing has attracted more and more attention owing to its
superior capacity of low storage cost and high query efficiency in large-scale
cross-modal retrieval. Benefiting from deep leaning, continuously compelling
results in cross-modal retrieval community have been achieved. However,
existing deep cross-modal hashing methods either rely on amounts of labeled
information or have no ability to learn an accuracy correlation between
different modalities. In this paper, we proposed Unsupervised coupled Cycle
generative adversarial Hashing networks (UCH), for cross-modal retrieval, where
outer-cycle network is used to learn powerful common representation, and
inner-cycle network is explained to generate reliable hash codes. Specifically,
our proposed UCH seamlessly couples these two networks with generative
adversarial mechanism, which can be optimized simultaneously to learn
representation and hash codes. Extensive experiments on three popular benchmark
datasets show that the proposed UCH outperforms the state-of-the-art
unsupervised cross-modal hashing methods.</p>
</td>
    <td>
      
        AAAI 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Multimodal Retrieval 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/li2019push/">Push For Quantization: Deep Fisher Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Push For Quantization: Deep Fisher Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Push For Quantization: Deep Fisher Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>7</td>
    <td><p>Current massive datasets demand light-weight access for analysis. Discrete
hashing methods are thus beneficial because they map high-dimensional data to
compact binary codes that are efficient to store and process, while preserving
semantic similarity. To optimize powerful deep learning methods for image
hashing, gradient-based methods are required. Binary codes, however, are
discrete and thus have no continuous derivatives. Relaxing the problem by
solving it in a continuous space and then quantizing the solution is not
guaranteed to yield separable binary codes. The quantization needs to be
included in the optimization. In this paper we push for quantization: We
optimize maximum class separability in the binary space. We introduce a margin
on distances between dissimilar image pairs as measured in the binary space. In
addition to pair-wise distances, we draw inspiration from Fisherâ€™s Linear
Discriminant Analysis (Fisher LDA) to maximize the binary distances between
classes and at the same time minimize the binary distance of images within the
same class. Experiments on CIFAR-10, NUS-WIDE and ImageNet100 demonstrate
compact codes comparing favorably to the current state of the art.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/shi2019compositional/">Compositional Embeddings Using Complementary Partitions For Memory-efficient Recommendation Systems</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Compositional Embeddings Using Complementary Partitions For Memory-efficient Recommendation Systems' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Compositional Embeddings Using Complementary Partitions For Memory-efficient Recommendation Systems' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Shi et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</td>
    <td>39</td>
    <td><p>Modern deep learning-based recommendation systems exploit hundreds to
thousands of different categorical features, each with millions of different
categories ranging from clicks to posts. To respect the natural diversity
within the categorical data, embeddings map each category to a unique dense
representation within an embedded space. Since each categorical feature could
take on as many as tens of millions of different possible categories, the
embedding tables form the primary memory bottleneck during both training and
inference. We propose a novel approach for reducing the embedding size in an
end-to-end fashion by exploiting complementary partitions of the category set
to produce a unique embedding vector for each category without explicit
definition. By storing multiple smaller embedding tables based on each
complementary partition and combining embeddings from each table, we define a
unique embedding for each category at smaller memory cost. This approach may be
interpreted as using a specific fixed codebook to ensure uniqueness of each
categoryâ€™s representation. Our experimental results demonstrate the
effectiveness of our approach over the hashing trick for reducing the size of
the embedding tables in terms of model loss and accuracy, while retaining a
similar reduction in the number of parameters.</p>
</td>
    <td>
      
        KDD 
      
        Recommender Systems 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/mu2019empirical/">An Empirical Comparison Of FAISS And FENSHSES For Nearest Neighbor Search In Hamming Space</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=An Empirical Comparison Of FAISS And FENSHSES For Nearest Neighbor Search In Hamming Space' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=An Empirical Comparison Of FAISS And FENSHSES For Nearest Neighbor Search In Hamming Space' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Mu Cun, Yang Binwei, Yan Zheng</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>11</td>
    <td><p>In this paper, we compare the performances of FAISS and FENSHSES on nearest
neighbor search in Hamming spaceâ€“a fundamental task with ubiquitous
applications in nowadays eCommerce. Comprehensive evaluations are made in terms
of indexing speed, search latency and RAM consumption. This comparison is
conducted towards a better understanding on trade-offs between nearest neighbor
search systems implemented in main memory and the ones implemented in secondary
memory, which is largely unaddressed in literature.</p>
</td>
    <td>
      
        Tools & Libraries 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/lejeune2019adaptive/">Adaptive Estimation For Approximate K-nearest-neighbor Computations</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Adaptive Estimation For Approximate K-nearest-neighbor Computations' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Adaptive Estimation For Approximate K-nearest-neighbor Computations' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lejeune Daniel, Baraniuk Richard G., Heckel Reinhard</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of Machine Learning Research 89 (2019)3099-3107</td>
    <td>8</td>
    <td><p>Algorithms often carry out equally many computations for â€œeasyâ€ and â€œhardâ€
problem instances. In particular, algorithms for finding nearest neighbors
typically have the same running time regardless of the particular problem
instance. In this paper, we consider the approximate k-nearest-neighbor
problem, which is the problem of finding a subset of O(k) points in a given set
of points that contains the set of k nearest neighbors of a given query point.
We propose an algorithm based on adaptively estimating the distances, and show
that it is essentially optimal out of algorithms that are only allowed to
adaptively estimate distances. We then demonstrate both theoretically and
experimentally that the algorithm can achieve significant speedups relative to
the naive method.</p>
</td>
    <td>
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/pratap2019efficient/">Efficient Sketching Algorithm For Sparse Binary Data</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Efficient Sketching Algorithm For Sparse Binary Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Efficient Sketching Algorithm For Sparse Binary Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Pratap Rameshwar, Bera Debajyoti, Revanuru Karthik</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE International Conference on Data Mining (ICDM)</td>
    <td>11</td>
    <td><p>Recent advancement of the WWW, IOT, social network, e-commerce, etc. have
generated a large volume of data. These datasets are mostly represented by high
dimensional and sparse datasets. Many fundamental subroutines of common data
analytic tasks such as clustering, classification, ranking, nearest neighbour
search, etc. scale poorly with the dimension of the dataset. In this work, we
address this problem and propose a sketching (alternatively, dimensionality
reduction) algorithm â€“ \(\binsketch\) (Binary Data Sketch) â€“ for sparse binary
datasets. \(\binsketch\) preserves the binary version of the dataset after
sketching and maintains estimates for multiple similarity measures such as
Jaccard, Cosine, Inner-Product similarities, and Hamming distance, on the same
sketch. We present a theoretical analysis of our algorithm and complement it
with extensive experimentation on several real-world datasets. We compare the
performance of our algorithm with the state-of-the-art algorithms on the task
of mean-square-error and ranking. Our proposed algorithm offers a comparable
accuracy while suggesting a significant speedup in the dimensionality reduction
time, with respect to the other candidate algorithms. Our proposal is simple,
easy to implement, and therefore can be adopted in practice.</p>
</td>
    <td>
      
        Alt 
      
        DATASETS 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/wu2019efficient/">Efficient Inner Product Approximation In Hybrid Spaces</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Efficient Inner Product Approximation In Hybrid Spaces' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Efficient Inner Product Approximation In Hybrid Spaces' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>7</td>
    <td><p>Many emerging use cases of data mining and machine learning operate on large
datasets with data from heterogeneous sources, specifically with both sparse
and dense components. For example, dense deep neural network embedding vectors
are often used in conjunction with sparse textual features to provide high
dimensional hybrid representation of documents. Efficient search in such hybrid
spaces is very challenging as the techniques that perform well for sparse
vectors have little overlap with those that work well for dense vectors.
Popular techniques like Locality Sensitive Hashing (LSH) and its data-dependent
variants also do not give good accuracy in high dimensional hybrid spaces. Even
though hybrid scenarios are becoming more prevalent, currently there exist no
efficient techniques in literature that are both fast and accurate. In this
paper, we propose a technique that approximates the inner product computation
in hybrid vectors, leading to substantial speedup in search while maintaining
high accuracy. We also propose efficient data structures that exploit modern
computer architectures, resulting in orders of magnitude faster search than the
existing baselines. The performance of the proposed method is demonstrated on
several datasets including a very large scale industrial dataset containing one
billion vectors in a billion dimensional space, achieving over 10x speedup and
higher accuracy against competitive baselines.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/sharma2019retrieving/">Retrieving Similar E-commerce Images Using Deep Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Retrieving Similar E-commerce Images Using Deep Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Retrieving Similar E-commerce Images Using Deep Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Sharma Rishab, Vishvakarma Anirudha</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>20</td>
    <td><p>In this paper, we propose a deep convolutional neural network for learning
the embeddings of images in order to capture the notion of visual similarity.
We present a deep siamese architecture that when trained on positive and
negative pairs of images learn an embedding that accurately approximates the
ranking of images in order of visual similarity notion. We also implement a
novel loss calculation method using an angular loss metrics based on the
problems requirement. The final embedding of the image is combined
representation of the lower and top-level embeddings. We used fractional
distance matrix to calculate the distance between the learned embeddings in
n-dimensional space. In the end, we compare our architecture with other
existing deep architecture and go on to demonstrate the superiority of our
solution in terms of image retrieval by testing the architecture on four
datasets. We also show how our suggested network is better than the other
traditional deep CNNs used for capturing fine-grained image similarities by
learning an optimum embedding.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/lee2019network/">Network Pruning For Low-rank Binary Indexing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Network Pruning For Low-rank Binary Indexing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Network Pruning For Low-rank Binary Indexing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lee et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>5</td>
    <td><p>Pruning is an efficient model compression technique to remove redundancy in
the connectivity of deep neural networks (DNNs). Computations using sparse
matrices obtained by pruning parameters, however, exhibit vastly different
parallelism depending on the index representation scheme. As a result,
fine-grained pruning has not gained much attention due to its irregular index
form leading to large memory footprint and low parallelism for convolutions and
matrix multiplications. In this paper, we propose a new network pruning
technique that generates a low-rank binary index matrix to compress index data
while decompressing index data is performed by simple binary matrix
multiplication. This proposed compression method finds a particular
fine-grained pruning mask that can be decomposed into two binary matrices. We
also propose a tile-based factorization technique that not only lowers memory
requirements but also enhances compression ratio. Various DNN models can be
pruned with much fewer indexes compared to previous sparse matrix formats while
maintaining the same pruning rate.</p>
</td>
    <td>
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2019</td>
    <td>
      <a href="/publications/lin2019towards/">Towards Optimal Discrete Online Hashing With Balanced Similarity</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Towards Optimal Discrete Online Hashing With Balanced Similarity' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Towards Optimal Discrete Online Hashing With Balanced Similarity' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lin et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>50</td>
    <td><p>When facing large-scale image datasets, online hashing serves as a promising
solution for online retrieval and prediction tasks. It encodes the online
streaming data into compact binary codes, and simultaneously updates the hash
functions to renew codes of the existing dataset. To this end, the existing
methods update hash functions solely based on the new data batch, without
investigating the correlation between such new data and the existing dataset.
In addition, existing works update the hash functions using a relaxation
process in its corresponding approximated continuous space. And it remains as
an open problem to directly apply discrete optimizations in online hashing. In
this paper, we propose a novel supervised online hashing method, termed
Balanced Similarity for Online Discrete Hashing (BSODH), to solve the above
problems in a unified framework. BSODH employs a well-designed hashing
algorithm to preserve the similarity between the streaming data and the
existing dataset via an asymmetric graph regularization. We further identify
the â€œdata-imbalanceâ€ problem brought by the constructed asymmetric graph, which
restricts the application of discrete optimization in our problem. Therefore, a
novel balanced similarity is further proposed, which uses two equilibrium
factors to balance the similar and dissimilar weights and eventually enables
the usage of discrete optimizations. Extensive experiments conducted on three
widely-used benchmarks demonstrate the advantages of the proposed method over
the state-of-the-art methods.</p>
</td>
    <td>
      
        AAAI 
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
    
      
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/fehervari2018scalable/">Scalable Logo Recognition Using Proxies</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Scalable Logo Recognition Using Proxies' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Scalable Logo Recognition Using Proxies' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Fehervari Istvan, Appalaraju Srikar</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE Winter Conference on Applications of Computer Vision (WACV)</td>
    <td>50</td>
    <td><p>Logo recognition is the task of identifying and classifying logos. Logo
recognition is a challenging problem as there is no clear definition of a logo
and there are huge variations of logos, brands and re-training to cover every
variation is impractical. In this paper, we formulate logo recognition as a
few-shot object detection problem. The two main components in our pipeline are
universal logo detector and few-shot logo recognizer. The universal logo
detector is a class-agnostic deep object detector network which tries to learn
the characteristics of what makes a logo. It predicts bounding boxes on likely
logo regions. These logo regions are then classified by logo recognizer using
nearest neighbor search, trained by triplet loss using proxies. We also
annotated a first of its kind product logo dataset containing 2000 logos from
295K images collected from Amazon called PL2K. Our pipeline achieves 97% recall
with 0.6 mAP on PL2K test dataset and state-of-the-art 0.565 mAP on the
publicly available FlickrLogos-32 test set without fine-tuning.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/xu2018sketchmate/">Sketchmate: Deep Hashing For Million-scale Human Sketch Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Sketchmate: Deep Hashing For Million-scale Human Sketch Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Sketchmate: Deep Hashing For Million-scale Human Sketch Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Xu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</td>
    <td>127</td>
    <td><p>We propose a deep hashing framework for sketch retrieval that, for the first
time, works on a multi-million scale human sketch dataset. Leveraging on this
large dataset, we explore a few sketch-specific traits that were otherwise
under-studied in prior literature. Instead of following the conventional sketch
recognition task, we introduce the novel problem of sketch hashing retrieval
which is not only more challenging, but also offers a better testbed for
large-scale sketch analysis, since: (i) more fine-grained sketch feature
learning is required to accommodate the large variations in style and
abstraction, and (ii) a compact binary code needs to be learned at the same
time to enable efficient retrieval. Key to our network design is the embedding
of unique characteristics of human sketch, where (i) a two-branch CNN-RNN
architecture is adapted to explore the temporal ordering of strokes, and (ii) a
novel hashing loss is specifically designed to accommodate both the temporal
and abstract traits of sketches. By working with a 3.8M sketch dataset, we show
that state-of-the-art hashing models specifically engineered for static images
fail to perform well on temporal sketch data. Our network on the other hand not
only offers the best retrieval performance on various code sizes, but also
yields the best generalization performance under a zero-shot setting and when
re-purposed for sketch recognition. Such superior performances effectively
demonstrate the benefit of our sketch-specific design.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        CVPR 
      
        Compact Codes 
      
        Neural Hashing 
      
        Similarity Search 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/lu2018fmhash/">Fmhash: Deep Hashing Of In-air-handwriting For User Identification</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fmhash: Deep Hashing Of In-air-handwriting For User Identification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fmhash: Deep Hashing Of In-air-handwriting For User Identification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lu Duo, Huang Dijiang, Rai Anshul</td> <!-- ðŸ”§ You were missing this -->
    <td>ICC 2019 - 2019 IEEE International Conference on Communications (ICC)</td>
    <td>9</td>
    <td><p>Many mobile systems and wearable devices, such as Virtual Reality (VR) or
Augmented Reality (AR) headsets, lack a keyboard or touchscreen to type an ID
and password for signing into a virtual website. However, they are usually
equipped with gesture capture interfaces to allow the user to interact with the
system directly with hand gestures. Although gesture-based authentication has
been well-studied, less attention is paid to the gesture-based user
identification problem, which is essentially an input method of account ID and
an efficient searching and indexing method of a database of gesture signals. In
this paper, we propose FMHash (i.e., Finger Motion Hash), a user identification
framework that can generate a compact binary hash code from a piece of
in-air-handwriting of an ID string. This hash code enables indexing and fast
search of a large account database using the in-air-handwriting by a hash
table. To demonstrate the effectiveness of the framework, we implemented a
prototype and achieved &gt;99.5% precision and &gt;92.6% recall with exact hash code
match on a dataset of 200 accounts collected by us. The ability of hashing
in-air-handwriting pattern to binary code can be used to achieve convenient
sign-in and sign-up with in-air-handwriting gesture ID on future mobile and
wearable systems connected to the Internet.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Alt 
      
        Neural Hashing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/xuan2018deep/">Deep Randomized Ensembles For Metric Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Randomized Ensembles For Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Randomized Ensembles For Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Xuan Hong, Souvenir Richard, Pless Robert</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>124</td>
    <td><p>Learning embedding functions, which map semantically related inputs to nearby
locations in a feature space supports a variety of classification and
information retrieval tasks. In this work, we propose a novel, generalizable
and fast method to define a family of embedding functions that can be used as
an ensemble to give improved results. Each embedding function is learned by
randomly bagging the training labels into small subsets. We show experimentally
that these embedding ensembles create effective embedding functions. The
ensemble output defines a metric space that improves state of the art
performance for image retrieval on CUB-200-2011, Cars-196, In-Shop Clothes
Retrieval and VehicleID.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/jin2018deep/">Deep Saliency Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Saliency Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Saliency Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jin et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Image Processing</td>
    <td>57</td>
    <td><p>In recent years, hashing methods have been proved to be effective and
efficient for the large-scale Web media search. However, the existing general
hashing methods have limited discriminative power for describing fine-grained
objects that share similar overall appearance but have subtle difference. To
solve this problem, we for the first time introduce the attention mechanism to
the learning of fine-grained hashing codes. Specifically, we propose a novel
deep hashing model, named deep saliency hashing (DSaH), which automatically
mines salient regions and learns semantic-preserving hashing codes
simultaneously. DSaH is a two-step end-to-end model consisting of an attention
network and a hashing network. Our loss function contains three basic
components, including the semantic loss, the saliency loss, and the
quantization loss. As the core of DSaH, the saliency loss guides the attention
network to mine discriminative regions from pairs of images. We conduct
extensive experiments on both fine-grained and general retrieval datasets for
performance evaluation. Experimental results on fine-grained datasets,
including Oxford Flowers-17, Stanford Dogs-120, and CUB Bird demonstrate that
our DSaH performs the best for fine-grained retrieval task and beats the
strongest competitor (DTQ) by approximately 10% on both Stanford Dogs-120 and
CUB Bird. DSaH is also comparable to several state-of-the-art hashing methods
on general datasets, including CIFAR-10 and NUS-WIDE.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Neural Hashing 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/yang2018gb/">GB-KMV: An Augmented KMV Sketch For Approximate Containment Similarity Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=GB-KMV: An Augmented KMV Sketch For Approximate Containment Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=GB-KMV: An Augmented KMV Sketch For Approximate Containment Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE 35th International Conference on Data Engineering (ICDE)</td>
    <td>18</td>
    <td><p>In this paper, we study the problem of approximate containment similarity
search. Given two records Q and X, the containment similarity between Q and X
with respect to Q is |Q intersect X|/ |Q|. Given a query record Q and a set of
records S, the containment similarity search finds a set of records from S
whose containment similarity regarding Q are not less than the given threshold.
This problem has many important applications in commercial and scientific
fields such as record matching and domain search. Existing solution relies on
the asymmetric LSH method by transforming the containment similarity to
well-studied Jaccard similarity. In this paper, we use a different framework by
transforming the containment similarity to set intersection. We propose a novel
augmented KMV sketch technique, namely GB-KMV, which is data-dependent and can
achieve a good trade-off between the sketch size and the accuracy. We provide a
set of theoretical analysis to underpin the proposed augmented KMV sketch
technique, and show that it outperforms the state-of-the-art technique LSH-E in
terms of estimation accuracy under practical assumption. Our comprehensive
experiments on real-life datasets verify that GB-KMV is superior to LSH-E in
terms of the space-accuracy trade-off, time-accuracy trade-off, and the sketch
construction time. For instance, with similar estimation accuracy (F-1 score),
GB-KMV is over 100 times faster than LSH-E on some real-life dataset.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Similarity Search 
      
        Tools & Libraries 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/fu2018neurons/">Neurons Merging Layer: Towards Progressive Redundancy Reduction For Deep Supervised Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Neurons Merging Layer: Towards Progressive Redundancy Reduction For Deep Supervised Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Neurons Merging Layer: Towards Progressive Redundancy Reduction For Deep Supervised Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Fu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence</td>
    <td>6</td>
    <td><p>Deep supervised hashing has become an active topic in information retrieval.
It generates hashing bits by the output neurons of a deep hashing network.
During binary discretization, there often exists much redundancy between
hashing bits that degenerates retrieval performance in terms of both storage
and accuracy. This paper proposes a simple yet effective Neurons Merging Layer
(NMLayer) for deep supervised hashing. A graph is constructed to represent the
redundancy relationship between hashing bits that is used to guide the learning
of a hashing network. Specifically, it is dynamically learned by a novel
mechanism defined in our active and frozen phases. According to the learned
relationship, the NMLayer merges the redundant neurons together to balance the
importance of each output neuron. Moreover, multiple NMLayers are progressively
trained for a deep hashing network to learn a more compact hashing code from a
long redundant code. Extensive experiments on four datasets demonstrate that
our proposed method outperforms state-of-the-art hashing methods.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        IJCAI 
      
        Neural Hashing 
      
        Hashing Methods 
      
        AAAI 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/freksen2018fully/">Fully Understanding The Hashing Trick</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fully Understanding The Hashing Trick' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fully Understanding The Hashing Trick' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Freksen Casper Benjamin, Kamma Lior, Larsen Kasper Green</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>11</td>
    <td><p>Feature hashing, also known as {\em the hashing trick}, introduced by
Weinberger et al. (2009), is one of the key techniques used in scaling-up
machine learning algorithms. Loosely speaking, feature hashing uses a random
sparse projection matrix \(A : \mathbb{R}^n \to \mathbb{R}^m\) (where \(m \ll n\))
in order to reduce the dimension of the data from \(n\) to \(m\) while
approximately preserving the Euclidean norm. Every column of \(A\) contains
exactly one non-zero entry, equals to either \(-1\) or \(1\).
  Weinberger et al. showed tail bounds on \(|Ax|<em>2^2\). Specifically they
showed that for every \(\epsilon, \delta\), if \(|x|</em>{\infty} / |x|<em>2\) is
sufficiently small, and \(m\) is sufficiently large, then $\(\Pr[ \; |
\;|Ax|_2^2 - |x|_2^2\; | &lt; \epsilon |x|_2^2 \;] \ge 1 - \delta \;.\)\(
These bounds were later extended by Dasgupta \etal (2010) and most recently
refined by Dahlgaard et al. (2017), however, the true nature of the performance
of this key technique, and specifically the correct tradeoff between the
pivotal parameters \)|x|</em>{\infty} / |x|_2, m, \epsilon, \delta\( remained
an open question.
  We settle this question by giving tight asymptotic bounds on the exact
tradeoff between the central parameters, thus providing a complete
understanding of the performance of feature hashing. We complement the
asymptotic bound with empirical data, which shows that the constants â€œhidingâ€
in the asymptotic notation are, in fact, very close to \)1$, thus further
illustrating the tightness of the presented bounds in practice.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/peng2018deep/">Deep Reinforcement Learning For Image Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Reinforcement Learning For Image Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Reinforcement Learning For Image Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Peng Yuxin, Zhang Jian, Ye Zhaoda</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Multimedia</td>
    <td>44</td>
    <td><p>Deep hashing methods have received much attention recently, which achieve
promising results by taking advantage of the strong representation power of
deep networks. However, most existing deep hashing methods learn a whole set of
hashing functions independently, while ignore the correlations between
different hashing functions that can promote the retrieval accuracy greatly.
Inspired by the sequential decision ability of deep reinforcement learning, we
propose a new Deep Reinforcement Learning approach for Image Hashing (DRLIH).
Our proposed DRLIH approach models the hashing learning problem as a sequential
decision process, which learns each hashing function by correcting the errors
imposed by previous ones and promotes retrieval accuracy. To the best of our
knowledge, this is the first work to address hashing problem from deep
reinforcement learning perspective. The main contributions of our proposed
DRLIH approach can be summarized as follows: (1) We propose a deep
reinforcement learning hashing network. In the proposed network, we utilize
recurrent neural network (RNN) as agents to model the hashing functions, which
take actions of projecting images into binary codes sequentially, so that the
current hashing function learning can take previous hashing functionsâ€™ error
into account. (2) We propose a sequential learning strategy based on proposed
DRLIH. We define the state as a tuple of internal features of RNNâ€™s hidden
layers and image features, which can reflect history decisions made by the
agents. We also propose an action group method to enhance the correlation of
hash functions in the same group. Experiments on three widely-used datasets
demonstrate the effectiveness of our proposed DRLIH approach.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Neural Hashing 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/loncaric2018convolutional/">Convolutional Hashing For Automated Scene Matching</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Convolutional Hashing For Automated Scene Matching' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Convolutional Hashing For Automated Scene Matching' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Loncaric Martin, Liu Bowei, Weber Ryan</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>42</td>
    <td><p>We present a powerful new loss function and training scheme for learning
binary hash functions. In particular, we demonstrate our method by creating for
the first time a neural network that outperforms state-of-the-art Haar wavelets
and color layout descriptors at the task of automated scene matching. By
accurately relating distance on the manifold of network outputs to distance in
Hamming space, we achieve a 100-fold reduction in nontrivial false positive
rate and significantly higher true positive rate. We expect our insights to
provide large wins for hashing models applied to other information retrieval
hashing tasks as well.</p>
</td>
    <td>
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/garg2018stochastic/">Stochastic Learning Of Nonstationary Kernels For Natural Language Modeling</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Stochastic Learning Of Nonstationary Kernels For Natural Language Modeling' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Stochastic Learning Of Nonstationary Kernels For Natural Language Modeling' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Garg Sahil, Steeg Greg Ver, Galstyan Aram</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers on XX - NAACL '06</td>
    <td>12</td>
    <td><p>Natural language processing often involves computations with semantic or
syntactic graphs to facilitate sophisticated reasoning based on structural
relationships. While convolution kernels provide a powerful tool for comparing
graph structure based on node (word) level relationships, they are difficult to
customize and can be computationally expensive. We propose a generalization of
convolution kernels, with a nonstationary model, for better expressibility of
natural languages in supervised settings. For a scalable learning of the
parameters introduced with our model, we propose a novel algorithm that
leverages stochastic sampling on k-nearest neighbor graphs, along with
approximations based on locality-sensitive hashing. We demonstrate the
advantages of our approach on a challenging real-world (structured inference)
problem of automatically extracting biological models from the text of
scientific papers.</p>
</td>
    <td>
      
        ACL 
      
        NAACL 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/gillick2018end/">End-to-end Retrieval In Continuous Space</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=End-to-end Retrieval In Continuous Space' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=End-to-end Retrieval In Continuous Space' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Gillick Daniel, Presta Alessandro, Tomar Gaurav Singh</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>81</td>
    <td><p>Most text-based information retrieval (IR) systems index objects by words or
phrases. These discrete systems have been augmented by models that use
embeddings to measure similarity in continuous space. But continuous-space
models are typically used just to re-rank the top candidates. We consider the
problem of end-to-end continuous retrieval, where standard approximate nearest
neighbor (ANN) search replaces the usual discrete inverted index, and rely
entirely on distances between learned embeddings. By training simple models
specifically for retrieval, with an appropriate model architecture, we improve
on a discrete baseline by 8% and 26% (MAP) on two similar-question retrieval
tasks. We also discuss the problem of evaluation for retrieval systems, and
show how to modify existing pairwise similarity datasets for this purpose.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/gattupalli2018weakly/">Weakly Supervised Deep Image Hashing Through Tag Embeddings</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Weakly Supervised Deep Image Hashing Through Tag Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Weakly Supervised Deep Image Hashing Through Tag Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Gattupalli Vijetha, Zhuo Yaoxin, Li Baoxin</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>42</td>
    <td><p>Many approaches to semantic image hashing have been formulated as supervised
learning problems that utilize images and label information to learn the binary
hash codes. However, large-scale labeled image data is expensive to obtain,
thus imposing a restriction on the usage of such algorithms. On the other hand,
unlabelled image data is abundant due to the existence of many Web image
repositories. Such Web images may often come with images tags that contain
useful information, although raw tags, in general, do not readily lead to
semantic labels. Motivated by this scenario, we formulate the problem of
semantic image hashing as a weakly-supervised learning problem. We utilize the
information contained in the user-generated tags associated with the images to
learn the hash codes. More specifically, we extract the word2vec semantic
embeddings of the tags and use the information contained in them for
constraining the learning. Accordingly, we name our model Weakly Supervised
Deep Hashing using Tag Embeddings (WDHT). WDHT is tested for the task of
semantic image retrieval and is compared against several state-of-art models.
Results show that our approach sets a new state-of-art in the area of weekly
supervised image hashing.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        CVPR 
      
        Alt 
      
        Neural Hashing 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/jin2018unsupervised/">Unsupervised Semantic Deep Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Unsupervised Semantic Deep Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Unsupervised Semantic Deep Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jin Sheng</td> <!-- ðŸ”§ You were missing this -->
    <td>Neurocomputing</td>
    <td>25</td>
    <td><p>In recent years, deep hashing methods have been proved to be efficient since
it employs convolutional neural network to learn features and hashing codes
simultaneously. However, these methods are mostly supervised. In real-world
application, it is a time-consuming and overloaded task for annotating a large
number of images. In this paper, we propose a novel unsupervised deep hashing
method for large-scale image retrieval. Our method, namely unsupervised
semantic deep hashing (\textbf{USDH}), uses semantic information preserved in
the CNN feature layer to guide the training of network. We enforce four
criteria on hashing codes learning based on VGG-19 model: 1) preserving
relevant information of feature space in hashing space; 2) minimizing
quantization loss between binary-like codes and hashing codes; 3) improving the
usage of each bit in hashing codes by using maximum information entropy, and 4)
invariant to image rotation. Extensive experiments on CIFAR-10, NUSWIDE have
demonstrated that \textbf{USDH} outperforms several state-of-the-art
unsupervised hashing methods for image retrieval. We also conduct experiments
on Oxford 17 datasets for fine-grained classification to verify its efficiency
for other computer vision tasks.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Neural Hashing 
      
        Quantization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/ertl2018bagminhash/">Bagminhash - Minwise Hashing Algorithm For Weighted Sets</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Bagminhash - Minwise Hashing Algorithm For Weighted Sets' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Bagminhash - Minwise Hashing Algorithm For Weighted Sets' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ertl Otmar</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</td>
    <td>15</td>
    <td><p>Minwise hashing has become a standard tool to calculate signatures which
allow direct estimation of Jaccard similarities. While very efficient
algorithms already exist for the unweighted case, the calculation of signatures
for weighted sets is still a time consuming task. BagMinHash is a new algorithm
that can be orders of magnitude faster than current state of the art without
any particular restrictions or assumptions on weights or data dimensionality.
Applied to the special case of unweighted sets, it represents the first
efficient algorithm producing independent signature components. A series of
tests finally verifies the new algorithm and also reveals limitations of other
approaches published in the recent past.</p>
</td>
    <td>
      
        KDD 
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/shi2018scalable/">A Scalable Optimization Mechanism For Pairwise Based Discrete Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Scalable Optimization Mechanism For Pairwise Based Discrete Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Scalable Optimization Mechanism For Pairwise Based Discrete Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Shi et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Image Processing</td>
    <td>11</td>
    <td><p>Maintaining the pair similarity relationship among originally
high-dimensional data into a low-dimensional binary space is a popular strategy
to learn binary codes. One simiple and intutive method is to utilize two
identical code matrices produced by hash functions to approximate a pairwise
real label matrix. However, the resulting quartic problem is difficult to
directly solve due to the non-convex and non-smooth nature of the objective. In
this paper, unlike previous optimization methods using various relaxation
strategies, we aim to directly solve the original quartic problem using a novel
alternative optimization mechanism to linearize the quartic problem by
introducing a linear regression model. Additionally, we find that gradually
learning each batch of binary codes in a sequential mode, i.e. batch by batch,
is greatly beneficial to the convergence of binary code learning. Based on this
significant discovery and the proposed strategy, we introduce a scalable
symmetric discrete hashing algorithm that gradually and smoothly updates each
batch of binary codes. To further improve the smoothness, we also propose a
greedy symmetric discrete hashing algorithm to update each bit of batch binary
codes. Moreover, we extend the proposed optimization mechanism to solve the
non-convex optimization problems for binary code learning in many other
pairwise based hashing algorithms. Extensive experiments on benchmark
single-label and multi-label databases demonstrate the superior performance of
the proposed mechanism over recent state-of-the-art methods.</p>
</td>
    <td>
      
        Compact Codes 
      
        Alt 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/shao2018h/">H-CNN: Spatial Hashing Based CNN For 3D Shape Analysis</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=H-CNN: Spatial Hashing Based CNN For 3D Shape Analysis' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=H-CNN: Spatial Hashing Based CNN For 3D Shape Analysis' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Shao et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Visualization and Computer Graphics</td>
    <td>30</td>
    <td><p>We present a novel spatial hashing based data structure to facilitate 3D
shape analysis using convolutional neural networks (CNNs). Our method well
utilizes the sparse occupancy of 3D shape boundary and builds hierarchical hash
tables for an input model under different resolutions. Based on this data
structure, we design two efficient GPU algorithms namely hash2col and col2hash
so that the CNN operations like convolution and pooling can be efficiently
parallelized. The spatial hashing is nearly minimal, and our data structure is
almost of the same size as the raw input. Compared with state-of-the-art
octree-based methods, our data structure significantly reduces the memory
footprint during the CNN training. As the input geometry features are more
compactly packed, CNN operations also run faster with our data structure. The
experiment shows that, under the same network structure, our method yields
comparable or better benchmarks compared to the state-of-the-art while it has
only one-third memory consumption. Such superior memory performance allows the
CNN to handle high-resolution shape analysis.</p>
</td>
    <td>
      
        Tree Based ANN 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/loncaric2018learning/">Learning Hash Codes Via Hamming Distance Targets</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning Hash Codes Via Hamming Distance Targets' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning Hash Codes Via Hamming Distance Targets' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Loncaric Martin, Liu Bowei, Weber Ryan</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Image Processing</td>
    <td>11</td>
    <td><p>We present a powerful new loss function and training scheme for learning
binary hash codes with any differentiable model and similarity function. Our
loss function improves over prior methods by using log likelihood loss on top
of an accurate approximation for the probability that two inputs fall within a
Hamming distance target. Our novel training scheme obtains a good estimate of
the true gradient by better sampling inputs and evaluating loss terms between
all pairs of inputs in each minibatch. To fully leverage the resulting hashes,
we use multi-indexing. We demonstrate that these techniques provide large
improvements to a similarity search tasks. We report the best results to date
on competitive information retrieval tasks for ImageNet and SIFT 1M, improving
MAP from 73% to 84% and reducing query cost by a factor of 2-8, respectively.</p>
</td>
    <td>
      
        Vector Indexing 
      
        Similarity Search 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/lam2018word2bits/">Word2bits - Quantized Word Vectors</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Word2bits - Quantized Word Vectors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Word2bits - Quantized Word Vectors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lam Maximilian</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>27</td>
    <td><p>Word vectors require significant amounts of memory and storage, posing issues
to resource limited devices like mobile phones and GPUs. We show that high
quality quantized word vectors using 1-2 bits per parameter can be learned by
introducing a quantization function into Word2Vec. We furthermore show that
training with the quantization function acts as a regularizer. We train word
vectors on English Wikipedia (2017) and evaluate them on standard word
similarity and analogy tasks and on question answering (SQuAD). Our quantized
word vectors not only take 8-16x less space than full precision (32 bit) word
vectors but also outperform them on word similarity tasks and question
answering.</p>
</td>
    <td>
      
        Quantization 
      
        Evaluation 
      
        Graph Based ANN 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/lin2018local/">Local Binary Pattern Networks</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Local Binary Pattern Networks' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Local Binary Pattern Networks' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lin et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Journal of Visual Communication and Image Representation</td>
    <td>78</td>
    <td><p>Memory and computation efficient deep learning architec- tures are crucial to
continued proliferation of machine learning capabili- ties to new platforms and
systems. Binarization of operations in convo- lutional neural networks has
shown promising results in reducing model size and computing efficiency. In
this paper, we tackle the problem us- ing a strategy different from the
existing literature by proposing local binary pattern networks or LBPNet, that
is able to learn and perform binary operations in an end-to-end fashion.
LBPNet1 uses local binary comparisons and random projection in place of
conventional convolu- tion (or approximation of convolution) operations. These
operations can be implemented efficiently on different platforms including
direct hard- ware implementation. We applied LBPNet and its variants on
standard benchmarks. The results are promising across benchmarks while provid-
ing an important means to improve memory and speed efficiency that is
particularly suited for small footprint devices and hardware accelerators.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/moulton2018maximally/">Maximally Consistent Sampling And The Jaccard Index Of Probability Distributions</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Maximally Consistent Sampling And The Jaccard Index Of Probability Distributions' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Maximally Consistent Sampling And The Jaccard Index Of Probability Distributions' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Moulton Ryan, Jiang Yunjiang</td> <!-- ðŸ”§ You were missing this -->
    <td>2018 IEEE International Conference on Data Mining (ICDM)</td>
    <td>15</td>
    <td><p>We introduce simple, efficient algorithms for computing a MinHash of a
probability distribution, suitable for both sparse and dense data, with
equivalent running times to the state of the art for both cases. The collision
probability of these algorithms is a new measure of the similarity of positive
vectors which we investigate in detail. We describe the sense in which this
collision probability is optimal for any Locality Sensitive Hash based on
sampling. We argue that this similarity measure is more useful for probability
distributions than the similarity pursued by other algorithms for weighted
MinHash, and is the natural generalization of the Jaccard index.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/dutta2018graph/">Graph Kernels Based On High Order Graphlet Parsing And Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Graph Kernels Based On High Order Graphlet Parsing And Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Graph Kernels Based On High Order Graphlet Parsing And Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Dutta Anjan, Sahbi Hichem</td> <!-- ðŸ”§ You were missing this -->
    <td>Pattern Recognition Letters</td>
    <td>5</td>
    <td><p>Graph-based methods are known to be successful in many machine learning and
pattern classification tasks. These methods consider semi-structured data as
graphs where nodes correspond to primitives (parts, interest points, segments,
etc.) and edges characterize the relationships between these primitives.
However, these non-vectorial graph data cannot be straightforwardly plugged
into off-the-shelf machine learning algorithms without a preliminary step of â€“
explicit/implicit â€“ graph vectorization and embedding. This embedding process
should be resilient to intra-class graph variations while being highly
discriminant. In this paper, we propose a novel high-order stochastic graphlet
embedding (SGE) that maps graphs into vector spaces. Our main contribution
includes a new stochastic search procedure that efficiently parses a given
graph and extracts/samples unlimitedly high-order graphlets. We consider these
graphlets, with increasing orders, to model local primitives as well as their
increasingly complex interactions. In order to build our graph representation,
we measure the distribution of these graphlets into a given graph, using
particular hash functions that efficiently assign sampled graphlets into
isomorphic sets with a very low probability of collision. When combined with
maximum margin classifiers, these graphlet-based representations have positive
impact on the performance of pattern comparison and recognition as corroborated
through extensive experiments using standard benchmark databases.</p>
</td>
    <td>
      
        Graph Based ANN 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/dutta2018when/">When Hashing Met Matching: Efficient Spatio-temporal Search For Ridesharing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=When Hashing Met Matching: Efficient Spatio-temporal Search For Ridesharing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=When Hashing Met Matching: Efficient Spatio-temporal Search For Ridesharing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Dutta Chinmoy</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>5</td>
    <td><p>Carpooling, or sharing a ride with other passengers, holds immense potential
for urban transportation. Ridesharing platforms enable such sharing of rides
using real-time data. Finding ride matches in real-time at urban scale is a
difficult combinatorial optimization task and mostly heuristic approaches are
applied. In this work, we mathematically model the problem as that of finding
near-neighbors and devise a novel efficient spatio-temporal search algorithm
based on the theory of locality sensitive hashing for Maximum Inner Product
Search (MIPS). The proposed algorithm can find \(k\) near-optimal potential
matches for every ride from a pool of \(n\) rides in time \(O(n^{1 + \rho} (k +
log n) log k)\) and space \(O(n^{1 + \rho} log k)\) for a small \(\rho &lt; 1\). Our
algorithm can be extended in several useful and interesting ways increasing its
practical appeal. Experiments with large NY yellow taxi trip datasets show that
our algorithm consistently outperforms state-of-the-art heuristic methods
thereby proving its practical applicability.</p>
</td>
    <td>
      
        AAAI 
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/douze2018link/">Link And Code: Fast Indexing With Graphs And Compact Regression Codes</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Link And Code: Fast Indexing With Graphs And Compact Regression Codes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Link And Code: Fast Indexing With Graphs And Compact Regression Codes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Douze Matthijs, Sablayrolles Alexandre, JÃ©gou HervÃ©</td> <!-- ðŸ”§ You were missing this -->
    <td>2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</td>
    <td>31</td>
    <td><p>Similarity search approaches based on graph walks have recently attained
outstanding speed-accuracy trade-offs, taking aside the memory requirements. In
this paper, we revisit these approaches by considering, additionally, the
memory constraint required to index billions of images on a single server. This
leads us to propose a method based both on graph traversal and compact
representations. We encode the indexed vectors using quantization and exploit
the graph structure to refine the similarity estimation.
  In essence, our method takes the best of these two worlds: the search
strategy is based on nested graphs, thereby providing high precision with a
relatively small set of comparisons. At the same time it offers a significant
memory compression. As a result, our approach outperforms the state of the art
on operating points considering 64-128 bytes per vector, as demonstrated by our
results on two billion-scale public benchmarks.</p>
</td>
    <td>
      
        CVPR 
      
        Large Scale Search 
      
        Similarity Search 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/zhang2018highly/">Highly-economized Multi-view Binary Compression For Scalable Image Clustering</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Highly-economized Multi-view Binary Compression For Scalable Image Clustering' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Highly-economized Multi-view Binary Compression For Scalable Image Clustering' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>49</td>
    <td><p>How to economically cluster large-scale multi-view images is a long-standing
problem in computer vision. To tackle this challenge, we introduce a novel
approach named Highly-economized Scalable Image Clustering (HSIC) that
radically surpasses conventional image clustering methods via binary
compression. We intuitively unify the binary representation learning and
efficient binary cluster structure learning into a joint framework. In
particular, common binary representations are learned by exploiting both
sharable and individual information across multiple views to capture their
underlying correlations. Meanwhile, cluster assignment with robust binary
centroids is also performed via effective discrete optimization under L21-norm
constraint. By this means, heavy continuous-valued Euclidean distance
computations can be successfully reduced by efficient binary XOR operations
during the clustering procedure. To our best knowledge, HSIC is the first
binary clustering work specifically designed for scalable multi-view image
clustering. Extensive experimental results on four large-scale image datasets
show that HSIC consistently outperforms the state-of-the-art approaches, whilst
significantly reducing computational time and memory footprint.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        Efficiency And Optimization 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/luo2018collaborative/">Collaborative Learning For Extremely Low Bit Asymmetric Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Collaborative Learning For Extremely Low Bit Asymmetric Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Collaborative Learning For Extremely Low Bit Asymmetric Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Luo et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Knowledge and Data Engineering</td>
    <td>14</td>
    <td><p>Hashing techniques are in great demand for a wide range of real-world
applications such as image retrieval and network compression. Nevertheless,
existing approaches could hardly guarantee a satisfactory performance with the
extremely low-bit (e.g., 4-bit) hash codes due to the severe information loss
and the shrink of the discrete solution space. In this paper, we propose a
novel \textit{Collaborative Learning} strategy that is tailored for generating
high-quality low-bit hash codes. The core idea is to jointly distill
bit-specific and informative representations for a group of pre-defined code
lengths. The learning of short hash codes among the group can benefit from the
manifold shared with other long codes, where multiple views from different hash
codes provide the supplementary guidance and regularization, making the
convergence faster and more stable. To achieve that, an asymmetric hashing
framework with two variants of multi-head embedding structures is derived,
termed as Multi-head Asymmetric Hashing (MAH), leading to great efficiency of
training and querying. Extensive experiments on three benchmark datasets have
been conducted to verify the superiority of the proposed MAH, and have shown
that the 8-bit hash codes generated by MAH achieve \(94.3%\) of the MAP (Mean
Average Precision (MAP)) score on the CIFAR-10 dataset, which significantly
surpasses the performance of the 48-bit codes by the state-of-the-arts in image
retrieval tasks.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/wang2018deep/">Deep Metric Learning By Online Soft Mining And Class-aware Attention</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Metric Learning By Online Soft Mining And Class-aware Attention' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Metric Learning By Online Soft Mining And Class-aware Attention' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>45</td>
    <td><p>Deep metric learning aims to learn a deep embedding that can capture the
semantic similarity of data points. Given the availability of massive training
samples, deep metric learning is known to suffer from slow convergence due to a
large fraction of trivial samples. Therefore, most existing methods generally
resort to sample mining strategies for selecting nontrivial samples to
accelerate convergence and improve performance. In this work, we identify two
critical limitations of the sample mining methods, and provide solutions for
both of them. First, previous mining methods assign one binary score to each
sample, i.e., dropping or keeping it, so they only selects a subset of relevant
samples in a mini-batch. Therefore, we propose a novel sample mining method,
called Online Soft Mining (OSM), which assigns one continuous score to each
sample to make use of all samples in the mini-batch. OSM learns extended
manifolds that preserve useful intraclass variances by focusing on more similar
positives. Second, the existing methods are easily influenced by outliers as
they are generally included in the mined subset. To address this, we introduce
Class-Aware Attention (CAA) that assigns little attention to abnormal data
samples. Furthermore, by combining OSM and CAA, we propose a novel weighted
contrastive loss to learn discriminative embeddings. Extensive experiments on
two fine-grained visual categorisation datasets and two video-based person
re-identification benchmarks show that our method significantly outperforms the
state-of-the-art.</p>
</td>
    <td>
      
        AAAI 
      
        DATASETS 
      
        Distance Metric Learning 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/do2018binary/">Binary Constrained Deep Hashing Network For Image Retrieval Without Manual Annotation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Binary Constrained Deep Hashing Network For Image Retrieval Without Manual Annotation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Binary Constrained Deep Hashing Network For Image Retrieval Without Manual Annotation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Do et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE Winter Conference on Applications of Computer Vision (WACV)</td>
    <td>9</td>
    <td><p>Learning compact binary codes for image retrieval task using deep neural
networks has attracted increasing attention recently. However, training deep
hashing networks for the task is challenging due to the binary constraints on
the hash codes, the similarity preserving property, and the requirement for a
vast amount of labelled images. To the best of our knowledge, none of the
existing methods has tackled all of these challenges completely in a unified
framework. In this work, we propose a novel end-to-end deep learning approach
for the task, in which the network is trained to produce binary codes directly
from image pixels without the need of manual annotation. In particular, to deal
with the non-smoothness of binary constraints, we propose a novel pairwise
constrained loss function, which simultaneously encodes the distances between
pairs of hash codes, and the binary quantization error. In order to train the
network with the proposed loss function, we propose an efficient parameter
learning algorithm. In addition, to provide similar / dissimilar training
images to train the network, we exploit 3D models reconstructed from unlabelled
images for automatic generation of enormous training image pairs. The extensive
experiments on image retrieval benchmark datasets demonstrate the improvements
of the proposed method over the state-of-the-art compact representation methods
on the image retrieval problem.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Neural Hashing 
      
        Quantization 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/do2018selective/">From Selective Deep Convolutional Features To Compact Binary Representations For Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=From Selective Deep Convolutional Features To Compact Binary Representations For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=From Selective Deep Convolutional Features To Compact Binary Representations For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Do et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>ACM Transactions on Multimedia Computing, Communications, and Applications</td>
    <td>30</td>
    <td><p>In the large-scale image retrieval task, the two most important requirements
are the discriminability of image representations and the efficiency in
computation and storage of representations. Regarding the former requirement,
Convolutional Neural Network (CNN) is proven to be a very powerful tool to
extract highly discriminative local descriptors for effective image search.
Additionally, in order to further improve the discriminative power of the
descriptors, recent works adopt fine-tuned strategies. In this paper, taking a
different approach, we propose a novel, computationally efficient, and
competitive framework. Specifically, we firstly propose various strategies to
compute masks, namely SIFT-mask, SUM-mask, and MAX-mask, to select a
representative subset of local convolutional features and eliminate redundant
features. Our in-depth analyses demonstrate that proposed masking schemes are
effective to address the burstiness drawback and improve retrieval accuracy.
Secondly, we propose to employ recent embedding and aggregating methods which
can significantly boost the feature discriminability. Regarding the computation
and storage efficiency, we include a hashing module to produce very compact
binary image representations. Extensive experiments on six image retrieval
benchmarks demonstrate that our proposed framework achieves the
state-of-the-art retrieval performances.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/misra2018bernoulli/">Bernoulli Embeddings For Graphs</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Bernoulli Embeddings For Graphs' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Bernoulli Embeddings For Graphs' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Misra Vinith, Bhatia Sumit</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>9</td>
    <td><p>Just as semantic hashing can accelerate information retrieval, binary valued
embeddings can significantly reduce latency in the retrieval of graphical data.
We introduce a simple but effective model for learning such binary vectors for
nodes in a graph. By imagining the embeddings as independent coin flips of
varying bias, continuous optimization techniques can be applied to the
approximate expected loss. Embeddings optimized in this fashion consistently
outperform the quantization of both spectral graph embeddings and various
learned real-valued embeddings, on both ranking and pre-ranking tasks for a
variety of datasets.</p>
</td>
    <td>
      
        AAAI 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Text Retrieval 
      
        Quantization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/schlegel2018hbst/">HBST: A Hamming Distance Embedding Binary Search Tree For Visual Place Recognition</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=HBST: A Hamming Distance Embedding Binary Search Tree For Visual Place Recognition' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=HBST: A Hamming Distance Embedding Binary Search Tree For Visual Place Recognition' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Schlegel Dominik, Grisetti Giorgio</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Robotics and Automation Letters</td>
    <td>52</td>
    <td><p>Reliable and efficient Visual Place Recognition is a major building block of
modern SLAM systems. Leveraging on our prior work, in this paper we present a
Hamming Distance embedding Binary Search Tree (HBST) approach for binary
Descriptor Matching and Image Retrieval. HBST allows for descriptor Search and
Insertion in logarithmic time by exploiting particular properties of binary
Feature descriptors. We support the idea behind our search structure with a
thorough analysis on the exploited descriptor properties and their effects on
completeness and complexity of search and insertion. To validate our claims we
conducted comparative experiments for HBST and several state-of-the-art methods
on a broad range of publicly available datasets. HBST is available as a compact
open-source C++ header-only library.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/tu2018object/">Object Detection Based Deep Unsupervised Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Object Detection Based Deep Unsupervised Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Object Detection Based Deep Unsupervised Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Tu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence</td>
    <td>10</td>
    <td><p>Recently, similarity-preserving hashing methods have been extensively studied
for large-scale image retrieval. Compared with unsupervised hashing, supervised
hashing methods for labeled data have usually better performance by utilizing
semantic label information. Intuitively, for unlabeled data, it will improve
the performance of unsupervised hashing methods if we can first mine some
supervised semantic â€˜label informationâ€™ from unlabeled data and then
incorporate the â€˜label informationâ€™ into the training process. Thus, in this
paper, we propose a novel Object Detection based Deep Unsupervised Hashing
method (ODDUH). Specifically, a pre-trained object detection model is utilized
to mining supervised â€˜label informationâ€™, which is used to guide the learning
process to generate high-quality hash codes.Extensive experiments on two public
datasets demonstrate that the proposed method outperforms the state-of-the-art
unsupervised hashing methods in the image retrieval task.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        IJCAI 
      
        Hashing Methods 
      
        Image Retrieval 
      
        AAAI 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/yu2018discriminative/">Discriminative Supervised Hashing For Cross-modal Similarity Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Discriminative Supervised Hashing For Cross-modal Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Discriminative Supervised Hashing For Cross-modal Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yu Jun, Wu Xiao-jun, Kittler Josef</td> <!-- ðŸ”§ You were missing this -->
    <td>Image and Vision Computing</td>
    <td>15</td>
    <td><p>With the advantage of low storage cost and high retrieval efficiency, hashing
techniques have recently been an emerging topic in cross-modal similarity
search. As multiple modal data reflect similar semantic content, many
researches aim at learning unified binary codes. However, discriminative
hashing features learned by these methods are not adequate. This results in
lower accuracy and robustness. We propose a novel hashing learning framework
which jointly performs classifier learning, subspace learning and matrix
factorization to preserve class-specific semantic content, termed
Discriminative Supervised Hashing (DSH), to learn the discrimative unified
binary codes for multi-modal data. Besides, reducing the loss of information
and preserving the non-linear structure of data, DSH non-linearly projects
different modalities into the common space in which the similarity among
heterogeneous data points can be measured. Extensive experiments conducted on
the three publicly available datasets demonstrate that the framework proposed
in this paper outperforms several state-of -the-art methods.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Similarity Search 
      
        Tools & Libraries 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/zhang2018zoom/">Zoom: Ssd-based Vector Search For Optimizing Accuracy, Latency And Memory</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Zoom: Ssd-based Vector Search For Optimizing Accuracy, Latency And Memory' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Zoom: Ssd-based Vector Search For Optimizing Accuracy, Latency And Memory' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang Minjia, He Yuxiong</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Circuits and Systems for Video Technology</td>
    <td>33</td>
    <td><p>With the advancement of machine learning and deep learning, vector search
becomes instrumental to many information retrieval systems, to search and find
best matches to user queries based on their semantic similarities.These online
services require the search architecture to be both effective with high
accuracy and efficient with low latency and memory footprint, which existing
work fails to offer. We develop, Zoom, a new vector search solution that
collaboratively optimizes accuracy, latency and memory based on a multiview
approach. (1) A â€œpreviewâ€ step generates a small set of good candidates,
leveraging compressed vectors in memory for reduced footprint and fast lookup.
(2) A â€œfullviewâ€ step on SSDs reranks those candidates with their full-length
vector, striking high accuracy. Our evaluation shows that, Zoom achieves an
order of magnitude improvements on efficiency while attaining equal or higher
accuracy, comparing with the state-of-the-art.</p>
</td>
    <td>
      
        Survey Paper 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/lessley2018data/">Data-parallel Hashing Techniques For GPU Architectures</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Data-parallel Hashing Techniques For GPU Architectures' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Data-parallel Hashing Techniques For GPU Architectures' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lessley Brenton</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Parallel and Distributed Systems</td>
    <td>33</td>
    <td><p>Hash tables are one of the most fundamental data structures for effectively
storing and accessing sparse data, with widespread usage in domains ranging
from computer graphics to machine learning. This study surveys the
state-of-the-art research on data-parallel hashing techniques for emerging
massively-parallel, many-core GPU architectures. Key factors affecting the
performance of different hashing schemes are discovered and used to suggest
best practices and pinpoint areas for further research.</p>
</td>
    <td>
      
        Survey Paper 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/zhang2018improved/">Improved Deep Hashing With Soft Pairwise Similarity For Multi-label Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Improved Deep Hashing With Soft Pairwise Similarity For Multi-label Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Improved Deep Hashing With Soft Pairwise Similarity For Multi-label Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Multimedia</td>
    <td>144</td>
    <td><p>Hash coding has been widely used in the approximate nearest neighbor search
for large-scale image retrieval. Recently, many deep hashing methods have been
proposed and shown largely improved performance over traditional
feature-learning-based methods. Most of these methods examine the pairwise
similarity on the semantic-level labels, where the pairwise similarity is
generally defined in a hard-assignment way. That is, the pairwise similarity is
â€˜1â€™ if they share no less than one class label and â€˜0â€™ if they do not share
any. However, such similarity definition cannot reflect the similarity ranking
for pairwise images that hold multiple labels. In this paper, a new deep
hashing method is proposed for multi-label image retrieval by re-defining the
pairwise similarity into an instance similarity, where the instance similarity
is quantified into a percentage based on the normalized semantic labels. Based
on the instance similarity, a weighted cross-entropy loss and a minimum mean
square error loss are tailored for loss-function construction, and are
efficiently used for simultaneous feature learning and hash coding. Experiments
on three popular datasets demonstrate that, the proposed method outperforms the
competing methods and achieves the state-of-the-art performance in multi-label
image retrieval.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Neural Hashing 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/lebedev2018impostor/">Impostor Networks For Fast Fine-grained Recognition</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Impostor Networks For Fast Fine-grained Recognition' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Impostor Networks For Fast Fine-grained Recognition' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lebedev Vadim, Babenko Artem, Lempitsky Victor</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)</td>
    <td>39</td>
    <td><p>In this work we introduce impostor networks, an architecture that allows to
perform fine-grained recognition with high accuracy and using a light-weight
convolutional network, making it particularly suitable for fine-grained
applications on low-power and non-GPU enabled platforms. Impostor networks
compensate for the lightness of its `backendâ€™ network by combining it with a
lightweight non-parametric classifier. The combination of a convolutional
network and such non-parametric classifier is trained in an end-to-end fashion.
Similarly to convolutional neural networks, impostor networks can fit
large-scale training datasets very well, while also being able to generalize to
new data points. At the same time, the bulk of computations within impostor
networks happen through nearest neighbor search in high-dimensions. Such search
can be performed efficiently on a variety of architectures including standard
CPUs, where deep convolutional networks are inefficient. In a series of
experiments with three fine-grained datasets, we show that impostor networks
are able to boost the classification accuracy of a moderate-sized convolutional
network considerably at a very small computational cost.</p>
</td>
    <td>
      
        ICCV 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/mohammadi2018multi/">Multi-reference Cosine: A New Approach To Text Similarity Measurement In Large Collections</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Multi-reference Cosine: A New Approach To Text Similarity Measurement In Large Collections' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Multi-reference Cosine: A New Approach To Text Similarity Measurement In Large Collections' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Mohammadi Hamid, Nikoukaran Amin</td> <!-- ðŸ”§ You were missing this -->
    <td>Journal of Big Data</td>
    <td>74</td>
    <td><p>The importance of an efficient and scalable document similarity detection
system is undeniable nowadays. Search engines need batch text similarity
measures to detect duplicated and near-duplicated web pages in their indexes in
order to prevent indexing a web page multiple times. Furthermore, in the
scoring phase, search engines need similarity measures to detect duplicated
contents on web pages so as to increase the quality of their results. In this
paper, a new approach to batch text similarity detection is proposed by
combining some ideas from dimensionality reduction techniques and information
gain theory. The new approach is focused on search engines need to detect
duplicated and near-duplicated web pages. The new approach is evaluated on the
NEWS20 dataset and the results show that the new approach is faster than the
cosine text similarity algorithm in terms of speed and performance. On top of
that, It is faster and more accurate than the other rival method, Simhash
similarity algorithm.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Evaluation 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/conway2018optimal/">Optimal Hashing In External Memory</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Optimal Hashing In External Memory' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Optimal Hashing In External Memory' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Conway Alex, Farach-colton Martin, Shilane Philip</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>6</td>
    <td><p>Hash tables are a ubiquitous class of dictionary data structures. However,
standard hash table implementations do not translate well into the external
memory model, because they do not incorporate locality for insertions.
  Iacono and Patracsu established an update/query tradeoff curve for external
hash tables: a hash table that performs insertions in \(O(\lambda/B)\) amortized
IOs requires \(Î©(log_\lambda N)\) expected IOs for queries, where \(N\) is
the number of items that can be stored in the data structure, \(B\) is the size
of a memory transfer, \(M\) is the size of memory, and \(\lambda\) is a tuning
parameter.
  They provide a hashing data structure that meets this curve for \(\lambda\)
that is \(Î©(loglog M + log_M N)\). Their data structure, which we call an
\defn{IP hash table}, is complicated and, to the best of our knowledge, has not
been implemented.
  In this paper, we present a new and much simpler optimal external memory hash
table, the \defn{Bundle of Arrays Hash Table} (BOA). BOAs are based on
size-tiered LSMs, a well-studied data structure, and are almost as easy to
implement. The BOA is optimal for a narrower range of \(\lambda\). However, the
simplicity of BOAs allows them to be readily modified to achieve the following
results:
  \begin{itemize}
  \item A new external memory data structure, the \defn{Bundle of Trees Hash
Table} (BOT), that matches the performance of the IP hash table, while
retaining some of the simplicity of the BOAs.
  \item The \defn{cache-oblivious Bundle of Trees Hash Table} (COBOT), the
first cache-oblivious hash table. This data structure matches the optimality of
BOTs and IP hash tables over the same range of \(\lambda\). \end{itemize}</p>
</td>
    <td>
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/royoletelier2018disambiguating/">Disambiguating Music Artists At Scale With Audio Metric Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Disambiguating Music Artists At Scale With Audio Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Disambiguating Music Artists At Scale With Audio Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Royo-letelier et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>5</td>
    <td><p>We address the problem of disambiguating large scale catalogs through the
definition of an unknown artist clustering task. We explore the use of metric
learning techniques to learn artist embeddings directly from audio, and using a
dedicated homonym artists dataset, we compare our method with a recent approach
that learn similar embeddings using artist classifiers. While both systems have
the ability to disambiguate unknown artists relying exclusively on audio, we
show that our system is more suitable in the case when enough audio data is
available for each artist in the train dataset. We also propose a new negative
sampling method for metric learning that takes advantage of side information
such as music genre during the learning phase and shows promising results for
the artist clustering task.</p>
</td>
    <td>
      
        DATASETS 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/christiani2018confirmation/">Confirmation Sampling For Exact Nearest Neighbor Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Confirmation Sampling For Exact Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Confirmation Sampling For Exact Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Christiani Tobias, Pagh Rasmus, Thorup Mikkel</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>6</td>
    <td><p>Locality-sensitive hashing (LSH), introduced by Indyk and Motwani in STOC
â€˜98, has been an extremely influential framework for nearest neighbor search in
high-dimensional data sets. While theoretical work has focused on the
approximate nearest neighbor problems, in practice LSH data structures with
suitably chosen parameters are used to solve the exact nearest neighbor problem
(with some error probability). Sublinear query time is often possible in
practice even for exact nearest neighbor search, intuitively because the
nearest neighbor tends to be significantly closer than other data points.
However, theory offers little advice on how to choose LSH parameters outside of
pre-specified worst-case settings.
  We introduce the technique of confirmation sampling for solving the exact
nearest neighbor problem using LSH. First, we give a general reduction that
transforms a sequence of data structures that each find the nearest neighbor
with a small, unknown probability, into a data structure that returns the
nearest neighbor with probability \(1-\delta\), using as few queries as possible.
Second, we present a new query algorithm for the LSH Forest data structure with
\(L\) trees that is able to return the exact nearest neighbor of a query point
within the same time bound as an LSH Forest of \(Î©(L)\) trees with internal
parameters specifically tuned to the query and data.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Tools & Libraries 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/chowdhury2018instance/">Instance-based Inductive Deep Transfer Learning By Cross-dataset Querying With Locality Sensitive Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Instance-based Inductive Deep Transfer Learning By Cross-dataset Querying With Locality Sensitive Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Instance-based Inductive Deep Transfer Learning By Cross-dataset Querying With Locality Sensitive Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Chowdhury Somnath Basu Roy, Annervaz K M, Dukkipati Ambedkar</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP (DeepLo 2019)</td>
    <td>5</td>
    <td><p>Supervised learning models are typically trained on a single dataset and the
performance of these models rely heavily on the size of the dataset, i.e.,
amount of data available with the ground truth. Learning algorithms try to
generalize solely based on the data that is presented with during the training.
In this work, we propose an inductive transfer learning method that can augment
learning models by infusing similar instances from different learning tasks in
the Natural Language Processing (NLP) domain. We propose to use instance
representations from a source dataset, \textit{without inheriting anything}
from the source learning model. Representations of the instances of
\textit{source} \&amp; \textit{target} datasets are learned, retrieval of relevant
source instances is performed using soft-attention mechanism and
\textit{locality sensitive hashing}, and then, augmented into the model during
training on the target dataset. Our approach simultaneously exploits the local
\textit{instance level information} as well as the macro statistical viewpoint
of the dataset. Using this approach we have shown significant improvements for
three major news classification datasets over the baseline. Experimental
evaluations also show that the proposed approach reduces dependency on labeled
data by a significant margin for comparable performance. With our proposed
cross dataset learning procedure we show that one can achieve
competitive/better performance than learning from a single dataset.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Evaluation 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/chiu2018learning/">Learning To Index For Nearest Neighbor Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning To Index For Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning To Index For Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Chiu Chih-yi, Prayoonwong Amorntip, Liao Yin-chih</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Pattern Analysis and Machine Intelligence</td>
    <td>24</td>
    <td><p>In this study, we present a novel ranking model based on learning
neighborhood relationships embedded in the index space. Given a query point,
conventional approximate nearest neighbor search calculates the distances to
the cluster centroids, before ranking the clusters from near to far based on
the distances. The data indexed in the top-ranked clusters are retrieved and
treated as the nearest neighbor candidates for the query. However, the loss of
quantization between the data and cluster centroids will inevitably harm the
search accuracy. To address this problem, the proposed model ranks clusters
based on their nearest neighbor probabilities rather than the query-centroid
distances. The nearest neighbor probabilities are estimated by employing neural
networks to characterize the neighborhood relationships, i.e., the density
function of nearest neighbors with respect to the query. The proposed
probability-based ranking can replace the conventional distance-based ranking
for finding candidate clusters, and the predicted probability can be used to
determine the data quantity to be retrieved from the candidate cluster. Our
experimental results demonstrated that the proposed ranking model could boost
the search performance effectively in billion-scale datasets.</p>
</td>
    <td>
      
        Large Scale Search 
      
        DATASETS 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/cheng2018crh/">CRH: A Simple Benchmark Approach To Continuous Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=CRH: A Simple Benchmark Approach To Continuous Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=CRH: A Simple Benchmark Approach To Continuous Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Cheng Miao, Tsoi Ah Chung</td> <!-- ðŸ”§ You were missing this -->
    <td>2015 IEEE Global Conference on Signal and Information Processing (GlobalSIP)</td>
    <td>6</td>
    <td><p>In recent years, the distinctive advancement of handling huge data promotes
the evolution of ubiquitous computing and analysis technologies. With the
constantly upward system burden and computational complexity, adaptive coding
has been a fascinating topic for pattern analysis, with outstanding
performance. In this work, a continuous hashing method, termed continuous
random hashing (CRH), is proposed to encode sequential data stream, while
ignorance of previously hashing knowledge is possible. Instead, a random
selection idea is adopted to adaptively approximate the differential encoding
patterns of data stream, e.g., streaming media, and iteration is avoided for
stepwise learning. Experimental results demonstrate our method is able to
provide outstanding performance, as a benchmark approach to continuous hashing.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/titus2018sig/">SIG-DB: Leveraging Homomorphic Encryption To Securely Interrogate Privately Held Genomic Databases</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=SIG-DB: Leveraging Homomorphic Encryption To Securely Interrogate Privately Held Genomic Databases' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=SIG-DB: Leveraging Homomorphic Encryption To Securely Interrogate Privately Held Genomic Databases' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Titus et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>PLOS Computational Biology</td>
    <td>13</td>
    <td><p>Genomic data are becoming increasingly valuable as we develop methods to
utilize the information at scale and gain a greater understanding of how
genetic information relates to biological function. Advances in synthetic
biology and the decreased cost of sequencing are increasing the amount of
privately held genomic data. As the quantity and value of private genomic data
grows, so does the incentive to acquire and protect such data, which creates a
need to store and process these data securely. We present an algorithm for the
Secure Interrogation of Genomic DataBases (SIG-DB). The SIG-DB algorithm
enables databases of genomic sequences to be searched with an encrypted query
sequence without revealing the query sequence to the Database Owner or any of
the database sequences to the Querier. SIG-DB is the first application of its
kind to take advantage of locality-sensitive hashing and homomorphic encryption
to allow generalized sequence-to-sequence comparisons of genomic data.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/ding2018mean/">Mean Local Group Average Precision (mlgap): A New Performance Metric For Hashing-based Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Mean Local Group Average Precision (mlgap): A New Performance Metric For Hashing-based Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Mean Local Group Average Precision (mlgap): A New Performance Metric For Hashing-based Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ding Pak Lun Kevin, Li Yikang, Li Baoxin</td> <!-- ðŸ”§ You were missing this -->
    <td>Encyclopedia of Database Systems</td>
    <td>8</td>
    <td><p>The research on hashing techniques for visual data is gaining increased
attention in recent years due to the need for compact representations
supporting efficient search/retrieval in large-scale databases such as online
images. Among many possibilities, Mean Average Precision(mAP) has emerged as
the dominant performance metric for hashing-based retrieval. One glaring
shortcoming of mAP is its inability in balancing retrieval accuracy and
utilization of hash codes: pushing a system to attain higher mAP will
inevitably lead to poorer utilization of the hash codes. Poor utilization of
the hash codes hinders good retrieval because of increased collision of samples
in the hash space. This means that a model giving a higher mAP values does not
necessarily do a better job in retrieval. In this paper, we introduce a new
metric named Mean Local Group Average Precision (mLGAP) for better evaluation
of the performance of hashing-based retrieval. The new metric provides a
retrieval performance measure that also reconciles the utilization of hash
codes, leading to a more practically meaningful performance metric than
conventional ones like mAP. To this end, we start by mathematical analysis of
the deficiencies of mAP for hashing-based retrieval. We then propose mLGAP and
show why it is more appropriate for hashing-based retrieval. Experiments on
image retrieval are used to demonstrate the effectiveness of the proposed
metric.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/li2018self/">Self-supervised Adversarial Hashing Networks For Cross-modal Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Self-supervised Adversarial Hashing Networks For Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Self-supervised Adversarial Hashing Networks For Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</td>
    <td>423</td>
    <td><p>Thanks to the success of deep learning, cross-modal retrieval has made
significant progress recently. However, there still remains a crucial
bottleneck: how to bridge the modality gap to further enhance the retrieval
accuracy. In this paper, we propose a self-supervised adversarial hashing
(\textbf{SSAH}) approach, which lies among the early attempts to incorporate
adversarial learning into cross-modal hashing in a self-supervised fashion. The
primary contribution of this work is that two adversarial networks are
leveraged to maximize the semantic correlation and consistency of the
representations between different modalities. In addition, we harness a
self-supervised semantic network to discover high-level semantic information in
the form of multi-label annotations. Such information guides the feature
learning process and preserves the modality relationships in both the common
semantic space and the Hamming space. Extensive experiments carried out on
three benchmark datasets validate that the proposed SSAH surpasses the
state-of-the-art methods.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        CVPR 
      
        Multimodal Retrieval 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/li2018dual/">Dual Asymmetric Deep Hashing Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Dual Asymmetric Deep Hashing Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Dual Asymmetric Deep Hashing Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Access</td>
    <td>16</td>
    <td><p>Due to the impressive learning power, deep learning has achieved a remarkable
performance in supervised hash function learning. In this paper, we propose a
novel asymmetric supervised deep hashing method to preserve the semantic
structure among different categories and generate the binary codes
simultaneously. Specifically, two asymmetric deep networks are constructed to
reveal the similarity between each pair of images according to their semantic
labels. The deep hash functions are then learned through two networks by
minimizing the gap between the learned features and discrete codes.
Furthermore, since the binary codes in the Hamming space also should keep the
semantic affinity existing in the original space, another asymmetric pairwise
loss is introduced to capture the similarity between the binary codes and
real-value features. This asymmetric loss not only improves the retrieval
performance, but also contributes to a quick convergence at the training phase.
By taking advantage of the two-stream deep structures and two types of
asymmetric pairwise functions, an alternating algorithm is designed to optimize
the deep features and high-quality binary codes efficiently. Experimental
results on three real-world datasets substantiate the effectiveness and
superiority of our approach as compared with state-of-the-art.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Alt 
      
        Neural Hashing 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/zhang2018sch/">SCH-GAN: Semi-supervised Cross-modal Hashing By Generative Adversarial Network</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=SCH-GAN: Semi-supervised Cross-modal Hashing By Generative Adversarial Network' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=SCH-GAN: Semi-supervised Cross-modal Hashing By Generative Adversarial Network' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang Jian, Peng Yuxin, Yuan Mingkuan</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Cybernetics</td>
    <td>124</td>
    <td><p>Cross-modal hashing aims to map heterogeneous multimedia data into a common
Hamming space, which can realize fast and flexible retrieval across different
modalities. Supervised cross-modal hashing methods have achieved considerable
progress by incorporating semantic side information. However, they mainly have
two limitations: (1) Heavily rely on large-scale labeled cross-modal training
data which are labor intensive and hard to obtain. (2) Ignore the rich
information contained in the large amount of unlabeled data across different
modalities, especially the margin examples that are easily to be incorrectly
retrieved, which can help to model the correlations. To address these problems,
in this paper we propose a novel Semi-supervised Cross-Modal Hashing approach
by Generative Adversarial Network (SCH-GAN). We aim to take advantage of GANâ€™s
ability for modeling data distributions to promote cross-modal hashing learning
in an adversarial way. The main contributions can be summarized as follows: (1)
We propose a novel generative adversarial network for cross-modal hashing. In
our proposed SCH-GAN, the generative model tries to select margin examples of
one modality from unlabeled data when giving a query of another modality. While
the discriminative model tries to distinguish the selected examples and true
positive examples of the query. These two models play a minimax game so that
the generative model can promote the hashing performance of discriminative
model. (2) We propose a reinforcement learning based algorithm to drive the
training of proposed SCH-GAN. The generative model takes the correlation score
predicted by discriminative model as a reward, and tries to select the examples
close to the margin to promote discriminative model by maximizing the margin
between positive and negative data. Experiments on 3 widely-used datasets
verify the effectiveness of our proposed approach.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/zhang2018relationnet2/">Relationnet2: Deep Comparison Columns For Few-shot Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Relationnet2: Deep Comparison Columns For Few-shot Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Relationnet2: Deep Comparison Columns For Few-shot Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>17</td>
    <td><p>Few-shot deep learning is a topical challenge area for scaling visual
recognition to open ended growth of unseen new classes with limited labeled
examples. A promising approach is based on metric learning, which trains a deep
embedding to support image similarity matching. Our insight is that effective
general purpose matching requires non-linear comparison of features at multiple
abstraction levels. We thus propose a new deep comparison network comprised of
embedding and relation modules that learn multiple non-linear distance metrics
based on different levels of features simultaneously. Furthermore, to reduce
over-fitting and enable the use of deeper embeddings, we represent images as
distributions rather than vectors via learning parameterized Gaussian noise
regularization. The resulting network achieves excellent performance on both
miniImageNet and tieredImageNet.</p>
</td>
    <td>
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/li2018hashtran/">Hashtran-dnn: A Framework For Enhancing Robustness Of Deep Neural Networks Against Adversarial Malware Samples</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hashtran-dnn: A Framework For Enhancing Robustness Of Deep Neural Networks Against Adversarial Malware Samples' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hashtran-dnn: A Framework For Enhancing Robustness Of Deep Neural Networks Against Adversarial Malware Samples' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>18</td>
    <td><p>Adversarial machine learning in the context of image processing and related
applications has received a large amount of attention. However, adversarial
machine learning, especially adversarial deep learning, in the context of
malware detection has received much less attention despite its apparent
importance. In this paper, we present a framework for enhancing the robustness
of Deep Neural Networks (DNNs) against adversarial malware samples, dubbed
Hashing Transformation Deep Neural Networks} (HashTran-DNN). The core idea is
to use hash functions with a certain locality-preserving property to transform
samples to enhance the robustness of DNNs in malware classification. The
framework further uses a Denoising Auto-Encoder (DAE) regularizer to
reconstruct the hash representations of samples, making the resulting DNN
classifiers capable of attaining the locality information in the latent space.
We experiment with two concrete instantiations of the HashTran-DNN framework to
classify Android malware. Experimental results show that four known attacks can
render standard DNNs useless in classifying Android malware, that known
defenses can at most defend three of the four attacks, and that HashTran-DNN
can effectively defend against all of the four attacks.</p>
</td>
    <td>
      
        Tools & Libraries 
      
        Hashing Methods 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/wu2018learning/">Learning Product Codebooks Using Vector Quantized Autoencoders For Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning Product Codebooks Using Vector Quantized Autoencoders For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning Product Codebooks Using Vector Quantized Autoencoders For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wu Hanwei, Flierl Markus</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE Global Conference on Signal and Information Processing (GlobalSIP)</td>
    <td>15</td>
    <td><p>Vector-Quantized Variational Autoencoders (VQ-VAE)[1] provide an unsupervised
model for learning discrete representations by combining vector quantization
and autoencoders. In this paper, we study the use of VQ-VAE for representation
learning for downstream tasks, such as image retrieval. We first describe the
VQ-VAE in the context of an information-theoretic framework. We show that the
regularization term on the learned representation is determined by the size of
the embedded codebook before the training and it affects the generalization
ability of the model. As a result, we introduce a hyperparameter to balance the
strength of the vector quantizer and the reconstruction error. By tuning the
hyperparameter, the embedded bottleneck quantizer is used as a regularizer that
forces the output of the encoder to share a constrained coding space such that
learned latent features preserve the similarity relations of the data space. In
addition, we provide a search range for finding the best hyperparameter.
Finally, we incorporate the product quantization into the bottleneck stage of
VQ-VAE and propose an end-to-end unsupervised learning model for the image
retrieval task. The product quantizer has the advantage of generating
large-size codebooks. Fast retrieval can be achieved by using the lookup tables
that store the distance between any pair of sub-codewords. State-of-the-art
retrieval results are achieved by the learned codebooks.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Tools & Libraries 
      
        Quantization 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/li2018sign/">Sign-full Random Projections</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Sign-full Random Projections' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Sign-full Random Projections' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li Ping</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>8</td>
    <td><p>The method of 1-bit (â€œsign-signâ€) random projections has been a popular tool
for efficient search and machine learning on large datasets. Given two \(D\)-dim
data vectors \(u\), \(v\in\mathbb{R}^D\), one can generate \(x = \sum_{i=1}^D u_i
r_i\), and \(y = \sum_{i=1}^D v_i r_i\), where \(r_i\sim N(0,1)\) iid. The
â€œcollision probabilityâ€ is \({Pr}\left(sgn(x)=sgn(y)\right) =
1-\frac{\cos^{-1}\rho}{\pi}\), where \(\rho = \rho(u,v)\) is the cosine
similarity.
  We develop â€œsign-fullâ€ random projections by estimating \(\rho\) from (e.g.,)
the expectation \(E(sgn(x)y)=\sqrt{\frac{2}{\pi}} \rho\), which can be further
substantially improved by normalizing \(y\). For nonnegative data, we recommend
an interesting estimator based on \(E\left(y_- 1<em>{x\geq 0} + y</em>+ 1_{x&lt;0}\right)\)
and its normalized version. The recommended estimator almost matches the
accuracy of the (computationally expensive) maximum likelihood estimator. At
high similarity (\(\rho\rightarrow1\)), the asymptotic variance of recommended
estimator is only \(\frac{4}{3\pi} \approx 0.4\) of the estimator for sign-sign
projections. At small \(k\) and high similarity, the improvement would be even
much more substantial.</p>
</td>
    <td>
      
        AAAI 
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/yan2018norm/">Norm-range Partition: A Universal Catalyst For LSH Based Maximum Inner Product Search (MIPS)</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Norm-range Partition: A Universal Catalyst For LSH Based Maximum Inner Product Search (MIPS)' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Norm-range Partition: A Universal Catalyst For LSH Based Maximum Inner Product Search (MIPS)' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yan et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>15</td>
    <td><p>Recently, locality sensitive hashing (LSH) was shown to be effective for MIPS
and several algorithms including \(L_2\)-ALSH, Sign-ALSH and Simple-LSH have been
proposed. In this paper, we introduce the norm-range partition technique, which
partitions the original dataset into sub-datasets containing items with similar
2-norms and builds hash index independently for each sub-dataset. We prove that
norm-range partition reduces the query processing complexity for all existing
LSH based MIPS algorithms under mild conditions. The key to performance
improvement is that norm-range partition allows to use smaller normalization
factor most sub-datasets. For efficient query processing, we also formulate a
unified framework to rank the buckets from the hash indexes of different
sub-datasets. Experiments on real datasets show that norm-range partition
significantly reduces the number of probed for LSH based MIPS algorithms when
achieving the same recall.</p>
</td>
    <td>
      
        AAAI 
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/chen2018distributed/">Distributed Collaborative Hashing And Its Applications In Ant Financial</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Distributed Collaborative Hashing And Its Applications In Ant Financial' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Distributed Collaborative Hashing And Its Applications In Ant Financial' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Chen et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</td>
    <td>7</td>
    <td><p>Collaborative filtering, especially latent factor model, has been popularly
used in personalized recommendation. Latent factor model aims to learn user and
item latent factors from user-item historic behaviors. To apply it into real
big data scenarios, efficiency becomes the first concern, including offline
model training efficiency and online recommendation efficiency. In this paper,
we propose a Distributed Collaborative Hashing (DCH) model which can
significantly improve both efficiencies. Specifically, we first propose a
distributed learning framework, following the state-of-the-art parameter server
paradigm, to learn the offline collaborative model. Our model can be learnt
efficiently by distributedly computing subgradients in minibatches on workers
and updating model parameters on servers asynchronously. We then adopt hashing
technique to speedup the online recommendation procedure. Recommendation can be
quickly made through exploiting lookup hash tables. We conduct thorough
experiments on two real large-scale datasets. The experimental results
demonstrate that, comparing with the classic and state-of-the-art (distributed)
latent factor models, DCH has comparable performance in terms of recommendation
accuracy but has both fast convergence speed in offline model training
procedure and realtime efficiency in online recommendation procedure.
Furthermore, the encouraging performance of DCH is also shown for several
real-world applications in Ant Financial.</p>
</td>
    <td>
      
        KDD 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Alt 
      
        Recommender Systems 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/tissier2018near/">Near-lossless Binarization Of Word Embeddings</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Near-lossless Binarization Of Word Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Near-lossless Binarization Of Word Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Tissier Julien, Gravier Christophe, Habrard Amaury</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>43</td>
    <td><p>Word embeddings are commonly used as a starting point in many NLP models to
achieve state-of-the-art performances. However, with a large vocabulary and
many dimensions, these floating-point representations are expensive both in
terms of memory and calculations which makes them unsuitable for use on
low-resource devices. The method proposed in this paper transforms real-valued
embeddings into binary embeddings while preserving semantic information,
requiring only 128 or 256 bits for each vector. This leads to a small memory
footprint and fast vector operations. The model is based on an autoencoder
architecture, which also allows to reconstruct original vectors from the binary
ones. Experimental results on semantic similarity, text classification and
sentiment analysis tasks show that the binarization of word embeddings only
leads to a loss of ~2% in accuracy while vector size is reduced by 97%.
Furthermore, a top-k benchmark demonstrates that using these binary vectors is
30 times faster than using real-valued vectors.</p>
</td>
    <td>
      
        AAAI 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/charikar2018multi/">Multi-resolution Hashing For Fast Pairwise Summations</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Multi-resolution Hashing For Fast Pairwise Summations' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Multi-resolution Hashing For Fast Pairwise Summations' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Charikar Moses, Siminelakis Paris</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE 60th Annual Symposium on Foundations of Computer Science (FOCS)</td>
    <td>5</td>
    <td><p>A basic computational primitive in the analysis of massive datasets is
summing simple functions over a large number of objects. Modern applications
pose an additional challenge in that such functions often depend on a parameter
vector \(y\) (query) that is unknown a priori. Given a set of points \(X\subset
\mathbb{R}^{d}\) and a pairwise function \(w:\mathbb{R}^{d}\times
\mathbb{R}^{d}\to [0,1]\), we study the problem of designing a data-structure
that enables sublinear-time approximation of the summation
\(Z_{w}(y)=\frac{1}{|X|}\sum_{x\in X}w(x,y)\) for any query \(y\in
\mathbb{R}^{d}\). By combining ideas from Harmonic Analysis (partitions of unity
and approximation theory) with Hashing-Based-Estimators [Charikar, Siminelakis
FOCSâ€™17], we provide a general framework for designing such data structures
through hashing that reaches far beyond what previous techniques allowed.
  A key design principle is a collection of \(T\geq 1\) hashing schemes with
collision probabilities \(p_{1},\ldots, p_{T}\) such that \(\sup_{t\in
[T]}\{p_{t}(x,y)\} = \Theta(\sqrt{w(x,y)})\). This leads to a data-structure
that approximates \(Z_{w}(y)\) using a sub-linear number of samples from each
hash family. Using this new framework along with Distance Sensitive Hashing
[Aumuller, Christiani, Pagh, Silvestri PODSâ€™18], we show that such a collection
can be constructed and evaluated efficiently for any log-convex function
\(w(x,y)=e^{\phi(\langle x,y\rangle)}\) of the inner product on the unit sphere
\(x,y\in \mathcal{S}^{d-1}\).
  Our method leads to data structures with sub-linear query time that
significantly improve upon random sampling and can be used for Kernel Density
or Partition Function Estimation. We provide extensions of our result from the
sphere to \(\mathbb{R}^{d}\) and from scalar functions to vector functions.</p>
</td>
    <td>
      
        DATASETS 
      
        Tools & Libraries 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/charikar2018hashing/">Hashing-based-estimators For Kernel Density In High Dimensions</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hashing-based-estimators For Kernel Density In High Dimensions' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hashing-based-estimators For Kernel Density In High Dimensions' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Charikar Moses, Siminelakis Paris</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 IEEE 58th Annual Symposium on Foundations of Computer Science (FOCS)</td>
    <td>51</td>
    <td><p>Given a set of points \(P\subset \mathbb{R}^{d}\) and a kernel \(k\), the Kernel
Density Estimate at a point \(x\in\mathbb{R}^{d}\) is defined as
\(\mathrm{KDE}<em>{P}(x)=\frac{1}{|P|}\sum</em>{y\in P} k(x,y)\). We study the problem
of designing a data structure that given a data set \(P\) and a kernel function,
returns <em>approximations to the kernel density</em> of a query point in <em>sublinear
time</em>. We introduce a class of unbiased estimators for kernel density
implemented through locality-sensitive hashing, and give general theorems
bounding the variance of such estimators. These estimators give rise to
efficient data structures for estimating the kernel density in high dimensions
for a variety of commonly used kernels. Our work is the first to provide
data-structures with theoretical guarantees that improve upon simple random
sampling in high dimensions.</p>
</td>
    <td>
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/zhang2018semantic/">Semantic Cluster Unary Loss For Efficient Deep Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Semantic Cluster Unary Loss For Efficient Deep Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Semantic Cluster Unary Loss For Efficient Deep Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang Shifeng, Li Jianmin, Zhang Bo</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Image Processing</td>
    <td>13</td>
    <td><p>Hashing method maps similar data to binary hashcodes with smaller hamming
distance, which has received a broad attention due to its low storage cost and
fast retrieval speed. With the rapid development of deep learning, deep hashing
methods have achieved promising results in efficient information retrieval.
Most of the existing deep hashing methods adopt pairwise or triplet losses to
deal with similarities underlying the data, but the training is difficult and
less efficient because \(O(n^2)\) data pairs and \(O(n^3)\) triplets are involved.
To address these issues, we propose a novel deep hashing algorithm with unary
loss which can be trained very efficiently. We first of all introduce a Unary
Upper Bound of the traditional triplet loss, thus reducing the complexity to
\(O(n)\) and bridging the classification-based unary loss and the triplet loss.
Second, we propose a novel Semantic Cluster Deep Hashing (SCDH) algorithm by
introducing a modified Unary Upper Bound loss, named Semantic Cluster Unary
Loss (SCUL). The resultant hashcodes form several compact clusters, which means
hashcodes in the same cluster have similar semantic information. We also
demonstrate that the proposed SCDH is easy to be extended to semi-supervised
settings by incorporating the state-of-the-art semi-supervised learning
algorithms. Experiments on large-scale datasets show that the proposed method
is superior to state-of-the-art hashing algorithms.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        Efficiency And Optimization 
      
        Neural Hashing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/liu2018adversarial/">Adversarial Binary Coding For Efficient Person Re-identification</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Adversarial Binary Coding For Efficient Person Re-identification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Adversarial Binary Coding For Efficient Person Re-identification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE International Conference on Multimedia and Expo (ICME)</td>
    <td>36</td>
    <td><p>Person re-identification (ReID) aims at matching persons across different
views/scenes. In addition to accuracy, the matching efficiency has received
more and more attention because of demanding applications using large-scale
data. Several binary coding based methods have been proposed for efficient
ReID, which either learn projections to map high-dimensional features to
compact binary codes, or directly adopt deep neural networks by simply
inserting an additional fully-connected layer with tanh-like activations.
However, the former approach requires time-consuming hand-crafted feature
extraction and complicated (discrete) optimizations; the latter lacks the
necessary discriminative information greatly due to the straightforward
activation functions. In this paper, we propose a simple yet effective
framework for efficient ReID inspired by the recent advances in adversarial
learning. Specifically, instead of learning explicit projections or adding
fully-connected mapping layers, the proposed Adversarial Binary Coding (ABC)
framework guides the extraction of binary codes implicitly and effectively. The
discriminability of the extracted codes is further enhanced by equipping the
ABC with a deep triplet network for the ReID task. More importantly, the ABC
and triplet network are simultaneously optimized in an end-to-end manner.
Extensive experiments on three large-scale ReID benchmarks demonstrate the
superiority of our approach over the state-of-the-art methods.</p>
</td>
    <td>
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Tools & Libraries 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/magliani2018efficient/">Efficient Nearest Neighbors Search For Large-scale Landmark Recognition</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Efficient Nearest Neighbors Search For Large-scale Landmark Recognition' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Efficient Nearest Neighbors Search For Large-scale Landmark Recognition' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Magliani Federico, Fontanini Tomaso, Prati Andrea</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>8</td>
    <td><p>The problem of landmark recognition has achieved excellent results in
small-scale datasets. When dealing with large-scale retrieval, issues that were
irrelevant with small amount of data, quickly become fundamental for an
efficient retrieval phase. In particular, computational time needs to be kept
as low as possible, whilst the retrieval accuracy has to be preserved as much
as possible. In this paper we propose a novel multi-index hashing method called
Bag of Indexes (BoI) for Approximate Nearest Neighbors (ANN) search. It allows
to drastically reduce the query time and outperforms the accuracy results
compared to the state-of-the-art methods for large-scale landmark recognition.
It has been demonstrated that this family of algorithms can be applied on
different embedding techniques like VLAD and R-MAC obtaining excellent results
in very short times on different public datasets: Holidays+Flickr1M, Oxford105k
and Paris106k.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Similarity Search 
      
        Vector Indexing 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/cao2018deep/">Deep Priority Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Priority Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Priority Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Cao et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 26th ACM international conference on Multimedia</td>
    <td>33</td>
    <td><p>Deep hashing enables image retrieval by end-to-end learning of deep
representations and hash codes from training data with pairwise similarity
information. Subject to the distribution skewness underlying the similarity
information, most existing deep hashing methods may underperform for imbalanced
data due to misspecified loss functions. This paper presents Deep Priority
Hashing (DPH), an end-to-end architecture that generates compact and balanced
hash codes in a Bayesian learning framework. The main idea is to reshape the
standard cross-entropy loss for similarity-preserving learning such that it
down-weighs the loss associated to highly-confident pairs. This idea leads to a
novel priority cross-entropy loss, which prioritizes the training on uncertain
pairs over confident pairs. Also, we propose another priority quantization
loss, which prioritizes hard-to-quantize examples for generation of nearly
lossless hash codes. Extensive experiments demonstrate that DPH can generate
high-quality hash codes and yield state-of-the-art image retrieval results on
three datasets, ImageNet, NUS-WIDE, and MS-COCO.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Neural Hashing 
      
        Quantization 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/cakir2018hashing/">Hashing With Binary Matrix Pursuit</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hashing With Binary Matrix Pursuit' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hashing With Binary Matrix Pursuit' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Cakir Fatih, He Kun, Sclaroff Stan</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>31</td>
    <td><p>We propose theoretical and empirical improvements for two-stage hashing
methods. We first provide a theoretical analysis on the quality of the binary
codes and show that, under mild assumptions, a residual learning scheme can
construct binary codes that fit any neighborhood structure with arbitrary
accuracy. Secondly, we show that with high-capacity hash functions such as
CNNs, binary code inference can be greatly simplified for many standard
neighborhood definitions, yielding smaller optimization problems and more
robust codes. Incorporating our findings, we propose a novel two-stage hashing
method that significantly outperforms previous hashing studies on widely used
image retrieval benchmarks.</p>
</td>
    <td>
      
        Compact Codes 
      
        Image Retrieval 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/cao2018end/">End-to-end Latent Fingerprint Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=End-to-end Latent Fingerprint Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=End-to-end Latent Fingerprint Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Cao et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Information Forensics and Security</td>
    <td>65</td>
    <td><p>Latent fingerprints are one of the most important and widely used sources of
evidence in law enforcement and forensic agencies. Yet the performance of the
state-of-the-art latent recognition systems is far from satisfactory, and they
often require manual markups to boost the latent search performance. Further,
the COTS systems are proprietary and do not output the true comparison scores
between a latent and reference prints to conduct quantitative evidential
analysis. We present an end-to-end latent fingerprint search system, including
automated region of interest (ROI) cropping, latent image preprocessing,
feature extraction, feature comparison , and outputs a candidate list. Two
separate minutiae extraction models provide complementary minutiae templates.
To compensate for the small number of minutiae in small area and poor quality
latents, a virtual minutiae set is generated to construct a texture template. A
96-dimensional descriptor is extracted for each minutia from its neighborhood.
For computational efficiency, the descriptor length for virtual minutiae is
further reduced to 16 using product quantization. Our end-to-end system is
evaluated on three latent databases: NIST SD27 (258 latents); MSP (1,200
latents), WVU (449 latents) and N2N (10,000 latents) against a background set
of 100K rolled prints, which includes the true rolled mates of the latents with
rank-1 retrieval rates of 65.7%, 69.4%, 65.5%, and 7.6% respectively. A
multi-core solution implemented on 24 cores obtains 1ms per latent to rolled
comparison.</p>
</td>
    <td>
      
        Quantization 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/qiu2018deep/">Deep Semantic Hashing With Generative Adversarial Networks</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Semantic Hashing With Generative Adversarial Networks' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Semantic Hashing With Generative Adversarial Networks' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Qiu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval</td>
    <td>97</td>
    <td><p>Hashing has been a widely-adopted technique for nearest neighbor search in
large-scale image retrieval tasks. Recent research has shown that leveraging
supervised information can lead to high quality hashing. However, the cost of
annotating data is often an obstacle when applying supervised hashing to a new
domain. Moreover, the results can suffer from the robustness problem as the
data at training and test stage could come from similar but different
distributions. This paper studies the exploration of generating synthetic data
through semi-supervised generative adversarial networks (GANs), which leverages
largely unlabeled and limited labeled training data to produce highly
compelling data with intrinsic invariance and global coherence, for better
understanding statistical structures of natural data. We demonstrate that the
above two limitations can be well mitigated by applying the synthetic data for
hashing. Specifically, a novel deep semantic hashing with GANs (DSH-GANs) is
presented, which mainly consists of four components: a deep convolution neural
networks (CNN) for learning image representations, an adversary stream to
distinguish synthetic images from real ones, a hash stream for encoding image
representations to hash codes and a classification stream. The whole
architecture is trained end-to-end by jointly optimizing three losses, i.e.,
adversarial loss to correct label of synthetic or real for each sample, triplet
ranking loss to preserve the relative similarity ordering in the input
real-synthetic triplets and classification loss to classify each sample
accurately. Extensive experiments conducted on both CIFAR-10 and NUS-WIDE image
benchmarks validate the capability of exploiting synthetic images for hashing.
Our framework also achieves superior results when compared to state-of-the-art
deep hash models.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        TACL 
      
        Text Retrieval 
      
        Neural Hashing 
      
        SIGIR 
      
        Tools & Libraries 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/cakaloglu2018text/">Text Embeddings For Retrieval From A Large Knowledge Base</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Text Embeddings For Retrieval From A Large Knowledge Base' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Text Embeddings For Retrieval From A Large Knowledge Base' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Cakaloglu Tolgahan, Szegedy Christian, Xu Xiaowei</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>6</td>
    <td><p>Text embedding representing natural language documents in a semantic vector
space can be used for document retrieval using nearest neighbor lookup. In
order to study the feasibility of neural models specialized for retrieval in a
semantically meaningful way, we suggest the use of the Stanford Question
Answering Dataset (SQuAD) in an open-domain question answering context, where
the first task is to find paragraphs useful for answering a given question.
First, we compare the quality of various text-embedding methods on the
performance of retrieval and give an extensive empirical comparison on the
performance of various non-augmented base embedding with, and without IDF
weighting. Our main results are that by training deep residual neural models,
specifically for retrieval purposes, can yield significant gains when it is
used to augment existing embeddings. We also establish that deeper models are
superior to this task. The best base baseline embeddings augmented by our
learned neural approach improves the top-1 paragraph recall of the system by
14%.</p>
</td>
    <td>
      
        Graph Based ANN 
      
        Text Retrieval 
      
        Evaluation 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/woodbridge2018detecting/">Detecting Homoglyph Attacks With A Siamese Neural Network</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Detecting Homoglyph Attacks With A Siamese Neural Network' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Detecting Homoglyph Attacks With A Siamese Neural Network' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Woodbridge et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2018 IEEE Security and Privacy Workshops (SPW)</td>
    <td>34</td>
    <td><p>A homoglyph (name spoofing) attack is a common technique used by adversaries
to obfuscate file and domain names. This technique creates process or domain
names that are visually similar to legitimate and recognized names. For
instance, an attacker may create malware with the name svch0st.exe so that in a
visual inspection of running processes or a directory listing, the process or
file name might be mistaken as the Windows system process svchost.exe. There
has been limited published research on detecting homoglyph attacks. Current
approaches rely on string comparison algorithms (such as Levenshtein distance)
that result in computationally heavy solutions with a high number of false
positives. In addition, there is a deficiency in the number of publicly
available datasets for reproducible research, with most datasets focused on
phishing attacks, in which homoglyphs are not always used. This paper presents
a fundamentally different solution to this problem using a Siamese
convolutional neural network (CNN). Rather than leveraging similarity based on
character swaps and deletions, this technique uses a learned metric on strings
rendered as images: a CNN learns features that are optimized to detect visual
similarity of the rendered strings. The trained model is used to convert
thousands of potentially targeted process or domain names to feature vectors.
These feature vectors are indexed using randomized KD-Trees to make similarity
searches extremely fast with minimal computational processing. This technique
shows a considerable 13% to 45% improvement over baseline techniques in terms
of area under the receiver operating characteristic curve (ROC AUC). In
addition, we provide both code and data to further future research.</p>
</td>
    <td>
      
        Tree Based ANN 
      
        DATASETS 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/wu2018cycle/">Cycle-consistent Deep Generative Hashing For Cross-modal Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Cycle-consistent Deep Generative Hashing For Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Cycle-consistent Deep Generative Hashing For Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wu Lin, Wang Yang, Shao Ling</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Image Processing</td>
    <td>189</td>
    <td><p>In this paper, we propose a novel deep generative approach to cross-modal
retrieval to learn hash functions in the absence of paired training samples
through the cycle consistency loss. Our proposed approach employs adversarial
training scheme to lean a couple of hash functions enabling translation between
modalities while assuming the underlying semantic relationship. To induce the
hash codes with semantics to the input-output pair, cycle consistency loss is
further proposed upon the adversarial training to strengthen the correlations
between inputs and corresponding outputs. Our approach is generative to learn
hash functions such that the learned hash codes can maximally correlate each
input-output correspondence, meanwhile can also regenerate the inputs so as to
minimize the information loss. The learning to hash embedding is thus performed
to jointly optimize the parameters of the hash functions across modalities as
well as the associated generative models. Extensive experiments on a variety of
large-scale cross-modal data sets demonstrate that our proposed method achieves
better retrieval results than the state-of-the-arts.</p>
</td>
    <td>
      
        Multimodal Retrieval 
      
        Hashing Methods 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/bhunia2018texture/">Texture Synthesis Guided Deep Hashing For Texture Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Texture Synthesis Guided Deep Hashing For Texture Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Texture Synthesis Guided Deep Hashing For Texture Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Bhunia et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE Winter Conference on Applications of Computer Vision (WACV)</td>
    <td>17</td>
    <td><p>With the large-scale explosion of images and videos over the internet,
efficient hashing methods have been developed to facilitate memory and time
efficient retrieval of similar images. However, none of the existing works uses
hashing to address texture image retrieval mostly because of the lack of
sufficiently large texture image databases. Our work addresses this problem by
developing a novel deep learning architecture that generates binary hash codes
for input texture images. For this, we first pre-train a Texture Synthesis
Network (TSN) which takes a texture patch as input and outputs an enlarged view
of the texture by injecting newer texture content. Thus it signifies that the
TSN encodes the learnt texture specific information in its intermediate layers.
In the next stage, a second network gathers the multi-scale feature
representations from the TSNâ€™s intermediate layers using channel-wise
attention, combines them in a progressive manner to a dense continuous
representation which is finally converted into a binary hash code with the help
of individual and pairwise label information. The new enlarged texture patches
also help in data augmentation to alleviate the problem of insufficient texture
data and are used to train the second stage of the network. Experiments on
three public texture image retrieval datasets indicate the superiority of our
texture synthesis guided hashing approach over current state-of-the-art
methods.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Neural Hashing 
      
        Similarity Search 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/song2018self/">Self-supervised Video Hashing With Hierarchical Binary Auto-encoder</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Self-supervised Video Hashing With Hierarchical Binary Auto-encoder' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Self-supervised Video Hashing With Hierarchical Binary Auto-encoder' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Song et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Image Processing</td>
    <td>165</td>
    <td><p>Existing video hash functions are built on three isolated stages: frame
pooling, relaxed learning, and binarization, which have not adequately explored
the temporal order of video frames in a joint binary optimization model,
resulting in severe information loss. In this paper, we propose a novel
unsupervised video hashing framework dubbed Self-Supervised Video Hashing
(SSVH), that is able to capture the temporal nature of videos in an end-to-end
learning-to-hash fashion. We specifically address two central problems: 1) how
to design an encoder-decoder architecture to generate binary codes for videos;
and 2) how to equip the binary codes with the ability of accurate video
retrieval. We design a hierarchical binary autoencoder to model the temporal
dependencies in videos with multiple granularities, and embed the videos into
binary codes with less computations than the stacked architecture. Then, we
encourage the binary codes to simultaneously reconstruct the visual content and
neighborhood structure of the videos. Experiments on two real-world datasets
(FCVID and YFCC) show that our SSVH method can significantly outperform the
state-of-the-art methods and achieve the currently best performance on the task
of unsupervised video retrieval.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/massarelli2018safe/">SAFE: Self-attentive Function Embeddings For Binary Similarity</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=SAFE: Self-attentive Function Embeddings For Binary Similarity' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=SAFE: Self-attentive Function Embeddings For Binary Similarity' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Massarelli et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>155</td>
    <td><p>The binary similarity problem consists in determining if two functions are
similar by only considering their compiled form. Advanced techniques for binary
similarity recently gained momentum as they can be applied in several fields,
such as copyright disputes, malware analysis, vulnerability detection, etc.,
and thus have an immediate practical impact. Current solutions compare
functions by first transforming their binary code in multi-dimensional vector
representations (embeddings), and then comparing vectors through simple and
efficient geometric operations. However, embeddings are usually derived from
binary code using manual feature extraction, that may fail in considering
important function characteristics, or may consider features that are not
important for the binary similarity problem. In this paper we propose SAFE, a
novel architecture for the embedding of functions based on a self-attentive
neural network. SAFE works directly on disassembled binary functions, does not
require manual feature extraction, is computationally more efficient than
existing solutions (i.e., it does not incur in the computational overhead of
building or manipulating control flow graphs), and is more general as it works
on stripped binaries and on multiple architectures. We report the results from
a quantitative and qualitative analysis that show how SAFE provides a
noticeable performance improvement with respect to previous solutions.
Furthermore, we show how clusters of our embedding vectors are closely related
to the semantic of the implemented algorithms, paving the way for further
interesting applications (e.g. semantic-based binary function search).</p>
</td>
    <td>
      
        Compact Codes 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/belyy2018memoir/">MEMOIR: Multi-class Extreme Classification With Inexact Margin</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=MEMOIR: Multi-class Extreme Classification With Inexact Margin' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=MEMOIR: Multi-class Extreme Classification With Inexact Margin' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Belyy Anton, Sholokhov Aleksei</td> <!-- ðŸ”§ You were missing this -->
    <td>Electronic Journal of Statistics</td>
    <td>13</td>
    <td><p>Multi-class classification with a very large number of classes, or extreme
classification, is a challenging problem from both statistical and
computational perspectives. Most of the classical approaches to multi-class
classification, including one-vs-rest or multi-class support vector machines,
require the exact estimation of the classifierâ€™s margin, at both the training
and the prediction steps making them intractable in extreme classification
scenarios. In this paper, we study the impact of computing an approximate
margin using nearest neighbor (ANN) search structures combined with
locality-sensitive hashing (LSH). This approximation allows to dramatically
reduce both the training and the prediction time without a significant loss in
performance. We theoretically prove that this approximation does not lead to a
significant loss of the risk of the model and provide empirical evidence over
five publicly available large scale datasets, showing that the proposed
approach is highly competitive with respect to state-of-the-art approaches on
time, memory and performance measures.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Evaluation 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/beierle2018do/">Do You Like What I Like? Similarity Estimation In Proximity-based Mobile Social Networks</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Do You Like What I Like? Similarity Estimation In Proximity-based Mobile Social Networks' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Do You Like What I Like? Similarity Estimation In Proximity-based Mobile Social Networks' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Beierle Felix</td> <!-- ðŸ”§ You were missing this -->
    <td>2018 17th IEEE International Conference On Trust, Security And Privacy In Computing And Communications/ 12th IEEE International Conference On Big Data Science And Engineering (TrustCom/BigDataSE)</td>
    <td>8</td>
    <td><p>While existing social networking services tend to connect people who know
each other, people show a desire to also connect to yet unknown people in
physical proximity. Existing research shows that people tend to connect to
similar people. Utilizing technology in order to stimulate human interaction
between strangers, we consider the scenario of two strangers meeting. On the
example of similarity in musical taste, we develop a solution for the problem
of similarity estimation in proximity-based mobile social networks. We show
that a single exchange of a probabilistic data structure between two devices
can closely estimate the similarity of two users - without the need to contact
a third-party server.We introduce metrics for fast and space-efficient
approximation of the Dice coefficient of two multisets - based on the
comparison of two Counting Bloom Filters or two Count-Min Sketches. Our
analysis shows that utilizing a single hash function minimizes the error when
comparing these probabilistic data structures. The size that should be chosen
for the data structure depends on the expected average number of unique input
elements. Using real user data, we show that a Counting Bloom Filter with a
single hash function and a length of 128 is sufficient to accurately estimate
the similarity between two multisets representing the musical tastes of two
users. Our approach is generalizable for any other similarity estimation of
frequencies represented as multisets.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/rubinstein2018hardness/">Hardness Of Approximate Nearest Neighbor Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hardness Of Approximate Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hardness Of Approximate Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Rubinstein Aviad</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 50th Annual ACM SIGACT Symposium on Theory of Computing</td>
    <td>74</td>
    <td><p>We prove conditional near-quadratic running time lower bounds for approximate
Bichromatic Closest Pair with Euclidean, Manhattan, Hamming, or edit distance.
Specifically, unless the Strong Exponential Time Hypothesis (SETH) is false,
for every \(\delta&gt;0\) there exists a constant \(\epsilon&gt;0\) such that computing a
\((1+\epsilon)\)-approximation to the Bichromatic Closest Pair requires
\(n^{2-\delta}\) time. In particular, this implies a near-linear query time for
Approximate Nearest Neighbor search with polynomial preprocessing time.
  Our reduction uses the Distributed PCP framework of [ARWâ€™17], but obtains
improved efficiency using Algebraic Geometry (AG) codes. Efficient PCPs from AG
codes have been constructed in other settings before [BKKMSâ€™16, BCGRSâ€™17], but
our construction is the first to yield new hardness results.</p>
</td>
    <td>
      
        Tools & Libraries 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/zhang2018hierarchical/">Hierarchical Information Quadtree: Efficient Spatial Temporal Image Search For Multimedia Stream</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hierarchical Information Quadtree: Efficient Spatial Temporal Image Search For Multimedia Stream' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hierarchical Information Quadtree: Efficient Spatial Temporal Image Search For Multimedia Stream' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Multimedia Tools and Applications</td>
    <td>21</td>
    <td><p>Massive amount of multimedia data that contain times- tamps and geographical
information are being generated at an unprecedented scale in many emerging
applications such as photo sharing web site and social networks applications.
Due to their importance, a large body of work has focused on efficiently
computing various spatial image queries. In this paper,we study the spatial
temporal image query which considers three important constraints during the
search including time recency, spatial proximity and visual relevance. A novel
index structure, namely Hierarchical Information Quadtree(\hiq), to efficiently
insert/delete spatial temporal images with high arrive rates. Base on \hiq an
efficient algorithm is developed to support spatial temporal image query. We
show via extensive experimentation with real spatial databases clearly
demonstrate the efficiency of our methods.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Vector Indexing 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/bai2018learning/">Learning-based Efficient Graph Similarity Computation Via Multi-scale Convolutional Set Matching</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning-based Efficient Graph Similarity Computation Via Multi-scale Convolutional Set Matching' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning-based Efficient Graph Similarity Computation Via Multi-scale Convolutional Set Matching' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Bai et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>62</td>
    <td><p>Graph similarity computation is one of the core operations in many
graph-based applications, such as graph similarity search, graph database
analysis, graph clustering, etc. Since computing the exact distance/similarity
between two graphs is typically NP-hard, a series of approximate methods have
been proposed with a trade-off between accuracy and speed. Recently, several
data-driven approaches based on neural networks have been proposed, most of
which model the graph-graph similarity as the inner product of their
graph-level representations, with different techniques proposed for generating
one embedding per graph. However, using one fixed-dimensional embedding per
graph may fail to fully capture graphs in varying sizes and link structures, a
limitation that is especially problematic for the task of graph similarity
computation, where the goal is to find the fine-grained difference between two
graphs. In this paper, we address the problem of graph similarity computation
from another perspective, by directly matching two sets of node embeddings
without the need to use fixed-dimensional vectors to represent whole graphs for
their similarity computation. The model, GraphSim, achieves the
state-of-the-art performance on four real-world graph datasets under six out of
eight settings (here we count a specific dataset and metric combination as one
setting), compared to existing popular methods for approximate Graph Edit
Distance (GED) and Maximum Common Subgraph (MCS) computation.</p>
</td>
    <td>
      
        AAAI 
      
        DATASETS 
      
        Graph Based ANN 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/baranchuk2018revisiting/">Revisiting The Inverted Indices For Billion-scale Approximate Nearest Neighbors</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Revisiting The Inverted Indices For Billion-scale Approximate Nearest Neighbors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Revisiting The Inverted Indices For Billion-scale Approximate Nearest Neighbors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Baranchuk Dmitry, Babenko Artem, Malkov Yury</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>67</td>
    <td><p>This work addresses the problem of billion-scale nearest neighbor search. The
state-of-the-art retrieval systems for billion-scale databases are currently
based on the inverted multi-index, the recently proposed generalization of the
inverted index structure. The multi-index provides a very fine-grained
partition of the feature space that allows extracting concise and accurate
short-lists of candidates for the search queries. In this paper, we argue that
the potential of the simple inverted index was not fully exploited in previous
works and advocate its usage both for the highly-entangled deep descriptors and
relatively disentangled SIFT descriptors. We introduce a new retrieval system
that is based on the inverted index and outperforms the multi-index by a large
margin for the same memory consumption and construction complexity. For
example, our system achieves the state-of-the-art recall rates several times
faster on the dataset of one billion deep descriptors compared to the efficient
implementation of the inverted multi-index from the FAISS library.</p>
</td>
    <td>
      
        DATASETS 
      
        Large Scale Search 
      
        Vector Indexing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/mccauley2018adaptive/">Adaptive Mapreduce Similarity Joins</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Adaptive Mapreduce Similarity Joins' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Adaptive Mapreduce Similarity Joins' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Mccauley Samuel, Silvestri Francesco</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 5th ACM SIGMOD Workshop on Algorithms and Systems for MapReduce and Beyond</td>
    <td>6</td>
    <td><p>Similarity joins are a fundamental database operation. Given data sets S and
R, the goal of a similarity join is to find all points x in S and y in R with
distance at most r. Recent research has investigated how locality-sensitive
hashing (LSH) can be used for similarity join, and in particular two recent
lines of work have made exciting progress on LSH-based join performance. Hu,
Tao, and Yi (PODS 17) investigated joins in a massively parallel setting,
showing strong results that adapt to the size of the output. Meanwhile, Ahle,
Aum"uller, and Pagh (SODA 17) showed a sequential algorithm that adapts to the
structure of the data, matching classic bounds in the worst case but improving
them significantly on more structured data. We show that this adaptive strategy
can be adapted to the parallel setting, combining the advantages of these
approaches. In particular, we show that a simple modification to Hu et al.â€™s
algorithm achieves bounds that depend on the density of points in the dataset
as well as the total outsize of the output. Our algorithm uses no extra
parameters over other LSH approaches (in particular, its execution does not
depend on the structure of the dataset), and is likely to be efficient in
practice.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Evaluation 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/azarafrooz2018fuzzy/">Fuzzy Hashing As Perturbation-consistent Adversarial Kernel Embedding</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fuzzy Hashing As Perturbation-consistent Adversarial Kernel Embedding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fuzzy Hashing As Perturbation-consistent Adversarial Kernel Embedding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Azarafrooz Ari, Brock John</td> <!-- ðŸ”§ You were missing this -->
    <td>Information Processing &amp; Management</td>
    <td>13</td>
    <td><p>Measuring the similarity of two files is an important task in malware
analysis, with fuzzy hash functions being a popular approach. Traditional fuzzy
hash functions are data agnostic: they do not learn from a particular dataset
how to determine similarity; their behavior is fixed across all datasets. In
this paper, we demonstrate that fuzzy hash functions can be learned in a novel
minimax training framework and that these learned fuzzy hash functions
outperform traditional fuzzy hash functions at the file similarity task for
Portable Executable files. In our approach, hash digests can be extracted from
the kernel embeddings of two kernel networks, trained in a minimax framework,
where the roles of players during training (i.e adversary versus generator)
alternate along with the input data. We refer to this new minimax architecture
as perturbation-consistent. The similarity score for a pair of files is the
utility of the minimax game in equilibrium. Our experiments show that learned
fuzzy hash functions generalize well, capable of determining that two files are
similar even when one of those files was generated using insertion and deletion
operations.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Alt 
      
        Tools & Libraries 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/yang2018deep/">Deep Attention-guided Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Attention-guided Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Attention-guided Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Circuits and Systems for Video Technology</td>
    <td>29</td>
    <td><p>With the rapid growth of multimedia data (e.g., image, audio and video etc.)
on the web, learning-based hashing techniques such as Deep Supervised Hashing
(DSH) have proven to be very efficient for large-scale multimedia search. The
recent successes seen in Learning-based hashing methods are largely due to the
success of deep learning-based hashing methods. However, there are some
limitations to previous learning-based hashing methods (e.g., the learned hash
codes containing repetitive and highly correlated information). In this paper,
we propose a novel learning-based hashing method, named Deep Attention-guided
Hashing (DAgH). DAgH is implemented using two stream frameworks. The core idea
is to use guided hash codes which are generated by the hashing network of the
first stream framework (called first hashing network) to guide the training of
the hashing network of the second stream framework (called second hashing
network). Specifically, in the first network, it leverages an attention network
and hashing network to generate the attention-guided hash codes from the
original images. The loss function we propose contains two components: the
semantic loss and the attention loss. The attention loss is used to punish the
attention network to obtain the salient region from pairs of images; in the
second network, these attention-guided hash codes are used to guide the
training of the second hashing network (i.e., these codes are treated as
supervised labels to train the second network). By doing this, DAgH can make
full use of the most critical information contained in images to guide the
second hashing network in order to learn efficient hash codes in a true
end-to-end fashion. Results from our experiments demonstrate that DAgH can
generate high quality hash codes and it outperforms current state-of-the-art
methods on three benchmark datasets, CIFAR-10, NUS-WIDE, and ImageNet.</p>
</td>
    <td>
      
        DATASETS 
      
        Tools & Libraries 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/yang2018efficient/">Efficient Image Retrieval Via Decoupling Diffusion Into Online And Offline Processing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Efficient Image Retrieval Via Decoupling Diffusion Into Online And Offline Processing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Efficient Image Retrieval Via Decoupling Diffusion Into Online And Offline Processing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>49</td>
    <td><p>Diffusion is commonly used as a ranking or re-ranking method in retrieval
tasks to achieve higher retrieval performance, and has attracted lots of
attention in recent years. A downside to diffusion is that it performs slowly
in comparison to the naive k-NN search, which causes a non-trivial online
computational cost on large datasets. To overcome this weakness, we propose a
novel diffusion technique in this paper. In our work, instead of applying
diffusion to the query, we pre-compute the diffusion results of each element in
the database, making the online search a simple linear combination on top of
the k-NN search process. Our proposed method becomes 10~ times faster in terms
of online search speed. Moreover, we propose to use late truncation instead of
early truncation in previous works to achieve better retrieval performance.</p>
</td>
    <td>
      
        Image Retrieval 
      
        AAAI 
      
        DATASETS 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/artetxe2018massively/">Massively Multilingual Sentence Embeddings For Zero-shot Cross-lingual Transfer And Beyond</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Massively Multilingual Sentence Embeddings For Zero-shot Cross-lingual Transfer And Beyond' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Massively Multilingual Sentence Embeddings For Zero-shot Cross-lingual Transfer And Beyond' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Artetxe Mikel, Schwenk Holger</td> <!-- ðŸ”§ You were missing this -->
    <td>Transactions of the Association for Computational Linguistics</td>
    <td>747</td>
    <td><p>We introduce an architecture to learn joint multilingual sentence
representations for 93 languages, belonging to more than 30 different families
and written in 28 different scripts. Our system uses a single BiLSTM encoder
with a shared BPE vocabulary for all languages, which is coupled with an
auxiliary decoder and trained on publicly available parallel corpora. This
enables us to learn a classifier on top of the resulting embeddings using
English annotated data only, and transfer it to any of the 93 languages without
any modification. Our experiments in cross-lingual natural language inference
(XNLI dataset), cross-lingual document classification (MLDoc dataset) and
parallel corpus mining (BUCC dataset) show the effectiveness of our approach.
We also introduce a new test set of aligned sentences in 112 languages, and
show that our sentence embeddings obtain strong results in multilingual
similarity search even for low-resource languages. Our implementation, the
pre-trained encoder and the multilingual test set are available at
https://github.com/facebookresearch/LASER</p>
</td>
    <td>
      
        DATASETS 
      
        TACL 
      
        ACL 
      
        Similarity Search 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/andoni2018approximate/">Approximate Nearest Neighbor Search In High Dimensions</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Approximate Nearest Neighbor Search In High Dimensions' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Approximate Nearest Neighbor Search In High Dimensions' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Andoni Alexandr, Indyk Piotr, Razenshteyn Ilya</td> <!-- ðŸ”§ You were missing this -->
    <td>2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition</td>
    <td>108</td>
    <td><p>The nearest neighbor problem is defined as follows: Given a set \(P\) of \(n\)
points in some metric space \((X,D)\), build a data structure that, given any
point \(q\), returns a point in \(P\) that is closest to \(q\) (its â€œnearest
neighborâ€ in \(P\)). The data structure stores additional information about the
set \(P\), which is then used to find the nearest neighbor without computing all
distances between \(q\) and \(P\). The problem has a wide range of applications in
machine learning, computer vision, databases and other fields.
  To reduce the time needed to find nearest neighbors and the amount of memory
used by the data structure, one can formulate the {\em approximate} nearest
neighbor problem, where the the goal is to return any point \(pâ€™ \in P\) such
that the distance from \(q\) to \(pâ€™\) is at most \(c \cdot \min_{p \in P} D(q,p)\),
for some \(c \geq 1\). Over the last two decades, many efficient solutions to
this problem were developed. In this article we survey these developments, as
well as their connections to questions in geometric functional analysis and
combinatorial geometry.</p>
</td>
    <td>
      
        Survey Paper 
      
        CVPR 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/shen2018nash/">NASH: Toward End-to-end Neural Architecture For Generative Semantic Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=NASH: Toward End-to-end Neural Architecture For Generative Semantic Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=NASH: Toward End-to-end Neural Architecture For Generative Semantic Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Shen et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</td>
    <td>65</td>
    <td><p>Semantic hashing has become a powerful paradigm for fast similarity search in
many information retrieval systems. While fairly successful, previous
techniques generally require two-stage training, and the binary constraints are
handled ad-hoc. In this paper, we present an end-to-end Neural Architecture for
Semantic Hashing (NASH), where the binary hashing codes are treated as
Bernoulli latent variables. A neural variational inference framework is
proposed for training, where gradients are directly back-propagated through the
discrete latent variable to optimize the hash function. We also draw
connections between proposed method and rate-distortion theory, which provides
a theoretical foundation for the effectiveness of the proposed framework.
Experimental results on three public datasets demonstrate that our method
significantly outperforms several state-of-the-art models on both unsupervised
and supervised scenarios.</p>
</td>
    <td>
      
        DATASETS 
      
        Text Retrieval 
      
        Hashing Methods 
      
        ACL 
      
        Similarity Search 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/tian2018learning/">Learning Decorrelated Hashing Codes For Multimodal Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning Decorrelated Hashing Codes For Multimodal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning Decorrelated Hashing Codes For Multimodal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Tian Dayong</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Access</td>
    <td>5</td>
    <td><p>In social networks, heterogeneous multimedia data correlate to each other,
such as videos and their corresponding tags in YouTube and image-text pairs in
Facebook. Nearest neighbor retrieval across multiple modalities on large data
sets becomes a hot yet challenging problem. Hashing is expected to be an
efficient solution, since it represents data as binary codes. As the bit-wise
XOR operations can be fast handled, the retrieval time is greatly reduced. Few
existing multimodal hashing methods consider the correlation among hashing
bits. The correlation has negative impact on hashing codes. When the hashing
code length becomes longer, the retrieval performance improvement becomes
slower. In this paper, we propose a minimum correlation regularization (MCR)
for multimodal hashing. First, the sigmoid function is used to embed the data
matrices. Then, the MCR is applied on the output of sigmoid function. As the
output of sigmoid function approximates a binary code matrix, the proposed MCR
can efficiently decorrelate the hashing codes. Experiments show the superiority
of the proposed method becomes greater as the code length increases.</p>
</td>
    <td>
      
        Compact Codes 
      
        Multimodal Retrieval 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/alemu2018multi/">Multi-feature Fusion For Image Retrieval Using Constrained Dominant Sets</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Multi-feature Fusion For Image Retrieval Using Constrained Dominant Sets' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Multi-feature Fusion For Image Retrieval Using Constrained Dominant Sets' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Alemu Leulseged Tesfaye, Pelillo Marcello</td> <!-- ðŸ”§ You were missing this -->
    <td>Image and Vision Computing</td>
    <td>23</td>
    <td><p>Aggregating different image features for image retrieval has recently shown
its effectiveness. While highly effective, though, the question of how to
uplift the impact of the best features for a specific query image persists as
an open computer vision problem. In this paper, we propose a computationally
efficient approach to fuse several hand-crafted and deep features, based on the
probabilistic distribution of a given membership score of a constrained cluster
in an unsupervised manner. First, we introduce an incremental nearest neighbor
(NN) selection method, whereby we dynamically select k-NN to the query. We then
build several graphs from the obtained NN sets and employ constrained dominant
sets (CDS) on each graph G to assign edge weights which consider the intrinsic
manifold structure of the graph, and detect false matches to the query.
Finally, we elaborate the computation of feature positive-impact weight (PIW)
based on the dispersive degree of the characteristics vector. To this end, we
exploit the entropy of a cluster membership-score distribution. In addition,
the final NN set bypasses a heuristic voting scheme. Experiments on several
retrieval benchmark datasets show that our method can improve the
state-of-the-art result.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/schlegel2018adding/">Adding Cues To Binary Feature Descriptors For Visual Place Recognition</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Adding Cues To Binary Feature Descriptors For Visual Place Recognition' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Adding Cues To Binary Feature Descriptors For Visual Place Recognition' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Schlegel Dominik, Grisetti Giorgio</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 International Conference on Robotics and Automation (ICRA)</td>
    <td>6</td>
    <td><p>In this paper we propose an approach to embed continuous and selector cues in
binary feature descriptors used for visual place recognition. The embedding is
achieved by extending each feature descriptor with a binary string that encodes
a cue and supports the Hamming distance metric. Augmenting the descriptors in
such a way has the advantage of being transparent to the procedure used to
compare them. We present two concrete applications of our methodology,
demonstrating the two considered types of cues. In addition to that, we
conducted on these applications a broad quantitative and comparative evaluation
covering five benchmark datasets and several state-of-the-art image retrieval
approaches in combination with various binary descriptor types.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        ICRA 
      
        Distance Metric Learning 
      
        Image Retrieval 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/shan2018recurrent/">Recurrent Binary Embedding For Gpu-enabled Exhaustive Retrieval From Billion-scale Semantic Vectors</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Recurrent Binary Embedding For Gpu-enabled Exhaustive Retrieval From Billion-scale Semantic Vectors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Recurrent Binary Embedding For Gpu-enabled Exhaustive Retrieval From Billion-scale Semantic Vectors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Shan et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</td>
    <td>9</td>
    <td><p>Rapid advances in GPU hardware and multiple areas of Deep Learning open up a
new opportunity for billion-scale information retrieval with exhaustive search.
Building on top of the powerful concept of semantic learning, this paper
proposes a Recurrent Binary Embedding (RBE) model that learns compact
representations for real-time retrieval. The model has the unique ability to
refine a base binary vector by progressively adding binary residual vectors to
meet the desired accuracy. The refined vector enables efficient implementation
of exhaustive similarity computation with bit-wise operations, followed by a
near- lossless k-NN selection algorithm, also proposed in this paper. The
proposed algorithms are integrated into an end-to-end multi-GPU system that
retrieves thousands of top items from over a billion candidates in real-time.
The RBE model and the retrieval system were evaluated with data from a major
paid search engine. When measured against the state-of-the-art model for binary
representation and the full precision model for semantic embedding, RBE
significantly outperformed the former, and filled in over 80% of the AUC gap
in-between. Experiments comparing with our production retrieval system also
demonstrated superior performance. While the primary focus of this paper is to
build RBE based on a particular class of semantic models, generalizing to other
types is straightforward, as exemplified by two different models at the end of
the paper.</p>
</td>
    <td>
      
        KDD 
      
        Hashing Methods 
      
        Large Scale Search 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/lin2018towards/">Towards A Theoretical Understanding Of Hashing-based Neural Nets</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Towards A Theoretical Understanding Of Hashing-based Neural Nets' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Towards A Theoretical Understanding Of Hashing-based Neural Nets' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lin Yibo, Song Zhao, Yang Lin F.</td> <!-- ðŸ”§ You were missing this -->
    <td>In Search of Hospitality</td>
    <td>21</td>
    <td><p>Parameter reduction has been an important topic in deep learning due to the
ever-increasing size of deep neural network models and the need to train and
run them on resource limited machines. Despite many efforts in this area, there
were no rigorous theoretical guarantees on why existing neural net compression
methods should work. In this paper, we provide provable guarantees on some
hashing-based parameter reduction methods in neural nets. First, we introduce a
neural net compression scheme based on random linear sketching (which is
usually implemented efficiently via hashing), and show that the sketched
(smaller) network is able to approximate the original network on all input data
coming from any smooth and well-conditioned low-dimensional manifold. The
sketched network can also be trained directly via back-propagation. Next, we
study the previously proposed HashedNets architecture and show that the
optimization landscape of one-hidden-layer HashedNets has a local strong
convexity property similar to a normal fully connected neural network. We
complement our theoretical results with empirical verifications.</p>
</td>
    <td>
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/aum%C3%BCller2018ann/">Ann-benchmarks: A Benchmarking Tool For Approximate Nearest Neighbor Algorithms</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Ann-benchmarks: A Benchmarking Tool For Approximate Nearest Neighbor Algorithms' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Ann-benchmarks: A Benchmarking Tool For Approximate Nearest Neighbor Algorithms' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>AumÃ¼ller Martin, Bernhardsson Erik, Faithfull Alexander</td> <!-- ðŸ”§ You were missing this -->
    <td>Information Systems</td>
    <td>189</td>
    <td><p>This paper describes ANN-Benchmarks, a tool for evaluating the performance of
in-memory approximate nearest neighbor algorithms. It provides a standard
interface for measuring the performance and quality achieved by nearest
neighbor algorithms on different standard data sets. It supports several
different ways of integrating \(k\)-NN algorithms, and its configuration system
automatically tests a range of parameter settings for each algorithm.
Algorithms are compared with respect to many different (approximate) quality
measures, and adding more is easy and fast; the included plotting front-ends
can visualise these as images, \(\LaTeX\) plots, and websites with interactive
plots. ANN-Benchmarks aims to provide a constantly updated overview of the
current state of the art of \(k\)-NN algorithms. In the short term, this overview
allows users to choose the correct \(k\)-NN algorithm and parameters for their
similarity search task; in the longer term, algorithm designers will be able to
use this overview to test and refine automatic parameter tuning. The paper
gives an overview of the system, evaluates the results of the benchmark, and
points out directions for future work. Interestingly, very different approaches
to \(k\)-NN search yield comparable quality-performance trade-offs. The system is
available at http://ann-benchmarks.com .</p>
</td>
    <td>
      
        Survey Paper 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/sharma2018improving/">Improving Similarity Search With High-dimensional Locality-sensitive Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Improving Similarity Search With High-dimensional Locality-sensitive Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Improving Similarity Search With High-dimensional Locality-sensitive Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Sharma Jaiyam, Navlakha Saket</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>6</td>
    <td><p>We propose a new class of data-independent locality-sensitive hashing (LSH)
algorithms based on the fruit fly olfactory circuit. The fundamental difference
of this approach is that, instead of assigning hashes as dense points in a low
dimensional space, hashes are assigned in a high dimensional space, which
enhances their separability. We show theoretically and empirically that this
new family of hash functions is locality-sensitive and preserves rank
similarity for inputs in any `p space. We then analyze different variations on
this strategy and show empirically that they outperform existing LSH methods
for nearest-neighbors search on six benchmark datasets. Finally, we propose a
multi-probe version of our algorithm that achieves higher performance for the
same query time, or conversely, that maintains performance of prior approaches
while taking significantly less indexing time and memory. Overall, our approach
leverages the advantages of separability provided by high-dimensional spaces,
while still remaining computationally efficient</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/wieder2018another/">Another Proof Of Cuckoo Hashing With New Variants</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Another Proof Of Cuckoo Hashing With New Variants' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Another Proof Of Cuckoo Hashing With New Variants' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wieder Udi</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>120</td>
    <td><p>We show a new proof for the load of obtained by a Cuckoo Hashing data
structure. Our proof is arguably simpler than previous proofs and allows for
new generalizations. The proof first appeared in Pinkas et. al. \cite{PSWW19}
in the context of a protocol for private set intersection. We present it here
separately to improve its readability.</p>
</td>
    <td>
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/mu2018towards/">Towards Practical Visual Search Engine Within Elasticsearch</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Towards Practical Visual Search Engine Within Elasticsearch' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Towards Practical Visual Search Engine Within Elasticsearch' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Mu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>11</td>
    <td><p>In this paper, we describe our end-to-end content-based image retrieval
system built upon Elasticsearch, a well-known and popular textual search
engine. As far as we know, this is the first time such a system has been
implemented in eCommerce, and our efforts have turned out to be highly
worthwhile. We end up with a novel and exciting visual search solution that is
extremely easy to be deployed, distributed, scaled and monitored in a
cost-friendly manner. Moreover, our platform is intrinsically flexible in
supporting multimodal searches, where visual and textual information can be
jointly leveraged in retrieval.
  The core idea is to encode image feature vectors into a collection of string
tokens in a way such that closer vectors will share more string tokens in
common. By doing that, we can utilize Elasticsearch to efficiently retrieve
similar images based on similarities within encoded sting tokens. As part of
the development, we propose a novel vector to string encoding method, which is
shown to substantially outperform the previous ones in terms of both precision
and latency.
  First-hand experiences in implementing this Elasticsearch-based platform are
extensively addressed, which should be valuable to practitioners also
interested in building visual search engine on top of Elasticsearch.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/shen2018zero/">Zero-shot Sketch-image Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Zero-shot Sketch-image Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Zero-shot Sketch-image Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Shen et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</td>
    <td>154</td>
    <td><p>Recent studies show that large-scale sketch-based image retrieval (SBIR) can
be efficiently tackled by cross-modal binary representation learning methods,
where Hamming distance matching significantly speeds up the process of
similarity search. Providing training and test data subjected to a fixed set of
pre-defined categories, the cutting-edge SBIR and cross-modal hashing works
obtain acceptable retrieval performance. However, most of the existing methods
fail when the categories of query sketches have never been seen during
training. In this paper, the above problem is briefed as a novel but realistic
zero-shot SBIR hashing task. We elaborate the challenges of this special task
and accordingly propose a zero-shot sketch-image hashing (ZSIH) model. An
end-to-end three-network architecture is built, two of which are treated as the
binary encoders. The third network mitigates the sketch-image heterogeneity and
enhances the semantic relations among data by utilizing the Kronecker fusion
layer and graph convolution, respectively. As an important part of ZSIH, we
formulate a generative hashing scheme in reconstructing semantic knowledge
representations for zero-shot retrieval. To the best of our knowledge, ZSIH is
the first zero-shot hashing work suitable for SBIR and cross-modal search.
Comprehensive experiments are conducted on two extended datasets, i.e., Sketchy
and TU-Berlin with a novel zero-shot train-test split. The proposed model
remarkably outperforms related works.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        CVPR 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/levrard2018quantization/">Quantization/clustering: When And Why Does K-means Work?</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Quantization/clustering: When And Why Does K-means Work?' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Quantization/clustering: When And Why Does K-means Work?' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Levrard ClÃ©ment Lpsm Umr 8001</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>6</td>
    <td><p>Though mostly used as a clustering algorithm, k-means are originally designed
as a quantization algorithm. Namely, it aims at providing a compression of a
probability distribution with k points. Building upon [21, 33], we try to
investigate how and when these two approaches are compatible. Namely, we show
that provided the sample distribution satisfies a margin like condition (in the
sense of [27] for supervised learning), both the associated empirical risk
minimizer and the output of Lloydâ€™s algorithm provide almost optimal
classification in certain cases (in the sense of [6]). Besides, we also show
that they achieved fast and optimal convergence rates in terms of sample size
and compression risk.</p>
</td>
    <td>
      
        Quantization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/hu2018deep/">Deep LDA Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep LDA Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep LDA Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Hu di, Nie Feiping, Li Xuelong</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Multimedia</td>
    <td>97</td>
    <td><p>The conventional supervised hashing methods based on classification do not
entirely meet the requirements of hashing technique, but Linear Discriminant
Analysis (LDA) does. In this paper, we propose to perform a revised LDA
objective over deep networks to learn efficient hashing codes in a truly
end-to-end fashion. However, the complicated eigenvalue decomposition within
each mini-batch in every epoch has to be faced with when simply optimizing the
deep network w.r.t. the LDA objective. In this work, the revised LDA objective
is transformed into a simple least square problem, which naturally overcomes
the intractable problems and can be easily solved by the off-the-shelf
optimizer. Such deep extension can also overcome the weakness of LDA Hashing in
the limited linear projection and feature learning. Amounts of experiments are
conducted on three benchmark datasets. The proposed Deep LDA Hashing shows
nearly 70 points improvement over the conventional one on the CIFAR-10 dataset.
It also beats several state-of-the-art methods on various metrics.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/hu2018hashing/">From Hashing To Cnns: Training Binaryweight Networks Via Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=From Hashing To Cnns: Training Binaryweight Networks Via Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=From Hashing To Cnns: Training Binaryweight Networks Via Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Hu Qinghao, Wang Peisong, Cheng Jian</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>42</td>
    <td><p>Deep convolutional neural networks (CNNs) have shown appealing performance on
various computer vision tasks in recent years. This motivates people to deploy
CNNs to realworld applications. However, most of state-of-art CNNs require
large memory and computational resources, which hinders the deployment on
mobile devices. Recent studies show that low-bit weight representation can
reduce much storage and memory demand, and also can achieve efficient network
inference. To achieve this goal, we propose a novel approach named BWNH to
train Binary Weight Networks via Hashing. In this paper, we first reveal the
strong connection between inner-product preserving hashing and binary weight
networks, and show that training binary weight networks can be intrinsically
regarded as a hashing problem. Based on this perspective, we propose an
alternating optimization method to learn the hash codes instead of directly
learning binary weights. Extensive experiments on CIFAR10, CIFAR100 and
ImageNet demonstrate that our proposed BWNH outperforms current state-of-art by
a large margin.</p>
</td>
    <td>
      
        Alt 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/hoang2018simultaneous/">Simultaneous Compression And Quantization: A Joint Approach For Efficient Unsupervised Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Simultaneous Compression And Quantization: A Joint Approach For Efficient Unsupervised Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Simultaneous Compression And Quantization: A Joint Approach For Efficient Unsupervised Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Hoang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Computer Vision and Image Understanding</td>
    <td>11</td>
    <td><p>For unsupervised data-dependent hashing, the two most important requirements
are to preserve similarity in the low-dimensional feature space and to minimize
the binary quantization loss. A well-established hashing approach is Iterative
Quantization (ITQ), which addresses these two requirements in separate steps.
In this paper, we revisit the ITQ approach and propose novel formulations and
algorithms to the problem. Specifically, we propose a novel approach, named
Simultaneous Compression and Quantization (SCQ), to jointly learn to compress
(reduce dimensionality) and binarize input data in a single formulation under
strict orthogonal constraint. With this approach, we introduce a loss function
and its relaxed version, termed Orthonormal Encoder (OnE) and Orthogonal
Encoder (OgE) respectively, which involve challenging binary and orthogonal
constraints. We propose to attack the optimization using novel algorithms based
on recent advances in cyclic coordinate descent approach. Comprehensive
experiments on unsupervised image retrieval demonstrate that our proposed
methods consistently outperform other state-of-the-art hashing methods.
Notably, our proposed methods outperform recent deep neural networks and GAN
based hashing in accuracy, while being very computationally-efficient.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Quantization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/ri2018fingerprint/">A Fingerprint Indexing Method Based On Minutia Descriptor And Clustering</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Fingerprint Indexing Method Based On Minutia Descriptor And Clustering' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Fingerprint Indexing Method Based On Minutia Descriptor And Clustering' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ri Gwang-il, Ri Chol-gyun, Ji Su-rim</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Pattern Analysis and Machine Intelligence</td>
    <td>152</td>
    <td><p>In this paper we propose a novel fingerprint indexing approach for speeding
up in the fingerprint recognition system. What kind of features are used for
indexing and how to employ the extracted features for searching are crucial for
the fingerprint indexing. In this paper, we select a minutia descriptor, which
has been used to improve the accuracy of the fingerprint matching, as a local
feature for indexing and construct a fixed-length feature vector which will be
used for searching from the minutia descriptors of the fingerprint image using
a clustering. And we propose a fingerprint searching approach that uses the
Euclidean distance between two feature vectors as the similarity between two
indexing features. Our indexing approach has several benefits. It reduces
searching time significantly and is irrespective of the existence of singular
points and robust even though the size of the fingerprint image is small or the
quality is low. And the constructed indexing vector by this approach is
independent of the features which are used for indexing based on the
geometrical relations between the minutiae, like one based on the minutiae
triplets. Thus, the proposed approach could be combined with other indexing
approaches to gain a better indexing performance.</p>
</td>
    <td>
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/liu2018stochastic/">Stochastic Attraction-repulsion Embedding For Large Scale Image Localization</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Stochastic Attraction-repulsion Embedding For Large Scale Image Localization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Stochastic Attraction-repulsion Embedding For Large Scale Image Localization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu Liu, Li Hongdong, Dai Yuchao</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE/CVF International Conference on Computer Vision (ICCV)</td>
    <td>96</td>
    <td><p>This paper tackles the problem of large-scale image-based localization (IBL)
where the spatial location of a query image is determined by finding out the
most similar reference images in a large database. For solving this problem, a
critical task is to learn discriminative image representation that captures
informative information relevant for localization. We propose a novel
representation learning method having higher location-discriminating power. It
provides the following contributions: 1) we represent a place (location) as a
set of exemplar images depicting the same landmarks and aim to maximize
similarities among intra-place images while minimizing similarities among
inter-place images; 2) we model a similarity measure as a probability
distribution on L_2-metric distances between intra-place and inter-place image
representations; 3) we propose a new Stochastic Attraction and Repulsion
Embedding (SARE) loss function minimizing the KL divergence between the learned
and the actual probability distributions; 4) we give theoretical comparisons
between SARE, triplet ranking and contrastive losses. It provides insights into
why SARE is better by analyzing gradients. Our SARE loss is easy to implement
and pluggable to any CNN. Experiments show that our proposed method improves
the localization performance on standard benchmarks by a large margin.
Demonstrating the broad applicability of our method, we obtained the third
place out of 209 teams in the 2018 Google Landmark Retrieval Challenge. Our
code and model are available at https://github.com/Liumouliu/deepIBL.</p>
</td>
    <td>
      
        ICCV 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/liu2018mtfh/">MTFH: A Matrix Tri-factorization Hashing Framework For Efficient Cross-modal Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=MTFH: A Matrix Tri-factorization Hashing Framework For Efficient Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=MTFH: A Matrix Tri-factorization Hashing Framework For Efficient Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Pattern Analysis and Machine Intelligence</td>
    <td>171</td>
    <td><p>Hashing has recently sparked a great revolution in cross-modal retrieval
because of its low storage cost and high query speed. Recent cross-modal
hashing methods often learn unified or equal-length hash codes to represent the
multi-modal data and make them intuitively comparable. However, such unified or
equal-length hash representations could inherently sacrifice their
representation scalability because the data from different modalities may not
have one-to-one correspondence and could be encoded more efficiently by
different hash codes of unequal lengths. To mitigate these problems, this paper
exploits a related and relatively unexplored problem: encode the heterogeneous
data with varying hash lengths and generalize the cross-modal retrieval in
various challenging scenarios. To this end, a generalized and flexible
cross-modal hashing framework, termed Matrix Tri-Factorization Hashing (MTFH),
is proposed to work seamlessly in various settings including paired or unpaired
multi-modal data, and equal or varying hash length encoding scenarios. More
specifically, MTFH exploits an efficient objective function to flexibly learn
the modality-specific hash codes with different length settings, while
synchronously learning two semantic correlation matrices to semantically
correlate the different hash representations for heterogeneous data comparable.
As a result, the derived hash codes are more semantically meaningful for
various challenging cross-modal retrieval tasks. Extensive experiments
evaluated on public benchmark datasets highlight the superiority of MTFH under
various retrieval scenarios and show its competitive performance with the
state-of-the-arts.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Multimodal Retrieval 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/kilias2018idel/">IDEL: In-database Entity Linking With Neural Embeddings</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=IDEL: In-database Entity Linking With Neural Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=IDEL: In-database Entity Linking With Neural Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Kilias et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>8</td>
    <td><p>We present a novel architecture, In-Database Entity Linking (IDEL), in which
we integrate the analytics-optimized RDBMS MonetDB with neural text mining
abilities. Our system design abstracts core tasks of most neural entity linking
systems for MonetDB. To the best of our knowledge, this is the first defacto
implemented system integrating entity-linking in a database. We leverage the
ability of MonetDB to support in-database-analytics with user defined functions
(UDFs) implemented in Python. These functions call machine learning libraries
for neural text mining, such as TensorFlow. The system achieves zero cost for
data shipping and transformation by utilizing MonetDBâ€™s ability to embed Python
processes in the database kernel and exchange data in NumPy arrays. IDEL
represents text and relational data in a joint vector space with neural
embeddings and can compensate errors with ambiguous entity representations. For
detecting matching entities, we propose a novel similarity function based on
joint neural embeddings which are learned via minimizing pairwise contrastive
ranking loss. This function utilizes a high dimensional index structures for
fast retrieval of matching entities. Our first implementation and experiments
using the WebNLG corpus show the effectiveness and the potentials of IDEL.</p>
</td>
    <td>
      
        Vector Indexing 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/tran2018device/">On-device Scalable Image-based Localization Via Prioritized Cascade Search And Fast One-many RANSAC</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=On-device Scalable Image-based Localization Via Prioritized Cascade Search And Fast One-many RANSAC' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=On-device Scalable Image-based Localization Via Prioritized Cascade Search And Fast One-many RANSAC' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Tran et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Image Processing</td>
    <td>38</td>
    <td><p>We present the design of an entire on-device system for large-scale urban
localization using images. The proposed design integrates compact image
retrieval and 2D-3D correspondence search to estimate the location in extensive
city regions. Our design is GPS agnostic and does not require network
connection. In order to overcome the resource constraints of mobile devices, we
propose a system design that leverages the scalability advantage of image
retrieval and accuracy of 3D model-based localization. Furthermore, we propose
a new hashing-based cascade search for fast computation of 2D-3D
correspondences. In addition, we propose a new one-many RANSAC for accurate
pose estimation. The new one-many RANSAC addresses the challenge of repetitive
building structures (e.g. windows, balconies) in urban localization. Extensive
experiments demonstrate that our 2D-3D correspondence search achieves
state-of-the-art localization accuracy on multiple benchmark datasets.
Furthermore, our experiments on a large Google Street View (GSV) image dataset
show the potential of large-scale localization entirely on a typical mobile
device.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/he2018local/">Local Descriptors Optimized For Average Precision</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Local Descriptors Optimized For Average Precision' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Local Descriptors Optimized For Average Precision' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>He Kun, Lu Yan, Sclaroff Stan</td> <!-- ðŸ”§ You were missing this -->
    <td>2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</td>
    <td>209</td>
    <td><p>Extraction of local feature descriptors is a vital stage in the solution
pipelines for numerous computer vision tasks. Learning-based approaches improve
performance in certain tasks, but still cannot replace handcrafted features in
general. In this paper, we improve the learning of local feature descriptors by
optimizing the performance of descriptor matching, which is a common stage that
follows descriptor extraction in local feature based pipelines, and can be
formulated as nearest neighbor retrieval. Specifically, we directly optimize a
ranking-based retrieval performance metric, Average Precision, using deep
neural networks. This general-purpose solution can also be viewed as a listwise
learning to rank approach, which is advantageous compared to recent local
ranking approaches. On standard benchmarks, descriptors learned with our
formulation achieve state-of-the-art results in patch verification, patch
retrieval, and image matching.</p>
</td>
    <td>
      
        CVPR 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/guruswami2018beating/">Beating Fredman-koml\'{o}s For Perfect \(k\)-hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Beating Fredman-koml\'{o}s For Perfect \(k\)-hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Beating Fredman-koml\'{o}s For Perfect \(k\)-hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Guruswami Venkatesan, Riazanov Andrii</td> <!-- ðŸ”§ You were missing this -->
    <td>Journal of Combinatorial Theory, Series A</td>
    <td>9</td>
    <td><p>We say a subset \(C \subseteq \{1,2,\dots,k\}^n\) is a \(k\)-hash code (also
called \(k\)-separated) if for every subset of \(k\) codewords from \(C\), there
exists a coordinate where all these codewords have distinct values.
Understanding the largest possible rate (in bits), defined as \((log_2 |C|)/n\),
of a \(k\)-hash code is a classical problem. It arises in two equivalent
contexts: (i) the smallest size possible for a perfect hash family that maps a
universe of \(N\) elements into \(\{1,2,\dots,k\}\), and (ii) the zero-error
capacity for decoding with lists of size less than \(k\) for a certain
combinatorial channel.
  A general upper bound of \(k!/k^{k-1}\) on the rate of a \(k\)-hash code (in the
limit of large \(n\)) was obtained by Fredman and Koml'{o}s in 1984 for any \(k
\geq 4\). While better bounds have been obtained for \(k=4\), their original bound
has remained the best known for each \(k \ge 5\). In this work, we obtain the
first improvement to the Fredman-Koml'{o}s bound for every \(k \ge 5\). While we
get explicit (numerical) bounds for \(k=5,6\), for larger \(k\) we only show that
the FK bound can be improved by a positive, but unspecified, amount. Under a
conjecture on the optimum value of a certain polynomial optimization problem
over the simplex, our methods allow an effective bound to be computed for every
\(k\).</p>
</td>
    <td>
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/kim2018attention/">Attention-based Ensemble For Deep Metric Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Attention-based Ensemble For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Attention-based Ensemble For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Kim et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>237</td>
    <td><p>Deep metric learning aims to learn an embedding function, modeled as deep
neural network. This embedding function usually puts semantically similar
images close while dissimilar images far from each other in the learned
embedding space. Recently, ensemble has been applied to deep metric learning to
yield state-of-the-art results. As one important aspect of ensemble, the
learners should be diverse in their feature embeddings. To this end, we propose
an attention-based ensemble, which uses multiple attention masks, so that each
learner can attend to different parts of the object. We also propose a
divergence loss, which encourages diversity among the learners. The proposed
method is applied to the standard benchmarks of deep metric learning and
experimental results show that it outperforms the state-of-the-art methods by a
significant margin on image retrieval tasks.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/kho2018fixed/">Fixed-length Bit-string Representation Of Fingerprint By Normalized Local Structures</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fixed-length Bit-string Representation Of Fingerprint By Normalized Local Structures' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fixed-length Bit-string Representation Of Fingerprint By Normalized Local Structures' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Kho et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Pattern Recognition</td>
    <td>11</td>
    <td><p>In this paper, we propose a method to represent a fingerprint image by an
ordered, fixed-length bit-string providing improved accuracy performance,
faster matching time and compressibility. First, we devise a novel
minutia-based local structure modeled by a mixture of 2D elliptical Gaussian
functions in the pixel space. Each local structure is mapped to the Euclidean
space by normalizing the local structure with the number of minutiae that
associates to it. This simple yet crucial crux enables fast dissimilarity
computation of two local structures with Euclidean distance without distortion.
A complementary texture-based local structure to the minutia-based local
structure is also introduced whereby both can be compressed via principal
component analysis and fused easily in the Euclidean space. The fused local
structure is then converted to a K-bit ordered string via a K-means clustering
algorithm. This chain of computation with sole use of Euclidean distance is
vital for speedy and discriminative bit-string conversion. The accuracy can be
further improved by a finger-specific bit-training algorithm in which two
criteria are leveraged to select useful bit positions for matching. Experiments
are performed on Fingerprint Verification Competition (FVC) databases for
comparison with existing techniques to show the superiority of the proposed
method.</p>
</td>
    <td>
      
        CVPR 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/zhai2018classification/">Classification Is A Strong Baseline For Deep Metric Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Classification Is A Strong Baseline For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Classification Is A Strong Baseline For Deep Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhai Andrew, Wu Hao-yu</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>132</td>
    <td><p>Deep metric learning aims to learn a function mapping image pixels to
embedding feature vectors that model the similarity between images. Two major
applications of metric learning are content-based image retrieval and face
verification. For the retrieval tasks, the majority of current state-of-the-art
(SOTA) approaches are triplet-based non-parametric training. For the face
verification tasks, however, recent SOTA approaches have adopted
classification-based parametric training. In this paper, we look into the
effectiveness of classification based approaches on image retrieval datasets.
We evaluate on several standard retrieval datasets such as CAR-196,
CUB-200-2011, Stanford Online Product, and In-Shop datasets for image retrieval
and clustering, and establish that our classification-based approach is
competitive across different feature dimensions and base feature networks. We
further provide insights into the performance effects of subsampling classes
for scalable classification-based training, and the effects of binarization,
enabling efficient storage and computation for practical applications.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Distance Metric Learning 
      
        Compact Codes 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/wu2018local/">Local Density Estimation In High Dimensions</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Local Density Estimation In High Dimensions' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Local Density Estimation In High Dimensions' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wu Xian, Charikar Moses, Natchu Vishnu</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>7</td>
    <td><p>An important question that arises in the study of high dimensional vector
representations learned from data is: given a set \(\mathcal{D}\) of vectors and
a query \(q\), estimate the number of points within a specified distance
threshold of \(q\). We develop two estimators, LSH Count and Multi-Probe Count
that use locality sensitive hashing to preprocess the data to accurately and
efficiently estimate the answers to such questions via importance sampling. A
key innovation is the ability to maintain a small number of hash tables via
preprocessing data structures and algorithms that sample from multiple buckets
in each hash table. We give bounds on the space requirements and sample
complexity of our schemes, and demonstrate their effectiveness in experiments
on a standard word embedding dataset.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Graph Based ANN 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/zhe2018directional/">Directional Statistics-based Deep Metric Learning For Image Classification And Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Directional Statistics-based Deep Metric Learning For Image Classification And Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Directional Statistics-based Deep Metric Learning For Image Classification And Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhe Xuefei, Chen Shifeng, Yan Hong</td> <!-- ðŸ”§ You were missing this -->
    <td>Pattern Recognition</td>
    <td>72</td>
    <td><p>Deep distance metric learning (DDML), which is proposed to learn image
similarity metrics in an end-to-end manner based on the convolution neural
network, has achieved encouraging results in many computer vision
tasks.\(L2\)-normalization in the embedding space has been used to improve the
performance of several DDML methods. However, the commonly used Euclidean
distance is no longer an accurate metric for \(L2\)-normalized embedding space,
i.e., a hyper-sphere. Another challenge of current DDML methods is that their
loss functions are usually based on rigid data formats, such as the triplet
tuple. Thus, an extra process is needed to prepare data in specific formats. In
addition, their losses are obtained from a limited number of samples, which
leads to a lack of the global view of the embedding space. In this paper, we
replace the Euclidean distance with the cosine similarity to better utilize the
\(L2\)-normalization, which is able to attenuate the curse of dimensionality.
More specifically, a novel loss function based on the von Mises-Fisher
distribution is proposed to learn a compact hyper-spherical embedding space.
Moreover, a new efficient learning algorithm is developed to better capture the
global structure of the embedding space. Experiments for both classification
and retrieval tasks on several standard datasets show that our method achieves
state-of-the-art performance with a simpler training procedure. Furthermore, we
demonstrate that, even with a small number of convolutional layers, our model
can still obtain significantly better classification performance than the
widely used softmax loss.</p>
</td>
    <td>
      
        CVPR 
      
        DATASETS 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/iwasaki2018optimization/">Optimization Of Indexing Based On K-nearest Neighbor Graph For Proximity Search In High-dimensional Data</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Optimization Of Indexing Based On K-nearest Neighbor Graph For Proximity Search In High-dimensional Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Optimization Of Indexing Based On K-nearest Neighbor Graph For Proximity Search In High-dimensional Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Iwasaki Masajiro, Miyazaki Daisuke</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>37</td>
    <td><p>Searching for high-dimensional vector data with high accuracy is an
inevitable search technology for various types of data. Graph-based indexes are
known to reduce the query time for high-dimensional data. To further improve
the query time by using graphs, we focused on the indegrees and outdegrees of
graphs. While a sufficient number of incoming edges (indegrees) are
indispensable for increasing search accuracy, an excessive number of outgoing
edges (outdegrees) should be suppressed so as to not increase the query time.
Therefore, we propose three degree-adjustment methods: static degree adjustment
of not only outdegrees but also indegrees, dynamic degree adjustment with which
outdegrees are determined by the search accuracy users require, and path
adjustment to remove edges that have alternative search paths to reduce
outdegrees. We also show how to obtain optimal degree-adjustment parameters and
that our methods outperformed previous methods for image and textual data.</p>
</td>
    <td>
      
        Alt 
      
        Graph Based ANN 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/zhao2018approximate/">Approximate K-nn Graph Construction: A Generic Online Approach</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Approximate K-nn Graph Construction: A Generic Online Approach' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Approximate K-nn Graph Construction: A Generic Online Approach' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhao Wan-lei, Wang Hui, Ngo Chong-wah</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Multimedia</td>
    <td>20</td>
    <td><p>Nearest neighbor search and k-nearest neighbor graph construction are two
fundamental issues arise from many disciplines such as multimedia information
retrieval, data-mining and machine learning. They become more and more imminent
given the big data emerge in various fields in recent years. In this paper, a
simple but effective solution both for approximate k-nearest neighbor search
and approximate k-nearest neighbor graph construction is presented. These two
issues are addressed jointly in our solution. On the one hand, the approximate
k-nearest neighbor graph construction is treated as a search task. Each sample
along with its k-nearest neighbors are joined into the k-nearest neighbor graph
by performing the nearest neighbor search sequentially on the graph under
construction. On the other hand, the built k-nearest neighbor graph is used to
support k-nearest neighbor search. Since the graph is built online, the dynamic
update on the graph, which is not possible from most of the existing solutions,
is supported. This solution is feasible for various distance measures. Its
effectiveness both as k-nearest neighbor construction and k-nearest neighbor
search approaches is verified across different types of data in different
scales, various dimensions and under different metrics.</p>
</td>
    <td>
      
        Graph Based ANN 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/srinivas2018merging/">Merging Datasets Through Deep Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Merging Datasets Through Deep Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Merging Datasets Through Deep Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Srinivas Kavitha, Gale Abraham, Dolby Julian</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>7</td>
    <td><p>Merging datasets is a key operation for data analytics. A frequent
requirement for merging is joining across columns that have different surface
forms for the same entity (e.g., the name of a person might be represented as
â€œDouglas Adamsâ€ or â€œAdams, Douglasâ€). Similarly, ontology alignment can require
recognizing distinct surface forms of the same entity, especially when
ontologies are independently developed. However, data management systems are
currently limited to performing merges based on string equality, or at best
using string similarity. We propose an approach to performing merges based on
deep learning models. Our approach depends on (a) creating a deep learning
model that maps surface forms of an entity into a set of vectors such that
alternate forms for the same entity are closest in vector space, (b) indexing
these vectors using a nearest neighbors algorithm to find the forms that can be
potentially joined together. To build these models, we had to adapt techniques
from metric learning due to the characteristics of the data; specifically we
describe novel sample selection techniques and loss functions that work for
this problem. To evaluate our approach, we used Wikidata as ground truth and
built models from datasets with approximately 1.1M peopleâ€™s names (200K
identities) and 130K company names (70K identities). We developed models that
allow for joins with precision@1 of .75-.81 and recall of .74-.81. We make the
models available for aligning people or companies across multiple datasets.</p>
</td>
    <td>
      
        Alt 
      
        DATASETS 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/indyk2018approximate/">Approximate Nearest Neighbors In Limited Space</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Approximate Nearest Neighbors In Limited Space' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Approximate Nearest Neighbors In Limited Space' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Indyk Piotr, Wagner Tal</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>6</td>
    <td><p>We consider the \((1+\epsilon)\)-approximate nearest neighbor search problem:
given a set \(X\) of \(n\) points in a \(d\)-dimensional space, build a data
structure that, given any query point \(y\), finds a point \(x \in X\) whose
distance to \(y\) is at most \((1+\epsilon) \min_{x \in X} |x-y|\) for an
accuracy parameter \(\epsilon \in (0,1)\). Our main result is a data structure
that occupies only \(O(\epsilon^{-2} n log(n) log(1/\epsilon))\) bits of space,
assuming all point coordinates are integers in the range \(\{-n^{O(1)} \ldots
n^{O(1)}\}\), i.e., the coordinates have \(O(log n)\) bits of precision. This
improves over the best previously known space bound of \(O(\epsilon^{-2} n
log(n)^2)\), obtained via the randomized dimensionality reduction method of
Johnson and Lindenstrauss (1984). We also consider the more general problem of
estimating all distances from a collection of query points to all data points
\(X\), and provide almost tight upper and lower bounds for the space complexity
of this problem.</p>
</td>
    <td>
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/huynh2018fast/">Fast Binary Embeddings, And Quantized Compressed Sensing With Structured Matrices</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fast Binary Embeddings, And Quantized Compressed Sensing With Structured Matrices' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fast Binary Embeddings, And Quantized Compressed Sensing With Structured Matrices' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Huynh Thang, Saab Rayan</td> <!-- ðŸ”§ You were missing this -->
    <td>Communications on Pure and Applied Mathematics</td>
    <td>12</td>
    <td><p>This paper deals with two related problems, namely distance-preserving binary
embeddings and quantization for compressed sensing . First, we propose fast
methods to replace points from a subset \(\mathcal{X} \subset \mathbb{R}^n\),
associated with the Euclidean metric, with points in the cube \(\{\pm 1\}^m\) and
we associate the cube with a pseudo-metric that approximates Euclidean distance
among points in \(\mathcal{X}\). Our methods rely on quantizing fast
Johnson-Lindenstrauss embeddings based on bounded orthonormal systems and
partial circulant ensembles, both of which admit fast transforms. Our
quantization methods utilize noise-shaping, and include Sigma-Delta schemes and
distributed noise-shaping schemes. The resulting approximation errors decay
polynomially and exponentially fast in \(m\), depending on the embedding method.
This dramatically outperforms the current decay rates associated with binary
embeddings and Hamming distances. Additionally, it is the first such binary
embedding result that applies to fast Johnson-Lindenstrauss maps while
preserving \(â„“â‚‚\) norms.
  Second, we again consider noise-shaping schemes, albeit this time to quantize
compressed sensing measurements arising from bounded orthonormal ensembles and
partial circulant matrices. We show that these methods yield a reconstruction
error that again decays with the number of measurements (and bits), when using
convex optimization for reconstruction. Specifically, for Sigma-Delta schemes,
the error decays polynomially in the number of measurements, and it decays
exponentially for distributed noise-shaping schemes based on beta encoding.
These results are near optimal and the first of their kind dealing with bounded
orthonormal systems.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        Quantization 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/liu2018discriminative/">Discriminative Cross-view Binary Representation Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Discriminative Cross-view Binary Representation Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Discriminative Cross-view Binary Representation Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu Liu, Qi Hairong</td> <!-- ðŸ”§ You were missing this -->
    <td>2018 IEEE Winter Conference on Applications of Computer Vision (WACV)</td>
    <td>5</td>
    <td><p>Learning compact representation is vital and challenging for large scale
multimedia data. Cross-view/cross-modal hashing for effective binary
representation learning has received significant attention with exponentially
growing availability of multimedia content. Most existing cross-view hashing
algorithms emphasize the similarities in individual views, which are then
connected via cross-view similarities. In this work, we focus on the
exploitation of the discriminative information from different views, and
propose an end-to-end method to learn semantic-preserving and discriminative
binary representation, dubbed Discriminative Cross-View Hashing (DCVH), in
light of learning multitasking binary representation for various tasks
including cross-view retrieval, image-to-image retrieval, and image
annotation/tagging. The proposed DCVH has the following key components. First,
it uses convolutional neural network (CNN) based nonlinear hashing functions
and multilabel classification for both images and texts simultaneously. Such
hashing functions achieve effective continuous relaxation during training
without explicit quantization loss by using Direct Binary Embedding (DBE)
layers. Second, we propose an effective view alignment via Hamming distance
minimization, which is efficiently accomplished by bit-wise XOR operation.
Extensive experiments on two image-text benchmark datasets demonstrate that
DCVH outperforms state-of-the-art cross-view hashing algorithms as well as
single-view image hashing algorithms. In addition, DCVH can provide competitive
performance for image annotation/tagging.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/yu2018semi/">Semi-supervised Hashing For Semi-paired Cross-view Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Semi-supervised Hashing For Semi-paired Cross-view Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Semi-supervised Hashing For Semi-paired Cross-view Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yu Jun, Wu Xiao-jun, Kittler Josef</td> <!-- ðŸ”§ You were missing this -->
    <td>2018 24th International Conference on Pattern Recognition (ICPR)</td>
    <td>10</td>
    <td><p>Recently, hashing techniques have gained importance in large-scale retrieval
tasks because of their retrieval speed. Most of the existing cross-view
frameworks assume that data are well paired. However, the fully-paired
multiview situation is not universal in real applications. The aim of the
method proposed in this paper is to learn the hashing function for semi-paired
cross-view retrieval tasks. To utilize the label information of partial data,
we propose a semi-supervised hashing learning framework which jointly performs
feature extraction and classifier learning. The experimental results on two
datasets show that our method outperforms several state-of-the-art methods in
terms of retrieval accuracy.</p>
</td>
    <td>
      
        DATASETS 
      
        Tools & Libraries 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/ji2018attribute/">Attribute-guided Network For Cross-modal Zero-shot Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Attribute-guided Network For Cross-modal Zero-shot Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Attribute-guided Network For Cross-modal Zero-shot Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ji et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Neural Networks and Learning Systems</td>
    <td>83</td>
    <td><p>Zero-Shot Hashing aims at learning a hashing model that is trained only by
instances from seen categories but can generate well to those of unseen
categories. Typically, it is achieved by utilizing a semantic embedding space
to transfer knowledge from seen domain to unseen domain. Existing efforts
mainly focus on single-modal retrieval task, especially Image-Based Image
Retrieval (IBIR). However, as a highlighted research topic in the field of
hashing, cross-modal retrieval is more common in real world applications. To
address the Cross-Modal Zero-Shot Hashing (CMZSH) retrieval task, we propose a
novel Attribute-Guided Network (AgNet), which can perform not only IBIR, but
also Text-Based Image Retrieval (TBIR). In particular, AgNet aligns different
modal data into a semantically rich attribute space, which bridges the gap
caused by modality heterogeneity and zero-shot setting. We also design an
effective strategy that exploits the attribute to guide the generation of hash
codes for image and text within the same network. Extensive experimental
results on three benchmark datasets (AwA, SUN, and ImageNet) demonstrate the
superiority of AgNet on both cross-modal and single-modal zero-shot image
retrieval tasks.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Multimodal Retrieval 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/jeong2018efficient/">Efficient End-to-end Learning For Quantizable Representations</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Efficient End-to-end Learning For Quantizable Representations' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Efficient End-to-end Learning For Quantizable Representations' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jeong Yeonwoo, Song Hyun Oh</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>9</td>
    <td><p>Embedding representation learning via neural networks is at the core
foundation of modern similarity based search. While much effort has been put in
developing algorithms for learning binary hamming code representations for
search efficiency, this still requires a linear scan of the entire dataset per
each query and trades off the search accuracy through binarization. To this
end, we consider the problem of directly learning a quantizable embedding
representation and the sparse binary hash code end-to-end which can be used to
construct an efficient hash table not only providing significant search
reduction in the number of data but also achieving the state of the art search
accuracy outperforming previous state of the art deep metric learning methods.
We also show that finding the optimal sparse binary hash code in a mini-batch
can be computed exactly in polynomial time by solving a minimum cost flow
problem. Our results on Cifar-100 and on ImageNet datasets show the state of
the art search accuracy in precision@k and NMI metrics while providing up to
98X and 478X search speedup respectively over exhaustive linear search. The
source code is available at
https://github.com/maestrojeong/Deep-Hash-Table-ICML18</p>
</td>
    <td>
      
        ICML 
      
        DATASETS 
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        Efficiency And Optimization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/zieba2018bingan/">Bingan: Learning Compact Binary Descriptors With A Regularized GAN</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Bingan: Learning Compact Binary Descriptors With A Regularized GAN' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Bingan: Learning Compact Binary Descriptors With A Regularized GAN' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zieba et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>36</td>
    <td><p>In this paper, we propose a novel regularization method for Generative
Adversarial Networks, which allows the model to learn discriminative yet
compact binary representations of image patches (image descriptors). We employ
the dimensionality reduction that takes place in the intermediate layers of the
discriminator network and train binarized low-dimensional representation of the
penultimate layer to mimic the distribution of the higher-dimensional preceding
layers. To achieve this, we introduce two loss terms that aim at: (i) reducing
the correlation between the dimensions of the binarized low-dimensional
representation of the penultimate layer i. e. maximizing joint entropy) and
(ii) propagating the relations between the dimensions in the high-dimensional
space to the low-dimensional space. We evaluate the resulting binary image
descriptors on two challenging applications, image matching and retrieval, and
achieve state-of-the-art results.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/wu2018review/">A Review For Weighted Minhash Algorithms</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Review For Weighted Minhash Algorithms' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Review For Weighted Minhash Algorithms' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Knowledge and Data Engineering</td>
    <td>30</td>
    <td><p>Data similarity (or distance) computation is a fundamental research topic
which underpins many high-level applications based on similarity measures in
machine learning and data mining. However, in large-scale real-world scenarios,
the exact similarity computation has become daunting due to â€œ3Vâ€ nature
(volume, velocity and variety) of big data. In such cases, the hashing
techniques have been verified to efficiently conduct similarity estimation in
terms of both theory and practice. Currently, MinHash is a popular technique
for efficiently estimating the Jaccard similarity of binary sets and
furthermore, weighted MinHash is generalized to estimate the generalized
Jaccard similarity of weighted sets. This review focuses on categorizing and
discussing the existing works of weighted MinHash algorithms. In this review,
we mainly categorize the Weighted MinHash algorithms into quantization-based
approaches, â€œactive indexâ€-based ones and others, and show the evolution and
inherent connection of the weighted MinHash algorithms, from the integer
weighted MinHash algorithms to real-valued weighted MinHash ones (particularly
the Consistent Weighted Sampling scheme). Also, we have developed a python
toolbox for the algorithms, and released it in our github. Based on the
toolbox, we experimentally conduct a comprehensive comparative study of the
standard MinHash algorithm and the weighted MinHash ones.</p>
</td>
    <td>
      
        Survey Paper 
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Quantization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/shi2018fast/">Fast Locality Sensitive Hashing For Beam Search On GPU</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fast Locality Sensitive Hashing For Beam Search On GPU' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fast Locality Sensitive Hashing For Beam Search On GPU' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Shi Xing, Xu Shizhen, Knight Kevin</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>9</td>
    <td><p>We present a GPU-based Locality Sensitive Hashing (LSH) algorithm to speed up
beam search for sequence models. We utilize the winner-take-all (WTA) hash,
which is based on relative ranking order of hidden dimensions and thus
resilient to perturbations in numerical values. Our algorithm is designed by
fully considering the underling architecture of CUDA-enabled GPUs
(Algorithm/Architecture Co-design): 1) A parallel Cuckoo hash table is applied
for LSH code lookup (guaranteed O(1) lookup time); 2) Candidate lists are
shared across beams to maximize the parallelism; 3) Top frequent words are
merged into candidate lists to improve performance. Experiments on 4
large-scale neural machine translation models demonstrate that our algorithm
can achieve up to 4x speedup on softmax module, and 2x overall speedup without
hurting BLEU on GPU.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/opitz2018deep/">Deep Metric Learning With BIER: Boosting Independent Embeddings Robustly</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Metric Learning With BIER: Boosting Independent Embeddings Robustly' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Metric Learning With BIER: Boosting Independent Embeddings Robustly' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Opitz et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Pattern Analysis and Machine Intelligence</td>
    <td>164</td>
    <td><p>Learning similarity functions between image pairs with deep neural networks
yields highly correlated activations of embeddings. In this work, we show how
to improve the robustness of such embeddings by exploiting the independence
within ensembles. To this end, we divide the last embedding layer of a deep
network into an embedding ensemble and formulate training this ensemble as an
online gradient boosting problem. Each learner receives a reweighted training
sample from the previous learners. Further, we propose two loss functions which
increase the diversity in our ensemble. These loss functions can be applied
either for weight initialization or during training. Together, our
contributions leverage large embedding sizes more effectively by significantly
reducing correlation of the embedding and consequently increase retrieval
accuracy of the embedding. Our method works with any differentiable loss
function and does not introduce any additional parameters during test time. We
evaluate our metric learning method on image retrieval tasks and show that it
improves over state-of-the-art methods on the CUB 200-2011, Cars-196, Stanford
Online Products, In-Shop Clothes Retrieval and VehicleID datasets.</p>
</td>
    <td>
      
        Distance Metric Learning 
      
        Image Retrieval 
      
        DATASETS 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/j%C3%A4%C3%A4saari2018efficient/">Efficient Autotuning Of Hyperparameters In Approximate Nearest Neighbor Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Efficient Autotuning Of Hyperparameters In Approximate Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Efficient Autotuning Of Hyperparameters In Approximate Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>JÃ¤Ã¤saari Elias, HyvÃ¶nen Ville, Roos Teemu</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>11</td>
    <td><p>Approximate nearest neighbor algorithms are used to speed up nearest neighbor
search in a wide array of applications. However, current indexing methods
feature several hyperparameters that need to be tuned to reach an acceptable
accuracyâ€“speed trade-off. A grid search in the parameter space is often
impractically slow due to a time-consuming index-building procedure. Therefore,
we propose an algorithm for automatically tuning the hyperparameters of
indexing methods based on randomized space-partitioning trees. In particular,
we present results using randomized k-d trees, random projection trees and
randomized PCA trees. The tuning algorithm adds minimal overhead to the
index-building process but is able to find the optimal hyperparameters
accurately. We demonstrate that the algorithm is significantly faster than
existing approaches, and that the indexing methods used are competitive with
the state-of-the-art methods in query time while being faster to build.</p>
</td>
    <td>
      
        Tree Based ANN 
      
        Locality Sensitive Hashing 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/noshad2018scalable/">Scalable Hash-based Estimation Of Divergence Measures</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Scalable Hash-based Estimation Of Divergence Measures' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Scalable Hash-based Estimation Of Divergence Measures' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Noshad Morteza, Hero Alfred O. Iii</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>7</td>
    <td><p>We propose a scalable divergence estimation method based on hashing. Consider
two continuous random variables \(X\) and \(Y\) whose densities have bounded
support. We consider a particular locality sensitive random hashing, and
consider the ratio of samples in each hash bin having non-zero numbers of Y
samples. We prove that the weighted average of these ratios over all of the
hash bins converges to f-divergences between the two samples sets. We show that
the proposed estimator is optimal in terms of both MSE rate and computational
complexity. We derive the MSE rates for two families of smooth functions; the
H"{o}lder smoothness class and differentiable functions. In particular, it is
proved that if the density functions have bounded derivatives up to the order
\(d/2\), where \(d\) is the dimension of samples, the optimal parametric MSE rate
of \(O(1/N)\) can be achieved. The computational complexity is shown to be
\(O(N)\), which is optimal. To the best of our knowledge, this is the first
empirical divergence estimator that has optimal computational complexity and
achieves the optimal parametric MSE estimation rate.</p>
</td>
    <td>
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/liu2018escaping/">Escaping The Curse Of Dimensionality In Similarity Learning: Efficient Frank-wolfe Algorithm And Generalization Bounds</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Escaping The Curse Of Dimensionality In Similarity Learning: Efficient Frank-wolfe Algorithm And Generalization Bounds' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Escaping The Curse Of Dimensionality In Similarity Learning: Efficient Frank-wolfe Algorithm And Generalization Bounds' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu Kuan, Bellet AurÃ©lien</td> <!-- ðŸ”§ You were missing this -->
    <td>Neurocomputing</td>
    <td>14</td>
    <td><p>Similarity and metric learning provides a principled approach to construct a
task-specific similarity from weakly supervised data. However, these methods
are subject to the curse of dimensionality: as the number of features grows
large, poor generalization is to be expected and training becomes intractable
due to high computational and memory costs. In this paper, we propose a
similarity learning method that can efficiently deal with high-dimensional
sparse data. This is achieved through a parameterization of similarity
functions by convex combinations of sparse rank-one matrices, together with the
use of a greedy approximate Frank-Wolfe algorithm which provides an efficient
way to control the number of active features. We show that the convergence rate
of the algorithm, as well as its time and memory complexity, are independent of
the data dimension. We further provide a theoretical justification of our
modeling choices through an analysis of the generalization error, which depends
logarithmically on the sparsity of the solution rather than on the number of
features. Our experiments on datasets with up to one million features
demonstrate the ability of our approach to generalize well despite the high
dimensionality as well as its superiority compared to several competing
methods.</p>
</td>
    <td>
      
        DATASETS 
      
        Tools & Libraries 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/zhe2018deep/">Deep Class-wise Hashing: Semantics-preserving Hashing Via Class-wise Loss</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Class-wise Hashing: Semantics-preserving Hashing Via Class-wise Loss' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Class-wise Hashing: Semantics-preserving Hashing Via Class-wise Loss' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhe Xuefei, Chen Shifeng, Yan Hong</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Neural Networks and Learning Systems</td>
    <td>36</td>
    <td><p>Deep supervised hashing has emerged as an influential solution to large-scale
semantic image retrieval problems in computer vision. In the light of recent
progress, convolutional neural network based hashing methods typically seek
pair-wise or triplet labels to conduct the similarity preserving learning.
However, complex semantic concepts of visual contents are hard to capture by
similar/dissimilar labels, which limits the retrieval performance. Generally,
pair-wise or triplet losses not only suffer from expensive training costs but
also lack in extracting sufficient semantic information. In this regard, we
propose a novel deep supervised hashing model to learn more compact class-level
similarity preserving binary codes. Our deep learning based model is motivated
by deep metric learning that directly takes semantic labels as supervised
information in training and generates corresponding discriminant hashing code.
Specifically, a novel cubic constraint loss function based on Gaussian
distribution is proposed, which preserves semantic variations while penalizes
the overlap part of different classes in the embedding space. To address the
discrete optimization problem introduced by binary codes, a two-step
optimization strategy is proposed to provide efficient training and avoid the
problem of gradient vanishing. Extensive experiments on four large-scale
benchmark databases show that our model can achieve the state-of-the-art
retrieval performance. Moreover, when training samples are limited, our method
surpasses other supervised deep hashing methods with non-negligible margins.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        Compact Codes 
      
        Neural Hashing 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/wu2018unsupervised/">Unsupervised Feature Learning Via Non-parametric Instance-level Discrimination</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Unsupervised Feature Learning Via Non-parametric Instance-level Discrimination' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Unsupervised Feature Learning Via Non-parametric Instance-level Discrimination' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>175</td>
    <td><p>Neural net classifiers trained on data with annotated class labels can also
capture apparent visual similarity among categories without being directed to
do so. We study whether this observation can be extended beyond the
conventional domain of supervised learning: Can we learn a good feature
representation that captures apparent similarity among instances, instead of
classes, by merely asking the feature to be discriminative of individual
instances? We formulate this intuition as a non-parametric classification
problem at the instance-level, and use noise-contrastive estimation to tackle
the computational challenges imposed by the large number of instance classes.
Our experimental results demonstrate that, under unsupervised learning
settings, our method surpasses the state-of-the-art on ImageNet classification
by a large margin. Our method is also remarkable for consistently improving
test performance with more training data and better network architectures. By
fine-tuning the learned feature, we further obtain competitive results for
semi-supervised learning and object detection tasks. Our non-parametric model
is highly compact: With 128 features per image, our method requires only 600MB
storage for a million images, enabling fast nearest neighbour retrieval at the
run time.</p>
</td>
    <td>
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2018</td>
    <td>
      <a href="/publications/novotn%C3%BD2018implementation/">Implementation Notes For The Soft Cosine Measure</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Implementation Notes For The Soft Cosine Measure' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Implementation Notes For The Soft Cosine Measure' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>NovotnÃ½ VÃ­t</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 27th ACM International Conference on Information and Knowledge Management</td>
    <td>27</td>
    <td><p>The standard bag-of-words vector space model (VSM) is efficient, and
ubiquitous in information retrieval, but it underestimates the similarity of
documents with the same meaning, but different terminology. To overcome this
limitation, Sidorov et al. proposed the Soft Cosine Measure (SCM) that
incorporates term similarity relations. Charlet and Damnati showed that the SCM
is highly effective in question answering (QA) systems. However, the
orthonormalization algorithm proposed by Sidorov et al. has an impractical time
complexity of \(\mathcal O(n^4)\), where n is the size of the vocabulary.
  In this paper, we prove a tighter lower worst-case time complexity bound of
\(\mathcal O(n^3)\). We also present an algorithm for computing the similarity
between documents and we show that its worst-case time complexity is \(\mathcal
O(1)\) given realistic conditions. Lastly, we describe implementation in
general-purpose vector databases such as Annoy, and Faiss and in the inverted
indices of text search engines such as Apache Lucene, and ElasticSearch. Our
results enable the deployment of the SCM in real-world information retrieval
systems.</p>
</td>
    <td>
      
        CIKM 
      
        Text Retrieval 
      
        Tools & Libraries 
      
        Graph Based ANN 
      
    </td>
    </tr>      
    
    
      
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/sivertsen2017fast/">Fast Nearest Neighbor Preserving Embeddings</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fast Nearest Neighbor Preserving Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fast Nearest Neighbor Preserving Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Sivertsen Johan</td> <!-- ðŸ”§ You were missing this -->
    <td>ACM Transactions on Algorithms</td>
    <td>62</td>
    <td><p>We show an analog to the Fast Johnson-Lindenstrauss Transform for Nearest
Neighbor Preserving Embeddings in \(â„“â‚‚\). These are sparse, randomized
embeddings that preserve the (approximate) nearest neighbors. The
dimensionality of the embedding space is bounded not by the size of the
embedded set n, but by its doubling dimension {\lambda}. For most large
real-world datasets this will mean a considerably lower-dimensional embedding
space than possible when preserving all distances. The resulting embeddings can
be used with existing approximate nearest neighbor data structures to yield
speed improvements.</p>
</td>
    <td>
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/christiani2017scalable/">Scalable And Robust Set Similarity Join</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Scalable And Robust Set Similarity Join' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Scalable And Robust Set Similarity Join' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Christiani Tobias, Pagh Rasmus, Sivertsen Johan</td> <!-- ðŸ”§ You were missing this -->
    <td>2018 IEEE 34th International Conference on Data Engineering (ICDE)</td>
    <td>31</td>
    <td><p>Set similarity join is a fundamental and well-studied database operator. It
is usually studied in the exact setting where the goal is to compute all pairs
of sets that exceed a given similarity threshold (measured e.g. as Jaccard
similarity). But set similarity join is often used in settings where 100%
recall may not be important â€” indeed, where the exact set similarity join is
itself only an approximation of the desired result set.
  We present a new randomized algorithm for set similarity join that can
achieve any desired recall up to 100%, and show theoretically and empirically
that it significantly improves on existing methods. The present
state-of-the-art exact methods are based on prefix-filtering, the performance
of which depends on the data set having many rare tokens. Our method is robust
against the absence of such structure in the data. At 90% recall our algorithm
is often more than an order of magnitude faster than state-of-the-art exact
methods, depending on how well a data set lends itself to prefix filtering. Our
experiments on benchmark data sets also show that the method is several times
faster than comparable approximate methods. Our algorithm makes use of recent
theoretical advances in high-dimensional sketching and indexing that we believe
to be of wider relevance to the data engineering community.</p>
</td>
    <td>
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/li2017fast/">Fast K-nearest Neighbour Search Via Prioritized DCI</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fast K-nearest Neighbour Search Via Prioritized DCI' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fast K-nearest Neighbour Search Via Prioritized DCI' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li Ke, Malik Jitendra</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>14</td>
    <td><p>Most exact methods for k-nearest neighbour search suffer from the curse of
dimensionality; that is, their query times exhibit exponential dependence on
either the ambient or the intrinsic dimensionality. Dynamic Continuous Indexing
(DCI) offers a promising way of circumventing the curse and successfully
reduces the dependence of query time on intrinsic dimensionality from
exponential to sublinear. In this paper, we propose a variant of DCI, which we
call Prioritized DCI, and show a remarkable improvement in the dependence of
query time on intrinsic dimensionality. In particular, a linear increase in
intrinsic dimensionality, or equivalently, an exponential increase in the
number of points near a query, can be mostly counteracted with just a linear
increase in space. We also demonstrate empirically that Prioritized DCI
significantly outperforms prior methods. In particular, relative to
Locality-Sensitive Hashing (LSH), Prioritized DCI reduces the number of
distance evaluations by a factor of 14 to 116 and the memory consumption by a
factor of 21.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/meyer2017deep/">Deep Metric Learning And Image Classification With Nearest Neighbour Gaussian Kernels</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Metric Learning And Image Classification With Nearest Neighbour Gaussian Kernels' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Metric Learning And Image Classification With Nearest Neighbour Gaussian Kernels' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Meyer Benjamin J., Harwood Ben, Drummond Tom</td> <!-- ðŸ”§ You were missing this -->
    <td>2018 25th IEEE International Conference on Image Processing (ICIP)</td>
    <td>29</td>
    <td><p>We present a Gaussian kernel loss function and training algorithm for
convolutional neural networks that can be directly applied to both distance
metric learning and image classification problems. Our method treats all
training features from a deep neural network as Gaussian kernel centres and
computes loss by summing the influence of a featureâ€™s nearby centres in the
feature embedding space. Our approach is made scalable by treating it as an
approximate nearest neighbour search problem. We show how to make end-to-end
learning feasible, resulting in a well formed embedding space, in which
semantically related instances are likely to be located near one another,
regardless of whether or not the network was trained on those classes. Our
approach outperforms state-of-the-art deep metric learning approaches on
embedding learning challenges, as well as conventional softmax classification
on several datasets.</p>
</td>
    <td>
      
        DATASETS 
      
        Similarity Search 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/han2017mild/">MILD: Multi-index Hashing For Loop Closure Detection</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=MILD: Multi-index Hashing For Loop Closure Detection' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=MILD: Multi-index Hashing For Loop Closure Detection' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Han Lei, Fang Lu</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 IEEE International Conference on Multimedia and Expo (ICME)</td>
    <td>9</td>
    <td><p>Loop Closure Detection (LCD) has been proved to be extremely useful in global
consistent visual Simultaneously Localization and Mapping (SLAM) and
appearance-based robot relocalization. Methods exploiting binary features in
bag of words representation have recently gained a lot of popularity for their
efficiency, but suffer from low recall due to the inherent drawback that high
dimensional binary feature descriptors lack well-defined centroids. In this
paper, we propose a realtime LCD approach called MILD (Multi-Index Hashing for
Loop closure Detection), in which image similarity is measured by feature
matching directly to achieve high recall without introducing extra
computational complexity with the aid of Multi-Index Hashing (MIH). A
theoretical analysis of the approximate image similarity measurement using MIH
is presented, which reveals the trade-off between efficiency and accuracy from
a probabilistic perspective. Extensive comparisons with state-of-the-art LCD
methods demonstrate the superiority of MILD in both efficiency and accuracy.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Alt 
      
        Vector Indexing 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/christiani2017fast/">Fast Locality-sensitive Hashing Frameworks For Approximate Near Neighbor Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fast Locality-sensitive Hashing Frameworks For Approximate Near Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fast Locality-sensitive Hashing Frameworks For Approximate Near Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Christiani Tobias</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>14</td>
    <td><p>The Indyk-Motwani Locality-Sensitive Hashing (LSH) framework (STOC 1998) is a
general technique for constructing a data structure to answer approximate near
neighbor queries by using a distribution \(\mathcal{H}\) over locality-sensitive
hash functions that partition space. For a collection of \(n\) points, after
preprocessing, the query time is dominated by \(O(n^{\rho} log n)\) evaluations
of hash functions from \(\mathcal{H}\) and \(O(n^{\rho})\) hash table lookups and
distance computations where \(\rho \in (0,1)\) is determined by the
locality-sensitivity properties of \(\mathcal{H}\). It follows from a recent
result by Dahlgaard et al. (FOCS 2017) that the number of locality-sensitive
hash functions can be reduced to \(O(log^2 n)\), leaving the query time to be
dominated by \(O(n^{\rho})\) distance computations and \(O(n^{\rho} log n)\)
additional word-RAM operations. We state this result as a general framework and
provide a simpler analysis showing that the number of lookups and distance
computations closely match the Indyk-Motwani framework, making it a viable
replacement in practice. Using ideas from another locality-sensitive hashing
framework by Andoni and Indyk (SODA 2006) we are able to reduce the number of
additional word-RAM operations to \(O(n^\rho)\).</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Graph Based ANN 
      
        Efficiency And Optimization 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/shen2017deep/">Deep Binaries: Encoding Semantic-rich Cues For Efficient Textual-visual Cross Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Binaries: Encoding Semantic-rich Cues For Efficient Textual-visual Cross Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Binaries: Encoding Semantic-rich Cues For Efficient Textual-visual Cross Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Shen et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 IEEE International Conference on Computer Vision (ICCV)</td>
    <td>49</td>
    <td><p>Cross-modal hashing is usually regarded as an effective technique for
large-scale textual-visual cross retrieval, where data from different
modalities are mapped into a shared Hamming space for matching. Most of the
traditional textual-visual binary encoding methods only consider holistic image
representations and fail to model descriptive sentences. This renders existing
methods inappropriate to handle the rich semantics of informative cross-modal
data for quality textual-visual search tasks. To address the problem of hashing
cross-modal data with semantic-rich cues, in this paper, a novel integrated
deep architecture is developed to effectively encode the detailed semantics of
informative images and long descriptive sentences, named as Textual-Visual Deep
Binaries (TVDB). In particular, region-based convolutional networks with long
short-term memory units are introduced to fully explore image regional details
while semantic cues of sentences are modeled by a text convolutional network.
Additionally, we propose a stochastic batch-wise training routine, where
high-quality binary codes and deep encoding functions are efficiently optimized
in an alternating manner. Experiments are conducted on three multimedia
datasets, i.e. Microsoft COCO, IAPR TC-12, and INRIA Web Queries, where the
proposed TVDB model significantly outperforms state-of-the-art binary coding
methods in the task of cross-modal retrieval.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Alt 
      
        ICCV 
      
        Multimodal Retrieval 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/he2017hashing/">Hashing As Tie-aware Learning To Rank</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hashing As Tie-aware Learning To Rank' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hashing As Tie-aware Learning To Rank' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>He et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</td>
    <td>89</td>
    <td><p>Hashing, or learning binary embeddings of data, is frequently used in nearest
neighbor retrieval. In this paper, we develop learning to rank formulations for
hashing, aimed at directly optimizing ranking-based evaluation metrics such as
Average Precision (AP) and Normalized Discounted Cumulative Gain (NDCG). We
first observe that the integer-valued Hamming distance often leads to tied
rankings, and propose to use tie-aware versions of AP and NDCG to evaluate
hashing for retrieval. Then, to optimize tie-aware ranking metrics, we derive
their continuous relaxations, and perform gradient-based optimization with deep
neural networks. Our results establish the new state-of-the-art for image
retrieval by Hamming ranking in common benchmarks.</p>
</td>
    <td>
      
        CVPR 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/pachori2017hashing/">Hashing In The Zero Shot Framework With Domain Adaptation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hashing In The Zero Shot Framework With Domain Adaptation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hashing In The Zero Shot Framework With Domain Adaptation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Pachori Shubham, Deshpande Ameya, Raman Shanmuganathan</td> <!-- ðŸ”§ You were missing this -->
    <td>Neurocomputing</td>
    <td>24</td>
    <td><p>Techniques to learn hash codes which can store and retrieve large dimensional
multimedia data efficiently have attracted broad research interests in the
recent years. With rapid explosion of newly emerged concepts and online data,
existing supervised hashing algorithms suffer from the problem of scarcity of
ground truth annotations due to the high cost of obtaining manual annotations.
Therefore, we propose an algorithm to learn a hash function from training
images belonging to <code class="language-plaintext highlighter-rouge">seen' classes which can efficiently encode images of
</code>unseenâ€™ classes to binary codes. Specifically, we project the image features
from visual space and semantic features from semantic space into a common
Hamming subspace. Earlier works to generate hash codes have tried to relax the
discrete constraints on hash codes and solve the continuous optimization
problem. However, it often leads to quantization errors. In this work, we use
the max-margin classifier to learn an efficient hash function. To address the
concern of domain-shift which may arise due to the introduction of new classes,
we also introduce an unsupervised domain adaptation model in the proposed
hashing framework. Results on the three datasets show the advantage of using
domain adaptation in learning a high-quality hash function and superiority of
our method for the task of image retrieval performance as compared to several
state-of-the-art hashing methods.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Quantization 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/shi2017face/">Face Clustering: Representation And Pairwise Constraints</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Face Clustering: Representation And Pairwise Constraints' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Face Clustering: Representation And Pairwise Constraints' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Shi Yichun, Otto Charles, Jain Anil K.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Information Forensics and Security</td>
    <td>107</td>
    <td><p>Clustering face images according to their identity has two important
applications: (i) grouping a collection of face images when no external labels
are associated with images, and (ii) indexing for efficient large scale face
retrieval. The clustering problem is composed of two key parts: face
representation and choice of similarity for grouping faces. We first propose a
representation based on ResNet, which has been shown to perform very well in
image classification problems. Given this representation, we design a
clustering algorithm, Conditional Pairwise Clustering (ConPaC), which directly
estimates the adjacency matrix only based on the similarity between face
images. This allows a dynamic selection of number of clusters and retains
pairwise similarity between faces. ConPaC formulates the clustering problem as
a Conditional Random Field (CRF) model and uses Loopy Belief Propagation to
find an approximate solution for maximizing the posterior probability of the
adjacency matrix. Experimental results on two benchmark face datasets (LFW and
IJB-B) show that ConPaC outperforms well known clustering algorithms such as
k-means, spectral clustering and approximate rank-order. Additionally, our
algorithm can naturally incorporate pairwise constraints to obtain a
semi-supervised version that leads to improved clustering performance. We also
propose an k-NN variant of ConPaC, which has a linear time complexity given a
k-NN graph, suitable for large datasets.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/tolias2017asymmetric/">Asymmetric Feature Maps With Application To Sketch Based Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Asymmetric Feature Maps With Application To Sketch Based Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Asymmetric Feature Maps With Application To Sketch Based Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Tolias Giorgos, Chum OndÅ™ej</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>39</td>
    <td><p>We propose a novel concept of asymmetric feature maps (AFM), which allows to
evaluate multiple kernels between a query and database entries without
increasing the memory requirements. To demonstrate the advantages of the AFM
method, we derive a short vector image representation that, due to asymmetric
feature maps, supports efficient scale and translation invariant sketch-based
image retrieval. Unlike most of the short-code based retrieval systems, the
proposed method provides the query localization in the retrieved image. The
efficiency of the search is boosted by approximating a 2D translation search
via trigonometric polynomial of scores by 1D projections. The projections are a
special case of AFM. An order of magnitude speed-up is achieved compared to
traditional trigonometric polynomials. The results are boosted by an
image-based average query expansion, exceeding significantly the state of the
art on standard benchmarks.</p>
</td>
    <td>
      
        CVPR 
      
        Image Retrieval 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/jain2017subic/">SUBIC: A Supervised, Structured Binary Code For Image Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=SUBIC: A Supervised, Structured Binary Code For Image Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=SUBIC: A Supervised, Structured Binary Code For Image Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jain et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 IEEE International Conference on Computer Vision (ICCV)</td>
    <td>61</td>
    <td><p>For large-scale visual search, highly compressed yet meaningful
representations of images are essential. Structured vector quantizers based on
product quantization and its variants are usually employed to achieve such
compression while minimizing the loss of accuracy. Yet, unlike binary hashing
schemes, these unsupervised methods have not yet benefited from the
supervision, end-to-end learning and novel architectures ushered in by the deep
learning revolution. We hence propose herein a novel method to make deep
convolutional neural networks produce supervised, compact, structured binary
codes for visual search. Our method makes use of a novel block-softmax
non-linearity and of batch-based entropy losses that together induce structure
in the learned encodings. We show that our method outperforms state-of-the-art
compact representations based on deep hashing or structured quantization in
single and cross-domain category retrieval, instance retrieval and
classification. We make our code and models publicly available online.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Compact Codes 
      
        Neural Hashing 
      
        ICCV 
      
        Quantization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/kociumaka2017longest/">Longest Common Substring With Approximately \(k\) Mismatches</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Longest Common Substring With Approximately \(k\) Mismatches' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Longest Common Substring With Approximately \(k\) Mismatches' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Kociumaka Tomasz, Radoszewski Jakub, Starikovskaya Tatiana</td> <!-- ðŸ”§ You were missing this -->
    <td>Algorithmica</td>
    <td>20</td>
    <td><p>In the longest common substring problem, we are given two strings of length
\(n\) and must find a substring of maximal length that occurs in both strings. It
is well known that the problem can be solved in linear time, but the solution
is not robust and can vary greatly when the input strings are changed even by
one character. To circumvent this, Leimeister and Morgenstern introduced the
problem of the longest common substring with \(k\) mismatches. Lately, this
problem has received a lot of attention in the literature. In this paper, we
first show a conditional lower bound based on the SETH hypothesis implying that
there is little hope to improve existing solutions. We then introduce a new but
closely related problem of the longest common substring with approximately \(k\)
mismatches and use locality-sensitive hashing to show that it admits a solution
with strongly subquadratic running time. We also apply these results to obtain
a strongly subquadratic-time 2-approximation algorithm for the longest common
substring with \(k\) mismatches problem and show conditional hardness of
improving its approximation ratio.</p>
</td>
    <td>
      
        Hashing Methods 
      
        ALT 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/wang2017supervised/">Supervised Deep Hashing For Hierarchical Labeled Data</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Supervised Deep Hashing For Hierarchical Labeled Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Supervised Deep Hashing For Hierarchical Labeled Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>26</td>
    <td><p>Recently, hashing methods have been widely used in large-scale image
retrieval. However, most existing hashing methods did not consider the
hierarchical relation of labels, which means that they ignored the rich
information stored in the hierarchy. Moreover, most of previous works treat
each bit in a hash code equally, which does not meet the scenario of
hierarchical labeled data. In this paper, we propose a novel deep hashing
method, called supervised hierarchical deep hashing (SHDH), to perform hash
code learning for hierarchical labeled data. Specifically, we define a novel
similarity formula for hierarchical labeled data by weighting each layer, and
design a deep convolutional neural network to obtain a hash code for each data
point. Extensive experiments on several real-world public datasets show that
the proposed method outperforms the state-of-the-art baselines in the image
retrieval task.</p>
</td>
    <td>
      
        AAAI 
      
        DATASETS 
      
        Neural Hashing 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/cui2017graphmatch/">Graphmatch: Efficient Large-scale Graph Construction For Structure From Motion</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Graphmatch: Efficient Large-scale Graph Construction For Structure From Motion' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Graphmatch: Efficient Large-scale Graph Construction For Structure From Motion' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Cui et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 International Conference on 3D Vision (3DV)</td>
    <td>9</td>
    <td><p>We present GraphMatch, an approximate yet efficient method for building the
matching graph for large-scale structure-from-motion (SfM) pipelines. Unlike
modern SfM pipelines that use vocabulary (Voc.) trees to quickly build the
matching graph and avoid a costly brute-force search of matching image pairs,
GraphMatch does not require an expensive offline pre-processing phase to
construct a Voc. tree. Instead, GraphMatch leverages two priors that can
predict which image pairs are likely to match, thereby making the matching
process for SfM much more efficient. The first is a score computed from the
distance between the Fisher vectors of any two images. The second prior is
based on the graph distance between vertices in the underlying matching graph.
GraphMatch combines these two priors into an iterative â€œsample-and-propagateâ€
scheme similar to the PatchMatch algorithm. Its sampling stage uses Fisher
similarity priors to guide the search for matching image pairs, while its
propagation stage explores neighbors of matched pairs to find new ones with a
high image similarity score. Our experiments show that GraphMatch finds the
most image pairs as compared to competing, approximate methods while at the
same time being the most efficient.</p>
</td>
    <td>
      
        Graph Based ANN 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/connor2017high/">High-dimensional Simplexes For Supermetric Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=High-dimensional Simplexes For Supermetric Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=High-dimensional Simplexes For Supermetric Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Connor Richard, Vadicamo Lucia, Rabitti Fausto</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>19</td>
    <td><p>In 1953, Blumenthal showed that every semi-metric space that is isometrically
embeddable in a Hilbert space has the n-point property; we have previously
called such spaces supermetric spaces. Although this is a strictly stronger
property than triangle inequality, it is nonetheless closely related and many
useful metric spaces possess it. These include Euclidean, Cosine and
Jensen-Shannon spaces of any dimension. A simple corollary of the n-point
property is that, for any (n+1) objects sampled from the space, there exists an
n-dimensional simplex in Euclidean space whose edge lengths correspond to the
distances among the objects. We show how the construction of such simplexes in
higher dimensions can be used to give arbitrarily tight lower and upper bounds
on distances within the original space. This allows the construction of an
n-dimensional Euclidean space, from which lower and upper bounds of the
original space can be calculated, and which is itself an indexable space with
the n-point property. For similarity search, the engineering tradeoffs are
good: we show significant reductions in data size and metric cost with little
loss of accuracy, leading to a significant overall improvement in search
performance.</p>
</td>
    <td>
      
        Alt 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/curt%C3%B32017segmentation/">Segmentation Of Objects By Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Segmentation Of Objects By Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Segmentation Of Objects By Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>CurtÃ³ et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Multimedia</td>
    <td>29</td>
    <td><p>We propose a novel approach to address the problem of Simultaneous Detection
and Segmentation introduced in [Hariharan et al 2014]. Using the hierarchical
structures first presented in [Arbel'aez et al 2011] we use an efficient and
accurate procedure that exploits the feature information of the hierarchy using
Locality Sensitive Hashing. We build on recent work that utilizes convolutional
neural networks to detect bounding boxes in an image [Ren et al 2015] and then
use the top similar hierarchical region that best fits each bounding box after
hashing, we call this approach C&amp;Z Segmentation. We then refine our final
segmentation results by automatic hierarchical pruning. C&amp;Z Segmentation
introduces a train-free alternative to Hypercolumns [Hariharan et al 2015]. We
conduct extensive experiments on PASCAL VOC 2012 segmentation dataset, showing
that C&amp;Z gives competitive state-of-the-art segmentations of objects.</p>
</td>
    <td>
      
        Alt 
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/dahlgaard2017fast/">Fast Similarity Sketching</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fast Similarity Sketching' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fast Similarity Sketching' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Dahlgaard et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 IEEE 58th Annual Symposium on Foundations of Computer Science (FOCS)</td>
    <td>30</td>
    <td><p>We consider the \(\textit{Similarity Sketching}\) problem: Given a universe
\([u] = \{0,\ldots, u-1\}\) we want a random function \(S\) mapping subsets
\(A\subseteq [u]\) into vectors \(S(A)\) of size \(t\), such that the Jaccard
similarity \(J(A,B) = |A\cap B|/|A\cup B|\) between sets \(A\) and \(B\) is
preserved. More precisely, define \(X_i = [S(A)[i] =
  S(B)[i]]\) and \(X = \sum_{i\in [t]} X_i\). We want \(E[X_i]=J(A,B)\), and we want
\(X\) to be strongly concentrated around \(E[X] = t \cdot J(A,B)\) (i.e.
Chernoff-style bounds). This is a fundamental problem which has found numerous
applications in data mining, large-scale classification, computer vision,
similarity search, etc. via the classic MinHash algorithm. The vectors \(S(A)\)
are also called \(\textit{sketches}\). Strong concentration is critical, for
often we want to sketch many sets \(B_1,\ldots,B_n\) so that we later, for a
query set \(A\), can find (one of) the most similar \(B_i\). It is then critical
that no \(B_i\) looks much more similar to \(A\) due to errors in the sketch.
  The seminal \(t\times\textit{MinHash}\) algorithm uses \(t\) random hash
functions \(h_1,\ldots, h_t\), and stores \(\left ( \min_{a\in A} h_1(A),\ldots,
\min_{a\in A} h_t(A) \right )\) as the sketch of \(A\). The main drawback of
MinHash is, however, its \(O(t\cdot |A|)\) running time, and finding a sketch
with similar properties and faster running time has been the subject of several
papers. (continuedâ€¦)</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/han2017beyond/">Beyond SIFT Using Binary Features For Loop Closure Detection</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Beyond SIFT Using Binary Features For Loop Closure Detection' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Beyond SIFT Using Binary Features For Loop Closure Detection' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Han et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</td>
    <td>10</td>
    <td><p>In this paper a binary feature based Loop Closure Detection (LCD) method is
proposed, which for the first time achieves higher precision-recall (PR)
performance compared with state-of-the-art SIFT feature based approaches. The
proposed system originates from our previous work Multi-Index hashing for Loop
closure Detection (MILD), which employs Multi-Index Hashing
(MIH)~\cite{greene1994multi} for Approximate Nearest Neighbor (ANN) search of
binary features. As the accuracy of MILD is limited by repeating textures and
inaccurate image similarity measurement, burstiness handling is introduced to
solve this problem and achieves considerable accuracy improvement.
Additionally, a comprehensive theoretical analysis on MIH used in MILD is
conducted to further explore the potentials of hashing methods for ANN search
of binary features from probabilistic perspective. This analysis provides more
freedom on best parameter choosing in MIH for different application scenarios.
Experiments on popular public datasets show that the proposed approach achieved
the highest accuracy compared with state-of-the-art while running at 30Hz for
databases containing thousands of images.</p>
</td>
    <td>
      
        DATASETS 
      
        IROS 
      
        Hashing Methods 
      
        Similarity Search 
      
        Vector Indexing 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/conjeti2017learning/">Learning Robust Hash Codes For Multiple Instance Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning Robust Hash Codes For Multiple Instance Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning Robust Hash Codes For Multiple Instance Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Conjeti et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Pattern Recognition Letters</td>
    <td>12</td>
    <td><p>In this paper, for the first time, we introduce a multiple instance (MI) deep
hashing technique for learning discriminative hash codes with weak bag-level
supervision suited for large-scale retrieval. We learn such hash codes by
aggregating deeply learnt hierarchical representations across bag members
through a dedicated MI pool layer. For better trainability and retrieval
quality, we propose a two-pronged approach that includes robust optimization
and training with an auxiliary single instance hashing arm which is
down-regulated gradually. We pose retrieval for tumor assessment as an MI
problem because tumors often coexist with benign masses and could exhibit
complementary signatures when scanned from different anatomical views.
Experimental validations on benchmark mammography and histology datasets
demonstrate improved retrieval performance over the state-of-the-art methods.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/dahlgaard2017practical/">Practical Hash Functions For Similarity Estimation And Dimensionality Reduction</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Practical Hash Functions For Similarity Estimation And Dimensionality Reduction' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Practical Hash Functions For Similarity Estimation And Dimensionality Reduction' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Dahlgaard SÃ¸ren, Knudsen Mathias BÃ¦k Tejs, Thorup Mikkel</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>16</td>
    <td><p>Hashing is a basic tool for dimensionality reduction employed in several
aspects of machine learning. However, the perfomance analysis is often carried
out under the abstract assumption that a truly random unit cost hash function
is used, without concern for which concrete hash function is employed. The
concrete hash function may work fine on sufficiently random input. The question
is if it can be trusted in the real world when faced with more structured
input.
  In this paper we focus on two prominent applications of hashing, namely
similarity estimation with the one permutation hashing (OPH) scheme of Li et
al. [NIPSâ€™12] and feature hashing (FH) of Weinberger et al. [ICMLâ€™09], both of
which have found numerous applications, i.e. in approximate near-neighbour
search with LSH and large-scale classification with SVM.
  We consider mixed tabulation hashing of Dahlgaard et al.[FOCSâ€™15] which was
proved to perform like a truly random hash function in many applications,
including OPH. Here we first show improved concentration bounds for FH with
truly random hashing and then argue that mixed tabulation performs similar for
sparse input. Our main contribution, however, is an experimental comparison of
different hashing schemes when used inside FH, OPH, and LSH.
  We find that mixed tabulation hashing is almost as fast as the
multiply-mod-prime scheme ax+b mod p. Mutiply-mod-prime is guaranteed to work
well on sufficiently random data, but we demonstrate that in the above
applications, it can lead to bias and poor concentration on both real-world and
synthetic data. We also compare with the popular MurmurHash3, which has no
proven guarantees. Mixed tabulation and MurmurHash3 both perform similar to
truly random hashing in our experiments. However, mixed tabulation is 40%
faster than MurmurHash3, and it has the proven guarantee of good performance on
all possible input.</p>
</td>
    <td>
      
        ICML 
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/min2017exemplar/">Exemplar-centered Supervised Shallow Parametric Data Embedding</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Exemplar-centered Supervised Shallow Parametric Data Embedding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Exemplar-centered Supervised Shallow Parametric Data Embedding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Min Martin Renqiang, Guo Hongyu, Song Dongjin</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>8</td>
    <td><p>Metric learning methods for dimensionality reduction in combination with
k-Nearest Neighbors (kNN) have been extensively deployed in many
classification, data embedding, and information retrieval applications.
However, most of these approaches involve pairwise training data comparisons,
and thus have quadratic computational complexity with respect to the size of
training set, preventing them from scaling to fairly big datasets. Moreover,
during testing, comparing test data against all the training data points is
also expensive in terms of both computational cost and resources required.
Furthermore, previous metrics are either too constrained or too expressive to
be well learned. To effectively solve these issues, we present an
exemplar-centered supervised shallow parametric data embedding model, using a
Maximally Collapsing Metric Learning (MCML) objective. Our strategy learns a
shallow high-order parametric embedding function and compares training/test
data only with learned or precomputed exemplars, resulting in a cost function
with linear computational complexity for both training and testing. We also
empirically demonstrate, using several benchmark datasets, that for
classification in two-dimensional embedding space, our approach not only gains
speedup of kNN by hundreds of times, but also outperforms state-of-the-art
supervised embedding approaches.</p>
</td>
    <td>
      
        Distance Metric Learning 
      
        DATASETS 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/dai2017stochastic/">Stochastic Generative Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Stochastic Generative Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Stochastic Generative Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Dai et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>73</td>
    <td><p>Learning-based binary hashing has become a powerful paradigm for fast search
and retrieval in massive databases. However, due to the requirement of discrete
outputs for the hash functions, learning such functions is known to be very
challenging. In addition, the objective functions adopted by existing hashing
techniques are mostly chosen heuristically. In this paper, we propose a novel
generative approach to learn hash functions through Minimum Description Length
principle such that the learned hash codes maximally compress the dataset and
can also be used to regenerate the inputs. We also develop an efficient
learning algorithm based on the stochastic distributional gradient, which
avoids the notorious difficulty caused by binary output constraints, to jointly
optimize the parameters of the hash function and the associated generative
model. Extensive experiments on a variety of large-scale datasets show that the
proposed method achieves better retrieval results than the existing
state-of-the-art methods.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/lindgren2017leveraging/">Leveraging Sparsity For Efficient Submodular Data Summarization</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Leveraging Sparsity For Efficient Submodular Data Summarization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Leveraging Sparsity For Efficient Submodular Data Summarization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lindgren Erik M., Wu Shanshan, Dimakis Alexandros G.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>12</td>
    <td><p>The facility location problem is widely used for summarizing large datasets
and has additional applications in sensor placement, image retrieval, and
clustering. One difficulty of this problem is that submodular optimization
algorithms require the calculation of pairwise benefits for all items in the
dataset. This is infeasible for large problems, so recent work proposed to only
calculate nearest neighbor benefits. One limitation is that several strong
assumptions were invoked to obtain provable approximation guarantees. In this
paper we establish that these extra assumptions are not necessaryâ€”solving the
sparsified problem will be almost optimal under the standard assumptions of the
problem. We then analyze a different method of sparsification that is a better
model for methods such as Locality Sensitive Hashing to accelerate the nearest
neighbor computations and extend the use of the problem to a broader family of
similarities. We validate our approach by demonstrating that it rapidly
generates interpretable summaries.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/prasath2017distance/">Distance And Similarity Measures Effect On The Performance Of K-nearest Neighbor Classifier -- A Review</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Distance And Similarity Measures Effect On The Performance Of K-nearest Neighbor Classifier -- A Review' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Distance And Similarity Measures Effect On The Performance Of K-nearest Neighbor Classifier -- A Review' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Prasath et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>92</td>
    <td><p>The K-nearest neighbor (KNN) classifier is one of the simplest and most
common classifiers, yet its performance competes with the most complex
classifiers in the literature. The core of this classifier depends mainly on
measuring the distance or similarity between the tested examples and the
training examples. This raises a major question about which distance measures
to be used for the KNN classifier among a large number of distance and
similarity measures available? This review attempts to answer this question
through evaluating the performance (measured by accuracy, precision and recall)
of the KNN using a large number of distance measures, tested on a number of
real-world datasets, with and without adding different levels of noise. The
experimental results show that the performance of KNN classifier depends
significantly on the distance used, and the results showed large gaps between
the performances of different distances. We found that a recently proposed
non-convex distance performed the best when applied on most datasets comparing
to the other tested distances. In addition, the performance of the KNN with
this top performing distance degraded only about \(20%\) while the noise level
reaches \(90%\), this is true for most of the distances used as well. This means
that the KNN classifier using any of the top \(10\) distances tolerate noise to a
certain degree. Moreover, the results show that some distances are less
affected by the added noise comparing to other distances.</p>
</td>
    <td>
      
        Survey Paper 
      
        Graph Based ANN 
      
        DATASETS 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/depalma2017distributed/">Distributed Stratified Locality Sensitive Hashing For Critical Event Prediction In The Cloud</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Distributed Stratified Locality Sensitive Hashing For Critical Event Prediction In The Cloud' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Distributed Stratified Locality Sensitive Hashing For Critical Event Prediction In The Cloud' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>de Palma Alessandro, Hemberg Erik, O'reilly Una-may</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 21st ACM international conference on Information and knowledge management</td>
    <td>52</td>
    <td><p>The availability of massive healthcare data repositories calls for efficient
tools for data-driven medicine. We introduce a distributed system for
Stratified Locality Sensitive Hashing to perform fast similarity-based
prediction on large medical waveform datasets. Our implementation, for an ICU
use case, prioritizes latency over throughput and is targeted at a cloud
environment. We demonstrate our system on Acute Hypotensive Episode prediction
from Arterial Blood Pressure waveforms. On a dataset of \(1.37\) million points,
we show scaling up to \(40\) processors and a \(21\times\) speedup in number of
comparisons to parallel exhaustive search at the price of a \(10%\) Matthews
correlation coefficient (MCC) loss. Furthermore, if additional MCC loss can be
tolerated, our system achieves speedups up to two orders of magnitude.</p>
</td>
    <td>
      
        CIKM 
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Alt 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/pratap2017efficient/">Efficient Compression Technique For Sparse Sets</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Efficient Compression Technique For Sparse Sets' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Efficient Compression Technique For Sparse Sets' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Pratap Rameshwar, Sohony Ishan, Kulkarni Raghav</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>8</td>
    <td><p>Recent technological advancements have led to the generation of huge amounts
of data over the web, such as text, image, audio and video. Most of this data
is high dimensional and sparse, for e.g., the bag-of-words representation used
for representing text. Often, an efficient search for similar data points needs
to be performed in many applications like clustering, nearest neighbour search,
ranking and indexing. Even though there have been significant increases in
computational power, a simple brute-force similarity-search on such datasets is
inefficient and at times impossible. Thus, it is desirable to get a compressed
representation which preserves the similarity between data points. In this
work, we consider the data points as sets and use Jaccard similarity as the
similarity measure. Compression techniques are generally evaluated on the
following parameters â€“1) Randomness required for compression, 2) Time required
for compression, 3) Dimension of the data after compression, and 4) Space
required to store the compressed data. Ideally, the compressed representation
of the data should be such, that the similarity between each pair of data
points is preserved, while keeping the time and the randomness required for
compression as low as possible.
  We show that the compression technique suggested by Pratap and Kulkarni also
works well for Jaccard similarity. We present a theoretical proof of the same
and complement it with rigorous experimentations on synthetic as well as
real-world datasets. We also compare our results with the state-of-the-art
â€œmin-wise independent permutationâ€, and show that our compression algorithm
achieves almost equal accuracy while significantly reducing the compression
time and the randomness.</p>
</td>
    <td>
      
        Compact Codes 
      
        DATASETS 
      
        Similarity Search 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/shrivastava2017optimal/">Optimal Densification For Fast And Accurate Minwise Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Optimal Densification For Fast And Accurate Minwise Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Optimal Densification For Fast And Accurate Minwise Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Shrivastava Anshumali</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>27</td>
    <td><p>Minwise hashing is a fundamental and one of the most successful hashing
algorithm in the literature. Recent advances based on the idea of
densification~\cite{Proc:OneHashLSH_ICML14,Proc:Shrivastava_UAI14} have shown
that it is possible to compute \(k\) minwise hashes, of a vector with \(d\)
nonzeros, in mere \((d + k)\) computations, a significant improvement over the
classical \(O(dk)\). These advances have led to an algorithmic improvement in the
query complexity of traditional indexing algorithms based on minwise hashing.
Unfortunately, the variance of the current densification techniques is
unnecessarily high, which leads to significantly poor accuracy compared to
vanilla minwise hashing, especially when the data is sparse. In this paper, we
provide a novel densification scheme which relies on carefully tailored
2-universal hashes. We show that the proposed scheme is variance-optimal, and
without losing the runtime efficiency, it is significantly more accurate than
existing densification techniques. As a result, we obtain a significantly
efficient hashing scheme which has the same variance and collision probability
as minwise hashing. Experimental evaluations on real sparse and
high-dimensional datasets validate our claims. We believe that given the
significant advantages, our method will replace minwise hashing implementations
in practice.</p>
</td>
    <td>
      
        ICML 
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        DATASETS 
      
        Efficiency And Optimization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/kumar2017neural/">Neural Signatures For Licence Plate Re-identification</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Neural Signatures For Licence Plate Re-identification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Neural Signatures For Licence Plate Re-identification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Kumar et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2020 International Conference for Emerging Technology (INCET)</td>
    <td>7</td>
    <td><p>The problem of vehicle licence plate re-identification is generally
considered as a one-shot image retrieval problem. The objective of this task is
to learn a feature representation (called a â€œsignatureâ€) for licence plates.
Incoming licence plate images are converted to signatures and matched to a
previously collected template database through a distance measure. Then, the
input image is recognized as the template whose signature is â€œnearestâ€ to the
input signature. The template database is restricted to contain only a single
signature per unique licence plate for our problem.
  We measure the performance of deep convolutional net-based features adapted
from face recognition on this task. In addition, we also test a hybrid approach
combining the Fisher vector with a neural network-based embedding called â€œf2nnâ€
trained with the Triplet loss function. We find that the hybrid approach
performs comparably while providing computational benefits. The signature
generated by the hybrid approach also shows higher generalizability to datasets
more dissimilar to the training corpus.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/liu2017deep/">Deep Hashing With Category Mask For Fast Video Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Hashing With Category Mask For Fast Video Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Hashing With Category Mask For Fast Video Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>10</td>
    <td><p>This paper proposes an end-to-end deep hashing framework with category mask
for fast video retrieval. We train our network in a supervised way by fully
exploiting inter-class diversity and intra-class identity. Classification loss
is optimized to maximize inter-class diversity, while intra-pair is introduced
to learn representative intra-class identity. We investigate the binary bits
distribution related to categories and find out that the effectiveness of
binary bits is highly correlated with data categories, and some bits may
degrade classification performance of some categories. We then design hash code
generation scheme with category mask to filter out bits with negative
contribution. Experimental results demonstrate the proposed method outperforms
several state-of-the-arts under various evaluation metrics on public datasets.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Neural Hashing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/li2017image/">Image Super-resolution Via Feature-augmented Random Forest</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Image Super-resolution Via Feature-augmented Random Forest' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Image Super-resolution Via Feature-augmented Random Forest' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li Hailiang, Lam Kin-man, Wang Miaohui</td> <!-- ðŸ”§ You were missing this -->
    <td>Signal Processing: Image Communication</td>
    <td>16</td>
    <td><p>Recent random-forest (RF)-based image super-resolution approaches inherit
some properties from dictionary-learning-based algorithms, but the
effectiveness of the properties in RF is overlooked in the literature. In this
paper, we present a novel feature-augmented random forest (FARF) for image
super-resolution, where the conventional gradient-based features are augmented
with gradient magnitudes and different feature recipes are formulated on
different stages in an RF. The advantages of our method are that, firstly, the
dictionary-learning-based features are enhanced by adding gradient magnitudes,
based on the observation that the non-linear gradient magnitude are with highly
discriminative property. Secondly, generalized locality-sensitive hashing (LSH)
is used to replace principal component analysis (PCA) for feature
dimensionality reduction and original high-dimensional features are employed,
instead of the compressed ones, for the leaf-nodesâ€™ regressors, since
regressors can benefit from higher dimensional features. This
original-compressed coupled feature sets scheme unifies the unsupervised LSH
evaluation on both image super-resolution and content-based image retrieval
(CBIR). Finally, we present a generalized weighted ridge regression (GWRR)
model for the leaf-nodesâ€™ regressors. Experiment results on several public
benchmark datasets show that our FARF method can achieve an average gain of
about 0.3 dB, compared to traditional RF-based methods. Furthermore, a
fine-tuned FARF model can compare to or (in many cases) outperform some recent
stateof-the-art deep-learning-based algorithms.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/zhu2017part/">Part-based Deep Hashing For Large-scale Person Re-identification</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Part-based Deep Hashing For Large-scale Person Re-identification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Part-based Deep Hashing For Large-scale Person Re-identification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Image Processing</td>
    <td>70</td>
    <td><p>Large-scale is a trend in person re-identification (re-id). It is important
that real-time search be performed in a large gallery. While previous methods
mostly focus on discriminative learning, this paper makes the attempt in
integrating deep learning and hashing into one framework to evaluate the
efficiency and accuracy for large-scale person re-id. We integrate spatial
information for discriminative visual representation by partitioning the
pedestrian image into horizontal parts. Specifically, Part-based Deep Hashing
(PDH) is proposed, in which batches of triplet samples are employed as the
input of the deep hashing architecture. Each triplet sample contains two
pedestrian images (or parts) with the same identity and one pedestrian image
(or part) of the different identity. A triplet loss function is employed with a
constraint that the Hamming distance of pedestrian images (or parts) with the
same identity is smaller than ones with the different identity. In the
experiment, we show that the proposed Part-based Deep Hashing method yields
very competitive re-id accuracy on the large-scale Market-1501 and
Market-1501+500K datasets.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        Efficiency And Optimization 
      
        Neural Hashing 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/srivastava20173d/">3D Binary Signatures</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=3D Binary Signatures' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=3D Binary Signatures' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Srivastava Siddharth, Lall Brejesh</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the Tenth Indian Conference on Computer Vision, Graphics and Image Processing</td>
    <td>8</td>
    <td><p>In this paper, we propose a novel binary descriptor for 3D point clouds. The
proposed descriptor termed as 3D Binary Signature (3DBS) is motivated from the
matching efficiency of the binary descriptors for 2D images. 3DBS describes
keypoints from point clouds with a binary vector resulting in extremely fast
matching. The method uses keypoints from standard keypoint detectors. The
descriptor is built by constructing a Local Reference Frame and aligning a
local surface patch accordingly. The local surface patch constitutes of
identifying nearest neighbours based upon an angular constraint among them. The
points are ordered with respect to the distance from the keypoints. The normals
of the ordered pairs of these keypoints are projected on the axes and the
relative magnitude is used to assign a binary digit. The vector thus
constituted is used as a signature for representing the keypoints. The matching
is done by using hamming distance. We show that 3DBS outperforms state of the
art descriptors on various evaluation metrics.</p>
</td>
    <td>
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/chen2017darkrank/">Darkrank: Accelerating Deep Metric Learning Via Cross Sample Similarities Transfer</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Darkrank: Accelerating Deep Metric Learning Via Cross Sample Similarities Transfer' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Darkrank: Accelerating Deep Metric Learning Via Cross Sample Similarities Transfer' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Chen Yuntao, Wang Naiyan, Zhang Zhaoxiang</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>218</td>
    <td><p>We have witnessed rapid evolution of deep neural network architecture design
in the past years. These latest progresses greatly facilitate the developments
in various areas such as computer vision and natural language processing.
However, along with the extraordinary performance, these state-of-the-art
models also bring in expensive computational cost. Directly deploying these
models into applications with real-time requirement is still infeasible.
Recently, Hinton etal. have shown that the dark knowledge within a powerful
teacher model can significantly help the training of a smaller and faster
student network. These knowledge are vastly beneficial to improve the
generalization ability of the student model. Inspired by their work, we
introduce a new type of knowledge â€“ cross sample similarities for model
compression and acceleration. This knowledge can be naturally derived from deep
metric learning model. To transfer them, we bring the â€œlearning to rankâ€
technique into deep metric learning formulation. We test our proposed DarkRank
method on various metric learning tasks including pedestrian re-identification,
image retrieval and image clustering. The results are quite encouraging. Our
method can improve over the baseline method by a large margin. Moreover, it is
fully compatible with other existing methods. When combined, the performance
can be further boosted.</p>
</td>
    <td>
      
        Image Retrieval 
      
        AAAI 
      
        Distance Metric Learning 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/linderman2017efficient/">Efficient Algorithms For T-distributed Stochastic Neighborhood Embedding</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Efficient Algorithms For T-distributed Stochastic Neighborhood Embedding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Efficient Algorithms For T-distributed Stochastic Neighborhood Embedding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Linderman et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>192</td>
    <td><p>t-distributed Stochastic Neighborhood Embedding (t-SNE) is a method for
dimensionality reduction and visualization that has become widely popular in
recent years. Efficient implementations of t-SNE are available, but they scale
poorly to datasets with hundreds of thousands to millions of high dimensional
data-points. We present Fast Fourier Transform-accelerated Interpolation-based
t-SNE (FIt-SNE), which dramatically accelerates the computation of t-SNE. The
most time-consuming step of t-SNE is a convolution that we accelerate by
interpolating onto an equispaced grid and subsequently using the fast Fourier
transform to perform the convolution. We also optimize the computation of input
similarities in high dimensions using multi-threaded approximate nearest
neighbors. We further present a modification to t-SNE called â€œlate
exaggeration,â€ which allows for easier identification of clusters in t-SNE
embeddings. Finally, for datasets that cannot be loaded into the memory, we
present out-of-core randomized principal component analysis (oocPCA), so that
the top principal components of a dataset can be computed without ever fully
loading the matrix, hence allowing for t-SNE of large datasets to be computed
on resource-limited machines.</p>
</td>
    <td>
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/li2017deep/">Deep Binary Reconstruction For Cross-modal Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Binary Reconstruction For Cross-modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Binary Reconstruction For Cross-modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li Xuelong, Hu di, Nie Feiping</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Multimedia</td>
    <td>126</td>
    <td><p>With the increasing demand of massive multimodal data storage and
organization, cross-modal retrieval based on hashing technique has drawn much
attention nowadays. It takes the binary codes of one modality as the query to
retrieve the relevant hashing codes of another modality. However, the existing
binary constraint makes it difficult to find the optimal cross-modal hashing
function. Most approaches choose to relax the constraint and perform
thresholding strategy on the real-value representation instead of directly
solving the original objective. In this paper, we first provide a concrete
analysis about the effectiveness of multimodal networks in preserving the
inter- and intra-modal consistency. Based on the analysis, we provide a
so-called Deep Binary Reconstruction (DBRC) network that can directly learn the
binary hashing codes in an unsupervised fashion. The superiority comes from a
proposed simple but efficient activation function, named as Adaptive Tanh
(ATanh). The ATanh function can adaptively learn the binary codes and be
trained via back-propagation. Extensive experiments on three benchmark datasets
demonstrate that DBRC outperforms several state-of-the-art methods in both
image2text and text2image retrieval task.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Multimodal Retrieval 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/haghiri2017comparison/">Comparison Based Nearest Neighbor Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Comparison Based Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Comparison Based Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Haghiri Siavash, Ghoshdastidar Debarghya, von Luxburg Ulrike</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>11</td>
    <td><p>We consider machine learning in a comparison-based setting where we are given
a set of points in a metric space, but we have no access to the actual
distances between the points. Instead, we can only ask an oracle whether the
distance between two points \(i\) and \(j\) is smaller than the distance between
the points \(i\) and \(k\). We are concerned with data structures and algorithms to
find nearest neighbors based on such comparisons. We focus on a simple yet
effective algorithm that recursively splits the space by first selecting two
random pivot points and then assigning all other points to the closer of the
two (comparison tree). We prove that if the metric space satisfies certain
expansion conditions, then with high probability the height of the comparison
tree is logarithmic in the number of points, leading to efficient search
performance. We also provide an upper bound for the failure probability to
return the true nearest neighbor. Experiments show that the comparison tree is
competitive with algorithms that have access to the actual distance values, and
needs less triplet comparisons than other competitors.</p>
</td>
    <td>
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/chaidaroon2017variational/">Variational Deep Semantic Hashing For Text Documents</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Variational Deep Semantic Hashing For Text Documents' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Variational Deep Semantic Hashing For Text Documents' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Chaidaroon Suthee, Fang Yi</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval</td>
    <td>71</td>
    <td><p>As the amount of textual data has been rapidly increasing over the past
decade, efficient similarity search methods have become a crucial component of
large-scale information retrieval systems. A popular strategy is to represent
original data samples by compact binary codes through hashing. A spectrum of
machine learning methods have been utilized, but they often lack expressiveness
and flexibility in modeling to learn effective representations. The recent
advances of deep learning in a wide range of applications has demonstrated its
capability to learn robust and powerful feature representations for complex
data. Especially, deep generative models naturally combine the expressiveness
of probabilistic generative models with the high capacity of deep neural
networks, which is very suitable for text modeling. However, little work has
leveraged the recent progress in deep learning for text hashing.
  In this paper, we propose a series of novel deep document generative models
for text hashing. The first proposed model is unsupervised while the second one
is supervised by utilizing document labels/tags for hashing. The third model
further considers document-specific factors that affect the generation of
words. The probabilistic generative formulation of the proposed models provides
a principled framework for model extension, uncertainty estimation, simulation,
and interpretability. Based on variational inference and reparameterization,
the proposed models can be interpreted as encoder-decoder deep neural networks
and thus they are capable of learning complex nonlinear distributed
representations of the original documents. We conduct a comprehensive set of
experiments on four public testbeds. The experimental results have demonstrated
the effectiveness of the proposed supervised learning models for text hashing.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Text Retrieval 
      
        SIGIR 
      
        Similarity Search 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/wieschollek2017efficient/">Efficient Large-scale Approximate Nearest Neighbor Search On The GPU</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Efficient Large-scale Approximate Nearest Neighbor Search On The GPU' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Efficient Large-scale Approximate Nearest Neighbor Search On The GPU' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wieschollek et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>54</td>
    <td><p>We present a new approach for efficient approximate nearest neighbor (ANN)
search in high dimensional spaces, extending the idea of Product Quantization.
We propose a two-level product and vector quantization tree that reduces the
number of vector comparisons required during tree traversal. Our approach also
includes a novel highly parallelizable re-ranking method for candidate vectors
by efficiently reusing already computed intermediate values. Due to its small
memory footprint during traversal, the method lends itself to an efficient,
parallel GPU implementation. This Product Quantization Tree (PQT) approach
significantly outperforms recent state of the art methods for high dimensional
nearest neighbor queries on standard reference datasets. Ours is the first work
that demonstrates GPU performance superior to CPU performance on high
dimensional, large scale ANN problems in time-critical real-world applications,
like loop-closing in videos.</p>
</td>
    <td>
      
        DATASETS 
      
        Efficiency And Optimization 
      
        CVPR 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/manocha2017content/">Content-based Representations Of Audio Using Siamese Neural Networks</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Content-based Representations Of Audio Using Siamese Neural Networks' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Content-based Representations Of Audio Using Siamese Neural Networks' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Manocha et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</td>
    <td>38</td>
    <td><p>In this paper, we focus on the problem of content-based retrieval for audio,
which aims to retrieve all semantically similar audio recordings for a given
audio clip query. This problem is similar to the problem of query by example of
audio, which aims to retrieve media samples from a database, which are similar
to the user-provided example. We propose a novel approach which encodes the
audio into a vector representation using Siamese Neural Networks. The goal is
to obtain an encoding similar for files belonging to the same audio class, thus
allowing retrieval of semantically similar audio. Using simple similarity
measures such as those based on simple euclidean distance and cosine similarity
we show that these representations can be very effectively used for retrieving
recordings similar in audio content.</p>
</td>
    <td>
      
        ICASSP 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/qi2017efficient/">An Efficient Deep Learning Hashing Neural Network For Mobile Visual Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=An Efficient Deep Learning Hashing Neural Network For Mobile Visual Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=An Efficient Deep Learning Hashing Neural Network For Mobile Visual Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Qi Heng, Liu Wu, Liu Liang</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 IEEE Global Conference on Signal and Information Processing (GlobalSIP)</td>
    <td>8</td>
    <td><p>Mobile visual search applications are emerging that enable users to sense
their surroundings with smart phones. However, because of the particular
challenges of mobile visual search, achieving a high recognition bitrate has
becomes a consistent target of previous related works. In this paper, we
propose a few-parameter, low-latency, and high-accuracy deep hashing approach
for constructing binary hash codes for mobile visual search. First, we exploit
the architecture of the MobileNet model, which significantly decreases the
latency of deep feature extraction by reducing the number of model parameters
while maintaining accuracy. Second, we add a hash-like layer into MobileNet to
train the model on labeled mobile visual data. Evaluations show that the
proposed system can exceed state-of-the-art accuracy performance in terms of
the MAP. More importantly, the memory consumption is much less than that of
other deep learning models. The proposed method requires only \(13\) MB of memory
for the neural network and achieves a MAP of \(97.80%\) on the mobile location
recognition dataset used for testing.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Neural Hashing 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/zhu2017discrete/">Discrete Multi-modal Hashing With Canonical Views For Robust Mobile Landmark Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Discrete Multi-modal Hashing With Canonical Views For Robust Mobile Landmark Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Discrete Multi-modal Hashing With Canonical Views For Robust Mobile Landmark Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>9</td>
    <td><p>Mobile landmark search (MLS) recently receives increasing attention for its
great practical values. However, it still remains unsolved due to two important
challenges. One is high bandwidth consumption of query transmission, and the
other is the huge visual variations of query images sent from mobile devices.
In this paper, we propose a novel hashing scheme, named as canonical view based
discrete multi-modal hashing (CV-DMH), to handle these problems via a novel
three-stage learning procedure. First, a submodular function is designed to
measure visual representativeness and redundancy of a view set. With it,
canonical views, which capture key visual appearances of landmark with limited
redundancy, are efficiently discovered with an iterative mining strategy.
Second, multi-modal sparse coding is applied to transform visual features from
multiple modalities into an intermediate representation. It can robustly and
adaptively characterize visual contents of varied landmark images with certain
canonical views. Finally, compact binary codes are learned on intermediate
representation within a tailored discrete binary embedding model which
preserves visual relations of images measured with canonical views and removes
the involved noises. In this part, we develop a new augmented Lagrangian
multiplier (ALM) based optimization method to directly solve the discrete
binary codes. We can not only explicitly deal with the discrete constraint, but
also consider the bit-uncorrelated constraint and balance constraint together.
Experiments on real world landmark datasets demonstrate the superior
performance of CV-DMH over several state-of-the-art methods.</p>
</td>
    <td>
      
        Compact Codes 
      
        DATASETS 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/matsui2017pqtable/">Pqtable: Non-exhaustive Fast Search For Product-quantized Codes Using Hash Tables</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Pqtable: Non-exhaustive Fast Search For Product-quantized Codes Using Hash Tables' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Pqtable: Non-exhaustive Fast Search For Product-quantized Codes Using Hash Tables' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Matsui Yusuke, Yamasaki Toshihiko, Aizawa Kiyoharu</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Multimedia</td>
    <td>8</td>
    <td><p>In this paper, we propose a product quantization table (PQTable); a fast
search method for product-quantized codes via hash-tables. An identifier of
each database vector is associated with the slot of a hash table by using its
PQ-code as a key. For querying, an input vector is PQ-encoded and hashed, and
the items associated with that code are then retrieved. The proposed PQTable
produces the same results as a linear PQ scan, and is 10^2 to 10^5 times
faster. Although state-of-the-art performance can be achieved by previous
inverted-indexing-based approaches, such methods require manually-designed
parameter setting and significant training; our PQTable is free of these
limitations, and therefore offers a practical and effective solution for
real-world problems. Specifically, when the vectors are highly compressed, our
PQTable achieves one of the fastest search performances on a single CPU to date
with significantly efficient memory usage (0.059 ms per query over 10^9 data
points with just 5.5 GB memory consumption). Finally, we show that our proposed
PQTable can naturally handle the codes of an optimized product quantization
(OPQTable).</p>
</td>
    <td>
      
        Alt 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/tian2017semi/">Semi-supervised Multimodal Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Semi-supervised Multimodal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Semi-supervised Multimodal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Tian et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Image Processing</td>
    <td>8</td>
    <td><p>Retrieving nearest neighbors across correlated data in multiple modalities,
such as image-text pairs on Facebook and video-tag pairs on YouTube, has become
a challenging task due to the huge amount of data. Multimodal hashing methods
that embed data into binary codes can boost the retrieving speed and reduce
storage requirement. As unsupervised multimodal hashing methods are usually
inferior to supervised ones, while the supervised ones requires too much
manually labeled data, the proposed method in this paper utilizes a part of
labels to design a semi-supervised multimodal hashing method. It first computes
the transformation matrices for data matrices and label matrix. Then, with
these transformation matrices, fuzzy logic is introduced to estimate a label
matrix for unlabeled data. Finally, it uses the estimated label matrix to learn
hashing functions for data in each modality to generate a unified binary code
matrix. Experiments show that the proposed semi-supervised method with 50%
labels can get a medium performance among the compared supervised ones and
achieve an approximate performance to the best supervised method with 90%
labels. With only 10% labels, the proposed method can still compete with the
worst compared supervised one.</p>
</td>
    <td>
      
        Compact Codes 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/cao2017transfer/">Transfer Adversarial Hashing For Hamming Space Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Transfer Adversarial Hashing For Hamming Space Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Transfer Adversarial Hashing For Hamming Space Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Cao et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>15</td>
    <td><p>Hashing is widely applied to large-scale image retrieval due to the storage
and retrieval efficiency. Existing work on deep hashing assumes that the
database in the target domain is identically distributed with the training set
in the source domain. This paper relaxes this assumption to a transfer
retrieval setting, which allows the database and the training set to come from
different but relevant domains. However, the transfer retrieval setting will
introduce two technical difficulties: first, the hash model trained on the
source domain cannot work well on the target domain due to the large
distribution gap; second, the domain gap makes it difficult to concentrate the
database points to be within a small Hamming ball. As a consequence, transfer
retrieval performance within Hamming Radius 2 degrades significantly in
existing hashing methods. This paper presents Transfer Adversarial Hashing
(TAH), a new hybrid deep architecture that incorporates a pairwise
\(t\)-distribution cross-entropy loss to learn concentrated hash codes and an
adversarial network to align the data distributions between the source and
target domains. TAH can generate compact transfer hash codes for efficient
image retrieval on both source and target domains. Comprehensive experiments
validate that TAH yields state of the art Hamming space retrieval performance
on standard datasets.</p>
</td>
    <td>
      
        Image Retrieval 
      
        AAAI 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Neural Hashing 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/cao2017hashnet/">Hashnet: Deep Learning To Hash By Continuation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hashnet: Deep Learning To Hash By Continuation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hashnet: Deep Learning To Hash By Continuation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Cao et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 IEEE International Conference on Computer Vision (ICCV)</td>
    <td>632</td>
    <td><p>Learning to hash has been widely applied to approximate nearest neighbor
search for large-scale multimedia retrieval, due to its computation efficiency
and retrieval quality. Deep learning to hash, which improves retrieval quality
by end-to-end representation learning and hash encoding, has received
increasing attention recently. Subject to the ill-posed gradient difficulty in
the optimization with sign activations, existing deep learning to hash methods
need to first learn continuous representations and then generate binary hash
codes in a separated binarization step, which suffer from substantial loss of
retrieval quality. This work presents HashNet, a novel deep architecture for
deep learning to hash by continuation method with convergence guarantees, which
learns exactly binary hash codes from imbalanced similarity data. The key idea
is to attack the ill-posed gradient problem in optimizing deep networks with
non-smooth binary activations by continuation method, in which we begin from
learning an easier network with smoothed activation function and let it evolve
during the training, until it eventually goes back to being the original,
difficult to optimize, deep network with the sign activation function.
Comprehensive empirical evidence shows that HashNet can generate exactly binary
hash codes and yield state-of-the-art multimedia retrieval performance on
standard benchmarks.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Neural Hashing 
      
        ICCV 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/cakir2017mihash/">Mihash: Online Hashing With Mutual Information</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Mihash: Online Hashing With Mutual Information' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Mihash: Online Hashing With Mutual Information' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Cakir et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 IEEE International Conference on Computer Vision (ICCV)</td>
    <td>99</td>
    <td><p>Learning-based hashing methods are widely used for nearest neighbor
retrieval, and recently, online hashing methods have demonstrated good
performance-complexity trade-offs by learning hash functions from streaming
data. In this paper, we first address a key challenge for online hashing: the
binary codes for indexed data must be recomputed to keep pace with updates to
the hash functions. We propose an efficient quality measure for hash functions,
based on an information-theoretic quantity, mutual information, and use it
successfully as a criterion to eliminate unnecessary hash table updates. Next,
we also show how to optimize the mutual information objective using stochastic
gradient descent. We thus develop a novel hashing method, MIHash, that can be
used in both online and batch settings. Experiments on image retrieval
benchmarks (including a 2.5M image dataset) confirm the effectiveness of our
formulation, both in reducing hash table recomputations and in learning
high-quality hash functions.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        ICCV 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/jain2017compact/">Compact Environment-invariant Codes For Robust Visual Place Recognition</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Compact Environment-invariant Codes For Robust Visual Place Recognition' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Compact Environment-invariant Codes For Robust Visual Place Recognition' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jain Unnat, Namboodiri Vinay P., Pandey Gaurav</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 14th Conference on Computer and Robot Vision (CRV)</td>
    <td>6</td>
    <td><p>Robust visual place recognition (VPR) requires scene representations that are
invariant to various environmental challenges such as seasonal changes and
variations due to ambient lighting conditions during day and night. Moreover, a
practical VPR system necessitates compact representations of environmental
features. To satisfy these requirements, in this paper we suggest a
modification to the existing pipeline of VPR systems to incorporate supervised
hashing. The modified system learns (in a supervised setting) compact binary
codes from image feature descriptors. These binary codes imbibe robustness to
the visual variations exposed to it during the training phase, thereby, making
the system adaptive to severe environmental changes. Also, incorporating
supervised hashing makes VPR computationally more efficient and easy to
implement on simple hardware. This is because binary embeddings can be learned
over simple-to-compute features and the distance computation is also in the
low-dimensional hamming space of binary codes. We have performed experiments on
several challenging data sets covering seasonal, illumination and viewpoint
variations. We also compare two widely used supervised hashing methods of
CCAITQ and MLH and show that this new pipeline out-performs or closely matches
the state-of-the-art deep learning VPR methods that are based on
high-dimensional features extracted from pre-trained deep convolutional neural
networks.</p>
</td>
    <td>
      
        Compact Codes 
      
        Hashing Methods 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/komorowski2017random/">Random Binary Trees For Approximate Nearest Neighbour Search In Binary Space</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Random Binary Trees For Approximate Nearest Neighbour Search In Binary Space' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Random Binary Trees For Approximate Nearest Neighbour Search In Binary Space' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Komorowski Michal, Trzcinski Tomasz</td> <!-- ðŸ”§ You were missing this -->
    <td>Applied Soft Computing</td>
    <td>9</td>
    <td><p>Approximate nearest neighbour (ANN) search is one of the most important
problems in computer science fields such as data mining or computer vision. In
this paper, we focus on ANN for high-dimensional binary vectors and we propose
a simple yet powerful search method that uses Random Binary Search Trees
(RBST). We apply our method to a dataset of 1.25M binary local feature
descriptors obtained from a real-life image-based localisation system provided
by Google as a part of Project Tango. An extensive evaluation of our method
against the state-of-the-art variations of Locality Sensitive Hashing (LSH),
namely Uniform LSH and Multi-probe LSH, shows the superiority of our method in
terms of retrieval precision with performance boost of over 20%</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/razeghi2017privacy/">Privacy Preserving Identification Using Sparse Approximation With Ambiguization</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Privacy Preserving Identification Using Sparse Approximation With Ambiguization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Privacy Preserving Identification Using Sparse Approximation With Ambiguization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Razeghi et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 IEEE Workshop on Information Forensics and Security (WIFS)</td>
    <td>25</td>
    <td><p>In this paper, we consider a privacy preserving encoding framework for
identification applications covering biometrics, physical object security and
the Internet of Things (IoT). The proposed framework is based on a sparsifying
transform, which consists of a trained linear map, an element-wise
nonlinearity, and privacy amplification. The sparsifying transform and privacy
amplification are not symmetric for the data owner and data user. We
demonstrate that the proposed approach is closely related to sparse ternary
codes (STC), a recent information-theoretic concept proposed for fast
approximate nearest neighbor (ANN) search in high dimensional feature spaces
that being machine learning in nature also offers significant benefits in
comparison to sparse approximation and binary embedding approaches. We
demonstrate that the privacy of the database outsourced to a server as well as
the privacy of the data user are preserved at a low computational cost, storage
and communication burdens.</p>
</td>
    <td>
      
        Tools & Libraries 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/cai2017revisit/">A Revisit On Deep Hashings For Large-scale Content Based Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Revisit On Deep Hashings For Large-scale Content Based Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Revisit On Deep Hashings For Large-scale Content Based Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Cai Deng, Gu Xiuye, Wang Chaoqi</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>13</td>
    <td><p>There is a growing trend in studying deep hashing methods for content-based
image retrieval (CBIR), where hash functions and binary codes are learnt using
deep convolutional neural networks and then the binary codes can be used to do
approximate nearest neighbor (ANN) search. All the existing deep hashing papers
report their methodsâ€™ superior performance over the traditional hashing methods
according to their experimental results. However, there are serious flaws in
the evaluations of existing deep hashing papers: (1) The datasets they used are
too small and simple to simulate the real CBIR situation. (2) They did not
correctly include the search time in their evaluation criteria, while the
search time is crucial in real CBIR systems. (3) The performance of some
unsupervised hashing algorithms (e.g., LSH) can easily be boosted if one uses
multiple hash tables, which is an important factor should be considered in the
evaluation while most of the deep hashing papers failed to do so.
  We re-evaluate several state-of-the-art deep hashing methods with a carefully
designed experimental setting. Empirical results reveal that the performance of
these deep hashing methods are inferior to multi-table IsoH, a very simple
unsupervised hashing method. Thus, the conclusions in all the deep hashing
papers should be carefully re-examined.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Neural Hashing 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/chandrasekaran2017lattice/">Lattice-based Locality Sensitive Hashing Is Optimal</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Lattice-based Locality Sensitive Hashing Is Optimal' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Lattice-based Locality Sensitive Hashing Is Optimal' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Chandrasekaran et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the IEEE</td>
    <td>40</td>
    <td><p>Locality sensitive hashing (LSH) was introduced by Indyk and Motwani (STOC
<code class="language-plaintext highlighter-rouge">98) to give the first sublinear time algorithm for the c-approximate nearest
neighbor (ANN) problem using only polynomial space. At a high level, an LSH
family hashes "nearby" points to the same bucket and "far away" points to
different buckets. The quality of measure of an LSH family is its LSH exponent,
which helps determine both query time and space usage.
  In a seminal work, Andoni and Indyk (FOCS </code>06) constructed an LSH family
based on random ball partitioning of space that achieves an LSH exponent of
1/c^2 for the l_2 norm, which was later shown to be optimal by Motwani, Naor
and Panigrahy (SIDMA <code class="language-plaintext highlighter-rouge">07) and O'Donnell, Wu and Zhou (TOCT </code>14). Although
optimal in the LSH exponent, the ball partitioning approach is computationally
expensive. So, in the same work, Andoni and Indyk proposed a simpler and more
practical hashing scheme based on Euclidean lattices and provided computational
results using the 24-dimensional Leech lattice. However, no theoretical
analysis of the scheme was given, thus leaving open the question of finding the
exponent of lattice based LSH.
  In this work, we resolve this question by showing the existence of lattices
achieving the optimal LSH exponent of 1/c^2 using techniques from the geometry
of numbers. At a more conceptual level, our results show that optimal LSH space
partitions can have periodic structure. Understanding the extent to which
additional structure can be imposed on these partitions, e.g. to yield low
space and query complexity, remains an important open problem.</p>
</td>
    <td>
      
        Alt 
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/brooks2017multi/">Multi-level Spherical Locality Sensitive Hashing For Approximate Near Neighbors</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Multi-level Spherical Locality Sensitive Hashing For Approximate Near Neighbors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Multi-level Spherical Locality Sensitive Hashing For Approximate Near Neighbors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Brooks Teresa Nicole, Almajalid Rania</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>10</td>
    <td><p>This paper introduces â€œMulti-Level Spherical LSHâ€: parameter-free, a
multi-level, data-dependant Locality Sensitive Hashing data structure for
solving the Approximate Near Neighbors Problem (ANN). This data structure uses
a modified version of a multi-probe adaptive querying algorithm, with the
potential of achieving a \(O(n^p + t)\) query run time, for all inputs n where \(t
&lt;= n\).</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/qu2017joint/">Joint Hierarchical Category Structure Learning And Large-scale Image Classification</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Joint Hierarchical Category Structure Learning And Large-scale Image Classification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Joint Hierarchical Category Structure Learning And Large-scale Image Classification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Qu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Image Processing</td>
    <td>40</td>
    <td><p>We investigate the scalable image classification problem with a large number
of categories. Hierarchical visual data structures are helpful for improving
the efficiency and performance of large-scale multi-class classification. We
propose a novel image classification method based on learning hierarchical
inter-class structures. Specifically, we first design a fast algorithm to
compute the similarity metric between categories, based on which a visual tree
is constructed by hierarchical spectral clustering. Using the learned visual
tree, a test sample label is efficiently predicted by searching for the best
path over the entire tree. The proposed method is extensively evaluated on the
ILSVRC2010 and Caltech 256 benchmark datasets. Experimental results show that
our method obtains significantly better category hierarchies than other
state-of-the-art visual tree-based methods and, therefore, much more accurate
classification.</p>
</td>
    <td>
      
        DATASETS 
      
        Distance Metric Learning 
      
        Efficiency And Optimization 
      
        Alt 
      
        Tree Based ANN 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/sicre2017unsupervised/">Unsupervised Part Learning For Visual Recognition</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Unsupervised Part Learning For Visual Recognition' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Unsupervised Part Learning For Visual Recognition' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Sicre et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>16</td>
    <td><p>Part-based image classification aims at representing categories by small sets
of learned discriminative parts, upon which an image representation is built.
Considered as a promising avenue a decade ago, this direction has been
neglected since the advent of deep neural networks. In this context, this paper
brings two contributions: first, it shows that despite the recent success of
end-to-end holistic models, explicit part learning can boosts classification
performance. Second, this work proceeds one step further than recent part-based
models (PBM), focusing on how to learn parts without using any labeled data.
Instead of learning a set of parts per class, as generally done in the PBM
literature, the proposed approach both constructs a partition of a given set of
images into visually similar groups, and subsequently learn a set of
discriminative parts per group in a fully unsupervised fashion. This strategy
opens the door to the use of PBM in new applications for which the notion of
image categories is irrelevant, such as instance-based image retrieval, for
example. We experimentally show that our learned parts can help building
efficient image representations, for classification as well as for indexing
tasks, resulting in performance superior to holistic state-of-the art Deep
Convolutional Neural Networks (DCNN) encoding.</p>
</td>
    <td>
      
        CVPR 
      
        Image Retrieval 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/venkateswara2017deep/">Deep Hashing Network For Unsupervised Domain Adaptation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Hashing Network For Unsupervised Domain Adaptation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Hashing Network For Unsupervised Domain Adaptation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Venkateswara et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>1690</td>
    <td><p>In recent years, deep neural networks have emerged as a dominant machine
learning tool for a wide variety of application domains. However, training a
deep neural network requires a large amount of labeled data, which is an
expensive process in terms of time, labor and human expertise. Domain
adaptation or transfer learning algorithms address this challenge by leveraging
labeled data in a different, but related source domain, to develop a model for
the target domain. Further, the explosive growth of digital data has posed a
fundamental challenge concerning its storage and retrieval. Due to its storage
and retrieval efficiency, recent years have witnessed a wide application of
hashing in a variety of computer vision applications. In this paper, we first
introduce a new dataset, Office-Home, to evaluate domain adaptation algorithms.
The dataset contains images of a variety of everyday objects from multiple
domains. We then propose a novel deep learning framework that can exploit
labeled source data and unlabeled target data to learn informative hash codes,
to accurately classify unseen target data. To the best of our knowledge, this
is the first research effort to exploit the feature learning capabilities of
deep neural networks to learn representative hash codes to address the domain
adaptation problem. Our extensive empirical studies on multiple transfer tasks
corroborate the usefulness of the framework in learning efficient hash codes
which outperform existing competitive baselines for unsupervised domain
adaptation.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        CVPR 
      
        Neural Hashing 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/maier2017dynamic/">Dynamic Space Efficient Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Dynamic Space Efficient Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Dynamic Space Efficient Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Maier Tobias, Sanders Peter</td> <!-- ðŸ”§ You were missing this -->
    <td>Algorithmica</td>
    <td>9</td>
    <td><p>We consider space efficient hash tables that can grow and shrink dynamically
and are always highly space efficient, i.e., their space consumption is always
close to the lower bound even while growing and when taking into account
storage that is only needed temporarily. None of the traditionally used hash
tables have this property. We show how known approaches like linear probing and
bucket cuckoo hashing can be adapted to this scenario by subdividing them into
many subtables or using virtual memory overcommitting. However, these rather
straightforward solutions suffer from slow amortized insertion times due to
frequent reallocation in small increments.
  Our main result is DySECT ({\bf Dy}namic {\bf S}pace {\bf E}fficient {\bf
C}uckoo {\bf T}able) which avoids these problems. DySECT consists of many
subtables which grow by doubling their size. The resulting inhomogeneity in
subtable sizes is equalized by the flexibility available in bucket cuckoo
hashing where each element can go to several buckets each of which containing
several cells. Experiments indicate that DySECT works well with load factors up
to 98%. With up to 2.7 times better performance than the next best solution.</p>
</td>
    <td>
      
        Evaluation 
      
        Hashing Methods 
      
        ALT 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/zemene2017large/">Large-scale Image Geo-localization Using Dominant Sets</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Large-scale Image Geo-localization Using Dominant Sets' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Large-scale Image Geo-localization Using Dominant Sets' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zemene et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Pattern Analysis and Machine Intelligence</td>
    <td>38</td>
    <td><p>This paper presents a new approach for the challenging problem of
geo-locating an image using image matching in a structured database of
city-wide reference images with known GPS coordinates. We cast the
geo-localization as a clustering problem on local image features. Akin to
existing approaches on the problem, our framework builds on low-level features
which allow partial matching between images. For each local feature in the
query image, we find its approximate nearest neighbors in the reference set.
Next, we cluster the features from reference images using Dominant Set
clustering, which affords several advantages over existing approaches. First,
it permits variable number of nodes in the cluster which we use to dynamically
select the number of nearest neighbors (typically coming from multiple
reference images) for each query feature based on its discrimination value.
Second, as we also quantify in our experiments, this approach is several orders
of magnitude faster than existing approaches. Thus, we obtain multiple clusters
(different local maximizers) and obtain a robust final solution to the problem
using multiple weak solutions through constrained Dominant Set clustering on
global image features, where we enforce the constraint that the query image
must be included in the cluster. This second level of clustering also bypasses
heuristic approaches to voting and selecting the reference image that matches
to the query. We evaluated the proposed framework on an existing dataset of
102k street view images as well as a new dataset of 300k images, and show that
it outperforms the state-of-the-art by 20% and 7%, respectively, on the two
datasets.</p>
</td>
    <td>
      
        DATASETS 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/hu2017learning/">Learning Discrete Representations Via Information Maximizing Self-augmented Training</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning Discrete Representations Via Information Maximizing Self-augmented Training' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning Discrete Representations Via Information Maximizing Self-augmented Training' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Hu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>206</td>
    <td><p>Learning discrete representations of data is a central machine learning task
because of the compactness of the representations and ease of interpretation.
The task includes clustering and hash learning as special cases. Deep neural
networks are promising to be used because they can model the non-linearity of
data and scale to large datasets. However, their model complexity is huge, and
therefore, we need to carefully regularize the networks in order to learn
useful representations that exhibit intended invariance for applications of
interest. To this end, we propose a method called Information Maximizing
Self-Augmented Training (IMSAT). In IMSAT, we use data augmentation to impose
the invariance on discrete representations. More specifically, we encourage the
predicted representations of augmented data points to be close to those of the
original data points in an end-to-end fashion. At the same time, we maximize
the information-theoretic dependency between data and their predicted discrete
representations. Extensive experiments on benchmark datasets show that IMSAT
produces state-of-the-art results for both clustering and unsupervised hash
learning.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/huang2017unsupervised/">Unsupervised Triplet Hashing For Fast Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Unsupervised Triplet Hashing For Fast Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Unsupervised Triplet Hashing For Fast Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Huang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the on Thematic Workshops of ACM Multimedia 2017</td>
    <td>54</td>
    <td><p>Hashing has played a pivotal role in large-scale image retrieval. With the
development of Convolutional Neural Network (CNN), hashing learning has shown
great promise. But existing methods are mostly tuned for classification, which
are not optimized for retrieval tasks, especially for instance-level retrieval.
In this study, we propose a novel hashing method for large-scale image
retrieval. Considering the difficulty in obtaining labeled datasets for image
retrieval task in large scale, we propose a novel CNN-based unsupervised
hashing method, namely Unsupervised Triplet Hashing (UTH). The unsupervised
hashing network is designed under the following three principles: 1) more
discriminative representations for image retrieval; 2) minimum quantization
loss between the original real-valued feature descriptors and the learned hash
codes; 3) maximum information entropy for the learned hash codes. Extensive
experiments on CIFAR-10, MNIST and In-shop datasets have shown that UTH
outperforms several state-of-the-art unsupervised hashing methods in terms of
retrieval accuracy.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Quantization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/jain2017learning/">Learning A Complete Image Indexing Pipeline</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning A Complete Image Indexing Pipeline' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning A Complete Image Indexing Pipeline' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jain et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</td>
    <td>14</td>
    <td><p>To work at scale, a complete image indexing system comprises two components:
An inverted file index to restrict the actual search to only a subset that
should contain most of the items relevant to the query; An approximate distance
computation mechanism to rapidly scan these lists. While supervised deep
learning has recently enabled improvements to the latter, the former continues
to be based on unsupervised clustering in the literature. In this work, we
propose a first system that learns both components within a unifying neural
framework of structured binary encoding.</p>
</td>
    <td>
      
        CVPR 
      
        Vector Indexing 
      
        Tools & Libraries 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/marshall2017exact/">Exact Clustering In Linear Time</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Exact Clustering In Linear Time' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Exact Clustering In Linear Time' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Marshall Jonathan A., Rafsky Lawrence C.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>25</td>
    <td><p>The time complexity of data clustering has been viewed as fundamentally
quadratic, slowing with the number of data items, as each item is compared for
similarity to preceding items. Clustering of large data sets has been
infeasible without resorting to probabilistic methods or to capping the number
of clusters. Here we introduce MIMOSA, a novel class of algorithms which
achieve linear time computational complexity on clustering tasks. MIMOSA
algorithms mark and match partial-signature keys in a hash table to obtain
exact, error-free cluster retrieval. Benchmark measurements, on clustering a
data set of 10,000,000 news articles by news topic, found that a MIMOSA
implementation finished more than four orders of magnitude faster than a
standard centroid implementation.</p>
</td>
    <td>
      
        AAAI 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/lai2017improved/">Improved Search In Hamming Space Using Deep Multi-index Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Improved Search In Hamming Space Using Deep Multi-index Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Improved Search In Hamming Space Using Deep Multi-index Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lai Hanjiang, Pan Yan</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Circuits and Systems for Video Technology</td>
    <td>12</td>
    <td><p>Similarity-preserving hashing is a widely-used method for nearest neighbour
search in large-scale image retrieval tasks. There has been considerable
research on generating efficient image representation via the
deep-network-based hashing methods. However, the issue of efficient searching
in the deep representation space remains largely unsolved. To this end, we
propose a simple yet efficient deep-network-based multi-index hashing method
for simultaneously learning the powerful image representation and the efficient
searching. To achieve these two goals, we introduce the multi-index hashing
(MIH) mechanism into the proposed deep architecture, which divides the binary
codes into multiple substrings. Due to the non-uniformly distributed codes will
result in inefficiency searching, we add the two balanced constraints at
feature-level and instance-level, respectively. Extensive evaluations on
several benchmark image retrieval datasets show that the learned balanced
binary codes bring dramatic speedups and achieve comparable performance over
the existing baselines.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Vector Indexing 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/xu2017neural/">Neural Network-based Graph Embedding For Cross-platform Binary Code Similarity Detection</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Neural Network-based Graph Embedding For Cross-platform Binary Code Similarity Detection' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Neural Network-based Graph Embedding For Cross-platform Binary Code Similarity Detection' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Xu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security</td>
    <td>545</td>
    <td><p>The problem of cross-platform binary code similarity detection aims at
detecting whether two binary functions coming from different platforms are
similar or not. It has many security applications, including plagiarism
detection, malware detection, vulnerability search, etc. Existing approaches
rely on approximate graph matching algorithms, which are inevitably slow and
sometimes inaccurate, and hard to adapt to a new task. To address these issues,
in this work, we propose a novel neural network-based approach to compute the
embedding, i.e., a numeric vector, based on the control flow graph of each
binary function, then the similarity detection can be done efficiently by
measuring the distance between the embeddings for two functions. We implement a
prototype called Gemini. Our extensive evaluation shows that Gemini outperforms
the state-of-the-art approaches by large margins with respect to similarity
detection accuracy. Further, Gemini can speed up prior artâ€™s embedding
generation time by 3 to 4 orders of magnitude and reduce the required training
time from more than 1 week down to 30 minutes to 10 hours. Our real world case
studies demonstrate that Gemini can identify significantly more vulnerable
firmware images than the state-of-the-art, i.e., Genius. Our research showcases
a successful application of deep learning on computer security problems.</p>
</td>
    <td>
      
        Compact Codes 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/jain2017asymmetric/">Asymmetric Learning Vector Quantization For Efficient Nearest Neighbor Classification In Dynamic Time Warping Spaces</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Asymmetric Learning Vector Quantization For Efficient Nearest Neighbor Classification In Dynamic Time Warping Spaces' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Asymmetric Learning Vector Quantization For Efficient Nearest Neighbor Classification In Dynamic Time Warping Spaces' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jain Brijnesh, Schultz David</td> <!-- ðŸ”§ You were missing this -->
    <td>Pattern Recognition</td>
    <td>20</td>
    <td><p>The nearest neighbor method together with the dynamic time warping (DTW)
distance is one of the most popular approaches in time series classification.
This method suffers from high storage and computation requirements for large
training sets. As a solution to both drawbacks, this article extends learning
vector quantization (LVQ) from Euclidean spaces to DTW spaces. The proposed LVQ
scheme uses asymmetric weighted averaging as update rule. Empirical results
exhibited superior performance of asymmetric generalized LVQ (GLVQ) over other
state-of-the-art prototype generation methods for nearest neighbor
classification.</p>
</td>
    <td>
      
        CVPR 
      
        Quantization 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/huang2017online/">Online Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Online Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Online Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Huang Long-kai, Yang Qiang, Zheng Wei-shi</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 IEEE International Conference on Computer Vision (ICCV)</td>
    <td>99</td>
    <td><p>Although hash function learning algorithms have achieved great success in
recent years, most existing hash models are off-line, which are not suitable
for processing sequential or online data. To address this problem, this work
proposes an online hash model to accommodate data coming in stream for online
learning. Specifically, a new loss function is proposed to measure the
similarity loss between a pair of data samples in hamming space. Then, a
structured hash model is derived and optimized in a passive-aggressive way.
Theoretical analysis on the upper bound of the cumulative loss for the proposed
online hash model is provided. Furthermore, we extend our online hashing from a
single-model to a multi-model online hashing that trains multiple models so as
to retain diverse online hashing models in order to avoid biased update. The
competitive efficiency and effectiveness of the proposed online hash models are
verified through extensive experiments on several large-scale datasets as
compared to related hashing methods.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Alt 
      
        ICCV 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/meel2017hashing/">On Hashing-based Approaches To Approximate Dnf-counting</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=On Hashing-based Approaches To Approximate Dnf-counting' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=On Hashing-based Approaches To Approximate Dnf-counting' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Meel Kuldeep S., Shrotri Aditya A., Vardi Moshe Y.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>8</td>
    <td><p>Propositional model counting is a fundamental problem in artificial
intelligence with a wide variety of applications, such as probabilistic
inference, decision making under uncertainty, and probabilistic databases.
Consequently, the problem is of theoretical as well as practical interest. When
the constraints are expressed as DNF formulas, Monte Carlo-based techniques
have been shown to provide a fully polynomial randomized approximation scheme
(FPRAS). For CNF constraints, hashing-based approximation techniques have been
demonstrated to be highly successful. Furthermore, it was shown that
hashing-based techniques also yield an FPRAS for DNF counting without usage of
Monte Carlo sampling. Our analysis, however, shows that the proposed
hashing-based approach to DNF counting provides poor time complexity compared
to the Monte Carlo-based DNF counting techniques. Given the success of
hashing-based techniques for CNF constraints, it is natural to ask: Can
hashing-based techniques provide an efficient FPRAS for DNF counting? In this
paper, we provide a positive answer to this question. To this end, we introduce
two novel algorithmic techniques: <em>Symbolic Hashing</em> and <em>Stochastic
Cell Counting</em>, along with a new hash family of <em>Row-Echelon hash
functions</em>. These innovations allow us to design a hashing-based FPRAS for DNF
counting of similar complexity (up to polylog factors) as that of prior works.
Furthermore, we expect these techniques to have potential applications beyond
DNF counting.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Graph Based ANN 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/bahi2017hash/">Hash Functions Using Chaotic Iterations</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hash Functions Using Chaotic Iterations' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hash Functions Using Chaotic Iterations' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Bahi Jacques M., Guyeux Christophe</td> <!-- ðŸ”§ You were missing this -->
    <td>Journal of Algorithms &amp; Computational Technology</td>
    <td>54</td>
    <td><p>In this paper, a novel formulation of discrete chaotic iterations in the
field of dynamical systems is given. Their topological properties are studied:
it is mathematically proved that, under some conditions, these iterations have
a chaotic behavior in the meaning of Devaney. This chaotic behavior allows us
to propose a way to generate new hash functions. An illustration example is
detailed in order to show how to use our theoretical study in practice.</p>
</td>
    <td>
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/zoran2017learning/">Learning Deep Nearest Neighbor Representations Using Differentiable Boundary Trees</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning Deep Nearest Neighbor Representations Using Differentiable Boundary Trees' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning Deep Nearest Neighbor Representations Using Differentiable Boundary Trees' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zoran Daniel, Lakshminarayanan Balaji, Blundell Charles</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>9</td>
    <td><p>Nearest neighbor (kNN) methods have been gaining popularity in recent years
in light of advances in hardware and efficiency of algorithms. There is a
plethora of methods to choose from today, each with their own advantages and
disadvantages. One requirement shared between all kNN based methods is the need
for a good representation and distance measure between samples.
  We introduce a new method called differentiable boundary tree which allows
for learning deep kNN representations. We build on the recently proposed
boundary tree algorithm which allows for efficient nearest neighbor
classification, regression and retrieval. By modelling traversals in the tree
as stochastic events, we are able to form a differentiable cost function which
is associated with the treeâ€™s predictions. Using a deep neural network to
transform the data and back-propagating through the tree allows us to learn
good representations for kNN methods.
  We demonstrate that our method is able to learn suitable representations
allowing for very efficient trees with a clearly interpretable structure.</p>
</td>
    <td>
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/valsesia2017binary/">Binary Adaptive Embeddings From Order Statistics Of Random Projections</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Binary Adaptive Embeddings From Order Statistics Of Random Projections' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Binary Adaptive Embeddings From Order Statistics Of Random Projections' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Valsesia Diego, Magli Enrico</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Signal Processing Letters</td>
    <td>13</td>
    <td><p>We use some of the largest order statistics of the random projections of a
reference signal to construct a binary embedding that is adapted to signals
correlated with such signal. The embedding is characterized from the analytical
standpoint and shown to provide improved performance on tasks such as
classification in a reduced-dimensionality space.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/zhang2017hashgan/">Hashgan:attention-aware Deep Adversarial Hashing For Cross Modal Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hashgan:attention-aware Deep Adversarial Hashing For Cross Modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hashgan:attention-aware Deep Adversarial Hashing For Cross Modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>16</td>
    <td><p>As the rapid growth of multi-modal data, hashing methods for cross-modal
retrieval have received considerable attention. Deep-networks-based cross-modal
hashing methods are appealing as they can integrate feature learning and hash
coding into end-to-end trainable frameworks. However, it is still challenging
to find content similarities between different modalities of data due to the
heterogeneity gap. To further address this problem, we propose an adversarial
hashing network with attention mechanism to enhance the measurement of content
similarities by selectively focusing on informative parts of multi-modal data.
The proposed new adversarial network, HashGAN, consists of three building
blocks: 1) the feature learning module to obtain feature representations, 2)
the generative attention module to generate an attention mask, which is used to
obtain the attended (foreground) and the unattended (background) feature
representations, 3) the discriminative hash coding module to learn hash
functions that preserve the similarities between different modalities. In our
framework, the generative module and the discriminative module are trained in
an adversarial way: the generator is learned to make the discriminator cannot
preserve the similarities of multi-modal data w.r.t. the background feature
representations, while the discriminator aims to preserve the similarities of
multi-modal data w.r.t. both the foreground and the background feature
representations. Extensive evaluations on several benchmark datasets
demonstrate that the proposed HashGAN brings substantial improvements over
other state-of-the-art cross-modal hashing methods.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Tools & Libraries 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/settle2017query/">Query-by-example Search With Discriminative Neural Acoustic Word Embeddings</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Query-by-example Search With Discriminative Neural Acoustic Word Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Query-by-example Search With Discriminative Neural Acoustic Word Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Settle et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Interspeech 2017</td>
    <td>56</td>
    <td><p>Query-by-example search often uses dynamic time warping (DTW) for comparing
queries and proposed matching segments. Recent work has shown that comparing
speech segments by representing them as fixed-dimensional vectors â€” acoustic
word embeddings â€” and measuring their vector distance (e.g., cosine distance)
can discriminate between words more accurately than DTW-based approaches. We
consider an approach to query-by-example search that embeds both the query and
database segments according to a neural model, followed by nearest-neighbor
search to find the matching segments. Earlier work on embedding-based
query-by-example, using template-based acoustic word embeddings, achieved
competitive performance. We find that our embeddings, based on recurrent neural
networks trained to optimize word discrimination, achieve substantial
improvements in performance and run-time efficiency over the previous
approaches.</p>
</td>
    <td>
      
        Efficiency And Optimization 
      
        INTERSPEECH 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/jiang2017asymmetric/">Asymmetric Deep Supervised Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Asymmetric Deep Supervised Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Asymmetric Deep Supervised Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jiang Qing-yuan, Li Wu-jun</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>248</td>
    <td><p>Hashing has been widely used for large-scale approximate nearest neighbor
search because of its storage and search efficiency. Recent work has found that
deep supervised hashing can significantly outperform non-deep supervised
hashing in many applications. However, most existing deep supervised hashing
methods adopt a symmetric strategy to learn one deep hash function for both
query points and database (retrieval) points. The training of these symmetric
deep supervised hashing methods is typically time-consuming, which makes them
hard to effectively utilize the supervised information for cases with
large-scale database. In this paper, we propose a novel deep supervised hashing
method, called asymmetric deep supervised hashing (ADSH), for large-scale
nearest neighbor search. ADSH treats the query points and database points in an
asymmetric way. More specifically, ADSH learns a deep hash function only for
query points, while the hash codes for database points are directly learned.
The training of ADSH is much more efficient than that of traditional symmetric
deep supervised hashing methods. Experiments show that ADSH can achieve
state-of-the-art performance in real applications.</p>
</td>
    <td>
      
        AAAI 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Neural Hashing 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/argerich2017generic/">Generic LSH Families For The Angular Distance Based On Johnson-lindenstrauss Projections And Feature Hashing LSH</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Generic LSH Families For The Angular Distance Based On Johnson-lindenstrauss Projections And Feature Hashing LSH' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Generic LSH Families For The Angular Distance Based On Johnson-lindenstrauss Projections And Feature Hashing LSH' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Argerich Luis, Golmar Natalia</td> <!-- ðŸ”§ You were missing this -->
    <td>2022 IEEE 38th International Conference on Data Engineering (ICDE)</td>
    <td>11</td>
    <td><p>In this paper we propose the creation of generic LSH families for the angular
distance based on Johnson-Lindenstrauss projections. We show that feature
hashing is a valid J-L projection and propose two new LSH families based on
feature hashing. These new LSH families are tested on both synthetic and real
datasets with very good results and a considerable performance improvement over
other LSH families. While the theoretical analysis is done for the angular
distance, these families can also be used in practice for the euclidean
distance with excellent results [2]. Our tests using real datasets show that
the proposed LSH functions work well for the euclidean distance.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/aum%C3%BCller2017distance/">Distance-sensitive Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Distance-sensitive Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Distance-sensitive Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>AumÃ¼ller et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 37th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems</td>
    <td>18</td>
    <td><p>Locality-sensitive hashing (LSH) is an important tool for managing
high-dimensional noisy or uncertain data, for example in connection with data
cleaning (similarity join) and noise-robust search (similarity search).
However, for a number of problems the LSH framework is not known to yield good
solutions, and instead ad hoc solutions have been designed for particular
similarity and distance measures. For example, this is true for
output-sensitive similarity search/join, and for indexes supporting annulus
queries that aim to report a point close to a certain given distance from the
query point.
  In this paper we initiate the study of distance-sensitive hashing (DSH), a
generalization of LSH that seeks a family of hash functions such that the
probability of two points having the same hash value is a given function of the
distance between them. More precisely, given a distance space \((X,
\text{dist})\) and a â€œcollision probability functionâ€ (CPF) \(f\colon
\mathbb{R}\rightarrow [0,1]\) we seek a distribution over pairs of functions
\((h,g)\) such that for every pair of points \(x, y \in X\) the collision
probability is \(\Pr[h(x)=g(y)] = f(\text{dist}(x,y))\). Locality-sensitive
hashing is the study of how fast a CPF can decrease as the distance grows. For
many spaces, \(f\) can be made exponentially decreasing even if we restrict
attention to the symmetric case where \(g=h\). We show that the asymmetry
achieved by having a pair of functions makes it possible to achieve CPFs that
are, for example, increasing or unimodal, and show how this leads to principled
solutions to problems not addressed by the LSH framework. This includes a novel
application to privacy-preserving distance estimation. We believe that the DSH
framework will find further applications in high-dimensional data management.</p>
</td>
    <td>
      
        Similarity Search 
      
        Locality Sensitive Hashing 
      
        Tools & Libraries 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/andr%C3%A92017accelerated/">Accelerated Nearest Neighbor Search With Quick ADC</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Accelerated Nearest Neighbor Search With Quick ADC' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Accelerated Nearest Neighbor Search With Quick ADC' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>AndrÃ© Fabien Technicolor, Kermarrec Anne-marie Inria, Scouarnec Nicolas Le Technicolor</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 2017 ACM on International Conference on Multimedia Retrieval</td>
    <td>14</td>
    <td><p>Efficient Nearest Neighbor (NN) search in high-dimensional spaces is a
foundation of many multimedia retrieval systems. Because it offers low
responses times, Product Quantization (PQ) is a popular solution. PQ compresses
high-dimensional vectors into short codes using several sub-quantizers, which
enables in-RAM storage of large databases. This allows fast answers to NN
queries, without accessing the SSD or HDD. The key feature of PQ is that it can
compute distances between short codes and high-dimensional vectors using
cache-resident lookup tables. The efficiency of this technique, named
Asymmetric Distance Computation (ADC), remains limited because it performs many
cache accesses.
  In this paper, we introduce Quick ADC, a novel technique that achieves a 3 to
6 times speedup over ADC by exploiting Single Instruction Multiple Data (SIMD)
units available in current CPUs. Efficiently exploiting SIMD requires
algorithmic changes to the ADC procedure. Namely, Quick ADC relies on two key
modifications of ADC: (i) the use 4-bit sub-quantizers instead of the standard
8-bit sub-quantizers and (ii) the quantization of floating-point distances.
This allows Quick ADC to exceed the performance of state-of-the-art systems,
e.g., it achieves a Recall@100 of 0.94 in 3.4 ms on 1 billion SIFT descriptors
(128-bit codes).</p>
</td>
    <td>
      
        Evaluation 
      
        Quantization 
      
        Efficiency And Optimization 
      
        Graph Based ANN 
      
        Compact Codes 
      
        Multimodal Retrieval 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/limasset2017fast/">Fast And Scalable Minimal Perfect Hashing For Massive Key Sets</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fast And Scalable Minimal Perfect Hashing For Massive Key Sets' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fast And Scalable Minimal Perfect Hashing For Massive Key Sets' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Limasset et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>38</td>
    <td><p>Minimal perfect hash functions provide space-efficient and collision-free
hashing on static sets. Existing algorithms and implementations that build such
functions have practical limitations on the number of input elements they can
process, due to high construction time, RAM or external memory usage. We
revisit a simple algorithm and show that it is highly competitive with the
state of the art, especially in terms of construction time and memory usage. We
provide a parallel C++ implementation called BBhash. It is capable of creating
a minimal perfect hash function of \(10^{10}\) elements in less than 7 minutes
using 8 threads and 5 GB of memory, and the resulting function uses 3.7
bits/element. To the best of our knowledge, this is also the first
implementation that has been successfully tested on an input of cardinality
\(10^{12}\). Source code: https://github.com/rizkg/BBHash</p>
</td>
    <td>
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/chandrasekhar2017compression/">Compression Of Deep Neural Networks For Image Instance Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Compression Of Deep Neural Networks For Image Instance Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Compression Of Deep Neural Networks For Image Instance Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Chandrasekhar et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 Data Compression Conference (DCC)</td>
    <td>21</td>
    <td><p>Image instance retrieval is the problem of retrieving images from a database
which contain the same object. Convolutional Neural Network (CNN) based
descriptors are becoming the dominant approach for generating {\it global image
descriptors} for the instance retrieval problem. One major drawback of
CNN-based {\it global descriptors} is that uncompressed deep neural network
models require hundreds of megabytes of storage making them inconvenient to
deploy in mobile applications or in custom hardware. In this work, we study the
problem of neural network model compression focusing on the image instance
retrieval task. We study quantization, coding, pruning and weight sharing
techniques for reducing model size for the instance retrieval problem. We
provide extensive experimental results on the trade-off between retrieval
performance and model size for different types of networks on several data sets
providing the most comprehensive study on this topic. We compress models to the
order of a few MBs: two orders of magnitude smaller than the uncompressed
models while achieving negligible loss in retrieval performance.</p>
</td>
    <td>
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/lillis2017hierarchical/">Hierarchical Bloom Filter Trees For Approximate Matching</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hierarchical Bloom Filter Trees For Approximate Matching' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hierarchical Bloom Filter Trees For Approximate Matching' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lillis David, Breitinger Frank, Scanlon Mark</td> <!-- ðŸ”§ You were missing this -->
    <td>The Journal of Digital Forensics, Security and Law</td>
    <td>5</td>
    <td><p>Bytewise approximate matching algorithms have in recent years shown
significant promise in de- tecting files that are similar at the byte level.
This is very useful for digital forensic investigators, who are regularly faced
with the problem of searching through a seized device for pertinent data. A
common scenario is where an investigator is in possession of a collection of
â€œknown-illegalâ€ files (e.g. a collection of child abuse material) and wishes to
find whether copies of these are stored on the seized device. Approximate
matching addresses shortcomings in traditional hashing, which can only find
identical files, by also being able to deal with cases of merged files,
embedded files, partial files, or if a file has been changed in any way.
  Most approximate matching algorithms work by comparing pairs of files, which
is not a scalable approach when faced with large corpora. This paper
demonstrates the effectiveness of using a â€œHierarchical Bloom Filter Treeâ€
(HBFT) data structure to reduce the running time of
collection-against-collection matching, with a specific focus on the MRSH-v2
algorithm. Three experiments are discussed, which explore the effects of
different configurations of HBFTs. The proposed approach dramatically reduces
the number of pairwise comparisons required, and demonstrates substantial speed
gains, while maintaining effectiveness.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/wygocki2017fast/">On Fast Bounded Locality Sensitive Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=On Fast Bounded Locality Sensitive Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=On Fast Bounded Locality Sensitive Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wygocki Piotr</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining</td>
    <td>85</td>
    <td><p>In this paper, we examine the hash functions expressed as scalar products,
i.e., \(f(x)=&lt;v,x&gt;\), for some bounded random vector \(v\). Such hash functions
have numerous applications, but often there is a need to optimize the choice of
the distribution of \(v\). In the present work, we focus on so-called
anti-concentration bounds, i.e. the upper bounds of \(\mathbb{P}\left[|&lt;v,x&gt;| &lt;
\alpha \right]\). In many applications, \(v\) is a vector of independent random
variables with standard normal distribution. In such case, the distribution of
\(&lt;v,x&gt;\) is also normal and it is easy to approximate \(\mathbb{P}\left[|&lt;v,x&gt;| &lt;
\alpha \right]\). Here, we consider two bounded distributions in the context of
the anti-concentration bounds. Particularly, we analyze \(v\) being a random
vector from the unit ball in \(l_{\infty}\) and \(v\) being a random vector from
the unit sphere in \(l_{2}\). We show optimal up to a constant anti-concentration
measures for functions \(f(x)=&lt;v,x&gt;\).
  As a consequence of our research, we obtain new best results for \newline
\textit{\(c\)-approximate nearest neighbors without false negatives} for \(l_p\) in
high dimensional space for all \(p\in[1,\infty]\), for
\(c=Î©(\max\{\sqrt{d},d^{1/p}\})\). These results improve over those
presented in [16]. Finally, our paper reports progress on answering the open
problem by Pagh~[17], who considered the nearest neighbor search without false
negatives for the Hamming distance.</p>
</td>
    <td>
      
        KDD 
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Graph Based ANN 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/laarhoven2017faster/">Faster Tuple Lattice Sieving Using Spherical Locality-sensitive Filters</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Faster Tuple Lattice Sieving Using Spherical Locality-sensitive Filters' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Faster Tuple Lattice Sieving Using Spherical Locality-sensitive Filters' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Laarhoven Thijs</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>27</td>
    <td><p>To overcome the large memory requirement of classical lattice sieving
algorithms for solving hard lattice problems, Bai-Laarhoven-Stehl'{e} [ANTS
2016] studied tuple lattice sieving, where tuples instead of pairs of lattice
vectors are combined to form shorter vectors. Herold-Kirshanova [PKC 2017]
recently improved upon their results for arbitrary tuple sizes, for example
showing that a triple sieve can solve the shortest vector problem (SVP) in
dimension \(d\) in time \(2^{0.3717d + o(d)}\), using a technique similar to
locality-sensitive hashing for finding nearest neighbors.
  In this work, we generalize the spherical locality-sensitive filters of
Becker-Ducas-Gama-Laarhoven [SODA 2016] to obtain space-time tradeoffs for near
neighbor searching on dense data sets, and we apply these techniques to tuple
lattice sieving to obtain even better time complexities. For instance, our
triple sieve heuristically solves SVP in time \(2^{0.3588d + o(d)}\). For
practical sieves based on Micciancio-Voulgarisâ€™ GaussSieve [SODA 2010], this
shows that a triple sieve uses less space and less time than the current best
near-linear space double sieve.</p>
</td>
    <td>
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/iscen2017fast/">Fast Spectral Ranking For Similarity Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fast Spectral Ranking For Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fast Spectral Ranking For Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Iscen et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</td>
    <td>37</td>
    <td><p>Despite the success of deep learning on representing images for particular
object retrieval, recent studies show that the learned representations still
lie on manifolds in a high dimensional space. This makes the Euclidean nearest
neighbor search biased for this task. Exploring the manifolds online remains
expensive even if a nearest neighbor graph has been computed offline. This work
introduces an explicit embedding reducing manifold search to Euclidean search
followed by dot product similarity search. This is equivalent to linear graph
filtering of a sparse signal in the frequency domain. To speed up online
search, we compute an approximate Fourier basis of the graph offline. We
improve the state of art on particular object retrieval datasets including the
challenging Instre dataset containing small objects. At a scale of 10^5 images,
the offline cost is only a few hours, while query time is comparable to
standard similarity search.</p>
</td>
    <td>
      
        CVPR 
      
        DATASETS 
      
        Similarity Search 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/wang2017flash/">FLASH: Randomized Algorithms Accelerated Over CPU-GPU For Ultra-high Dimensional Similarity Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=FLASH: Randomized Algorithms Accelerated Over CPU-GPU For Ultra-high Dimensional Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=FLASH: Randomized Algorithms Accelerated Over CPU-GPU For Ultra-high Dimensional Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>9</td>
    <td><p>We present FLASH (\textbf{F}ast \textbf{L}SH \textbf{A}lgorithm for
\textbf{S}imilarity search accelerated with \textbf{H}PC), a similarity search
system for ultra-high dimensional datasets on a single machine, that does not
require similarity computations and is tailored for high-performance computing
platforms. By leveraging a LSH style randomized indexing procedure and
combining it with several principled techniques, such as reservoir sampling,
recent advances in one-pass minwise hashing, and count based estimations, we
reduce the computational and parallelization costs of similarity search, while
retaining sound theoretical guarantees.
  We evaluate FLASH on several real, high-dimensional datasets from different
domains, including text, malicious URL, click-through prediction, social
networks, etc. Our experiments shed new light on the difficulties associated
with datasets having several million dimensions. Current state-of-the-art
implementations either fail on the presented scale or are orders of magnitude
slower than FLASH. FLASH is capable of computing an approximate k-NN graph,
from scratch, over the full webspam dataset (1.3 billion nonzeros) in less than
10 seconds. Computing a full k-NN graph in less than 10 seconds on the webspam
dataset, using brute-force (\(n^2D\)), will require at least 20 teraflops. We
provide CPU and GPU implementations of FLASH for replicability of our results.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/ahle2017optimal/">Optimal Las Vegas Locality Sensitive Data Structures</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Optimal Las Vegas Locality Sensitive Data Structures' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Optimal Las Vegas Locality Sensitive Data Structures' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ahle Thomas Dybdahl</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 IEEE 58th Annual Symposium on Foundations of Computer Science (FOCS)</td>
    <td>13</td>
    <td><p>We show that approximate similarity (near neighbour) search can be solved in
high dimensions with performance matching state of the art (data independent)
Locality Sensitive Hashing, but with a guarantee of no false negatives.
  Specifically, we give two data structures for common problems.
  For \(c\)-approximate near neighbour in Hamming space we get query time
\(dn^{1/c+o(1)}\) and space \(dn^{1+1/c+o(1)}\) matching that of
\cite{indyk1998approximate} and answering a long standing open question
from~\cite{indyk2000dimensionality} and~\cite{pagh2016locality} in the
affirmative.
  By means of a new deterministic reduction from \(\ell_1\) to Hamming we also
solve \(\ell_1\) and \(â„“â‚‚\) with query time \(d^2n^{1/c+o(1)}\) and space \(d^2
n^{1+1/c+o(1)}\).
  For \((s_1,s_2)\)-approximate Jaccard similarity we get query time
\(dn^{\rho+o(1)}\) and space \(dn^{1+\rho+o(1)}\),
\(\rho=log\frac{1+s_1}{2s_1}\big/log\frac{1+s_2}{2s_2}\), when sets have equal
size, matching the performance of~\cite{tobias2016}.
  The algorithms are based on space partitions, as with classic LSH, but we
construct these using a combination of brute force, tensoring, perfect hashing
and splitter functions `a la~\cite{naor1995splitters}. We also show a new
dimensionality reduction lemma with 1-sided error.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Graph Based ANN 
      
        Efficiency And Optimization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/jinnai2017hash/">On Hash-based Work Distribution Methods For Parallel Best-first Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=On Hash-based Work Distribution Methods For Parallel Best-first Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=On Hash-based Work Distribution Methods For Parallel Best-first Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jinnai Yuu, Fukunaga Alex</td> <!-- ðŸ”§ You were missing this -->
    <td>Journal of Artificial Intelligence Research</td>
    <td>5</td>
    <td><p>Parallel best-first search algorithms such as Hash Distributed A* (HDA<em>)
distribute work among the processes using a global hash function. We analyze
the search and communication overheads of state-of-the-art hash-based parallel
best-first search algorithms, and show that although Zobrist hashing, the
standard hash function used by HDA</em>, achieves good load balance for many
domains, it incurs significant communication overhead since almost all
generated nodes are transferred to a different processor than their parents. We
propose Abstract Zobrist hashing, a new work distribution method for parallel
search which, instead of computing a hash value based on the raw features of a
state, uses a feature projection function to generate a set of abstract
features which results in a higher locality, resulting in reduced
communications overhead. We show that Abstract Zobrist hashing outperforms
previous methods on search domains using hand-coded, domain specific feature
projection functions. We then propose GRAZHDA<em>, a graph-partitioning based
approach to automatically generating feature projection functions. GRAZHDA</em>
seeks to approximate the partitioning of the actual search space graph by
partitioning the domain transition graph, an abstraction of the state space
graph. We show that GRAZHDA* outperforms previous methods on domain-independent
planning.</p>
</td>
    <td>
      
        Alt 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/jiang2017discrete/">Discrete Latent Factor Model For Cross-modal Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Discrete Latent Factor Model For Cross-modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Discrete Latent Factor Model For Cross-modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jiang Qing-yuan, Li Wu-jun</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Image Processing</td>
    <td>143</td>
    <td><p>Due to its storage and retrieval efficiency, cross-modal hashing~(CMH) has
been widely used for cross-modal similarity search in multimedia applications.
According to the training strategy, existing CMH methods can be mainly divided
into two categories: relaxation-based continuous methods and discrete methods.
In general, the training of relaxation-based continuous methods is faster than
discrete methods, but the accuracy of relaxation-based continuous methods is
not satisfactory. On the contrary, the accuracy of discrete methods is
typically better than relaxation-based continuous methods, but the training of
discrete methods is time-consuming. In this paper, we propose a novel CMH
method, called discrete latent factor model based cross-modal hashing~(DLFH),
for cross modal similarity search. DLFH is a discrete method which can directly
learn the binary hash codes for CMH. At the same time, the training of DLFH is
efficient. Experiments on real datasets show that DLFH can achieve
significantly better accuracy than existing methods, and the training time of
DLFH is comparable to that of relaxation-based continuous methods which are
much faster than existing discrete methods.</p>
</td>
    <td>
      
        DATASETS 
      
        Similarity Search 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/marchet2017resource/">A Resource-frugal Probabilistic Dictionary And Applications In Bioinformatics</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Resource-frugal Probabilistic Dictionary And Applications In Bioinformatics' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Resource-frugal Probabilistic Dictionary And Applications In Bioinformatics' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Marchet et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Discrete Applied Mathematics</td>
    <td>26</td>
    <td><p>Indexing massive data sets is extremely expensive for large scale problems.
In many fields, huge amounts of data are currently generated, however
extracting meaningful information from voluminous data sets, such as computing
similarity between elements, is far from being trivial. It remains nonetheless
a fundamental need. This work proposes a probabilistic data structure based on
a minimal perfect hash function for indexing large sets of keys. Our structure
out-compete the hash table for construction, query times and for memory usage,
in the case of the indexation of a static set. To illustrate the impact of
algorithms performances, we provide two applications based on similarity
computation between collections of sequences, and for which this calculation is
an expensive but required operation. In particular, we show a practical case in
which other bioinformatics tools fail to scale up the tested data set or
provide lower recall quality results.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/qiu2017foresthash/">Foresthash: Semantic Hashing With Shallow Random Forests And Tiny Convolutional Networks</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Foresthash: Semantic Hashing With Shallow Random Forests And Tiny Convolutional Networks' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Foresthash: Semantic Hashing With Shallow Random Forests And Tiny Convolutional Networks' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Qiu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>8</td>
    <td><p>Hash codes are efficient data representations for coping with the ever
growing amounts of data. In this paper, we introduce a random forest semantic
hashing scheme that embeds tiny convolutional neural networks (CNN) into
shallow random forests, with near-optimal information-theoretic code
aggregation among trees. We start with a simple hashing scheme, where random
trees in a forest act as hashing functions by setting <code class="language-plaintext highlighter-rouge">1' for the visited tree
leaf, and </code>0â€™ for the rest. We show that traditional random forests fail to
generate hashes that preserve the underlying similarity between the trees,
rendering the random forests approach to hashing challenging. To address this,
we propose to first randomly group arriving classes at each tree split node
into two groups, obtaining a significantly simplified two-class classification
problem, which can be handled using a light-weight CNN weak learner. Such
random class grouping scheme enables code uniqueness by enforcing each class to
share its code with different classes in different trees. A non-conventional
low-rank loss is further adopted for the CNN weak learners to encourage code
consistency by minimizing intra-class variations and maximizing inter-class
distance for the two random class groups. Finally, we introduce an
information-theoretic approach for aggregating codes of individual trees into a
single hash code, producing a near-optimal unique hash for each class. The
proposed approach significantly outperforms state-of-the-art hashing methods
for image retrieval tasks on large-scale public datasets, while performing at
the level of other state-of-the-art image classification techniques while
utilizing a more compact and efficient scalable representation. This work
proposes a principled and robust procedure to train and deploy in parallel an
ensemble of light-weight CNNs, instead of simply going deeper.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Text Retrieval 
      
        Hashing Methods 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/song2017binary/">Binary Generative Adversarial Networks For Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Binary Generative Adversarial Networks For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Binary Generative Adversarial Networks For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Song Jingkuan</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>164</td>
    <td><p>The most striking successes in image retrieval using deep hashing have mostly
involved discriminative models, which require labels. In this paper, we use
binary generative adversarial networks (BGAN) to embed images to binary codes
in an unsupervised way. By restricting the input noise variable of generative
adversarial networks (GAN) to be binary and conditioned on the features of each
input image, BGAN can simultaneously learn a binary representation per image,
and generate an image plausibly similar to the original one. In the proposed
framework, we address two main problems: 1) how to directly generate binary
codes without relaxation? 2) how to equip the binary representation with the
ability of accurate image retrieval? We resolve these problems by proposing new
sign-activation strategy and a loss function steering the learning process,
which consists of new models for adversarial loss, a content loss, and a
neighborhood structure loss. Experimental results on standard datasets
(CIFAR-10, NUSWIDE, and Flickr) demonstrate that our BGAN significantly
outperforms existing hashing methods by up to 107% in terms of~mAP (See Table
tab.res.map.comp) Our anonymous code is available at:
https://github.com/htconquer/BGAN.</p>
</td>
    <td>
      
        Image Retrieval 
      
        AAAI 
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Neural Hashing 
      
        Tools & Libraries 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/liu2017end/">End-to-end Binary Representation Learning Via Direct Binary Embedding</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=End-to-end Binary Representation Learning Via Direct Binary Embedding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=End-to-end Binary Representation Learning Via Direct Binary Embedding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 IEEE International Conference on Image Processing (ICIP)</td>
    <td>7</td>
    <td><p>Learning binary representation is essential to large-scale computer vision
tasks. Most existing algorithms require a separate quantization constraint to
learn effective hashing functions. In this work, we present Direct Binary
Embedding (DBE), a simple yet very effective algorithm to learn binary
representation in an end-to-end fashion. By appending an ingeniously designed
DBE layer to the deep convolutional neural network (DCNN), DBE learns binary
code directly from the continuous DBE layer activation without quantization
error. By employing the deep residual network (ResNet) as DCNN component, DBE
captures rich semantics from images. Furthermore, in the effort of handling
multilabel images, we design a joint cross entropy loss that includes both
softmax cross entropy and weighted binary cross entropy in consideration of the
correlation and independence of labels, respectively. Extensive experiments
demonstrate the significant superiority of DBE over state-of-the-art methods on
tasks of natural object recognition, image retrieval and image annotation.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Quantization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/quedenfeld2017variant/">Variant Tolerant Read Mapping Using Min-hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Variant Tolerant Read Mapping Using Min-hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Variant Tolerant Read Mapping Using Min-hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Quedenfeld Jens, Rahmann Sven</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>6</td>
    <td><p>DNA read mapping is a ubiquitous task in bioinformatics, and many tools have
been developed to solve the read mapping problem. However, there are two trends
that are changing the landscape of readmapping: First, new sequencing
technologies provide very long reads with high error rates (up to 15%). Second,
many genetic variants in the population are known, so the reference genome is
not considered as a single string over ACGT, but as a complex object containing
these variants. Most existing read mappers do not handle these new
circumstances appropriately.
  We introduce a new read mapper prototype called VATRAM that considers
variants. It is based on Min-Hashing of q-gram sets of reference genome
windows. Min-Hashing is one form of locality sensitive hashing. The variants
are directly inserted into VATRAMs index which leads to a fast mapping process.
Our results show that VATRAM achieves better precision and recall than
state-of-the-art read mappers like BWA under certain cirumstances. VATRAM is
open source and can be accessed at
https://bitbucket.org/Quedenfeld/vatram-src/.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/kapralov2017sample/">Sample Efficient Estimation And Recovery In Sparse FFT Via Isolation On Average</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Sample Efficient Estimation And Recovery In Sparse FFT Via Isolation On Average' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Sample Efficient Estimation And Recovery In Sparse FFT Via Isolation On Average' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Kapralov Michael</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 IEEE 58th Annual Symposium on Foundations of Computer Science (FOCS)</td>
    <td>31</td>
    <td><p>The problem of computing the Fourier Transform of a signal whose spectrum is
dominated by a small number \(k\) of frequencies quickly and using a small number
of samples of the signal in time domain (the Sparse FFT problem) has received
significant attention recently. It is known how to approximately compute the
\(k\)-sparse Fourier transform in \(\approx klog^2 n\) time [Hassanieh et
alâ€™STOCâ€™12], or using the optimal number \(O(klog n)\) of samples [Indyk et
alâ€™FOCSâ€™14] in time domain, or come within \((loglog n)^{O(1)}\) factors of
both these bounds simultaneously, but no algorithm achieving the optimal
\(O(klog n)\) bound in sublinear time is known.
  In this paper we propose a new technique for analysing noisy hashing schemes
that arise in Sparse FFT, which we refer to as isolation on average. We apply
this technique to two problems in Sparse FFT: estimating the values of a list
of frequencies using few samples and computing Sparse FFT itself, achieving
sample-optimal results in \(klog^{O(1)} n\) time for both. We feel that our
approach will likely be of interest in designing Fourier sampling schemes for
more general settings (e.g. model based Sparse FFT).</p>
</td>
    <td>
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/xu2017non/">Non-iterative Label Propagation In Optimal Leading Forest</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Non-iterative Label Propagation In Optimal Leading Forest' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Non-iterative Label Propagation In Optimal Leading Forest' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Xu Ji, Wang Guoyin</td> <!-- ðŸ”§ You were missing this -->
    <td>Information Sciences</td>
    <td>5</td>
    <td><p>Graph based semi-supervised learning (GSSL) has intuitive representation and
can be improved by exploiting the matrix calculation. However, it has to
perform iterative optimization to achieve a preset objective, which usually
leads to low efficiency. Another inconvenience lying in GSSL is that when new
data come, the graph construction and the optimization have to be conducted all
over again. We propose a sound assumption, arguing that: the neighboring data
points are not in peer-to-peer relation, but in a partial-ordered relation
induced by the local density and distance between the data; and the label of a
center can be regarded as the contribution of its followers. Starting from the
assumption, we develop a highly efficient non-iterative label propagation
algorithm based on a novel data structure named as optimal leading forest
(LaPOLeaF). The major weaknesses of the traditional GSSL are addressed by this
study. We further scale LaPOLeaF to accommodate big data by utilizing block
distance matrix technique, parallel computing, and Locality-Sensitive Hashing
(LSH). Experiments on large datasets have shown the promising results of the
proposed methods.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Graph Based ANN 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/yan2017privmin/">Privmin: Differentially Private Minhash For Jaccard Similarity Computation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Privmin: Differentially Private Minhash For Jaccard Similarity Computation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Privmin: Differentially Private Minhash For Jaccard Similarity Computation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yan et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>7</td>
    <td><p>In many industrial applications of big data, the Jaccard Similarity
Computation has been widely used to measure the distance between two profiles
or sets respectively owned by two users. Yet, one semi-honest user with
unpredictable knowledge may also deduce the private or sensitive information
(e.g., the existence of a single element in the original sets) of the other
user via the shared similarity. In this paper, we aim at solving the privacy
issues in Jaccard similarity computation with strict differential privacy
guarantees. To achieve this, we first define the Conditional \(\epsilon\)-DPSO, a
relaxed differential privacy definition regarding set operations, and prove
that the MinHash-based Jaccard Similarity Computation (MH-JSC) satisfies this
definition. Then for achieving strict differential privacy in MH-JSC, we
propose the PrivMin algorithm, which consists of two private operations: 1) the
Private MinHash Value Generation that works by introducing the Exponential
noise to the generation of MinHash signature. 2) the Randomized MinHashing
Steps Selection that works by adopting Randomized Response technique to
privately select several steps within the MinHashing phase that are deployed
with the Exponential mechanism. Experiments on real datasets demonstrate that
the proposed PrivMin algorithm can successfully retain the utility of the
computed similarity while preserving privacy.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/wu2017improved/">Improved Consistent Weighted Sampling Revisited</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Improved Consistent Weighted Sampling Revisited' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Improved Consistent Weighted Sampling Revisited' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Knowledge and Data Engineering</td>
    <td>19</td>
    <td><p>Min-Hash is a popular technique for efficiently estimating the Jaccard
similarity of binary sets. Consistent Weighted Sampling (CWS) generalizes the
Min-Hash scheme to sketch weighted sets and has drawn increasing interest from
the community. Due to its constant-time complexity independent of the values of
the weights, Improved CWS (ICWS) is considered as the state-of-the-art CWS
algorithm. In this paper, we revisit ICWS and analyze its underlying mechanism
to show that there actually exists dependence between the two components of the
hash-code produced by ICWS, which violates the condition of independence. To
remedy the problem, we propose an Improved ICWS (I\(^2\)CWS) algorithm which not
only shares the same theoretical computational complexity as ICWS but also
abides by the required conditions of the CWS scheme. The experimental results
on a number of synthetic data sets and real-world text data sets demonstrate
that our I\(^2\)CWS algorithm can estimate the Jaccard similarity more
accurately, and also compete with or outperform the compared methods, including
ICWS, in classification and top-\(K\) retrieval, after relieving the underlying
dependence.</p>
</td>
    <td>
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/wu2017sampling/">Sampling Matters In Deep Embedding Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Sampling Matters In Deep Embedding Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Sampling Matters In Deep Embedding Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 IEEE International Conference on Computer Vision (ICCV)</td>
    <td>863</td>
    <td><p>Deep embeddings answer one simple question: How similar are two images?
Learning these embeddings is the bedrock of verification, zero-shot learning,
and visual search. The most prominent approaches optimize a deep convolutional
network with a suitable loss function, such as contrastive loss or triplet
loss. While a rich line of work focuses solely on the loss functions, we show
in this paper that selecting training examples plays an equally important role.
We propose distance weighted sampling, which selects more informative and
stable examples than traditional approaches. In addition, we show that a simple
margin based loss is sufficient to outperform all other loss functions. We
evaluate our approach on the Stanford Online Products, CAR196, and the
CUB200-2011 datasets for image retrieval and clustering, and on the LFW dataset
for face verification. Our method achieves state-of-the-art performance on all
of them.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Graph Based ANN 
      
        Distance Metric Learning 
      
        ICCV 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/ferdowsi2017sparse/">Sparse Ternary Codes For Similarity Search Have Higher Coding Gain Than Dense Binary Codes</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Sparse Ternary Codes For Similarity Search Have Higher Coding Gain Than Dense Binary Codes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Sparse Ternary Codes For Similarity Search Have Higher Coding Gain Than Dense Binary Codes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ferdowsi et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 IEEE International Symposium on Information Theory (ISIT)</td>
    <td>12</td>
    <td><p>This paper addresses the problem of Approximate Nearest Neighbor (ANN) search
in pattern recognition where feature vectors in a database are encoded as
compact codes in order to speed-up the similarity search in large-scale
databases. Considering the ANN problem from an information-theoretic
perspective, we interpret it as an encoding, which maps the original feature
vectors to a less entropic sparse representation while requiring them to be as
informative as possible. We then define the coding gain for ANN search using
information-theoretic measures. We next show that the classical approach to
this problem, which consists of binarization of the projected vectors is
sub-optimal. Instead, a properly designed ternary encoding achieves higher
coding gains and lower complexity.</p>
</td>
    <td>
      
        Compact Codes 
      
        Similarity Search 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/luo2017arrays/">Arrays Of (locality-sensitive) Count Estimators (ACE): High-speed Anomaly Detection Via Cache Lookups</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Arrays Of (locality-sensitive) Count Estimators (ACE): High-speed Anomaly Detection Via Cache Lookups' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Arrays Of (locality-sensitive) Count Estimators (ACE): High-speed Anomaly Detection Via Cache Lookups' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Luo Chen, Shrivastava Anshumali</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>5</td>
    <td><p>Anomaly detection is one of the frequent and important subroutines deployed
in large-scale data processing systems. Even being a well-studied topic,
existing techniques for unsupervised anomaly detection require storing
significant amounts of data, which is prohibitive from memory and latency
perspective. In the big-data world existing methods fail to address the new set
of memory and latency constraints. In this paper, we propose ACE (Arrays of
(locality-sensitive) Count Estimators) algorithm that can be 60x faster than
the ELKI package~\cite{DBLP:conf/ssd/AchtertBKSZ09}, which has the fastest
implementation of the unsupervised anomaly detection algorithms. ACE algorithm
requires less than \(4MB\) memory, to dynamically compress the full data
information into a set of count arrays. These tiny \(4MB\) arrays of counts are
sufficient for unsupervised anomaly detection. At the core of the ACE
algorithm, there is a novel statistical estimator which is derived from the
sampling view of Locality Sensitive Hashing(LSH). This view is significantly
different and efficient than the widely popular view of LSH for near-neighbor
search. We show the superiority of ACE algorithm over 11 popular baselines on 3
benchmark datasets, including the KDD-Cup99 data which is the largest available
benchmark comprising of more than half a million entries with ground truth
anomaly labels.</p>
</td>
    <td>
      
        KDD 
      
        DATASETS 
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/lau2017end/">End-to-end Network For Twitter Geolocation Prediction And Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=End-to-end Network For Twitter Geolocation Prediction And Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=End-to-end Network For Twitter Geolocation Prediction And Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lau et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>7</td>
    <td><p>We propose an end-to-end neural network to predict the geolocation of a
tweet. The network takes as input a number of raw Twitter metadata such as the
tweet message and associated user account information. Our model is language
independent, and despite minimal feature engineering, it is interpretable and
capable of learning location indicative words and timing patterns. Compared to
state-of-the-art systems, our model outperforms them by 2%-6%. Additionally, we
propose extensions to the model to compress representation learnt by the
network into binary codes. Experiments show that it produces compact codes
compared to benchmark hashing algorithms. An implementation of the model is
released publicly.</p>
</td>
    <td>
      
        Compact Codes 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/ertl2017superminhash/">Superminhash - A New Minwise Hashing Algorithm For Jaccard Similarity Estimation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Superminhash - A New Minwise Hashing Algorithm For Jaccard Similarity Estimation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Superminhash - A New Minwise Hashing Algorithm For Jaccard Similarity Estimation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ertl Otmar</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>13</td>
    <td><p>This paper presents a new algorithm for calculating hash signatures of sets
which can be directly used for Jaccard similarity estimation. The new approach
is an improvement over the MinHash algorithm, because it has a better runtime
behavior and the resulting signatures allow a more precise estimation of the
Jaccard index.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/lai2017transductive/">Transductive Zero-shot Hashing Via Coarse-to-fine Similarity Mining</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Transductive Zero-shot Hashing Via Coarse-to-fine Similarity Mining' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Transductive Zero-shot Hashing Via Coarse-to-fine Similarity Mining' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lai Hanjiang, Pan Yan</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 2018 ACM on International Conference on Multimedia Retrieval</td>
    <td>9</td>
    <td><p>Zero-shot Hashing (ZSH) is to learn hashing models for novel/target classes
without training data, which is an important and challenging problem. Most
existing ZSH approaches exploit transfer learning via an intermediate shared
semantic representations between the seen/source classes and novel/target
classes. However, due to having disjoint, the hash functions learned from the
source dataset are biased when applied directly to the target classes. In this
paper, we study the transductive ZSH, i.e., we have unlabeled data for novel
classes. We put forward a simple yet efficient joint learning approach via
coarse-to-fine similarity mining which transfers knowledges from source data to
target data. It mainly consists of two building blocks in the proposed deep
architecture: 1) a shared two-streams network, which the first stream operates
on the source data and the second stream operates on the unlabeled data, to
learn the effective common image representations, and 2) a coarse-to-fine
module, which begins with finding the most representative images from target
classes and then further detect similarities among these images, to transfer
the similarities of the source data to the target data in a greedy fashion.
Extensive evaluation results on several benchmark datasets demonstrate that the
proposed hashing method achieves significant improvement over the
state-of-the-art methods.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        Hashing Methods 
      
        Multimodal Retrieval 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/raff2017lempel/">Lempel-ziv Jaccard Distance, An Effective Alternative To Ssdeep And Sdhash</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Lempel-ziv Jaccard Distance, An Effective Alternative To Ssdeep And Sdhash' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Lempel-ziv Jaccard Distance, An Effective Alternative To Ssdeep And Sdhash' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Raff Edward, Nicholas Charles K.</td> <!-- ðŸ”§ You were missing this -->
    <td>Digital Investigation</td>
    <td>22</td>
    <td><p>Recent work has proposed the Lempel-Ziv Jaccard Distance (LZJD) as a method
to measure the similarity between binary byte sequences for malware
classification. We propose and test LZJDâ€™s effectiveness as a similarity digest
hash for digital forensics. To do so we develop a high performance Java
implementation with the same command-line arguments as sdhash, making it easy
to integrate into existing workflows. Our testing shows that LZJD is effective
for this task, and significantly outperforms sdhash and ssdeep in its ability
to match related file fragments and files corrupted with random noise. In
addition, LZJD is up to 60x faster than sdhash at comparison time.</p>
</td>
    <td>
      
        Alt 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/shu2017compressing/">Compressing Word Embeddings Via Deep Compositional Code Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Compressing Word Embeddings Via Deep Compositional Code Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Compressing Word Embeddings Via Deep Compositional Code Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Shu Raphael, Nakayama Hideki</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>95</td>
    <td><p>Natural language processing (NLP) models often require a massive number of
parameters for word embeddings, resulting in a large storage or memory
footprint. Deploying neural NLP models to mobile devices requires compressing
the word embeddings without any significant sacrifices in performance. For this
purpose, we propose to construct the embeddings with few basis vectors. For
each word, the composition of basis vectors is determined by a hash code. To
maximize the compression rate, we adopt the multi-codebook quantization
approach instead of binary coding scheme. Each code is composed of multiple
discrete numbers, such as (3, 2, 1, 8), where the value of each component is
limited to a fixed range. We propose to directly learn the discrete codes in an
end-to-end neural network by applying the Gumbel-softmax trick. Experiments
show the compression rate achieves 98% in a sentiment analysis task and 94% ~
99% in machine translation tasks without performance loss. In both tasks, the
proposed method can improve the model performance by slightly lowering the
compression rate. Compared to other approaches such as character-level
segmentation, the proposed method is language-independent and does not require
modifications to the network architecture.</p>
</td>
    <td>
      
        Quantization 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/wu2017structured/">Structured Deep Hashing With Convolutional Neural Networks For Fast Person Re-identification</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Structured Deep Hashing With Convolutional Neural Networks For Fast Person Re-identification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Structured Deep Hashing With Convolutional Neural Networks For Fast Person Re-identification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wu Lin, Wang Yang</td> <!-- ðŸ”§ You were missing this -->
    <td>Computer Vision and Image Understanding</td>
    <td>71</td>
    <td><p>Given a pedestrian image as a query, the purpose of person re-identification
is to identify the correct match from a large collection of gallery images
depicting the same person captured by disjoint camera views. The critical
challenge is how to construct a robust yet discriminative feature
representation to capture the compounded variations in pedestrian appearance.
To this end, deep learning methods have been proposed to extract hierarchical
features against extreme variability of appearance. However, existing methods
in this category generally neglect the efficiency in the matching stage whereas
the searching speed of a re-identification system is crucial in real-world
applications. In this paper, we present a novel deep hashing framework with
Convolutional Neural Networks (CNNs) for fast person re-identification.
Technically, we simultaneously learn both CNN features and hash functions/codes
to get robust yet discriminative features and similarity-preserving hash codes.
Thereby, person re-identification can be resolved by efficiently computing and
ranking the Hamming distances between images. A structured loss function
defined over positive pairs and hard negatives is proposed to formulate a novel
optimization problem so that fast convergence and more stable optimized
solution can be obtained. Extensive experiments on two benchmarks CUHK03
\cite{FPNN} and Market-1501 \cite{Market1501} show that the proposed deep
architecture is efficacy over state-of-the-arts.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Neural Hashing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/dutta2017stochastic/">Stochastic Graphlet Embedding</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Stochastic Graphlet Embedding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Stochastic Graphlet Embedding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Dutta Anjan, Sahbi Hichem</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Neural Networks and Learning Systems</td>
    <td>19</td>
    <td><p>Graph-based methods are known to be successful in many machine learning and
pattern classification tasks. These methods consider semi-structured data as
graphs where nodes correspond to primitives (parts, interest points, segments,
etc.) and edges characterize the relationships between these primitives.
However, these non-vectorial graph data cannot be straightforwardly plugged
into off-the-shelf machine learning algorithms without a preliminary step of â€“
explicit/implicit â€“ graph vectorization and embedding. This embedding process
should be resilient to intra-class graph variations while being highly
discriminant. In this paper, we propose a novel high-order stochastic graphlet
embedding (SGE) that maps graphs into vector spaces. Our main contribution
includes a new stochastic search procedure that efficiently parses a given
graph and extracts/samples unlimitedly high-order graphlets. We consider these
graphlets, with increasing orders, to model local primitives as well as their
increasingly complex interactions. In order to build our graph representation,
we measure the distribution of these graphlets into a given graph, using
particular hash functions that efficiently assign sampled graphlets into
isomorphic sets with a very low probability of collision. When combined with
maximum margin classifiers, these graphlet-based representations have positive
impact on the performance of pattern comparison and recognition as corroborated
through extensive experiments using standard benchmark databases.</p>
</td>
    <td>
      
        Graph Based ANN 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/xu2017self/">Self-taught Convolutional Neural Networks For Short Text Clustering</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Self-taught Convolutional Neural Networks For Short Text Clustering' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Self-taught Convolutional Neural Networks For Short Text Clustering' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Xu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Neural Networks</td>
    <td>208</td>
    <td><p>Short text clustering is a challenging problem due to its sparseness of text
representation. Here we propose a flexible Self-Taught Convolutional neural
network framework for Short Text Clustering (dubbed STC^2), which can flexibly
and successfully incorporate more useful semantic features and learn non-biased
deep text representation in an unsupervised manner. In our framework, the
original raw text features are firstly embedded into compact binary codes by
using one existing unsupervised dimensionality reduction methods. Then, word
embeddings are explored and fed into convolutional neural networks to learn
deep feature representations, meanwhile the output units are used to fit the
pre-trained binary codes in the training process. Finally, we get the optimal
clusters by employing K-means to cluster the learned representations. Extensive
experimental results demonstrate that the proposed framework is effective,
flexible and outperform several popular clustering methods when tested on three
public short text datasets.</p>
</td>
    <td>
      
        DATASETS 
      
        Tools & Libraries 
      
        ICANN 
      
        Compact Codes 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/wang2017composite/">Composite Quantization</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Composite Quantization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Composite Quantization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang Jingdong, Zhang Ting</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>197</td>
    <td><p>This paper studies the compact coding approach to approximate nearest
neighbor search. We introduce a composite quantization framework. It uses the
composition of several (\(M\)) elements, each of which is selected from a
different dictionary, to accurately approximate a \(D\)-dimensional vector, thus
yielding accurate search, and represents the data vector by a short code
composed of the indices of the selected elements in the corresponding
dictionaries. Our key contribution lies in introducing a near-orthogonality
constraint, which makes the search efficiency is guaranteed as the cost of the
distance computation is reduced to \(O(M)\) from \(O(D)\) through a distance table
lookup scheme. The resulting approach is called near-orthogonal composite
quantization. We theoretically justify the equivalence between near-orthogonal
composite quantization and minimizing an upper bound of a function formed by
jointly considering the quantization error and the search cost according to a
generalized triangle inequality. We empirically show the efficacy of the
proposed approach over several benchmark datasets. In addition, we demonstrate
the superior performances in other three applications: combination with
inverted multi-index, quantizing the query for mobile search, and inner-product
similarity search.</p>
</td>
    <td>
      
        DATASETS 
      
        Efficiency And Optimization 
      
        Similarity Search 
      
        Quantization 
      
        Vector Indexing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/driemel2017locality/">Locality-sensitive Hashing Of Curves</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Locality-sensitive Hashing Of Curves' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Locality-sensitive Hashing Of Curves' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Driemel Anne, Silvestri Francesco</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>31</td>
    <td><p>We study data structures for storing a set of polygonal curves in \({\rm R}^d\)
such that, given a query curve, we can efficiently retrieve similar curves from
the set, where similarity is measured using the discrete Fr'echet distance or
the dynamic time warping distance. To this end we devise the first
locality-sensitive hashing schemes for these distance measures. A major
challenge is posed by the fact that these distance measures internally optimize
the alignment between the curves. We give solutions for different types of
alignments including constrained and unconstrained versions. For unconstrained
alignments, we improve over a result by Indyk from 2002 for short curves. Let
\(n\) be the number of input curves and let \(m\) be the maximum complexity of a
curve in the input. In the particular case where \(m \leq \frac{\alpha}{4d} log
n\), for some fixed \(\alpha&gt;0\), our solutions imply an approximate near-neighbor
data structure for the discrete Fr'echet distance that uses space in
\(O(n^{1+\alpha}log n)\) and achieves query time in \(O(n^{\alpha}log^2 n)\) and
constant approximation factor. Furthermore, our solutions provide a trade-off
between approximation quality and computational performance: for any parameter
\(k \in [m]\), we can give a data structure that uses space in \(O(2^{2k}m^{k-1} n
log n + nm)\), answers queries in \(O( 2^{2k} m^{k}log n)\) time and achieves
approximation factor in \(O(m/k)\).</p>
</td>
    <td>
      
        Graph Based ANN 
      
        Hashing Methods 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/rygl2017semantic/">Semantic Vector Encoding And Similarity Search Using Fulltext Search Engines</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Semantic Vector Encoding And Similarity Search Using Fulltext Search Engines' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Semantic Vector Encoding And Similarity Search Using Fulltext Search Engines' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Rygl et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 2nd Workshop on Representation Learning for NLP</td>
    <td>12</td>
    <td><p>Vector representations and vector space modeling (VSM) play a central role in
modern machine learning. We propose a novel approach to `vector similarity
searchingâ€™ over dense semantic representations of words and documents that can
be deployed on top of traditional inverted-index-based fulltext engines, taking
advantage of their robustness, stability, scalability and ubiquity.
  We show that this approach allows the indexing and querying of dense vectors
in text domains. This opens up exciting avenues for major efficiency gains,
along with simpler deployment, scaling and monitoring.
  The end result is a fast and scalable vector database with a tunable
trade-off between vector search performance and quality, backed by a standard
fulltext engine such as Elasticsearch.
  We empirically demonstrate its querying performance and quality by applying
this solution to the task of semantic searching over a dense vector
representation of the entire English Wikipedia.</p>
</td>
    <td>
      
        Efficiency And Optimization 
      
        Text Retrieval 
      
        Similarity Search 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/song2017deep/">Deep Discrete Hashing With Self-supervised Pairwise Labels</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Discrete Hashing With Self-supervised Pairwise Labels' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Discrete Hashing With Self-supervised Pairwise Labels' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Song et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>11</td>
    <td><p>Hashing methods have been widely used for applications of large-scale image
retrieval and classification. Non-deep hashing methods using handcrafted
features have been significantly outperformed by deep hashing methods due to
their better feature representation and end-to-end learning framework. However,
the most striking successes in deep hashing have mostly involved discriminative
models, which require labels. In this paper, we propose a novel unsupervised
deep hashing method, named Deep Discrete Hashing (DDH), for large-scale image
retrieval and classification. In the proposed framework, we address two main
problems: 1) how to directly learn discrete binary codes? 2) how to equip the
binary representation with the ability of accurate image retrieval and
classification in an unsupervised way? We resolve these problems by introducing
an intermediate variable and a loss function steering the learning process,
which is based on the neighborhood structure in the original space.
Experimental results on standard datasets (CIFAR-10, NUS-WIDE, and Oxford-17)
demonstrate that our DDH significantly outperforms existing hashing methods by
large margin in terms of~mAP for image retrieval and object recognition. Code
is available at https://github.com/htconquer/ddh.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Neural Hashing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/dong2017video/">Video Retrieval Based On Deep Convolutional Neural Network</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Video Retrieval Based On Deep Convolutional Neural Network' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Video Retrieval Based On Deep Convolutional Neural Network' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Dong Yj, Li Jg</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 3rd International Conference on Multimedia Systems and Signal Processing</td>
    <td>17</td>
    <td><p>Recently, with the enormous growth of online videos, fast video retrieval
research has received increasing attention. As an extension of image hashing
techniques, traditional video hashing methods mainly depend on hand-crafted
features and transform the real-valued features into binary hash codes. As
videos provide far more diverse and complex visual information than images,
extracting features from videos is much more challenging than that from images.
Therefore, high-level semantic features to represent videos are needed rather
than low-level hand-crafted methods. In this paper, a deep convolutional neural
network is proposed to extract high-level semantic features and a binary hash
function is then integrated into this framework to achieve an end-to-end
optimization. Particularly, our approach also combines triplet loss function
which preserves the relative similarity and difference of videos and
classification loss function as the optimization objective. Experiments have
been performed on two public datasets and the results demonstrate the
superiority of our proposed method compared with other state-of-the-art video
retrieval methods.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/laarhoven2017graph/">Graph-based Time-space Trade-offs For Approximate Near Neighbors</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Graph-based Time-space Trade-offs For Approximate Near Neighbors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Graph-based Time-space Trade-offs For Approximate Near Neighbors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Laarhoven Thijs</td> <!-- ðŸ”§ You were missing this -->
    <td>34th International Symposium on Computational Geometry (SoCG) pp. 571-5714 2018</td>
    <td>5</td>
    <td><p>We take a first step towards a rigorous asymptotic analysis of graph-based
approaches for finding (approximate) nearest neighbors in high-dimensional
spaces, by analyzing the complexity of (randomized) greedy walks on the
approximate near neighbor graph. For random data sets of size \(n = 2^{o(d)}\) on
the \(d\)-dimensional Euclidean unit sphere, using near neighbor graphs we can
provably solve the approximate nearest neighbor problem with approximation
factor \(c &gt; 1\) in query time \(n^{\rho_q + o(1)}\) and space \(n^{1 + \rho_s +
o(1)}\), for arbitrary \(\rho_q, \rho_s \geq 0\) satisfying \begin{align} (2c^2 -
1) \rho_q + 2 c^2 (c^2 - 1) \sqrt{\rho_s (1 - \rho_s)} \geq c^4. \end{align}
Graph-based near neighbor searching is especially competitive with hash-based
methods for small \(c\) and near-linear memory, and in this regime the asymptotic
scaling of a greedy graph-based search matches the recent optimal hash-based
trade-offs of Andoni-Laarhoven-Razenshteyn-Waingarten [SODAâ€™17]. We further
study how the trade-offs scale when the data set is of size \(n =
2^{\Theta(d)}\), and analyze asymptotic complexities when applying these results
to lattice sieving.</p>
</td>
    <td>
      
        Graph Based ANN 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/zhao2017scalable/">Scalable Nearest Neighbor Search Based On Knn Graph</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Scalable Nearest Neighbor Search Based On Knn Graph' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Scalable Nearest Neighbor Search Based On Knn Graph' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhao Wan-lei, Yang Jie, Deng Cheng-hao</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>7</td>
    <td><p>Nearest neighbor search is known as a challenging issue that has been studied
for several decades. Recently, this issue becomes more and more imminent in
viewing that the big data problem arises from various fields. In this paper, a
scalable solution based on hill-climbing strategy with the support of k-nearest
neighbor graph (kNN) is presented. Two major issues have been considered in the
paper. Firstly, an efficient kNN graph construction method based on two means
tree is presented. For the nearest neighbor search, an enhanced hill-climbing
procedure is proposed, which sees considerable performance boost over original
procedure. Furthermore, with the support of inverted indexing derived from
residue vector quantization, our method achieves close to 100% recall with high
speed efficiency in two state-of-the-art evaluation benchmarks. In addition, a
comparative study on both the compressional and traditional nearest neighbor
search methods is presented. We show that our method achieves the best
trade-off between search quality, efficiency and memory complexity.</p>
</td>
    <td>
      
        Survey Paper 
      
        Graph Based ANN 
      
        Efficiency And Optimization 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/klein2017end/">End-to-end Supervised Product Quantization For Image Search And Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=End-to-end Supervised Product Quantization For Image Search And Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=End-to-end Supervised Product Quantization For Image Search And Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Klein Benjamin, Wolf Lior</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>59</td>
    <td><p>Product Quantization, a dictionary based hashing method, is one of the
leading unsupervised hashing techniques. While it ignores the labels, it
harnesses the features to construct look up tables that can approximate the
feature space. In recent years, several works have achieved state of the art
results on hashing benchmarks by learning binary representations in a
supervised manner. This work presents Deep Product Quantization (DPQ), a
technique that leads to more accurate retrieval and classification than the
latest state of the art methods, while having similar computational complexity
and memory footprint as the Product Quantization method. To our knowledge, this
is the first work to introduce a dictionary-based representation that is
inspired by Product Quantization and which is learned end-to-end, and thus
benefits from the supervised signal. DPQ explicitly learns soft and hard
representations to enable an efficient and accurate asymmetric search, by using
a straight-through estimator. Our method obtains state of the art results on an
extensive array of retrieval and classification experiments.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        CVPR 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/do2017simultaneous/">Simultaneous Feature Aggregating And Hashing For Large-scale Image Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Simultaneous Feature Aggregating And Hashing For Large-scale Image Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Simultaneous Feature Aggregating And Hashing For Large-scale Image Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Do et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>38</td>
    <td><p>In most state-of-the-art hashing-based visual search systems, local image
descriptors of an image are first aggregated as a single feature vector. This
feature vector is then subjected to a hashing function that produces a binary
hash code. In previous work, the aggregating and the hashing processes are
designed independently. In this paper, we propose a novel framework where
feature aggregating and hashing are designed simultaneously and optimized
jointly. Specifically, our joint optimization produces aggregated
representations that can be better reconstructed by some binary codes. This
leads to more discriminative binary hash codes and improved retrieval accuracy.
In addition, we also propose a fast version of the recently-proposed Binary
Autoencoder to be used in our proposed framework. We perform extensive
retrieval experiments on several benchmark datasets with both SIFT and
convolutional features. Our results suggest that the proposed framework
achieves significant improvements over the state of the art.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        CVPR 
      
        Compact Codes 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/do2017compact/">Compact Hash Code Learning With Binary Deep Neural Network</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Compact Hash Code Learning With Binary Deep Neural Network' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Compact Hash Code Learning With Binary Deep Neural Network' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Do et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Multimedia</td>
    <td>23</td>
    <td><p>Learning compact binary codes for image retrieval problem using deep neural
networks has recently attracted increasing attention. However, training deep
hashing networks is challenging due to the binary constraints on the hash
codes. In this paper, we propose deep network models and learning algorithms
for learning binary hash codes given image representations under both
unsupervised and supervised manners. The novelty of our network design is that
we constrain one hidden layer to directly output the binary codes. This design
has overcome a challenging problem in some previous works: optimizing
non-smooth objective functions because of binarization. In addition, we propose
to incorporate independence and balance properties in the direct and strict
forms into the learning schemes. We also include a similarity preserving
property in our objective functions. The resulting optimizations involving
these binary, independence, and balance constraints are difficult to solve. To
tackle this difficulty, we propose to learn the networks with alternating
optimization and careful relaxation. Furthermore, by leveraging the powerful
capacity of convolutional neural networks, we propose an end-to-end
architecture that jointly learns to extract visual features and produce binary
hash codes. Experimental results for the benchmark datasets show that the
proposed methods compare favorably or outperform the state of the art.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Alt 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/jin2017ranking/">Ranking Based Locality Sensitive Hashing Enabled Cancelable Biometrics: Index-of-max Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Ranking Based Locality Sensitive Hashing Enabled Cancelable Biometrics: Index-of-max Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Ranking Based Locality Sensitive Hashing Enabled Cancelable Biometrics: Index-of-max Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jin et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Information Forensics and Security</td>
    <td>195</td>
    <td><p>In this paper, we propose a ranking based locality sensitive hashing inspired
two-factor cancelable biometrics, dubbed â€œIndex-of-Maxâ€ (IoM) hashing for
biometric template protection. With externally generated random parameters, IoM
hashing transforms a real-valued biometric feature vector into discrete index
(max ranked) hashed code. We demonstrate two realizations from IoM hashing
notion, namely Gaussian Random Projection based and Uniformly Random
Permutation based hashing schemes. The discrete indices representation nature
of IoM hashed codes enjoy serveral merits. Firstly, IoM hashing empowers strong
concealment to the biometric information. This contributes to the solid ground
of non-invertibility guarantee. Secondly, IoM hashing is insensitive to the
features magnitude, hence is more robust against biometric features variation.
Thirdly, the magnitude-independence trait of IoM hashing makes the hash codes
being scale-invariant, which is critical for matching and feature alignment.
The experimental results demonstrate favorable accuracy performance on
benchmark FVC2002 and FVC2004 fingerprint databases. The analyses justify its
resilience to the existing and newly introduced security and privacy attacks as
well as satisfy the revocability and unlinkability criteria of cancelable
biometrics.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/zhang2017effective/">Effective Image Retrieval Via Multilinear Multi-index Fusion</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Effective Image Retrieval Via Multilinear Multi-index Fusion' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Effective Image Retrieval Via Multilinear Multi-index Fusion' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Multimedia</td>
    <td>24</td>
    <td><p>Multi-index fusion has demonstrated impressive performances in retrieval task
by integrating different visual representations in a unified framework.
However, previous works mainly consider propagating similarities via neighbor
structure, ignoring the high order information among different visual
representations. In this paper, we propose a new multi-index fusion scheme for
image retrieval. By formulating this procedure as a multilinear based
optimization problem, the complementary information hidden in different indexes
can be explored more thoroughly. Specially, we first build our multiple indexes
from various visual representations. Then a so-called index-specific functional
matrix, which aims to propagate similarities, is introduced for updating the
original index. The functional matrices are then optimized in a unified tensor
space to achieve a refinement, such that the relevant images can be pushed more
closer. The optimization problem can be efficiently solved by the augmented
Lagrangian method with theoretical convergence guarantee. Unlike the
traditional multi-index fusion scheme, our approach embeds the multi-index
subspace structure into the new indexes with sparse constraint, thus it has
little additional memory consumption in online query stage. Experimental
evaluation on three benchmark datasets reveals that the proposed approach
achieves the state-of-the-art performance, i.e., N-score 3.94 on UKBench, mAP
94.1% on Holiday and 62.39% on Market-1501.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Vector Indexing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/wang2017subspace/">Subspace Approximation For Approximate Nearest Neighbor Search In NLP</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Subspace Approximation For Approximate Nearest Neighbor Search In NLP' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Subspace Approximation For Approximate Nearest Neighbor Search In NLP' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang Jing</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Pattern Analysis and Machine Intelligence</td>
    <td>56</td>
    <td><p>Most natural language processing tasks can be formulated as the approximated
nearest neighbor search problem, such as word analogy, document similarity,
machine translation. Take the question-answering task as an example, given a
question as the query, the goal is to search its nearest neighbor in the
training dataset as the answer. However, existing methods for approximate
nearest neighbor search problem may not perform well owing to the following
practical challenges: 1) there are noise in the data; 2) the large scale
dataset yields a huge retrieval space and high search time complexity.
  In order to solve these problems, we propose a novel approximate nearest
neighbor search framework which i) projects the data to a subspace based
spectral analysis which eliminates the influence of noise; ii) partitions the
training dataset to different groups in order to reduce the search space.
Specifically, the retrieval space is reduced from \(O(n)\) to \(O(log n)\) (where
\(n\) is the number of data points in the training dataset). We prove that the
retrieved nearest neighbor in the projected subspace is the same as the one in
the original feature space. We demonstrate the outstanding performance of our
framework on real-world natural language processing tasks.</p>
</td>
    <td>
      
        Graph Based ANN 
      
        DATASETS 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/fu2017fast/">Fast Approximate Nearest Neighbor Search With The Navigating Spreading-out Graph</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fast Approximate Nearest Neighbor Search With The Navigating Spreading-out Graph' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fast Approximate Nearest Neighbor Search With The Navigating Spreading-out Graph' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Fu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the VLDB Endowment</td>
    <td>219</td>
    <td><p>Approximate nearest neighbor search (ANNS) is a fundamental problem in databases and data mining. A scalable ANNS algorithm should be both memory-efficient and fast. Some early graph-based approaches have shown attractive theoretical guarantees on search time complexity, but they all suffer from the problem of high indexing time complexity. Recently, some graph-based methods have been proposed to reduce indexing complexity by approximating the traditional graphs; these methods have achieved revolutionary performance on million-scale datasets. Yet, they still can not scale to billion-node databases. In this paper, to further improve the search-efficiency and scalability of graph-based methods, we start by introducing four aspects: (1) ensuring the connectivity of the graph; (2) lowering the average out-degree of the graph for fast traversal; (3) shortening the search path; and (4) reducing the index size. Then, we propose a novel graph structure called Monotonic Relative Neighborhood Graph (MRNG) which guarantees very low search complexity (close to logarithmic time). To further lower the indexing complexity and make it practical for billion-node ANNS problems, we propose a novel graph structure named Navigating Spreading-out Graph (NSG) by approximating the MRNG. The NSG takes the four aspects into account simultaneously. Extensive experiments show that NSG outperforms all the existing algorithms significantly. In addition, NSG shows superior performance in the E-commercial search scenario of Taobao (Alibaba Group) and has been integrated into their search engine at billion-node scale.</p>
</td>
    <td>
      
        Graph Based ANN 
      
        DATASETS 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/shenoy2017deduplication/">Deduplication In A Massive Clinical Note Dataset</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deduplication In A Massive Clinical Note Dataset' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deduplication In A Massive Clinical Note Dataset' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Shenoy et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 17th International Conference on Mining Software Repositories</td>
    <td>18</td>
    <td><p>Duplication, whether exact or partial, is a common issue in many datasets. In
clinical notes data, duplication (and near duplication) can arise for many
reasons, such as the pervasive use of templates, copy-pasting, or notes being
generated by automated procedures. A key challenge in removing such near
duplicates is the size of such datasets; our own dataset consists of more than
10 million notes. To detect and correct such duplicates requires algorithms
that both accurate and highly scalable. We describe a solution based on
Minhashing with Locality Sensitive Hashing. In this paper, we present the
theory behind this method and present a database-inspired approach to make the
method scalable. We also present a clustering technique using disjoint sets to
produce dense clusters, which speeds up our algorithm.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/garg2017kernelized/">Kernelized Hashcode Representations For Relation Extraction</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Kernelized Hashcode Representations For Relation Extraction' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Kernelized Hashcode Representations For Relation Extraction' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Garg et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>8</td>
    <td><p>Kernel methods have produced state-of-the-art results for a number of NLP
tasks such as relation extraction, but suffer from poor scalability due to the
high cost of computing kernel similarities between natural language structures.
A recently proposed technique, kernelized locality-sensitive hashing (KLSH),
can significantly reduce the computational cost, but is only applicable to
classifiers operating on kNN graphs. Here we propose to use random subspaces of
KLSH codes for efficiently constructing an explicit representation of NLP
structures suitable for general classification methods. Further, we propose an
approach for optimizing the KLSH model for classification problems by
maximizing an approximation of mutual information between the KLSH codes
(feature vectors) and the class labels. We evaluate the proposed approach on
biomedical relation extraction datasets, and observe significant and robust
improvements in accuracy w.r.t. state-of-the-art classifiers, along with
drastic (orders-of-magnitude) speedup compared to conventional kernel methods.</p>
</td>
    <td>
      
        AAAI 
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/johnson2017billion/">Billion-scale Similarity Search With Gpus</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Billion-scale Similarity Search With Gpus' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Billion-scale Similarity Search With Gpus' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Johnson Jeff, Douze Matthijs, JÃ©gou HervÃ©</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Big Data</td>
    <td>2024</td>
    <td><p>Similarity search finds application in specialized database systems handling
complex data such as images or videos, which are typically represented by
high-dimensional features and require specific indexing structures. This paper
tackles the problem of better utilizing GPUs for this task. While GPUs excel at
data-parallel tasks, prior approaches are bottlenecked by algorithms that
expose less parallelism, such as k-min selection, or make poor use of the
memory hierarchy.
  We propose a design for k-selection that operates at up to 55% of theoretical
peak performance, enabling a nearest neighbor implementation that is 8.5x
faster than prior GPU state of the art. We apply it in different similarity
search scenarios, by proposing optimized design for brute-force, approximate
and compressed-domain search based on product quantization. In all these
setups, we outperform the state of the art by large margins. Our implementation
enables the construction of a high accuracy k-NN graph on 95 million images
from the Yfcc100M dataset in 35 minutes, and of a graph connecting 1 billion
vectors in less than 12 hours on 4 Maxwell Titan X GPUs. We have open-sourced
our approach for the sake of comparison and reproducibility.</p>
</td>
    <td>
      
        DATASETS 
      
        Large Scale Search 
      
        Similarity Search 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/yu2017hyperminhash/">Hyperminhash: Minhash In Loglog Space</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hyperminhash: Minhash In Loglog Space' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hyperminhash: Minhash In Loglog Space' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yu Yun William, Weber Griffin M.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Knowledge and Data Engineering</td>
    <td>16</td>
    <td><p>In this extended abstract, we describe and analyze a lossy compression of
MinHash from buckets of size \(O(log n)\) to buckets of size \(O(loglog n)\) by
encoding using floating-point notation. This new compressed sketch, which we
call HyperMinHash, as we build off a HyperLogLog scaffold, can be used as a
drop-in replacement of MinHash. Unlike comparable Jaccard index fingerprinting
algorithms in sub-logarithmic space (such as b-bit MinHash), HyperMinHash
retains MinHashâ€™s features of streaming updates, unions, and cardinality
estimation. For a multiplicative approximation error \(1+ \epsilon\) on a Jaccard
index \( t \), given a random oracle, HyperMinHash needs \(O\left(\epsilon^{-2}
\left( loglog n + log \frac{1}{ t \epsilon} \right)\right)\) space.
HyperMinHash allows estimating Jaccard indices of 0.01 for set cardinalities on
the order of \(10^{19}\) with relative error of around 10% using 64KiB of
memory; MinHash can only estimate Jaccard indices for cardinalities of
\(10^{10}\) with the same memory consumption.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/zhang2017unsupervised/">Unsupervised Generative Adversarial Cross-modal Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Unsupervised Generative Adversarial Cross-modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Unsupervised Generative Adversarial Cross-modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang Jian, Peng Yuxin, Yuan Mingkuan</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>203</td>
    <td><p>Cross-modal hashing aims to map heterogeneous multimedia data into a common
Hamming space, which can realize fast and flexible retrieval across different
modalities. Unsupervised cross-modal hashing is more flexible and applicable
than supervised methods, since no intensive labeling work is involved. However,
existing unsupervised methods learn hashing functions by preserving inter and
intra correlations, while ignoring the underlying manifold structure across
different modalities, which is extremely helpful to capture meaningful nearest
neighbors of different modalities for cross-modal retrieval. To address the
above problem, in this paper we propose an Unsupervised Generative Adversarial
Cross-modal Hashing approach (UGACH), which makes full use of GANâ€™s ability for
unsupervised representation learning to exploit the underlying manifold
structure of cross-modal data. The main contributions can be summarized as
follows: (1) We propose a generative adversarial network to model cross-modal
hashing in an unsupervised fashion. In the proposed UGACH, given a data of one
modality, the generative model tries to fit the distribution over the manifold
structure, and select informative data of another modality to challenge the
discriminative model. The discriminative model learns to distinguish the
generated data and the true positive data sampled from correlation graph to
achieve better retrieval accuracy. These two models are trained in an
adversarial way to improve each other and promote hashing function learning.
(2) We propose a correlation graph based approach to capture the underlying
manifold structure across different modalities, so that data of different
modalities but within the same manifold can have smaller Hamming distance and
promote retrieval accuracy. Extensive experiments compared with 6
state-of-the-art methods verify the effectiveness of our proposed approach.</p>
</td>
    <td>
      
        AAAI 
      
        Hashing Methods 
      
        Multimodal Retrieval 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2017</td>
    <td>
      <a href="/publications/svenstrup2017hash/">Hash Embeddings For Efficient Word Representations</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hash Embeddings For Efficient Word Representations' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hash Embeddings For Efficient Word Representations' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Svenstrup Dan, Hansen Jonas Meinertz, Winther Ole</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>29</td>
    <td><p>We present hash embeddings, an efficient method for representing words in a
continuous vector form. A hash embedding may be seen as an interpolation
between a standard word embedding and a word embedding created using a random
hash function (the hashing trick). In hash embeddings each token is represented
by \(k\) \(d\)-dimensional embeddings vectors and one \(k\) dimensional weight
vector. The final \(d\) dimensional representation of the token is the product of
the two. Rather than fitting the embedding vectors for each token these are
selected by the hashing trick from a shared pool of \(B\) embedding vectors. Our
experiments show that hash embeddings can easily deal with huge vocabularies
consisting of millions of tokens. When using a hash embedding there is no need
to create a dictionary before training nor to perform any kind of vocabulary
pruning after training. We show that models trained using hash embeddings
exhibit at least the same level of performance as models trained using regular
embeddings across a wide range of tasks. Furthermore, the number of parameters
needed by such an embedding is only a fraction of what is required by a regular
embedding. Since standard embeddings and embeddings constructed using the
hashing trick are actually just special cases of a hash embedding, hash
embeddings can be considered an extension and improvement over the existing
regular embedding types.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
    
      
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/zhang2016ssdh/">SSDH: Semi-supervised Deep Hashing For Large Scale Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=SSDH: Semi-supervised Deep Hashing For Large Scale Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=SSDH: Semi-supervised Deep Hashing For Large Scale Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang Jian, Peng Yuxin</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Circuits and Systems for Video Technology</td>
    <td>150</td>
    <td><p>Hashing methods have been widely used for efficient similarity retrieval on
large scale image database. Traditional hashing methods learn hash functions to
generate binary codes from hand-crafted features, which achieve limited
accuracy since the hand-crafted features cannot optimally represent the image
content and preserve the semantic similarity. Recently, several deep hashing
methods have shown better performance because the deep architectures generate
more discriminative feature representations. However, these deep hashing
methods are mainly designed for supervised scenarios, which only exploit the
semantic similarity information, but ignore the underlying data structures. In
this paper, we propose the semi-supervised deep hashing (SSDH) approach, to
perform more effective hash function learning by simultaneously preserving
semantic similarity and underlying data structures. The main contributions are
as follows: (1) We propose a semi-supervised loss to jointly minimize the
empirical error on labeled data, as well as the embedding error on both labeled
and unlabeled data, which can preserve the semantic similarity and capture the
meaningful neighbors on the underlying data structures for effective hashing.
(2) A semi-supervised deep hashing network is designed to extensively exploit
both labeled and unlabeled data, in which we propose an online graph
construction method to benefit from the evolving deep features during training
to better capture semantic neighbors. To the best of our knowledge, the
proposed deep network is the first deep hashing method that can perform hash
code learning and feature learning simultaneously in a semi-supervised fashion.
Experimental results on 5 widely-used datasets show that our proposed approach
outperforms the state-of-the-art hashing methods.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Neural Hashing 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/pham2016scalability/">Scalability And Total Recall With Fast Coveringlsh</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Scalability And Total Recall With Fast Coveringlsh' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Scalability And Total Recall With Fast Coveringlsh' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Pham Ninh, Pagh Rasmus</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 25th ACM International on Conference on Information and Knowledge Management</td>
    <td>11</td>
    <td><p>Locality-sensitive hashing (LSH) has emerged as the dominant algorithmic
technique for similarity search with strong performance guarantees in
high-dimensional spaces. A drawback of traditional LSH schemes is that they may
have <em>false negatives</em>, i.e., the recall is less than 100%. This limits
the applicability of LSH in settings requiring precise performance guarantees.
Building on the recent theoretical â€œCoveringLSHâ€ construction that eliminates
false negatives, we propose a fast and practical covering LSH scheme for
Hamming space called <em>Fast CoveringLSH (fcLSH)</em>. Inheriting the design
benefits of CoveringLSH our method avoids false negatives and always reports
all near neighbors. Compared to CoveringLSH we achieve an asymptotic
improvement to the hash function computation time from \(\mathcal{O}(dL)\) to
\(\mathcal{O}(d + Llog{L})\), where \(d\) is the dimensionality of data and \(L\) is
the number of hash tables. Our experiments on synthetic and real-world data
sets demonstrate that <em>fcLSH</em> is comparable (and often superior) to
traditional hashing-based approaches for search radius up to 20 in
high-dimensional Hamming space.</p>
</td>
    <td>
      
        CIKM 
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/salvi2016bloom/">Bloom Filters And Compact Hash Codes For Efficient And Distributed Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Bloom Filters And Compact Hash Codes For Efficient And Distributed Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Bloom Filters And Compact Hash Codes For Efficient And Distributed Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Salvi et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2016 IEEE International Symposium on Multimedia (ISM)</td>
    <td>5</td>
    <td><p>This paper presents a novel method for efficient image retrieval, based on a
simple and effective hashing of CNN features and the use of an indexing
structure based on Bloom filters. These filters are used as gatekeepers for the
database of image features, allowing to avoid to perform a query if the query
features are not stored in the database and speeding up the query process,
without affecting retrieval performance. Thanks to the limited memory
requirements the system is suitable for mobile applications and distributed
databases, associating each filter to a distributed portion of the database.
Experimental validation has been performed on three standard image retrieval
datasets, outperforming state-of-the-art hashing methods in terms of precision,
while the proposed indexing method obtains a \(2\times\) speedup.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/esen2016large/">Large-scale Video Search With Efficient Temporal Voting Structure</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Large-scale Video Search With Efficient Temporal Voting Structure' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Large-scale Video Search With Efficient Temporal Voting Structure' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Esen Ersin, Ozkan Savas, Atil Ilkay</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 25th ACM international conference on Multimedia</td>
    <td>9</td>
    <td><p>In this work, we propose a fast content-based video querying system for
large-scale video search. The proposed system is distinguished from similar
works with two major contributions. First contribution is superiority of joint
usage of repeated content representation and efficient hashing mechanisms.
Repeated content representation is utilized with a simple yet robust feature,
which is based on edge energy of frames. Each of the representation is
converted into hash code with Hamming Embedding method for further queries.
Second contribution is novel queue-based voting scheme that leads to modest
memory requirements with gradual memory allocation capability, contrary to
complete brute-force temporal voting schemes. This aspect enables us to make
queries on large video databases conveniently, even on commodity computers with
limited memory capacity. Our results show that the system can respond to video
queries on a large video database with fast query times, high recall rate and
very low memory and disk requirements.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/andoni2016optimal/">Optimal Hashing-based Time-space Trade-offs For Approximate Near Neighbors</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Optimal Hashing-based Time-space Trade-offs For Approximate Near Neighbors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Optimal Hashing-based Time-space Trade-offs For Approximate Near Neighbors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Andoni et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>66</td>
    <td><p>[See the paper for the full abstract.]
  We show tight upper and lower bounds for time-space trade-offs for the
\(c\)-Approximate Near Neighbor Search problem. For the \(d\)-dimensional Euclidean
space and \(n\)-point datasets, we develop a data structure with space \(n^{1 +
\rho_u + o(1)} + O(dn)\) and query time \(n^{\rho_q + o(1)} + d n^{o(1)}\) for
every \(\rho_u, \rho_q \geq 0\) such that: \begin{equation} c^2 \sqrt{\rho_q} +
(c^2 - 1) \sqrt{\rho_u} = \sqrt{2c^2 - 1}. \end{equation}
  This is the first data structure that achieves sublinear query time and
near-linear space for every approximation factor \(c &gt; 1\), improving upon
[Kapralov, PODS 2015]. The data structure is a culmination of a long line of
work on the problem for all space regimes; it builds on Spherical
Locality-Sensitive Filtering [Becker, Ducas, Gama, Laarhoven, SODA 2016] and
data-dependent hashing [Andoni, Indyk, Nguyen, Razenshteyn, SODA 2014] [Andoni,
Razenshteyn, STOC 2015].
  Our matching lower bounds are of two types: conditional and unconditional.
First, we prove tightness of the whole above trade-off in a restricted model of
computation, which captures all known hashing-based approaches. We then show
unconditional cell-probe lower bounds for one and two probes that match the
above trade-off for \(\rho_q = 0\), improving upon the best known lower bounds
from [Panigrahy, Talwar, Wieder, FOCS 2010]. In particular, this is the first
space lower bound (for any static data structure) for two probes which is not
polynomially smaller than the one-probe bound. To show the result for two
probes, we establish and exploit a connection to locally-decodable codes.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/andoni2016lower/">Lower Bounds On Time-space Trade-offs For Approximate Near Neighbors</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Lower Bounds On Time-space Trade-offs For Approximate Near Neighbors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Lower Bounds On Time-space Trade-offs For Approximate Near Neighbors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Andoni et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the Twenty-Eighth Annual ACM-SIAM Symposium on Discrete Algorithms</td>
    <td>30</td>
    <td><p>We show tight lower bounds for the entire trade-off between space and query
time for the Approximate Near Neighbor search problem. Our lower bounds hold in
a restricted model of computation, which captures all hashing-based approaches.
In articular, our lower bound matches the upper bound recently shown in
[Laarhoven 2015] for the random instance on a Euclidean sphere (which we show
in fact extends to the entire space \(\mathbb{R}^d\) using the techniques from
[Andoni, Razenshteyn 2015]).
  We also show tight, unconditional cell-probe lower bounds for one and two
probes, improving upon the best known bounds from [Panigrahy, Talwar, Wieder
2010]. In particular, this is the first space lower bound (for any static data
structure) for two probes which is not polynomially smaller than for one probe.
To show the result for two probes, we establish and exploit a connection to
locally-decodable codes.</p>
</td>
    <td>
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/mor%C3%A8re2016group/">Group Invariant Deep Representations For Image Instance Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Group Invariant Deep Representations For Image Instance Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Group Invariant Deep Representations For Image Instance Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>MorÃ¨re et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>6</td>
    <td><p>Most image instance retrieval pipelines are based on comparison of vectors
known as global image descriptors between a query image and the database
images. Due to their success in large scale image classification,
representations extracted from Convolutional Neural Networks (CNN) are quickly
gaining ground on Fisher Vectors (FVs) as state-of-the-art global descriptors
for image instance retrieval. While CNN-based descriptors are generally
remarked for good retrieval performance at lower bitrates, they nevertheless
present a number of drawbacks including the lack of robustness to common object
transformations such as rotations compared with their interest point based FV
counterparts.
  In this paper, we propose a method for computing invariant global descriptors
from CNNs. Our method implements a recently proposed mathematical theory for
invariance in a sensory cortex modeled as a feedforward neural network. The
resulting global descriptors can be made invariant to multiple arbitrary
transformation groups while retaining good discriminativeness.
  Based on a thorough empirical evaluation using several publicly available
datasets, we show that our method is able to significantly and consistently
improve retrieval results every time a new type of invariance is incorporated.
We also show that our method which has few parameters is not prone to
overfitting: improvements generalize well across datasets with different
properties with regard to invariances. Finally, we show that our descriptors
are able to compare favourably to other state-of-the-art compact descriptors in
similar bitranges, exceeding the highest retrieval results reported in the
literature on some datasets. A dedicated dimensionality reduction step
â€“quantization or hashingâ€“ may be able to further improve the competitiveness
of the descriptors.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Quantization 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/araujo2016large/">Large-scale Query-by-image Video Retrieval Using Bloom Filters</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Large-scale Query-by-image Video Retrieval Using Bloom Filters' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Large-scale Query-by-image Video Retrieval Using Bloom Filters' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Araujo et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>14</td>
    <td><p>We consider the problem of using image queries to retrieve videos from a
database. Our focus is on large-scale applications, where it is infeasible to
index each database video frame independently. Our main contribution is a
framework based on Bloom filters, which can be used to index long video
segments, enabling efficient image-to-video comparisons. Using this framework,
we investigate several retrieval architectures, by considering different types
of aggregation and different functions to encode visual information â€“ these
play a crucial role in achieving high performance. Extensive experiments show
that the proposed technique improves mean average precision by 24% on a public
dataset, while being 4X faster, compared to the previous state-of-the-art.</p>
</td>
    <td>
      
        DATASETS 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/wang2016contextual/">Contextual Visual Similarity</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Contextual Visual Similarity' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Contextual Visual Similarity' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang Xiaofang, Kitani Kris M., Hebert Martial</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>7</td>
    <td><p>Measuring visual similarity is critical for image understanding. But what
makes two images similar? Most existing work on visual similarity assumes that
images are similar because they contain the same object instance or category.
However, the reason why images are similar is much more complex. For example,
from the perspective of category, a black dog image is similar to a white dog
image. However, in terms of color, a black dog image is more similar to a black
horse image than the white dog image. This example serves to illustrate that
visual similarity is ambiguous but can be made precise when given an explicit
contextual perspective. Based on this observation, we propose the concept of
contextual visual similarity. To be concrete, we examine the concept of
contextual visual similarity in the application domain of image search. Instead
of providing only a single image for image similarity search (\eg, Google image
search), we require three images. Given a query image, a second positive image
and a third negative image, dissimilar to the first two images, we define a
contextualized similarity search criteria. In particular, we learn feature
weights over all the feature dimensions of each image such that the distance
between the query image and the positive image is small and their distances to
the negative image are large after reweighting their features. The learned
feature weights encode the contextualized visual similarity specified by the
user and can be used for attribute specific image search. We also show the
usefulness of our contextualized similarity weighting scheme for different
tasks, such as answering visual analogy questions and unsupervised attribute
discovery.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Similarity Search 
      
        Graph Based ANN 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/oymak2016near/">Near-optimal Sample Complexity Bounds For Circulant Binary Embedding</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Near-optimal Sample Complexity Bounds For Circulant Binary Embedding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Near-optimal Sample Complexity Bounds For Circulant Binary Embedding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Oymak Samet</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</td>
    <td>13</td>
    <td><p>Binary embedding is the problem of mapping points from a high-dimensional
space to a Hamming cube in lower dimension while preserving pairwise distances.
An efficient way to accomplish this is to make use of fast embedding techniques
involving Fourier transform e.g.~circulant matrices. While binary embedding has
been studied extensively, theoretical results on fast binary embedding are
rather limited. In this work, we build upon the recent literature to obtain
significantly better dependencies on the problem parameters. A set of \(N\)
points in \(\mathbb{R}^n\) can be properly embedded into the Hamming cube \(\{\pm
1\}^k\) with \(\delta\) distortion, by using \(k\sim\delta^{-3}log N\) samples
which is optimal in the number of points \(N\) and compares well with the optimal
distortion dependency \(\delta^{-2}\). Our optimal embedding result applies in
the regime \(log N\lesssim n^{1/3}\). Furthermore, if the looser condition \(log
N\lesssim \sqrt{n}\) holds, we show that all but an arbitrarily small fraction
of the points can be optimally embedded. We believe our techniques can be
useful to obtain improved guarantees for other nonlinear embedding problems.</p>
</td>
    <td>
      
        ICASSP 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/goswami2016distance/">Distance Sensitive Bloom Filters Without False Negatives</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Distance Sensitive Bloom Filters Without False Negatives' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Distance Sensitive Bloom Filters Without False Negatives' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Goswami et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the Twenty-Eighth Annual ACM-SIAM Symposium on Discrete Algorithms</td>
    <td>7</td>
    <td><p>A Bloom filter is a widely used data-structure for representing a set \(S\) and
answering queries of the form â€œIs \(x\) in \(S\)?â€. By allowing some false positive
answers (saying â€œyesâ€ when the answer is in fact `noâ€™) Bloom filters use space
significantly below what is required for storing \(S\). In the distance sensitive
setting we work with a set \(S\) of (Hamming) vectors and seek a data structure
that offers a similar trade-off, but answers queries of the form â€œIs \(x\) close
to an element of \(S\)?â€ (in Hamming distance). Previous work on distance
sensitive Bloom filters have accepted false positive and false negative
answers. Absence of false negatives is of critical importance in many
applications of Bloom filters, so it is natural to ask if this can be also
achieved in the distance sensitive setting. Our main contributions are upper
and lower bounds (that are tight in several cases) for space usage in the
distance sensitive setting where false negatives are not allowed.</p>
</td>
    <td>
      
        Graph Based ANN 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/li20162/">2-bit Random Projections, Nonlinear Estimators, And Approximate Near Neighbor Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=2-bit Random Projections, Nonlinear Estimators, And Approximate Near Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=2-bit Random Projections, Nonlinear Estimators, And Approximate Near Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li Ping, Mitzenmacher Michael, Shrivastava Anshumali</td> <!-- ðŸ”§ You were missing this -->
    <td>Neurocomputing</td>
    <td>5</td>
    <td><p>The method of random projections has become a standard tool for machine
learning, data mining, and search with massive data at Web scale. The effective
use of random projections requires efficient coding schemes for quantizing
(real-valued) projected data into integers. In this paper, we focus on a simple
2-bit coding scheme. In particular, we develop accurate nonlinear estimators of
data similarity based on the 2-bit strategy. This work will have important
practical applications. For example, in the task of near neighbor search, a
crucial step (often called re-ranking) is to compute or estimate data
similarities once a set of candidate data points have been identified by hash
table techniques. This re-ranking step can take advantage of the proposed
coding scheme and estimator.
  As a related task, in this paper, we also study a simple uniform quantization
scheme for the purpose of building hash tables with projected data. Our
analysis shows that typically only a small number of bits are needed. For
example, when the target similarity level is high, 2 or 3 bits might be
sufficient. When the target similarity level is not so high, it is preferable
to use only 1 or 2 bits. Therefore, a 2-bit scheme appears to be overall a good
choice for the task of sublinear time approximate near neighbor search via hash
tables.
  Combining these results, we conclude that 2-bit random projections should be
recommended for approximate near neighbor search and similarity estimation.
Extensive experimental results are provided.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Quantization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/ercoli2016compact/">Compact Hash Codes For Efficient Visual Descriptors Retrieval In Large Scale Databases</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Compact Hash Codes For Efficient Visual Descriptors Retrieval In Large Scale Databases' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Compact Hash Codes For Efficient Visual Descriptors Retrieval In Large Scale Databases' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ercoli Simone, Bertini Marco, del Bimbo Alberto</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Multimedia</td>
    <td>42</td>
    <td><p>In this paper we present an efficient method for visual descriptors retrieval
based on compact hash codes computed using a multiple k-means assignment. The
method has been applied to the problem of approximate nearest neighbor (ANN)
search of local and global visual content descriptors, and it has been tested
on different datasets: three large scale public datasets of up to one billion
descriptors (BIGANN) and, supported by recent progress in convolutional neural
networks (CNNs), also on the CIFAR-10 and MNIST datasets. Experimental results
show that, despite its simplicity, the proposed method obtains a very high
performance that makes it superior to more complex state-of-the-art methods.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/perez2016mahalanobis/">Mahalanobis Distance Metric Learning Algorithm For Instance-based Data Stream Classification</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Mahalanobis Distance Metric Learning Algorithm For Instance-based Data Stream Classification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Mahalanobis Distance Metric Learning Algorithm For Instance-based Data Stream Classification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Perez Jorge Luis Rivero, Ribeiro Bernardete, Perez Carlos Morell</td> <!-- ðŸ”§ You were missing this -->
    <td>2016 International Joint Conference on Neural Networks (IJCNN)</td>
    <td>5</td>
    <td><p>With the massive data challenges nowadays and the rapid growing of
technology, stream mining has recently received considerable attention. To
address the large number of scenarios in which this phenomenon manifests itself
suitable tools are required in various research fields. Instance-based data
stream algorithms generally employ the Euclidean distance for the
classification task underlying this problem. A novel way to look into this
issue is to take advantage of a more flexible metric due to the increased
requirements imposed by the data stream scenario. In this paper we present a
new algorithm that learns a Mahalanobis metric using similarity and
dissimilarity constraints in an online manner. This approach hybridizes a
Mahalanobis distance metric learning algorithm and a k-NN data stream
classification algorithm with concept drift detection. First, some basic
aspects of Mahalanobis distance metric learning are described taking into
account key properties as well as online distance metric learning algorithms.
Second, we implement specific evaluation methodologies and comparative metrics
such as Q statistic for data stream classification algorithms. Finally, our
algorithm is evaluated on different datasets by comparing its results with one
of the best instance-based data stream classification algorithm of the state of
the art. The results demonstrate that our proposal is better</p>
</td>
    <td>
      
        DATASETS 
      
        Tools & Libraries 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/amato2016reducing/">On Reducing The Number Of Visual Words In The Bag-of-features Representation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=On Reducing The Number Of Visual Words In The Bag-of-features Representation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=On Reducing The Number Of Visual Words In The Bag-of-features Representation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Amato Giuseppe, Falchi Fabrizio, Gennaro Claudio</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the International Conference on Computer Vision Theory and Applications</td>
    <td>9</td>
    <td><p>A new class of applications based on visual search engines are emerging,
especially on smart-phones that have evolved into powerful tools for processing
images and videos. The state-of-the-art algorithms for large visual content
recognition and content based similarity search today use the â€œBag of Featuresâ€
(BoF) or â€œBag of Wordsâ€ (BoW) approach. The idea, borrowed from text retrieval,
enables the use of inverted files. A very well known issue with this approach
is that the query images, as well as the stored data, are described with
thousands of words. This poses obvious efficiency problems when using inverted
files to perform efficient image matching. In this paper, we propose and
compare various techniques to reduce the number of words describing an image to
improve efficiency and we study the effects of this reduction on effectiveness
in landmark recognition and retrieval scenarios. We show that very relevant
improvement in performance are achievable still preserving the advantages of
the BoF base approach.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Efficiency And Optimization 
      
        Text Retrieval 
      
        ICCV 
      
        Similarity Search 
      
        Vector Indexing 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/wang2016comprehensive/">A Comprehensive Survey On Cross-modal Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Comprehensive Survey On Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Comprehensive Survey On Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>230</td>
    <td><p>In recent years, cross-modal retrieval has drawn much attention due to the
rapid growth of multimodal data. It takes one type of data as the query to
retrieve relevant data of another type. For example, a user can use a text to
retrieve relevant pictures or videos. Since the query and its retrieved results
can be of different modalities, how to measure the content similarity between
different modalities of data remains a challenge. Various methods have been
proposed to deal with such a problem. In this paper, we first review a number
of representative methods for cross-modal retrieval and classify them into two
main groups: 1) real-valued representation learning, and 2) binary
representation learning. Real-valued representation learning methods aim to
learn real-valued common representations for different modalities of data. To
speed up the cross-modal retrieval, a number of binary representation learning
methods are proposed to map different modalities of data into a common Hamming
space. Then, we introduce several multimodal datasets in the community, and
show the experimental results on two commonly used multimodal datasets. The
comparison reveals the characteristic of different kinds of cross-modal
retrieval methods, which is expected to benefit both practical applications and
future research. Finally, we discuss open problems and future research
directions.</p>
</td>
    <td>
      
        Survey Paper 
      
        DATASETS 
      
        Hashing Methods 
      
        Multimodal Retrieval 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/jacques2016time/">Time For Dithering: Fast And Quantized Random Embeddings Via The Restricted Isometry Property</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Time For Dithering: Fast And Quantized Random Embeddings Via The Restricted Isometry Property' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Time For Dithering: Fast And Quantized Random Embeddings Via The Restricted Isometry Property' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jacques Laurent, Cambareri Valerio</td> <!-- ðŸ”§ You were missing this -->
    <td>Information and Inference: A Journal of the IMA</td>
    <td>31</td>
    <td><p>Recently, many works have focused on the characterization of non-linear
dimensionality reduction methods obtained by quantizing linear embeddings,
e.g., to reach fast processing time, efficient data compression procedures,
novel geometry-preserving embeddings or to estimate the information/bits stored
in this reduced data representation. In this work, we prove that many linear
maps known to respect the restricted isometry property (RIP) can induce a
quantized random embedding with controllable multiplicative and additive
distortions with respect to the pairwise distances of the data points beings
considered. In other words, linear matrices having fast matrix-vector
multiplication algorithms (e.g., based on partial Fourier ensembles or on the
adjacency matrix of unbalanced expanders) can be readily used in the definition
of fast quantized embeddings with small distortions. This implication is made
possible by applying right after the linear map an additive and random â€œditherâ€
that stabilizes the impact of the uniform scalar quantization operator applied
afterwards. For different categories of RIP matrices, i.e., for different
linear embeddings of a metric space \((\mathcal K \subset \mathbb R^n, \ell_q)\)
in \((\mathbb R^m, \ell_p)\) with \(p,q \geq 1\), we derive upper bounds on the
additive distortion induced by quantization, showing that it decays either when
the embedding dimension \(m\) increases or when the distance of a pair of
embedded vectors in \(\mathcal K\) decreases. Finally, we develop a novel
â€œbi-ditheredâ€ quantization scheme, which allows for a reduced distortion that
decreases when the embedding dimension grows and independently of the
considered pair of vectors.</p>
</td>
    <td>
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/pacuk2016locality/">Locality-sensitive Hashing Without False Negatives For L_p</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Locality-sensitive Hashing Without False Negatives For L_p' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Locality-sensitive Hashing Without False Negatives For L_p' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Pacuk et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>7</td>
    <td><p>In this paper, we show a construction of locality-sensitive hash functions
without false negatives, i.e., which ensure collision for every pair of points
within a given radius \(R\) in \(d\) dimensional space equipped with \(l_p\) norm
when \(p \in [1,\infty]\). Furthermore, we show how to use these hash functions
to solve the \(c\)-approximate nearest neighbor search problem without false
negatives. Namely, if there is a point at distance \(R\), we will certainly
report it and points at distance greater than \(cR\) will not be reported for
\(c=Î©(\sqrt{d},d^{1-\frac{1}{p}})\). The constructed algorithms work: - with
preprocessing time \(\mathcal{O}(n log(n))\) and sublinear expected query time,</p>
<ul>
  <li>with preprocessing time \(\mathcal{O}(\mathrm{poly}(n))\) and expected query
time \(\mathcal{O}(log(n))\). Our paper reports progress on answering the open
problem presented by Pagh [8] who considered the nearest neighbor search
without false negatives for the Hamming distance.</li>
</ul>
</td>
    <td>
      
        Hashing Methods 
      
        Graph Based ANN 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/tizhoosh2016minmax/">Minmax Radon Barcodes For Medical Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Minmax Radon Barcodes For Medical Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Minmax Radon Barcodes For Medical Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Tizhoosh et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>38</td>
    <td><p>Content-based medical image retrieval can support diagnostic decisions by
clinical experts. Examining similar images may provide clues to the expert to
remove uncertainties in his/her final diagnosis. Beyond conventional feature
descriptors, binary features in different ways have been recently proposed to
encode the image content. A recent proposal is â€œRadon barcodesâ€ that employ
binarized Radon projections to tag/annotate medical images with content-based
binary vectors, called barcodes. In this paper, MinMax Radon barcodes are
introduced which are superior to â€œlocal thresholdingâ€ scheme suggested in the
literature. Using IRMA dataset with 14,410 x-ray images from 193 different
classes, the advantage of using MinMax Radon barcodes over <em>thresholded</em>
Radon barcodes are demonstrated. The retrieval error for direct search drops by
more than 15%. As well, SURF, as a well-established non-binary approach, and
BRISK, as a recent binary method are examined to compare their results with
MinMax Radon barcodes when retrieving images from IRMA dataset. The results
demonstrate that MinMax Radon barcodes are faster and more accurate when
applied on IRMA images.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/mor%C3%A8re2016nested/">Nested Invariance Pooling And RBM Hashing For Image Instance Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Nested Invariance Pooling And RBM Hashing For Image Instance Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Nested Invariance Pooling And RBM Hashing For Image Instance Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>MorÃ¨re et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 2017 ACM on International Conference on Multimedia Retrieval</td>
    <td>17</td>
    <td><p>The goal of this work is the computation of very compact binary hashes for
image instance retrieval. Our approach has two novel contributions. The first
one is Nested Invariance Pooling (NIP), a method inspired from i-theory, a
mathematical theory for computing group invariant transformations with
feed-forward neural networks. NIP is able to produce compact and
well-performing descriptors with visual representations extracted from
convolutional neural networks. We specifically incorporate scale, translation
and rotation invariances but the scheme can be extended to any arbitrary sets
of transformations. We also show that using moments of increasing order
throughout nesting is important. The NIP descriptors are then hashed to the
target code size (32-256 bits) with a Restricted Boltzmann Machine with a novel
batch-level regularization scheme specifically designed for the purpose of
hashing (RBMH). A thorough empirical evaluation with state-of-the-art shows
that the results obtained both with the NIP descriptors and the NIP+RBMH hashes
are consistently outstanding across a wide range of datasets.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        Hashing Methods 
      
        Multimodal Retrieval 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/marchet2016resource/">A Resource-frugal Probabilistic Dictionary And Applications In (meta)genomics</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Resource-frugal Probabilistic Dictionary And Applications In (meta)genomics' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Resource-frugal Probabilistic Dictionary And Applications In (meta)genomics' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Marchet et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>8</td>
    <td><p>Genomic and metagenomic fields, generating huge sets of short genomic
sequences, brought their own share of high performance problems. To extract
relevant pieces of information from the huge data sets generated by current
sequencing techniques, one must rely on extremely scalable methods and
solutions. Indexing billions of objects is a task considered too expensive
while being a fundamental need in this field. In this paper we propose a
straightforward indexing structure that scales to billions of element and we
propose two direct applications in genomics and metagenomics. We show that our
proposal solves problem instances for which no other known solution scales-up.
We believe that many tools and applications could benefit from either the
fundamental data structure we provide or from the applications developed from
this structure.</p>
</td>
    <td>
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/sharma2016stacked/">Stacked Autoencoders For Medical Image Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Stacked Autoencoders For Medical Image Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Stacked Autoencoders For Medical Image Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Sharma et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>32</td>
    <td><p>Medical images can be a valuable resource for reliable information to support
medical diagnosis. However, the large volume of medical images makes it
challenging to retrieve relevant information given a particular scenario. To
solve this challenge, content-based image retrieval (CBIR) attempts to
characterize images (or image regions) with invariant content information in
order to facilitate image search. This work presents a feature extraction
technique for medical images using stacked autoencoders, which encode images to
binary vectors. The technique is applied to the IRMA dataset, a collection of
14,410 x-ray images in order to demonstrate the ability of autoencoders to
retrieve similar x-rays given test queries. Using IRMA dataset as a benchmark,
it was found that stacked autoencoders gave excellent results with a retrieval
error of 376 for 1,733 test images with a compression of 74.61%.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/morris2016faster/">Faster Kernels For Graphs With Continuous Attributes Via Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Faster Kernels For Graphs With Continuous Attributes Via Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Faster Kernels For Graphs With Continuous Attributes Via Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Morris et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2016 IEEE 16th International Conference on Data Mining (ICDM)</td>
    <td>87</td>
    <td><p>While state-of-the-art kernels for graphs with discrete labels scale well to
graphs with thousands of nodes, the few existing kernels for graphs with
continuous attributes, unfortunately, do not scale well. To overcome this
limitation, we present hash graph kernels, a general framework to derive
kernels for graphs with continuous attributes from discrete ones. The idea is
to iteratively turn continuous attributes into discrete labels using randomized
hash functions. We illustrate hash graph kernels for the Weisfeiler-Lehman
subtree kernel and for the shortest-path kernel. The resulting novel graph
kernels are shown to be, both, able to handle graphs with continuous attributes
and scalable to large graphs and data sets. This is supported by our
theoretical analysis and demonstrated by an extensive experimental evaluation.</p>
</td>
    <td>
      
        Tools & Libraries 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/huang2016local/">Local Similarity-aware Deep Feature Embedding</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Local Similarity-aware Deep Feature Embedding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Local Similarity-aware Deep Feature Embedding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Huang Chen, Loy Chen Change, Tang Xiaoou</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>124</td>
    <td><p>Existing deep embedding methods in vision tasks are capable of learning a
compact Euclidean space from images, where Euclidean distances correspond to a
similarity metric. To make learning more effective and efficient, hard sample
mining is usually employed, with samples identified through computing the
Euclidean feature distance. However, the global Euclidean distance cannot
faithfully characterize the true feature similarity in a complex visual feature
space, where the intraclass distance in a high-density region may be larger
than the interclass distance in low-density regions. In this paper, we
introduce a Position-Dependent Deep Metric (PDDM) unit, which is capable of
learning a similarity metric adaptive to local feature structure. The metric
can be used to select genuinely hard samples in a local neighborhood to guide
the deep embedding learning in an online and robust manner. The new layer is
appealing in that it is pluggable to any convolutional networks and is trained
end-to-end. Our local similarity-aware feature embedding not only demonstrates
faster convergence and boosted performance on two complex image retrieval
datasets, its large margin nature also leads to superior generalization results
under the large and open set scenarios of transfer learning and zero-shot
learning on ImageNet 2010 and ImageNet-10K datasets.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Distance Metric Learning 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/im2016learning/">Learning A Metric For Class-conditional KNN</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning A Metric For Class-conditional KNN' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning A Metric For Class-conditional KNN' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Im Daniel Jiwoong, Taylor Graham W.</td> <!-- ðŸ”§ You were missing this -->
    <td>2016 International Joint Conference on Neural Networks (IJCNN)</td>
    <td>5</td>
    <td><p>Naive Bayes Nearest Neighbour (NBNN) is a simple and effective framework
which addresses many of the pitfalls of K-Nearest Neighbour (KNN)
classification. It has yielded competitive results on several computer vision
benchmarks. Its central tenet is that during NN search, a query is not compared
to every example in a database, ignoring class information. Instead, NN
searches are performed within each class, generating a score per class. A key
problem with NN techniques, including NBNN, is that they fail when the data
representation does not capture perceptual (e.g.~class-based) similarity. NBNN
circumvents this by using independent engineered descriptors (e.g.~SIFT). To
extend its applicability outside of image-based domains, we propose to learn a
metric which captures perceptual similarity. Similar to how Neighbourhood
Components Analysis optimizes a differentiable form of KNN classification, we
propose â€œClass Conditionalâ€ metric learning (CCML), which optimizes a soft form
of the NBNN selection rule. Typical metric learning algorithms learn either a
global or local metric. However, our proposed method can be adjusted to a
particular level of locality by tuning a single parameter. An empirical
evaluation on classification and retrieval tasks demonstrates that our proposed
method clearly outperforms existing learned distance metrics across a variety
of image and non-image datasets.</p>
</td>
    <td>
      
        DATASETS 
      
        Tools & Libraries 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/fu2016improved/">An Improved System For Sentence-level Novelty Detection In Textual Streams</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=An Improved System For Sentence-level Novelty Detection In Textual Streams' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=An Improved System For Sentence-level Novelty Detection In Textual Streams' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Fu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2015 International Conference on Smart and Sustainable City and Big Data (ICSSC)</td>
    <td>5</td>
    <td><p>Novelty detection in news events has long been a difficult problem. A number
of models performed well on specific data streams but certain issues are far
from being solved, particularly in large data streams from the WWW where
unpredictability of new terms requires adaptation in the vector space model. We
present a novel event detection system based on the Incremental Term
Frequency-Inverse Document Frequency (TF-IDF) weighting incorporated with
Locality Sensitive Hashing (LSH). Our system could efficiently and effectively
adapt to the changes within the data streams of any new terms with continual
updates to the vector space model. Regarding miss probability, our proposed
novelty detection framework outperforms a recognised baseline system by
approximately 16% when evaluating a benchmark dataset from Google News.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/gripon2016associative/">Associative Memories To Accelerate Approximate Nearest Neighbor Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Associative Memories To Accelerate Approximate Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Associative Memories To Accelerate Approximate Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Gripon Vincent, LÃ¶we Matthias, Vermet Franck</td> <!-- ðŸ”§ You were missing this -->
    <td>Applied Sciences</td>
    <td>9</td>
    <td><p>Nearest neighbor search is a very active field in machine learning for it
appears in many application cases, including classification and object
retrieval. In its canonical version, the complexity of the search is linear
with both the dimension and the cardinal of the collection of vectors the
search is performed in. Recently many works have focused on reducing the
dimension of vectors using quantization techniques or hashing, while providing
an approximate result. In this paper we focus instead on tackling the cardinal
of the collection of vectors. Namely, we introduce a technique that partitions
the collection of vectors and stores each part in its own associative memory.
When a query vector is given to the system, associative memories are polled to
identify which one contain the closest match. Then an exhaustive search is
conducted only on the part of vectors stored in the selected associative
memory. We study the effectiveness of the system when messages to store are
generated from i.i.d. uniform \(\pm\)1 random variables or 0-1 sparse i.i.d.
random variables. We also conduct experiment on both synthetic data and real
data and show it is possible to achieve interesting trade-offs between
complexity and accuracy.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Quantization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/fu2016auto/">Auto-jacobin: Auto-encoder Jacobian Binary Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Auto-jacobin: Auto-encoder Jacobian Binary Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Auto-jacobin: Auto-encoder Jacobian Binary Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Fu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Image Processing</td>
    <td>220</td>
    <td><p>Binary codes can be used to speed up nearest neighbor search tasks in large
scale data sets as they are efficient for both storage and retrieval. In this
paper, we propose a robust auto-encoder model that preserves the geometric
relationships of high-dimensional data sets in Hamming space. This is done by
considering a noise-removing function in a region surrounding the manifold
where the training data points lie. This function is defined with the property
that it projects the data points near the manifold into the manifold wisely,
and we approximate this function by its first order approximation. Experimental
results show that the proposed method achieves better than state-of-the-art
results on three large scale high dimensional data sets.</p>
</td>
    <td>
      
        Compact Codes 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/lai2016instance/">Instance-aware Hashing For Multi-label Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Instance-aware Hashing For Multi-label Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Instance-aware Hashing For Multi-label Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lai et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Image Processing</td>
    <td>78</td>
    <td><p>Similarity-preserving hashing is a commonly used method for nearest neighbour
search in large-scale image retrieval. For image retrieval, deep-networks-based
hashing methods are appealing since they can simultaneously learn effective
image representations and compact hash codes. This paper focuses on
deep-networks-based hashing for multi-label images, each of which may contain
objects of multiple categories. In most existing hashing methods, each image is
represented by one piece of hash code, which is referred to as semantic
hashing. This setting may be suboptimal for multi-label image retrieval. To
solve this problem, we propose a deep architecture that learns
\textbf{instance-aware} image representations for multi-label image data, which
are organized in multiple groups, with each group containing the features for
one category. The instance-aware representations not only bring advantages to
semantic hashing, but also can be used in category-aware hashing, in which an
image is represented by multiple pieces of hash codes and each piece of code
corresponds to a category. Extensive evaluations conducted on several benchmark
datasets demonstrate that, for both semantic hashing and category-aware
hashing, the proposed method shows substantial improvement over the
state-of-the-art supervised and unsupervised hashing methods.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Text Retrieval 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/liu2016ordinal/">Ordinal Constrained Binary Code Learning For Nearest Neighbor Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Ordinal Constrained Binary Code Learning For Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Ordinal Constrained Binary Code Learning For Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>23</td>
    <td><p>Recent years have witnessed extensive attention in binary code learning,
a.k.a. hashing, for nearest neighbor search problems. It has been seen that
high-dimensional data points can be quantized into binary codes to give an
efficient similarity approximation via Hamming distance. Among existing
schemes, ranking-based hashing is recent promising that targets at preserving
ordinal relations of ranking in the Hamming space to minimize retrieval loss.
However, the size of the ranking tuples, which shows the ordinal relations, is
quadratic or cubic to the size of training samples. By given a large-scale
training data set, it is very expensive to embed such ranking tuples in binary
code learning. Besides, it remains a dificulty to build ranking tuples
efficiently for most ranking-preserving hashing, which are deployed over an
ordinal graph-based setting. To handle these problems, we propose a novel
ranking-preserving hashing method, dubbed Ordinal Constraint Hashing (OCH),
which efficiently learns the optimal hashing functions with a graph-based
approximation to embed the ordinal relations. The core idea is to reduce the
size of ordinal graph with ordinal constraint projection, which preserves the
ordinal relations through a small data set (such as clusters or random
samples). In particular, to learn such hash functions effectively, we further
relax the discrete constraints and design a specific stochastic gradient decent
algorithm for optimization. Experimental results on three large-scale visual
search benchmark datasets, i.e. LabelMe, Tiny100K and GIST1M, show that the
proposed OCH method can achieve superior performance over the state-of-the-arts
approaches.</p>
</td>
    <td>
      
        AAAI 
      
        DATASETS 
      
        Hashing Methods 
      
        Graph Based ANN 
      
        Compact Codes 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/mu2016deep/">Deep Hashing: A Joint Approach For Image Signature Learning</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Hashing: A Joint Approach For Image Signature Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Hashing: A Joint Approach For Image Signature Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Mu Yadong, Liu Zhu</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>9</td>
    <td><p>Similarity-based image hashing represents crucial technique for visual data
storage reduction and expedited image search. Conventional hashing schemes
typically feed hand-crafted features into hash functions, which separates the
procedures of feature extraction and hash function learning. In this paper, we
propose a novel algorithm that concurrently performs feature engineering and
non-linear supervised hashing function learning. Our technical contributions in
this paper are two-folds: 1) deep network optimization is often achieved by
gradient propagation, which critically requires a smooth objective function.
The discrete nature of hash codes makes them not amenable for gradient-based
optimization. To address this issue, we propose an exponentiated hashing loss
function and its bilinear smooth approximation. Effective gradient calculation
and propagation are thereby enabled; 2) pre-training is an important trick in
supervised deep learning. The impact of pre-training on the hash code quality
has never been discussed in current deep hashing literature. We propose a
pre-training scheme inspired by recent advance in deep network based image
classification, and experimentally demonstrate its effectiveness. Comprehensive
quantitative evaluations are conducted on several widely-used image benchmarks.
On all benchmarks, our proposed deep hashing algorithm outperforms all
state-of-the-art competitors by significant margins. In particular, our
algorithm achieves a near-perfect 0.99 in terms of Hamming ranking accuracy
with only 12 bits on MNIST, and a new record of 0.74 on the CIFAR10 dataset. In
comparison, the best accuracies obtained on CIFAR10 by existing hashing
algorithms without or with deep networks are known to be 0.36 and 0.58
respectively.</p>
</td>
    <td>
      
        Image Retrieval 
      
        AAAI 
      
        DATASETS 
      
        Hashing Methods 
      
        Neural Hashing 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/eghbali2016fast/">Fast Cosine Similarity Search In Binary Space With Angular Multi-index Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fast Cosine Similarity Search In Binary Space With Angular Multi-index Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fast Cosine Similarity Search In Binary Space With Angular Multi-index Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Eghbali Sepehr, Tahvildari Ladan</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Knowledge and Data Engineering</td>
    <td>15</td>
    <td><p>Given a large dataset of binary codes and a binary query point, we address
how to efficiently find \(K\) codes in the dataset that yield the largest cosine
similarities to the query. The straightforward answer to this problem is to
compare the query with all items in the dataset, but this is practical only for
small datasets. One potential solution to enhance the search time and achieve
sublinear cost is to use a hash table populated with binary codes of the
dataset and then look up the nearby buckets to the query to retrieve the
nearest neighbors. However, if codes are compared in terms of cosine similarity
rather than the Hamming distance, then the main issue is that the order of
buckets to probe is not evident. To examine this issue, we first elaborate on
the connection between the Hamming distance and the cosine similarity. Doing
this allows us to systematically find the probing sequence in the hash table.
However, solving the nearest neighbor search with a single table is only
practical for short binary codes. To address this issue, we propose the angular
multi-index hashing search algorithm which relies on building multiple hash
tables on binary code substrings. The proposed search algorithm solves the
exact angular \(K\) nearest neighbor problem in a time that is often orders of
magnitude faster than the linear scan baseline and even approximation methods.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Graph Based ANN 
      
        Distance Metric Learning 
      
        Compact Codes 
      
        Similarity Search 
      
        Vector Indexing 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/lin2016structured/">Structured Learning Of Binary Codes With Column Generation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Structured Learning Of Binary Codes With Column Generation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Structured Learning Of Binary Codes With Column Generation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Lin et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>International Journal of Computer Vision</td>
    <td>11</td>
    <td><p>Hashing methods aim to learn a set of hash functions which map the original
features to compact binary codes with similarity preserving in the Hamming
space. Hashing has proven a valuable tool for large-scale information
retrieval. We propose a column generation based binary code learning framework
for data-dependent hash function learning. Given a set of triplets that encode
the pairwise similarity comparison information, our column generation based
method learns hash functions that preserve the relative comparison relations
within the large-margin learning framework. Our method iteratively learns the
best hash functions during the column generation procedure. Existing hashing
methods optimize over simple objectives such as the reconstruction error or
graph Laplacian related loss functions, instead of the performance evaluation
criteria of interestâ€”multivariate performance measures such as the AUC and
NDCG. Our column generation based method can be further generalized from the
triplet loss to a general structured learning based framework that allows one
to directly optimize multivariate performance measures. For optimizing general
ranking measures, the resulting optimization problem can involve exponentially
or infinitely many variables and constraints, which is more challenging than
standard structured output learning. We use a combination of column generation
and cutting-plane techniques to solve the optimization problem. To speed-up the
training we further explore stage-wise training and propose to use a simplified
NDCG loss for efficient inference. We demonstrate the generality of our method
by applying it to ranking prediction and image retrieval, and show that it
outperforms a few state-of-the-art hashing methods.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        Compact Codes 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/grzegorczyk2016binary/">Binary Paragraph Vectors</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Binary Paragraph Vectors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Binary Paragraph Vectors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Grzegorczyk Karol, Kurdziel Marcin</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 2nd Workshop on Representation Learning for NLP</td>
    <td>5</td>
    <td><p>Recently Le &amp; Mikolov described two log-linear models, called Paragraph
Vector, that can be used to learn state-of-the-art distributed representations
of documents. Inspired by this work, we present Binary Paragraph Vector models:
simple neural networks that learn short binary codes for fast information
retrieval. We show that binary paragraph vectors outperform autoencoder-based
binary codes, despite using fewer bits. We also evaluate their precision in
transfer learning settings, where binary codes are inferred for documents
unrelated to the training corpus. Results from these experiments indicate that
binary paragraph vectors can capture semantics relevant for various
domain-specific documents. Finally, we present a model that simultaneously
learns short binary codes and longer, real-valued representations. This model
can be used to rapidly retrieve a short list of highly relevant documents from
a large document collection.</p>
</td>
    <td>
      
        Compact Codes 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/fu2016efanna/">EFANNA : An Extremely Fast Approximate Nearest Neighbor Search Algorithm Based On Knn Graph</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=EFANNA : An Extremely Fast Approximate Nearest Neighbor Search Algorithm Based On Knn Graph' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=EFANNA : An Extremely Fast Approximate Nearest Neighbor Search Algorithm Based On Knn Graph' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Fu Cong, Cai Deng</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>65</td>
    <td><p>Approximate nearest neighbor (ANN) search is a fundamental problem in many
areas of data mining, machine learning and computer vision. The performance of
traditional hierarchical structure (tree) based methods decreases as the
dimensionality of data grows, while hashing based methods usually lack
efficiency in practice. Recently, the graph based methods have drawn
considerable attention. The main idea is that <em>a neighbor of a neighbor is
also likely to be a neighbor</em>, which we refer as <em>NN-expansion</em>. These
methods construct a \(k\)-nearest neighbor (\(k\)NN) graph offline. And at online
search stage, these methods find candidate neighbors of a query point in some
way (\eg, random selection), and then check the neighbors of these candidate
neighbors for closer ones iteratively. Despite some promising results, there
are mainly two problems with these approaches: 1) These approaches tend to
converge to local optima. 2) Constructing a \(k\)NN graph is time consuming. We
find that these two problems can be nicely solved when we provide a good
initialization for NN-expansion. In this paper, we propose EFANNA, an extremely
fast approximate nearest neighbor search algorithm based on \(k\)NN Graph. Efanna
nicely combines the advantages of hierarchical structure based methods and
nearest-neighbor-graph based methods. Extensive experiments have shown that
EFANNA outperforms the state-of-art algorithms both on approximate nearest
neighbor search and approximate nearest neighbor graph construction. To the
best of our knowledge, EFANNA is the fastest algorithm so far both on
approximate nearest neighbor graph construction and approximate nearest
neighbor search. A library EFANNA based on this research is released on Github.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Graph Based ANN 
      
        Efficiency And Optimization 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/fredriksson2016geometric/">Geometric Near-neighbor Access Tree (GNAT) Revisited</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Geometric Near-neighbor Access Tree (GNAT) Revisited' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Geometric Near-neighbor Access Tree (GNAT) Revisited' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Fredriksson Kimmo</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>6</td>
    <td><p>Geometric Near-neighbor Access Tree (GNAT) is a metric space indexing method
based on hierarchical hyperplane partitioning of the space. While GNAT is very
efficient in proximity searching, it has a bad reputation of being a memory
hog. We show that this is partially based on too coarse analysis, and that the
memory requirements can be lowered while at the same time improving the search
efficiency. We also show how to make GNAT memory adaptive in a smooth way, and
that the hyperplane partitioning can be replaced with ball partitioning, which
can further improve the search performance. We conclude with experimental
results showing the new methods can give significant performance boost.</p>
</td>
    <td>
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/wang2016unsupervised/">Unsupervised Cross-media Hashing With Structure Preservation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Unsupervised Cross-media Hashing With Structure Preservation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Unsupervised Cross-media Hashing With Structure Preservation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang Xiangyu, Chia Alex Yong-sang</td> <!-- ðŸ”§ You were missing this -->
    <td>Chinese Journal of Electronics</td>
    <td>22</td>
    <td><p>Recent years have seen the exponential growth of heterogeneous multimedia
data. The need for effective and accurate data retrieval from heterogeneous
data sources has attracted much research interest in cross-media retrieval.
Here, given a query of any media type, cross-media retrieval seeks to find
relevant results of different media types from heterogeneous data sources. To
facilitate large-scale cross-media retrieval, we propose a novel unsupervised
cross-media hashing method. Our method incorporates local affinity and distance
repulsion constraints into a matrix factorization framework. Correspondingly,
the proposed method learns hash functions that generates unified hash codes
from different media types, while ensuring intrinsic geometric structure of the
data distribution is preserved. These hash codes empower the similarity between
data of different media types to be evaluated directly. Experimental results on
two large-scale multimedia datasets demonstrate the effectiveness of the
proposed method, where we outperform the state-of-the-art methods.</p>
</td>
    <td>
      
        DATASETS 
      
        Tools & Libraries 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/amato2016aggregating/">Aggregating Binary Local Descriptors For Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Aggregating Binary Local Descriptors For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Aggregating Binary Local Descriptors For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Amato Giuseppe, Falchi Fabrizio, Vadicamo Lucia</td> <!-- ðŸ”§ You were missing this -->
    <td>Multimedia Tools and Applications</td>
    <td>11</td>
    <td><p>Content-Based Image Retrieval based on local features is computationally
expensive because of the complexity of both extraction and matching of local
feature. On one hand, the cost for extracting, representing, and comparing
local visual descriptors has been dramatically reduced by recently proposed
binary local features. On the other hand, aggregation techniques provide a
meaningful summarization of all the extracted feature of an image into a single
descriptor, allowing us to speed up and scale up the image search. Only a few
works have recently mixed together these two research directions, defining
aggregation methods for binary local features, in order to leverage on the
advantage of both approaches. In this paper, we report an extensive comparison
among state-of-the-art aggregation methods applied to binary features. Then, we
mathematically formalize the application of Fisher Kernels to Bernoulli Mixture
Models. Finally, we investigate the combination of the aggregated binary
features with the emerging Convolutional Neural Network (CNN) features. Our
results show that aggregation methods on binary features are effective and
represent a worthwhile alternative to the direct matching. Moreover, the
combination of the CNN with the Fisher Vector (FV) built upon binary features
allowed us to obtain a relative improvement over the CNN results that is in
line with that recently obtained using the combination of the CNN with the FV
built upon SIFTs. The advantage of using the FV built upon binary features is
that the extraction process of binary features is about two order of magnitude
faster than SIFTs.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Alt 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/xia2016unsupervised/">Unsupervised Deep Hashing For Large-scale Visual Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Unsupervised Deep Hashing For Large-scale Visual Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Unsupervised Deep Hashing For Large-scale Visual Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Xia et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2016 Sixth International Conference on Image Processing Theory, Tools and Applications (IPTA)</td>
    <td>17</td>
    <td><p>Learning based hashing plays a pivotal role in large-scale visual search.
However, most existing hashing algorithms tend to learn shallow models that do
not seek representative binary codes. In this paper, we propose a novel hashing
approach based on unsupervised deep learning to hierarchically transform
features into hash codes. Within the heterogeneous deep hashing framework, the
autoencoder layers with specific constraints are considered to model the
nonlinear mapping between features and binary codes. Then, a Restricted
Boltzmann Machine (RBM) layer with constraints is utilized to reduce the
dimension in the hamming space. Extensive experiments on the problem of visual
search demonstrate the competitiveness of our proposed approach compared to
state-of-the-art.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Compact Codes 
      
        Neural Hashing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/iwamura2016scalable/">Scalable Solution For Approximate Nearest Subspace Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Scalable Solution For Approximate Nearest Subspace Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Scalable Solution For Approximate Nearest Subspace Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Iwamura Masakazu, Konishi Masataka, Kise Koichi</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Pattern Analysis and Machine Intelligence</td>
    <td>56</td>
    <td><p>Finding the nearest subspace is a fundamental problem and influential to many
applications. In particular, a scalable solution that is fast and accurate for
a large problem has a great impact. The existing methods for the problem are,
however, useless in a large-scale problem with a large number of subspaces and
high dimensionality of the feature space. A cause is that they are designed
based on the traditional idea to represent a subspace by a single point. In
this paper, we propose a scalable solution for the approximate nearest subspace
search (ANSS) problem. Intuitively, the proposed method represents a subspace
by multiple points unlike the existing methods. This makes a large-scale ANSS
problem tractable. In the experiment with 3036 subspaces in the
1024-dimensional space, we confirmed that the proposed method was 7.3 times
faster than the previous state-of-the-art without loss of accuracy.</p>
</td>
    <td>
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/feng2016deep/">Deep Image Set Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Image Set Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Image Set Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Feng et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 IEEE Winter Conference on Applications of Computer Vision (WACV)</td>
    <td>12</td>
    <td><p>In applications involving matching of image sets, the information from
multiple images must be effectively exploited to represent each set.
State-of-the-art methods use probabilistic distribution or subspace to model a
set and use specific distance measure to compare two sets. These methods are
slow to compute and not compact to use in a large scale scenario.
Learning-based hashing is often used in large scale image retrieval as they
provide a compact representation of each sample and the Hamming distance can be
used to efficiently compare two samples. However, most hashing methods encode
each image separately and discard knowledge that multiple images in the same
set represent the same object or person. We investigate the set hashing problem
by combining both set representation and hashing in a single deep neural
network. An image set is first passed to a CNN module to extract image
features, then these features are aggregated using two types of set feature to
capture both set specific and database-wide distribution information. The
computed set feature is then fed into a multilayer perceptron to learn a
compact binary embedding. Triplet loss is used to train the network by forming
set similarity relations using class labels. We extensively evaluate our
approach on datasets used for image matching and show highly competitive
performance compared to state-of-the-art methods.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/ahle2016parameter/">Parameter-free Locality Sensitive Hashing For Spherical Range Reporting</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Parameter-free Locality Sensitive Hashing For Spherical Range Reporting' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Parameter-free Locality Sensitive Hashing For Spherical Range Reporting' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ahle Thomas D., AumÃ¼ller Martin, Pagh Rasmus</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>19</td>
    <td><p>We present a data structure for <em>spherical range reporting</em> on a point set
\(S\), i.e., reporting all points in \(S\) that lie within radius \(r\) of a given
query point \(q\). Our solution builds upon the Locality-Sensitive Hashing (LSH)
framework of Indyk and Motwani, which represents the asymptotically best
solutions to near neighbor problems in high dimensions. While traditional LSH
data structures have several parameters whose optimal values depend on the
distance distribution from \(q\) to the points of \(S\), our data structure is
parameter-free, except for the space usage, which is configurable by the user.
Nevertheless, its expected query time basically matches that of an LSH data
structure whose parameters have been <em>optimally chosen for the data and query</em>
in question under the given space constraints. In particular, our data
structure provides a smooth trade-off between hard queries (typically addressed
by standard LSH) and easy queries such as those where the number of points to
report is a constant fraction of \(S\), or where almost all points in \(S\) are far
away from the query point. In contrast, known data structures fix LSH
parameters based on certain parameters of the input alone.
  The algorithm has expected query time bounded by \(O(t (n/t)^\rho)\), where \(t\)
is the number of points to report and \(\rho\in (0,1)\) depends on the data
distribution and the strength of the LSH family used. We further present a
parameter-free way of using multi-probing, for LSH families that support it,
and show that for many such families this approach allows us to get expected
query time close to \(O(n^\rho+t)\), which is the best we can hope to achieve
using LSH. The previously best running time in high dimensions was \(Î©(t
n^\rho)\). For many data distributions where the intrinsic dimensionality of the
point set close to \(q\) is low, we can give improved upper bounds on the
expected query time.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Tools & Libraries 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/liu2016supervised/">Supervised Matrix Factorization For Cross-modality Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Supervised Matrix Factorization For Cross-modality Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Supervised Matrix Factorization For Cross-modality Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>65</td>
    <td><p>Matrix factorization has been recently utilized for the task of multi-modal
hashing for cross-modality visual search, where basis functions are learned to
map data from different modalities to the same Hamming embedding. In this
paper, we propose a novel cross-modality hashing algorithm termed Supervised
Matrix Factorization Hashing (SMFH) which tackles the multi-modal hashing
problem with a collective non-matrix factorization across the different
modalities. In particular, SMFH employs a well-designed binary code learning
algorithm to preserve the similarities among multi-modal original features
through a graph regularization. At the same time, semantic labels, when
available, are incorporated into the learning procedure. We conjecture that all
these would facilitate to preserve the most relevant information during the
binary quantization process, and hence improve the retrieval accuracy. We
demonstrate the superior performance of SMFH on three cross-modality visual
search benchmarks, i.e., the PASCAL-Sentence, Wiki, and NUS-WIDE, with
quantitative comparison to various state-of-the-art methods</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Compact Codes 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/gordo2016end/">End-to-end Learning Of Deep Visual Representations For Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=End-to-end Learning Of Deep Visual Representations For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=End-to-end Learning Of Deep Visual Representations For Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Gordo et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>International Journal of Computer Vision</td>
    <td>532</td>
    <td><p>While deep learning has become a key ingredient in the top performing methods
for many computer vision tasks, it has failed so far to bring similar
improvements to instance-level image retrieval. In this article, we argue that
reasons for the underwhelming results of deep methods on image retrieval are
threefold: i) noisy training data, ii) inappropriate deep architecture, and
iii) suboptimal training procedure. We address all three issues.
  First, we leverage a large-scale but noisy landmark dataset and develop an
automatic cleaning method that produces a suitable training set for deep
retrieval. Second, we build on the recent R-MAC descriptor, show that it can be
interpreted as a deep and differentiable architecture, and present improvements
to enhance it. Last, we train this network with a siamese architecture that
combines three streams with a triplet loss. At the end of the training process,
the proposed architecture produces a global image representation in a single
forward pass that is well suited for image retrieval. Extensive experiments
show that our approach significantly outperforms previous retrieval approaches,
including state-of-the-art methods based on costly local descriptor indexing
and spatial verification. On Oxford 5k, Paris 6k and Holidays, we respectively
report 94.7, 96.6, and 94.8 mean average precision. Our representations can
also be heavily compressed using product quantization with little loss in
accuracy. For additional material, please see
www.xrce.xerox.com/Deep-Image-Retrieval.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Distance Metric Learning 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/sablayrolles2016how/">How Should We Evaluate Supervised Hashing?</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=How Should We Evaluate Supervised Hashing?' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=How Should We Evaluate Supervised Hashing?' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Sablayrolles et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</td>
    <td>97</td>
    <td><p>Hashing produces compact representations for documents, to perform tasks like
classification or retrieval based on these short codes. When hashing is
supervised, the codes are trained using labels on the training data. This paper
first shows that the evaluation protocols used in the literature for supervised
hashing are not satisfactory: we show that a trivial solution that encodes the
output of a classifier significantly outperforms existing supervised or
semi-supervised methods, while using much shorter codes. We then propose two
alternative protocols for supervised hashing: one based on retrieval on a
disjoint set of classes, and another based on transfer learning to new classes.
We provide two baseline methods for image-related tasks to assess the
performance of (semi-)supervised hashing: without coding and with unsupervised
codes. These baselines give a lower- and upper-bound on the performance of a
supervised hashing scheme.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Compact Codes 
      
        Alt 
      
        ICASSP 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/zhang2016query/">Query-adaptive Image Retrieval By Deep Weighted Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Query-adaptive Image Retrieval By Deep Weighted Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Query-adaptive Image Retrieval By Deep Weighted Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhang Jian, Peng Yuxin</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Multimedia</td>
    <td>55</td>
    <td><p>Hashing methods have attracted much attention for large scale image
retrieval. Some deep hashing methods have achieved promising results by taking
advantage of the strong representation power of deep networks recently.
However, existing deep hashing methods treat all hash bits equally. On one
hand, a large number of images share the same distance to a query image due to
the discrete Hamming distance, which raises a critical issue of image retrieval
where fine-grained rankings are very important. On the other hand, different
hash bits actually contribute to the image retrieval differently, and treating
them equally greatly affects the retrieval accuracy of image. To address the
above two problems, we propose the query-adaptive deep weighted hashing (QaDWH)
approach, which can perform fine-grained ranking for different queries by
weighted Hamming distance. First, a novel deep hashing network is proposed to
learn the hash codes and corresponding class-wise weights jointly, so that the
learned weights can reflect the importance of different hash bits for different
image classes. Second, a query-adaptive image retrieval method is proposed,
which rapidly generates hash bit weights for different query images by fusing
its semantic probability and the learned class-wise weights. Fine-grained image
retrieval is then performed by the weighted Hamming distance, which can provide
more accurate ranking than the traditional Hamming distance. Experiments on
four widely used datasets show that the proposed approach outperforms eight
state-of-the-art hashing methods.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Neural Hashing 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/kanji2016self/">Self-localization From Images With Small Overlap</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Self-localization From Images With Small Overlap' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Self-localization From Images With Small Overlap' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Kanji Tanaka</td> <!-- ðŸ”§ You were missing this -->
    <td>2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</td>
    <td>20</td>
    <td><p>With the recent success of visual features from deep convolutional neural
networks (DCNN) in visual robot self-localization, it has become important and
practical to address more general self-localization scenarios. In this paper,
we address the scenario of self-localization from images with small overlap. We
explicitly introduce a localization difficulty index as a decreasing function
of view overlap between query and relevant database images and investigate
performance versus difficulty for challenging cross-view self-localization
tasks. We then reformulate the self-localization as a scalable
bag-of-visual-features (BoVF) scene retrieval and present an efficient solution
called PCA-NBNN, aiming to facilitate fast and yet discriminative
correspondence between partially overlapping images. The proposed approach
adopts recent findings in discriminativity preserving encoding of DCNN features
using principal component analysis (PCA) and cross-domain scene matching using
naive Bayes nearest neighbor distance metric (NBNN). We experimentally
demonstrate that the proposed PCA-NBNN framework frequently achieves comparable
results to previous DCNN features and that the BoVF model is significantly more
efficient. We further address an important alternative scenario of
â€œself-localization from images with NO overlapâ€ and report the result.</p>
</td>
    <td>
      
        IROS 
      
        Distance Metric Learning 
      
        Alt 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/bury2016efficient/">Efficient Similarity Search In Dynamic Data Streams</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Efficient Similarity Search In Dynamic Data Streams' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Efficient Similarity Search In Dynamic Data Streams' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Bury Marc, Schwiegelshohn Chris, Sorella Mara</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Knowledge and Data Engineering</td>
    <td>8</td>
    <td><p>The Jaccard index is an important similarity measure for item sets and
Boolean data. On large datasets, an exact similarity computation is often
infeasible for all item pairs both due to time and space constraints, giving
rise to faster approximate methods. The algorithm of choice used to quickly
compute the Jaccard index \(\frac{\vert A \cap B \vert}{\vert A\cup B\vert}\) of
two item sets \(A\) and \(B\) is usually a form of min-hashing. Most min-hashing
schemes are maintainable in data streams processing only additions, but none
are known to work when facing item-wise deletions. In this paper, we
investigate scalable approximation algorithms for rational set similarities, a
broad class of similarity measures including Jaccard. Motivated by a result of
Chierichetti and Kumar [J. ACM 2015] who showed any rational set similarity \(S\)
admits a locality sensitive hashing (LSH) scheme if and only if the
corresponding distance \(1-S\) is a metric, we can show that there exists a space
efficient summary maintaining a \((1\pm \epsilon)\) multiplicative
approximation to \(1-S\) in dynamic data streams. This in turn also yields a
\(\epsilon\) additive approximation of the similarity. The existence of these
approximations hints at, but does not directly imply a LSH scheme in dynamic
data streams. Our second and main contribution now lies in the design of such a
LSH scheme maintainable in dynamic data streams. The scheme is space efficient,
easy to implement and to the best of our knowledge the first of its kind able
to process deletions.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Similarity Search 
      
        Hashing Methods 
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/kehl2016hashmod/">Hashmod: A Hashing Method For Scalable 3D Object Detection</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hashmod: A Hashing Method For Scalable 3D Object Detection' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hashmod: A Hashing Method For Scalable 3D Object Detection' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Kehl et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Procedings of the British Machine Vision Conference 2015</td>
    <td>46</td>
    <td><p>We present a scalable method for detecting objects and estimating their 3D
poses in RGB-D data. To this end, we rely on an efficient representation of
object views and employ hashing techniques to match these views against the
input frame in a scalable way. While a similar approach already exists for 2D
detection, we show how to extend it to estimate the 3D pose of the detected
objects. In particular, we explore different hashing strategies and identify
the one which is more suitable to our problem. We show empirically that the
complexity of our method is sublinear with the number of objects and we enable
detection and pose estimation of many 3D objects with high accuracy while
outperforming the state-of-the-art in terms of runtime.</p>
</td>
    <td>
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/liu2016generalized/">Generalized Residual Vector Quantization For Large Scale Data</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Generalized Residual Vector Quantization For Large Scale Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Generalized Residual Vector Quantization For Large Scale Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Liu Shicong, Shao Junru, Lu Hongtao</td> <!-- ðŸ”§ You were missing this -->
    <td>2016 IEEE International Conference on Multimedia and Expo (ICME)</td>
    <td>5</td>
    <td><p>Vector quantization is an essential tool for tasks involving large scale
data, for example, large scale similarity search, which is crucial for
content-based information retrieval and analysis. In this paper, we propose a
novel vector quantization framework that iteratively minimizes quantization
error. First, we provide a detailed review on a relevant vector quantization
method named \textit{residual vector quantization} (RVQ). Next, we propose
\textit{generalized residual vector quantization} (GRVQ) to further improve
over RVQ. Many vector quantization methods can be viewed as the special cases
of our proposed framework. We evaluate GRVQ on several large scale benchmark
datasets for large scale search, classification and object retrieval. We
compared GRVQ with existing methods in detail. Extensive experiments
demonstrate our GRVQ framework substantially outperforms existing methods in
term of quantization accuracy and computation efficiency.</p>
</td>
    <td>
      
        Survey Paper 
      
        DATASETS 
      
        Efficiency And Optimization 
      
        Similarity Search 
      
        Quantization 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/cai2016revisit/">A Revisit Of Hashing Algorithms For Approximate Nearest Neighbor Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Revisit Of Hashing Algorithms For Approximate Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Revisit Of Hashing Algorithms For Approximate Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Cai Deng</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Knowledge and Data Engineering</td>
    <td>29</td>
    <td><p>Approximate Nearest Neighbor Search (ANNS) is a fundamental problem in many
areas of machine learning and data mining. During the past decade, numerous
hashing algorithms are proposed to solve this problem. Every proposed algorithm
claims outperform other state-of-the-art hashing methods. However, the
evaluation of these hashing papers was not thorough enough, and those claims
should be re-examined. The ultimate goal of an ANNS method is returning the
most accurate answers (nearest neighbors) in the shortest time. If implemented
correctly, almost all the hashing methods will have their performance improved
as the code length increases. However, many existing hashing papers only report
the performance with the code length shorter than 128. In this paper, we
carefully revisit the problem of search with a hash index, and analyze the pros
and cons of two popular hash index search procedures. Then we proposed a very
simple but effective two level index structures and make a thorough comparison
of eleven popular hashing algorithms. Surprisingly, the random-projection-based
Locality Sensitive Hashing (LSH) is the best performed algorithm, which is in
contradiction to the claims in all the other ten hashing papers. Despite the
extreme simplicity of random-projection-based LSH, our results show that the
capability of this algorithm has been far underestimated. For the sake of
reproducibility, all the codes used in the paper are released on GitHub, which
can be used as a testing platform for a fair comparison between various hashing
algorithms.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Graph Based ANN 
      
        Vector Indexing 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/srijith2016sub/">Sub-story Detection In Twitter With Hierarchical Dirichlet Processes</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Sub-story Detection In Twitter With Hierarchical Dirichlet Processes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Sub-story Detection In Twitter With Hierarchical Dirichlet Processes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Srijith et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Information Processing &amp; Management</td>
    <td>59</td>
    <td><p>Social media has now become the de facto information source on real world
events. The challenge, however, due to the high volume and velocity nature of
social media streams, is in how to follow all posts pertaining to a given event
over time, a task referred to as story detection. Moreover, there are often
several different stories pertaining to a given event, which we refer to as
sub-stories and the corresponding task of their automatic detection as
sub-story detection. This paper proposes hierarchical Dirichlet processes
(HDP), a probabilistic topic model, as an effective method for automatic
sub-story detection. HDP can learn sub-topics associated with sub-stories which
enables it to handle subtle variations in sub-stories. It is compared with
state- of-the-art story detection approaches based on locality sensitive
hashing and spectral clustering. We demonstrate the superior performance of HDP
for sub-story detection on real world Twitter data sets using various
evaluation measures. The ability of HDP to learn sub-topics helps it to recall
the sub- stories with high precision. Another contribution of this paper is in
demonstrating that the conversational structures within the Twitter stream can
be used to improve sub-story detection performance significantly.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/hoffer2016semi/">Semi-supervised Deep Learning By Metric Embedding</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Semi-supervised Deep Learning By Metric Embedding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Semi-supervised Deep Learning By Metric Embedding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Hoffer Elad, Ailon Nir</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>28</td>
    <td><p>Deep networks are successfully used as classification models yielding
state-of-the-art results when trained on a large number of labeled samples.
These models, however, are usually much less suited for semi-supervised
problems because of their tendency to overfit easily when trained on small
amounts of data. In this work we will explore a new training objective that is
targeting a semi-supervised regime with only a small subset of labeled data.
This criterion is based on a deep metric embedding over distance relations
within the set of labeled samples, together with constraints over the
embeddings of the unlabeled set. The final learned representations are
discriminative in euclidean space, and hence can be used with subsequent
nearest-neighbor classification using the labeled samples.</p>
</td>
    <td>
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/zhuang2016fast/">Fast Training Of Triplet-based Deep Binary Embedding Networks</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fast Training Of Triplet-based Deep Binary Embedding Networks' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fast Training Of Triplet-based Deep Binary Embedding Networks' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhuang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>136</td>
    <td><p>In this paper, we aim to learn a mapping (or embedding) from images to a
compact binary space in which Hamming distances correspond to a ranking measure
for the image retrieval task.
  We make use of a triplet loss because this has been shown to be most
effective for ranking problems.
  However, training in previous works can be prohibitively expensive due to the
fact that optimization is directly performed on the triplet space, where the
number of possible triplets for training is cubic in the number of training
examples.
  To address this issue, we propose to formulate high-order binary codes
learning as a multi-label classification problem by explicitly separating
learning into two interleaved stages.
  To solve the first stage, we design a large-scale high-order binary codes
inference algorithm to reduce the high-order objective to a standard binary
quadratic problem such that graph cuts can be used to efficiently infer the
binary code which serve as the label of each training datum.
  In the second stage we propose to map the original image to compact binary
codes via carefully designed deep convolutional neural networks (CNNs) and the
hashing function fitting can be solved by training binary CNN classifiers.
  An incremental/interleaved optimization strategy is proffered to ensure that
these two steps are interactive with each other during training for better
accuracy.
  We conduct experiments on several benchmark datasets, which demonstrate both
improved training time (by as much as two orders of magnitude) as well as
producing state-of-the-art hashing for various retrieval tasks.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        CVPR 
      
        Compact Codes 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/cao2016transitive/">Transitive Hashing Network For Heterogeneous Multimedia Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Transitive Hashing Network For Heterogeneous Multimedia Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Transitive Hashing Network For Heterogeneous Multimedia Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Cao Zhangjie, Long Mingsheng, Yang Qiang</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>25</td>
    <td><p>Hashing has been widely applied to large-scale multimedia retrieval due to
the storage and retrieval efficiency. Cross-modal hashing enables efficient
retrieval from database of one modality in response to a query of another
modality. Existing work on cross-modal hashing assumes heterogeneous
relationship across modalities for hash function learning. In this paper, we
relax the strong assumption by only requiring such heterogeneous relationship
in an auxiliary dataset different from the query/database domain. We craft a
hybrid deep architecture to simultaneously learn the cross-modal correlation
from the auxiliary dataset, and align the dataset distributions between the
auxiliary dataset and the query/database domain, which generates transitive
hash codes for heterogeneous multimedia retrieval. Extensive experiments
exhibit that the proposed approach yields state of the art multimedia retrieval
performance on public datasets, i.e. NUS-WIDE, ImageNet-YahooQA.</p>
</td>
    <td>
      
        AAAI 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/tabei2016scalable/">Scalable Similarity Search For Molecular Descriptors</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Scalable Similarity Search For Molecular Descriptors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Scalable Similarity Search For Molecular Descriptors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Tabei Yasuo, Puglisi Simon J.</td> <!-- ðŸ”§ You were missing this -->
    <td>Journal of Chemical Information and Computer Sciences</td>
    <td>62</td>
    <td><p>Similarity search over chemical compound databases is a fundamental task in
the discovery and design of novel drug-like molecules. Such databases often
encode molecules as non-negative integer vectors, called molecular descriptors,
which represent rich information on various molecular properties. While there
exist efficient indexing structures for searching databases of binary vectors,
solutions for more general integer vectors are in their infancy. In this paper
we present a time- and space- efficient index for the problem that we call the
succinct intervals-splitting tree algorithm for molecular descriptors (SITAd).
Our approach extends efficient methods for binary-vector databases, and uses
ideas from succinct data structures. Our experiments, on a large database of
over 40 million compounds, show SITAd significantly outperforms alternative
approaches in practice.</p>
</td>
    <td>
      
        Alt 
      
        Similarity Search 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/cao2016correlation/">Correlation Hashing Network For Efficient Cross-modal Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Correlation Hashing Network For Efficient Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Correlation Hashing Network For Efficient Cross-modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Cao et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Procedings of the British Machine Vision Conference 2017</td>
    <td>62</td>
    <td><p>Hashing is widely applied to approximate nearest neighbor search for
large-scale multimodal retrieval with storage and computation efficiency.
Cross-modal hashing improves the quality of hash coding by exploiting semantic
correlations across different modalities. Existing cross-modal hashing methods
first transform data into low-dimensional feature vectors, and then generate
binary codes by another separate quantization step. However, suboptimal hash
codes may be generated since the quantization error is not explicitly minimized
and the feature representation is not jointly optimized with the binary codes.
This paper presents a Correlation Hashing Network (CHN) approach to cross-modal
hashing, which jointly learns good data representation tailored to hash coding
and formally controls the quantization error. The proposed CHN is a hybrid deep
architecture that constitutes a convolutional neural network for learning good
image representations, a multilayer perception for learning good text
representations, two hashing layers for generating compact binary codes, and a
structured max-margin loss that integrates all things together to enable
learning similarity-preserving and high-quality hash codes. Extensive empirical
study shows that CHN yields state of the art cross-modal retrieval performance
on standard benchmarks.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Multimodal Retrieval 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/joulin2016fasttext/">Fasttext.zip: Compressing Text Classification Models</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fasttext.zip: Compressing Text Classification Models' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fasttext.zip: Compressing Text Classification Models' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Joulin et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>872</td>
    <td><p>We consider the problem of producing compact architectures for text
classification, such that the full model fits in a limited amount of memory.
After considering different solutions inspired by the hashing literature, we
propose a method built upon product quantization to store word embeddings.
While the original technique leads to a loss in accuracy, we adapt this method
to circumvent quantization artefacts. Our experiments carried out on several
benchmarks show that our approach typically requires two orders of magnitude
less memory than fastText while being only slightly inferior with respect to
accuracy. As a result, it outperforms the state of the art by a good margin in
terms of the compromise between memory usage and accuracy.</p>
</td>
    <td>
      
        Quantization 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/douze2016polysemous/">Polysemous Codes</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Polysemous Codes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Polysemous Codes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Douze Matthijs, JÃ©gou HervÃ©, Perronnin Florent</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>45</td>
    <td><p>This paper considers the problem of approximate nearest neighbor search in
the compressed domain. We introduce polysemous codes, which offer both the
distance estimation quality of product quantization and the efficient
comparison of binary codes with Hamming distance. Their design is inspired by
algorithms introduced in the 90â€™s to construct channel-optimized vector
quantizers. At search time, this dual interpretation accelerates the search.
Most of the indexed vectors are filtered out with Hamming distance, letting
only a fraction of the vectors to be ranked with an asymmetric distance
estimator.
  The method is complementary with a coarse partitioning of the feature space
such as the inverted multi-index. This is shown by our experiments performed on
several public benchmarks such as the BIGANN dataset comprising one billion
vectors, for which we report state-of-the-art results for query times below
0.3\,millisecond per core. Last but not least, our approach allows the
approximate computation of the k-NN graph associated with the Yahoo Flickr
Creative Commons 100M, described by CNN image descriptors, in less than 8 hours
on a single machine.</p>
</td>
    <td>
      
        DATASETS 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Quantization 
      
        Vector Indexing 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/roy2016representing/">Representing Documents And Queries As Sets Of Word Embedded Vectors For Information Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Representing Documents And Queries As Sets Of Word Embedded Vectors For Information Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Representing Documents And Queries As Sets Of Word Embedded Vectors For Information Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Roy et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>11</td>
    <td><p>A major difficulty in applying word vector embeddings in IR is in devising an
effective and efficient strategy for obtaining representations of compound
units of text, such as whole documents, (in comparison to the atomic words),
for the purpose of indexing and scoring documents. Instead of striving for a
suitable method for obtaining a single vector representation of a large
document of text, we rather aim for developing a similarity metric that makes
use of the similarities between the individual embedded word vectors in a
document and a query. More specifically, we represent a document and a query as
sets of word vectors, and use a standard notion of similarity measure between
these sets, computed as a function of the similarities between each constituent
word pair from these sets. We then make use of this similarity measure in
combination with standard IR based similarities for document ranking. The
results of our initial experimental investigations shows that our proposed
method improves MAP by up to \(5.77%\), in comparison to standard text-based
language model similarity, on the TREC ad-hoc dataset.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/spring2016scalable/">Scalable And Sustainable Deep Learning Via Randomized Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Scalable And Sustainable Deep Learning Via Randomized Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Scalable And Sustainable Deep Learning Via Randomized Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Spring Ryan, Shrivastava Anshumali</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</td>
    <td>108</td>
    <td><p>Current deep learning architectures are growing larger in order to learn from
complex datasets. These architectures require giant matrix multiplication
operations to train millions of parameters. Conversely, there is another
growing trend to bring deep learning to low-power, embedded devices. The matrix
operations, associated with both training and testing of deep networks, are
very expensive from a computational and energy standpoint. We present a novel
hashing based technique to drastically reduce the amount of computation needed
to train and test deep networks. Our approach combines recent ideas from
adaptive dropouts and randomized hashing for maximum inner product search to
select the nodes with the highest activation efficiently. Our new algorithm for
deep learning reduces the overall computational cost of forward and
back-propagation by operating on significantly fewer (sparse) nodes. As a
consequence, our algorithm uses only 5% of the total multiplications, while
keeping on average within 1% of the accuracy of the original model. A unique
property of the proposed hashing based back-propagation is that the updates are
always sparse. Due to the sparse gradient updates, our algorithm is ideally
suited for asynchronous and parallel training leading to near linear speedup
with increasing number of cores. We demonstrate the scalability and
sustainability (energy efficiency) of our proposed algorithm via rigorous
experimental evaluations on several real datasets.</p>
</td>
    <td>
      
        KDD 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/pele2016interpolated/">Interpolated Discretized Embedding Of Single Vectors And Vector Pairs For Classification, Metric Learning And Distance Approximation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Interpolated Discretized Embedding Of Single Vectors And Vector Pairs For Classification, Metric Learning And Distance Approximation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Interpolated Discretized Embedding Of Single Vectors And Vector Pairs For Classification, Metric Learning And Distance Approximation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Pele Ofir, Ben-aliz Yakir</td> <!-- ðŸ”§ You were missing this -->
    <td>Pattern Recognition</td>
    <td>8</td>
    <td><p>We propose a new embedding method for a single vector and for a pair of
vectors. This embedding method enables: a) efficient classification and
regression of functions of single vectors; b) efficient approximation of
distance functions; and c) non-Euclidean, semimetric learning. To the best of
our knowledge, this is the first work that enables learning any general,
non-Euclidean, semimetrics. That is, our method is a universal semimetric
learning and approximation method that can approximate any distance function
with as high accuracy as needed with or without semimetric constraints. The
project homepage including code is at: http://www.ariel.ac.il/sites/ofirpele/ID</p>
</td>
    <td>
      
        CVPR 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/radenovi%C4%872016cnn/">CNN Image Retrieval Learns From Bow: Unsupervised Fine-tuning With Hard Examples</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=CNN Image Retrieval Learns From Bow: Unsupervised Fine-tuning With Hard Examples' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=CNN Image Retrieval Learns From Bow: Unsupervised Fine-tuning With Hard Examples' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>RadenoviÄ‡ Filip, Tolias Giorgos, Chum OndÅ™ej</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>523</td>
    <td><p>Convolutional Neural Networks (CNNs) achieve state-of-the-art performance in
many computer vision tasks. However, this achievement is preceded by extreme
manual annotation in order to perform either training from scratch or
fine-tuning for the target task. In this work, we propose to fine-tune CNN for
image retrieval from a large collection of unordered images in a fully
automated manner. We employ state-of-the-art retrieval and
Structure-from-Motion (SfM) methods to obtain 3D models, which are used to
guide the selection of the training data for CNN fine-tuning. We show that both
hard positive and hard negative examples enhance the final performance in
particular object retrieval with compact codes.</p>
</td>
    <td>
      
        Compact Codes 
      
        Image Retrieval 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/jain2016approximate/">Approximate Search With Quantized Sparse Representations</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Approximate Search With Quantized Sparse Representations' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Approximate Search With Quantized Sparse Representations' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jain et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>17</td>
    <td><p>This paper tackles the task of storing a large collection of vectors, such as
visual descriptors, and of searching in it. To this end, we propose to
approximate database vectors by constrained sparse coding, where possible atom
weights are restricted to belong to a finite subset. This formulation
encompasses, as particular cases, previous state-of-the-art methods such as
product or residual quantization. As opposed to traditional sparse coding
methods, quantized sparse coding includes memory usage as a design constraint,
thereby allowing us to index a large collection such as the BIGANN
billion-sized benchmark. Our experiments, carried out on standard benchmarks,
show that our formulation leads to competitive solutions when considering
different trade-offs between learning/coding time, index size and search
quality.</p>
</td>
    <td>
      
        Quantization 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/nouredanesh2016gabor/">Gabor Barcodes For Medical Image Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Gabor Barcodes For Medical Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Gabor Barcodes For Medical Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Nouredanesh Mina, Tizhoosh Hamid R., Banijamali Ershad</td> <!-- ðŸ”§ You were missing this -->
    <td>2016 IEEE International Conference on Image Processing (ICIP)</td>
    <td>9</td>
    <td><p>In recent years, advances in medical imaging have led to the emergence of
massive databases, containing images from a diverse range of modalities. This
has significantly heightened the need for automated annotation of the images on
one side, and fast and memory-efficient content-based image retrieval systems
on the other side. Binary descriptors have recently gained more attention as a
potential vehicle to achieve these goals. One of the recently introduced binary
descriptors for tagging of medical images are Radon barcodes (RBCs) that are
driven from Radon transform via local thresholding. Gabor transform is also a
powerful transform to extract texture-based information. Gabor features have
exhibited robustness against rotation, scale, and also photometric
disturbances, such as illumination changes and image noise in many
applications. This paper introduces Gabor Barcodes (GBCs), as a novel framework
for the image annotation. To find the most discriminative GBC for a given query
image, the effects of employing Gabor filters with different parameters, i.e.,
different sets of scales and orientations, are investigated, resulting in
different barcode lengths and retrieval performances. The proposed method has
been evaluated on the IRMA dataset with 193 classes comprising of 12,677 x-ray
images for indexing, and 1,733 x-rays images for testing. A total error score
as low as \(351\) (\(\approx 80%\) accuracy for the first hit) was achieved.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Tools & Libraries 
      
        Evaluation 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/sankaranarayanan2016triplet/">Triplet Similarity Embedding For Face Verification</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Triplet Similarity Embedding For Face Verification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Triplet Similarity Embedding For Face Verification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Sankaranarayanan Swami, Alavi Azadeh, Chellappa Rama</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>47</td>
    <td><p>In this work, we present an unconstrained face verification algorithm and
evaluate it on the recently released IJB-A dataset that aims to push the
boundaries of face verification methods. The proposed algorithm couples a deep
CNN-based approach with a low-dimensional discriminative embedding learnt using
triplet similarity constraints in a large margin fashion. Aside from yielding
performance improvement, this embedding provides significant advantages in
terms of memory and post-processing operations like hashing and visualization.
Experiments on the IJB-A dataset show that the proposed algorithm outperforms
state of the art methods in verification and identification metrics, while
requiring less training time.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/yu2016variable/">Variable-length Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Variable-length Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Variable-length Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>29</td>
    <td><p>Hashing has emerged as a popular technique for large-scale similarity search.
Most learning-based hashing methods generate compact yet correlated hash codes.
However, this redundancy is storage-inefficient. Hence we propose a lossless
variable-length hashing (VLH) method that is both storage- and
search-efficient. Storage efficiency is achieved by converting the fixed-length
hash code into a variable-length code. Search efficiency is obtained by using a
multiple hash table structure. With VLH, we are able to deliberately add
redundancy into hash codes to improve retrieval performance with little
sacrifice in storage efficiency or search complexity. In particular, we propose
a block K-means hashing (B-KMH) method to obtain significantly improved
retrieval performance with no increase in storage and marginal increase in
computational cost.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        CVPR 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/malkov2016efficient/">Efficient And Robust Approximate Nearest Neighbor Search Using Hierarchical Navigable Small World Graphs</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Efficient And Robust Approximate Nearest Neighbor Search Using Hierarchical Navigable Small World Graphs' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Efficient And Robust Approximate Nearest Neighbor Search Using Hierarchical Navigable Small World Graphs' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Malkov Yu. A., Yashunin D. A.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Pattern Analysis and Machine Intelligence</td>
    <td>1063</td>
    <td><p>We present a new approach for the approximate K-nearest neighbor search based
on navigable small world graphs with controllable hierarchy (Hierarchical NSW,
HNSW). The proposed solution is fully graph-based, without any need for
additional search structures, which are typically used at the coarse search
stage of the most proximity graph techniques. Hierarchical NSW incrementally
builds a multi-layer structure consisting from hierarchical set of proximity
graphs (layers) for nested subsets of the stored elements. The maximum layer in
which an element is present is selected randomly with an exponentially decaying
probability distribution. This allows producing graphs similar to the
previously studied Navigable Small World (NSW) structures while additionally
having the links separated by their characteristic distance scales. Starting
search from the upper layer together with utilizing the scale separation boosts
the performance compared to NSW and allows a logarithmic complexity scaling.
Additional employment of a heuristic for selecting proximity graph neighbors
significantly increases performance at high recall and in case of highly
clustered data. Performance evaluation has demonstrated that the proposed
general metric space search index is able to strongly outperform previous
opensource state-of-the-art vector-only approaches. Similarity of the algorithm
to the skip list structure allows straightforward balanced distributed
implementation.</p>
</td>
    <td>
      
        Graph Based ANN 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/carreiraperpi%C3%B1%C3%A1n2016ensemble/">An Ensemble Diversity Approach To Supervised Binary Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=An Ensemble Diversity Approach To Supervised Binary Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=An Ensemble Diversity Approach To Supervised Binary Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Carreira-perpiÃ±Ã¡n Miguel Ã., Raziperchikolaei Ramin</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>8</td>
    <td><p>Binary hashing is a well-known approach for fast approximate nearest-neighbor
search in information retrieval. Much work has focused on affinity-based
objective functions involving the hash functions or binary codes. These
objective functions encode neighborhood information between data points and are
often inspired by manifold learning algorithms. They ensure that the hash
functions differ from each other through constraints or penalty terms that
encourage codes to be orthogonal or dissimilar across bits, but this couples
the binary variables and complicates the already difficult optimization. We
propose a much simpler approach: we train each hash function (or bit)
independently from each other, but introduce diversity among them using
techniques from classifier ensembles. Surprisingly, we find that not only is
this faster and trivially parallelizable, but it also improves over the more
complex, coupled objective function, and achieves state-of-the-art precision
and recall in experiments with image retrieval.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Compact Codes 
      
        Alt 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/koutaki2016fast/">Fast Supervised Discrete Hashing And Its Analysis</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fast Supervised Discrete Hashing And Its Analysis' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fast Supervised Discrete Hashing And Its Analysis' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Koutaki Gou, Shirai Keiichiro, Ambai Mitsuru</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>7</td>
    <td><p>In this paper, we propose a learning-based supervised discrete hashing
method. Binary hashing is widely used for large-scale image retrieval as well
as video and document searches because the compact representation of binary
code is essential for data storage and reasonable for query searches using
bit-operations. The recently proposed Supervised Discrete Hashing (SDH)
efficiently solves mixed-integer programming problems by alternating
optimization and the Discrete Cyclic Coordinate descent (DCC) method. We show
that the SDH model can be simplified without performance degradation based on
some preliminary experiments; we call the approximate model for this the â€œFast
SDHâ€ (FSDH) model. We analyze the FSDH model and provide a mathematically exact
solution for it. In contrast to SDH, our model does not require an alternating
optimization algorithm and does not depend on initial values. FSDH is also
easier to implement than Iterative Quantization (ITQ). Experimental results
involving a large-scale database showed that FSDH outperforms conventional SDH
in terms of precision, recall, and computation time.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Alt 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/song2016deep/">Deep Metric Learning Via Facility Location</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Metric Learning Via Facility Location' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Metric Learning Via Facility Location' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Song et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>308</td>
    <td><p>Learning the representation and the similarity metric in an end-to-end
fashion with deep networks have demonstrated outstanding results for clustering
and retrieval. However, these recent approaches still suffer from the
performance degradation stemming from the local metric training procedure which
is unaware of the global structure of the embedding space.
  We propose a global metric learning scheme for optimizing the deep metric
embedding with the learnable clustering function and the clustering metric
(NMI) in a novel structured prediction framework.
  Our experiments on CUB200-2011, Cars196, and Stanford online products
datasets show state of the art performance both on the clustering and retrieval
tasks measured in the NMI and Recall@K evaluation metrics.</p>
</td>
    <td>
      
        DATASETS 
      
        Distance Metric Learning 
      
        CVPR 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/riazi2016sub/">Sub-linear Privacy-preserving Near-neighbor Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Sub-linear Privacy-preserving Near-neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Sub-linear Privacy-preserving Near-neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Riazi et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>11</td>
    <td><p>In Near-Neighbor Search (NNS), a new client queries a database (held by a
server) for the most similar data (near-neighbors) given a certain similarity
metric. The Privacy-Preserving variant (PP-NNS) requires that neither server
nor the client shall learn information about the other partyâ€™s data except what
can be inferred from the outcome of NNS. The overwhelming growth in the size of
current datasets and the lack of a truly secure server in the online world
render the existing solutions impractical; either due to their high
computational requirements or non-realistic assumptions which potentially
compromise privacy. PP-NNS having query time {\it sub-linear} in the size of
the database has been suggested as an open research direction by Li et al.
(CCSWâ€™15). In this paper, we provide the first such algorithm, called Secure
Locality Sensitive Indexing (SLSI) which has a sub-linear query time and the
ability to handle honest-but-curious parties. At the heart of our proposal lies
a secure binary embedding scheme generated from a novel probabilistic
transformation over locality sensitive hashing family. We provide information
theoretic bound for the privacy guarantees and support our theoretical claims
using substantial empirical evidence on real-world datasets.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/xu2016binary/">Binary Subspace Coding For Query-by-image Video Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Binary Subspace Coding For Query-by-image Video Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Binary Subspace Coding For Query-by-image Video Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Xu et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 25th ACM international conference on Multimedia</td>
    <td>7</td>
    <td><p>The query-by-image video retrieval (QBIVR) task has been attracting
considerable research attention recently. However, most existing methods
represent a video by either aggregating or projecting all its frames into a
single datum point, which may easily cause severe information loss. In this
paper, we propose an efficient QBIVR framework to enable an effective and
efficient video search with image query. We first define a
similarity-preserving distance metric between an image and its orthogonal
projection in the subspace of the video, which can be equivalently transformed
to a Maximum Inner Product Search (MIPS) problem.
  Besides, to boost the efficiency of solving the MIPS problem, we propose two
asymmetric hashing schemes, which bridge the domain gap of images and videos.
The first approach, termed Inner-product Binary Coding (IBC), preserves the
inner relationships of images and videos in a common Hamming space. To further
improve the retrieval efficiency, we devise a Bilinear Binary Coding (BBC)
approach, which employs compact bilinear projections instead of a single large
projection matrix. Extensive experiments have been conducted on four real-world
video datasets to verify the effectiveness of our proposed approaches as
compared to the state-of-the-arts.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        Efficiency And Optimization 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/tang2016visualizing/">Visualizing Large-scale And High-dimensional Data</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Visualizing Large-scale And High-dimensional Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Visualizing Large-scale And High-dimensional Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Tang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 25th International Conference on World Wide Web</td>
    <td>215</td>
    <td><p>We study the problem of visualizing large-scale and high-dimensional data in
a low-dimensional (typically 2D or 3D) space. Much success has been reported
recently by techniques that first compute a similarity structure of the data
points and then project them into a low-dimensional space with the structure
preserved. These two steps suffer from considerable computational costs,
preventing the state-of-the-art methods such as the t-SNE from scaling to
large-scale and high-dimensional data (e.g., millions of data points and
hundreds of dimensions). We propose the LargeVis, a technique that first
constructs an accurately approximated K-nearest neighbor graph from the data
and then layouts the graph in the low-dimensional space. Comparing to t-SNE,
LargeVis significantly reduces the computational cost of the graph construction
step and employs a principled probabilistic model for the visualization step,
the objective of which can be effectively optimized through asynchronous
stochastic gradient descent with a linear time complexity. The whole procedure
thus easily scales to millions of high-dimensional data points. Experimental
results on real-world data sets demonstrate that the LargeVis outperforms the
state-of-the-art methods in both efficiency and effectiveness. The
hyper-parameters of LargeVis are also much more stable over different data
sets.</p>
</td>
    <td>
      
        Graph Based ANN 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/spencer2016noisy/">Noisy 1-bit Compressed Sensing Embeddings Enjoy A Restricted Isometry Property</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Noisy 1-bit Compressed Sensing Embeddings Enjoy A Restricted Isometry Property' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Noisy 1-bit Compressed Sensing Embeddings Enjoy A Restricted Isometry Property' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Spencer Scott</td> <!-- ðŸ”§ You were missing this -->
    <td>SIAM Review</td>
    <td>104</td>
    <td><p>We investigate the sign-linear embeddings of 1-bit compressed sensing given
by Gaussian measurements. One can give short arguments concerning a Restricted
Isometry Property of such maps using Vapnik-Chervonenkis dimension of sparse
hemispheres. This approach has a natural extension to the presence of additive
white noise prior to quantization. Noisy one-bit mappings are shown to satisfy
an RIP when the metric on the sphere is given by the noise.</p>
</td>
    <td>
      
        Survey Paper 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/tizhoosh2016barcodes/">Barcodes For Medical Image Retrieval Using Autoencoded Radon Transform</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Barcodes For Medical Image Retrieval Using Autoencoded Radon Transform' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Barcodes For Medical Image Retrieval Using Autoencoded Radon Transform' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Tizhoosh et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2016 23rd International Conference on Pattern Recognition (ICPR)</td>
    <td>16</td>
    <td><p>Using content-based binary codes to tag digital images has emerged as a
promising retrieval technology. Recently, Radon barcodes (RBCs) have been
introduced as a new binary descriptor for image search. RBCs are generated by
binarization of Radon projections and by assembling them into a vector, namely
the barcode. A simple local thresholding has been suggested for binarization.
In this paper, we put forward the idea of â€œautoencoded Radon barcodesâ€. Using
images in a training dataset, we autoencode Radon projections to perform
binarization on outputs of hidden layers. We employed the mini-batch stochastic
gradient descent approach for the training. Each hidden layer of the
autoencoder can produce a barcode using a threshold determined based on the
range of the logistic function used. The compressing capability of autoencoders
apparently reduces the redundancies inherent in Radon projections leading to
more accurate retrieval results. The IRMA dataset with 14,410 x-ray images is
used to validate the performance of the proposed method. The experimental
results, containing comparison with RBCs, SURF and BRISK, show that autoencoded
Radon barcode (ARBC) has the capacity to capture important information and to
learn richer representations resulting in lower retrieval errors for image
retrieval measured with the accuracy of the first hit only.</p>
</td>
    <td>
      
        Compact Codes 
      
        Image Retrieval 
      
        DATASETS 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/chadha2016voronoi/">Voronoi-based Compact Image Descriptors: Efficient Region-of-interest Retrieval With VLAD And Deep-learning-based Descriptors</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Voronoi-based Compact Image Descriptors: Efficient Region-of-interest Retrieval With VLAD And Deep-learning-based Descriptors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Voronoi-based Compact Image Descriptors: Efficient Region-of-interest Retrieval With VLAD And Deep-learning-based Descriptors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Chadha Aaron, Andreopoulos Yiannis</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Multimedia</td>
    <td>29</td>
    <td><p>We investigate the problem of image retrieval based on visual queries when
the latter comprise arbitrary regions-of-interest (ROI) rather than entire
images. Our proposal is a compact image descriptor that combines the
state-of-the-art in content-based descriptor extraction with a multi-level,
Voronoi-based spatial partitioning of each dataset image. The proposed
multi-level Voronoi-based encoding uses a spatial hierarchical K-means over
interest-point locations, and computes a content-based descriptor over each
cell. In order to reduce the matching complexity with minimal or no sacrifice
in retrieval performance: (i) we utilize the tree structure of the spatial
hierarchical K-means to perform a top-to-bottom pruning for local similarity
maxima; (ii) we propose a new image similarity score that combines relevant
information from all partition levels into a single measure for similarity;
(iii) we combine our proposal with a novel and efficient approach for optimal
bit allocation within quantized descriptor representations. By deriving both a
Voronoi-based VLAD descriptor (termed as Fast-VVLAD) and a Voronoi-based deep
convolutional neural network (CNN) descriptor (termed as Fast-VDCNN), we
demonstrate that our Voronoi-based framework is agnostic to the descriptor
basis, and can easily be slotted into existing frameworks. Via a range of ROI
queries in two standard datasets, it is shown that the Voronoi-based
descriptors achieve comparable or higher mean Average Precision against
conventional grid-based spatial search, while offering more than two-fold
reduction in complexity. Finally, beyond ROI queries, we show that Voronoi
partitioning improves the geometric invariance of compact CNN descriptors,
thereby resulting in competitive performance to the current state-of-the-art on
whole image retrieval.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/shrivastava2016exact/">Exact Weighted Minwise Hashing In Constant Time</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Exact Weighted Minwise Hashing In Constant Time' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Exact Weighted Minwise Hashing In Constant Time' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Shrivastava Anshumali</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>7</td>
    <td><p>Weighted minwise hashing (WMH) is one of the fundamental subroutine, required
by many celebrated approximation algorithms, commonly adopted in industrial
practice for large scale-search and learning. The resource bottleneck of the
algorithms is the computation of multiple (typically a few hundreds to
thousands) independent hashes of the data. The fastest hashing algorithm is by
Ioffe \cite{Proc:Ioffe_ICDM10}, which requires one pass over the entire data
vector, \(O(d)\) (\(d\) is the number of non-zeros), for computing one hash.
However, the requirement of multiple hashes demands hundreds or thousands
passes over the data. This is very costly for modern massive dataset.
  In this work, we break this expensive barrier and show an expected constant
amortized time algorithm which computes \(k\) independent and unbiased WMH in
time \(O(k)\) instead of \(O(dk)\) required by Ioffeâ€™s method. Moreover, our
proposal only needs a few bits (5 - 9 bits) of storage per hash value compared
to around \(64\) bits required by the state-of-art-methodologies. Experimental
evaluations, on real datasets, show that for computing 500 WMH, our proposal
can be 60000x faster than the Ioffeâ€™s method without losing any accuracy. Our
method is also around 100x faster than approximate heuristics capitalizing on
the efficient â€œdensifiedâ€ one permutation hashing schemes
\cite{Proc:OneHashLSH_ICML14}. Given the simplicity of our approach and its
significant advantages, we hope that it will replace existing implementations
in practice.</p>
</td>
    <td>
      
        ICML 
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        DATASETS 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/morales2016streaming/">Streaming Similarity Self-join</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Streaming Similarity Self-join' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Streaming Similarity Self-join' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Morales Gianmarco de Francisci, Gionis Aristides</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the VLDB Endowment</td>
    <td>27</td>
    <td><p>We introduce and study the problem of computing the similarity self-join in a
streaming context (SSSJ), where the input is an unbounded stream of items
arriving continuously. The goal is to find all pairs of items in the stream
whose similarity is greater than a given threshold. The simplest formulation of
the problem requires unbounded memory, and thus, it is intractable. To make the
problem feasible, we introduce the notion of time-dependent similarity: the
similarity of two items decreases with the difference in their arrival time. By
leveraging the properties of this time-dependent similarity function, we design
two algorithmic frameworks to solve the sssj problem. The first one, MiniBatch
(MB), uses existing index-based filtering techniques for the static version of
the problem, and combines them in a pipeline. The second framework, Streaming
(STR), adds time filtering to the existing indexes, and integrates new
time-based bounds deeply in the working of the algorithms. We also introduce a
new indexing technique (L2), which is based on an existing state-of-the-art
indexing technique (L2AP), but is optimized for the streaming case. Extensive
experiments show that the STR algorithm, when instantiated with the L2 index,
is the most scalable option across a wide array of datasets and parameters.</p>
</td>
    <td>
      
        DATASETS 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/genuzio2016fast/">Fast Scalable Construction Of (minimal Perfect Hash) Functions</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fast Scalable Construction Of (minimal Perfect Hash) Functions' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fast Scalable Construction Of (minimal Perfect Hash) Functions' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Genuzio Marco, Ottaviano Giuseppe, Vigna Sebastiano</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>19</td>
    <td><p>Recent advances in random linear systems on finite fields have paved the way
for the construction of constant-time data structures representing static
functions and minimal perfect hash functions using less space with respect to
existing techniques. The main obstruction for any practical application of
these results is the cubic-time Gaussian elimination required to solve these
linear systems: despite they can be made very small, the computation is still
too slow to be feasible.
  In this paper we describe in detail a number of heuristics and programming
techniques to speed up the resolution of these systems by several orders of
magnitude, making the overall construction competitive with the standard and
widely used MWHC technique, which is based on hypergraph peeling. In
particular, we introduce broadword programming techniques for fast equation
manipulation and a lazy Gaussian elimination algorithm. We also describe a
number of technical improvements to the data structure which further reduce
space usage and improve lookup speed.
  Our implementation of these techniques yields a minimal perfect hash function
data structure occupying 2.24 bits per element, compared to 2.68 for MWHC-based
ones, and a static function data structure which reduces the multiplicative
overhead from 1.23 to 1.03.</p>
</td>
    <td>
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/andoni2016approximate/">Approximate Near Neighbors For General Symmetric Norms</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Approximate Near Neighbors For General Symmetric Norms' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Approximate Near Neighbors For General Symmetric Norms' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Andoni et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of Computing</td>
    <td>24</td>
    <td><p>We show that every symmetric normed space admits an efficient nearest
neighbor search data structure with doubly-logarithmic approximation.
Specifically, for every \(n\), \(d = n^{o(1)}\), and every \(d\)-dimensional
symmetric norm \(|\cdot|\), there exists a data structure for
\(\mathrm{poly}(log log n)\)-approximate nearest neighbor search over
\(|\cdot|\) for \(n\)-point datasets achieving \(n^{o(1)}\) query time and
\(n^{1+o(1)}\) space. The main technical ingredient of the algorithm is a
low-distortion embedding of a symmetric norm into a low-dimensional iterated
product of top-\(k\) norms.
  We also show that our techniques cannot be extended to general norms.</p>
</td>
    <td>
      
        DATASETS 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/wu2016robust/">Robust Hashing For Multi-view Data: Jointly Learning Low-rank Kernelized Similarity Consensus And Hash Functions</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Robust Hashing For Multi-view Data: Jointly Learning Low-rank Kernelized Similarity Consensus And Hash Functions' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Robust Hashing For Multi-view Data: Jointly Learning Low-rank Kernelized Similarity Consensus And Hash Functions' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wu Lin, Wang Yang</td> <!-- ðŸ”§ You were missing this -->
    <td>Image and Vision Computing</td>
    <td>49</td>
    <td><p>Learning hash functions/codes for similarity search over multi-view data is
attracting increasing attention, where similar hash codes are assigned to the
data objects characterizing consistently neighborhood relationship across
views. Traditional methods in this category inherently suffer three
limitations: 1) they commonly adopt a two-stage scheme where similarity matrix
is first constructed, followed by a subsequent hash function learning; 2) these
methods are commonly developed on the assumption that data samples with
multiple representations are noise-free,which is not practical in real-life
applications; 3) they often incur cumbersome training model caused by the
neighborhood graph construction using all \(N\) points in the database (\(O(N)\)).
In this paper, we motivate the problem of jointly and efficiently training the
robust hash functions over data objects with multi-feature representations
which may be noise corrupted. To achieve both the robustness and training
efficiency, we propose an approach to effectively and efficiently learning
low-rank kernelized \footnote{We use kernelized similarity rather than kernel,
as it is not a squared symmetric matrix for data-landmark affinity matrix.}
hash functions shared across views. Specifically, we utilize landmark graphs to
construct tractable similarity matrices in multi-views to automatically
discover neighborhood structure in the data. To learn robust hash functions, a
latent low-rank kernel function is used to construct hash functions in order to
accommodate linearly inseparable data. In particular, a latent kernelized
similarity matrix is recovered by rank minimization on multiple kernel-based
similarity matrices. Extensive experiments on real-world multi-view datasets
validate the efficacy of our method in the presence of error corruptions.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Graph Based ANN 
      
        Efficiency And Optimization 
      
        Similarity Search 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/abeywickrama2016k/">K-nearest Neighbors On Road Networks: A Journey In Experimentation And In-memory Implementation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=K-nearest Neighbors On Road Networks: A Journey In Experimentation And In-memory Implementation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=K-nearest Neighbors On Road Networks: A Journey In Experimentation And In-memory Implementation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Abeywickrama Tenindra, Cheema Muhammad Aamir, Taniar David</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>25</td>
    <td><p>A k nearest neighbor (kNN) query on road networks retrieves the k closest
points of interest (POIs) by their network distances from a given location.
Today, in the era of ubiquitous mobile computing, this is a highly pertinent
query. While Euclidean distance has been used as a heuristic to search for the
closest POIs by their road network distance, its efficacy has not been
thoroughly investigated. The most recent methods have shown significant
improvement in query performance. Earlier studies, which proposed disk-based
indexes, were compared to the current state-of-the-art in main memory. However,
recent studies have shown that main memory comparisons can be challenging and
require careful adaptation. This paper presents an extensive experimental
investigation in main memory to settle these and several other issues. We use
efficient and fair memory-resident implementations of each method to reproduce
past experiments and conduct additional comparisons for several overlooked
evaluations. Notably we revisit a previously discarded technique (IER) showing
that, through a simple improvement, it is often the best performing technique.</p>
</td>
    <td>
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/jiang2016deep/">Deep Cross-modal Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Cross-modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Cross-modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Jiang Qing-yuan, Li Wu-jun</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>752</td>
    <td><p>Due to its low storage cost and fast query speed, cross-modal hashing (CMH)
has been widely used for similarity search in multimedia retrieval
applications. However, almost all existing CMH methods are based on
hand-crafted features which might not be optimally compatible with the
hash-code learning procedure. As a result, existing CMH methods with
handcrafted features may not achieve satisfactory performance. In this paper,
we propose a novel cross-modal hashing method, called deep crossmodal hashing
(DCMH), by integrating feature learning and hash-code learning into the same
framework. DCMH is an end-to-end learning framework with deep neural networks,
one for each modality, to perform feature learning from scratch. Experiments on
two real datasets with text-image modalities show that DCMH can outperform
other baselines to achieve the state-of-the-art performance in cross-modal
retrieval applications.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        CVPR 
      
        Similarity Search 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/indyk2016simultaneous/">Simultaneous Nearest Neighbor Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Simultaneous Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Simultaneous Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Indyk et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Pattern Recognition Letters</td>
    <td>195</td>
    <td><p>Motivated by applications in computer vision and databases, we introduce and
study the Simultaneous Nearest Neighbor Search (SNN) problem. Given a set of
data points, the goal of SNN is to design a data structure that, given a
collection of queries, finds a collection of close points that are compatible
with each other. Formally, we are given \(k\) query points \(Q=q_1,\cdots,q_k\),
and a compatibility graph \(G\) with vertices in \(Q\), and the goal is to return
data points \(p_1,\cdots,p_k\) that minimize (i) the weighted sum of the
distances from \(q_i\) to \(p_i\) and (ii) the weighted sum, over all edges \((i,j)\)
in the compatibility graph \(G\), of the distances between \(p_i\) and \(p_j\). The
problem has several applications, where one wants to return a set of consistent
answers to multiple related queries. This generalizes well-studied
computational problems, including NN, Aggregate NN and the 0-extension problem.
  In this paper we propose and analyze the following general two-step method
for designing efficient data structures for SNN. In the first step, for each
query point \(q_i\) we find its (approximate) nearest neighbor point \(\hat{p}_i\);
this can be done efficiently using existing approximate nearest neighbor
structures. In the second step, we solve an off-line optimization problem over
sets \(q_1,\cdots,q_k\) and \(\hat{p}_1,\cdots,\hat{p}_k\); this can be done
efficiently given that \(k\) is much smaller than \(n\). Even though
\(\hat{p}_1,\cdots,\hat{p}_k\) might not constitute the optimal answers to
queries \(q_1,\cdots,q_k\), we show that, for the unweighted case, the resulting
algorithm is \(O(log k/log log k)\)-approximation. Also, we show that the
approximation factor can be in fact reduced to a constant for compatibility
graphs frequently occurring in practice.
  Finally, we show that the â€œempirical approximation factorâ€ provided by the
above approach is very close to 1.</p>
</td>
    <td>
      
        Graph Based ANN 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/gehrig2016visual/">Visual Place Recognition With Probabilistic Vertex Voting</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Visual Place Recognition With Probabilistic Vertex Voting' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Visual Place Recognition With Probabilistic Vertex Voting' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Gehrig et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 IEEE International Conference on Robotics and Automation (ICRA)</td>
    <td>36</td>
    <td><p>We propose a novel scoring concept for visual place recognition based on
nearest neighbor descriptor voting and demonstrate how the algorithm naturally
emerges from the problem formulation. Based on the observation that the number
of votes for matching places can be evaluated using a binomial distribution
model, loop closures can be detected with high precision. By casting the
problem into a probabilistic framework, we not only remove the need for
commonly employed heuristic parameters but also provide a powerful score to
classify matching and non-matching places. We present methods for both a 2D-2D
pose-graph vertex matching and a 2D-3D landmark matching based on the above
scoring. The approach maintains accuracy while being efficient enough for
online application through the use of compact (low dimensional) descriptors and
fast nearest neighbor retrieval techniques. The proposed methods are evaluated
on several challenging datasets in varied environments, showing
state-of-the-art results with high precision and high recall.</p>
</td>
    <td>
      
        DATASETS 
      
        Tools & Libraries 
      
        Evaluation 
      
        ICRA 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/luo2016ssh/">SSH (sketch, Shingle, & Hash) For Indexing Massive-scale Time Series</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=SSH (sketch, Shingle, & Hash) For Indexing Massive-scale Time Series' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=SSH (sketch, Shingle, & Hash) For Indexing Massive-scale Time Series' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Luo Chen, Shrivastava Anshumali</td> <!-- ðŸ”§ You were missing this -->
    <td>Data Mining and Knowledge Discovery</td>
    <td>18</td>
    <td><p>Similarity search on time series is a frequent operation in large-scale
data-driven applications. Sophisticated similarity measures are standard for
time series matching, as they are usually misaligned. Dynamic Time Warping or
DTW is the most widely used similarity measure for time series because it
combines alignment and matching at the same time. However, the alignment makes
DTW slow. To speed up the expensive similarity search with DTW, branch and
bound based pruning strategies are adopted. However, branch and bound based
pruning are only useful for very short queries (low dimensional time series),
and the bounds are quite weak for longer queries. Due to the loose bounds
branch and bound pruning strategy boils down to a brute-force search.
  To circumvent this issue, we design SSH (Sketch, Shingle, &amp; Hashing), an
efficient and approximate hashing scheme which is much faster than the
state-of-the-art branch and bound searching technique: the UCR suite. SSH uses
a novel combination of sketching, shingling and hashing techniques to produce
(probabilistic) indexes which align (near perfectly) with DTW similarity
measure. The generated indexes are then used to create hash buckets for
sub-linear search. Our results show that SSH is very effective for longer time
sequence and prunes around 95% candidates, leading to the massive speedup in
search with DTW. Empirical results on two large-scale benchmark time series
data show that our proposed method can be around 20 times faster than the
state-of-the-art package (UCR suite) without any significant loss in accuracy.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/szeto2016binary/">Binary Codes For Tagging X-ray Images Via Deep De-noising Autoencoders</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Binary Codes For Tagging X-ray Images Via Deep De-noising Autoencoders' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Binary Codes For Tagging X-ray Images Via Deep De-noising Autoencoders' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Sze-to Antonio, Tizhoosh Hamid R., Wong Andrew K. C.</td> <!-- ðŸ”§ You were missing this -->
    <td>2016 International Joint Conference on Neural Networks (IJCNN)</td>
    <td>11</td>
    <td><p>A Content-Based Image Retrieval (CBIR) system which identifies similar
medical images based on a query image can assist clinicians for more accurate
diagnosis. The recent CBIR research trend favors the construction and use of
binary codes to represent images. Deep architectures could learn the non-linear
relationship among image pixels adaptively, allowing the automatic learning of
high-level features from raw pixels. However, most of them require class
labels, which are expensive to obtain, particularly for medical images. The
methods which do not need class labels utilize a deep autoencoder for binary
hashing, but the code construction involves a specific training algorithm and
an ad-hoc regularization technique. In this study, we explored using a deep
de-noising autoencoder (DDA), with a new unsupervised training scheme using
only backpropagation and dropout, to hash images into binary codes. We
conducted experiments on more than 14,000 x-ray images. By using class labels
only for evaluating the retrieval results, we constructed a 16-bit DDA and a
512-bit DDA independently. Comparing to other unsupervised methods, we
succeeded to obtain the lowest total error by using the 512-bit codes for
retrieval via exhaustive search, and speed up 9.27 times with the use of the
16-bit codes while keeping a comparable total error. We found that our new
training scheme could reduce the total retrieval error significantly by 21.9%.
To further boost the image retrieval performance, we developed Radon
Autoencoder Barcode (RABC) which are learned from the Radon projections of
images using a de-noising autoencoder. Experimental results demonstrated its
superior performance in retrieval when it was combined with DDA binary codes.</p>
</td>
    <td>
      
        Compact Codes 
      
        Image Retrieval 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/do2016learning/">Learning To Hash With Binary Deep Neural Network</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning To Hash With Binary Deep Neural Network' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning To Hash With Binary Deep Neural Network' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Do Thanh-toan, Doan Anh-dzung, Cheung Ngai-man</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>168</td>
    <td><p>This work proposes deep network models and learning algorithms for
unsupervised and supervised binary hashing. Our novel network design constrains
one hidden layer to directly output the binary codes. This addresses a
challenging issue in some previous works: optimizing non-smooth objective
functions due to binarization. Moreover, we incorporate independence and
balance properties in the direct and strict forms in the learning. Furthermore,
we include similarity preserving property in our objective function. Our
resulting optimization with these binary, independence, and balance constraints
is difficult to solve. We propose to attack it with alternating optimization
and careful relaxation. Experimental results on three benchmark datasets show
that our proposed methods compare favorably with the state of the art.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Alt 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/zhou2016transfer/">Transfer Hashing With Privileged Information</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Transfer Hashing With Privileged Information' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Transfer Hashing With Privileged Information' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhou et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>25</td>
    <td><p>Most existing learning to hash methods assume that there are sufficient data,
either labeled or unlabeled, on the domain of interest (i.e., the target
domain) for training. However, this assumption cannot be satisfied in some
real-world applications. To address this data sparsity issue in hashing,
inspired by transfer learning, we propose a new framework named Transfer
Hashing with Privileged Information (THPI). Specifically, we extend the
standard learning to hash method, Iterative Quantization (ITQ), in a transfer
learning manner, namely ITQ+. In ITQ+, a new slack function is learned from
auxiliary data to approximate the quantization error in ITQ. We developed an
alternating optimization approach to solve the resultant optimization problem
for ITQ+. We further extend ITQ+ to LapITQ+ by utilizing the geometry structure
among the auxiliary data for learning more precise binary codes in the target
domain. Extensive experiments on several benchmark datasets verify the
effectiveness of our proposed approaches through comparisons with several
state-of-the-art baselines.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
        Compact Codes 
      
        Alt 
      
        Quantization 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/kennedy2016fast/">Fast Cross-polytope Locality-sensitive Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fast Cross-polytope Locality-sensitive Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fast Cross-polytope Locality-sensitive Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Kennedy Christopher, Ward Rachel</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>9</td>
    <td><p>We provide a variant of cross-polytope locality sensitive hashing with
respect to angular distance which is provably optimal in asymptotic sensitivity
and enjoys \(\mathcal{O}(d \ln d )\) hash computation time. Building on a recent
result (by Andoni, Indyk, Laarhoven, Razenshteyn, Schmidt, 2015), we show that
optimal asymptotic sensitivity for cross-polytope LSH is retained even when the
dense Gaussian matrix is replaced by a fast Johnson-Lindenstrauss transform
followed by discrete pseudo-rotation, reducing the hash computation time from
\(\mathcal{O}(d^2)\) to \(\mathcal{O}(d \ln d )\). Moreover, our scheme achieves
the optimal rate of convergence for sensitivity. By incorporating a
low-randomness Johnson-Lindenstrauss transform, our scheme can be modified to
require only \(\mathcal{O}(\ln^9(d))\) random bits</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/yang2016zero/">Zero-shot Hashing Via Transferring Supervised Knowledge</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Zero-shot Hashing Via Transferring Supervised Knowledge' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Zero-shot Hashing Via Transferring Supervised Knowledge' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 24th ACM international conference on Multimedia</td>
    <td>138</td>
    <td><p>Hashing has shown its efficiency and effectiveness in facilitating
large-scale multimedia applications. Supervised knowledge e.g. semantic labels
or pair-wise relationship) associated to data is capable of significantly
improving the quality of hash codes and hash functions. However, confronted
with the rapid growth of newly-emerging concepts and multimedia data on the
Web, existing supervised hashing approaches may easily suffer from the scarcity
and validity of supervised information due to the expensive cost of manual
labelling. In this paper, we propose a novel hashing scheme, termed
<em>zero-shot hashing</em> (ZSH), which compresses images of â€œunseenâ€ categories
to binary codes with hash functions learned from limited training data of
â€œseenâ€ categories. Specifically, we project independent data labels i.e.
0/1-form label vectors) into semantic embedding space, where semantic
relationships among all the labels can be precisely characterized and thus seen
supervised knowledge can be transferred to unseen classes. Moreover, in order
to cope with the semantic shift problem, we rotate the embedded space to more
suitably align the embedded semantics with the low-level visual feature space,
thereby alleviating the influence of semantic gap. In the meantime, to exert
positive effects on learning high-quality hash functions, we further propose to
preserve local structural property and discrete nature in binary codes.
Besides, we develop an efficient alternating algorithm to solve the ZSH model.
Extensive experiments conducted on various real-life datasets show the superior
zero-shot image retrieval performance of ZSH as compared to several
state-of-the-art hashing methods.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Compact Codes 
      
        Alt 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/wurzer2016randomised/">Randomised Relevance Model</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Randomised Relevance Model' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Randomised Relevance Model' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wurzer Dominik, Osborne Miles, Lavrenko Victor</td> <!-- ðŸ”§ You were missing this -->
    <td>The Lancet Oncology</td>
    <td>81</td>
    <td><p>Relevance Models are well-known retrieval models and capable of producing
competitive results. However, because they use query expansion they can be very
slow. We address this slowness by incorporating two variants of locality
sensitive hashing (LSH) into the query expansion process. Results on two
document collections suggest that we can obtain large reductions in the amount
of work, with a small reduction in effectiveness. Our approach is shown to be
additive when pruning query terms.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/uchida2016image/">Image Retrieval With Fisher Vectors Of Binary Features</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Image Retrieval With Fisher Vectors Of Binary Features' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Image Retrieval With Fisher Vectors Of Binary Features' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Uchida Yusuke, Sakazawa Shigeyuki, Satoh Shin'ichi</td> <!-- ðŸ”§ You were missing this -->
    <td>2013 2nd IAPR Asian Conference on Pattern Recognition</td>
    <td>13</td>
    <td><p>Recently, the Fisher vector representation of local features has attracted
much attention because of its effectiveness in both image classification and
image retrieval. Another trend in the area of image retrieval is the use of
binary features such as ORB, FREAK, and BRISK. Considering the significant
performance improvement for accuracy in both image classification and retrieval
by the Fisher vector of continuous feature descriptors, if the Fisher vector
were also to be applied to binary features, we would receive similar benefits
in binary feature based image retrieval and classification. In this paper, we
derive the closed-form approximation of the Fisher vector of binary features
modeled by the Bernoulli mixture model. We also propose accelerating the Fisher
vector by using the approximate value of posterior probability. Experiments
show that the Fisher vector representation significantly improves the accuracy
of image retrieval compared with a bag of binary words approach.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/ning2016scalable/">Scalable Image Retrieval By Sparse Product Quantization</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Scalable Image Retrieval By Sparse Product Quantization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Scalable Image Retrieval By Sparse Product Quantization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ning et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Multimedia</td>
    <td>40</td>
    <td><p>Fast Approximate Nearest Neighbor (ANN) search technique for high-dimensional
feature indexing and retrieval is the crux of large-scale image retrieval. A
recent promising technique is Product Quantization, which attempts to index
high-dimensional image features by decomposing the feature space into a
Cartesian product of low dimensional subspaces and quantizing each of them
separately. Despite the promising results reported, their quantization approach
follows the typical hard assignment of traditional quantization methods, which
may result in large quantization errors and thus inferior search performance.
Unlike the existing approaches, in this paper, we propose a novel approach
called Sparse Product Quantization (SPQ) to encoding the high-dimensional
feature vectors into sparse representation. We optimize the sparse
representations of the feature vectors by minimizing their quantization errors,
making the resulting representation is essentially close to the original data
in practice. Experiments show that the proposed SPQ technique is not only able
to compress data, but also an effective encoding technique. We obtain
state-of-the-art results for ANN search on four public image datasets and the
promising results of content-based image retrieval further validate the
efficacy of our proposed method.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Similarity Search 
      
        Quantization 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/shen2016learning/">Learning Binary Codes And Binary Weights For Efficient Classification</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning Binary Codes And Binary Weights For Efficient Classification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning Binary Codes And Binary Weights For Efficient Classification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Shen et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Communications Letters</td>
    <td>111</td>
    <td><p>This paper proposes a generic formulation that significantly expedites the
training and deployment of image classification models, particularly under the
scenarios of many image categories and high feature dimensions. As a defining
property, our method represents both the images and learned classifiers using
binary hash codes, which are simultaneously learned from the training data.
Classifying an image thereby reduces to computing the Hamming distance between
the binary codes of the image and classifiers and selecting the class with
minimal Hamming distance. Conventionally, compact hash codes are primarily used
for accelerating image search. Our work is first of its kind to represent
classifiers using binary codes. Specifically, we formulate multi-class image
classification as an optimization problem over binary variables. The
optimization alternatively proceeds over the binary classifiers and image hash
codes. Profiting from the special property of binary codes, we show that the
sub-problems can be efficiently solved through either a binary quadratic
program (BQP) or linear program. In particular, for attacking the BQP problem,
we propose a novel bit-flipping procedure which enjoys high efficacy and local
optimality guarantee. Our formulation supports a large family of empirical loss
functions and is here instantiated by exponential / hinge losses. Comprehensive
evaluations are conducted on several representative image benchmarks. The
experiments consistently observe reduced complexities of model training and
deployment, without sacrifice of accuracies.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Compact Codes 
      
        Alt 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/li2016theory/">Theory Of The GMM Kernel</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Theory Of The GMM Kernel' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Theory Of The GMM Kernel' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li Ping, Zhang Cun-hui</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 26th International Conference on World Wide Web</td>
    <td>15</td>
    <td><p>We develop some theoretical results for a robust similarity measure named
â€œgeneralized min-maxâ€ (GMM). This similarity has direct applications in machine
learning as a positive definite kernel and can be efficiently computed via
probabilistic hashing. Owing to the discrete nature, the hashed values can also
be used for efficient near neighbor search. We prove the theoretical limit of
GMM and the consistency result, assuming that the data follow an elliptical
distribution, which is a very general family of distributions and includes the
multivariate \(t\)-distribution as a special case. The consistency result holds
as long as the data have bounded first moment (an assumption which essentially
holds for datasets commonly encountered in practice). Furthermore, we establish
the asymptotic normality of GMM. Compared to the â€œcosineâ€ similarity which is
routinely adopted in current practice in statistics and machine learning, the
consistency of GMM requires much weaker conditions. Interestingly, when the
data follow the \(t\)-distribution with \(\nu\) degrees of freedom, GMM typically
provides a better measure of similarity than â€œcosineâ€ roughly when \(\nu&lt;8\)
(which is already very close to normal). These theoretical results will help
explain the recent success of GMM in learning tasks.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/podlesnaya2016deep/">Deep Learning Based Semantic Video Indexing And Retrieval</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Learning Based Semantic Video Indexing And Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Learning Based Semantic Video Indexing And Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Podlesnaya Anna, Podlesnyy Sergey</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Networks and Systems</td>
    <td>20</td>
    <td><p>We share the implementation details and testing results for video retrieval
system based exclusively on features extracted by convolutional neural
networks. We show that deep learned features might serve as universal signature
for semantic content of video useful in many search and retrieval tasks. We
further show that graph-based storage structure for video index allows to
efficiently retrieving the content with complicated spatial and temporal search
queries.</p>
</td>
    <td>
      
        Graph Based ANN 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/wang2016deep/">Deep Supervised Hashing With Triplet Labels</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Supervised Hashing With Triplet Labels' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Supervised Hashing With Triplet Labels' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang Xiaofang, Shi Yi, Kitani Kris M.</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>191</td>
    <td><p>Hashing is one of the most popular and powerful approximate nearest neighbor
search techniques for large-scale image retrieval. Most traditional hashing
methods first represent images as off-the-shelf visual features and then
produce hashing codes in a separate stage. However, off-the-shelf visual
features may not be optimally compatible with the hash code learning procedure,
which may result in sub-optimal hash codes. Recently, deep hashing methods have
been proposed to simultaneously learn image features and hash codes using deep
neural networks and have shown superior performance over traditional hashing
methods. Most deep hashing methods are given supervised information in the form
of pairwise labels or triplet labels. The current state-of-the-art deep hashing
method DPSH~\cite{li2015feature}, which is based on pairwise labels, performs
image feature learning and hash code learning simultaneously by maximizing the
likelihood of pairwise similarities. Inspired by DPSH~\cite{li2015feature}, we
propose a triplet label based deep hashing method which aims to maximize the
likelihood of the given triplet labels. Experimental results show that our
method outperforms all the baselines on CIFAR-10 and NUS-WIDE datasets,
including the state-of-the-art method DPSH~\cite{li2015feature} and all the
previous triplet label based deep hashing methods.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Hashing Methods 
      
        Neural Hashing 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/dirksen2016fast/">Fast Binary Embeddings With Gaussian Circulant Matrices: Improved Bounds</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fast Binary Embeddings With Gaussian Circulant Matrices: Improved Bounds' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fast Binary Embeddings With Gaussian Circulant Matrices: Improved Bounds' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Dirksen Sjoerd, Stollenwerk Alexander</td> <!-- ðŸ”§ You were missing this -->
    <td>Discrete &amp; Computational Geometry</td>
    <td>13</td>
    <td><p>We consider the problem of encoding a finite set of vectors into a small
number of bits while approximately retaining information on the angular
distances between the vectors. By deriving improved variance bounds related to
binary Gaussian circulant embeddings, we largely fix a gap in the proof of the
best known fast binary embedding method. Our bounds also show that
well-spreadness assumptions on the data vectors, which were needed in earlier
work on variance bounds, are unnecessary. In addition, we propose a new binary
embedding with a faster running time on sparse data.</p>
</td>
    <td>
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/do2016embedding/">Embedding Based On Function Approximation For Large Scale Image Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Embedding Based On Function Approximation For Large Scale Image Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Embedding Based On Function Approximation For Large Scale Image Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Do Thanh-toan, Cheung Ngai-man</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Pattern Analysis and Machine Intelligence</td>
    <td>37</td>
    <td><p>The objective of this paper is to design an embedding method that maps local
features describing an image (e.g. SIFT) to a higher dimensional representation
useful for the image retrieval problem. First, motivated by the relationship
between the linear approximation of a nonlinear function in high dimensional
space and the stateof-the-art feature representation used in image retrieval,
i.e., VLAD, we propose a new approach for the approximation. The embedded
vectors resulted by the function approximation process are then aggregated to
form a single representation for image retrieval. Second, in order to make the
proposed embedding method applicable to large scale problem, we further derive
its fast version in which the embedded vectors can be efficiently computed,
i.e., in the closed-form. We compare the proposed embedding methods with the
state of the art in the context of image search under various settings: when
the images are represented by medium length vectors, short vectors, or binary
vectors. The experimental results show that the proposed embedding methods
outperform existing the state of the art on the standard public image retrieval
benchmarks.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/curtin2016fast/">Fast Approximate Furthest Neighbors With Data-dependent Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fast Approximate Furthest Neighbors With Data-dependent Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fast Approximate Furthest Neighbors With Data-dependent Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Curtin Ryan R., Gardner Andrew B.</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>9</td>
    <td><p>We present a novel hashing strategy for approximate furthest neighbor search
that selects projection bases using the data distribution. This strategy leads
to an algorithm, which we call DrusillaHash, that is able to outperform
existing approximate furthest neighbor strategies. Our strategy is motivated by
an empirical study of the behavior of the furthest neighbor search problem,
which lends intuition for where our algorithm is most useful. We also present a
variant of the algorithm that gives an absolute approximation guarantee; to our
knowledge, this is the first such approximate furthest neighbor hashing
approach to give such a guarantee. Performance studies indicate that
DrusillaHash can achieve comparable levels of approximation to other algorithms
while giving up to an order of magnitude speedup. An implementation is
available in the mlpack machine learning library (found at
http://www.mlpack.org).</p>
</td>
    <td>
      
        Tools & Libraries 
      
        Hashing Methods 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/pachori2016zero/">Zero Shot Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Zero Shot Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Zero Shot Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Pachori Shubham, Raman Shanmuganathan</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 24th ACM international conference on Multimedia</td>
    <td>138</td>
    <td><p>This paper provides a framework to hash images containing instances of
unknown object classes. In many object recognition problems, we might have
access to huge amount of data. It may so happen that even this huge data
doesnâ€™t cover the objects belonging to classes that we see in our day to day
life. Zero shot learning exploits auxiliary information (also called as
signatures) in order to predict the labels corresponding to unknown classes. In
this work, we attempt to generate the hash codes for images belonging to unseen
classes, information of which is available only through the textual corpus. We
formulate this as an unsupervised hashing formulation as the exact labels are
not available for the instances of unseen classes. We show that the proposed
solution is able to generate hash codes which can predict labels corresponding
to unseen classes with appreciably good precision.</p>
</td>
    <td>
      
        Tools & Libraries 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/zhu2016radon/">Radon Features And Barcodes For Medical Image Retrieval Via SVM</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Radon Features And Barcodes For Medical Image Retrieval Via SVM' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Radon Features And Barcodes For Medical Image Retrieval Via SVM' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhu Shujin, Tizhoosh H. R.</td> <!-- ðŸ”§ You were missing this -->
    <td>2016 International Joint Conference on Neural Networks (IJCNN)</td>
    <td>12</td>
    <td><p>For more than two decades, research has been performed on content-based image
retrieval (CBIR). By combining Radon projections and the support vector
machines (SVM), a content-based medical image retrieval method is presented in
this work. The proposed approach employs the normalized Radon projections with
corresponding image category labels to build an SVM classifier, and the Radon
barcode database which encodes every image in a binary format is also generated
simultaneously to tag all images. To retrieve similar images when a query image
is given, Radon projections and the barcode of the query image are generated.
Subsequently, the k-nearest neighbor search method is applied to find the
images with minimum Hamming distance of the Radon barcode within the same class
predicted by the trained SVM classifier that uses Radon features. The
performance of the proposed method is validated by using the IRMA 2009 dataset
with 14,410 x-ray images in 57 categories. The results demonstrate that our
method has the capacity to retrieve similar responses for the correctly
identified query image and even for those mistakenly classified by SVM. The
approach further is very fast and has low memory requirement.</p>
</td>
    <td>
      
        Image Retrieval 
      
        DATASETS 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/zhou2016generic/">A Generic Inverted Index Framework For Similarity Search On The GPU - Technical Report</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Generic Inverted Index Framework For Similarity Search On The GPU - Technical Report' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Generic Inverted Index Framework For Similarity Search On The GPU - Technical Report' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhou et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2018 IEEE 34th International Conference on Data Engineering (ICDE)</td>
    <td>11</td>
    <td><p>We propose a novel generic inverted index framework on the GPU (called
GENIE), aiming to reduce the programming complexity of the GPU for parallel
similarity search of different data types. Not every data type and similarity
measure are supported by GENIE, but many popular ones are. We present the
system design of GENIE, and demonstrate similarity search with GENIE on several
data types along with a theoretical analysis of search results. A new concept
of locality sensitive hashing (LSH) named \(\tau\)-ANN search, and a novel data
structure c-PQ on the GPU are also proposed for achieving this purpose.
Extensive experiments on different real-life datasets demonstrate the
efficiency and effectiveness of our framework. The implemented system has been
released as open source.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        DATASETS 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Similarity Search 
      
        Quantization 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/wang2016survey/">A Survey On Learning To Hash</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Survey On Learning To Hash' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Survey On Learning To Hash' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Pattern Analysis and Machine Intelligence</td>
    <td>920</td>
    <td><p>Nearest neighbor search is a problem of finding the data points from the
database such that the distances from them to the query point are the smallest.
Learning to hash is one of the major solutions to this problem and has been
widely studied recently. In this paper, we present a comprehensive survey of
the learning to hash algorithms, categorize them according to the manners of
preserving the similarities into: pairwise similarity preserving, multiwise
similarity preserving, implicit similarity preserving, as well as quantization,
and discuss their relations. We separate quantization from pairwise similarity
preserving as the objective function is very different though quantization, as
we show, can be derived from preserving the pairwise similarities. In addition,
we present the evaluation protocols, and the general performance analysis, and
point out that the quantization algorithms perform superiorly in terms of
search accuracy, search time cost, and space cost. Finally, we introduce a few
emerging topics.</p>
</td>
    <td>
      
        Survey Paper 
      
        Quantization 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/do2016binary/">Binary Hashing With Semidefinite Relaxation And Augmented Lagrangian</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Binary Hashing With Semidefinite Relaxation And Augmented Lagrangian' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Binary Hashing With Semidefinite Relaxation And Augmented Lagrangian' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Do et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>20</td>
    <td><p>This paper proposes two approaches for inferencing binary codes in two-step
(supervised, unsupervised) hashing. We first introduce an unified formulation
for both supervised and unsupervised hashing. Then, we cast the learning of one
bit as a Binary Quadratic Problem (BQP). We propose two approaches to solve
BQP. In the first approach, we relax BQP as a semidefinite programming problem
which its global optimum can be achieved. We theoretically prove that the
objective value of the binary solution achieved by this approach is well
bounded. In the second approach, we propose an augmented Lagrangian based
approach to solve BQP directly without relaxing the binary constraint.
Experimental results on three benchmark datasets show that our proposed methods
compare favorably with the state of the art.</p>
</td>
    <td>
      
        Compact Codes 
      
        DATASETS 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/ravanbakhsh2016efficient/">Efficient Convolutional Neural Network With Binary Quantization Layer</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Efficient Convolutional Neural Network With Binary Quantization Layer' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Efficient Convolutional Neural Network With Binary Quantization Layer' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Ravanbakhsh et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2016 8th International Conference on Wireless Communications &amp; Signal Processing (WCSP)</td>
    <td>7</td>
    <td><p>In this paper we introduce a novel method for segmentation that can benefit
from general semantics of Convolutional Neural Network (CNN). Our segmentation
proposes visually and semantically coherent image segments. We use binary
encoding of CNN features to overcome the difficulty of the clustering on the
high-dimensional CNN feature space. These binary encoding can be embedded into
the CNN as an extra layer at the end of the network. This results in real-time
segmentation. To the best of our knowledge our method is the first attempt on
general semantic image segmentation using CNN. All the previous papers were
limited to few number of category of the images (e.g. PASCAL VOC). Experiments
show that our segmentation algorithm outperform the state-of-the-art
non-semantic segmentation methods by a large margin.</p>
</td>
    <td>
      
        Hashing Methods 
      
        Quantization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/li2016generalized/">Generalized Intersection Kernel</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Generalized Intersection Kernel' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Generalized Intersection Kernel' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li Ping</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE International Conference on Image Processing 2005</td>
    <td>99</td>
    <td><p>Following the very recent line of work on the <code class="language-plaintext highlighter-rouge">generalized min-max'' (GMM)
kernel, this study proposes the</code>generalized intersectionâ€™â€™ (GInt) kernel and
the related <code class="language-plaintext highlighter-rouge">normalized generalized min-max'' (NGMM) kernel. In computer
vision, the (histogram) intersection kernel has been popular, and the GInt
kernel generalizes it to data which can have both negative and positive
entries. Through an extensive empirical classification study on 40 datasets
from the UCI repository, we are able to show that this (tuning-free) GInt
kernel performs fairly well.
  The empirical results also demonstrate that the NGMM kernel typically
outperforms the GInt kernel. Interestingly, the NGMM kernel has another
interpretation --- it is the</code>asymmetrically transformedâ€™â€™ version of the GInt
kernel, based on the idea of ``asymmetric hashingâ€™â€™. Just like the GMM kernel,
the NGMM kernel can be efficiently linearized through (e.g.,) generalized
consistent weighted sampling (GCWS), as empirically validated in our study.
Owing to the discrete nature of hashed values, it also provides a scheme for
approximate near neighbor search.</p>
</td>
    <td>
      
        DATASETS 
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/cheng2016adaptive/">Adaptive Training Of Random Mapping For Data Quantization</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Adaptive Training Of Random Mapping For Data Quantization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Adaptive Training Of Random Mapping For Data Quantization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Cheng Miao, Tsoi Ah Chung</td> <!-- ðŸ”§ You were missing this -->
    <td>2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>36</td>
    <td><p>Data quantization learns encoding results of data with certain requirements,
and provides a broad perspective of many real-world applications to data
handling. Nevertheless, the results of encoder is usually limited to
multivariate inputs with the random mapping, and side information of binary
codes are hardly to mostly depict the original data patterns as possible. In
the literature, cosine based random quantization has attracted much attentions
due to its intrinsic bounded results. Nevertheless, it usually suffers from the
uncertain outputs, and information of original data fails to be fully preserved
in the reduced codes. In this work, a novel binary embedding method, termed
adaptive training quantization (ATQ), is proposed to learn the ideal transform
of random encoder, where the limitation of cosine random mapping is tackled. As
an adaptive learning idea, the reduced mapping is adaptively calculated with
idea of data group, while the bias of random transform is to be improved to
hold most matching information. Experimental results show that the proposed
method is able to obtain outstanding performance compared with other random
quantization methods.</p>
</td>
    <td>
      
        CVPR 
      
        Quantization 
      
        Hashing Methods 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/christiani2016set/">Set Similarity Search Beyond Minhash</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Set Similarity Search Beyond Minhash' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Set Similarity Search Beyond Minhash' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Christiani Tobias, Pagh Rasmus</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of Computing</td>
    <td>45</td>
    <td><p>We consider the problem of approximate set similarity search under
Braun-Blanquet similarity \(B(\mathbf{x}, \mathbf{y}) = |\mathbf{x} \cap
\mathbf{y}| / \max(|\mathbf{x}|, |\mathbf{y}|)\). The \((b_2, b_2)\)-approximate
Braun-Blanquet similarity search problem is to preprocess a collection of sets
\(P\) such that, given a query set \(\mathbf{q}\), if there exists \(\mathbf{x} \in
P\) with \(B(\mathbf{q}, \mathbf{x}) \geq b_1\), then we can efficiently return
\(\mathbf{x}â€™ \in P\) with \(B(\mathbf{q}, \mathbf{x}â€™) &gt; b_2\).
  We present a simple data structure that solves this problem with space usage
\(O(n^{1+\rho}log n + \sum_{\mathbf{x} \in P}|\mathbf{x}|)\) and query time
\(O(|\mathbf{q}|n^{\rho} log n)\) where \(n = |P|\) and \(\rho =
log(1/b_1)/log(1/b_2)\). Making use of existing lower bounds for
locality-sensitive hashing by Oâ€™Donnell et al. (TOCT 2014) we show that this
value of \(\rho\) is tight across the parameter space, i.e., for every choice of
constants \(0 &lt; b_2 &lt; b_1 &lt; 1\).
  In the case where all sets have the same size our solution strictly improves
upon the value of \(\rho\) that can be obtained through the use of
state-of-the-art data-independent techniques in the Indyk-Motwani
locality-sensitive hashing framework (STOC 1998) such as Broderâ€™s MinHash (CCS
1997) for Jaccard similarity and Andoni et al.â€™s cross-polytope LSH (NIPS 2015)
for cosine similarity. Surprisingly, even though our solution is
data-independent, for a large part of the parameter space we outperform the
currently best data-dependent method by Andoni and Razenshteyn (STOC 2015).</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Distance Metric Learning 
      
        Efficiency And Optimization 
      
        Similarity Search 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/christiani2016framework/">A Framework For Similarity Search With Space-time Tradeoffs Using Locality-sensitive Filtering</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=A Framework For Similarity Search With Space-time Tradeoffs Using Locality-sensitive Filtering' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=A Framework For Similarity Search With Space-time Tradeoffs Using Locality-sensitive Filtering' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Christiani Tobias</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>21</td>
    <td><p>We present a framework for similarity search based on Locality-Sensitive
Filtering (LSF), generalizing the Indyk-Motwani (STOC 1998) Locality-Sensitive
Hashing (LSH) framework to support space-time tradeoffs. Given a family of
filters, defined as a distribution over pairs of subsets of space with certain
locality-sensitivity properties, we can solve the approximate near neighbor
problem in \(d\)-dimensional space for an \(n\)-point data set with query time
\(dn^{\rho_q+o(1)}\), update time \(dn^{\rho_u+o(1)}\), and space usage \(dn + n^{1</p>
<ul>
  <li>\rho_u + o(1)}\). The space-time tradeoff is tied to the tradeoff between
query time and update time, controlled by the exponents \(\rho_q, \rho_u\) that
are determined by the filter family. Locality-sensitive filtering was
introduced by Becker et al. (SODA 2016) together with a framework yielding a
single, balanced, tradeoff between query time and space, further relying on the
assumption of an efficient oracle for the filter evaluation algorithm. We
extend the LSF framework to support space-time tradeoffs and through a
combination of existing techniques we remove the oracle assumption.
Building on a filter family for the unit sphere by Laarhoven (arXiv 2015) we
use a kernel embedding technique by Rahimi &amp; Recht (NIPS 2007) to show a
solution to the \((r,cr)\)-near neighbor problem in \(\ell_s^d\)-space for \(0 &lt; s
\leq 2\) with query and update exponents
\(\rho_q=\frac{c^s(1+\lambda)^2}{(c^s+\lambda)^2}\) and
\(\rho_u=\frac{c^s(1-\lambda)^2}{(c^s+\lambda)^2}\) where \(\lambda\in[-1,1]\) is a
tradeoff parameter. This result improves upon the space-time tradeoff of
Kapralov (PODS 2015) and is shown to be optimal in the case of a balanced
tradeoff. Finally, we show a lower bound for the space-time tradeoff on the
unit sphere that matches Laarhovenâ€™s and our own upper bound in the case of
random data.</li>
</ul>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Hashing Methods 
      
        Efficiency And Optimization 
      
        Similarity Search 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/pagh2016approximate/">Approximate Furthest Neighbor With Application To Annulus Query</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Approximate Furthest Neighbor With Application To Annulus Query' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Approximate Furthest Neighbor With Application To Annulus Query' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Pagh et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Information Systems</td>
    <td>10</td>
    <td><p>Much recent work has been devoted to approximate nearest neighbor queries.
Motivated by applications in recommender systems, we consider approximate
furthest neighbor (AFN) queries and present a simple, fast, and highly
practical data structure for answering AFN queries in high- dimensional
Euclidean space. The method builds on the technique of In- dyk (SODA 2003),
storing random projections to provide sublinear query time for AFN. However, we
introduce a different query algorithm, improving on Indykâ€™s approximation
factor and reducing the running time by a logarithmic factor. We also present a
variation based on a query- independent ordering of the database points; while
this does not have the provable approximation factor of the query-dependent
data structure, it offers significant improvement in time and space complexity.
We give a theoretical analysis, and experimental results. As an application,
the query-dependent approach is used for deriving a data structure for the
approximate annulus query problem, which is defined as follows: given an input
set S and two parameters r &gt; 0 and w &gt;= 1, construct a data structure that
returns for each query point q a point p in S such that the distance between p
and q is at least r/w and at most wr.</p>
</td>
    <td>
      
        Recommender Systems 
      
        Locality Sensitive Hashing 
      
        Graph Based ANN 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/conjeti2016deep/">Deep Residual Hashing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Residual Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Residual Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Conjeti et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEICE Transactions on Fundamentals of Electronics, Communications and Computer Sciences</td>
    <td>8</td>
    <td><p>Hashing aims at generating highly compact similarity preserving code words
which are well suited for large-scale image retrieval tasks.
  Most existing hashing methods first encode the images as a vector of
hand-crafted features followed by a separate binarization step to generate hash
codes. This two-stage process may produce sub-optimal encoding. In this paper,
for the first time, we propose a deep architecture for supervised hashing
through residual learning, termed Deep Residual Hashing (DRH), for an
end-to-end simultaneous representation learning and hash coding. The DRH model
constitutes four key elements: (1) a sub-network with multiple stacked residual
blocks; (2) hashing layer for binarization; (3) supervised retrieval loss
function based on neighbourhood component analysis for similarity preserving
embedding; and (4) hashing related losses and regularisation to control the
quantization error and improve the quality of hash coding. We present results
of extensive experiments on a large public chest x-ray image database with
co-morbidities and discuss the outcome showing substantial improvements over
the latest state-of-the art methods.</p>
</td>
    <td>
      
        Image Retrieval 
      
        Hashing Methods 
      
        Quantization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/connor2016hilbert/">Hilbert Exclusion: Improved Metric Search Through Finite Isometric Embeddings</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hilbert Exclusion: Improved Metric Search Through Finite Isometric Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hilbert Exclusion: Improved Metric Search Through Finite Isometric Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Connor et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>ACM Transactions on Information Systems (TOIS) 35 3 Article 17 (2016)</td>
    <td>18</td>
    <td><p>Most research into similarity search in metric spaces relies upon the
triangle inequality property. This property allows the space to be arranged
according to relative distances to avoid searching some subspaces. We show that
many common metric spaces, notably including those using Euclidean and
Jensen-Shannon distances, also have a stronger property, sometimes called the
four-point property: in essence, these spaces allow an isometric embedding of
any four points in three-dimensional Euclidean space, as well as any three
points in two-dimensional Euclidean space. In fact, we show that any space
which is isometrically embeddable in Hilbert space has the stronger property.
This property gives stronger geometric guarantees, and one in particular, which
we name the Hilbert Exclusion property, allows any indexing mechanism which
uses hyperplane partitioning to perform better. One outcome of this observation
is that a number of state-of-the-art indexing mechanisms over high dimensional
spaces can be easily extended to give a significant increase in performance;
furthermore, the improvement given is greater in higher dimensions. This
therefore leads to a significant improvement in the cost of metric search in
these spaces.</p>
</td>
    <td>
      
        Similarity Search 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2016</td>
    <td>
      <a href="/publications/clifford2016approximate/">Approximate Hamming Distance In A Stream</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Approximate Hamming Distance In A Stream' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Approximate Hamming Distance In A Stream' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Clifford Raphael, Starikovskaya Tatiana</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>9</td>
    <td><p>We consider the problem of computing a \((1+\epsilon)\)-approximation of the
Hamming distance between a pattern of length \(n\) and successive substrings of a
stream. We first look at the one-way randomised communication complexity of
this problem, giving Alice the first half of the stream and Bob the second
half. We show the following: (1) If Alice and Bob both share the pattern then
there is an \(O(\epsilon^{-4} log^2 n)\) bit randomised one-way communication
protocol. (2) If only Alice has the pattern then there is an
\(O(\epsilon^{-2}\sqrt{n}log n)\) bit randomised one-way communication protocol.
  We then go on to develop small space streaming algorithms for
\((1+\epsilon)\)-approximate Hamming distance which give worst case running time
guarantees per arriving symbol. (1) For binary input alphabets there is an
\(O(\epsilon^{-3} \sqrt{n} log^{2} n)\) space and \(O(\epsilon^{-2} log{n})\)
time streaming \((1+\epsilon)\)-approximate Hamming distance algorithm. (2) For
general input alphabets there is an \(O(\epsilon^{-5} \sqrt{n} log^{4} n)\)
space and \(O(\epsilon^{-4} log^3 {n})\) time streaming
\((1+\epsilon)\)-approximate Hamming distance algorithm.</p>
</td>
    <td>
      
    </td>
    </tr>      
    
    
      
     <tr>
  <td>2015</td>
    <td>
      <a href="/publications/yi2015binary/">Binary Embedding: Fundamental Limits And Fast Algorithm</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Binary Embedding: Fundamental Limits And Fast Algorithm' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Binary Embedding: Fundamental Limits And Fast Algorithm' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yi Xinyang, Caramanis Constantine, Price Eric</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>19</td>
    <td><p>Binary embedding is a nonlinear dimension reduction methodology where high
dimensional data are embedded into the Hamming cube while preserving the
structure of the original space. Specifically, for an arbitrary \(N\) distinct
points in \(\mathbb{S}^{p-1}\), our goal is to encode each point using
\(m\)-dimensional binary strings such that we can reconstruct their geodesic
distance up to \(\delta\) uniform distortion. Existing binary embedding
algorithms either lack theoretical guarantees or suffer from running time
\(O\big(mp\big)\). We make three contributions: (1) we establish a lower bound
that shows any binary embedding oblivious to the set of points requires \(m =
Î©(\frac{1}{\delta^2}log{N})\) bits and a similar lower bound for
non-oblivious embeddings into Hamming distance; (2) [DELETED, see comment]; (3)
we also provide an analytic result about embedding a general set of points \(K
\subseteq \mathbb{S}^{p-1}\) with even infinite size. Our theoretical findings
are supported through experiments on both synthetic and real data sets.</p>
</td>
    <td>
      
        Hashing Methods 
      
    </td>
    </tr>      
    
     <tr>
  <td>2015</td>
    <td>
      <a href="/publications/albrecht2015genoogle/">Genoogle: An Indexed And Parallelized Search Engine For Similar DNA Sequences</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Genoogle: An Indexed And Parallelized Search Engine For Similar DNA Sequences' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Genoogle: An Indexed And Parallelized Search Engine For Similar DNA Sequences' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Albrecht Felipe</td> <!-- ðŸ”§ You were missing this -->
    <td>Nucleic Acids Research</td>
    <td>9</td>
    <td><p>The search for similar genetic sequences is one of the main bioinformatics
tasks. The genetic sequences data banks are growing exponentially and the
searching techniques that use linear time are not capable to do the search in
the required time anymore. Another problem is that the clock speed of the
modern processors are not growing as it did before, instead, the processing
capacity is growing with the addiction of more processing cores and the
techniques which does not use parallel computing does not have benefits from
these extra cores. This work aims to use data indexing techniques to reduce the
searching process computation cost united with the parallelization of the
searching techniques to use the computational capacity of the multi core
processors. To verify the viability of using these two techniques
simultaneously, a software which uses parallelization techniques with inverted
indexes was developed.
  Experiments were executed to analyze the performance gain when parallelism is
utilized, the search time gain, and also the quality of the results when it
compared with others searching tools. The results of these experiments were
promising, the parallelism gain overcame the expected speedup, the searching
time was 20 times faster than the parallelized NCBI BLAST, and the searching
results showed a good quality when compared with this tool.
  The software source code is available at
https://github.com/felipealbrecht/Genoogle .</p>
</td>
    <td>
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2015</td>
    <td>
      <a href="/publications/yang2015beyond/">Beyond Classification: Latent User Interests Profiling From Visual Contents Analysis</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Beyond Classification: Latent User Interests Profiling From Visual Contents Analysis' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Beyond Classification: Latent User Interests Profiling From Visual Contents Analysis' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Yang Longqi, Hsieh Cheng-kang, Estrin Deborah</td> <!-- ðŸ”§ You were missing this -->
    <td>2015 IEEE International Conference on Data Mining Workshop (ICDMW)</td>
    <td>22</td>
    <td><p>User preference profiling is an important task in modern online social
networks (OSN). With the proliferation of image-centric social platforms, such
as Pinterest, visual contents have become one of the most informative data
streams for understanding user preferences. Traditional approaches usually
treat visual content analysis as a general classification problem where one or
more labels are assigned to each image. Although such an approach simplifies
the process of image analysis, it misses the rich context and visual cues that
play an important role in peopleâ€™s perception of images. In this paper, we
explore the possibilities of learning a userâ€™s latent visual preferences
directly from image contents. We propose a distance metric learning method
based on Deep Convolutional Neural Networks (CNN) to directly extract
similarity information from visual contents and use the derived distance metric
to mine individual usersâ€™ fine-grained visual preferences. Through our
preliminary experiments using data from 5,790 Pinterest users, we show that
even for the images within the same category, each user possesses distinct and
individually-identifiable visual preferences that are consistent over their
lifetime. Our results underscore the untapped potential of finer-grained visual
preference profiling in understanding usersâ€™ preferences.</p>
</td>
    <td>
      
        Alt 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2015</td>
    <td>
      <a href="/publications/gouk2015fast/">Fast Metric Learning For Deep Neural Networks</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fast Metric Learning For Deep Neural Networks' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fast Metric Learning For Deep Neural Networks' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Gouk Henry, Pfahringer Bernhard, Cree Michael</td> <!-- ðŸ”§ You were missing this -->
    <td>2019 III International Conference on Control in Technical Systems (CTS)</td>
    <td>7</td>
    <td><p>Similarity metrics are a core component of many information retrieval and
machine learning systems. In this work we propose a method capable of learning
a similarity metric from data equipped with a binary relation. By considering
only the similarity constraints, and initially ignoring the features, we are
able to learn target vectors for each instance using one of several
appropriately designed loss functions. A regression model can then be
constructed that maps novel feature vectors to the same target vector space,
resulting in a feature extractor that computes vectors for which a predefined
metric is a meaningful measure of similarity. We present results on both
multiclass and multi-label classification datasets that demonstrate
considerably faster convergence, as well as higher accuracy on the majority of
the intrinsic evaluation tasks and all extrinsic evaluation tasks.</p>
</td>
    <td>
      
        DATASETS 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2015</td>
    <td>
      <a href="/publications/song2015deep/">Deep Metric Learning Via Lifted Structured Feature Embedding</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Deep Metric Learning Via Lifted Structured Feature Embedding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Deep Metric Learning Via Lifted Structured Feature Embedding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Song et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>1648</td>
    <td><p>Learning the distance metric between pairs of examples is of great importance
for learning and visual recognition. With the remarkable success from the state
of the art convolutional neural networks, recent works have shown promising
results on discriminatively training the networks to learn semantic feature
embeddings where similar examples are mapped close to each other and dissimilar
examples are mapped farther apart. In this paper, we describe an algorithm for
taking full advantage of the training batches in the neural network training by
lifting the vector of pairwise distances within the batch to the matrix of
pairwise distances. This step enables the algorithm to learn the state of the
art feature embedding by optimizing a novel structured prediction objective on
the lifted problem. Additionally, we collected Online Products dataset: 120k
images of 23k classes of online products for metric learning. Our experiments
on the CUB-200-2011, CARS196, and Online Products datasets demonstrate
significant improvement over existing deep feature embedding methods on all
experimented embedding sizes with the GoogLeNet network.</p>
</td>
    <td>
      
        CVPR 
      
        DATASETS 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2015</td>
    <td>
      <a href="/publications/schroff2015facenet/">Facenet: A Unified Embedding For Face Recognition And Clustering</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Facenet: A Unified Embedding For Face Recognition And Clustering' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Facenet: A Unified Embedding For Face Recognition And Clustering' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Schroff Florian, Kalenichenko Dmitry, Philbin James</td> <!-- ðŸ”§ You were missing this -->
    <td>2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</td>
    <td>8308</td>
    <td><p>Despite significant recent advances in the field of face recognition,
implementing face verification and recognition efficiently at scale presents
serious challenges to current approaches. In this paper we present a system,
called FaceNet, that directly learns a mapping from face images to a compact
Euclidean space where distances directly correspond to a measure of face
similarity. Once this space has been produced, tasks such as face recognition,
verification and clustering can be easily implemented using standard techniques
with FaceNet embeddings as feature vectors.
  Our method uses a deep convolutional network trained to directly optimize the
embedding itself, rather than an intermediate bottleneck layer as in previous
deep learning approaches. To train, we use triplets of roughly aligned matching
/ non-matching face patches generated using a novel online triplet mining
method. The benefit of our approach is much greater representational
efficiency: we achieve state-of-the-art face recognition performance using only
128-bytes per face.
  On the widely used Labeled Faces in the Wild (LFW) dataset, our system
achieves a new record accuracy of 99.63%. On YouTube Faces DB it achieves
95.12%. Our system cuts the error rate in comparison to the best published
result by 30% on both datasets.
  We also introduce the concept of harmonic embeddings, and a harmonic triplet
loss, which describe different versions of face embeddings (produced by
different networks) that are compatible to each other and allow for direct
comparison between each other.</p>
</td>
    <td>
      
        CVPR 
      
        DATASETS 
      
        Evaluation 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
    
      
     <tr>
  <td>2014</td>
    <td>
      <a href="/publications/csurka2014unsupervised/">Unsupervised Visual And Textual Information Fusion In Multimedia Retrieval - A Graph-based Point Of View</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Unsupervised Visual And Textual Information Fusion In Multimedia Retrieval - A Graph-based Point Of View' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Unsupervised Visual And Textual Information Fusion In Multimedia Retrieval - A Graph-based Point Of View' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Csurka Gabriela, Ah-pine Julien, Clinchant StÃ©phane</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>6</td>
    <td><p>Multimedia collections are more than ever growing in size and diversity.
Effective multimedia retrieval systems are thus critical to access these
datasets from the end-user perspective and in a scalable way. We are interested
in repositories of image/text multimedia objects and we study multimodal
information fusion techniques in the context of content based multimedia
information retrieval. We focus on graph based methods which have proven to
provide state-of-the-art performances. We particularly examine two of such
methods : cross-media similarities and random walk based scores. From a
theoretical viewpoint, we propose a unifying graph based framework which
encompasses the two aforementioned approaches. Our proposal allows us to
highlight the core features one should consider when using a graph based
technique for the combination of visual and textual information. We compare
cross-media and random walk based results using three different real-world
datasets. From a practical standpoint, our extended empirical analysis allow us
to provide insights and guidelines about the use of graph based methods for
multimodal information fusion in content based multimedia information
retrieval.</p>
</td>
    <td>
      
        Graph Based ANN 
      
        DATASETS 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2014</td>
    <td>
      <a href="/publications/weissman2014identifying/">Identifying Duplicate And Contradictory Information In Wikipedia</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Identifying Duplicate And Contradictory Information In Wikipedia' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Identifying Duplicate And Contradictory Information In Wikipedia' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Weissman et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries</td>
    <td>10</td>
    <td><p>Our study identifies sentences in Wikipedia articles that are either
identical or highly similar by applying techniques for near-duplicate detection
of web pages. This is accomplished with a MapReduce implementation of minhash
to identify clusters of sentences with high Jaccard similarity. We show that
these clusters can be categorized into six different types, two of which are
particularly interesting: identical sentences quantify the extent to which
content in Wikipedia is copied and pasted, and near-duplicate sentences that
state contradictory facts point to quality issues in Wikipedia.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2014</td>
    <td>
      <a href="/publications/gottlieb2014near/">Near-optimal Sample Compression For Nearest Neighbors</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Near-optimal Sample Compression For Nearest Neighbors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Near-optimal Sample Compression For Nearest Neighbors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Gottlieb Lee-ad, Kontorovich Aryeh, Nisnevitch Pinhas</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Information Theory</td>
    <td>22</td>
    <td><p>We present the first sample compression algorithm for nearest neighbors with
non-trivial performance guarantees. We complement these guarantees by
demonstrating almost matching hardness lower bounds, which show that our bound
is nearly optimal. Our result yields new insight into margin-based nearest
neighbor classification in metric spaces and allows us to significantly sharpen
and simplify existing bounds. Some encouraging empirical results are also
presented.</p>
</td>
    <td>
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2014</td>
    <td>
      <a href="/publications/rippel2014learning/">Learning Ordered Representations With Nested Dropout</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Learning Ordered Representations With Nested Dropout' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Learning Ordered Representations With Nested Dropout' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Rippel Oren, Gelbart Michael A., Adams Ryan P.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>49</td>
    <td><p>In this paper, we study ordered representations of data in which different
dimensions have different degrees of importance. To learn these representations
we introduce nested dropout, a procedure for stochastically removing coherent
nested sets of hidden units in a neural network. We first present a sequence of
theoretical results in the simple case of a semi-linear autoencoder. We
rigorously show that the application of nested dropout enforces identifiability
of the units, which leads to an exact equivalence with PCA. We then extend the
algorithm to deep models and demonstrate the relevance of ordered
representations to a number of applications. Specifically, we use the ordered
property of the learned codes to construct hash-based data structures that
permit very fast retrieval, achieving retrieval in time logarithmic in the
database size and independent of the dimensionality of the representation. This
allows codes that are hundreds of times longer than currently feasible for
retrieval. We therefore avoid the diminished quality associated with short
codes, while still performing retrieval that is competitive in speed with
existing methods. We also show that ordered representations are a promising way
to learn adaptive compression for efficient online data reconstruction.</p>
</td>
    <td>
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2014</td>
    <td>
      <a href="/publications/larocca2014density/">Density Adaptive Parallel Clustering</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Density Adaptive Parallel Clustering' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Density Adaptive Parallel Clustering' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>La Rocca Marcello</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Computational Social Systems</td>
    <td>5</td>
    <td><p>In this paper we are going to introduce a new nearest neighbours based
approach to clustering, and compare it with previous solutions; the resulting
algorithm, which takes inspiration from both DBscan and minimum spanning tree
approaches, is deterministic but proves simpler, faster and doesnt require to
set in advance a value for k, the number of clusters.</p>
</td>
    <td>
      
    </td>
    </tr>      
    
    
      
     <tr>
  <td>2013</td>
    <td>
      <a href="/publications/gog2013large/">Large-scale Pattern Search Using Reduced-space On-disk Suffix Arrays</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Large-scale Pattern Search Using Reduced-space On-disk Suffix Arrays' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Large-scale Pattern Search Using Reduced-space On-disk Suffix Arrays' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Gog et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>IEEE Transactions on Knowledge and Data Engineering</td>
    <td>21</td>
    <td><p>The suffix array is an efficient data structure for in-memory pattern search.
Suffix arrays can also be used for external-memory pattern search, via
two-level structures that use an internal index to identify the correct block
of suffix pointers. In this paper we describe a new two-level suffix
array-based index structure that requires significantly less disk space than
previous approaches. Key to the saving is the use of disk blocks that are based
on prefixes rather than the more usual uniform-sampling approach, allowing
reductions between blocks and subparts of other blocks. We also describe a new
in-memory structure based on a condensed BWT string, and show that it allows
common patterns to be resolved without access to the text. Experiments using 64
GB of English web text and a laptop computer with just 4 GB of main memory
demonstrate the speed and versatility of the new approach. For this data the
index is around one- third the size of previous two-level mechanisms; and the
memory footprint of as little as 1% of the text size means that queries can be
processed more quickly than is possible with a compact FM-INDEX.</p>
</td>
    <td>
      
        Vector Indexing 
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2013</td>
    <td>
      <a href="/publications/dasgupta2013randomized/">Randomized Partition Trees For Exact Nearest Neighbor Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Randomized Partition Trees For Exact Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Randomized Partition Trees For Exact Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Dasgupta Sanjoy, Sinha Kaushik</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>26</td>
    <td><p>The k-d tree was one of the first spatial data structures proposed for
nearest neighbor search. Its efficacy is diminished in high-dimensional spaces,
but several variants, with randomization and overlapping cells, have proved to
be successful in practice. We analyze three such schemes. We show that the
probability that they fail to find the nearest neighbor, for any data set and
any query point, is directly related to a simple potential function that
captures the difficulty of the point configuration. We then bound this
potential function in two situations of interest: the first, when data come
from a doubling measure, and the second, when the data are documents from a
topic model.</p>
</td>
    <td>
      
        Tree Based ANN 
      
    </td>
    </tr>      
    
     <tr>
  <td>2013</td>
    <td>
      <a href="/publications/elmehdwi2013secure/">Secure K-nearest Neighbor Query Over Encrypted Data In Outsourced Environments</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Secure K-nearest Neighbor Query Over Encrypted Data In Outsourced Environments' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Secure K-nearest Neighbor Query Over Encrypted Data In Outsourced Environments' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Elmehdwi Yousef, Samanthula Bharath K., Jiang Wei</td> <!-- ðŸ”§ You were missing this -->
    <td>2014 IEEE 30th International Conference on Data Engineering</td>
    <td>359</td>
    <td><p>For the past decade, query processing on relational data has been studied
extensively, and many theoretical and practical solutions to query processing
have been proposed under various scenarios. With the recent popularity of cloud
computing, users now have the opportunity to outsource their data as well as
the data management tasks to the cloud. However, due to the rise of various
privacy issues, sensitive data (e.g., medical records) need to be encrypted
before outsourcing to the cloud. In addition, query processing tasks should be
handled by the cloud; otherwise, there would be no point to outsource the data
at the first place. To process queries over encrypted data without the cloud
ever decrypting the data is a very challenging task. In this paper, we focus on
solving the k-nearest neighbor (kNN) query problem over encrypted database
outsourced to a cloud: a user issues an encrypted query record to the cloud,
and the cloud returns the k closest records to the user. We first present a
basic scheme and demonstrate that such a naive solution is not secure. To
provide better security, we propose a secure kNN protocol that protects the
confidentiality of the data, userâ€™s input query, and data access patterns.
Also, we empirically analyze the efficiency of our protocols through various
experiments. These results indicate that our secure protocol is very efficient
on the user end, and this lightweight scheme allows a user to use any mobile
device to perform the kNN query.</p>
</td>
    <td>
      
        Efficiency And Optimization 
      
    </td>
    </tr>      
    
     <tr>
  <td>2013</td>
    <td>
      <a href="/publications/li2013sign/">Sign Stable Projections, Sign Cauchy Projections And Chi-square Kernels</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Sign Stable Projections, Sign Cauchy Projections And Chi-square Kernels' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Sign Stable Projections, Sign Cauchy Projections And Chi-square Kernels' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Li Ping, Samorodnitsky Gennady, Hopcroft John</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings of the AAAI Conference on Artificial Intelligence</td>
    <td>6</td>
    <td><p>The method of stable random projections is popular for efficiently computing
the Lp distances in high dimension (where 0&lt;p&lt;=2), using small space. Because
it adopts nonadaptive linear projections, this method is naturally suitable
when the data are collected in a dynamic streaming fashion (i.e., turnstile
data streams). In this paper, we propose to use only the signs of the projected
data and analyze the probability of collision (i.e., when the two signs
differ). We derive a bound of the collision probability which is exact when p=2
and becomes less sharp when p moves away from 2. Interestingly, when p=1 (i.e.,
Cauchy random projections), we show that the probability of collision can be
accurately approximated as functions of the chi-square similarity. For example,
when the (un-normalized) data are binary, the maximum approximation error of
the collision probability is smaller than 0.0192. In text and vision
applications, the chi-square similarity is a popular measure for nonnegative
data when the features are generated from histograms. Our experiments confirm
that the proposed method is promising for large-scale learning applications.</p>
</td>
    <td>
      
        AAAI 
      
        Locality Sensitive Hashing 
      
    </td>
    </tr>      
    
    
      
     <tr>
  <td>2012</td>
    <td>
      <a href="/publications/xu2012distance/">Distance Metric Learning For Kernel Machines</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Distance Metric Learning For Kernel Machines' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Distance Metric Learning For Kernel Machines' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Xu Zhixiang, Weinberger Kilian Q., Chapelle Olivier</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>44</td>
    <td><p>Recent work in metric learning has significantly improved the
state-of-the-art in k-nearest neighbor classification. Support vector machines
(SVM), particularly with RBF kernels, are amongst the most popular
classification algorithms that uses distance metrics to compare examples. This
paper provides an empirical analysis of the efficacy of three of the most
popular Mahalanobis metric learning algorithms as pre-processing for SVM
training. We show that none of these algorithms generate metrics that lead to
particularly satisfying improvements for SVM-RBF classification. As a remedy we
introduce support vector metric learning (SVML), a novel algorithm that
seamlessly combines the learning of a Mahalanobis metric with the training of
the RBF-SVM parameters. We demonstrate the capabilities of SVML on nine
benchmark data sets of varying sizes and difficulties. In our study, SVML
outperforms all alternative state-of-the-art metric learning algorithms in
terms of accuracy and establishes itself as a serious alternative to the
standard Euclidean metric with model selection by cross validation.</p>
</td>
    <td>
      
        Alt 
      
        Evaluation 
      
        Distance Metric Learning 
      
    </td>
    </tr>      
    
     <tr>
  <td>2012</td>
    <td>
      <a href="/publications/zadeh2012dimension/">Dimension Independent Similarity Computation</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Dimension Independent Similarity Computation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Dimension Independent Similarity Computation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zadeh Reza Bosagh, Goel Ashish</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>53</td>
    <td><p>We present a suite of algorithms for Dimension Independent Similarity
Computation (DISCO) to compute all pairwise similarities between very high
dimensional sparse vectors. All of our results are provably independent of
dimension, meaning apart from the initial cost of trivially reading in the
data, all subsequent operations are independent of the dimension, thus the
dimension can be very large. We study Cosine, Dice, Overlap, and the Jaccard
similarity measures. For Jaccard similiarity we include an improved version of
MinHash. Our results are geared toward the MapReduce framework. We empirically
validate our theorems at large scale using data from the social networking site
Twitter. At time of writing, our algorithms are live in production at
twitter.com.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
     <tr>
  <td>2012</td>
    <td>
      <a href="/publications/cox2012large/">Large-scale Compression Of Genomic Sequence Databases With The Burrows-wheeler Transform</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Large-scale Compression Of Genomic Sequence Databases With The Burrows-wheeler Transform' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Large-scale Compression Of Genomic Sequence Databases With The Burrows-wheeler Transform' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Cox et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Bioinformatics</td>
    <td>139</td>
    <td><p>Motivation
  The Burrows-Wheeler transform (BWT) is the foundation of many algorithms for
compression and indexing of text data, but the cost of computing the BWT of
very large string collections has prevented these techniques from being widely
applied to the large sets of sequences often encountered as the outcome of DNA
sequencing experiments. In previous work, we presented a novel algorithm that
allows the BWT of human genome scale data to be computed on very moderate
hardware, thus enabling us to investigate the BWT as a tool for the compression
of such datasets.
  Results
  We first used simulated reads to explore the relationship between the level
of compression and the error rate, the length of the reads and the level of
sampling of the underlying genome and compare choices of second-stage
compression algorithm.
  We demonstrate that compression may be greatly improved by a particular
reordering of the sequences in the collection and give a novel `implicit
sortingâ€™ strategy that enables these benefits to be realised without the
overhead of sorting the reads. With these techniques, a 45x coverage of real
human genome sequence data compresses losslessly to under 0.5 bits per base,
allowing the 135.3Gbp of sequence to fit into only 8.2Gbytes of space (trimming
a small proportion of low-quality bases from the reads improves the compression
still further).
  This is more than 4 times smaller than the size achieved by a standard
BWT-based compressor (bzip2) on the untrimmed reads, but an important further
advantage of our approach is that it facilitates the building of compressed
full text indexes such as the FM-index on large-scale DNA sequence collections.</p>
</td>
    <td>
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2012</td>
    <td>
      <a href="/publications/duda2012optimal/">Optimal Compression Of Hash-origin Prefix Trees</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Optimal Compression Of Hash-origin Prefix Trees' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Optimal Compression Of Hash-origin Prefix Trees' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Duda Jarek</td> <!-- ðŸ”§ You were missing this -->
    <td>2017 ACM/IEEE Symposium on Architectures for Networking and Communications Systems (ANCS)</td>
    <td>9</td>
    <td><p>There is a common problem of operating on hash values of elements of some
database. In this paper there will be analyzed informational content of such
general task and how to practically approach such found lower boundaries.
Minimal prefix tree which distinguish elements turns out to require
asymptotically only about 2.77544 bits per element, while standard approaches
use a few times more. While being certain of working inside the database, the
cost of distinguishability can be reduced further to about 2.33275 bits per
elements. Increasing minimal depth of nodes to reduce probability of false
positives leads to simple relation with average depth of such random tree,
which is asymptotically larger by about 1.33275 bits than lg(n) of the perfect
binary tree. This asymptotic case can be also seen as a way to optimally encode
n large unordered numbers - saving lg(n!) bits of information about their
ordering, which can be the major part of contained information. This ability
itself allows to reduce memory requirements even to about 0.693 of required in
Bloom filter for the same false positive probability.</p>
</td>
    <td>
      
    </td>
    </tr>      
    
    
      
     <tr>
  <td>2011</td>
    <td>
      <a href="/publications/zhou2011hamming/">Hamming Compressed Sensing</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Hamming Compressed Sensing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Hamming Compressed Sensing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zhou Tianyi, Tao Dacheng</td> <!-- ðŸ”§ You were missing this -->
    <td>2012 IEEE International Symposium on Information Theory Proceedings</td>
    <td>7</td>
    <td><p>Compressed sensing (CS) and 1-bit CS cannot directly recover quantized
signals and require time consuming recovery. In this paper, we introduce
\textit{Hamming compressed sensing} (HCS) that directly recovers a k-bit
quantized signal of dimensional \(n\) from its 1-bit measurements via invoking
\(n\) times of Kullback-Leibler divergence based nearest neighbor search.
Compared with CS and 1-bit CS, HCS allows the signal to be dense, takes
considerably less (linear) recovery time and requires substantially less
measurements (\(\mathcal O(log n)\)). Moreover, HCS recovery can accelerate the
subsequent 1-bit CS dequantizer. We study a quantized recovery error bound of
HCS for general signals and â€œHCS+dequantizerâ€ recovery error bound for sparse
signals. Extensive numerical simulations verify the appealing accuracy,
robustness, efficiency and consistency of HCS.</p>
</td>
    <td>
      
        Efficiency And Optimization 
      
        Robustness 
      
    </td>
    </tr>      
    
     <tr>
  <td>2011</td>
    <td>
      <a href="/publications/blundo2011espresso/">Espresso: Efficient Privacy-preserving Evaluation Of Sample Set Similarity</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Espresso: Efficient Privacy-preserving Evaluation Of Sample Set Similarity' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Espresso: Efficient Privacy-preserving Evaluation Of Sample Set Similarity' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Blundo Carlo, de Cristofaro Emiliano, Gasti Paolo</td> <!-- ðŸ”§ You were missing this -->
    <td>Lecture Notes in Computer Science</td>
    <td>44</td>
    <td><p>Electronic information is increasingly often shared among entities without
complete mutual trust. To address related security and privacy issues, a few
cryptographic techniques have emerged that support privacy-preserving
information sharing and retrieval. One interesting open problem in this context
involves two parties that need to assess the similarity of their datasets, but
are reluctant to disclose their actual content. This paper presents an
efficient and provably-secure construction supporting the privacy-preserving
evaluation of sample set similarity, where similarity is measured as the
Jaccard index. We present two protocols: the first securely computes the
(Jaccard) similarity of two sets, and the second approximates it, using MinHash
techniques, with lower complexities. We show that our novel protocols are
attractive in many compelling applications, including document/multimedia
similarity, biometric authentication, and genetic tests. In the process, we
demonstrate that our constructions are appreciably more efficient than prior
work.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Evaluation 
      
        DATASETS 
      
    </td>
    </tr>      
    
    
      
     <tr>
  <td>2010</td>
    <td>
      <a href="/publications/wang2010efficient/">Efficient K-nearest Neighbor Join Algorithms For High Dimensional Sparse Data</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Efficient K-nearest Neighbor Join Algorithms For High Dimensional Sparse Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Efficient K-nearest Neighbor Join Algorithms For High Dimensional Sparse Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Wang et al.</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>5</td>
    <td><p>The K-Nearest Neighbor (KNN) join is an expensive but important operation in
many data mining algorithms. Several recent applications need to perform KNN
join for high dimensional sparse data. Unfortunately, all existing KNN join
algorithms are designed for low dimensional data. To fulfill this void, we
investigate the KNN join problem for high dimensional sparse data.
  In this paper, we propose three KNN join algorithms: a brute force (BF)
algorithm, an inverted index-based(IIB) algorithm and an improved inverted
index-based(IIIB) algorithm. Extensive experiments on both synthetic and
real-world datasets were conducted to demonstrate the effectiveness of our
algorithms for high dimensional sparse data.</p>
</td>
    <td>
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2010</td>
    <td>
      <a href="/publications/zvedeniouk2010angle/">Angle Tree: Nearest Neighbor Search In High Dimensions With Low Intrinsic Dimensionality</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Angle Tree: Nearest Neighbor Search In High Dimensions With Low Intrinsic Dimensionality' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Angle Tree: Nearest Neighbor Search In High Dimensions With Low Intrinsic Dimensionality' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Zvedeniouk Ilia, Chawla Sanjay</td> <!-- ðŸ”§ You were missing this -->
    <td>Information Systems</td>
    <td>14</td>
    <td><p>We propose an extension of tree-based space-partitioning indexing structures
for data with low intrinsic dimensionality embedded in a high dimensional
space. We call this extension an Angle Tree. Our extension can be applied to
both classical kd-trees as well as the more recent rp-trees. The key idea of
our approach is to store the angle (the â€œdihedral angleâ€) between the data
region (which is a low dimensional manifold) and the random hyperplane that
splits the region (the â€œsplitterâ€). We show that the dihedral angle can be used
to obtain a tight lower bound on the distance between the query point and any
point on the opposite side of the splitter. This in turn can be used to
efficiently prune the search space. We introduce a novel randomized strategy to
efficiently calculate the dihedral angle with a high degree of accuracy.
Experiments and analysis on real and synthetic data sets shows that the Angle
Tree is the most efficient known indexing structure for nearest neighbor
queries in terms of preprocessing and space usage while achieving high accuracy
and fast search time.</p>
</td>
    <td>
      
        Tree Based ANN 
      
    </td>
    </tr>      
    
    
      
     <tr>
  <td>2009</td>
    <td>
      <a href="/publications/kato2009solving/">Solving \(k\)-nearest Neighbor Problem On Multiple Graphics Processors</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Solving \(k\)-nearest Neighbor Problem On Multiple Graphics Processors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Solving \(k\)-nearest Neighbor Problem On Multiple Graphics Processors' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Kato Kimikazu, Hosino Tikara</td> <!-- ðŸ”§ You were missing this -->
    <td>2010 10th IEEE/ACM International Conference on Cluster, Cloud and Grid Computing</td>
    <td>37</td>
    <td><p>The recommendation system is a software system to predict customersâ€™ unknown
preferences from known preferences. In the recommendation system, customersâ€™
preferences are encoded into vectors, and finding the nearest vectors to each
vector is an essential part. This vector-searching part of the problem is
called a \(k\)-nearest neighbor problem. We give an effective algorithm to solve
this problem on multiple graphics processor units (GPUs).
  Our algorithm consists of two parts: an \(N\)-body problem and a partial sort.
For a algorithm of the \(N\)-body problem, we applied the idea of a known
algorithm for the \(N\)-body problem in physics, although another trick is need
to overcome the problem of small sized shared memory. For the partial sort, we
give a novel GPU algorithm which is effective for small \(k\). In our partial
sort algorithm, a heap is accessed in parallel by threads with a low cost of
synchronization. Both of these two parts of our algorithm utilize maximal power
of coalesced memory access, so that a full bandwidth is achieved.
  By an experiment, we show that when the size of the problem is large, an
implementation of the algorithm on two GPUs runs more than 330 times faster
than a single core implementation on a latest CPU. We also show that our
algorithm scales well with respect to the number of GPUs.</p>
</td>
    <td>
      
        Alt 
      
        Recommender Systems 
      
    </td>
    </tr>      
    
     <tr>
  <td>2009</td>
    <td>
      <a href="/publications/giannella2009new/">New Instability Results For High Dimensional Nearest Neighbor Search</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=New Instability Results For High Dimensional Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=New Instability Results For High Dimensional Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Giannella Chris</td> <!-- ðŸ”§ You were missing this -->
    <td>Information Processing Letters</td>
    <td>8</td>
    <td><p>Consider a dataset of n(d) points generated independently from R^d according
to a common p.d.f. f_d with support(f_d) = [0,1]^d and sup{f_d([0,1]^d)}
growing sub-exponentially in d. We prove that: (i) if n(d) grows
sub-exponentially in d, then, for any query point q^d in [0,1]^d and any
epsilon&gt;0, the ratio of the distance between any two dataset points and q^d is
less that 1+epsilon with probability â€“&gt;1 as dâ€“&gt;infinity; (ii) if
n(d)&gt;[4(1+epsilon)]^d for large d, then for all q^d in [0,1]^d (except a small
subset) and any epsilon&gt;0, the distance ratio is less than 1+epsilon with
limiting probability strictly bounded away from one. Moreover, we provide
preliminary results along the lines of (i) when f_d=N(mu_d,Sigma_d).</p>
</td>
    <td>
      
        DATASETS 
      
    </td>
    </tr>      
    
     <tr>
  <td>2009</td>
    <td>
      <a href="/publications/uno2009efficient/">Efficient Construction Of Neighborhood Graphs By The Multiple Sorting Method</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Efficient Construction Of Neighborhood Graphs By The Multiple Sorting Method' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Efficient Construction Of Neighborhood Graphs By The Multiple Sorting Method' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Uno Takeaki, Sugiyama Masashi, Tsuda Koji</td> <!-- ðŸ”§ You were missing this -->
    <td>Arxiv</td>
    <td>10</td>
    <td><p>Neighborhood graphs are gaining popularity as a concise data representation
in machine learning. However, naive graph construction by pairwise distance
calculation takes \(O(n^2)\) runtime for \(n\) data points and this is
prohibitively slow for millions of data points. For strings of equal length,
the multiple sorting method (Uno, 2008) can construct an \(\epsilon\)-neighbor
graph in \(O(n+m)\) time, where \(m\) is the number of \(\epsilon\)-neighbor pairs in
the data. To introduce this remarkably efficient algorithm to continuous
domains such as images, signals and texts, we employ a random projection method
to convert vectors to strings. Theoretical results are presented to elucidate
the trade-off between approximation quality and computation time. Empirical
results show the efficiency of our method in comparison to fast nearest
neighbor alternatives.</p>
</td>
    <td>
      
        Locality Sensitive Hashing 
      
        Graph Based ANN 
      
        Efficiency And Optimization 
      
        Alt 
      
        Evaluation 
      
    </td>
    </tr>      
    
    
      
     <tr>
  <td>2008</td>
    <td>
      <a href="/publications/garcia2008fast/">Fast K Nearest Neighbor Search Using GPU</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Fast K Nearest Neighbor Search Using GPU' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Fast K Nearest Neighbor Search Using GPU' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Garcia Vincent, Debreuve Eric, Barlaud Michel</td> <!-- ðŸ”§ You were missing this -->
    <td>2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops</td>
    <td>444</td>
    <td><p>The recent improvements of graphics processing units (GPU) offer to the
computer vision community a powerful processing platform. Indeed, a lot of
highly-parallelizable computer vision problems can be significantly accelerated
using GPU architecture. Among these algorithms, the k nearest neighbor search
(KNN) is a well-known problem linked with many applications such as
classification, estimation of statistical properties, etc. The main drawback of
this task lies in its computation burden, as it grows polynomially with the
data size. In this paper, we show that the use of the NVIDIA CUDA API
accelerates the search for the KNN up to a factor of 120.</p>
</td>
    <td>
      
        CVPR 
      
        Tools & Libraries 
      
    </td>
    </tr>      
    
    
      
     <tr>
  <td>2007</td>
    <td>
      <a href="/publications/sriperumbudur2007metric/">Metric Embedding For Nearest Neighbor Classification</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Metric Embedding For Nearest Neighbor Classification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Metric Embedding For Nearest Neighbor Classification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Sriperumbudur Bharath K., Lanckriet Gert R. G.</td> <!-- ðŸ”§ You were missing this -->
    <td>Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)</td>
    <td>8</td>
    <td><p>The distance metric plays an important role in nearest neighbor (NN)
classification. Usually the Euclidean distance metric is assumed or a
Mahalanobis distance metric is optimized to improve the NN performance. In this
paper, we study the problem of embedding arbitrary metric spaces into a
Euclidean space with the goal to improve the accuracy of the NN classifier. We
propose a solution by appealing to the framework of regularization in a
reproducing kernel Hilbert space and prove a representer-like theorem for NN
classification. The embedding function is then determined by solving a
semidefinite program which has an interesting connection to the soft-margin
linear binary support vector machine classifier. Although the main focus of
this paper is to present a general, theoretical framework for metric embedding
in a NN setting, we demonstrate the performance of the proposed method on some
benchmark datasets and show that it performs better than the Mahalanobis metric
learning algorithm in terms of leave-one-out and generalization errors.</p>
</td>
    <td>
      
        DATASETS 
      
        Distance Metric Learning 
      
        CVPR 
      
        Alt 
      
        Tools & Libraries 
      
        Evaluation 
      
    </td>
    </tr>      
    
    
      
     <tr>
  <td>2006</td>
    <td>
      <a href="/publications/brodu2006spherical/">Spherical Indexing For Neighborhood Queries</a>
      <span class="externallinks">
        &nbsp;<a href='http://scholar.google.com/scholar?q=Spherical Indexing For Neighborhood Queries' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
        <a href='https://www.semanticscholar.org/search?q=Spherical Indexing For Neighborhood Queries' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
      </span>
    </td>
    <td>Brodu Nicolas</td> <!-- ðŸ”§ You were missing this -->
    <td>ACM Transactions on Database Systems</td>
    <td>5</td>
    <td><p>This is an algorithm for finding neighbors when the objects can freely move
and have no predefined position. The query consists in finding neighbors for a
center location and a given radius. Space is discretized in cubic cells. This
algorithm introduces a direct spherical indexing that gives the list of all
cells making up the query sphere, for any radius and any center location. It
can additionally take in account both cyclic and non-cyclic regions of
interest. Finding only the K nearest neighbors naturally benefits from the
spherical indexing by minimally running through the sphere from center to edge,
and reducing the maximum distance when K neighbors have been found.</p>
</td>
    <td>
      
    </td>
    </tr>      
    
    
  </tbody>
</table>

<!-- CSS Styles -->
<style>
  /* Hide the table initially */

  #allPapers {
  display: none;
  table-layout: fixed;
  width: 100%;
  }
  /* Style the loading indicator */
  #loading {
    position: fixed;
    top: 50%;
    left: 50%;
    transform: translate(-50%, -50%);
    font-size: 1.5em;
    text-align: center;
  }
</style>

<!-- JavaScript -->
<script>
  var datatable;
  var searchInitialized = false;

  function searchTable() {
    // Check if datatable is initialized
    if (datatable && searchInitialized) {
      var hash = decodeURIComponent(window.location.hash.substr(1));
      if (hash) {
        datatable.search(hash).draw();
      } else {
        datatable.search('').draw();  // Clear search if no hash is present
      }
    } else {
      // Retry if datatable is not yet initialized
      setTimeout(searchTable, 500);
    }
  }

  $(document).ready(function() {
    // Show the loading indicator
    $('#loading').show();

    // Initialize the DataTable
    datatable = $('#allPapers').DataTable({
      paging: false,
      pageLength: 100,
      searching: true,
      order: [[0, 'desc'], [4, 'desc']],  // Default sort: Year desc, then Citations desc
      columnDefs: [
        {
          targets: [5, 6],  // Adjusted for new column indices
          visible: false,
          searchable: true
        },
        {
          targets: 4,  // Citation count column
          type: 'num'
        }
      ],
      // Callback when DataTable is initialized
      initComplete: function(settings, json) {
        // Hide the loading indicator
        $('#loading').hide();
        // Show the table
        $('#allPapers').show();
        // Set searchInitialized to true after initialization
        searchInitialized = true;
        // Perform the initial search based on the hash (if any)
        searchTable();
      }
    });
  });

  // Update search whenever the hash changes
  $(window).on('hashchange', function() {
    searchTable();
  });
</script>


    </div>

  </body>
</html>
