<!DOCTYPE html>
<html lang="en-us">

  <head>
  <!-- Hotjar Tracking Code for https://learning2hash.github.io/ -->
<script>
    (function(h,o,t,j,a,r){
        h.hj=h.hj||function(){(h.hj.q=h.hj.q||[]).push(arguments)};
        h._hjSettings={hjid:1843243,hjsv:6};
        a=o.getElementsByTagName('head')[0];
        r=o.createElement('script');r.async=1;
        r.src=t+h._hjSettings.hjid+j+h._hjSettings.hjsv;
        a.appendChild(r);
    })(window,document,'https://static.hotjar.com/c/hotjar-','.js?sv=');
</script><!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-109544763-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-109544763-1');
</script>

  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="keywords" content="machine learning, hashing, approximate nearest neighbour search, lsh, learning-to-hash">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Search all Publications on Machine Learning for Hashing | Awesome Learning to Hash</title>
<meta name="generator" content="Jekyll v4.1.0" />
<meta property="og:title" content="Search all Publications on Machine Learning for Hashing" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A list of research papers for machine learning models for hashing." />
<meta property="og:description" content="A list of research papers for machine learning models for hashing." />
<link rel="canonical" href="https://learning2hash.github.io/papers.html" />
<meta property="og:url" content="https://learning2hash.github.io/papers.html" />
<meta property="og:site_name" content="Awesome Learning to Hash" />
<script type="application/ld+json">
{"url":"https://learning2hash.github.io/papers.html","headline":"Search all Publications on Machine Learning for Hashing","@type":"WebPage","description":"A list of research papers for machine learning models for hashing.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="shortcut icon" href="/public/favicon.svg">
  <link rel="search" href="/public/opensearchdescription.xml" 
      type="application/opensearchdescription+xml" 
      title="learning2hash" />

  <script src="https://code.jquery.com/jquery-3.2.1.min.js"
  integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
  crossorigin="anonymous"></script>
  
  <link rel="stylesheet" type="text/css" href="//cdn.datatables.net/1.10.16/css/jquery.dataTables.min.css">
  <script type="text/javascript" charset="utf8" src="//cdn.datatables.net/1.10.16/js/jquery.dataTables.min.js"></script>
</head>


  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

  <body class="theme-base-0c layout-reverse">

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Awesome Learning to Hash
        </a>
      </h1>
      <p class="lead">A webpage dedicated to the latest research on learning-to-hash, including state-of-the-art deep hashing models, all updated on a weekly basis. Maintained by <a href="http://sjmoran.github.io/">Sean Moran</a>.</p>
    </div>

  <nav class="sidebar-nav">
   <div class="sidebar-item"><p style="font-size: 12px">Search related work <input type='text' id='searchTarget' size="16"/> <button onClick="search();">Go</button></p></div>
   <a class="sidebar-nav-item" href="/cite.html">How to Cite this Work</a>
    <a class="sidebar-nav-item" href="/papers.html">All Papers</a>
   <a class="sidebar-nav-item" href="/tags.html">Papers by Tag</a>
   <a class="sidebar-nav-item" href="/tsne-viz.html">2D Map of Papers</a>
   <a class="sidebar-nav-item" href="/base-taxonomy/">Core Taxonomy</a>
   <a class="sidebar-nav-item-small" href="/base-taxonomy/quantisation.html">Quantisation Models</a>
   <a class="sidebar-nav-item-small" href="/base-taxonomy/supervised.html">Supervised Projection Models</a>
   <a class="sidebar-nav-item-small" href="/base-taxonomy/unsupervised.html">Unsupervised Projection Models</a></ul>
   <a class="sidebar-nav-item-small" href="/base-taxonomy/independent.html">Data Independent Projection Models</a></ul>
  <a class="sidebar-nav-item" href="/base-taxonomy/datasets.html">Datasets</a>
  <a class="sidebar-nav-item" href="/resources.html">Resources, Courses &#38; Events</a>
  <a class="sidebar-nav-item" href="/contributing.html">Contributing</a>
  <a class="sidebar-nav-item" href="/contributors.html">Contributors</a>

</nav>

  <div class="sidebar-item">
    <p style="font-size: 12px">Contact <a href="http://www.seanjmoran.com">Sean Moran</a> about this survey or website.
    <span style="font-size: 9px">
      Made with <a href="https://jekyllrb.com">Jekyll</a> and <a href="https://github.com/poole/hyde">Hyde</a>.
    </span></p>
  </div>
</div></div>

<script>
$("#searchTarget").keydown(function (e) {	
  if (e.keyCode == 13) {
    search();
  }
});
function search() {
  try {
    ga('send', 'event', 'search', 'search', $("#searchTarget").val());
  } finally {
    window.location = "/papers.html#" + $("#searchTarget").val();
  }
}
</script>


    <div class="content container">
      <p>
Search across all paper titles, abstracts, authors by using the search field.
Please consider <a href="/contributing.html">contributing</a> by updating
the information of existing papers or adding new work. 
</p>

</br>
<table id="allPapers">
<thead><th>Year</th><th>Title</th><th>Authors</th><th>Venue</th><th>Abstract</th></thead><tbody>



<tr>
	<td>2020</td>
	<td><a href="/publications/yuan2020central/">Central Similarity Hashing for Efficient Image and Video Retrieval</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Central Similarity Hashing for Efficient Image and Video Retrieval' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Central Similarity Hashing for Efficient Image and Video Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Central%20Similarity%20Hashing%20for%20Efficient%20Image%20and%20Video%20Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Li Yuan, Tao Wang, Xiaopeng Zhang, Zequn Jie, Francis EH Tay, Jiashi Feng</td>
	<td>CVPR</td>
	<td><p>Existing data-dependent hashing methods usually learn
hash functions from the pairwise or triplet data relationships, which only capture the data similarity locally, and
often suffer low learning efficiency and low collision rate.
In this work, we propose a new global similarity metric,
termed as central similarity, with which the hash codes for
similar data pairs are encouraged to approach a common
center and those for dissimilar pairs to converge to different centers, to improve hash learning efficiency and retrieval accuracy. We principally formulate the computation of the proposed central similarity metric by introducing a new concept, i.e. hash center that refers to a set
of data points scattered in the Hamming space with sufficient mutual distance between each other. We then provide an efficient method to construct well separated hash
centers by leveraging the Hadamard matrix and Bernoulli
distributions. Finally, we propose the Central Similarity
Hashing (CSH) that optimizes the central similarity between data points w.r.t. their hash centers instead of optimizing the local similarity. The CSH is generic and applicable to both image and video hashing. Extensive experiments on large-scale image and video retrieval demonstrate CSH can generate cohesive hash codes for similar
data pairs and dispersed hash codes for dissimilar pairs,
and achieve noticeable boost in retrieval performance, i.e.
3%-20% in mAP over the previous state-of-the-art. The
codes are in: https://github.com/yuanli2333/
Hadamard-Matrix-for-hashing</p>
</td>
</tr>

<tr>
	<td>2020</td>
	<td><a href="/publications/ryali2020bio/">Bio-Inspired Hashing for Unsupervised Similarity Search</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Bio-Inspired Hashing for Unsupervised Similarity Search' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Bio-Inspired Hashing for Unsupervised Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Bio-Inspired%20Hashing%20for%20Unsupervised%20Similarity%20Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Chaitanya K. Ryali, John J. Hopfield, Leopold Grinberg, Dmitry Krotov</td>
	<td>ICML</td>
	<td><p>The fruit fly Drosophila’s olfactory circuit has inspired a new locality sensitive hashing (LSH) algorithm, FlyHash. In contrast with classical LSH algorithms that produce low dimensional hash codes, FlyHash produces sparse high-dimensional hash codes and has also been shown to have superior empirical performance compared to classical LSH algorithms in similarity search. However, FlyHash uses random projections and cannot learn from data. Building on inspiration from FlyHash and the ubiquity of sparse expansive representations in neurobiology, our work proposes a novel hashing algorithm BioHash that produces sparse high dimensional hash codes in a data-driven manner. We show that BioHash outperforms previously published benchmarks for various hashing methods. Since our learning algorithm is based on a local and biologically plausible synaptic plasticity rule, our work provides evidence for the proposal that LSH might be a computational reason for the abundance of sparse expansive motifs in a variety of biological systems. We also propose a convolutional variant BioConvHash that further improves performance. From the perspective of computer science, BioHash and BioConvHash are fast, scalable and yield compressed binary representations that are useful for similarity search.</p>
</td>
</tr>

<tr>
	<td>2020</td>
	<td><a href="/publications/ye2020nearoptimal/">Unsupervised Few-Bits Semantic Hashing with Implicit Topics Modeling</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Unsupervised Few-Bits Semantic Hashing with Implicit Topics Modeling' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Unsupervised Few-Bits Semantic Hashing with Implicit Topics Modeling' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Unsupervised%20Few-Bits%20Semantic%20Hashing%20with%20Implicit%20Topics%20Modeling' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Fanghua Ye, Jarana Manotumruksa, Emine Yilmaz</td>
	<td>EMNLP</td>
	<td><p>Semantic hashing is a powerful paradigm for
representing texts as compact binary hash
codes. The explosion of short text data has
spurred the demand of few-bits hashing. However, the performance of existing semantic
hashing methods cannot be guaranteed when
applied to few-bits hashing because of severe
information loss. In this paper, we present a
simple but effective unsupervised neural generative semantic hashing method with a focus on
few-bits hashing. Our model is built upon variational autoencoder and represents each hash
bit as a Bernoulli variable, which allows the
model to be end-to-end trainable. To address
the issue of information loss, we introduce a
set of auxiliary implicit topic vectors. With
the aid of these topic vectors, the generated
hash codes are not only low-dimensional representations of the original texts but also capture their implicit topics. We conduct comprehensive experiments on four datasets. The results demonstrate that our approach achieves
significant improvements over state-of-the-art
semantic hashing methods in few-bits hashing.</p>
</td>
</tr>

<tr>
	<td>2020</td>
	<td><a href="/publications/cui2020exchnet/">ExchNet: A Unified Hashing Network for Large-Scale Fine-Grained Image Retrieval</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=ExchNet: A Unified Hashing Network for Large-Scale Fine-Grained Image Retrieval' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=ExchNet: A Unified Hashing Network for Large-Scale Fine-Grained Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=ExchNet:%20A%20Unified%20Hashing%20Network%20for%20Large-Scale%20Fine-Grained%20Image%20Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Quan Cui, Qing-Yuan Jiang, Xiu-Shen Wei, Wu-Jun Li, and Osamu Yoshie</td>
	<td>ECCV</td>
	<td><p>Retrieving content relevant images from a large-scale fine grained dataset could suffer from intolerably slow query speed and highly
redundant storage cost, due to high-dimensional real-valued embeddings
which aim to distinguish subtle visual differences of fine-grained objects.
In this paper, we study the novel fine-grained hashing topic to generate compact binary codes for fine-grained images, leveraging the search
and storage efficiency of hash learning to alleviate the aforementioned
problems. Specifically, we propose a unified end-to-end trainable network,
termed as ExchNet. Based on attention mechanisms and proposed attention constraints, it can firstly obtain both local and global features
to represent object parts and whole fine-grained objects, respectively.
Furthermore, to ensure the discriminative ability and semantic meaning’s
consistency of these part-level features across images, we design a local
feature alignment approach by performing a feature exchanging operation. Later, an alternative learning algorithm is employed to optimize
the whole ExchNet and then generate the final binary hash codes. Validated by extensive experiments, our proposal consistently outperforms
state-of-the-art generic hashing methods on five fine-grained datasets,
which shows our effectiveness. Moreover, compared with other approximate nearest neighbor methods, ExchNet achieves the best speed-up and
storage reduction, revealing its efficiency and practicality.</p>
</td>
</tr>

<tr>
	<td>2020</td>
	<td><a href="/publications/dong2020learning/">Learning Space Partitions for Nearest Neighbor Search</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Learning Space Partitions for Nearest Neighbor Search' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Learning Space Partitions for Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Learning%20Space%20Partitions%20for%20Nearest%20Neighbor%20Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Yihe Dong, Piotr Indyk, Ilya Razenshteyn, Tal Wagner</td>
	<td>ICLR</td>
	<td><p>Space partitions of underlie a vast and important
class of fast nearest neighbor search (NNS) algorithms. Inspired by recent theoretical work on NNS for general metric spaces (Andoni et al. 2018b,c), we develop a new framework for building space partitions reducing the problem to balanced graph partitioning followed by supervised classification.
We instantiate this general approach with the KaHIP graph partitioner (Sanders and Schulz 2013) and neural networks, respectively, to obtain a new partitioning procedure called Neural Locality-Sensitive Hashing (Neural LSH). On several standard benchmarks for NNS (Aumuller et al. 2017), our experiments show that the partitions obtained by Neural LSH consistently outperform partitions found by quantization-based and tree-based methods as well as classic, data-oblivious LSH.</p>

</td>
</tr>

<tr>
	<td>2020</td>
	<td><a href="/publications/morgado2020deep/">Deep Hashing with Hash-Consistent Large Margin Proxy Embeddings</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Deep Hashing with Hash-Consistent Large Margin Proxy Embeddings' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Deep Hashing with Hash-Consistent Large Margin Proxy Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Deep%20Hashing%20with%20Hash-Consistent%20Large%20Margin%20Proxy%20Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Pedro Morgado, Yunsheng Li, Jose Costa Pereira, Mohammad Saberian, Nuno Vasconcelos</td>
	<td>Arxiv</td>
	<td><p>Image hash codes are produced by binarizing
the embeddings of convolutional neural networks (CNN)
trained for either classification or retrieval. While proxy
embeddings achieve good performance on both tasks,
they are non-trivial to binarize, due to a rotational ambiguity that encourages non-binary embeddings. The use
of a fixed set of proxies (weights of the CNN classification layer) is proposed to eliminate this ambiguity, and
a procedure to design proxy sets that are nearly optimal
for both classification and hashing is introduced. The
resulting hash-consistent large margin (HCLM) proxies
are shown to encourage saturation of hashing units, thus
guaranteeing a small binarization error, while producing
highly discriminative hash-codes. A semantic extension
(sHCLM), aimed to improve hashing performance in
a transfer scenario, is also proposed. Extensive experiments show that sHCLM embeddings achieve significant
improvements over state-of-the-art hashing procedures
on several small and large datasets, both within and
beyond the set of training classes.</p>
</td>
</tr>

<tr>
	<td>2020</td>
	<td><a href="/publications/shen2020auto/">Auto-Encoding Twin-Bottleneck Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Auto-Encoding Twin-Bottleneck Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Auto-Encoding Twin-Bottleneck Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Auto-Encoding%20Twin-Bottleneck%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Yuming Shen, Jie Qin, Jiaxin Chen, Mengyang Yu, Li Liu, Fan Zhu, Fumin Shen, Ling Shao</td>
	<td>CVPR</td>
	<td><p>Conventional unsupervised hashing methods usually take advantage of similarity graphs, which are either pre-computed in the high-dimensional space or obtained from random anchor points. On the one hand, existing methods uncouple the procedures of hash function learning and graph construction. On the other hand, graphs empirically built upon original data could introduce biased prior knowledge of data relevance, leading to sub-optimal retrieval performance. In this paper, we tackle the above problems by proposing an efficient and adaptive code-driven graph, which is updated by decoding in the context of an auto-encoder. Specifically, we introduce into our framework twin bottlenecks (i.e., latent variables) that exchange crucial information collaboratively. One bottleneck (i.e., binary codes) conveys the high-level intrinsic data structure captured by the code-driven graph to the other (i.e., continuous variables for low-level detail information), which in turn propagates the updated network feedback for the encoder to learn more discriminative binary codes. The auto-encoding learning objective literally rewards the code-driven graph to learn an optimal encoder. Moreover, the proposed model can be simply optimized by gradient descent without violating the binary constraints. Experiments on benchmarked datasets clearly show the superiority of our framework over the state-of-the-art hashing methods.</p>
</td>
</tr>

<tr>
	<td>2020</td>
	<td><a href="/publications/liu2020model/">Model Optimization Boosting Framework for Linear Model Hash Learning</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Model Optimization Boosting Framework for Linear Model Hash Learning' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Model Optimization Boosting Framework for Linear Model Hash Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Model%20Optimization%20Boosting%20Framework%20for%20Linear%20Model%20Hash%20Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Xingbo Liu, Xiushan Nie, Quan Zhou, Liqiang Nie, Yilong Yin</td>
	<td>TIP</td>
	<td><p>Efficient hashing techniques have attracted extensive research interests in both storage and retrieval of high dimensional data, such as images and videos. In existing hashing methods, a linear model is commonly utilized owing to its efficiency. To obtain better accuracy, linear-based hashing methods focus on designing a generalized linear objective function with different constraints or penalty terms that consider the inherent characteristics and neighborhood information of samples. Differing from existing hashing methods, in this study, we propose a self-improvement framework called Model Boost (MoBoost) to improve model parameter optimization for linear-based hashing methods without adding new constraints or penalty terms. In the proposed MoBoost, for a linear-based hashing method, we first repeatedly execute the hashing method to obtain several hash codes to training samples. Then, utilizing two novel fusion strategies, these codes are fused into a single set. We also propose two new criteria to evaluate the goodness of hash bits during the fusion process. Based on the fused set of hash codes, we learn new parameters for the linear hash function that can significantly improve the accuracy. In general, the proposed MoBoost can be adopted by existing linear-based hashing methods, achieving more precise and stable performance compared to the original methods, and adopting the proposed MoBoost will incur negligible time and space costs. To evaluate the proposed MoBoost, we performed extensive experiments on four benchmark datasets, and the results demonstrate superior performance.</p>
</td>
</tr>

<tr>
	<td>2020</td>
	<td><a href="/publications/hansen2020content/">Content-aware Neural Hashing for Cold-start Recommendation</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Content-aware Neural Hashing for Cold-start Recommendation' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Content-aware Neural Hashing for Cold-start Recommendation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Content-aware%20Neural%20Hashing%20for%20Cold-start%20Recommendation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Casper Hansen, Christian Hansen, Jakob Grue Simonsen, Stephen Alstrup, Christina Lioma</td>
	<td>SIGIR</td>
	<td><p>Content-aware recommendation approaches are essential for providing meaningful recommendations for new (i.e., cold-start) items in a recommender system. We present a content-aware neural hashing-based collaborative filtering approach (NeuHash-CF), which generates binary hash codes for users and items, such that the highly efficient Hamming distance can be used for estimating user-item relevance. NeuHash-CF is modelled as an autoencoder architecture, consisting of two joint hashing components for generating user and item hash codes. Inspired from semantic hashing, the item hashing component generates a hash code directly from an item’s content information (i.e., it generates cold-start and seen item hash codes in the same manner). This contrasts existing state-of-the-art models, which treat the two item cases separately. The user hash codes are generated directly based on user id, through learning a user embedding matrix. We show experimentally that NeuHash-CF significantly outperforms state-of-the-art baselines by up to 12% NDCG and 13% MRR in cold-start recommendation settings, and up to 4% in both NDCG and MRR in standard settings where all items are present while training. Our approach uses 2-4x shorter hash codes, while obtaining the same or better performance compared to the state of the art, thus consequently also enabling a notable storage reduction.</p>
</td>
</tr>

<tr>
	<td>2020</td>
	<td><a href="/publications/bai2020bai/">Targeted Attack for Deep Hashing based Retrieval</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Targeted Attack for Deep Hashing based Retrieval' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Targeted Attack for Deep Hashing based Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Targeted%20Attack%20for%20Deep%20Hashing%20based%20Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Jiawang Bai, Bin Chen, Yiming Li, Dongxian Wu, Weiwei Guo, Shu-tao Xia, En-hui Yang</td>
	<td>Arxiv</td>
	<td><p>The deep hashing based retrieval method is widely adopted in large-scale image and video retrieval. However, there is little investigation on its security. In this paper, we propose a novel method, dubbed deep hashing targeted attack (DHTA), to study the targeted attack on such retrieval. Specifically, we first formulate the targeted attack as a point-to-set optimization, which minimizes the average distance between the hash code of an adversarial example and those of a set of objects with the target label. Then we design a novel component-voting scheme to obtain an anchor code as the representative of the set of hash codes of objects with the target label, whose optimality guarantee is also theoretically derived. To balance the performance and perceptibility, we propose to minimize the Hamming distance between the hash code of the adversarial example and the anchor code under the ℓ∞ restriction on the perturbation. Extensive experiments verify that DHTA is effective in attacking both deep hashing based image retrieval and video retrieval.</p>
</td>
</tr>

<tr>
	<td>2020</td>
	<td><a href="/publications/hu2020creating/">Creating Something from Nothing: Unsupervised Knowledge Distillation for Cross-Modal Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Creating Something from Nothing: Unsupervised Knowledge Distillation for Cross-Modal Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Creating Something from Nothing: Unsupervised Knowledge Distillation for Cross-Modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Creating%20Something%20from%20Nothing:%20Unsupervised%20Knowledge%20Distillation%20for%20Cross-Modal%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Hengtong Hu, Lingxi Xie, Richang Hong, Qi Tian</td>
	<td>CVPR</td>
	<td><p>In recent years, cross-modal hashing (CMH) has attracted increasing attentions, mainly because its potential
ability of mapping contents from different modalities, especially in vision and language, into the same space, so that
it becomes efficient in cross-modal data retrieval. There are
two main frameworks for CMH, differing from each other in
whether semantic supervision is required. Compared to the
unsupervised methods, the supervised methods often enjoy
more accurate results, but require much heavier labors in
data annotation. In this paper, we propose a novel approach
that enables guiding a supervised method using outputs produced by an unsupervised method. Specifically, we make
use of teacher-student optimization for propagating knowledge. Experiments are performed on two popular CMH
benchmarks, i.e., the MIRFlickr and NUS-WIDE datasets.
Our approach outperforms all existing unsupervised methods by a large margin</p>
</td>
</tr>



<tr>
	<td>2019</td>
	<td><a href="/publications/he2019knearest/">K-Nearest Neighbors Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=K-Nearest Neighbors Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=K-Nearest Neighbors Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=K-Nearest%20Neighbors%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Xiangyu He, Peisong Wang, Jian Cheng</td>
	<td>CVPR</td>
	<td><p>Hashing based approximate nearest neighbor search embeds high dimensional data to compact binary codes, which
enables efficient similarity search and storage. However,
the non-isometry sign(·) function makes it hard to project
the nearest neighbors in continuous data space into the
closest codewords in discrete Hamming space. In this work,
we revisit the sign(·) function from the perspective of space partitioning.
In specific, we bridge the gap between
k-nearest neighbors and binary hashing codes with Shannon entropy. We further propose a novel K-Nearest Neighbors Hashing (KNNH) method to learn binary representations from KNN within the subspaces generated by sign(·).
Theoretical and experimental results show that the KNN relation is of central importance to neighbor preserving embeddings, and the proposed method outperforms the state-of-the-arts on benchmark datasets.</p>
</td>
</tr>

<tr>
	<td>2019</td>
	<td><a href="/publications/hu2019separated/">Separated Variational Hashing Networks for Cross-Modal Retrieval</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Separated Variational Hashing Networks for Cross-Modal Retrieval' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Separated Variational Hashing Networks for Cross-Modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Separated%20Variational%20Hashing%20Networks%20for%20Cross-Modal%20Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Peng Hu, Xu Wang, Liangli Zhen, Dezhong Peng</td>
	<td>MM</td>
	<td><p>Cross-modal hashing, due to its low storage cost and high query speed, has been successfully used for similarity search in multimedia retrieval applications. It projects high-dimensional data into a shared isomorphic Hamming space with similar binary codes for semantically-similar data. In some applications, all modalities may not be obtained or trained simultaneously for some reasons, such as privacy, secret, storage limitation, and computational resource limitation. However, most existing cross-modal hashing methods need all modalities to jointly learn the common Hamming space, thus hindering them from handling these problems. In this paper, we propose a novel approach called Separated Variational Hashing Networks (SVHNs) to overcome the above challenge. Firstly, it adopts a label network (LabNet) to exploit available and nonspecific label annotations to learn a latent common Hamming space by projecting each semantic label into a common binary representation. Then, each modality-specific network can separately map the samples of the corresponding modality into their binary semantic codes learned by LabNet. We achieve it by conducting variational inference to match the aggregated posterior of the hashing code of LabNet with an arbitrary prior distribution. The effectiveness and efficiency of our SVHNs are verified by extensive experiments carried out on four widely-used multimedia databases, in comparison with 11 state-of-the-art approaches.</p>
</td>
</tr>

<tr>
	<td>2019</td>
	<td><a href="/publications/li2019neighbourhood/">Neighborhood Preserving Hashing for Scalable Video Retrieval</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Neighborhood Preserving Hashing for Scalable Video Retrieval' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Neighborhood Preserving Hashing for Scalable Video Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Neighborhood%20Preserving%20Hashing%20for%20Scalable%20Video%20Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Shuyan Li, Zhixiang Chen, Jiwen Lu, Xiu Li, Jie Zhou</td>
	<td>ICCV</td>
	<td><p>In this paper, we propose a Neighborhood Preserving Hashing (NPH) method for scalable video retrieval in an unsupervised manner. Unlike most existing deep video hashing methods which indiscriminately compress an entire video into a binary code, we embed the spatial-temporal neighborhood information into the encoding network such that the neighborhood-relevant visual content of a video can be preferentially encoded into a binary code under the guidance of the neighborhood information. Specifically, we propose a neighborhood attention mechanism which focuses on partial useful content of each input frame conditioned on the neighborhood information. We then integrate the neighborhood attention mechanism into an RNN-based reconstruction scheme to encourage the binary codes to capture the spatial-temporal structure in a video which is consistent with that in the neighborhood. As a consequence, the learned hashing functions can map similar videos to similar binary codes. Extensive experiments on three widely-used benchmark datasets validate the effectiveness of our proposed approach.</p>
</td>
</tr>

<tr>
	<td>2019</td>
	<td><a href="/publications/hansen2019unsupervised/">Unsupervised Neural Generative Semantic Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Unsupervised Neural Generative Semantic Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Unsupervised Neural Generative Semantic Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Unsupervised%20Neural%20Generative%20Semantic%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Casper Hansen, Christian Hansen, Jakob Grue Simonsen, Stephen Alstrup, Christina Lioma</td>
	<td>SIGIR</td>
	<td><p>Fast similarity search is a key component in large-scale information retrieval, where semantic hashing has become a popular strategy for representing documents as binary hash codes. Recent advances in this area have been obtained through neural network based models: generative models trained by learning to reconstruct the original documents. We present a novel unsupervised generative semantic hashing approach, \textit{Ranking based Semantic Hashing} (RBSH) that consists of both a variational and a ranking based component. Similarly to variational autoencoders, the variational component is trained to reconstruct the original document conditioned on its generated hash code, and as in prior work, it only considers documents individually. The ranking component solves this limitation by incorporating inter-document similarity into the hash code generation, modelling document ranking through a hinge loss. To circumvent the need for labelled data to compute the hinge loss, we use a weak labeller and thus keep the approach fully unsupervised.
Extensive experimental evaluation on four publicly available datasets against traditional baselines and recent state-of-the-art methods for semantic hashing shows that RBSH significantly outperforms all other methods across all evaluated hash code lengths. In fact, RBSH hash codes are able to perform similarly to state-of-the-art hash codes while using 2-4x fewer bits.</p>
</td>
</tr>

<tr>
	<td>2019</td>
	<td><a href="/publications/gattupalli2019weakly/">Weakly Supervised Deep Image Hashing through Tag Embeddings</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Weakly Supervised Deep Image Hashing through Tag Embeddings' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Weakly Supervised Deep Image Hashing through Tag Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Weakly%20Supervised%20Deep%20Image%20Hashing%20through%20Tag%20Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Vijetha Gattupalli, Yaoxin Zhuo, Baoxin Li</td>
	<td>CVPR</td>
	<td><p>Many approaches to semantic image hashing have been formulated as supervised learning problems that utilize images and label information to learn the binary hash codes. However, large-scale labeled image data is expensive to obtain, thus imposing a restriction on the usage of such algorithms. On the other hand, unlabelled image data is abundant due to the existence of many Web image repositories. Such Web images may often come with images tags that contain useful information, although raw tags, in general, do not readily lead to semantic labels.
Motivated by this scenario, we formulate the problem of semantic image hashing as a weakly-supervised learning problem. We utilize the information contained in the user-generated tags associated with the images to learn the hash codes. More specifically, we extract the word2vec semantic embeddings of the tags and use the information contained in them for constraining the learning.
Accordingly, we name our model Weakly Supervised Deep Hashing using Tag Embeddings (WDHT). WDHT is tested for the task of semantic image retrieval and is compared against several state-of-art models. Results show that our approach sets a new state-of-art in the area of weekly supervised image hashing.</p>
</td>
</tr>

<tr>
	<td>2019</td>
	<td><a href="/publications/kang2019maximum/">Maximum-Margin Hamming Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Maximum-Margin Hamming Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Maximum-Margin Hamming Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Maximum-Margin%20Hamming%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Rong Kang, Yue Cao, Mingsheng Long (B), Jianmin Wang, and Philip S. Yu</td>
	<td>ICCV</td>
	<td><p>Deep hashing enables computation and memory efficient
image search through end-to-end learning of feature representations and binary codes. While linear scan over binary
hash codes is more efficient than over the high-dimensional
representations, its linear-time complexity is still unacceptable for very large databases. Hamming space retrieval enables constant-time search through hash lookups, where for
each query, there is a Hamming ball centered at the query
and the data points within the ball are returned as relevant.
Since inside the Hamming ball implies retrievable while
outside irretrievable, it is crucial to explicitly characterize
the Hamming ball. The main idea of this work is to directly
embody the Hamming radius into the loss functions, leading
to Maximum-Margin Hamming Hashing (MMHH), a new
model specifically optimized for Hamming space retrieval.
We introduce a max-margin t-distribution loss, where the
t-distribution concentrates more similar data points to be
within the Hamming ball, and the margin characterizes the
Hamming radius such that less penalization is applied to
similar data points within the Hamming ball. The loss function also introduces robustness to data noise, where the similarity supervision may be inaccurate in practical problems.
The model is trained end-to-end using a new semi-batch optimization algorithm tailored to extremely imbalanced data.
Our method yields state-of-the-art results on four datasets
and shows superior performance on noisy data.</p>
</td>
</tr>

<tr>
	<td>2019</td>
	<td><a href="/publications/cakir2019hashing/">Hashing with Mutual Information</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Hashing with Mutual Information' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Hashing with Mutual Information' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Hashing%20with%20Mutual%20Information' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>F. Cakir, K. He, S. Bargal, S. Sclaroff</td>
	<td>TPAMI</td>
	<td><p>Binary vector embeddings enable fast nearest neighbor retrieval in large databases of high-dimensional objects, and play an important role in many practical applications, such as image and video retrieval. We study the problem of learning binary vector embeddings under a supervised setting, also known as hashing. We propose a novel supervised hashing method based on optimizing an information-theoretic quantity: mutual information. We show that optimizing mutual information can reduce ambiguity in the induced neighborhood structure in the learned Hamming space, which is essential in obtaining high retrieval performance. To this end, we optimize mutual information in deep neural networks with minibatch stochastic gradient descent, with a formulation that maximally and efficiently utilizes available supervision. Experiments on four image retrieval benchmarks, including ImageNet, confirm the effectiveness of our method in learning high-quality binary embeddings for nearest neighbor retrieval.</p>
</td>
</tr>

<tr>
	<td>2019</td>
	<td><a href="/publications/wang2019deep/">Deep Collaborative Discrete Hashing with Semantic-Invariant Structure</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Deep Collaborative Discrete Hashing with Semantic-Invariant Structure' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Deep Collaborative Discrete Hashing with Semantic-Invariant Structure' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Deep%20Collaborative%20Discrete%20Hashing%20with%20Semantic-Invariant%20Structure' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Zijian Wang, Zheng Zhang, Yadan Luo and Zi Huang</td>
	<td>SIGIR</td>
	<td><p>Existing deep hashing approaches fail to fully explore semantic correlations and neglect the effect of linguistic context on visual attention learning, leading to inferior performance. This paper proposes a dual-stream learning framework, dubbed Deep Collaborative Discrete Hashing (DCDH), which constructs a discriminative common discrete space by collaboratively incorporating the shared and individual semantics deduced from visual features and semantic labels. Specifically, the context-aware representations are generated by employing the outer product of visual embeddings and semantic encodings. Moreover, we reconstruct the labels and introduce the focal loss to take advantage of frequent and rare concepts. The common binary code space is built on the joint learning of the visual representations attended by language, the semantic-invariant structure construction and the label distribution correction. Extensive experiments demonstrate the superiority of our method.</p>
</td>
</tr>

<tr>
	<td>2019</td>
	<td><a href="/publications/wang2019semi/">Semi-supervised Deep Quantization for Cross-modal Search</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Semi-supervised Deep Quantization for Cross-modal Search' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Semi-supervised Deep Quantization for Cross-modal Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Semi-supervised%20Deep%20Quantization%20for%20Cross-modal%20Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Xin Wang, Wenwu Zhu, Chenghao Liu</td>
	<td>MM</td>
	<td><p>The problem of cross-modal similarity search, which aims at making efficient and accurate queries across multiple domains, has become a significant and important research topic. Composite quantization, a compact coding solution superior to hashing techniques, has shown its effectiveness for similarity search. However, most existing works utilizing composite quantization to search multi-domain content only consider either pairwise similarity information or class label information across different domains, which fails to tackle the semi-supervised problem in composite quantization. In this paper, we address the semi-supervised quantization problem by considering: (i) pairwise similarity information (without class label information) across different domains, which captures the intra-document relation, (ii) cross-domain data with class label which can help capture inter-document relation, and (iii) cross-domain data with neither pairwise similarity nor class label which enables the full use of abundant unlabelled information. To the best of our knowledge, we are the first to consider both supervised information (pairwise similarity + class label) and unsupervised information (neither pairwise similarity nor class label) simultaneously in composite quantization. A challenging problem arises: how can we jointly handle these three sorts of information across multiple domains in an efficient way? To tackle this challenge, we propose a novel semi-supervised deep quantization (SSDQ) model that takes both supervised and unsupervised information into account. The proposed SSDQ model is capable of incorporating the above three kinds of information into one single framework when utilizing composite quantization for accurate and efficient queries across different domains. More specifically, we employ a modified deep autoencoder for better latent representation and formulate pairwise similarity loss, supervised quantization loss as well as unsupervised distribution match loss to handle all three types of information. The extensive experiments demonstrate the significant improvement of SSDQ over several state-of-the-art methods on various datasets.</p>
</td>
</tr>

<tr>
	<td>2019</td>
	<td><a href="/publications/liu2019moboost/">MoBoost: A Self-improvement Framework for Linear-based Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=MoBoost: A Self-improvement Framework for Linear-based Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=MoBoost: A Self-improvement Framework for Linear-based Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=MoBoost:%20A%20Self-improvement%20Framework%20for%20Linear-based%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Xingbo Liu, Xiushan Nie, Xiaoming Xi, Lei Zhu, Yilong Yin</td>
	<td>CIKM</td>
	<td><p>The linear model is commonly utilized in hashing methods owing to its efficiency. To obtain better accuracy, linear-based hashing methods focus on designing a generalized linear objective function with different constraints or penalty terms that consider neighborhood information. In this study, we propose a novel generalized framework called Model Boost (MoBoost), which can achieve the self-improvement of the linear-based hashing. The proposed MoBoost is used to improve model parameter optimization for linear-based hashing methods without adding new constraints or penalty terms. In the proposed MoBoost, given a linear-based hashing method, we first execute the method several times to get several different hash codes for training samples, and then combine these different hash codes into one set utilizing one novel fusion strategy. Based on this set of hash codes, we learn some new parameters for the linear hash function that can significantly improve accuracy. The proposed MoBoost can be generally adopted in existing linear-based hashing methods, achieving more precise and stable performance compared to the original methods while imposing negligible added expenditure in terms of time and space. Extensive experiments are performed based on three benchmark datasets, and the results demonstrate the superior performance of the proposed framework.</p>
</td>
</tr>

<tr>
	<td>2019</td>
	<td><a href="/publications/jin2019deep/">Deep Saliency Hashing for Fine-grained Retrieval</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Deep Saliency Hashing for Fine-grained Retrieval' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Deep Saliency Hashing for Fine-grained Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Deep%20Saliency%20Hashing%20for%20Fine-grained%20Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Sheng Jin, Hongxun Yao, Xiaoshuai Sun, Shangchen Zhou, Lei Zhang, Xiansheng Hua</td>
	<td>Arxiv</td>
	<td><p>In recent years, hashing methods have been proved to be
effective and efficient for the large-scale Web media search.
However, the existing general hashing methods have limited discriminative power for describing fine-grained objects that share similar overall appearance but have subtle
difference. To solve this problem, we for the first time introduce the attention mechanism to the learning of fine-grained
hashing codes. Specifically, we propose a novel deep hashing model, named deep saliency hashing (DSaH), which
automatically mines salient regions and learns semanticpreserving hashing codes simultaneously. DSaH is a twostep end-to-end model consisting of an attention network
and a hashing network. Our loss function contains three
basic components, including the semantic loss, the saliency
loss, and the quantization loss. As the core of DSaH, the
saliency loss guides the attention network to mine discriminative regions from pairs of images. We conduct extensive experiments on both fine-grained and general retrieval
datasets for performance evaluation. Experimental results
on fine grained dataset, including Oxford Flowers-17, Stanford Dogs-120 and CUB Bird demonstrate that our DSaH
performs the best for fine-grained retrieval task and beats
strongest competitor (DTQ) by approximately 10% on both
Stanford Dogs-120 and CUB Bird. DSaH is also comparable to several state-of-the-art hashing methods on general
datasets, including CIFAR-10 and NUS-WIDE.</p>
</td>
</tr>

<tr>
	<td>2019</td>
	<td><a href="/publications/chen2019twostep/">A Two-step Cross-modal Hashing by Exploiting Label Correlations and Preserving Similarity in Both Steps</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=A Two-step Cross-modal Hashing by Exploiting Label Correlations and Preserving Similarity in Both Steps' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=A Two-step Cross-modal Hashing by Exploiting Label Correlations and Preserving Similarity in Both Steps' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=A%20Two-step%20Cross-modal%20Hashing%20by%20Exploiting%20Label%20Correlations%20and%20Preserving%20Similarity%20in%20Both%20Steps' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Zhen-Duo Chen, Yongxin Wang, Hui-Qiong Li, Xin Luo, Liqiang Nie, Xin-Shun</td>
	<td>MM</td>
	<td><p>In this paper, we present a novel Two-stEp Cross-modal Hashing method, TECH for short, for cross-modal retrieval tasks. As a two-step method, it first learns hash codes based on semantic labels, while preserving the similarity in the original space and exploiting the label correlations in the label space. In the light of this, it is able to make better use of label information and generate better binary codes. In addition, different from other two-step methods that mainly focus on the hash codes learning, TECH adopts a new hash function learning strategy in the second step, which also preserves the similarity in the original space. Moreover, with the help of well designed objective function and optimization scheme, it is able to generate hash codes discretely and scalable for large scale data. To the best of our knowledge, it is the first cross-modal hashing method exploiting label correlations, and also the first two-step hashing model preserving the similarity while leaning hash function. Extensive experiments demonstrate that the proposed approach outperforms some state-of-the-art cross-modal hashing methods.</p>
</td>
</tr>

<tr>
	<td>2019</td>
	<td><a href="/publications/sun2019supervised/">Supervised Hierarchical Cross-Modal Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Supervised Hierarchical Cross-Modal Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Supervised Hierarchical Cross-Modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Supervised%20Hierarchical%20Cross-Modal%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Changchang Sun, Xuemeng Song, Fuli Feng, Wayne Xin Zhao, Hao Zhang and Liqiang Nie</td>
	<td>SIGIR</td>
	<td><p>Recently, due to the unprecedented growth of multimedia data,
cross-modal hashing has gained increasing attention for the
efficient cross-media retrieval. Typically, existing methods on crossmodal hashing treat labels of one instance independently but
overlook the correlations among labels. Indeed, in many real-world
scenarios, like the online fashion domain, instances (items) are
labeled with a set of categories correlated by certain hierarchy. In
this paper, we propose a new end-to-end solution for supervised
cross-modal hashing, named HiCHNet, which explicitly exploits the
hierarchical labels of instances. In particular, by the pre-established
label hierarchy, we comprehensively characterize each modality
of the instance with a set of layer-wise hash representations. In
essence, hash codes are encouraged to not only preserve the layerwise semantic similarities encoded by the label hierarchy, but also
retain the hierarchical discriminative capabilities. Due to the lack
of benchmark datasets, apart from adapting the existing dataset
FashionVC from fashion domain, we create a dataset from the
online fashion platform Ssense consisting of 15, 696 image-text
pairs labeled by 32 hierarchical categories. Extensive experiments
on two real-world datasets demonstrate the superiority of our model
over the state-of-the-art methods.</p>
</td>
</tr>

<tr>
	<td>2019</td>
	<td><a href="/publications/wu2019deep/">Deep Incremental Hashing Network for Efficient Image Retrieval</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Deep Incremental Hashing Network for Efficient Image Retrieval' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Deep Incremental Hashing Network for Efficient Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Deep%20Incremental%20Hashing%20Network%20for%20Efficient%20Image%20Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Dayan Wu, Qi Dai, Jing Liu, Bo Li, Weiping Wang</td>
	<td>CVPR</td>
	<td><p>Hashing has shown great potential in large-scale image retrieval due to its storage and computation efficiency, especially the recent deep supervised hashing methods. To achieve promising performance, deep supervised hashing methods require a large amount of training data from different classes. However, when images of new categories emerge, existing deep hashing methods have to retrain the CNN model and generate hash codes for all the database images again, which is impractical for large-scale retrieval system.
In this paper, we propose a novel deep hashing framework, called Deep Incremental Hashing Network (DIHN), for learning hash codes in an incremental manner. DIHN learns the hash codes for the new coming images directly, while keeping the old ones unchanged. Simultaneously, a deep hash function for query set is learned by preserving the similarities between training points. Extensive experiments on two widely used image retrieval benchmarks demonstrate that the proposed DIHN framework can significantly decrease the training time while keeping the state-of-the-art retrieval accuracy.</p>
</td>
</tr>

<tr>
	<td>2019</td>
	<td><a href="/publications/chen2019locality/">Locality-Sensitive Hashing for f-Divergences: Mutual Information Loss and Beyond</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Locality-Sensitive Hashing for f-Divergences: Mutual Information Loss and Beyond' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Locality-Sensitive Hashing for f-Divergences: Mutual Information Loss and Beyond' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Locality-Sensitive%20Hashing%20for%20f-Divergences:%20Mutual%20Information%20Loss%20and%20Beyond' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>L. Chen, H. Esfandiari, G. Fu, V. Mirrokni</td>
	<td>NIPS</td>
	<td><p>Computing approximate nearest neighbors in high dimensional spaces is a central problem in large-scale data mining with a wide range of applications in machine learning and data science. A popular and effective technique in computing nearest neighbors approximately is the locality-sensitive hashing (LSH) scheme. In this paper, we aim to develop LSH schemes for distance functions that measure the distance between two probability distributions, particularly for f-divergences as well as a generalization to capture mutual information loss. First, we provide a general framework to design LHS schemes for f-divergence distance functions and develop LSH schemes for the generalized Jensen-Shannon divergence and triangular discrimination in this framework. We show a two-sided approximation result for approximation of the generalized Jensen-Shannon divergence by the Hellinger distance, which may be of independent interest. Next, we show a general method of reducing the problem of designing an LSH scheme for a Krein kernel (which can be expressed as the difference of two positive definite kernels) to the problem of maximum inner product search. We exemplify this method by applying it to the mutual information loss, due to its several important applications such as model compression.</p>
</td>
</tr>

<tr>
	<td>2019</td>
	<td><a href="/publications/chen2019deep/">Deep Supervised Hashing With Anchor Graph</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Deep Supervised Hashing With Anchor Graph' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Deep Supervised Hashing With Anchor Graph' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Deep%20Supervised%20Hashing%20With%20Anchor%20Graph' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Yudong Chen, Zhihui Lai, Yujuan Ding, Kaiyi Lin, Wai Keung Wong</td>
	<td>ICCV</td>
	<td><p>Recently, a series of deep supervised hashing methods were proposed for binary code learning. However, due to the high computation cost and the limited hardware’s memory, these methods will first select a subset from the training set, and then form a mini-batch data to update the network in each iteration. Therefore, the remaining labeled data cannot be fully utilized and the model cannot directly obtain the binary codes of the entire training set for retrieval. To address these problems, this paper proposes an interesting regularized deep model to seamlessly integrate the advantages of deep hashing and efficient binary code learning by using the anchor graph. As such, the deep features and label matrix can be jointly used to optimize the binary codes, and the network can obtain more discriminative feedback from the linear combinations of the learned bits. Moreover, we also reveal the algorithm mechanism and its computation essence. Experiments on three large-scale datasets indicate that the proposed method achieves better retrieval performance with less training time compared to previous deep hashing methods.</p>
</td>
</tr>

<tr>
	<td>2019</td>
	<td><a href="/publications/chaidaroon2019deep/">Deep Semantic Text Hashing with Weak Supervision</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Deep Semantic Text Hashing with Weak Supervision' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Deep Semantic Text Hashing with Weak Supervision' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Deep%20Semantic%20Text%20Hashing%20with%20Weak%20Supervision' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Suthee Chaidaroon, Travis Ebesu, Yi Fang</td>
	<td>SIGIR</td>
	<td><p>With an ever increasing amount of data available on the web, fast similarity search has become the critical component for large-scale information retrieval systems. One solution is semantic hashing which designs binary codes to accelerate similarity search. Recently, deep learning has been successfully applied to the semantic hashing problem and produces high-quality compact binary codes compared to traditional methods. However, most state-of-the-art semantic hashing approaches require large amounts of hand-labeled training data which are often expensive and time consuming to collect. The cost of getting labeled data is the key bottleneck in deploying these hashing methods. Motivated by the recent success in machine learning that makes use of weak supervision, we employ unsupervised ranking methods such as BM25 to extract weak signals from training data. We further introduce two deep generative semantic hashing models to leverage weak signals for text hashing. The experimental results on four public datasets show that our models can generate high-quality binary codes without using hand-labeled training data and significantly outperform the competitive unsupervised semantic hashing baselines.</p>
</td>
</tr>

<tr>
	<td>2019</td>
	<td><a href="/publications/su2019unsupervised/">Deep Joint-Semantics Reconstructing Hashing for Large-Scale Unsupervised Cross-Modal Retrieval</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Deep Joint-Semantics Reconstructing Hashing for Large-Scale Unsupervised Cross-Modal Retrieval' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Deep Joint-Semantics Reconstructing Hashing for Large-Scale Unsupervised Cross-Modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Deep%20Joint-Semantics%20Reconstructing%20Hashing%20for%20Large-Scale%20Unsupervised%20Cross-Modal%20Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Shupeng Su, Zhisheng Zhong, Chao Zhang</td>
	<td>ICCV</td>
	<td><p><img src="https://github.com/zzs1994/DJSRH/blob/master/page_image/DJRSH.png?raw=true" alt="Deep Joint-Semantics Reconstructing Hashing for Large-Scale Unsupervised Cross-Modal Retrieval" title="Deep Joint-Semantics Reconstructing Hashing for Large-Scale Unsupervised Cross-Modal Retrieval" /></p>

<p>Cross-modal hashing encodes the multimedia data into a common binary hash space in which the correlations among the samples from different modalities can be effectively measured. Deep cross-modal hashing further improves the retrieval performance as the deep neural networks can generate more semantic relevant features and hash codes. In this paper, we study the unsupervised deep cross-modal hash coding and propose Deep Joint Semantics Reconstructing Hashing (DJSRH), which has the following two main advantages. First, to learn binary codes that preserve the neighborhood structure of the original data, DJSRH constructs a novel joint-semantics affinity matrix which elaborately integrates the original neighborhood information from different modalities and accordingly is capable to capture the latent intrinsic semantic affinity for the input multi-modal instances. Second, DJSRH later trains the networks to generate binary codes that maximally reconstruct above joint-semantics relations via the proposed reconstructing framework, which is more competent for the batch-wise training as it reconstructs the specific similarity value unlike the common Laplacian constraint merely preserving the similarity order. Extensive experiments demonstrate the significant improvement by DJSRH in various cross-modal retrieval tasks.</p>
</td>
</tr>

<tr>
	<td>2019</td>
	<td><a href="/publications/li2019push/">Push for Quantization: Deep Fisher Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Push for Quantization: Deep Fisher Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Push for Quantization: Deep Fisher Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Push%20for%20Quantization:%20Deep%20Fisher%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Yunqiang Li, Wenjie Pei, Yufei zha, Jan van Gemert</td>
	<td>BMVC</td>
	<td><p>Current massive datasets demand light-weight access for analysis. Discrete hashing methods are thus beneficial because they map high-dimensional data to compact binary codes that are efficient to store and process, while preserving semantic similarity. To optimize powerful deep learning methods for image hashing, gradient-based methods are required. Binary codes, however, are discrete and thus have no continuous derivatives. Relaxing the problem by solving it in a continuous space and then quantizing the solution is not guaranteed to yield separable binary codes. The quantization needs to be included in the optimization. In this paper we push for quantization: We optimize maximum class separability in the binary space. We introduce a margin on distances between dissimilar image pairs as measured in the binary space. In addition to pair-wise distances, we draw inspiration from Fisher’s Linear Discriminant Analysis (Fisher LDA) to maximize the binary distances between classes and at the same time minimize the binary distance of images within the same class. Experiments on CIFAR-10, NUS-WIDE and ImageNet100 demonstrate compact codes comparing favorably to the current state of the art.</p>
</td>
</tr>

<tr>
	<td>2019</td>
	<td><a href="/publications/xu2019online/">Online Multi-modal Hashing with Dynamic Query-adaption</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Online Multi-modal Hashing with Dynamic Query-adaption' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Online Multi-modal Hashing with Dynamic Query-adaption' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Online%20Multi-modal%20Hashing%20with%20Dynamic%20Query-adaption' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Xu Lu, Lei Zhu, Zhiyong Cheng, Liqiang Nie and Huaxiang Zhang</td>
	<td>SIGIR</td>
	<td><p>Multi-modal hashing is an effective technique to support large-scale multimedia retrieval, due to its capability of encoding heterogeneous multi-modal features into compact and similarity-preserving binary codes. Although great progress has been achieved so far, existing methods still suffer from several problems, including: 1) All existing methods simply adopt fixed modality combination weights in online hashing process to generate the query hash codes. This strategy cannot adaptively capture the variations of different queries. 2) They either suffer from insufficient semantics (for unsupervised methods) or require high computation and storage cost (for the supervised methods, which rely on pair-wise semantic matrix). 3) They solve the hash codes with relaxed optimization strategy or bit-by-bit discrete optimization, which results in significant quantization loss or consumes considerable computation time. To address the above limitations, in this paper, we propose an Online Multi-modal Hashing with Dynamic Query-adaption (OMH-DQ) method in a novel fashion. Specifically, a self-weighted fusion strategy is designed to adaptively preserve the multi-modal feature information into hash codes by exploiting their complementarity. The hash codes are learned with the supervision of pair-wise semantic labels to enhance their discriminative capability, while avoiding the challenging symmetric similarity matrix factorization. Under such learning framework, the binary hash codes can be directly obtained with efficient operations and without quantization errors. Accordingly, our method can benefit from the semantic labels, and simultaneously, avoid the high computation complexity. Moreover, to accurately capture the query variations, at the online retrieval stage, we design a parameter-free online hashing module which can adaptively learn the query hash codes according to the dynamic query contents. Extensive experiments demonstrate the state-of-the-art performance of the proposed approach from various aspects.</p>
</td>
</tr>

<tr>
	<td>2019</td>
	<td><a href="/publications/yan2019deep/">Deep Hashing by Discriminating Hard Examples</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Deep Hashing by Discriminating Hard Examples' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Deep Hashing by Discriminating Hard Examples' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Deep%20Hashing%20by%20Discriminating%20Hard%20Examples' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Cheng Yan, Guansong Pang, Xiao Bai, Chunhua Shen, Jun Zhou, Edwin Hancock</td>
	<td>MM</td>
	<td><p>This paper tackles a rarely explored but critical problem within learning to hash, i.e., to learn hash codes that effectively discriminate hard similar and dissimilar examples, to empower large-scale image retrieval. Hard similar examples refer to image pairs from the same semantic class that demonstrate some shared appearance but have different fine-grained appearance. Hard dissimilar examples are image pairs that come from different semantic classes but exhibit similar appearance. These hard examples generally have a small distance due to the shared appearance. Therefore, effective encoding of the hard examples can well discriminate the relevant images within a small Hamming distance, enabling more accurate retrieval in the top-ranked returned images. However, most existing hashing methods cannot capture this key information as their optimization is dominated byeasy examples, i.e., distant similar/dissimilar pairs that share no or limited appearance. To address this problem, we introduce a novel Gamma distribution-enabled and symmetric Kullback-Leibler divergence-based loss, which is dubbed dual hinge loss because it works similarly as imposing two smoothed hinge losses on the respective similar and dissimilar pairs. Specifically, the loss enforces exponentially variant penalization on the hard similar (dissimilar) examples to emphasize and learn their fine-grained difference. It meanwhile imposes a bounding penalization on easy similar (dissimilar) examples to prevent the dominance of the easy examples in the optimization while preserving the high-level similarity (dissimilarity). This enables our model to well encode the key information carried by both easy and hard examples. Extensive empirical results on three widely-used image retrieval datasets show that (i) our method consistently and substantially outperforms state-of-the-art competing methods using hash codes of the same length and (ii) our method can use significantly (e.g., 50%-75%) shorter hash codes to perform substantially better than, or comparably well to, the competing methods.</p>
</td>
</tr>

<tr>
	<td>2019</td>
	<td><a href="/publications/yang2019distill/">DistillHash: Unsupervised Deep Hashing by Distilling Data Pairs</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=DistillHash: Unsupervised Deep Hashing by Distilling Data Pairs' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=DistillHash: Unsupervised Deep Hashing by Distilling Data Pairs' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=DistillHash:%20Unsupervised%20Deep%20Hashing%20by%20Distilling%20Data%20Pairs' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Erkun Yang, Tongliang Liu, Cheng Deng, Wei Liu, Dacheng Tao</td>
	<td>CVPR</td>
	<td><p>Due to the high storage and search efficiency, hashing
has become prevalent for large-scale similarity search. Particularly, deep hashing methods have greatly improved the
search performance under supervised scenarios. In contrast, unsupervised deep hashing models can hardly achieve
satisfactory performance due to the lack of reliable supervisory similarity signals.
 To address this issue, we propose
a novel deep unsupervised hashing model, dubbed DistillHash, which can learn a distilled data set consisted of data
pairs, which have confidence similarity signals. Specifically, we investigate the relationship between the initial
noisy similarity signals learned from local structures and
the semantic similarity labels assigned by a Bayes optimal
classifier. We show that under a mild assumption, some
data pairs, of which labels are consistent with those assigned by the Bayes optimal classifier, can be potentially
distilled. Inspired by this fact, we design a simple yet effective strategy to distill data pairs automatically and further
adopt a Bayesian learning framework to learn hash functions from the distilled data set. Extensive experimental results on three widely used benchmark datasets show that the
proposed DistillHash consistently accomplishes the stateof-the-art search performance.</p>
</td>
</tr>

<tr>
	<td>2019</td>
	<td><a href="/publications/shen2019embarass/">Embarrassingly Simple Binary Representation Learning</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Embarrassingly Simple Binary Representation Learning' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Embarrassingly Simple Binary Representation Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Embarrassingly%20Simple%20Binary%20Representation%20Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Yuming Shen, Jie Qin,Jiaxin Chen, Li Liu, and Fan Zhu</td>
	<td>ICCVW</td>
	<td><p>Recent binary representation learning models usually require sophisticated binary optimization, similarity measure or even generative models as auxiliaries. However, one may wonder whether these non-trivial components are needed to formulate practical and effective hashing models. In this paper, we answer the above question by proposing an embarrassingly simple approach to binary representation learning. With a simple classification objective, our model only incorporates two additional fully-connected layers onto the top of an arbitrary backbone network, whilst complying with the binary constraints during training. The proposed model lower-bounds the Information Bottleneck (IB) between data samples and their semantics, and can be related to many recent `learning to hash’ paradigms. We show that, when properly designed, even such a simple network can generate effective binary codes, by fully exploring data semantics without any held-out alternating updating steps or auxiliary models. Experiments are conducted on conventional large-scale benchmarks, i.e., CIFAR-10, NUS-WIDE, and ImageNet, where the proposed simple model outperforms the state-of-the-art methods.</p>
</td>
</tr>

<tr>
	<td>2019</td>
	<td><a href="/publications/huang2019accelerate/">Accelerate Learning of Deep Hashing With Gradient Attention</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Accelerate Learning of Deep Hashing With Gradient Attention' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Accelerate Learning of Deep Hashing With Gradient Attention' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Accelerate%20Learning%20of%20Deep%20Hashing%20With%20Gradient%20Attention' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Long-Kai Huang, Jianda Chen, Sinno Jialin Pan</td>
	<td>ICCV</td>
	<td><p>Recent years have witnessed the success of learning to hash in fast large-scale image retrieval. As deep learning has shown its superior performance on many computer vision applications, recent designs of learning-based hashing models have been moving from shallow ones to deep architectures. However, based on our analysis, we find that gradient descent based algorithms used in deep hashing models would potentially cause hash codes of a pair of training instances to be updated towards the directions of each other simultaneously during optimization. In the worst case, the paired hash codes switch their directions after update, and consequently, their corresponding distance in the Hamming space remain unchanged. This makes the overall learning process highly inefficient. To address this issue, we propose a new deep hashing model integrated with a novel gradient attention mechanism. Extensive experimental results on three benchmark datasets show that our proposed algorithm is able to accelerate the learning process and obtain competitive retrieval performance compared with state-of-the-art deep hashing models.</p>
</td>
</tr>

<tr>
	<td>2019</td>
	<td><a href="/publications/shi2019variable/">Variable-Length Quantization Strategy for Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Variable-Length Quantization Strategy for Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Variable-Length Quantization Strategy for Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Variable-Length%20Quantization%20Strategy%20for%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Yang Shi, Xiushan Nie, Xin Zhou, Xiaoming Xi, Yilong Yin</td>
	<td>ICIP</td>
	<td><p>Hashing is widely used to solve fast Approximate Nearest Neighbor (ANN) search problems, involves converting the original real-valued samples to binary-valued representations. The conventional quantization strategies, such as Single-Bit Quantization and Multi-Bit quantization, are considered ineffective, because of their serious information loss. To address this issue, we propose a novel variable-length quantization (VLQ) strategy for hashing. In the proposed VLQ technique, we divide all samples into different regions in each dimension firstly given the real-valued features of samples. Then we compute the dispersion degrees of these regions. Subsequently, we attempt to optimally assign different number of bits to each dimensions to obtain the minimum dispersion degree. Our experiments show that the VLQ strategy achieves not only superior performance over the state-of-the-art methods, but also has a faster retrieval speed on public datasets.</p>
</td>
</tr>



<tr>
	<td>2018</td>
	<td><a href="/publications/li2018scratch/">SCRATCH: A Scalable Discrete Matrix Factorization Hashing for Cross-Modal Retrieval</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=SCRATCH: A Scalable Discrete Matrix Factorization Hashing for Cross-Modal Retrieval' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=SCRATCH: A Scalable Discrete Matrix Factorization Hashing for Cross-Modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=SCRATCH:%20A%20Scalable%20Discrete%20Matrix%20Factorization%20Hashing%20for%20Cross-Modal%20Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Chuan-Xiang Li , Zhen-Duo Chen, Peng-Fei Zhang, Xin Luo, Liqiang Nie, Wei Zhang, Xin-Shun Xu</td>
	<td>MM</td>
	<td><p>In recent years, many hashing methods have been proposed for the cross-modal retrieval task. However, there are still some issues that need to be further explored. For example, some of them relax the binary constraints to generate the hash codes, which may generate large quantization error. Although some discrete schemes have been proposed, most of them are time-consuming. In addition, most of the existing supervised hashing methods use an n x n similarity matrix during the optimization, making them unscalable. To address these issues, in this paper, we present a novel supervised cross-modal hashing method—Scalable disCRete mATrix faCtorization Hashing, SCRATCH for short. It leverages the collective matrix factorization on the kernelized features and the semantic embedding with labels to find a latent semantic space to preserve the intra- and inter-modality similarities. In addition, it incorporates the label matrix instead of the similarity matrix into the loss function. Based on the proposed loss function and the iterative optimization algorithm, it can learn the hash functions and binary codes simultaneously. Moreover, the binary codes can be generated discretely, reducing the quantization error generated by the relaxation scheme. Its time complexity is linear to the size of the dataset, making it scalable to large-scale datasets. Extensive experiments on three benchmark datasets, namely, Wiki, MIRFlickr-25K, and NUS-WIDE, have verified that our proposed SCRATCH model outperforms several state-of-the-art unsupervised and supervised hashing methods for cross-modal retrieval.</p>
</td>
</tr>

<tr>
	<td>2018</td>
	<td><a href="/publications/cao2018hashgan/">HashGAN: Deep Learning to Hash with Pair Conditional Wasserstein GAN</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=HashGAN: Deep Learning to Hash with Pair Conditional Wasserstein GAN' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=HashGAN: Deep Learning to Hash with Pair Conditional Wasserstein GAN' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=HashGAN:%20Deep%20Learning%20to%20Hash%20with%20Pair%20Conditional%20Wasserstein%20GAN' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Yue Cao, Mingsheng Long, Bin Liu, Jiamin Wang</td>
	<td>CVPR</td>
	<td><p>Deep learning to hash improves image retrieval performance by end-to-end representation learning and hash coding from training data with pairwise similarity information.
Subject to the scarcity of similarity information that is often
expensive to collect for many application domains, existing
deep learning to hash methods may overfit the training data
and result in substantial loss of retrieval quality. This paper
presents HashGAN, a novel architecture for deep learning
to hash, which learns compact binary hash codes from both
real images and diverse images synthesized by generative
models. The main idea is to augment the training data with
nearly real images synthesized from a new Pair Conditional
Wasserstein GAN (PC-WGAN) conditioned on the pairwise
similarity information. Extensive experiments demonstrate
that HashGAN can generate high-quality binary hash codes
and yield state-of-the-art image retrieval performance on
three benchmarks, NUS-WIDE, CIFAR-10, and MS-COCO.</p>
</td>
</tr>

<tr>
	<td>2018</td>
	<td><a href="/publications/cakir2018hashing/">Hashing with Binary Matrix Pursuit</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Hashing with Binary Matrix Pursuit' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Hashing with Binary Matrix Pursuit' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Hashing%20with%20Binary%20Matrix%20Pursuit' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>F. Cakir, K. He, S. Sclaroff</td>
	<td>ECCV</td>
	<td><p>We propose theoretical and empirical improvements for two-stage hashing methods. We first provide a theoretical analysis on the quality of the binary codes and show that, under mild assumptions, a residual learning scheme can construct binary codes that fit any neighborhood structure with arbitrary accuracy. Secondly, we show that with high-capacity hash functions such as CNNs, binary code inference can be greatly simplified for many standard neighborhood definitions, yielding smaller optimization problems and more robust codes. Incorporating our findings, we propose a novel two-stage hashing method that significantly outperforms previous hashing studies on widely used image retrieval benchmarks.</p>
</td>
</tr>

<tr>
	<td>2018</td>
	<td><a href="/publications/ma2018progressive/">Progressive Generative Hashing for Image Retrieval</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Progressive Generative Hashing for Image Retrieval' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Progressive Generative Hashing for Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Progressive%20Generative%20Hashing%20for%20Image%20Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Yuqing Ma, Yue He, Fan Ding, Sheng Hu, Jun Li, Xianglong Liu</td>
	<td>IJCAI</td>
	<td><p>Recent years have witnessed the success of the emerging hashing techniques in large-scale image
retrieval. Owing to the great learning capacity,
deep hashing has become one of the most promising solutions, and achieved attractive performance
in practice. However, without semantic label information, the unsupervised deep hashing still remains
an open question. In this paper, we propose a novel
progressive generative hashing (PGH) framework
to help learn a discriminative hashing network in an
unsupervised way. Different from existing studies,
it first treats the hash codes as a kind of semantic
condition for the similar image generation, and simultaneously feeds the original image and its codes
into the generative adversarial networks (GANs).
The real images together with the synthetic ones
can further help train a discriminative hashing network based on a triplet loss. By iteratively inputting
the learnt codes into the hash conditioned GANs, we can progressively enable the hashing network
to discover the semantic relations. Extensive experiments on the widely-used image datasets demonstrate that PGH can significantly outperform stateof-the-art unsupervised hashing methods.</p>
</td>
</tr>

<tr>
	<td>2018</td>
	<td><a href="/publications/luo2018fast/">Fast Scalable Supervised Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Fast Scalable Supervised Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Fast Scalable Supervised Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Fast%20Scalable%20Supervised%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Xin Luo, Liqiang Nie, Xiangnan He,  Ye Wu,  Zhen-Duo Chen,  Xin-Shun Xu</td>
	<td>SIGIR</td>
	<td><p>Despite significant progress in supervised hashing, there are three
common limitations of existing methods. First, most pioneer methods discretely learn hash codes bit by bit, making the learning
procedure rather time-consuming. Second, to reduce the large complexity of the n by n pairwise similarity matrix, most methods apply
sampling strategies during training, which inevitably results in information loss and suboptimal performance; some recent methods
try to replace the large matrix with a smaller one, but the size is
still large. Third, among the methods that leverage the pairwise
similarity matrix, most of them only encode the semantic label
information in learning the hash codes, failing to fully capture
the characteristics of data. In this paper, we present a novel supervised hashing method, called Fast Scalable Supervised Hashing
(FSSH), which circumvents the use of the large similarity matrix by
introducing a pre-computed intermediate term whose size is independent with the size of training data. Moreover, FSSH can learn
the hash codes with not only the semantic information but also
the features of data. Extensive experiments on three widely used
datasets demonstrate its superiority over several state-of-the-art
methods in both accuracy and scalability. Our experiment codes
are available at: https://lcbwlx.wixsite.com/fssh.</p>
</td>
</tr>

<tr>
	<td>2018</td>
	<td><a href="/publications/rong2018locality/">Locality-Sensitive Hashing for Earthquake Detection: A Case Study of Scaling Data-Driven Science</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Locality-Sensitive Hashing for Earthquake Detection: A Case Study of Scaling Data-Driven Science' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Locality-Sensitive Hashing for Earthquake Detection: A Case Study of Scaling Data-Driven Science' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Locality-Sensitive%20Hashing%20for%20Earthquake%20Detection:%20A%20Case%20Study%20of%20Scaling%20Data-Driven%20Science' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Kexin Rong, Clara E. Yoon, Karianne J. Bergen, Hashem Elezabi,Peter Bailis, Philip Levis, Gregory C. Beroza</td>
	<td>VLDB</td>
	<td><p>In this work, we report on a novel application of Locality Sensitive
Hashing (LSH) to seismic data at scale. Based on the high waveform similarity between reoccurring earthquakes, our application
identifies potential earthquakes by searching for similar time series
segments via LSH. However, a straightforward implementation of
this LSH-enabled application has difficulty scaling beyond 3 months
of continuous time series data measured at a single seismic station.
As a case study of a data-driven science workflow, we illustrate how
domain knowledge can be incorporated into the workload to improve
both the efficiency and result quality. We describe several end-toend optimizations of the analysis pipeline from pre-processing to
post-processing, which allow the application to scale to time series data measured at multiple seismic stations. Our optimizations
enable an over 100× speedup in the end-to-end analysis pipeline.
This improved scalability enabled seismologists to perform seismic
analysis on more than ten years of continuous time series data from
over ten seismic stations, and has directly enabled the discovery of
597 new earthquakes near the Diablo Canyon nuclear power plant
in California and 6123 new earthquakes in New Zealand.</p>
</td>
</tr>

<tr>
	<td>2018</td>
	<td><a href="/publications/cao2018cauchy/">Deep Cauchy Hashing for Hamming Space Retrieval</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Deep Cauchy Hashing for Hamming Space Retrieval' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Deep Cauchy Hashing for Hamming Space Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Deep%20Cauchy%20Hashing%20for%20Hamming%20Space%20Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Yue Cao, Mingsheng Long, Bin Liu, Jianmin Wang</td>
	<td>CVPR</td>
	<td><p>Due to its computation efficiency and retrieval quality,
hashing has been widely applied to approximate nearest
neighbor search for large-scale image retrieval, while deep
hashing further improves the retrieval quality by end-toend representation learning and hash coding. With compact
hash codes, Hamming space retrieval enables the most efficient constant-time search that returns data points within a
given Hamming radius to each query, by hash table lookups
instead of linear scan. However, subject to the weak capability of concentrating relevant images to be within a small
Hamming ball due to mis-specified loss functions, existing deep hashing methods may underperform for Hamming
space retrieval.  This work presents Deep Cauchy Hashing
(DCH), a novel deep hashing model that generates compact
and concentrated binary hash codes to enable efficient and
effective Hamming space retrieval. The main idea is to design a pairwise cross-entropy loss based on Cauchy distribution, which penalizes significantly on similar image pairs
with Hamming distance larger than the given Hamming radius threshold. Comprehensive experiments demonstrate
that DCH can generate highly concentrated hash codes and
yield state-of-the-art Hamming space retrieval performance
on three datasets, NUS-WIDE, CIFAR-10, and MS-COCO.</p>
</td>
</tr>

<tr>
	<td>2018</td>
	<td><a href="/publications/long2018deep/">Deep Domain Adaptation Hashing with Adversarial Learning</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Deep Domain Adaptation Hashing with Adversarial Learning' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Deep Domain Adaptation Hashing with Adversarial Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Deep%20Domain%20Adaptation%20Hashing%20with%20Adversarial%20Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Fuchen Long, Ting Yao, Qi Dai, Xinmei Tian, Jiebo Luo, Tao Mei</td>
	<td>SIGIR</td>
	<td><p>The recent advances in deep neural networks have demonstrated high capability in a wide variety of scenarios. Nevertheless, fine-tuning deep models in a new domain still requires a significant amount of labeled data despite expensive labeling efforts. A valid question is how to leverage the source knowledge plus unlabeled or only sparsely labeled target data for learning a new model in target domain. The core problem is to bring the source and target distributions closer in the feature space. In the paper, we facilitate this issue in an adversarial learning framework, in which a domain discriminator is devised to handle domain shift. Particularly, we explore the learning in the context of hashing problem, which has been studied extensively due to its great efficiency in gigantic data. Specifically, a novel Deep Domain Adaptation Hashing with Adversarial learning (DeDAHA) architecture is presented, which mainly consists of three components: a deep convolutional neural networks (CNN) for learning basic image/frame representation followed by an adversary stream on one hand to optimize the domain discriminator, and on the other, to interact with each domain-specific hashing stream for encoding image representation to hash codes. The whole architecture is trained end-to-end by jointly optimizing two types of losses, i.e., triplet ranking loss to preserve the relative similarity ordering in the input triplets and adversarial loss to maximally fool the domain discriminator with the learnt source and target feature distributions. Extensive experiments are conducted on three domain transfer tasks, including cross-domain digits retrieval, image to image and image to video transfers, on several benchmarks. Our DeDAHA framework achieves superior results when compared to the state-of-the-art techniques.</p>
</td>
</tr>

<tr>
	<td>2018</td>
	<td><a href="/publications/song2018self/">Self-Supervised Video Hashing with Hierarchical Binary Auto-encoder</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Self-Supervised Video Hashing with Hierarchical Binary Auto-encoder' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Self-Supervised Video Hashing with Hierarchical Binary Auto-encoder' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Self-Supervised%20Video%20Hashing%20with%20Hierarchical%20Binary%20Auto-encoder' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Jingkuan Song, Hanwang Zhang, Xiangpeng Li, Lianli Gao, Meng Wang, Richang Hong</td>
	<td>TIP</td>
	<td><p>Existing video hash functions are built on three isolated stages: frame pooling, relaxed learning, and binarization, which have not adequately explored the temporal order of video frames in a joint binary optimization model, resulting in severe information loss. In this paper, we propose a novel unsupervised video hashing framework dubbed Self-Supervised Video Hashing (SSVH), that is able to capture the temporal nature of videos in an end-to-end learning-to-hash fashion. We specifically address two central problems: 1) how to design an encoder-decoder architecture to generate binary codes for videos; and 2) how to equip the binary codes with the ability of accurate video retrieval. We design a hierarchical binary autoencoder to model the temporal dependencies in videos with multiple granularities, and embed the videos into binary codes with less computations than the stacked architecture. Then, we encourage the binary codes to simultaneously reconstruct the visual content and neighborhood structure of the videos. Experiments on two real-world datasets (FCVID and YFCC) show that our SSVH method can significantly outperform the state-of-the-art methods and achieve the currently best performance on the task of unsupervised video retrieval.</p>
</td>
</tr>

<tr>
	<td>2018</td>
	<td><a href="/publications/su2018greedy/">Greedy Hash: Towards Fast Optimization for Accurate Hash Coding in CNN</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Greedy Hash: Towards Fast Optimization for Accurate Hash Coding in CNN' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Greedy Hash: Towards Fast Optimization for Accurate Hash Coding in CNN' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Greedy%20Hash:%20Towards%20Fast%20Optimization%20for%20Accurate%20Hash%20Coding%20in%20CNN' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Shupeng Su, Chao Zhang, Kai Han, Yonghong Tian</td>
	<td>NIPS</td>
	<td><p>To convert the input into binary code, hashing algorithm has been widely used for approximate nearest neighbor search on large-scale image sets due to its computation and storage efficiency. Deep hashing further improves the retrieval quality by combining the hash coding with deep neural network. However, a major difficulty in deep hashing lies in the discrete constraints imposed on the network output, which generally makes the optimization NP hard. In this work, we adopt the greedy principle to tackle this NP hard problem by iteratively updating the network toward the probable optimal discrete solution in each iteration. A hash coding layer is designed to implement our approach which strictly uses the sign function in forward propagation to maintain the discrete constraints, while in back propagation the gradients are transmitted intactly to the front layer to avoid the vanishing gradients. In addition to the theoretical derivation, we provide a new perspective to visualize and understand the effectiveness and efficiency of our algorithm. Experiments on benchmark datasets show that our scheme outperforms state-of-the-art hashing methods in both supervised and unsupervised tasks.</p>
</td>
</tr>

<tr>
	<td>2018</td>
	<td><a href="/publications/shen2018nash/">NASH: Toward End-to-End Neural Architecture for Generative Semantic Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=NASH: Toward End-to-End Neural Architecture for Generative Semantic Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=NASH: Toward End-to-End Neural Architecture for Generative Semantic Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=NASH:%20Toward%20End-to-End%20Neural%20Architecture%20for%20Generative%20Semantic%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Dinghan Shen, Qinliang Su, Paidamoyo Chapfuwa, Wenlin Wang, Guoyin Wang, Lawrence Carin, Ricardo Henao</td>
	<td>ACL</td>
	<td><p>Semantic hashing has become a powerful paradigm for fast similarity search
in many information retrieval systems.
While fairly successful, previous techniques generally require two-stage training, and the binary constraints are handled ad-hoc. In this paper, we present
an end-to-end Neural Architecture for Semantic Hashing (NASH), where the binary
hashing codes are treated as Bernoulli latent variables. A neural variational inference framework is proposed for training, where gradients are directly backpropagated through the discrete latent
variable to optimize the hash function.
We also draw connections between proposed method and rate-distortion theory, which provides a theoretical foundation for the effectiveness of the proposed framework. Experimental results on
three public datasets demonstrate that our
method significantly outperforms several
state-of-the-art models on both unsupervised and supervised scenarios.</p>
</td>
</tr>

<tr>
	<td>2018</td>
	<td><a href="/publications/he2018hashing/">Hashing as Tie-Aware Learning to Rank</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Hashing as Tie-Aware Learning to Rank' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Hashing as Tie-Aware Learning to Rank' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Hashing%20as%20Tie-Aware%20Learning%20to%20Rank' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>K. He, F. Cakir, S. Bargal, S. Sclaroff</td>
	<td>CVPR</td>
	<td><p>Hashing, or learning binary embeddings of data, is frequently used in nearest neighbor retrieval. In this paper, we develop learning to rank formulations for hashing, aimed at directly optimizing ranking-based evaluation metrics such as Average Precision (AP) and Normalized Discounted Cumulative Gain (NDCG). We first observe that the integer-valued Hamming distance often leads to tied rankings, and propose to use tie-aware versions of AP and NDCG to evaluate hashing for retrieval. Then, to optimize tie-aware ranking metrics, we derive their continuous relaxations, and perform gradient-based optimization with deep neural networks. Our results establish the new state-of-the-art for image retrieval by Hamming ranking in common benchmarks.</p>
</td>
</tr>

<tr>
	<td>2018</td>
	<td><a href="/publications/shen2018unsupervised/">Unsupervised Deep Hashing with Similarity-Adaptive and Discrete Optimization</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Unsupervised Deep Hashing with Similarity-Adaptive and Discrete Optimization' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Unsupervised Deep Hashing with Similarity-Adaptive and Discrete Optimization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Unsupervised%20Deep%20Hashing%20with%20Similarity-Adaptive%20and%20Discrete%20Optimization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Fumin Shen, Yan Xu, Li Liu, Yang Yang, Zi Huang, Heng Tao Shen</td>
	<td>TPAMI</td>
	<td><p>Recent vision and learning studies show that learning compact hash codes can facilitate massive data processing
with significantly reduced storage and computation. Particularly, learning deep hash functions has greatly improved the retrieval
performance, typically under the semantic supervision. In contrast, current unsupervised deep hashing algorithms can hardly achieve
satisfactory performance due to either the relaxed optimization or absence of similarity-sensitive objective. In this work, we propose a
simple yet effective unsupervised hashing framework, named Similarity-Adaptive Deep Hashing (SADH), which alternatingly proceeds
over three training modules: deep hash model training, similarity graph updating and binary code optimization. The key difference from
the widely-used two-step hashing method is that the output representations of the learned deep model help update the similarity graph
matrix, which is then used to improve the subsequent code optimization. In addition, for producing high-quality binary codes, we devise
an effective discrete optimization algorithm which can directly handle the binary constraints with a general hashing loss. Extensive
experiments validate the efficacy of SADH, which consistently outperforms the state-of-the-arts by large gaps.</p>
</td>
</tr>



<tr>
	<td>2017</td>
	<td><a href="/publications/wang2017survey/">A Survey on Learning to Hash</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=A Survey on Learning to Hash' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=A Survey on Learning to Hash' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=A%20Survey%20on%20Learning%20to%20Hash' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Jingdong Wang, Ting Zhang, Jingkuan Song, Nicu Sebe, and Heng Tao Shen</td>
	<td>TPAMI</td>
	<td><p>Nearest neighbor search is a problem of finding the data points from the database such that the distances from them to the
query point are the smallest. Learning to hash is one of the major solutions to this problem and has been widely studied recently. In this
paper, we present a comprehensive survey of the learning to hash algorithms, categorize them according to the manners of preserving
the similarities into: pairwise similarity preserving, multiwise similarity preserving, implicit similarity preserving, as well as quantization,
and discuss their relations. We separate quantization from pairwise similarity preserving as the objective function is very different
though quantization, as we show, can be derived from preserving the pairwise similarities. In addition, we present the evaluation
protocols, and the general performance analysis, and point out that the quantization algori</p>
</td>
</tr>

<tr>
	<td>2017</td>
	<td><a href="/publications/qiu2017deep/">Deep Semantic Hashing with Generative Adversarial Networks </a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Deep Semantic Hashing with Generative Adversarial Networks ' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Deep Semantic Hashing with Generative Adversarial Networks ' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Deep%20Semantic%20Hashing%20with%20Generative%20Adversarial%20Networks%20' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Zhaofan Qiu, Yingwei Pan, Ting Yao, Tao Mei</td>
	<td>SIGIR</td>
	<td><p>Hashing has been a widely-adopted technique for nearest
neighbor search in large-scale image retrieval tasks. Recent research has shown that leveraging supervised information can
lead to high quality hashing. However, the cost of annotating
data is often an obstacle when applying supervised hashing
to a new domain. Moreover, the results can suffer from the
robustness problem as the data at training and test stage
may come from different distributions. This paper studies
the exploration of generating synthetic data through semisupervised generative adversarial networks (GANs), which
leverages largely unlabeled and limited labeled training data
to produce highly compelling data with intrinsic invariance
and global coherence, for better understanding statistical
structures of natural data. We demonstrate that the above
two limitations can be well mitigated by applying the synthetic data for hashing. Specifically, a novel deep semantic
hashing with GANs (DSH-GANs) is presented, which mainly
consists of four components: a deep convolution neural networks (CNN) for learning image representations, an adversary
stream to distinguish synthetic images from real ones, a hash
stream for encoding image representations to hash codes and
a classification stream. The whole architecture is trained endto-end by jointly optimizing three losses, i.e., adversarial loss
to correct label of synthetic or real for each sample, triplet
ranking loss to preserve the relative similarity ordering in the
input real-synthetic triplets and classification loss to classify
each sample accurately. Extensive experiments conducted on
both CIFAR-10 and NUS-WIDE image benchmarks validate the capability of exploiting synthetic images for hashing. Our
framework also achieves superior results when compared to
state-of-the-art deep hash models.</p>
</td>
</tr>

<tr>
	<td>2017</td>
	<td><a href="/publications/li2017deep/">Deep Supervised Discrete Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Deep Supervised Discrete Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Deep Supervised Discrete Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Deep%20Supervised%20Discrete%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Qi Li, Zhenan Sun, Ran He, Tieniu Tan</td>
	<td>NIPS</td>
	<td><p>With the rapid growth of image and video data on the web, hashing has been
extensively studied for image or video search in recent years. Benefiting from
recent advances in deep learning, deep hashing methods have achieved promising
results for image retrieval. However, there are some limitations of previous deep
hashing methods (e.g., the semantic information is not fully exploited). In this
paper, we develop a deep supervised discrete hashing algorithm based on the
assumption that the learned binary codes should be ideal for classification. Both the
pairwise label information and the classification information are used to learn the
hash codes within one stream framework. We constrain the outputs of the last layer
to be binary codes directly, which is rarely investigated in deep hashing algorithm.
Because of the discrete nature of hash codes, an alternating minimization method
is used to optimize the objective function. Experimental results have shown that
our method outperforms current state-of-the-art methods on benchmark datasets.</p>
</td>
</tr>

<tr>
	<td>2017</td>
	<td><a href="/publications/cakir2017online/">MIHash: Online Hashing with Mutual Information</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=MIHash: Online Hashing with Mutual Information' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=MIHash: Online Hashing with Mutual Information' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=MIHash:%20Online%20Hashing%20with%20Mutual%20Information' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>F. Cakir, K. He, S. Bargal, S. Sclaroff</td>
	<td>ICCV</td>
	<td><p>Learning-based hashing methods are widely used for
nearest neighbor retrieval, and recently, online hashing
methods have demonstrated good performance-complexity
trade-offs by learning hash functions from streaming data.
In this paper, we first address a key challenge for online
hashing: the binary codes for indexed data must be recomputed
to keep pace with updates to the hash functions.
We propose an efficient quality measure for hash functions,
based on an information-theoretic quantity, mutual information,
and use it successfully as a criterion to eliminate
unnecessary hash table updates. Next, we also show how to
optimize the mutual information objective using stochastic
gradient descent. We thus develop a novel hashing method,
MIHash, that can be used in both online and batch settings.
Experiments on image retrieval benchmarks (including a
2.5M image dataset) confirm the effectiveness of our formulation,
both in reducing hash table recomputations and
in learning high-quality hash functions.</p>
</td>
</tr>

<tr>
	<td>2017</td>
	<td><a href="/publications/cao2017collective/">Collective Deep Quantization for Efficient Cross-Modal Retrieval</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Collective Deep Quantization for Efficient Cross-Modal Retrieval' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Collective Deep Quantization for Efficient Cross-Modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Collective%20Deep%20Quantization%20for%20Efficient%20Cross-Modal%20Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Yue Cao, Mingsheng Long, Jianmin Wang, Shichen Liu</td>
	<td>AAAI</td>
	<td><p>Cross-modal similarity retrieval is a problem about designing a retrieval system that supports querying across
content modalities, e.g., using an image to retrieve for
texts. This paper presents a compact coding solution for
efficient cross-modal retrieval, with a focus on the quantization approach which has already shown the superior
performance over the hashing solutions in single-modal
similarity retrieval. We propose a collective deep quantization (CDQ) approach, which is the first attempt to
introduce quantization in end-to-end deep architecture
for cross-modal retrieval. The major contribution lies in
jointly learning deep representations and the quantizers
for both modalities using carefully-crafted hybrid networks and well-specified loss functions. In addition, our
approach simultaneously learns the common quantizer
codebook for both modalities through which the crossmodal correlation can be substantially enhanced. CDQ
enables efficient and effective cross-modal retrieval using inner product distance computed based on the common codebook with fast distance table lookup. Extensive experiments show that CDQ yields state of the art
cross-modal retrieval results on standard benchmarks.</p>
</td>
</tr>

<tr>
	<td>2017</td>
	<td><a href="/publications/cao2017correlation/">Correlation Autoencoder Hashing for Supervised Cross-Modal Search</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Correlation Autoencoder Hashing for Supervised Cross-Modal Search' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Correlation Autoencoder Hashing for Supervised Cross-Modal Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Correlation%20Autoencoder%20Hashing%20for%20Supervised%20Cross-Modal%20Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Yue Cao, Mingsheng Long, Jianmin Wang, Han Zhu</td>
	<td>BMVC</td>
	<td><p>Hashing is widely applied to approximate nearest neighbor search for large-scale multimodal retrieval with storage and computation efficiency. Cross-modal hashing improves the quality of hash coding by exploiting semantic correlations across different modalities. Existing cross-modal hashing methods first transform data into low-dimensional feature vectors, and then generate binary codes by another separate quantization step. However, suboptimal hash codes may be generated since the quantization error is not explicitly minimized and the feature representation is not jointly optimized with the binary codes.
This paper presents a Correlation Hashing Network (CHN) approach to cross-modal hashing, which jointly learns good data representation tailored to hash coding and formally controls the quantization error. The proposed CHN is a hybrid deep architecture that constitutes a convolutional neural network for learning good image representations, a multilayer perception for learning good text representations, two hashing layers for generating compact binary codes, and a structured max-margin loss that integrates all things together to enable learning similarity-preserving and high-quality hash codes. Extensive empirical study shows that CHN yields state of the art cross-modal retrieval performance on standard benchmarks.</p>
</td>
</tr>

<tr>
	<td>2017</td>
	<td><a href="/publications/cao2017hashnet/">HashNet: Deep Learning to Hash by Continuation</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=HashNet: Deep Learning to Hash by Continuation' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=HashNet: Deep Learning to Hash by Continuation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=HashNet:%20Deep%20Learning%20to%20Hash%20by%20Continuation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Zhangjie Cao, Mingsheng Long, Jianmin Wang, Philip S. Yu</td>
	<td>CVPR</td>
	<td><p>Learning to hash has been widely applied to approximate nearest neighbor search for large-scale multimedia retrieval, due to its computation efficiency and retrieval quality. Deep learning to hash, which improves retrieval quality
by end-to-end representation learning and hash encoding,
has received increasing attention recently. Subject to the illposed gradient difficulty in the optimization with sign activations, existing deep learning to hash methods need to first
learn continuous representations and then generate binary
hash codes in a separated binarization step, which suffer
from substantial loss of retrieval quality.  This work presents
HashNet, a novel deep architecture for deep learning to
hash by continuation method with convergence guarantees,
which learns exactly binary hash codes from imbalanced
similarity data. The key idea is to attack the ill-posed gradient problem in optimizing deep networks with non-smooth
binary activations by continuation method, in which we begin from learning an easier network with smoothed activation function and let it evolve during the training, until it
eventually goes back to being the original, difficult to optimize, deep network with the sign activation function. Comprehensive empirical evidence shows that HashNet can generate exactly binary hash codes and yield state-of-the-art
multimedia retrieval performance on standard benchmarks.</p>
</td>
</tr>

<tr>
	<td>2017</td>
	<td><a href="/publications/chaidaroon2017variational/">Variational Deep Semantic Hashing for Text Documents</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Variational Deep Semantic Hashing for Text Documents' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Variational Deep Semantic Hashing for Text Documents' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Variational%20Deep%20Semantic%20Hashing%20for%20Text%20Documents' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Suthee Chaidaroon, Yi Fang</td>
	<td>SIGIR</td>
	<td><p>As the amount of textual data has been rapidly increasing over
the past decade, efficient similarity search methods have become
a crucial component of large-scale information retrieval systems.
A popular strategy is to represent original data samples by compact binary codes through hashing. A spectrum of machine learning methods have been utilized, but they often lack expressiveness
and flexibility in modeling to learn effective representations. The
recent advances of deep learning in a wide range of applications
has demonstrated its capability to learn robust and powerful feature representations for complex data. Especially, deep generative
models naturally combine the expressiveness of probabilistic generative models with the high capacity of deep neural networks,
which is very suitable for text modeling. However, little work has
leveraged the recent progress in deep learning for text hashing. In this paper, we propose a series of novel deep document generative models for text hashing. The first proposed model is unsupervised while the second one is supervised by utilizing document labels/tags for hashing. The third model further considers document-specific factors that affect the generation of words. The probabilistic generative formulation of the proposed models provides a principled framework for model extension, uncertainty estimation, simulation, and interpretability. Based on variational inference and reparameterization, the proposed models can be interpreted as encoder-decoder deep neural networks and thus they are capable of learning complex nonlinear distributed representations of the original documents. We conduct a comprehensive set of experiments on four public testbeds. The experimental results have demonstrated the effectiveness of the proposed supervised learning models for text hashing.</p>
</td>
</tr>

<tr>
	<td>2017</td>
	<td><a href="/publications/wu2017deep/">Deep Supervised Hashing for Multi-Label and Large-Scale Image Retrieval</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Deep Supervised Hashing for Multi-Label and Large-Scale Image Retrieval' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Deep Supervised Hashing for Multi-Label and Large-Scale Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Deep%20Supervised%20Hashing%20for%20Multi-Label%20and%20Large-Scale%20Image%20Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Dayan Wu, Zheng Lin, Bo Li, Mingzhen Ye, Weiping Wang</td>
	<td>ICMR</td>
	<td><p>One of the most challenging tasks in large-scale multi-label image retrieval is to map images into binary codes while preserving multilevel semantic similarity. Recently, several deep supervised hashing methods have been proposed to learn hash functions that preserve multilevel semantic similarity with deep convolutional neural networks. However, these triplet label based methods try to preserve the ranking order of images according to their similarity degrees to the queries while not putting direct constraints on the distance between the codes of very similar images. Besides, the current evaluation criteria are not able to measure the performance of existing hashing methods on preserving fine-grained multilevel semantic similarity. To tackle these issues, we propose a novel Deep Multilevel Semantic Similarity Preserving Hashing (DMSSPH) method to learn compact similarity-preserving binary codes for the huge body of multi-label image data with deep convolutional neural networks. In our approach, we make the best of the supervised information in the form of pairwise labels to maximize the discriminability of output binary codes. Extensive evaluations conducted on several benchmark datasets demonstrate that the proposed method significantly outperforms the state-of-the-art supervised and unsupervised hashing methods at the accuracies of top returned images, especially for shorter binary codes. Meanwhile, the proposed method shows better performance on preserving fine-grained multilevel semantic similarity according to the results under the Jaccard coefficient based evaluation criteria we propose.</p>
</td>
</tr>

<tr>
	<td>2017</td>
	<td><a href="/publications/jiang2017deep/">Deep Cross-Modal Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Deep Cross-Modal Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Deep Cross-Modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Deep%20Cross-Modal%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Qing-Yuan Jiang, Wu-Jun Li</td>
	<td>CVPR</td>
	<td><p>Due to its low storage cost and fast query speed, crossmodal hashing (CMH) has been widely used for similarity
search in multimedia retrieval applications. However, most
existing CMH methods are based on hand-crafted features
which might not be optimally compatible with the hash-code
learning procedure. As a result, existing CMH methods
with hand-crafted features may not achieve satisfactory
performance. In this paper, we propose a novel CMH
method, called deep cross-modal hashing (DCMH), by
integrating feature learning and hash-code learning into
the same framework. DCMH is an end-to-end learning
framework with deep neural networks, one for each modality, to perform feature learning from scratch. Experiments
on three real datasets with image-text modalities show
that DCMH can outperform other baselines to achieve
the state-of-the-art performance in cross-modal retrieval
applications.</p>
</td>
</tr>



<tr>
	<td>2016</td>
	<td><a href="/publications/moran2016enhancing/">Enhancing First Story Detection using Word Embeddings</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Enhancing First Story Detection using Word Embeddings' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Enhancing First Story Detection using Word Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Enhancing%20First%20Story%20Detection%20using%20Word%20Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>S. Moran, R. McCreadie, C. Macdonald, I. Ounis</td>
	<td>SIGIR</td>
	<td><p>In this paper we show how word embeddings can be used to increase the effectiveness of a state-of-the art Locality Sensitive Hashing (LSH) based first story detection (FSD) system over a standard tweet corpus. Vocabulary mismatch, in which related tweets use different words, is a serious hindrance to the effectiveness of a modern FSD system. In this case, a tweet could be flagged as a first story even if a related tweet, which uses different but synonymous words, was already returned as a first story. In this work, we propose a novel approach to mitigate this problem of lexical variation, based on tweet expansion. In particular, we propose to expand tweets with semantically related paraphrases identified via automatically mined word embeddings over a background tweet corpus. Through experimentation on a large data stream comprised of 50 million tweets, we show that FSD effectiveness can be improved by 9.5% over a state-of-the-art FSD system.</p>
</td>
</tr>

<tr>
	<td>2016</td>
	<td><a href="/publications/moran2016learning/">Learning to Project and Binarise for Hashing-Based Approximate Nearest Neighbour Search</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Learning to Project and Binarise for Hashing-Based Approximate Nearest Neighbour Search' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Learning to Project and Binarise for Hashing-Based Approximate Nearest Neighbour Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Learning%20to%20Project%20and%20Binarise%20for%20Hashing-Based%20Approximate%20Nearest%20Neighbour%20Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>S. Moran</td>
	<td>SIGIR</td>
	<td><p>In this paper we focus on improving the effectiveness of hashing-based approximate nearest neighbour search. Generating similarity preserving hashcodes for images has been shown to be an effective and efficient method for searching through large datasets. Hashcode generation generally involves two steps: bucketing the input feature space with a set of hyperplanes, followed by quantising the projection of the data-points onto the normal vectors to those hyperplanes. This procedure results in the makeup of the hashcodes depending on the positions of the data-points with respect to the hyperplanes in the feature space, allowing a degree of locality to be encoded into the hashcodes. In this paper we study the effect of learning both the hyperplanes and the thresholds as part of the same model. Most previous research either learn the hyperplanes assuming a fixed set of thresholds, or vice-versa. In our experiments over two standard image datasets we find statistically significant increases in retrieval effectiveness versus a host of state-of-the-art data-dependent and independent hashing models.</p>
</td>
</tr>

<tr>
	<td>2016</td>
	<td><a href="/publications/zhang2016efficient/">Efficient Training of Very Deep Neural Networks for Supervised Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Efficient Training of Very Deep Neural Networks for Supervised Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Efficient Training of Very Deep Neural Networks for Supervised Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Efficient%20Training%20of%20Very%20Deep%20Neural%20Networks%20for%20Supervised%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Ziming Zhang, Yuting Chen, Venkatesh Saligrama</td>
	<td>CVPR</td>
	<td><p>In this paper, we propose training very deep neural networks (DNNs) for supervised learning of hash codes. Existing methods in this context train relatively “shallow” networks limited by the issues arising in back propagation (e.e. vanishing gradients) as well as computational efficiency. We propose a novel and efficient training algorithm inspired by alternating direction method of multipliers (ADMM) that overcomes some of these limitations. Our method decomposes the training process into independent layer-wise local updates through auxiliary variables. Empirically we observe that our training algorithm always converges and its computational complexity is linearly proportional to the number of edges in the networks. Empirically we manage to train DNNs with 64 hidden layers and 1024 nodes per layer for supervised hashing in about 3 hours using a single GPU. Our proposed very deep supervised hashing (VDSH) method significantly outperforms the state-of-the-art on several benchmark datasets.</p>
</td>
</tr>

<tr>
	<td>2016</td>
	<td><a href="/publications/cao2016correlation/">Correlation Autoencoder Hashing for Supervised Cross-Modal Search</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Correlation Autoencoder Hashing for Supervised Cross-Modal Search' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Correlation Autoencoder Hashing for Supervised Cross-Modal Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Correlation%20Autoencoder%20Hashing%20for%20Supervised%20Cross-Modal%20Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Yue Cao, Mingsheng Long, Jianmin Wang, Han Zhu</td>
	<td>ICMR</td>
	<td><p>Due to its storage and query efficiency, hashing has been widely
applied to approximate nearest neighbor search from large-scale
datasets. While there is increasing interest in cross-modal hashing
which facilitates cross-media retrieval by embedding data from different modalities into a common Hamming space, how to distill the
cross-modal correlation structure effectively remains a challenging
problem. In this paper, we propose a novel supervised cross-modal
hashing method, Correlation Autoencoder Hashing (CAH), to learn
discriminative and compact binary codes based on deep autoencoders. Specifically, CAH jointly maximizes the feature correlation
revealed by bimodal data and the semantic correlation conveyed in
similarity labels, while embeds them into hash codes by nonlinear
deep autoencoders. Extensive experiments clearly show the superior effectiveness and efficiency of CAH against the state-of-the-art
hashing methods on standard cross-modal retrieval benchmarks.</p>
</td>
</tr>

<tr>
	<td>2016</td>
	<td><a href="/publications/cao2016deep/">Deep Visual-Semantic Hashing for Cross-Modal Retrieval</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Deep Visual-Semantic Hashing for Cross-Modal Retrieval' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Deep Visual-Semantic Hashing for Cross-Modal Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Deep%20Visual-Semantic%20Hashing%20for%20Cross-Modal%20Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Yue Cao, Mingsheng Long, Jianmin Wang, Qiang Yang, Philip S. Yu</td>
	<td>KDD</td>
	<td><p>Due to the storage and retrieval efficiency, hashing has been
widely applied to approximate nearest neighbor search for
large-scale multimedia retrieval. Cross-modal hashing, which
enables efficient retrieval of images in response to text queries
or vice versa, has received increasing attention recently. Most
existing work on cross-modal hashing does not capture the
spatial dependency of images and temporal dynamics of text
sentences for learning powerful feature representations and
cross-modal embeddings that mitigate the heterogeneity of
different modalities. This paper presents a new Deep Visual Semantic Hashing (DVSH) model that generates compact
hash codes of images and sentences in an end-to-end deep
learning architecture, which capture the intrinsic cross-modal
correspondences between visual data and natural language.
DVSH is a hybrid deep architecture that constitutes a visual semantic fusion network for learning joint embedding space
of images and text sentences, and two modality-specific hashing networks for learning hash functions to generate compact
binary codes. Our architecture effectively unifies joint multimodal embedding and cross-modal hashing, which is based
on a novel combination of Convolutional Neural Networks
over images, Recurrent Neural Networks over sentences, and
a structured max-margin objective that integrates all things
together to enable learning of similarity-preserving and highquality hash codes. Extensive empirical evidence shows that
our DVSH approach yields state of the art results in crossmodal retrieval experiments on image-sentences datasets,
i.e. standard IAPR TC-12 and large-scale Microsoft COCO.</p>
</td>
</tr>

<tr>
	<td>2016</td>
	<td><a href="/publications/rastegari2016xnor/">XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks </a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks ' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks ' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=XNOR-Net:%20ImageNet%20Classification%20Using%20Binary%20Convolutional%20Neural%20Networks%20' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>M. Rastegari, V. Ordonez, J. Redmon, A. Farhadi</td>
	<td>ECCV</td>
	<td><p>We propose two efficient approximations to standard convolutional neural networks: Binary-Weight-Networks and XNOR-Networks. In Binary-Weight-Networks, the filters are approximated with binary values
resulting in 32x memory saving. In XNOR-Networks, both the filters and the input to convolutional layers are binary. XNOR-Networks approximate convolutions using primarily binary operations. This
results in 58x faster convolutional operations and 32x memory savings. XNOR-Nets offer the possibility of running state-of-the-art networks on CPUs (rather than GPUs) in real-time. Our binary
networks are simple, accurate, efficient, and work on challenging visual tasks. We evaluate our approach on the ImageNet classification task. The classification accuracy with a Binary-Weight-Network
version of AlexNet is only 2.9\% less than the full-precision AlexNet (in top-1 measure). We compare our method with recent network binarization methods, BinaryConnect and BinaryNets, and outperform these methods by large margins on ImageNet, more than 16\% in top-1 accuracy.</p>
</td>
</tr>

<tr>
	<td>2016</td>
	<td><a href="/publications/wang2016affinity/">Affinity Preserving Quantization for Hashing: A Vector Quantization Approach to Learning Compact Binary Codes</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Affinity Preserving Quantization for Hashing: A Vector Quantization Approach to Learning Compact Binary Codes' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Affinity Preserving Quantization for Hashing: A Vector Quantization Approach to Learning Compact Binary Codes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Affinity%20Preserving%20Quantization%20for%20Hashing:%20A%20Vector%20Quantization%20Approach%20to%20Learning%20Compact%20Binary%20Codes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Z. Wang, L. Duan, T. Huang, W. Gao</td>
	<td>AAAI</td>
	<td><p>Hashing techniques are powerful for approximate nearest
neighbour (ANN) search. Existing quantization methods in
hashing are all focused on scalar quantization (SQ) which
is inferior in utilizing the inherent data distribution. In this
paper, we propose a novel vector quantization (VQ) method
named affinity preserving quantization (APQ) to improve the
quantization quality of projection values, which has significantly
boosted the performance of state-of-the-art hashing
techniques. In particular, our method incorporates the neighbourhood
structure in the pre- and post-projection data space
into vector quantization. APQ minimizes the quantization errors
of projection values as well as the loss of affinity property
of original space. An effective algorithm has been proposed
to solve the joint optimization problem in APQ, and
the extension to larger binary codes has been resolved by applying
product quantization to APQ. Extensive experiments
have shown that APQ consistently outperforms the state-ofthe-art
quantization methods, and has significantly improved
the performance of various hashing techniques.</p>
</td>
</tr>

<tr>
	<td>2016</td>
	<td><a href="/publications/kang2016columnsample/">Column Sampling Based Discrete Supervised Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Column Sampling Based Discrete Supervised Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Column Sampling Based Discrete Supervised Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Column%20Sampling%20Based%20Discrete%20Supervised%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Wang-Cheng Kang, Wu-Jun Li, Zhi-Hua Zhou</td>
	<td>AAAI</td>
	<td><p>By leveraging semantic (label) information, supervised hashing has demonstrated better accuracy than unsupervised hashing in many real applications. Because the hashing-code learning problem is essentially a discrete optimization problem which is hard to solve, most existing supervised hashing methods try to solve a relaxed continuous optimization problem by dropping the discrete constraints.
However, these methods typically suffer from poor performance due to the errors caused by the relaxation. Some other methods try to directly solve the discrete optimization problem. However, they are typically time-consuming and unscalable. In this paper, we propose a novel method, called column sampling based discrete supervised hashing (COSDISH), to directly learn the discrete hashing code from semantic information.
COSDISH is an iterative method, in each iteration of which several columns are sampled from the semantic similarity matrix and then the hashing code is decomposed into two parts which can be alternately optimized in a discrete way. Theoretical analysis shows that the learning (optimization) algorithm of COSDISH has a constant-approximation bound in each step of the alternating optimization procedure. Empirical results on datasets with semantic labels illustrate that COSDISH can outperform the state-of-the-art methods in real applications like image retrieval.</p>
</td>
</tr>

<tr>
	<td>2016</td>
	<td><a href="/publications/li2016feature/">Feature Learning based Deep Supervised Hashing with Pairwise Labels</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Feature Learning based Deep Supervised Hashing with Pairwise Labels' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Feature Learning based Deep Supervised Hashing with Pairwise Labels' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Feature%20Learning%20based%20Deep%20Supervised%20Hashing%20with%20Pairwise%20Labels' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Wu-Jun Li, Sheng Wang and Wang-Cheng Kang</td>
	<td>IJCAI</td>
	<td><p>Recent years have witnessed wide application of
hashing for large-scale image retrieval. However,
most existing hashing methods are based on handcrafted features which might not be optimally compatible with the hashing procedure. Recently, deep
hashing methods have been proposed to perform simultaneous feature learning and hash-code learning with deep neural networks, which have shown
better performance than traditional hashing methods with hand-crafted features. Most of these deep
hashing methods are supervised whose supervised
information is given with triplet labels. For another common application scenario with pairwise labels, there have not existed methods for simultaneous feature learning and hash-code learning. In this
paper, we propose a novel deep hashing method,
called deep pairwise-supervised hashing (DPSH),
to perform simultaneous feature learning and hashcode learning for applications with pairwise labels.
Experiments on real datasets show that our DPSH
method can outperform other methods to achieve
the state-of-the-art performance in image retrieval
applications.</p>
</td>
</tr>

<tr>
	<td>2016</td>
	<td><a href="/publications/zhu2016deep/">Deep Hashing Network for Efficient Similarity Retrieval</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Deep Hashing Network for Efficient Similarity Retrieval' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Deep Hashing Network for Efficient Similarity Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Deep%20Hashing%20Network%20for%20Efficient%20Similarity%20Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Han Zhu, Mingsheng Long, Jianmin Wang, Yue Cao</td>
	<td>AAAI</td>
	<td><p>Due to the storage and retrieval efficiency, hashing has been widely deployed to approximate nearest neighbor search for large-scale multimedia retrieval. Supervised hashing, which improves the quality of hash coding by exploiting the semantic similarity on data pairs, has received increasing attention recently. For most existing supervised hashing methods for image retrieval, an image is first represented as a vector of hand-crafted or machine-learned features, followed by another separate quantization step that generates binary codes.
However, suboptimal hash coding may be produced, because the quantization error is not statistically minimized and the feature representation is not optimally compatible with the binary coding. In this paper, we propose a novel Deep Hashing Network (DHN) architecture for supervised hashing, in which we jointly learn good image representation tailored to hash coding and formally control the quantization error.
The DHN model constitutes four key components: (1) a sub-network with multiple convolution-pooling layers to capture image representations; (2) a fully-connected hashing layer to generate compact binary hash codes; (3) a pairwise cross-entropy loss layer for similarity-preserving learning; and (4) a pairwise quantization loss for controlling hashing quality. Extensive experiments on standard image retrieval datasets show the proposed DHN model yields substantial boosts over latest state-of-the-art hashing methods.</p>
</td>
</tr>



<tr>
	<td>2015</td>
	<td><a href="/publications/carreira2015hashing/">Hashing with Binary Autoencoders</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Hashing with Binary Autoencoders' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Hashing with Binary Autoencoders' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Hashing%20with%20Binary%20Autoencoders' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>M. Carreira-Perpinan, R. Raziperchikolaei</td>
	<td>CVPR</td>
	<td><p>An attractive approach for fast search in image
databases is binary hashing, where each high-dimensional,
real-valued image is mapped onto a low-dimensional, binary
vector and the search is done in this binary space.
Finding the optimal hash function is difficult because it involves
binary constraints, and most approaches approximate
the optimization by relaxing the constraints and then
binarizing the result. Here, we focus on the binary autoencoder
model, which seeks to reconstruct an image from the
binary code produced by the hash function. We show that
the optimization can be simplified with the method of auxiliary
coordinates. This reformulates the optimization as
alternating two easier steps: one that learns the encoder
and decoder separately, and one that optimizes the code for
each image. Image retrieval experiments show the resulting
hash function outperforms or is competitive with state-ofthe-art
methods for binary hashing.</p>
</td>
</tr>

<tr>
	<td>2015</td>
	<td><a href="/publications/xu2015convolutional/">Convolutional Neural Networks for Text Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Convolutional Neural Networks for Text Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Convolutional Neural Networks for Text Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Convolutional%20Neural%20Networks%20for%20Text%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Jiaming Xu, PengWang, Guanhua Tian, Bo Xu, Jun Zhao, Fangyuan Wang, Hongwei Hao</td>
	<td>IJCAI</td>
	<td><p>Hashing, as a popular approximate nearest neighbor
search, has been widely used for large-scale similarity search. Recently, a spectrum of machine learning
methods are utilized to learn similarity-preserving
binary codes. However, most of them directly encode the explicit features, keywords, which fail to
preserve the accurate semantic similarities in binary code beyond keyword matching, especially on
short texts. Here we propose a novel text hashing
framework with convolutional neural networks. In
particular, we first embed the keyword features into
compact binary code with a locality preserving constraint. Meanwhile word features and position features are together fed into a convolutional network to
learn the implicit features which are further incorporated with the explicit features to fit the pre-trained
binary code. Such base method can be successfully
accomplished without any external tags/labels, and
other three model variations are designed to integrate tags/labels. Experimental results show the
superiority of our proposed approach over several
state-of-the-art hashing methods when tested on one
short text dataset as well as one normal text dataset.</p>
</td>
</tr>

<tr>
	<td>2015</td>
	<td><a href="/publications/lin2015deep/">Deep learning of binary hash codes for fast image retrieval</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Deep learning of binary hash codes for fast image retrieval' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Deep learning of binary hash codes for fast image retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Deep%20learning%20of%20binary%20hash%20codes%20for%20fast%20image%20retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Kevin Lin, Huei-Fang Yang, Jen-Hao Hsiao, Chu-Song Chen</td>
	<td>CVPRW</td>
	<td><p>Approximate nearest neighbor search is an efficient strategy for large-scale image retrieval. Encouraged by the recent advances in convolutional neural networks (CNNs), we propose an effective deep learning framework to generate binary hash codes for fast image retrieval. Our idea is that when the data labels are available, binary codes can be learned by employing a hidden layer for representing the latent concepts that dominate the class labels.
he utilization of the CNN also allows for learning image representations. Unlike other supervised methods that require pair-wised inputs for binary code learning, our method learns hash codes and image representations in a point-wised manner, making it suitable for large-scale datasets. Experimental results show that our method outperforms several state-of-the-art hashing algorithms on the CIFAR-10 and MNIST datasets. We further demonstrate its scalability and efficacy on a large-scale dataset of 1 million clothing images.</p>
</td>
</tr>

<tr>
	<td>2015</td>
	<td><a href="/publications/lin2015semantics/">Semantics-Preserving Hashing for Cross-View Retrieval</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Semantics-Preserving Hashing for Cross-View Retrieval' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Semantics-Preserving Hashing for Cross-View Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Semantics-Preserving%20Hashing%20for%20Cross-View%20Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Zijia Lin, Guiguang Ding, Mingqing Hu and Jianmin Wang</td>
	<td>CVPR</td>
	<td><p>With benefits of low storage costs and high query speeds,
hashing methods are widely researched for efficiently retrieving large-scale data, which commonly contains multiple views, e.g. a news report with images, videos and texts.
In this paper, we study the problem of cross-view retrieval
and propose an effective Semantics-Preserving Hashing
method, termed SePH. Given semantic affinities of training data as supervised information, SePH transforms them
into a probability distribution and approximates it with tobe-learnt hash codes in Hamming space via minimizing the
Kullback-Leibler divergence. Then kernel logistic regression with a sampling strategy is utilized to learn the nonlinear projections from features in each view to the learnt
hash codes. And for any unseen instance, predicted hash
codes and their corresponding output probabilities from observed views are utilized to determine its unified hash code,
using a novel probabilistic approach. Extensive experiments conducted on three benchmark datasets well demonstrate the effectiveness and reasonableness of SePH.</p>
</td>
</tr>

<tr>
	<td>2015</td>
	<td><a href="/publications/liong2015using/">Deep Hashing for Compact Binary Codes Learning</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Deep Hashing for Compact Binary Codes Learning' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Deep Hashing for Compact Binary Codes Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Deep%20Hashing%20for%20Compact%20Binary%20Codes%20Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>V. Liong, J. Lu, G. Wang, P. Moulin, J. Zhou</td>
	<td>CVPR</td>
	<td><p>In this paper, we propose a new deep hashing (DH) approach
to learn compact binary codes for large scale visual
search. Unlike most existing binary codes learning methods
which seek a single linear projection to map each sample
into a binary vector, we develop a deep neural network
to seek multiple hierarchical non-linear transformations to
learn these binary codes, so that the nonlinear relationship
of samples can be well exploited. Our model is learned under
three constraints at the top layer of the deep network:
1) the loss between the original real-valued feature descriptor
and the learned binary vector is minimized, 2) the binary
codes distribute evenly on each bit, and 3) different bits
are as independent as possible. To further improve the discriminative
power of the learned binary codes, we extend
DH into supervised DH (SDH) by including one discriminative
term into the objective function of DH which simultaneously
maximizes the inter-class variations and minimizes
the intra-class variations of the learned binary codes. Experimental
results show the superiority of the proposed approach
over the state-of-the-arts.</p>
</td>
</tr>

<tr>
	<td>2015</td>
	<td><a href="/publications/li2015bit/">0-Bit Consistent Weighted Sampling</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=0-Bit Consistent Weighted Sampling' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=0-Bit Consistent Weighted Sampling' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=0-Bit%20Consistent%20Weighted%20Sampling' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>P. Li</td>
	<td>KDD</td>
	<td><p>We develop 0-bit consistent weighted sampling (CWS) for efficiently estimating min-max kernel, which is a generalization of the resemblance kernel originally designed for binary data. Because the estimator of 0-bit CWS constitutes a positive definite kernel, this method can be naturally applied to large-scale data mining problems. Basically, if we feed the sampled data from 0-bit CWS to a highly efficient linear classifier (e.g., linear SVM), we effectively (and approximately) train a nonlinear classifier based on the min-max kernel. The accuracy improves as we increase the sample size.</p>

<p>In this paper, we first demonstrate, through an extensive classification study using kernel machines, that the min-max kernel often provides an effective measure of similarity for nonnegative data. This helps justify the use of min-max kernel. However, as the min-max kernel is nonlinear and might be difficult to be used for industrial applications with massive data, we propose to linearize the min-max kernel via 0-bit CWS, a simplification of the original CWS method.</p>

<p>The previous remarkable work on consistent weighted sampling (CWS) produces samples in the form of (i<em>, t</em>) where the i* records the location (and in fact also the weights) information analogous to the samples produced by classical minwise hashing on binary data. Because the t* is theoretically unbounded, it was not immediately clear how to effectively implement CWS for building large-scale linear classifiers. We provide a simple solution by discarding t* (which we refer to as the “0-bit” scheme). Via an extensive empirical study, we show that this 0-bit scheme does not lose essential information. We then apply 0-bit CWS for building linear classifiers to approximate min-max kernel classifiers, as extensively validated on a wide range of public datasets.</p>

<p>We expect this work will generate interests among data mining practitioners who would like to efficiently utilize the nonlinear information of non-binary and nonnegative data.</p>

</td>
</tr>

<tr>
	<td>2015</td>
	<td><a href="/publications/li2015birds/">Two Birds, One Stone: Jointly Learning Binary Code for Large-scale Face Image Retrieval and Attributes Prediction</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Two Birds, One Stone: Jointly Learning Binary Code for Large-scale Face Image Retrieval and Attributes Prediction' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Two Birds, One Stone: Jointly Learning Binary Code for Large-scale Face Image Retrieval and Attributes Prediction' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Two%20Birds,%20One%20Stone:%20Jointly%20Learning%20Binary%20Code%20for%20Large-scale%20Face%20Image%20Retrieval%20and%20Attributes%20Prediction' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Yan Li, Ruiping Wang, Haomiao Liu, Huajie Jiang, Shiguang Shan and Xilin Chen</td>
	<td>ICCV</td>
	<td><p>We address the challenging large-scale content-based
face image retrieval problem, intended as searching images
based on the presence of specific subject, given one face
image of him/her. To this end, one natural demand is a supervised binary code learning method. While the learned
codes might be discriminating, people often have a further
expectation that whether some semantic message (e.g., visual attributes) can be read from the human-incomprehensible
codes. For this purpose, we propose a novel binary code
learning framework by jointly encoding identity discriminability and a number of facial attributes into unified binary code. In this way, the learned binary codes can be applied to not only fine-grained face image retrieval, but also
facial attributes prediction, which is the very innovation of
this work, just like killing two birds with one stone. To evaluate the effectiveness of the proposed method, extensive experiments are conducted on a new purified large-scale web
celebrity database, named CFW 60K, with abundant manual identity and attributes annotation, and experimental results exhibit the superiority of our method over state-of-the-art.</p>
</td>
</tr>

<tr>
	<td>2015</td>
	<td><a href="/publications/leng2015hashing/">Hashing for Distributed Data</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Hashing for Distributed Data' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Hashing for Distributed Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Hashing%20for%20Distributed%20Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Cong Leng, Jiaxiang Wu, Jian Cheng, Xi Zhang and Hanqing Lu</td>
	<td>ICML</td>
	<td><p>Recently, hashing based approximate nearest
neighbors search has attracted much attention.
Extensive centralized hashing algorithms have
been proposed and achieved promising performance. However, due to the large scale of many
applications, the data is often stored or even collected in a distributed manner. Learning hash
functions by aggregating all the data into a fusion
center is infeasible because of the prohibitively
expensive communication and computation overhead.
In this paper, we develop a novel hashing
model to learn hash functions in a distributed setting. We cast a centralized hashing model as a
set of subproblems with consensus constraints.
We find these subproblems can be analytically
solved in parallel on the distributed compute nodes. Since no training data is transmitted across
the nodes in the learning process, the communication cost of our model is independent to the data size. Extensive experiments on several large
scale datasets containing up to 100 million samples demonstrate the efficacy of our method.</p>
</td>
</tr>

<tr>
	<td>2015</td>
	<td><a href="/publications/lai2015simultaneous/">Simultaneous Feature Learning and Hash Coding with Deep Neural Networks</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Simultaneous Feature Learning and Hash Coding with Deep Neural Networks' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Simultaneous Feature Learning and Hash Coding with Deep Neural Networks' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Simultaneous%20Feature%20Learning%20and%20Hash%20Coding%20with%20Deep%20Neural%20Networks' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>H. Lai, Y. Pan, Y. Liu, S. Yan</td>
	<td>CVPR</td>
	<td><p>Similarity-preserving hashing is a widely-used method
for nearest neighbour search in large-scale image retrieval
tasks. For most existing hashing methods, an image is
first encoded as a vector of hand-engineering visual features,
followed by another separate projection or quantization
step that generates binary codes. However, such visual
feature vectors may not be optimally compatible with the
coding process, thus producing sub-optimal hashing codes.
In this paper, we propose a deep architecture for supervised
hashing, in which images are mapped into binary codes via
carefully designed deep neural networks. The pipeline of
the proposed deep architecture consists of three building
blocks: 1) a sub-network with a stack of convolution layers
to produce the effective intermediate image features; 2)
a divide-and-encode module to divide the intermediate image
features into multiple branches, each encoded into one
hash bit; and 3) a triplet ranking loss designed to characterize
that one image is more similar to the second image than
to the third one. Extensive evaluations on several benchmark
image datasets show that the proposed simultaneous
feature learning and hash coding pipeline brings substantial
improvements over other state-of-the-art supervised or
unsupervised hashing methods.</p>
</td>
</tr>

<tr>
	<td>2015</td>
	<td><a href="/publications/ding2015knn/">kNN Hashing with Factorized Neighborhood Representation</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=kNN Hashing with Factorized Neighborhood Representation' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=kNN Hashing with Factorized Neighborhood Representation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=kNN%20Hashing%20with%20Factorized%20Neighborhood%20Representation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Kun Ding, Chunlei Huo, Bin Fan, Chunhong Pan</td>
	<td>ICCV</td>
	<td><p>Hashing is very effective for many tasks in reducing the
processing time and in compressing massive databases. Although lots of approaches have been developed to learn
data-dependent hash functions in recent years, how to learn
hash functions to yield good performance with acceptable
computational and memory cost is still a challenging problem. Based on the observation that retrieval precision is
highly related to the kNN classification accuracy, this paper
proposes a novel kNN-based supervised hashing method,
which learns hash functions by directly maximizing the kNN
accuracy of the Hamming-embedded training data. To make
it scalable well to large problem, we propose a factorized
neighborhood representation to parsimoniously model the
neighborhood relationships inherent in training data. Considering that real-world data are often linearly inseparable,
we further kernelize this basic model to improve its performance. As a result, the proposed method is able to learn
accurate hashing functions with tolerable computation and
storage cost. Experiments on four benchmarks demonstrate
that our method outperforms the state-of-the-arts.</p>
</td>
</tr>

<tr>
	<td>2015</td>
	<td><a href="/publications/liu2015multi/">Multi-View Complementary Hash Tables for Nearest Neighbor Search</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Multi-View Complementary Hash Tables for Nearest Neighbor Search' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Multi-View Complementary Hash Tables for Nearest Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Multi-View%20Complementary%20Hash%20Tables%20for%20Nearest%20Neighbor%20Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Xianglong Liu, Lei Huang, Cheng Deng, Jiwen Lu and Bo Land</td>
	<td>ICCV</td>
	<td><p>Recent years have witnessed the success of hashing techniques in fast nearest neighbor search. In practice many
applications (e.g., visual search, object detection, image
matching, etc.) have enjoyed the benefits of complementary hash tables and information fusion over multiple views.
However, most of prior research mainly focused on compact hash code cleaning, and rare work studies how to build
multiple complementary hash tables, much less to adaptively integrate information stemming from multiple views.
In
this paper we first present a novel multi-view complementary hash table method that learns complementary hash tables from the data with multiple views. For single multiview table, using exemplar based feature fusion, we approximate the inherent data similarities with a low-rank matrix,
and learn discriminative hash functions in an efficient way.
To build complementary tables and meanwhile maintain scalable training and fast out-of-sample extension, an exemplar reweighting scheme is introduced to update the induced low-rank similarity in the sequential table construction framework, which indeed brings mutual benefits between tables by placing greater importance on exemplars
shared by mis-separated neighbors. Extensive experiments
on three large-scale image datasets demonstrate that the
proposed method significantly outperforms various naive
solutions and state-of-the-art multi-table methods.</p>
</td>
</tr>

<tr>
	<td>2015</td>
	<td><a href="/publications/zhang2015bit/">Bit-Scalable Deep Hashing With Regularized Similarity Learning for Image Retrieval and Person Re-Identification</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Bit-Scalable Deep Hashing With Regularized Similarity Learning for Image Retrieval and Person Re-Identification' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Bit-Scalable Deep Hashing With Regularized Similarity Learning for Image Retrieval and Person Re-Identification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Bit-Scalable%20Deep%20Hashing%20With%20Regularized%20Similarity%20Learning%20for%20Image%20Retrieval%20and%20Person%20Re-Identification' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>R. Zhang, L. Lin, R. Zhang, W. Zuo, L. Zhang</td>
	<td>TIP</td>
	<td><p>Extracting informative image features and learning
effective approximate hashing functions are two crucial steps in
image retrieval . Conventional methods often study these two
steps separately, e.g., learning hash functions from a predefined
hand-crafted feature space. Meanwhile, the bit lengths of output
hashing codes are preset in most previous methods, neglecting the
significance level of different bits and restricting their practical
flexibility. To address these issues, we propose a supervised
learning framework to generate compact and bit-scalable hashing
codes directly from raw images. We pose hashing learning as
a problem of regularized similarity learning. Specifically, we
organize the training images into a batch of triplet samples,
each sample containing two images with the same label and one
with a different label. With these triplet samples, we maximize
the margin between matched pairs and mismatched pairs in the
Hamming space. In addition, a regularization term is introduced
to enforce the adjacency consistency, i.e., images of similar
appearances should have similar codes. The deep convolutional
neural network is utilized to train the model in an end-to-end
fashion, where discriminative image features and hash functions
are simultaneously optimized. Furthermore, each bit of our
hashing codes is unequally weighted so that we can manipulate
the code lengths by truncating the insignificant bits. Our
framework outperforms state-of-the-arts on public benchmarks
of similar image search and also achieves promising results in
the application of person re-identification in surveillance. It is
also shown that the generated bit-scalable hashing codes well
preserve the discriminative powers with shorter code lengths.</p>
</td>
</tr>

<tr>
	<td>2015</td>
	<td><a href="/publications/zhao2015deep/">Deep Semantic Ranking Based Hashing for Multi-Label Image Retrieval</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Deep Semantic Ranking Based Hashing for Multi-Label Image Retrieval' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Deep Semantic Ranking Based Hashing for Multi-Label Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Deep%20Semantic%20Ranking%20Based%20Hashing%20for%20Multi-Label%20Image%20Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>F. Zhao, Y. Huang, L. Wang, and T. Tan</td>
	<td>CVPR</td>
	<td><p>With the rapid growth of web images, hashing has received
increasing interests in large scale image retrieval.
Research efforts have been devoted to learning compact binary
codes that preserve semantic similarity based on labels.
However, most of these hashing methods are designed
to handle simple binary similarity. The complex multilevel
semantic structure of images associated with multiple labels
have not yet been well explored. Here we propose a deep
semantic ranking based method for learning hash functions
that preserve multilevel semantic similarity between multilabel
images. In our approach, deep convolutional neural
network is incorporated into hash functions to jointly
learn feature representations and mappings from them to
hash codes, which avoids the limitation of semantic representation
power of hand-crafted features. Meanwhile, a
ranking list that encodes the multilevel similarity information
is employed to guide the learning of such deep hash
functions. An effective scheme based on surrogate loss is
used to solve the intractable optimization problem of nonsmooth
and multivariate ranking measures involved in the
learning procedure. Experimental results show the superiority
of our proposed approach over several state-of-theart
hashing methods in term of ranking evaluation metrics
when tested on multi-label image datasets.</p>
</td>
</tr>

<tr>
	<td>2015</td>
	<td><a href="/publications/zhen2015cross/">Cross-Modal Similarity Learning via Pairs, Preferences, and Active Supervision</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Cross-Modal Similarity Learning via Pairs, Preferences, and Active Supervision' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Cross-Modal Similarity Learning via Pairs, Preferences, and Active Supervision' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Cross-Modal%20Similarity%20Learning%20via%20Pairs,%20Preferences,%20and%20Active%20Supervision' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Yi Zhen, Piyush Rai, Hongyuan Zha, and Lawrence Carin</td>
	<td>AAAI</td>
	<td><p>We present a probabilistic framework for learning pairwise similarities between objects belonging to different modalities, such as drugs and proteins, or text and
images. Our framework is based on learning a binary
code based representation for objects in each modality, and has the following key properties: (i) it can
leverage both pairwise as well as easy-to-obtain relative
preference based cross-modal constraints, (ii) the probabilistic framework naturally allows querying for the
most useful/informative constraints, facilitating an active learning setting (existing methods for cross-modal
similarity learning do not have such a mechanism), and
(iii) the binary code length is learned from the data. We
demonstrate the effectiveness of the proposed approach
on two problems that require computing pairwise similarities between cross-modal object pairs: cross-modal
link prediction in bipartite graphs, and hashing based
cross-modal similarity search.</p>
</td>
</tr>

<tr>
	<td>2015</td>
	<td><a href="/publications/wang2015semantic/">Semantic Topic Multimodal Hashing for Cross-Media Retrieval</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Semantic Topic Multimodal Hashing for Cross-Media Retrieval' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Semantic Topic Multimodal Hashing for Cross-Media Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Semantic%20Topic%20Multimodal%20Hashing%20for%20Cross-Media%20Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Di Wang, Xinbo Gao, Xiumei Wang and Lihuo He</td>
	<td>IJCAI</td>
	<td><p>Multimodal hashing is essential to cross-media
similarity search for its low storage cost and fast
query speed. Most existing multimodal hashing
methods embedded heterogeneous data into a common low-dimensional Hamming space, and then
rounded the continuous embeddings to obtain the
binary codes. Yet they usually neglect the inherent discrete nature of hashing for relaxing the discrete constraints, which will cause degraded retrieval performance especially for long codes. For
this purpose, a novel Semantic Topic Multimodal
Hashing (STMH) is developed by considering latent semantic information in coding procedure.
It
first discovers clustering patterns of texts and robust factorizes the matrix of images to obtain multiple semantic topics of texts and concepts of images.
Then the learned multimodal semantic features are
transformed into a common subspace by their correlations. Finally, each bit of unified hash code
can be generated directly by figuring out whether a
topic or concept is contained in a text or an image.
Therefore, the obtained model by STMH is more
suitable for hashing scheme as it directly learns discrete hash codes in the coding process. Experimental results demonstrate that the proposed method
outperforms several state-of-the-art methods.</p>
</td>
</tr>

<tr>
	<td>2015</td>
	<td><a href="/publications/cakir2015adaptive/">Adaptive Hashing for Fast Similarity Search</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Adaptive Hashing for Fast Similarity Search' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Adaptive Hashing for Fast Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Adaptive%20Hashing%20for%20Fast%20Similarity%20Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>F. Cakir, S. Sclaroff</td>
	<td>ICCV</td>
	<td><p>With the staggering growth in image and video datasets,
algorithms that provide fast similarity search and compact
storage are crucial. Hashing methods that map the
data into Hamming space have shown promise; however,
many of these methods employ a batch-learning strategy
in which the computational cost and memory requirements
may become intractable and infeasible with larger and
larger datasets. To overcome these challenges, we propose
an online learning algorithm based on stochastic gradient
descent in which the hash functions are updated iteratively
with streaming data. In experiments with three image retrieval
benchmarks, our online algorithm attains retrieval
accuracy that is comparable to competing state-of-the-art
batch-learning solutions, while our formulation is orders
of magnitude faster and being online it is adaptable to the
variations of the data. Moreover, our formulation yields improved
retrieval performance over a recently reported online
hashing technique, Online Kernel Hashing.</p>
</td>
</tr>

<tr>
	<td>2015</td>
	<td><a href="/publications/mukherjee2015nmf/">An NMF perspective on Binary Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=An NMF perspective on Binary Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=An NMF perspective on Binary Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=An%20NMF%20perspective%20on%20Binary%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Lopamudra Mukherjee, Sathya N. Ravi, Vamsi K. Ithapu, Tyler Holmes and Vikas Singh</td>
	<td>ICCV</td>
	<td><p>The pervasiveness of massive data repositories has led
to much interest in efficient methods for indexing, search,
and retrieval. For image data, a rapidly developing body of
work for these applications shows impressive performance
with methods that broadly fall under the umbrella term of
Binary Hashing. Given a distance matrix, a binary hashing
algorithm solves for a binary code for the given set of examples, whose Hamming distance nicely approximates the
original distances. The formulation is non-convex — so existing solutions adopt spectral relaxations or perform coordinate descent (or quantization) on a surrogate objective
that is numerically more tractable. In this paper, we first
derive an Augmented Lagrangian approach to optimize the
standard binary Hashing objective (i.e., maintain fidelity
with a given distance matrix). With appropriate step sizes,
we find that this scheme already yields results that match or
substantially outperform state of the art methods on most
benchmarks used in the literature. Then, to allow the model
to scale to large datasets, we obtain an interesting reformulation of the binary hashing objective as a non-negative matrix factorization. Later, this leads to a simple multiplicative updates algorithm — whose parallelization properties
are exploited to obtain a fast GPU based implementation.
We give a probabilistic analysis of our initialization scheme
and present a range of experiments to show that the method
is simple to implement and competes favorably with available methods (both for optimization and generalization).</p>

</td>
</tr>

<tr>
	<td>2015</td>
	<td><a href="/publications/jiang2015scalable/">Scalable Graph Hashing with Feature Transformation</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Scalable Graph Hashing with Feature Transformation' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Scalable Graph Hashing with Feature Transformation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Scalable%20Graph%20Hashing%20with%20Feature%20Transformation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Q. Jiang, W. Li</td>
	<td>IJCAI</td>
	<td><p>Hashing has been widely used for approximate nearest
neighbor (ANN) search in big data applications
because of its low storage cost and fast retrieval
speed. The goal of hashing is to map the data
points from the original space into a binary-code
space where the similarity (neighborhood structure)
in the original space is preserved. By directly
exploiting the similarity to guide the hashing
code learning procedure, graph hashing has attracted
much attention. However, most existing graph
hashing methods cannot achieve satisfactory performance
in real applications due to the high complexity
for graph modeling. In this paper, we propose
a novel method, called scalable graph hashing
with feature transformation (SGH), for large-scale
graph hashing. Through feature transformation, we
can effectively approximate the whole graph without
explicitly computing the similarity graph matrix,
based on which a sequential learning method
is proposed to learn the hash functions in a bit-wise
manner. Experiments on two datasets with one million
data points show that our SGH method can
outperform the state-of-the-art methods in terms of
both accuracy and scalability.</p>
</td>
</tr>

<tr>
	<td>2015</td>
	<td><a href="/publications/andoni2015practical/">Practical and Optimal LSH for Angular Distance</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Practical and Optimal LSH for Angular Distance' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Practical and Optimal LSH for Angular Distance' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Practical%20and%20Optimal%20LSH%20for%20Angular%20Distance' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>A. Andoni, P. Indyk, T. Laarhoven</td>
	<td>NIPS</td>
	<td><p>We show the existence of a Locality-Sensitive Hashing (LSH) family for the angular
distance that yields an approximate Near Neighbor Search algorithm with the
asymptotically optimal running time exponent. Unlike earlier algorithms with this
property (e.g., Spherical LSH [1, 2]), our algorithm is also practical, improving
upon the well-studied hyperplane LSH [3] in practice. We also introduce a multiprobe
version of this algorithm and conduct an experimental evaluation on real
and synthetic data sets.
We complement the above positive results with a fine-grained lower bound for the
quality of any LSH family for angular distance. Our lower bound implies that the
above LSH family exhibits a trade-off between evaluation time and quality that is
close to optimal for a natural class of LSH functions.</p>
</td>
</tr>

<tr>
	<td>2015</td>
	<td><a href="/publications/wang2015hamming/">Hamming Compatible Quantization for Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Hamming Compatible Quantization for Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Hamming Compatible Quantization for Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Hamming%20Compatible%20Quantization%20for%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Z. Wang, L. Duan, J. Lin, X. Wang, T. Huang and W. Gao</td>
	<td>IJCAI</td>
	<td><p>Hashing is one of the effective techniques for fast
Approximate Nearest Neighbour (ANN) search.
Traditional single-bit quantization (SBQ) in most
hashing methods incurs lots of quantization error
which seriously degrades the search performance.
To address the limitation of SBQ, researchers have
proposed promising multi-bit quantization (MBQ)
methods to quantize each projection dimension
with multiple bits. However, some MBQ methods
need to adopt specific distance for binary code
matching instead of the original Hamming distance,
which would significantly decrease the retrieval
speed. Two typical MBQ methods Hierarchical
Quantization and Double Bit Quantization
retain the Hamming distance, but both of them only
consider the projection dimensions during quantization,
ignoring the neighborhood structure of raw
data inherent in Euclidean space. In this paper,
we propose a multi-bit quantization method named
Hamming Compatible Quantization (HCQ) to preserve
the capability of similarity metric between
Euclidean space and Hamming space by utilizing
the neighborhood structure of raw data. Extensive
experiment results have shown our approach significantly
improves the performance of various stateof-the-art
hashing methods while maintaining fast
retrieval speed.</p>

</td>
</tr>

<tr>
	<td>2015</td>
	<td><a href="/publications/moran2015bregularised/">Regularised Cross-Modal Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Regularised Cross-Modal Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Regularised Cross-Modal Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Regularised%20Cross-Modal%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>S. Moran, V. Lavrenko</td>
	<td>SIGIR</td>
	<td><p>In this paper we propose Regularised Cross-Modal Hashing (RCMH) a new cross-modal hashing scheme that projects annotation and visual feature descriptors into a common Hamming space. RCMH optimises the intra-modality similarity of data-points in the annotation modality using an iterative three-step hashing algorithm: in the first step each training image is assigned a K-bit hashcode based on hyperplanes learnt at the previous iteration; in the second step the binary bits are smoothed by a formulation of graph regularisation so that similar data-points have similar bits; in the third step a set of binary classifiers are trained to predict the regularised bits with maximum margin. Visual descriptors are projected into the annotation Hamming space by a set of binary classifiers learnt using the bits of the corresponding annotations as labels. RCMH is shown to consistently improve retrieval effectiveness over state-of-the-art baselines.</p>
</td>
</tr>

<tr>
	<td>2015</td>
	<td><a href="/publications/moran2015agraph/">Graph Regularised Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Graph Regularised Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Graph Regularised Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Graph%20Regularised%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>S. Moran, V. Lavrenko</td>
	<td>ECIR</td>
	<td><p>In this paper we propose a two-step iterative scheme, Graph Regularised Hashing (GRH), for incrementally adjusting the positioning of the hashing hypersurfaces to better conform to the supervisory signal: in the first step the binary bits are regularised using a data similarity graph so that similar data points receive similar bits. In the second step the regularised hashcodes form targets for a set of binary classifiers which shift the position of each hypersurface so as to separate opposite bits with maximum margin. GRH exhibits superior retrieval accuracy to competing hashing methods.</p>
</td>
</tr>

<tr>
	<td>2015</td>
	<td><a href="/publications/song2015rank/">Top Rank Supervised Binary Coding for Visual Search</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Top Rank Supervised Binary Coding for Visual Search' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Top Rank Supervised Binary Coding for Visual Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Top%20Rank%20Supervised%20Binary%20Coding%20for%20Visual%20Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Dongjin Song, Wei Liu, Rongrong Ji, David A. Meyer, John R. Smith</td>
	<td>ICCV</td>
	<td><p>In recent years, binary coding techniques are becoming
increasingly popular because of their high efficiency in handling large-scale computer vision applications. It has been
demonstrated that supervised binary coding techniques that
leverage supervised information can significantly enhance
the coding quality, and hence greatly benefit visual search
tasks. Typically, a modern binary coding method seeks
to learn a group of coding functions which compress data
samples into binary codes. However, few methods pursued
the coding functions such that the precision at the top of
a ranking list according to Hamming distances of the generated binary codes is optimized.
In this paper, we propose a novel supervised binary coding approach, namely
Top Rank Supervised Binary Coding (Top-RSBC), which
explicitly focuses on optimizing the precision of top positions in a Hamming-distance ranking list towards preserving the supervision information. The core idea is to train
the disciplined coding functions, by which the mistakes at
the top of a Hamming-distance ranking list are penalized
more than those at the bottom. To solve such coding functions, we relax the original discrete optimization objective
with a continuous surrogate, and derive a stochastic gradient descent to optimize the surrogate objective. To further reduce the training time cost, we also design an online
learning algorithm to optimize the surrogate objective more
efficiently. Empirical studies based upon three benchmark
image datasets demonstrate that the proposed binary coding approach achieves superior image search accuracy over
the state-of-the-arts.</p>
</td>
</tr>



<tr>
	<td>2014</td>
	<td><a href="/publications/liu2014discrete/">Discrete Graph Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Discrete Graph Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Discrete Graph Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Discrete%20Graph%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>W. Liu, C. Mu, S. Kumar, S. Chang</td>
	<td>NIPS</td>
	<td><p>Hashing has emerged as a popular technique for fast nearest neighbor search in gigantic
databases. In particular, learning based hashing has received considerable
attention due to its appealing storage and search efficiency. However, the performance
of most unsupervised learning based hashing methods deteriorates rapidly
as the hash code length increases. We argue that the degraded performance is due
to inferior optimization procedures used to achieve discrete binary codes. This
paper presents a graph-based unsupervised hashing model to preserve the neighborhood
structure of massive data in a discrete code space. We cast the graph
hashing problem into a discrete optimization framework which directly learns the
binary codes. A tractable alternating maximization algorithm is then proposed to
explicitly deal with the discrete constraints, yielding high-quality codes to well
capture the local neighborhoods. Extensive experiments performed on four large
datasets with up to one million samples show that our discrete optimization based
graph hashing method obtains superior search accuracy over state-of-the-art unsupervised
hashing methods, especially for longer codes.</p>
</td>
</tr>

<tr>
	<td>2014</td>
	<td><a href="/publications/coco2014new/">Microsoft COCO: Common Objects in Context</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Microsoft COCO: Common Objects in Context' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Microsoft COCO: Common Objects in Context' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Microsoft%20COCO:%20Common%20Objects%20in%20Context' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Tsung-Yi Lin, Michael Maire, Serge Belongie, Lubomir Bourdev, Ross Girshick, James Hays, Pietro Perona, Deva Ramanan, C. Lawrence Zitnick, Piotr Dollar</td>
	<td></td>
	<td><p>We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old.
With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model.</p>
</td>
</tr>

<tr>
	<td>2014</td>
	<td><a href="/publications/xia2014supervised/">Supervised Hashing via Image Representation Learning</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Supervised Hashing via Image Representation Learning' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Supervised Hashing via Image Representation Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Supervised%20Hashing%20via%20Image%20Representation%20Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>R. Xia, Y. Pan, H. Lai, C. Liu, S. Yan.</td>
	<td>AAAI</td>
	<td><p>Hashing is a popular approximate nearest neighbor
search approach for large-scale image retrieval.
Supervised hashing, which incorporates similarity/dissimilarity
information on entity pairs to improve
the quality of hashing function learning, has recently
received increasing attention. However, in the existing
supervised hashing methods for images, an input
image is usually encoded by a vector of hand-crafted
visual features. Such hand-crafted feature vectors
do not necessarily preserve the accurate semantic
similarities of images pairs, which may often degrade
the performance of hashing function learning. In this
paper, we propose a supervised hashing method for
image retrieval, in which we automatically learn a good
image representation tailored to hashing as well as a
set of hash functions. The proposed method has two
stages. In the first stage, given the pairwise similarity
matrix S over training images, we propose a scalable
coordinate descent method to decompose S into a
product of HHT where H is a matrix with each of its
rows being the approximate hash code associated to
a training image. In the second stage, we propose to
simultaneously learn a good feature representation for
the input images as well as a set of hash functions, via
a deep convolutional network tailored to the learned
hash codes in H and optionally the discrete class labels
of the images. Extensive empirical evaluations on three
benchmark datasets with different kinds of images
show that the proposed method has superior performance
gains over several state-of-the-art supervised
and unsupervised hashing methods.</p>
</td>
</tr>

<tr>
	<td>2014</td>
	<td><a href="/publications/xiong2014using/">Adaptive Quantization for Hashing: An Information-Based Approach to Learning Binary Codes</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Adaptive Quantization for Hashing: An Information-Based Approach to Learning Binary Codes' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Adaptive Quantization for Hashing: An Information-Based Approach to Learning Binary Codes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Adaptive%20Quantization%20for%20Hashing:%20An%20Information-Based%20Approach%20to%20Learning%20Binary%20Codes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>C. Xiong, W. Chen, G. Chen, D. Johnson, J. Corso</td>
	<td>SDM</td>
	<td><p>Large-scale data mining and retrieval applications have
increasingly turned to compact binary data representations
as a way to achieve both fast queries and efficient
data storage; many algorithms have been proposed for
learning effective binary encodings. Most of these algorithms
focus on learning a set of projection hyperplanes
for the data and simply binarizing the result from each
hyperplane, but this neglects the fact that informativeness
may not be uniformly distributed across the projections.
In this paper, we address this issue by proposing
a novel adaptive quantization (AQ) strategy that
adaptively assigns varying numbers of bits to different
hyperplanes based on their information content. Our
method provides an information-based schema that preserves
the neighborhood structure of data points, and
we jointly find the globally optimal bit-allocation for
all hyperplanes. In our experiments, we compare with
state-of-the-art methods on four large-scale datasets
and find that our adaptive quantization approach significantly
improves on traditional hashing methods.</p>
</td>
</tr>

<tr>
	<td>2014</td>
	<td><a href="/publications/xirau2014fast/">Fast Approximate Nearest-Neighbor Field by Cascaded Spherical Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Fast Approximate Nearest-Neighbor Field by Cascaded Spherical Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Fast Approximate Nearest-Neighbor Field by Cascaded Spherical Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Fast%20Approximate%20Nearest-Neighbor%20Field%20by%20Cascaded%20Spherical%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>I. Torres-Xirau, J. Salvador, E. Pérez-Pellitero</td>
	<td>ACCV</td>
	<td><p>We present an efficient and fast algorithm for computing approximate nearest neighbor fields between two images. Our method builds on the concept of Coherency-Sensitive Hashing (CSH), but uses a recent hashing scheme, Spherical Hashing (SpH), which is known to be better adapted to the nearest-neighbor problem for natural images. Cascaded Spherical Hashing concatenates different configurations of SpH to build larger Hash Tables with less elements in each bin to achieve higher selectivity. Our method amply outperforms existing techniques like PatchMatch and CSH, and the experimental results show that our algorithm is faster and more accurate than existing methods.</p>
</td>
</tr>

<tr>
	<td>2014</td>
	<td><a href="/publications/liu2014collaborative/">Collaborative Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Collaborative Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Collaborative Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Collaborative%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>X. Liu, J. He, C. Deng, B. Lang</td>
	<td>CVPR</td>
	<td><p>Hashing technique has become a promising approach for
fast similarity search. Most of existing hashing research
pursue the binary codes for the same type of entities by
preserving their similarities. In practice, there are many
scenarios involving nearest neighbor search on the data
given in matrix form, where two different types of, yet
naturally associated entities respectively correspond to its
two dimensions or views. To fully explore the duality
between the two views, we propose a collaborative hashing
scheme for the data in matrix form to enable fast search
in various applications such as image search using bag of
words and recommendation using user-item ratings. By
simultaneously preserving both the entity similarities in
each view and the interrelationship between views, our
collaborative hashing effectively learns the compact binary
codes and the explicit hash functions for out-of-sample
extension in an alternating optimization way. Extensive
evaluations are conducted on three well-known datasets
for search inside a single view and search across different
views, demonstrating that our proposed method outperforms
state-of-the-art baselines, with significant accuracy
gains ranging from 7.67% to 45.87% relatively.</p>
</td>
</tr>

<tr>
	<td>2014</td>
	<td><a href="/publications/shrivastava2014asymmetric/">Asymmetric LSH (ALSH) for Sublinear Time Maximum Inner Product Search (MIPS).</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Asymmetric LSH (ALSH) for Sublinear Time Maximum Inner Product Search (MIPS).' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Asymmetric LSH (ALSH) for Sublinear Time Maximum Inner Product Search (MIPS).' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Asymmetric%20LSH%20(ALSH)%20for%20Sublinear%20Time%20Maximum%20Inner%20Product%20Search%20(MIPS).' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>A. Shrivastava, P. Li</td>
	<td>NIPS</td>
	<td><p>We present the first provably sublinear time hashing algorithm for approximate
Maximum Inner Product Search (MIPS). Searching with (un-normalized) inner
product as the underlying similarity measure is a known difficult problem and
finding hashing schemes for MIPS was considered hard. While the existing Locality
Sensitive Hashing (LSH) framework is insufficient for solving MIPS, in this
paper we extend the LSH framework to allow asymmetric hashing schemes. Our
proposal is based on a key observation that the problem of finding maximum inner
products, after independent asymmetric transformations, can be converted into
the problem of approximate near neighbor search in classical settings. This key
observation makes efficient sublinear hashing scheme for MIPS possible. Under
the extended asymmetric LSH (ALSH) framework, this paper provides an example
of explicit construction of provably fast hashing scheme for MIPS. Our proposed
algorithm is simple and easy to implement. The proposed hashing scheme
leads to significant computational savings over the two popular conventional LSH
schemes: (i) Sign Random Projection (SRP) and (ii) hashing based on p-stable
distributions for L2 norm (L2LSH), in the collaborative filtering task of item recommendations
on Netflix and Movielens (10M) datasets.</p>
</td>
</tr>

<tr>
	<td>2014</td>
	<td><a href="/publications/shrivastava2014densifying/">Densifying One Permutation Hashing via Rotation for Fast Near Neighbor Search</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Densifying One Permutation Hashing via Rotation for Fast Near Neighbor Search' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Densifying One Permutation Hashing via Rotation for Fast Near Neighbor Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Densifying%20One%20Permutation%20Hashing%20via%20Rotation%20for%20Fast%20Near%20Neighbor%20Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>A. Shrivastava, P. Li</td>
	<td>ICML</td>
	<td><p>The query complexity of locality sensitive hashing
(LSH) based similarity search is dominated
by the number of hash evaluations, and this number
grows with the data size (Indyk &amp; Motwani,
1998). In industrial applications such as search
where the data are often high-dimensional and
binary (e.g., text n-grams), minwise hashing is
widely adopted, which requires applying a large
number of permutations on the data. This is
costly in computation and energy-consumption.
In this paper, we propose a hashing technique
which generates all the necessary hash evaluations
needed for similarity search, using one
single permutation. The heart of the proposed
hash function is a “rotation” scheme which densifies
the sparse sketches of one permutation
hashing (Li et al., 2012) in an unbiased fashion
thereby maintaining the LSH property. This
makes the obtained sketches suitable for hash table
construction. This idea of rotation presented
in this paper could be of independent interest for
densifying other types of sparse sketches.
Using our proposed hashing method, the query
time of a (K, L)-parameterized LSH is reduced
from the typical O(dKL) complexity to merely
O(KL + dL), where d is the number of nonzeros
of the data vector, K is the number of hashes
in each hash table, and L is the number of hash
tables. Our experimental evaluation on real data
confirms that the proposed scheme significantly
reduces the query processing time over minwise
hashing without loss in retrieval accuracies.</p>
</td>
</tr>

<tr>
	<td>2014</td>
	<td><a href="/publications/zhang2014latent/">Supervised Hashing with Latent Factor Models</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Supervised Hashing with Latent Factor Models' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Supervised Hashing with Latent Factor Models' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Supervised%20Hashing%20with%20Latent%20Factor%20Models' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>P. Zhang, W. Zhang, W. Li, M. Guo</td>
	<td>SIGIR</td>
	<td><p>Due to its low storage cost and fast query speed, hashing
has been widely adopted for approximate nearest neighbor
search in large-scale datasets. Traditional hashing methods
try to learn the hash codes in an unsupervised way where
the metric (Euclidean) structure of the training data is preserved.
Very recently, supervised hashing methods, which
try to preserve the semantic structure constructed from the
semantic labels of the training points, have exhibited higher
accuracy than unsupervised methods. In this paper, we
propose a novel supervised hashing method, called latent
factor hashing (LFH), to learn similarity-preserving binary
codes based on latent factor models. An algorithm with
convergence guarantee is proposed to learn the parameters
of LFH. Furthermore, a linear-time variant with stochastic
learning is proposed for training LFH on large-scale datasets.
Experimental results on two large datasets with semantic
labels show that LFH can achieve superior accuracy than
state-of-the-art methods with comparable training time.</p>
</td>
</tr>

<tr>
	<td>2014</td>
	<td><a href="/publications/zhang2014largescale/">Large-scale supervised multimodal hashing with semantic correlation maximization</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Large-scale supervised multimodal hashing with semantic correlation maximization' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Large-scale supervised multimodal hashing with semantic correlation maximization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Large-scale%20supervised%20multimodal%20hashing%20with%20semantic%20correlation%20maximization' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>D. Zhang, W. Li</td>
	<td>AAAI</td>
	<td><p>Due to its low storage cost and fast query speed, hashing
has been widely adopted for similarity search in multimedia
data. In particular, more and more attentions
have been payed to multimodal hashing for search in
multimedia data with multiple modalities, such as images
with tags. Typically, supervised information of semantic
labels is also available for the data points in
many real applications. Hence, many supervised multimodal
hashing (SMH) methods have been proposed
to utilize such semantic labels to further improve the
search accuracy. However, the training time complexity
of most existing SMH methods is too high, which
makes them unscalable to large-scale datasets. In this
paper, a novel SMH method, called semantic correlation
maximization (SCM), is proposed to seamlessly integrate
semantic labels into the hashing learning procedure
for large-scale data modeling. Experimental results
on two real-world datasets show that SCM can signifi-
cantly outperform the state-of-the-art SMH methods, in
terms of both accuracy and scalability.</p>
</td>
</tr>

<tr>
	<td>2014</td>
	<td><a href="/publications/ge2014graph/">Graph Cuts for Supervised Binary Coding</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Graph Cuts for Supervised Binary Coding' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Graph Cuts for Supervised Binary Coding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Graph%20Cuts%20for%20Supervised%20Binary%20Coding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>T. Ge, K. He, J. Sun</td>
	<td>ECCV</td>
	<td><p>Learning short binary codes is challenged by the inherent discrete
nature of the problem. The graph cuts algorithm is a well-studied
discrete label assignment solution in computer vision, but has not yet
been applied to solve the binary coding problems. This is partially because
it was unclear how to use it to learn the encoding (hashing) functions
for out-of-sample generalization. In this paper, we formulate supervised
binary coding as a single optimization problem that involves both
the encoding functions and the binary label assignment. Then we apply
the graph cuts algorithm to address the discrete optimization problem
involved, with no continuous relaxation. This method, named as Graph
Cuts Coding (GCC), shows competitive results in various datasets.</p>
</td>
</tr>

<tr>
	<td>2014</td>
	<td><a href="/publications/lin2014optimising/">Optimizing Ranking Measures for Compact Binary Code Learning</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Optimizing Ranking Measures for Compact Binary Code Learning' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Optimizing Ranking Measures for Compact Binary Code Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Optimizing%20Ranking%20Measures%20for%20Compact%20Binary%20Code%20Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Guosheng Lin, Chunhua Shen, Jianxin Wu.</td>
	<td>ECCV</td>
	<td><p>Hashing has proven a valuable tool for large-scale information retrieval. Despite much success, existing hashing methods optimize over simple objectives such as the reconstruction error or graph Laplacian related loss functions, instead of the performance evaluation criteria of interest—multivariate performance measures such as the AUC and NDCG. Here we present a general framework (termed StructHash) that allows one to directly optimize multivariate performance measures.
The resulting optimization problem can involve exponentially or infinitely many variables and constraints, which is more challenging than standard structured output learning. To solve the StructHash optimization problem, we use a combination of column generation and cutting-plane techniques. We demonstrate the generality of StructHash by applying it to ranking prediction and image retrieval, and show that it outperforms a few state-of-the-art hashing methods.</p>
</td>
</tr>

<tr>
	<td>2014</td>
	<td><a href="/publications/lin2014fast/">Fast supervised hashing with decision trees for high-dimensional data</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Fast supervised hashing with decision trees for high-dimensional data' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Fast supervised hashing with decision trees for high-dimensional data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Fast%20supervised%20hashing%20with%20decision%20trees%20for%20high-dimensional%20data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Guosheng Lin, Chunhua Shen, Qinfeng Shi, Anton van den Hengel, and David Suter.</td>
	<td>CVPR</td>
	<td><p>Supervised hashing aims to map the original features to
compact binary codes that are able to preserve label based
similarity in the Hamming space. Non-linear hash functions
have demonstrated their advantage over linear ones due to
their powerful generalization capability. In the literature,
kernel functions are typically used to achieve non-linearity
in hashing, which achieve encouraging retrieval performance at the price of slow evaluation and training time.
Here we propose to use boosted decision trees for achieving
non-linearity in hashing, which are fast to train and evaluate, hence more suitable for hashing with high dimensional
data. In our approach, we first propose sub-modular formulations for the hashing binary code inference problem
and an efficient GraphCut based block search method for
solving large-scale inference.
Then we learn hash functions by training boosted decision trees to fit the binary
codes. Experiments demonstrate that our proposed method
significantly outperforms most state-of-the-art methods in
retrieval precision and training time. Especially for highdimensional data, our method is orders of magnitude faster
than many methods in terms of training time.</p>
</td>
</tr>

<tr>
	<td>2014</td>
	<td><a href="/publications/yu2014using/">Circulant Binary Embedding</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Circulant Binary Embedding' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Circulant Binary Embedding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Circulant%20Binary%20Embedding' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>F. Yu, S. Kumar, Y. Gong, S. Chang</td>
	<td>ICML</td>
	<td><p>Binary embedding of high-dimensional data requires
long codes to preserve the discriminative
power of the input space. Traditional binary coding
methods often suffer from very high computation
and storage costs in such a scenario. To
address this problem, we propose Circulant Binary
Embedding (CBE) which generates binary
codes by projecting the data with a circulant matrix.
The circulant structure enables the use of
Fast Fourier Transformation to speed up the computation.
Compared to methods that use unstructured
matrices, the proposed method improves
the time complexity from O(d^2
) to O(d log d),
and the space complexity from O(d^2) to O(d)
where d is the input dimensionality. We also
propose a novel time-frequency alternating optimization
to learn data-dependent circulant projections,
which alternatively minimizes the objective
in original and Fourier domains. We show
by extensive experiments that the proposed approach
gives much better performance than the
state-of-the-art approaches for fixed time, and
provides much faster computation with no performance
degradation for fixed number of bits.</p>
</td>
</tr>

<tr>
	<td>2014</td>
	<td><a href="/publications/irie2014locality/">Locally Linear Hashing for Extracting Non-Linear Manifolds</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Locally Linear Hashing for Extracting Non-Linear Manifolds' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Locally Linear Hashing for Extracting Non-Linear Manifolds' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Locally%20Linear%20Hashing%20for%20Extracting%20Non-Linear%20Manifolds' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>G. Irie, Z. Li, X. Wu, S. Chang</td>
	<td>CVPR</td>
	<td><p>Previous efforts in hashing intend to preserve data variance
or pairwise affinity, but neither is adequate in capturing
the manifold structures hidden in most visual data. In
this paper, we tackle this problem by reconstructing the locally
linear structures of manifolds in the binary Hamming
space, which can be learned by locality-sensitive sparse
coding. We cast the problem as a joint minimization of
reconstruction error and quantization loss, and show that,
despite its NP-hardness, a local optimum can be obtained
efficiently via alternative optimization. Our method distinguishes
itself from existing methods in its remarkable ability
to extract the nearest neighbors of the query from the
same manifold, instead of from the ambient space. On extensive
experiments on various image benchmarks, our results
improve previous state-of-the-art by 28-74% typically,
and 627% on the Yale face data.</p>
</td>
</tr>

<tr>
	<td>2014</td>
	<td><a href="/publications/ding2014collective/">Collective Matrix Factorization Hashing for Multimodal data</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Collective Matrix Factorization Hashing for Multimodal data' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Collective Matrix Factorization Hashing for Multimodal data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Collective%20Matrix%20Factorization%20Hashing%20for%20Multimodal%20data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>G. Ding, Y. Guo, J. Zhou</td>
	<td>CVPR</td>
	<td><p>Nearest neighbor search methods based on hashing have
attracted considerable attention for effective and efficient
large-scale similarity search in computer vision and information
retrieval community. In this paper, we study the
problems of learning hash functions in the context of multimodal
data for cross-view similarity search. We put forward
a novel hashing method, which is referred to Collective
Matrix Factorization Hashing (CMFH). CMFH learns unified
hash codes by collective matrix factorization with latent
factor model from different modalities of one instance,
which can not only supports cross-view search but also increases
the search accuracy by merging multiple view information
sources. We also prove that CMFH, a similaritypreserving
hashing learning method, has upper and lower
boundaries. Extensive experiments verify that CMFH significantly
outperforms several state-of-the-art methods on
three different datasets.</p>
</td>
</tr>



<tr>
	<td>2013</td>
	<td><a href="/publications/sundaram2013streaming/">Streaming Similarity Search over one Billion Tweets using Parallel Locality-Sensitive Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Streaming Similarity Search over one Billion Tweets using Parallel Locality-Sensitive Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Streaming Similarity Search over one Billion Tweets using Parallel Locality-Sensitive Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Streaming%20Similarity%20Search%20over%20one%20Billion%20Tweets%20using%20Parallel%20Locality-Sensitive%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Narayanan Sundaram, Aizana Turmukhametova, Nadathur Satish, Todd Mostak, Piotr Indyk, Samuel Madden and Pradeep Dubey</td>
	<td>VLDB</td>
	<td><p>Finding nearest neighbors has become an important operation on databases, with applications to text search, multimedia indexing,
and many other areas. One popular algorithm for similarity search, especially for high dimensional data (where spatial indexes like kdtrees do not perform well) is Locality Sensitive Hashing (LSH), an
approximation algorithm for finding similar objects. In this paper, we describe a new variant of LSH, called Parallel
LSH (PLSH) designed to be extremely efficient, capable of scaling out on multiple nodes and multiple cores, and which supports highthroughput streaming of new data. Our approach employs several
novel ideas, including: cache-conscious hash table layout, using a 2-level merge algorithm for hash table construction; an efficient
algorithm for duplicate elimination during hash-table querying; an insert-optimized hash table structure and efficient data expiration
algorithm for streaming data; and a performance model that accurately estimates performance of the algorithm and can be used to
optimize parameter settings. We show that on a workload where we perform similarity search on a dataset of &gt; 1 Billion tweets, with
hundreds of millions of new tweets per day, we can achieve query times of 1–2.5 ms. We show that this is an order of magnitude faster
than existing indexing schemes, such as inverted indexes. To the best of our knowledge, this is the fastest implementation of LSH,
with table construction times up to 3.7x faster and query times that are 8.3x faster than a basic implementation.</p>
</td>
</tr>

<tr>
	<td>2013</td>
	<td><a href="/publications/moran2013bvariable/">Variable Bit Quantisation for LSH</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Variable Bit Quantisation for LSH' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Variable Bit Quantisation for LSH' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Variable%20Bit%20Quantisation%20for%20LSH' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>S. Moran, V. Lavrenko, and M. Osborne</td>
	<td>ACL</td>
	<td><p>We introduce a scheme for optimally allocating
a variable number of bits per
LSH hyperplane. Previous approaches assign
a constant number of bits per hyperplane.
This neglects the fact that a subset
of hyperplanes may be more informative
than others. Our method, dubbed Variable
Bit Quantisation (VBQ), provides a datadriven
non-uniform bit allocation across
hyperplanes. Despite only using a fraction
of the available hyperplanes, VBQ outperforms
uniform quantisation by up to 168%
for retrieval across standard text and image
datasets.</p>
</td>
</tr>

<tr>
	<td>2013</td>
	<td><a href="/publications/song2013intermedia/">Inter-Media Hashing for Large-Scale Retrieval from Heterogeneous Data Sources</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Inter-Media Hashing for Large-Scale Retrieval from Heterogeneous Data Sources' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Inter-Media Hashing for Large-Scale Retrieval from Heterogeneous Data Sources' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Inter-Media%20Hashing%20for%20Large-Scale%20Retrieval%20from%20Heterogeneous%20Data%20Sources' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>J. Song, Y. Yang, Y. Yang, Z. Huang, H. Shen</td>
	<td>SIGMOD</td>
	<td><p>In this paper, we present a new multimedia retrieval paradigm to innovate large-scale search of heterogenous multimedia data. It is able to return results of different media types from heterogeneous data sources, e.g., using a query image to retrieve relevant text documents or images from different data sources. This utilizes the widely available data from different sources and caters for the current users’ demand of receiving a result list simultaneously containing multiple types of data to obtain a comprehensive understanding of the query’s results. To enable large-scale inter-media retrieval, we propose a novel inter-media hashing (IMH) model to explore the correlations among multiple media types from different data sources and tackle the scalability issue. To this end, multimedia data from heterogeneous data sources are transformed into a common Hamming space, in which fast search can be easily implemented by XOR and bit-count operations. Furthermore, we integrate a linear regression model to learn hashing functions so that the hash codes for new data points can be efficiently generated. Experiments conducted on real-world large-scale multimedia datasets demonstrate the superiority of our proposed method compared with state-of-the-art techniques.</p>
</td>
</tr>

<tr>
	<td>2013</td>
	<td><a href="/publications/moran2013aneighbourhood/">Neighbourhood Preserving Quantisation for LSH</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Neighbourhood Preserving Quantisation for LSH' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Neighbourhood Preserving Quantisation for LSH' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Neighbourhood%20Preserving%20Quantisation%20for%20LSH' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>S. Moran, V. Lavrenko, and M. Osborne</td>
	<td>SIGIR</td>
	<td><p>We introduce a scheme for optimally allocating multiple bits per hyperplane for Locality Sensitive Hashing (LSH). Existing approaches binarise LSH projections by thresholding at zero yielding a single bit per dimension. We demonstrate that this is a sub-optimal bit allocation approach that can easily destroy the neighbourhood structure in the original feature space. Our proposed method, dubbed Neighbourhood Preserving Quantization (NPQ), assigns multiple bits per hyperplane based upon adaptively learned thresholds. NPQ exploits a pairwise affinity matrix to discretise each dimension such that nearest neighbours in the original feature space fall within the same quantisation thresholds and are therefore assigned identical bits. NPQ is not only applicable to LSH, but can also be applied to any low-dimensional projection scheme. Despite using half the number of hyperplanes, NPQ is shown to improve LSH-based retrieval accuracy by up to 65% compared to the state-of-the-art.</p>
</td>
</tr>

<tr>
	<td>2013</td>
	<td><a href="/publications/ou2013comparing/">Comparing apples to oranges: a scalable solution with heterogeneous hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Comparing apples to oranges: a scalable solution with heterogeneous hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Comparing apples to oranges: a scalable solution with heterogeneous hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Comparing%20apples%20to%20oranges:%20a%20scalable%20solution%20with%20heterogeneous%20hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>M. Ou, P. Cui, F. Wang, J. Wang, W. Zhu, S. Yang</td>
	<td>KDD</td>
	<td><p>Although hashing techniques have been popular for the large scale similarity search problem, most of the existing methods for designing optimal hash functions focus on homogeneous similarity assessment, i.e., the data entities to be indexed are of the same type. Realizing that heterogeneous entities and relationships are also ubiquitous in the real world applications, there is an emerging need to retrieve and search similar or relevant data entities from multiple heterogeneous domains, e.g., recommending relevant posts and images to a certain Facebook user. In this paper, we address the problem of ``comparing apples to oranges’’ under the large scale setting. Specifically, we propose a novel Relation-aware Heterogeneous Hashing (RaHH), which provides a general framework for generating hash codes of data entities sitting in multiple heterogeneous domains. Unlike some existing hashing methods that map heterogeneous data in a common Hamming space, the RaHH approach constructs a Hamming space for each type of data entities, and learns optimal mappings between them simultaneously. This makes the learned hash codes flexibly cope with the characteristics of different data domains. Moreover, the RaHH framework encodes both homogeneous and heterogeneous relationships between the data entities to design hash functions with improved accuracy. To validate the proposed RaHH method, we conduct extensive evaluations on two large datasets; one is crawled from a popular social media sites, Tencent Weibo, and the other is an open dataset of Flickr(NUS-WIDE). The experimental results clearly demonstrate that the RaHH outperforms several state-of-the-art hashing methods with significant performance gains.</p>
</td>
</tr>

<tr>
	<td>2013</td>
	<td><a href="/publications/grauman2013learning/">Learning Binary Hash Codes for Large-Scale Image Search</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Learning Binary Hash Codes for Large-Scale Image Search' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Learning Binary Hash Codes for Large-Scale Image Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Learning%20Binary%20Hash%20Codes%20for%20Large-Scale%20Image%20Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Kristen Grauman, Rob Fergus</td>
	<td>Machine Learning for Computer Vision</td>
	<td><p>Algorithms to rapidly search massive image or video collections are critical for many vision applications, including visual search, content-based retrieval, and non-parametric models for object recognition. Recent work shows that learned binary projections are a powerful way to index large collections according to their content. The basic idea is to formulate the projections so as to approximately preserve a given similarity function of interest. Having done so, one can then search the data efficiently using hash tables, or by exploring the Hamming ball volume around a novel query. Both enable sub-linear time retrieval with respect to the database size. Further, depending on the design of the projections, in some cases it is possible to bound the number of database examples that must be searched in order to achieve a given level of accuracy.</p>

<p>This chapter overviews data structures for fast search with binary codes, and then describes several supervised and unsupervised strategies for generating the codes. In particular, we review supervised methods that integrate metric learning, boosting, and neural networks into the hash key construction, and unsupervised methods based on spectral analysis or kernelized random projections that compute affinity-preserving binary codes.Whether learning from explicit semantic supervision or exploiting the structure among unlabeled data, these methods make scalable retrieval possible for a variety of robust visual similarity measures.We focus on defining the algorithms, and illustrate the main points with results using millions of images.</p>
</td>
</tr>

<tr>
	<td>2013</td>
	<td><a href="/publications/gong2013bilinear/">Learning Binary Codes for High-Dimensional Data Using Bilinear Projections</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Learning Binary Codes for High-Dimensional Data Using Bilinear Projections' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Learning Binary Codes for High-Dimensional Data Using Bilinear Projections' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Learning%20Binary%20Codes%20for%20High-Dimensional%20Data%20Using%20Bilinear%20Projections' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Y. Gong, S. Kumar, H. Rowley, S. Lazebnik</td>
	<td>CVPR</td>
	<td><p>Recent advances in visual recognition indicate that to
achieve good retrieval and classification accuracy on largescale
datasets like ImageNet, extremely high-dimensional
visual descriptors, e.g., Fisher Vectors, are needed. We
present a novel method for converting such descriptors to
compact similarity-preserving binary codes that exploits
their natural matrix structure to reduce their dimensionality
using compact bilinear projections instead of a single
large projection matrix. This method achieves comparable
retrieval and classification accuracy to the original descriptors
and to the state-of-the-art Product Quantization
approach while having orders of magnitude faster code generation
time and smaller memory footprint.</p>
</td>
</tr>

<tr>
	<td>2013</td>
	<td><a href="/publications/zhu2013linear/">Linear cross-modal hashing for efficient multimedia search</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Linear cross-modal hashing for efficient multimedia search' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Linear cross-modal hashing for efficient multimedia search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Linear%20cross-modal%20hashing%20for%20efficient%20multimedia%20search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Xiaofeng Zhu, Zi Huang, Heng Tao Shen, Xin Zhao</td>
	<td>MM</td>
	<td><p>Most existing cross-modal hashing methods suffer from the scalability issue in the training phase. In this paper, we propose a novel 
cross-modal hashing approach with a linear time complexity to the training data size, to enable scalable indexing for multimedia 
search across multiple modals. Taking both the intra-similarity in each modal and the inter-similarity across different modals 
into consideration, the proposed approach aims at effectively learning hash functions from large-scale training datasets. 
More specifically, for each modal, we first partition the training data into $k$ clusters and then represent each training data 
point with its distances to $k$ centroids of the clusters. Interestingly, such a k-dimensional data representation can reduce 
the time complexity of the training phase from traditional O(n2) or higher to O(n), where $n$ is the training data size, leading to 
practical learning on large-scale datasets. We further prove that this new representation preserves the intra-similarity in each modal. 
To preserve the inter-similarity among data points across different modals, we transform the derived data representations into a 
common binary subspace in which binary codes from all the modals are “consistent” and comparable. The transformation simultaneously 
outputs the hash functions for all modals, which are used to convert unseen data into binary codes. Given a query of one modal, 
it is first mapped into the binary codes using the modal’s hash functions, followed by matching the database binary codes of any other 
modals. Experimental results on two benchmark datasets confirm the scalability and the effectiveness of the proposed approach in 
comparison with the state of the art.</p>
</td>
</tr>

<tr>
	<td>2013</td>
	<td><a href="/publications/xu2013harmonious/">Harmonious Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Harmonious Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Harmonious Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Harmonious%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>B. Xu, J. Bu, Y. Chen, X. He, D. Cai</td>
	<td>IJCAI</td>
	<td><p>Hashing-based fast nearest neighbor search technique
has attracted great attention in both research
and industry areas recently. Many existing hashing
approaches encode data with projection-based hash
functions and represent each projected dimension
by 1-bit. However, the dimensions with high variance
hold large energy or information of data but
treated equivalently as dimensions with low variance,
which leads to a serious information loss. In
this paper, we introduce a novel hashing algorithm
called Harmonious Hashing which aims at learning
hash functions with low information loss. Specifically,
we learn a set of optimized projections to
preserve the maximum cumulative energy and meet
the constraint of equivalent variance on each dimension
as much as possible. In this way, we could
minimize the information loss after binarization.
Despite the extreme simplicity, our method outperforms
superiorly to many state-of-the-art hashing
methods in large-scale and high-dimensional nearest
neighbor search experiments.</p>
</td>
</tr>

<tr>
	<td>2013</td>
	<td><a href="/publications/jin2013complementary/">Complementary Projection Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Complementary Projection Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Complementary Projection Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Complementary%20Projection%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Z. Jin, Y. Hu, Y. Lin, D. Zhang, S. Lin, D. Cai, X. Li</td>
	<td>ICCV</td>
	<td><p>Recently, hashing techniques have been widely applied
to solve the approximate nearest neighbors search problem
in many vision applications. Generally, these hashing
approaches generate 2^c buckets, where c is the length
of the hash code. A good hashing method should satisfy
the following two requirements: 1) mapping the nearby
data points into the same bucket or nearby (measured by
the Hamming distance) buckets. 2) all the data points are
evenly distributed among all the buckets. In this paper,
we propose a novel algorithm named Complementary Projection
Hashing (CPH) to find the optimal hashing functions
which explicitly considers the above two requirements.
Specifically, CPH aims at sequentially finding a series of hyperplanes
(hashing functions) which cross the sparse region
of the data. At the same time, the data points are evenly distributed
in the hypercubes generated by these hyperplanes.
The experiments comparing with the state-of-the-art hashing
methods demonstrate the effectiveness of the proposed
method.</p>
</td>
</tr>

<tr>
	<td>2013</td>
	<td><a href="/publications/neyshabur2013power/">The Power of Asymmetry in Binary Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=The Power of Asymmetry in Binary Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=The Power of Asymmetry in Binary Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=The%20Power%20of%20Asymmetry%20in%20Binary%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>B. Neyshabur, R. Salakhutdinov, N. Srebro</td>
	<td>NIPS</td>
	<td><p>When approximating binary similarity using the hamming distance between short
binary hashes, we show that even if the similarity is symmetric, we can have
shorter and more accurate hashes by using two distinct code maps. I.e. by approximating the similarity between x and x
0
as the hamming distance between f(x)
and g(x0), for two distinct binary codes f, g, rather than as the hamming distance
between f(x) and f(x0).</p>
</td>
</tr>

<tr>
	<td>2013</td>
	<td><a href="/publications/li2013column/">Learning Hash Functions Using Column Generation</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Learning Hash Functions Using Column Generation' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Learning Hash Functions Using Column Generation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Learning%20Hash%20Functions%20Using%20Column%20Generation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>X. Li, G. Lin, C. Shen, A. Hengel, A. Dick</td>
	<td>ICML</td>
	<td><p>Fast nearest neighbor searching is becoming
an increasingly important tool in solving
many large-scale problems. Recently
a number of approaches to learning datadependent
hash functions have been developed.
In this work, we propose a column
generation based method for learning datadependent
hash functions on the basis of
proximity comparison information. Given a
set of triplets that encode the pairwise proximity
comparison information, our method
learns hash functions that preserve the relative
comparison relationships in the data
as well as possible within the large-margin
learning framework. The learning procedure
is implemented using column generation and
hence is named CGHash. At each iteration
of the column generation procedure, the best
hash function is selected. Unlike most other
hashing methods, our method generalizes to
new data points naturally; and has a training
objective which is convex, thus ensuring
that the global optimum can be identi-
fied. Experiments demonstrate that the proposed
method learns compact binary codes
and that its retrieval performance compares
favorably with state-of-the-art methods when
tested on a few benchmark datasets.</p>
</td>
</tr>

<tr>
	<td>2013</td>
	<td><a href="/publications/liu2013hashbit/">Hash Bit Selection: a Unified Solution for Selection Problems in Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Hash Bit Selection: a Unified Solution for Selection Problems in Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Hash Bit Selection: a Unified Solution for Selection Problems in Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Hash%20Bit%20Selection:%20a%20Unified%20Solution%20for%20Selection%20Problems%20in%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>X. Liu, J. He, B. Lang, S. Chang</td>
	<td>CVPR</td>
	<td><p>Hashing based methods recently have been shown promising for large-scale nearest neighbor search. However, good designs involve difficult decisions of many unknowns – data features, hashing algorithms, parameter settings, kernels, etc. In this paper, we provide a unified solution as hash bit selection, i.e., selecting the most informative hash bits from a pool of candidates that may have been generated under various conditions mentioned above. We represent the candidate bit pool as a vertex- and edge-weighted graph with the pooled bits as vertices. Then we formulate the bit selection problem as quadratic programming over the graph, and solve it efficiently by replicator dynamics. Extensive experiments show that our bit selection approach can achieve superior performance over both naive selection methods and state-of-the-art methods under each scenario, usually with significant accuracy gains from 10% to 50% relatively.</p>

</td>
</tr>

<tr>
	<td>2013</td>
	<td><a href="/publications/fan2013supervised/">Supervised binary hash code learning with jensen shannon divergence</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Supervised binary hash code learning with jensen shannon divergence' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Supervised binary hash code learning with jensen shannon divergence' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Supervised%20binary%20hash%20code%20learning%20with%20jensen%20shannon%20divergence' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Lixin Fan</td>
	<td>ICCV</td>
	<td><p>This paper proposes to learn binary hash codes within
a statistical learning framework, in which an upper bound
of the probability of Bayes decision errors is derived for
different forms of hash functions and a rigorous proof of
the convergence of the upper bound is presented. Consequently, minimizing such an upper bound leads to consistent
performance improvements of existing hash code learning
algorithms, regardless of whether original algorithms are
unsupervised or supervised. This paper also illustrates a
fast hash coding method that exploits simple binary tests to
achieve orders of magnitude improvement in coding speed
as compared to projection based methods.</p>
</td>
</tr>

<tr>
	<td>2013</td>
	<td><a href="/publications/lin2013twostep/">A General Two-Step Approach to Learning-Based Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=A General Two-Step Approach to Learning-Based Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=A General Two-Step Approach to Learning-Based Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=A%20General%20Two-Step%20Approach%20to%20Learning-Based%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>G. Lin, C. Shen, D. Suter, A. Hengel</td>
	<td>ICCV</td>
	<td><p>Most existing approaches to hashing apply a single form of hash function, and an optimization process which
is typically deeply coupled to this specific form. This tight coupling restricts the flexibility of the method to
respond to the data, and can result in complex optimization problems that are difficult to solve. Here we propose
a flexible yet simple framework that is able to accommodate different types of loss functions and hash functions.
This framework allows a number of existing approaches to hashing to be placed in context, and simplifies the
development of new problem-specific hashing methods. Our framework decomposes hashing learning problem
into two steps: hash bit learning and hash function learning based on the learned bits. The first step can typically
be formulated as binary quadratic problems, and the second step can be accomplished by training standard binary
classifiers. Both problems have been extensively studied in the literature. Our extensive experiments demonstrate
that the proposed framework is effective, flexible and outperforms the state-of-the-art.</p>
</td>
</tr>



<tr>
	<td>2012</td>
	<td><a href="/publications/kong2012ausing/">Manhattan Hashing for Large-Scale Image Retrieval</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Manhattan Hashing for Large-Scale Image Retrieval' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Manhattan Hashing for Large-Scale Image Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Manhattan%20Hashing%20for%20Large-Scale%20Image%20Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>W. Kong, W. Li, M. Guo</td>
	<td>SIGIR</td>
	<td><p>Hashing is used to learn binary-code representation for data with
expectation of preserving the neighborhood structure in the original
feature space. Due to its fast query speed and reduced storage
cost, hashing has been widely used for efficient nearest neighbor
search in a large variety of applications like text and image retrieval.
Most existing hashing methods adopt Hamming distance to
measure the similarity (neighborhood) between points in the hashcode
space. However, one problem with Hamming distance is that
it may destroy the neighborhood structure in the original feature
space, which violates the essential goal of hashing. In this paper,
Manhattan hashing (MH), which is based on Manhattan distance, is
proposed to solve the problem of Hamming distance based hashing.
The basic idea of MH is to encode each projected dimension with
multiple bits of natural binary code (NBC), based on which the
Manhattan distance between points in the hashcode space is calculated
for nearest neighbor search. MH can effectively preserve the
neighborhood structure in the data to achieve the goal of hashing.
To the best of our knowledge, this is the first work to adopt Manhattan
distance with NBC for hashing. Experiments on several largescale
image data sets containing up to one million points show that
our MH method can significantly outperform other state-of-the-art
methods.</p>
</td>
</tr>

<tr>
	<td>2012</td>
	<td><a href="/publications/kong2012busing/">Double-Bit Quantisation for Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Double-Bit Quantisation for Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Double-Bit Quantisation for Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Double-Bit%20Quantisation%20for%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>W. Kong, W. Li</td>
	<td>AAAI</td>
	<td><p>Hashing, which tries to learn similarity-preserving binary
codes for data representation, has been widely
used for efficient nearest neighbor search in massive
databases due to its fast query speed and low storage
cost. Because it is NP hard to directly compute the best
binary codes for a given data set, mainstream hashing
methods typically adopt a two-stage strategy. In the
first stage, several projected dimensions of real values
are generated. Then in the second stage, the real values
will be quantized into binary codes by thresholding.
Currently, most existing methods use one single bit to
quantize each projected dimension. One problem with
this single-bit quantization (SBQ) is that the threshold
typically lies in the region of the highest point density
and consequently a lot of neighboring points close to
the threshold will be hashed to totally different bits,
which is unexpected according to the principle of hashing.
In this paper, we propose a novel quantization strategy,
called double-bit quantization (DBQ), to solve the
problem of SBQ. The basic idea of DBQ is to quantize
each projected dimension into double bits with adaptively
learned thresholds. Extensive experiments on two
real data sets show that our DBQ strategy can signifi-
cantly outperform traditional SBQ strategy for hashing.</p>
</td>
</tr>

<tr>
	<td>2012</td>
	<td><a href="/publications/kong2012cusing/">Isotropic Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Isotropic Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Isotropic Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Isotropic%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>W. Kong, W. Li</td>
	<td>NIPS</td>
	<td><p>Most existing hashing methods adopt some projection functions to project the original data into several dimensions of real values, and then each of these projected dimensions is quantized into one bit (zero or one) by thresholding. Typically, the variances of different projected dimensions are different for existing projection functions such as principal component analysis (PCA). Using the same number of bits for different projected dimensions is unreasonable because larger-variance dimensions will carry more information. Although this viewpoint has been widely accepted by many researchers, it is still not verified by either theory or experiment because no methods have been proposed to find a projection with equal variances for different dimensions. In this paper, we propose a novel method, called isotropic hashing (IsoHash), to learn projection functions which can produce projected dimensions with isotropic variances (equal variances). Experimental results on real data sets show that IsoHash can outperform its counterpart with different variances for different dimensions, which verifies the viewpoint that projections with isotropic variances will be better than those with anisotropic variances.</p>
</td>
</tr>

<tr>
	<td>2012</td>
	<td><a href="/publications/heo2012spherical/">Spherical Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Spherical Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Spherical Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Spherical%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>J. Heo, Y. Lee, J. He, S. Chang, S. Yoon</td>
	<td>CVPR</td>
	<td><p>Many binary code encoding schemes based on hashing
have been actively studied recently, since they can provide
efficient similarity search, especially nearest neighbor
search, and compact data representations suitable for handling
large scale image databases in many computer vision
problems. Existing hashing techniques encode highdimensional
data points by using hyperplane-based hashing
functions. In this paper we propose a novel hyperspherebased
hashing function, spherical hashing, to map more
spatially coherent data points into a binary code compared
to hyperplane-based hashing functions. Furthermore, we
propose a new binary code distance function, spherical
Hamming distance, that is tailored to our hyperspherebased
binary coding scheme, and design an efficient iterative
optimization process to achieve balanced partitioning
of data points for each hash function and independence between
hashing functions. Our extensive experiments show
that our spherical hashing technique significantly outperforms
six state-of-the-art hashing techniques based on hyperplanes
across various image benchmarks of sizes ranging
from one to 75 million of GIST descriptors. The performance
gains are consistent and large, up to 100% improvements.
The excellent results confirm the unique merits of
the proposed idea in using hyperspheres to encode proximity
regions in high-dimensional spaces. Finally, our method
is intuitive and easy to implement.</p>
</td>
</tr>

<tr>
	<td>2012</td>
	<td><a href="/publications/norouzi2012hamming/">Hamming Distance Metric Learning</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Hamming Distance Metric Learning' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Hamming Distance Metric Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Hamming%20Distance%20Metric%20Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>M. Norouzi, D. Fleet, R. Salakhutdinov</td>
	<td>NIPS</td>
	<td><p>Motivated by large-scale multimedia applications we propose to learn mappings
from high-dimensional data to binary codes that preserve semantic similarity.
Binary codes are well suited to large-scale applications as they are storage efficient and permit exact sub-linear kNN search. The framework is applicable
to broad families of mappings, and uses a flexible form of triplet ranking loss.
We overcome discontinuous optimization of the discrete mappings by minimizing
a piecewise-smooth upper bound on empirical loss, inspired by latent structural
SVMs. We develop a new loss-augmented inference algorithm that is quadratic in
the code length. We show strong retrieval performance on CIFAR-10 and MNIST,
with promising classification results using no more than kNN on the binary codes.</p>
</td>
</tr>

<tr>
	<td>2012</td>
	<td><a href="/publications/liu2012supervised/">Supervised Hashing with Kernels</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Supervised Hashing with Kernels' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Supervised Hashing with Kernels' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Supervised%20Hashing%20with%20Kernels' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>W. Liu, J. Wang, R. Ji, Y. Jiang, S. Chang</td>
	<td>CVPR</td>
	<td><p>Recent years have witnessed the growing popularity of
hashing in large-scale vision problems. It has been shown
that the hashing quality could be boosted by leveraging supervised
information into hash function learning. However,
the existing supervised methods either lack adequate performance
or often incur cumbersome model training. In this
paper, we propose a novel kernel-based supervised hashing
model which requires a limited amount of supervised information,
i.e., similar and dissimilar data pairs, and a feasible
training cost in achieving high quality hashing. The idea
is to map the data to compact binary codes whose Hamming
distances are minimized on similar pairs and simultaneously
maximized on dissimilar pairs. Our approach is
distinct from prior works by utilizing the equivalence between
optimizing the code inner products and the Hamming
distances. This enables us to sequentially and efficiently
train the hash functions one bit at a time, yielding very
short yet discriminative codes. We carry out extensive experiments
on two image benchmarks with up to one million
samples, demonstrating that our approach significantly outperforms
the state-of-the-arts in searching both metric distance
neighbors and semantically similar neighbors, with
accuracy gains ranging from 13% to 46%.</p>
</td>
</tr>

<tr>
	<td>2012</td>
	<td><a href="/publications/petrovic2012paraphrases/">Using paraphrases for improving first story detection in news and Twitter</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Using paraphrases for improving first story detection in news and Twitter' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Using paraphrases for improving first story detection in news and Twitter' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Using%20paraphrases%20for%20improving%20first%20story%20detection%20in%20news%20and%20Twitter' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>S. Petrovic, M. Osborne, V. Lavrenko</td>
	<td>NAACL</td>
	<td><p>First story detection (FSD) involves identifying
first stories about events from a continuous
stream of documents. A major problem in this
task is the high degree of lexical variation in
documents which makes it very difficult to detect
stories that talk about the same event but
expressed using different words. We suggest
using paraphrases to alleviate this problem,
making this the first work to use paraphrases
for FSD. We show a novel way of integrating
paraphrases with locality sensitive hashing
(LSH) in order to obtain an efficient FSD system
that can scale to very large datasets. Our
system achieves state-of-the-art results on the
first story detection task, beating both the best
supervised and unsupervised systems. To test
our approach on large data, we construct a corpus
of events for Twitter, consisting of 50 million
documents, and show that paraphrasing is
also beneficial in this domain.</p>
</td>
</tr>

<tr>
	<td>2012</td>
	<td><a href="/publications/zhen2012coregularised/">Co-Regularized Hashing for Multimodal Data</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Co-Regularized Hashing for Multimodal Data' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Co-Regularized Hashing for Multimodal Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Co-Regularized%20Hashing%20for%20Multimodal%20Data' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Y. Zhen, D. Yeung</td>
	<td>NIPS</td>
	<td><p>Hashing-based methods provide a very promising approach to large-scale similarity
search. To obtain compact hash codes, a recent trend seeks to learn the hash
functions from data automatically. In this paper, we study hash function learning
in the context of multimodal data. We propose a novel multimodal hash function
learning method, called Co-Regularized Hashing (CRH), based on a boosted coregularization
framework. The hash functions for each bit of the hash codes are
learned by solving DC (difference of convex functions) programs, while the learning
for multiple bits proceeds via a boosting procedure so that the bias introduced
by the hash functions can be sequentially minimized. We empirically compare
CRH with two state-of-the-art multimodal hash function learning methods on two
publicly available data sets.</p>
</td>
</tr>

<tr>
	<td>2012</td>
	<td><a href="/publications/weiss2012multi/">Multidimensional Spectral Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Multidimensional Spectral Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Multidimensional Spectral Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Multidimensional%20Spectral%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Y. Weiss, R. Fergus, A. Torralba</td>
	<td>ECCV</td>
	<td><p>en a surge of interest in methods based on “semantic hashing”,
i.e. compact binary codes of data-points so that the Hamming distance
between codewords correlates with similarity. In reviewing and
comparing existing methods, we show that their relative performance can
change drastically depending on the definition of ground-truth neighbors.
Motivated by this finding, we propose a new formulation for learning binary
codes which seeks to reconstruct the affinity between datapoints,
rather than their distances. We show that this criterion is intractable
to solve exactly, but a spectral relaxation gives an algorithm where the
bits correspond to thresholded eigenvectors of the affinity matrix, and
as the number of datapoints goes to infinity these eigenvectors converge
to eigenfunctions of Laplace-Beltrami operators, similar to the recently
proposed Spectral Hashing (SH) method. Unlike SH whose performance
may degrade as the number of bits increases, the optimal code using
our formulation is guaranteed to faithfully reproduce the affinities as
the number of bits increases. We show that the number of eigenfunctions
needed may increase exponentially with dimension, but introduce a “kernel
trick” to allow us to compute with an exponentially large number of
bits but using only memory and computation that grows linearly with
dimension. Experiments shows that MDSH outperforms the state-of-the
art, especially in the challenging regime of small distance thresholds.</p>
</td>
</tr>



<tr>
	<td>2011</td>
	<td><a href="/publications/song2011random/">Random Maximum Margin Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Random Maximum Margin Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Random Maximum Margin Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Random%20Maximum%20Margin%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>A. Joly, O. Buisson</td>
	<td>CVPR</td>
	<td><p>Following the success of hashing methods for multidimensional
indexing, more and more works are interested
in embedding visual feature space in compact hash codes.
Such approaches are not an alternative to using index structures
but a complementary way to reduce both the memory
usage and the distance computation cost. Several data
dependent hash functions have notably been proposed to
closely fit data distribution and provide better selectivity
than usual random projections such as LSH. However, improvements
occur only for relatively small hash code sizes
up to 64 or 128 bits. As discussed in the paper, this is mainly
due to the lack of independence between the produced hash
functions. We introduce a new hash function family that
attempts to solve this issue in any kernel space. Rather
than boosting the collision probability of close points, our
method focus on data scattering. By training purely random
splits of the data, regardless the closeness of the training
samples, it is indeed possible to generate consistently
more independent hash functions. On the other side, the
use of large margin classifiers allows to maintain good generalization
performances. Experiments show that our new
Random Maximum Margin Hashing scheme (RMMH) outperforms
four state-of-the-art hashing methods, notably in
kernel spaces.</p>
</td>
</tr>

<tr>
	<td>2011</td>
	<td><a href="/publications/gong2011using/">Iterative Quantization: A Procrustean Approach to Learning Binary Codes</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Iterative Quantization: A Procrustean Approach to Learning Binary Codes' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Iterative Quantization: A Procrustean Approach to Learning Binary Codes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Iterative%20Quantization:%20A%20Procrustean%20Approach%20to%20Learning%20Binary%20Codes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Y. Gong, S. Lazebnik</td>
	<td>CVPR</td>
	<td><p>This paper addresses the problem of learning similarity preserving binary codes for efficient retrieval in large-scale image collections. We propose a simple and efficient alternating minimization scheme for finding a rotation of zerocentered data so as to minimize the quantization error of
mapping this data to the vertices of a zero-centered binary
hypercube. This method, dubbed iterative quantization
(ITQ), has connections to multi-class spectral clustering
and to the orthogonal Procrustes problem, and it can be
used both with unsupervised data embeddings such as PCA
and supervised embeddings such as canonical correlation
analysis (CCA). Our experiments show that the resulting
binary coding schemes decisively outperform several other
state-of-the-art methods.</p>
</td>
</tr>

<tr>
	<td>2011</td>
	<td><a href="/publications/zhang2011composite/">Composite Hashing with Multiple Information Sources</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Composite Hashing with Multiple Information Sources' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Composite Hashing with Multiple Information Sources' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Composite%20Hashing%20with%20Multiple%20Information%20Sources' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>D. Zhang, F. Wang, L. Si</td>
	<td>SIGIR</td>
	<td><p>Similarity search applications with a large amount of text
and image data demands an efficient and effective solution.
One useful strategy is to represent the examples in databases
as compact binary codes through semantic hashing, which
has attracted much attention due to its fast query/search
speed and drastically reduced storage requirement. All of
the current semantic hashing methods only deal with the
case when each example is represented by one type of features.
However, examples are often described from several
different information sources in many real world applications.
For example, the characteristics of a webpage can be
derived from both its content part and its associated links.
To address the problem of learning good hashing codes in
this scenario, we propose a novel research problem – Composite
Hashing with Multiple Information Sources (CHMIS).
The focus of the new research problem is to design an algorithm
for incorporating the features from different information
sources into the binary hashing codes efficiently and
effectively. In particular, we propose an algorithm CHMISAW
(CHMIS with Adjusted Weights) for learning the codes.
The proposed algorithm integrates information from several
different sources into the binary hashing codes by adjusting
the weights on each individual source for maximizing
the coding performance, and enables fast conversion from
query examples to their binary hashing codes. Experimental
results on five different datasets demonstrate the superior
performance of the proposed method against several other
state-of-the-art semantic hashing techniques.</p>
</td>
</tr>

<tr>
	<td>2011</td>
	<td><a href="/publications/norouzi2011minimal/">Minimal Loss Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Minimal Loss Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Minimal Loss Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Minimal%20Loss%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>M. Norouzi, D. Fleet</td>
	<td>ICML</td>
	<td><p>We propose a method for learning similaritypreserving
hash functions that map highdimensional
data onto binary codes. The
formulation is based on structured prediction
with latent variables and a hinge-like
loss function. It is efficient to train for large
datasets, scales well to large code lengths,
and outperforms state-of-the-art methods.</p>
</td>
</tr>

<tr>
	<td>2011</td>
	<td><a href="/publications/kumar2011learning/">Learning hash functions for cross-view similarity search</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Learning hash functions for cross-view similarity search' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Learning hash functions for cross-view similarity search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Learning%20hash%20functions%20for%20cross-view%20similarity%20search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>S. Kumar, R. Udupa</td>
	<td>IJCAI</td>
	<td><p>Many applications in Multilingual and Multimodal
Information Access involve searching large
databases of high dimensional data objects with
multiple (conditionally independent) views. In this
work we consider the problem of learning hash
functions for similarity search across the views
for such applications. We propose a principled
method for learning a hash function for each view
given a set of multiview training data objects. The
hash functions map similar objects to similar codes
across the views thus enabling cross-view similarity
search. We present results from an extensive
empirical study of the proposed approach
which demonstrate its effectiveness on Japanese
language People Search and Multilingual People
Search problems.</p>
</td>
</tr>

<tr>
	<td>2011</td>
	<td><a href="/publications/liu2011hashing/">Hashing with Graphs</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Hashing with Graphs' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Hashing with Graphs' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Hashing%20with%20Graphs' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>W. Liu, J. Wang, S. Kumar, S. Chang</td>
	<td>ICML</td>
	<td><p>Hashing is becoming increasingly popular for
efficient nearest neighbor search in massive
databases. However, learning short codes
that yield good search performance is still
a challenge. Moreover, in many cases realworld
data lives on a low-dimensional manifold,
which should be taken into account
to capture meaningful nearest neighbors. In
this paper, we propose a novel graph-based
hashing method which automatically discovers
the neighborhood structure inherent in
the data to learn appropriate compact codes.
To make such an approach computationally
feasible, we utilize Anchor Graphs to obtain
tractable low-rank adjacency matrices. Our
formulation allows constant time hashing of a
new data point by extrapolating graph Laplacian
eigenvectors to eigenfunctions. Finally,
we describe a hierarchical threshold learning
procedure in which each eigenfunction yields
multiple bits, leading to higher search accuracy.
Experimental comparison with the
other state-of-the-art methods on two large
datasets demonstrates the efficacy of the proposed
method.</p>
</td>
</tr>



<tr>
	<td>2010</td>
	<td><a href="/publications/wiki2010new/">A New Approach to Cross-Modal Multimedia Retrieval</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=A New Approach to Cross-Modal Multimedia Retrieval' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=A New Approach to Cross-Modal Multimedia Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=A%20New%20Approach%20to%20Cross-Modal%20Multimedia%20Retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>N. Rasiwasia, J. Costa Pereira, E. Coviello, G. Doyle, G. Lanckriet, R.Levy and N. Vasconcelos</td>
	<td>ICME</td>
	<td><p>The collected documents are selected sections from the Wikipedia’s featured articles collection. This is a continuously growing dataset, that at the time of collection (October 2009) had 2,669 articles spread over 29 categories. Some of the categories are very scarce, therefore we considered only the 10 most populated ones. The articles generally have multiple sections and pictures. We have split them into sections based on section headings, and assign each image to the section in which it was placed by the author(s). Then this dataset was prunned to keep only sections that contained a single image and at least 70 words. 
The final corpus contains 2,866 multimedia documents. The median text length is 200 words.</p>
</td>
</tr>

<tr>
	<td>2010</td>
	<td><a href="/publications/wang2010sequential/">Sequential projection learning for hashing with compact codes</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Sequential projection learning for hashing with compact codes' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Sequential projection learning for hashing with compact codes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Sequential%20projection%20learning%20for%20hashing%20with%20compact%20codes' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>J. Wang, S. Kumar, S. Chang</td>
	<td>ICML</td>
	<td><p>Hashing based Approximate Nearest Neighbor
(ANN) search has attracted much attention
due to its fast query time and drastically
reduced storage. However, most of the hashing
methods either use random projections or
extract principal directions from the data to
derive hash functions. The resulting embedding
suffers from poor discrimination when
compact codes are used. In this paper, we
propose a novel data-dependent projection
learning method such that each hash function
is designed to correct the errors made by
the previous one sequentially. The proposed
method easily adapts to both unsupervised
and semi-supervised scenarios and shows significant
performance gains over the state-ofthe-art
methods on two large datasets containing
up to 1 million points.</p>
</td>
</tr>

<tr>
	<td>2010</td>
	<td><a href="/publications/wang2010semisupervised/">Semi-supervised hashing for scalable image retrieval</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Semi-supervised hashing for scalable image retrieval' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Semi-supervised hashing for scalable image retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Semi-supervised%20hashing%20for%20scalable%20image%20retrieval' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>J. Wang, S. Kumar, and S. Chang</td>
	<td>CVPR</td>
	<td><p>Large scale image search has recently attracted considerable
attention due to easy availability of huge amounts of
data. Several hashing methods have been proposed to allow
approximate but highly efficient search. Unsupervised
hashing methods show good performance with metric distances
but, in image search, semantic similarity is usually
given in terms of labeled pairs of images. There exist supervised
hashing methods that can handle such semantic similarity
but they are prone to overfitting when labeled data
is small or noisy. Moreover, these methods are usually very
slow to train. In this work, we propose a semi-supervised
hashing method that is formulated as minimizing empirical
error on the labeled data while maximizing variance
and independence of hash bits over the labeled and unlabeled
data. The proposed method can handle both metric as
well as semantic similarity. The experimental results on two
large datasets (up to one million samples) demonstrate its
superior performance over state-of-the-art supervised and
unsupervised methods.</p>
</td>
</tr>

<tr>
	<td>2010</td>
	<td><a href="/publications/petrovic2010streaming/">Streaming First Story Detection with application to Twitter</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Streaming First Story Detection with application to Twitter' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Streaming First Story Detection with application to Twitter' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Streaming%20First%20Story%20Detection%20with%20application%20to%20Twitter' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>S. Petrovic, M. Osborne, V. Lavrenko</td>
	<td>NAACL</td>
	<td><p>With the recent rise in popularity and size of
social media, there is a growing need for systems
that can extract useful information from
this amount of data. We address the problem
of detecting new events from a stream of
Twitter posts. To make event detection feasible
on web-scale corpora, we present an algorithm
based on locality-sensitive hashing which
is able overcome the limitations of traditional
approaches, while maintaining competitive results.
In particular, a comparison with a stateof-the-art
system on the first story detection
task shows that we achieve over an order of
magnitude speedup in processing time, while
retaining comparable performance. Event detection
experiments on a collection of 160 million
Twitter posts show that celebrity deaths
are the fastest spreading news on Twitter.</p>
</td>
</tr>

<tr>
	<td>2010</td>
	<td><a href="/publications/zhang2010self/">Self-Taught Hashing for Fast Similarity Search</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Self-Taught Hashing for Fast Similarity Search' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Self-Taught Hashing for Fast Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Self-Taught%20Hashing%20for%20Fast%20Similarity%20Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>D. Zhang, J. Wang, D. Cai, and J. Lu</td>
	<td>SIGIR</td>
	<td><p>The ability of fast similarity search at large scale is of great
importance to many Information Retrieval (IR) applications.
A promising way to accelerate similarity search is semantic
hashing which designs compact binary codes for a large number
of documents so that semantically similar documents
are mapped to similar codes (within a short Hamming distance).
Although some recently proposed techniques are
able to generate high-quality codes for documents known
in advance, obtaining the codes for previously unseen documents
remains to be a very challenging problem. In this
paper, we emphasise this issue and propose a novel SelfTaught
Hashing (STH) approach to semantic hashing: we
first find the optimal l-bit binary codes for all documents in
the given corpus via unsupervised learning, and then train
l classifiers via supervised learning to predict the l-bit code
for any query document unseen before. Our experiments on
three real-world text datasets show that the proposed approach
using binarised Laplacian Eigenmap (LapEig) and
linear Support Vector Machine (SVM) outperforms stateof-the-art
techniques significantly.</p>
</td>
</tr>

<tr>
	<td>2010</td>
	<td><a href="/publications/jain2010hashing/">Hashing Hyperplane Queries to Near Points with Applications to Large-Scale Active Learning</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Hashing Hyperplane Queries to Near Points with Applications to Large-Scale Active Learning' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Hashing Hyperplane Queries to Near Points with Applications to Large-Scale Active Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Hashing%20Hyperplane%20Queries%20to%20Near%20Points%20with%20Applications%20to%20Large-Scale%20Active%20Learning' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>P. Jain, S. Vijayanarasimhan, K. Grauman</td>
	<td>NIPS</td>
	<td><p>We consider the problem of retrieving the database points nearest to a given hyperplane query without exhaustively scanning the 
database. We propose two hashing-based solutions. Our first approach maps the data to two-bit binary keys that are locality-sensitive for the angle between the hyperplane normal and a database point. Our second approach embeds the data into a vector space where the Euclidean norm reflects the desired distance between the original points and hyperplane query. Both use hashing to retrieve near points in sub-linear time. Our first method’s preprocessing stage is more efficient, while the second has stronger accuracy guarantees. We apply both to pool-based active learning: taking the current hyperplane classifier as a query, our algorithm identifies those points (approximately) satisfying the well-known minimal distance-to-hyperplane selection criterion. We empirically demonstrate our methods’ tradeoffs, and show that they make it practical to perform active selection with millions 
of unlabeled points.</p>
</td>
</tr>



<tr>
	<td>2009</td>
	<td><a href="/publications/kulis2009learning/">Learning to Hash with Binary Reconstructive Embeddings</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Learning to Hash with Binary Reconstructive Embeddings' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Learning to Hash with Binary Reconstructive Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Learning%20to%20Hash%20with%20Binary%20Reconstructive%20Embeddings' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>B. Kulis, T. Darrell</td>
	<td>NIPS</td>
	<td><p>Fast retrieval methods are increasingly critical for many large-scale analysis tasks, and there have been
several recent methods that attempt to learn hash functions for fast and accurate nearest neighbor searches.
In this paper, we develop an algorithm for learning hash functions based on explicitly minimizing the
reconstruction error between the original distances and the Hamming distances of the corresponding binary
embeddings. We develop a scalable coordinate-descent algorithm for our proposed hashing objective that
is able to efficiently learn hash functions in a variety of settings. Unlike existing methods such as semantic
hashing and spectral hashing, our method is easily kernelized and does not require restrictive assumptions
about the underlying distribution of the data. We present results over several domains to demonstrate that
our method outperforms existing state-of-the-art techniques.</p>
</td>
</tr>

<tr>
	<td>2009</td>
	<td><a href="/publications/weiss2009spectral/">Spectral Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Spectral Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Spectral Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Spectral%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Y. Weiss, A. Torralba, R. Fergus</td>
	<td>NIPS</td>
	<td><p>Semantic hashing seeks compact binary codes of data-points so that the
Hamming distance between codewords correlates with semantic similarity.
In this paper, we show that the problem of finding a best code for a given
dataset is closely related to the problem of graph partitioning and can
be shown to be NP hard. By relaxing the original problem, we obtain a
spectral method whose solutions are simply a subset of thresholded eigenvectors
of the graph Laplacian. By utilizing recent results on convergence
of graph Laplacian eigenvectors to the Laplace-Beltrami eigenfunctions of
manifolds, we show how to efficiently calculate the code of a novel datapoint.
Taken together, both learning the code and applying it to a novel
point are extremely simple. Our experiments show that our codes outperform
the state-of-the art.</p>
</td>
</tr>

<tr>
	<td>2009</td>
	<td><a href="/publications/jain2009fast/">Fast Similarity Search for Learned Metrics</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Fast Similarity Search for Learned Metrics' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Fast Similarity Search for Learned Metrics' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Fast%20Similarity%20Search%20for%20Learned%20Metrics' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>P. Jain, B. Kulis, K. Grauman</td>
	<td>TPAMI</td>
	<td><p>We propose a method to efficiently index into a large database of examples according to a learned metric.
Given a collection of examples, we learn a Mahalanobis distance using an information-theoretic metric
learning technique that adapts prior knowledge about pairwise distances to incorporate similarity and dissimilarity
constraints. To enable sub-linear time similarity search under the learned metric, we show how
to encode a learned Mahalanobis parameterization into randomized locality-sensitive hash functions. We
further formulate an indirect solution that enables metric learning and hashing for sparse input vector spaces
whose high dimensionality make it infeasible to learn an explicit weighting over the feature dimensions.
We demonstrate the approach applied to systems and image datasets, and show that our learned metrics
improve accuracy relative to commonly-used metric baselines, while our hashing construction permits effi-
cient indexing with a learned distance and very large databases.</p>
</td>
</tr>

<tr>
	<td>2009</td>
	<td><a href="/publications/kulis2009kernelized/">Kernelized Locality-Sensitive Hashing for Scalable Image Search</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Kernelized Locality-Sensitive Hashing for Scalable Image Search' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Kernelized Locality-Sensitive Hashing for Scalable Image Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Kernelized%20Locality-Sensitive%20Hashing%20for%20Scalable%20Image%20Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>B. Kulis, K. Grauman</td>
	<td>ICCV</td>
	<td><p>Fast retrieval methods are critical for large-scale and
data-driven vision applications. Recent work has explored
ways to embed high-dimensional features or complex distance
functions into a low-dimensional Hamming space
where items can be efficiently searched. However, existing
methods do not apply for high-dimensional kernelized
data when the underlying feature embedding for the kernel
is unknown. We show how to generalize locality-sensitive
hashing to accommodate arbitrary kernel functions, making
it possible to preserve the algorithm’s sub-linear time similarity
search guarantees for a wide class of useful similarity
functions. Since a number of successful image-based kernels
have unknown or incomputable embeddings, this is especially
valuable for image retrieval tasks. We validate our
technique on several large-scale datasets, and show that it
enables accurate and fast performance for example-based
object classification, feature matching, and content-based
retrieval.</p>
</td>
</tr>

<tr>
	<td>2009</td>
	<td><a href="/publications/cifar2009learning/">Learning Multiple Layers of Features from Tiny Images</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Learning Multiple Layers of Features from Tiny Images' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Learning Multiple Layers of Features from Tiny Images' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Learning%20Multiple%20Layers%20of%20Features%20from%20Tiny%20Images' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>A. Krizhevsky</td>
	<td>University of Toronto</td>
	<td><p>Groups at MIT and NYU have collected a dataset of millions of tiny colour images from the web. It
is, in principle, an excellent dataset for unsupervised training of deep generative models, but previous
researchers who have tried this have found it difficult to learn a good set of
filters from the images.
We show how to train a multi-layer generative model that learns to extract meaningful features which
resemble those found in the human visual cortex. Using a novel parallelization algorithm to distribute
the work among multiple machines connected on a network, we show how training such a model can be
done in reasonable time.
A second problematic aspect of the tiny images dataset is that there are no reliable class labels
which makes it hard to use for object recognition experiments. We created two sets of reliable labels.
The CIFAR-10 set has 6000 examples of each of 10 classes and the CIFAR-100 set has 600 examples of
each of 100 non-overlapping classes. Using these labels, we show that object recognition is significantly
improved by pre-training a layer of features on a large set of unlabeled tiny images.</p>
</td>
</tr>

<tr>
	<td>2009</td>
	<td><a href="/publications/raginsky2009locality/">Locality-sensitive binary codes from shift-invariant kernels</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Locality-sensitive binary codes from shift-invariant kernels' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Locality-sensitive binary codes from shift-invariant kernels' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Locality-sensitive%20binary%20codes%20from%20shift-invariant%20kernels' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>M. Raginsky, S. Lazebnik</td>
	<td>NIPS</td>
	<td><p>This paper addresses the problem of designing binary codes for high-dimensional
data such that vectors that are similar in the original space map to similar binary
strings. We introduce a simple distribution-free encoding scheme based on
random projections, such that the expected Hamming distance between the binary
codes of two vectors is related to the value of a shift-invariant kernel (e.g., a
Gaussian kernel) between the vectors. We present a full theoretical analysis of the
convergence properties of the proposed scheme, and report favorable experimental
performance as compared to a recent state-of-the-art method, spectral hashing.</p>
</td>
</tr>

<tr>
	<td>2009</td>
	<td><a href="/publications/imagenet2009using/">ImageNet: A large-scale hierarchical image database</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=ImageNet: A large-scale hierarchical image database' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=ImageNet: A large-scale hierarchical image database' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=ImageNet:%20A%20large-scale%20hierarchical%20image%20database' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>J. Deng, W. Dong, R. Socher, L. Li, K. Li, L. Fei-Fei</td>
	<td>CVPR</td>
	<td><p>The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called “ImageNet”, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.</p>
</td>
</tr>

<tr>
	<td>2009</td>
	<td><a href="/publications/nuswide2009nuswide/">NUS-WIDE: a real-world web image database from National University of Singapore</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=NUS-WIDE: a real-world web image database from National University of Singapore' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=NUS-WIDE: a real-world web image database from National University of Singapore' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=NUS-WIDE:%20a%20real-world%20web%20image%20database%20from%20National%20University%20of%20Singapore' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>T. Chua, J. Tang, R. Hong, H. Li, Z. Luo, Y. Zheng</td>
	<td>CIVR</td>
	<td><p>This paper introduces a web image dataset created by NUS’s Lab for Media Search. The dataset includes: (1) 269,648 images and the associated tags from Flickr, with a total of 5,018 unique tags; (2) six types of low-level features extracted from these images, including 64-D color histogram, 144-D color correlogram, 73-D edge direction histogram, 128-D wavelet texture, 225-D block-wise color moments extracted over 5x5 fixed grid partitions, and 500-D bag of words based on SIFT descriptions; and (3) ground-truth for 81 concepts that can be used for evaluation. Based on this dataset, we highlight characteristics of Web image collections and identify four research issues on web image annotation and retrieval. We also provide the baseline results for web image annotation by learning from the tags using the traditional k-NN algorithm. The benchmark results indicate that it is possible to learn effective models from sufficiently large image dataset to facilitate general image retrieval.</p>
</td>
</tr>

<tr>
	<td>2009</td>
	<td><a href="/publications/sift1m2009searching/">Searching with quantization: approximate nearest neighbor search using short codes and distance estimators</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Searching with quantization: approximate nearest neighbor search using short codes and distance estimators' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Searching with quantization: approximate nearest neighbor search using short codes and distance estimators' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Searching%20with%20quantization:%20approximate%20nearest%20neighbor%20search%20using%20short%20codes%20and%20distance%20estimators' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>H. Jegou, M. Douze, C. Schmid</td>
	<td>INRIA Technical Report</td>
	<td><p>We propose an approximate nearest neighbor search method based
on quantization. It uses, in particular, product quantizer to produce short codes
and corresponding distance estimators approximating the Euclidean distance
between the orginal vectors. The method is advantageously used in an asymmetric
manner, by computing the distance between a vector and code, unlike
competing techniques such as spectral hashing that only compare codes.
Our approach approximates the Euclidean distance based on memory efficient codes and, thus, permits efficient nearest neighbor search. Experiments
performed on SIFT and GIST image descriptors show excellent search accuracy.
The method is shown to outperform two state-of-the-art approaches of the literature.
Timings measured when searching a vector set of 2 billion vectors are
shown to be excellent given the high accuracy of the method.</p>
</td>
</tr>



<tr>
	<td>2008</td>
	<td><a href="/publications/mirflickr2008new/">The MIR Flickr Retrieval Evaluation.</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=The MIR Flickr Retrieval Evaluation.' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=The MIR Flickr Retrieval Evaluation.' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=The%20MIR%20Flickr%20Retrieval%20Evaluation.' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>M. J. Huiskes, M. S. Lew</td>
	<td>MIR</td>
	<td><p>In most well known image retrieval test sets, the imagery
typically cannot be freely distributed or is not representative of a
large community of users. In this paper we present a collection
for the MIR community comprising 25000 images from the Flickr
website which are redistributable for research purposes and
represent a real community of users both in the image content and
image tags. We have extracted the tags and EXIF image metadata,
and also make all of these publicly available. In addition we
discuss several challenges for benchmarking retrieval and
classification methods.</p>
</td>
</tr>

<tr>
	<td>2008</td>
	<td><a href="/publications/tiny2008million/">80 million tiny images: a large dataset for non-parametric object and scene recognition</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=80 million tiny images: a large dataset for non-parametric object and scene recognition' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=80 million tiny images: a large dataset for non-parametric object and scene recognition' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=80%20million%20tiny%20images:%20a%20large%20dataset%20for%20non-parametric%20object%20and%20scene%20recognition' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>A. Torralba, R. Fergus and W. Freeman</td>
	<td>TPAMI</td>
	<td><p>With the advent of the Internet, billions of images
are now freely available online and constitute a dense sampling
of the visual world. Using a variety of non-parametric methods,
we explore this world with the aid of a large dataset of 79,302,017
images collected from the Web. Motivated by psychophysical
results showing the remarkable tolerance of the human visual
system to degradations in image resolution, the images in the
dataset are stored as 32 × 32 color images. Each image is
loosely labeled with one of the 75,062 non-abstract nouns in
English, as listed in the Wordnet lexical database. Hence the
image database gives a comprehensive coverage of all object
categories and scenes. The semantic information from Wordnet
can be used in conjunction with nearest-neighbor methods to
perform object classification over a range of semantic levels
minimizing the effects of labeling noise. For certain classes that
are particularly prevalent in the dataset, such as people, we are
able to demonstrate a recognition performance comparable to
class-specific Viola-Jones style detectors.</p>
</td>
</tr>



<tr>
	<td>2007</td>
	<td><a href="/publications/lv2007probe/">Multi-Probe LSH: Efficient Indexing for High-Dimensional Similarity Search</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Multi-Probe LSH: Efficient Indexing for High-Dimensional Similarity Search' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Multi-Probe LSH: Efficient Indexing for High-Dimensional Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Multi-Probe%20LSH:%20Efficient%20Indexing%20for%20High-Dimensional%20Similarity%20Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Q. Lv, W. Josephson, Z. Wang, M. Charikar, K. Li</td>
	<td>VLDB</td>
	<td><p>Similarity indices for high-dimensional data are very desirable for building content-based search systems for featurerich data such as audio, images, videos, and other sensor
data. Recently, locality sensitive hashing (LSH) and its
variations have been proposed as indexing techniques for
approximate similarity search. A significant drawback of
these approaches is the requirement for a large number of
hash tables in order to achieve good search quality. This paper proposes a new indexing scheme called multi-probe LSH
that overcomes this drawback. Multi-probe LSH is built on
the well-known LSH technique, but it intelligently probes
multiple buckets that are likely to contain query results in
a hash table. Our method is inspired by and improves upon
recent theoretical work on entropy-based LSH designed to
reduce the space requirement of the basic LSH method. We
have implemented the multi-probe LSH method and evaluated the implementation with two different high-dimensional
datasets. Our evaluation shows that the multi-probe LSH
method substantially improves upon previously proposed
methods in both space and time efficiency. To achieve the
same search quality, multi-probe LSH has a similar timeefficiency as the basic LSH method while reducing the number of hash tables by an order of magnitude. In comparison
with the entropy-based LSH method, to achieve the same
search quality, multi-probe LSH uses less query time and 5
to 8 times fewer number of hash tables.</p>
</td>
</tr>

<tr>
	<td>2007</td>
	<td><a href="/publications/labelme2007labelme/">LabelMe: a database and web-based tool for image annotation</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=LabelMe: a database and web-based tool for image annotation' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=LabelMe: a database and web-based tool for image annotation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=LabelMe:%20a%20database%20and%20web-based%20tool%20for%20image%20annotation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>B. Russell, A. Torralba, K. Murphy, W. T. Freeman</td>
	<td>IJCV</td>
	<td><p>We seek to build a large collection of images with ground truth labels to be used for object
detection and recognition research. Such data is useful for supervised learning and quantitative evaluation. To achieve this, we developed a web-based tool that allows easy image annotation
and instant sharing of such annotations. Using this annotation tool, we have collected a large
dataset that spans many object categories, often containing multiple instances over a wide variety
of images. We quantify the contents of the dataset and compare against existing state of the
art datasets used for object recognition and detection. Also, we show how to extend the dataset
to automatically enhance object labels with WordNet, discover object parts, recover a depth ordering
of objects in a scene, and increase the number of labels using minimal user supervision
and images from the web.</p>
</td>
</tr>

<tr>
	<td>2007</td>
	<td><a href="/publications/salakhutdinov2007semantic/">Semantic Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Semantic Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Semantic Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Semantic%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>R. Salakhutdinov, G. Hinton</td>
	<td>NIPS</td>
	<td><p>We show how to learn a deep graphical model of the word-count
vectors obtained from a large set of documents. The values of the
latent variables in the deepest layer are easy to infer and give a
much better representation of each document than Latent Semantic
Analysis. When the deepest layer is forced to use a small number of
binary variables (e.g. 32), the graphical model performs “semantic
hashing”: Documents are mapped to memory addresses in such a
way that semantically similar documents are located at nearby addresses.
Documents similar to a query document can then be found
by simply accessing all the addresses that differ by only a few bits
from the address of the query document. This way of extending the
efficiency of hash-coding to approximate matching is much faster
than locality sensitive hashing, which is the fastest current method.
By using semantic hashing to filter the documents given to TF-IDF,
we achieve higher accuracy than applying TF-IDF to the entire document
set.</p>
</td>
</tr>



<tr>
	<td>2006</td>
	<td><a href="/publications/andoni2006near/">Near-Optimal Hashing Algorithms for Approximate Nearest Neighbor in High Dimensions</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Near-Optimal Hashing Algorithms for Approximate Nearest Neighbor in High Dimensions' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Near-Optimal Hashing Algorithms for Approximate Nearest Neighbor in High Dimensions' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Near-Optimal%20Hashing%20Algorithms%20for%20Approximate%20Nearest%20Neighbor%20in%20High%20Dimensions' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>A. Andoni, P. Indyk</td>
	<td>FOCS</td>
	<td><p>We present an algorithm for the c-approximate nearest neighbor problem in a d-dimensional Euclidean space, achieving query time of O(dn 1c2/+o(1)) and space O(dn + n1+1c2/+o(1)). This almost matches the lower bound for hashing-based algorithm recently obtained in (R. Motwani et al., 2006). We also obtain a space-efficient version of the algorithm, which uses dn+n logO(1) n space, with a query time of dnO(1/c2). Finally, we discuss practical variants of the algorithms that utilize fast bounded-distance decoders for the Leech lattice</p>
</td>
</tr>



<tr>
	<td>2005</td>
	<td><a href="/publications/bawa2005forest/">LSH Forest: Self-Tuning Indexes for Similarity Search</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=LSH Forest: Self-Tuning Indexes for Similarity Search' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=LSH Forest: Self-Tuning Indexes for Similarity Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=LSH%20Forest:%20Self-Tuning%20Indexes%20for%20Similarity%20Search' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>M. Bawa, T. Condie, P. Ganesan</td>
	<td>WWW</td>
	<td><p>We consider the problem of indexing high-dimensional data for answering (approximate) similarity-search queries. Similarity indexes prove to be important in a wide variety of settings: Web search
engines desire fast, parallel, main-memory-based indexes for similarity search on text data; database systems desire disk-based similarity indexes for high-dimensional data, including text and images;
peer-to-peer systems desire distributed similarity indexes with low
communication cost. We propose an indexing scheme called LSH
Forest which is applicable in all the above contexts. Our index uses the well-known technique of locality-sensitive hashing (LSH),
but improves upon previous designs by (a) eliminating the different data-dependent parameters for which LSH must be constantly hand-tuned, and (b) improving on LSH’s performance guarantees for skewed data distributions while retaining the same storage
and query overhead. We show how to construct this index in main
memory, on disk, in parallel systems, and in peer-to-peer systems.
We evaluate the design with experiments on multiple text corpora
and demonstrate both the self-tuning nature and the superior performance of LSH Forest.</p>
</td>
</tr>



<tr>
	<td>2004</td>
	<td><a href="/publications/datar2004locality/">Locality-sensitive hashing scheme based on p-stable distributions</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Locality-sensitive hashing scheme based on p-stable distributions' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Locality-sensitive hashing scheme based on p-stable distributions' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Locality-sensitive%20hashing%20scheme%20based%20on%20p-stable%20distributions' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>M. Datar, N. Immorlica, P. Indyk, V. Mirrokni</td>
	<td>SCG</td>
	<td><p>We present a novel Locality-Sensitive Hashing scheme for the Approximate Nearest Neighbor Problem under lp norm, based on p-stable distributions.Our scheme improves the running time of the earlier algorithm for the case of the lp norm. It also yields the first known provably efficient approximate NN algorithm for the case p&lt;1. We also show that the algorithm finds the exact near neigbhor in O(log n) time for data satisfying certain “bounded growth” condition.Unlike earlier schemes, our LSH scheme works directly on points in the Euclidean space without embeddings. Consequently, the resulting query time bound is free of large factors and is simple and easy to implement. Our experiments (on synthetic data sets) show that the our data structure is up to 40 times faster than kd-tree.</p>
</td>
</tr>



<tr>
	<td>1999</td>
	<td><a href="/publications/gionis1999similarity/">Similarity Search in High Dimensions via Hashing</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=Similarity Search in High Dimensions via Hashing' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=Similarity Search in High Dimensions via Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=Similarity%20Search%20in%20High%20Dimensions%20via%20Hashing' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>A. Gionis, P. Indyk, R. Motwani</td>
	<td>VLDB</td>
	<td><p>The nearest- or near-neighbor query problems arise in a large variety of database applications, usually in the context of similarity searching. Of late, there has been increasing interest in building search/index structures for performing similarity search over high-dimensional data, e.g., image databases, document collections, time-series databases, and genome databases. Unfortunately,
all known techniques for solving this problem fall prey to the curse of dimensionality. That is, the data structures scale poorly with data dimensionality;
in fact, if the number of dimensions exceeds 10 to 20, searching in k-d trees and related structures involves the inspection of a large fraction of the database, thereby doing no better than brute-force linear search. It has been suggested that since the selection of features and the choice of a distance metric in typical applications is rather heuristic, determining an approximate nearest neighbor should suffice for most practical purposes. In this paper, we examine a novel scheme for approximate similarity search based on hashing. The basic idea is to hash the points from the database so as to ensure that the probability of collision is much higher for objects that are close to each other than for those that are far apart. We provide experimental evidence that our
method gives significant improvement in running time over other methods for searching in highdimensional spaces based on hierarchical tree decomposition.
Experimental results also indicate that our scheme scales well even for a relatively large number of dimensions (more than 50).</p>
</td>
</tr>

<tr>
	<td>1999</td>
	<td><a href="/publications/mnist1999mnist/">The MNIST Database of Handwritten Digits</a>
		<span class="externallinks">
			&nbsp;<a href='http://scholar.google.com/scholar?q=The MNIST Database of Handwritten Digits' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
			<a href='https://www.semanticscholar.org/search?q=The MNIST Database of Handwritten Digits' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
			<a href='http://academic.microsoft.com/#/search?iq=The%20MNIST%20Database%20of%20Handwritten%20Digits' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
		</span>
	</td>
	<td>Y. LeCun, C. Cortes, C. Burges</td>
	<td></td>
	<td><p>The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.
It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting.</p>
</td>
</tr>


</tbody></table>

<script>
var datatable;
function searchTable() {
    var hash = decodeURIComponent(window.location.hash.substr(1));
    datatable.search(hash).draw();
}
$(document).ready( function () {
    datatable = $('#allPapers').DataTable({
		paging: false,
		"order": [[ 0, 'desc' ], [ 1, 'asc' ]],
		columnDefs: [
			{
				targets: [3, 4],
				visible: false,
				searchable: true
			}]
		});
    searchTable();
});
$(window).on('hashchange', function() {
  searchTable();
});
</script>

    </div>

  </body>
</html>
