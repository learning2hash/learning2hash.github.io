[["shoeybi2019megatron", "Megatron-lm Training Multi-billion Parameter Language Models Using Model Parallelism"], ["shi2022language", "Language Models Are Multilingual Chain-of-thought Reasoners"], ["muennighoff2022crosslingual", "Crosslingual Generalization Through Multitask Finetuning"], ["xue2020massively", "Mt5 A Massively Multilingual Pre-trained Text-to-text Transformer"]]