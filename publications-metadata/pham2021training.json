[["qin2021hardware", "Hardware-friendly Deep Learning By Network Quantization And Binarization"], ["nardini2023neural", "Neural Network Compression Using Binarization And Few Full-precision Weights"], ["nayak2019bit", "Bit Efficient Quantization For Deep Neural Networks"], ["zhou2017deep", "Deep Hashing With Triplet Quantization Loss"]]