[["nayak2019bit", "Bit Efficient Quantization For Deep Neural Networks"], ["qin2021hardware", "Hardware-friendly Deep Learning By Network Quantization And Binarization"], ["qu2019adaptive", "Adaptive Loss-aware Quantization For Multi-bit Networks"], ["wang2016affinity", "Affinity Preserving Quantization For Hashing: A Vector Quantization Approach To Learning Compact Binary Codes"]]