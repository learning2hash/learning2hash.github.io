[["liu2021p", "P-tuning V2 Prompt Tuning Can Be Comparable To Fine-tuning Universally Across Scales And Tasks"], ["ge2023chain", "Chain Of Thought Prompt Tuning In Vision Language Models"], ["wei2023symbol", "Symbol Tuning Improves In-context Learning In Language Models"], ["gonen2022demystifying", "Demystifying Prompts In Language Models Via Perplexity Estimation"]]