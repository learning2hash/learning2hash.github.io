[["ruoss2023randomized", "Randomized Positional Encodings Boost Length Generalization Of Transformers"], ["peng2023rwkv", "RWKV Reinventing Rnns For The Transformer Era"], ["gu2023mamba", "Mamba Linear-time Sequence Modeling With Selective State Spaces"], ["bulatov2023scaling", "Scaling Transformer To 1M Tokens And Beyond With RMT"]]