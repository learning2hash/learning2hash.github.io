[["ma2024drop", "Drop Your Decoder: Pre-training With Bag-of-word Prediction For Dense Passage Retrieval"], ["lu2021less", "Less Is More: Pre-train A Strong Text Encoder For Dense Retrieval Using A Weak Decoder"], ["wu2023cot", "Cot-mae V2: Contextual Masked Auto-encoder With Multi-view Modeling For Passage Retrieval"], ["ma2023cot", "Cot-mote: Exploring Contextual Masked Auto-encoder Pre-training With Mixture-of-textual-experts For Passage Retrieval"]]