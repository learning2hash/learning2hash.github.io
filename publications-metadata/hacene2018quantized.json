[["zhao2019focused", "Focused Quantization For Sparse Cnns"], ["kwon2019structured", "Structured Compression By Weight Encryption For Unstructured Pruning And Quantization"], ["nardini2023neural", "Neural Network Compression Using Binarization And Few Full-precision Weights"], ["bahou2018xnorbin", "XNORBIN: A 95 Top/s/w Hardware Accelerator For Binary Convolutional Neural Networks"]]