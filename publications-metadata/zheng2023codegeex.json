[["soltan2022alexatm", "Alexatm 20B Few-shot Learning Using A Large-scale Multilingual Seq2seq Model"], ["shi2022language", "Language Models Are Multilingual Chain-of-thought Reasoners"], ["xue2020massively", "Mt5 A Massively Multilingual Pre-trained Text-to-text Transformer"], ["li2022competition", "Competition-level Code Generation With Alphacode"]]