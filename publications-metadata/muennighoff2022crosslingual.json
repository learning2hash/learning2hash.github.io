[["soltan2022alexatm", "Alexatm 20B Few-shot Learning Using A Large-scale Multilingual Seq2seq Model"], ["won2022scaling", "Scaling Instruction-finetuned Language Models"], ["sanh2021multitask", "Multitask Prompted Training Enables Zero-shot Task Generalization"], ["workshop2022bloom", "BLOOM A 176b-parameter Open-access Multilingual Language Model"]]