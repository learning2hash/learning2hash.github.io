[["merrick2024embedding", "Embedding And Clustering Your Data Can Improve Contrastive Pretraining"], ["jang2024distilling", "Distilling Vision-language Pretraining For Efficient Cross-modal Retrieval"], ["jang2022unifying", "Unifying Vision-language Representation Space With Single-tower Transformer"], ["zhong2022evaluating", "Evaluating Token-level And Passage-level Dense Retrieval Models For Math Information Retrieval"]]