[["yin2016quantization", "Quantization And Training Of Low Bit-width Convolutional Neural Networks For Object Detection"], ["nardini2023neural", "Neural Network Compression Using Binarization And Few Full-precision Weights"], ["wen2020exploiting", "Exploiting Weight Redundancy In Cnns: Beyond Pruning And Quantization"], ["nayak2019bit", "Bit Efficient Quantization For Deep Neural Networks"]]