[["liu2023blockwise", "Blockwise Parallel Transformer For Large Context Models"], ["peng2023rwkv", "RWKV Reinventing Rnns For The Transformer Era"], ["shoeybi2019megatron", "Megatron-lm Training Multi-billion Parameter Language Models Using Model Parallelism"], ["tay2022transcending", "Transcending Scaling Laws With 0.1 Extra Compute"]]