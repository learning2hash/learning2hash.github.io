[["wei2021finetuned", "Finetuned Language Models Are Zero-shot Learners"], ["liu2021p", "P-tuning V2 Prompt Tuning Can Be Comparable To Fine-tuning Universally Across Scales And Tasks"], ["lester2021power", "The Power Of Scale For Parameter-efficient Prompt Tuning"], ["longpre2023flan", "The Flan Collection Designing Data And Methods For Effective Instruction Tuning"]]