[["tay2022transcending", "Transcending Scaling Laws With 0.1 Extra Compute"], ["won2022scaling", "Scaling Instruction-finetuned Language Models"], ["soltan2022alexatm", "Alexatm 20B Few-shot Learning Using A Large-scale Multilingual Seq2seq Model"], ["w2021scaling", "Scaling Language Models Methods Analysis Insights From Training Gopher"]]