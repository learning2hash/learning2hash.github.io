[["he2023exploring", "Exploring Human-like Translation Strategy With Large Language Models"], ["nllb2022no", "No Language Left Behind Scaling Human-centered Machine Translation"], ["vaswani2017attention", "Attention Is All You Need"], ["shoeybi2019megatron", "Megatron-lm Training Multi-billion Parameter Language Models Using Model Parallelism"]]