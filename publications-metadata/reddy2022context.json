[["wang2020distilling", "Distilling Knowledge By Mimicking Features"], ["he2024bit", "Bit-mask Robust Contrastive Knowledge Distillation For Unsupervised Semantic Hashing"], ["ma2023let", "Let All Be Whitened: Multi-teacher Distillation For Efficient Visual Retrieval"], ["jang2024distilling", "Distilling Vision-language Pretraining For Efficient Cross-modal Retrieval"]]